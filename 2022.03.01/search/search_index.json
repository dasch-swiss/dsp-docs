{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DaSCH Service Platform Documentation Since 2017, the Data and Service Center for the Humanities (DaSCH) has been a member of the Swiss Academy of Humanities and Social Sciences. The main task of the institution is to operate a platform for humanities research data that ensures access to this data. In addition, the networking of data with other databases is to be promoted (linked open data), thus creating added value for research and the interested public. Services The task of the DaSCH is to promote and support the generation, use and long-term availability of research data in the humanities in Switzerland. The focus is on making research data in the humanities available online over the long term in the most direct and easy-to-use way possible and supporting researchers in using them for further research projects (\"re-use of research data\"). The DaSCH operates the necessary infrastructures (a so called \"keep-alive\" archive) and supports researchers in using this infrastructure. In order to reach this goal, the DaSCH offers the following services: Long term hosting of research data The infrastructure of the DaSCH is designed to host and keep accessible complex qualitative research data (e.g. any kind of databases and associated digital objects such as digital texts, images, movies, audio). The data has to be migrated to the infrastructure (both hardware and software) maintained by the DaSCH. All data will be held with a minimal redundancy of 6 identical copies at two geographically different locations in Switzerland (based on switchEngines) for an undefinite amount of time. Access to the data is provided by an API based on widely adopted standards (e.g. RESTful based on JSON-LD, IIIF, RDF, TEI/XML etc.) and through a generic web interface. In order to fulfill these requirements, DaSCH develops and maintains various software tools which are described and documented here. Documentation For researchers If you are a researcher you're probably most interested in the usage of the generic web application. In this case please have a look at our DSP-APP documentation . For developers The documentation for developers is split into different groups depending on the software repository. Overview DSP-API is the main software framework in the back-end. DSP-APP DSP-Tools is a python library to enable researchers and data stuarts to work with the API (e.g. creating data models, uploading data, etc.). DSP Libraries Sipi For the community In case of further questions, bug reports or if you want to get in contact with us have a look at our community page .","title":"Overview"},{"location":"#dasch-service-platform-documentation","text":"Since 2017, the Data and Service Center for the Humanities (DaSCH) has been a member of the Swiss Academy of Humanities and Social Sciences. The main task of the institution is to operate a platform for humanities research data that ensures access to this data. In addition, the networking of data with other databases is to be promoted (linked open data), thus creating added value for research and the interested public.","title":"DaSCH Service Platform Documentation"},{"location":"#services","text":"The task of the DaSCH is to promote and support the generation, use and long-term availability of research data in the humanities in Switzerland. The focus is on making research data in the humanities available online over the long term in the most direct and easy-to-use way possible and supporting researchers in using them for further research projects (\"re-use of research data\"). The DaSCH operates the necessary infrastructures (a so called \"keep-alive\" archive) and supports researchers in using this infrastructure. In order to reach this goal, the DaSCH offers the following services:","title":"Services"},{"location":"#long-term-hosting-of-research-data","text":"The infrastructure of the DaSCH is designed to host and keep accessible complex qualitative research data (e.g. any kind of databases and associated digital objects such as digital texts, images, movies, audio). The data has to be migrated to the infrastructure (both hardware and software) maintained by the DaSCH. All data will be held with a minimal redundancy of 6 identical copies at two geographically different locations in Switzerland (based on switchEngines) for an undefinite amount of time. Access to the data is provided by an API based on widely adopted standards (e.g. RESTful based on JSON-LD, IIIF, RDF, TEI/XML etc.) and through a generic web interface. In order to fulfill these requirements, DaSCH develops and maintains various software tools which are described and documented here.","title":"Long term hosting of research data"},{"location":"#documentation","text":"","title":"Documentation"},{"location":"#for-researchers","text":"If you are a researcher you're probably most interested in the usage of the generic web application. In this case please have a look at our DSP-APP documentation .","title":"For researchers"},{"location":"#for-developers","text":"The documentation for developers is split into different groups depending on the software repository. Overview DSP-API is the main software framework in the back-end. DSP-APP DSP-Tools is a python library to enable researchers and data stuarts to work with the API (e.g. creating data models, uploading data, etc.). DSP Libraries Sipi","title":"For developers"},{"location":"#for-the-community","text":"In case of further questions, bug reports or if you want to get in contact with us have a look at our community page .","title":"For the community"},{"location":"DSP-API/","text":"Introduction DSP Ontologies DSP APIs Publishing and Deployment DSP-API Internals Sipi Lucene Frequently Asked Questions Release Notes","title":"Home"},{"location":"DSP-API/00-release-notes/","text":"Changelog 17.5.1 (2022-02-16) Maintenance deps: upgrade Jena Fuseki docker image to v2.0.8 ( #2001 ) ( 3e2eccc ) deps: upgrate Jena API to v4.4.0 ( #1999 ) ( 3eecc69 ) Documentation fix markdown issues in documentation (DEV-504) ( #2003 ) ( ff6b4cf ) 17.5.0 (2022-02-11) Enhancements ontologies: make comments optional for property and class creation (DEV-342) ( #1996 ) ( a3c286c ) 17.4.1 (2022-02-07) Maintenance deps: upgrade Jena to v4.3.2 (DEV-473) ( #1995 ) ( 216dcb4 ) deps: upgrade titanium-json-ld to v1.2.0 & jakarta-json to v2.0.1 (DEV-335) ( #1993 ) ( ad01bf9 ) 17.4.0 (2022-02-04) Bug Fixes version-upgrade: add upgrade plugin for ArchiveRepresentation and DeletedResource (DEV-467) ( #1992 ) ( e1566e9 ) Maintenance add support for building native API and Fuseki Docker images on Apple M1 (DEV-435) ( #1987 ) ( ab80e72 ) refactor test models (DEV-264) ( #1975 ) ( 65952f9 ) Enhancements resource: add ArchiveRepresentation to API V1 (DEV-393) (DEV-394) ( #1984 ) ( 65b88a2 ) UUID: add IRI validation that allows only to create IRIs using UUID version 4 and 5 (DEV-402) ( #1990 ) ( 74d4344 ) 17.3.1 (2022-01-28) Bug Fixes ontology: Sub-properties of link values aren't created correctly (DEV-426) ( #1985 ) ( 70a8b08 ) Maintenance deps: bump fuseki image to 2.0.7 (DEV-389) ( #1983 ) ( fcbfb1d ) license: update the license (DEV-374) ( #1981 ) ( 044fdc5 ) 17.3.0 (2022-01-17) Bug Fixes ontology: DSP-API creates wrong partOfValue property (DEV-216) ( #1978 ) ( 27b5c86 ) resource: return sensible CreationDate for DeletedResource ( #1979 ) ( 1658103 ) Enhancements resource: add support for 7z files in ArchiveRepresentation (DEV-322) ( #1977 ) ( 729689c ) Maintenance admin: refactor projects & users value objects (DEV-240) ( #1976 ) ( 563d252 ) CI: add disk cache and other cleanup (DEV-388) ( #1982 ) ( e590d12 ) 17.2.0 (2022-01-10) Bug Fixes search: Return matching sub-nodes when searching for list label (DEV-158) ( #1973 ) ( 7e8c759 ) Enhancements return a DeletedResource or DeletedValue instead of 404 if a deleted resource or value is requested (DEV-226) ( #1960 ) ( c78e252 ) 17.1.0 (2021-12-20) Enhancements listsADM: add canDeleteList route ( #1968 ) ( c276625 ) Maintenance deps: bump log4j to 2.17.0 and Fuseki to 4.3.2 (DEV-334) ( #1972 ) ( afb6587 ) 17.0.4 (2021-12-17) Bug Fixes authentication: delete cookie (in chrome) on logout (DEV-325) ( #1970 ) ( b2c9204 ) candeletecardinalities: return canDoResponse of false instead of throwing an exception for inherited cardinalities (DEV-314) ( #1966 ) ( 55b5d4b ) ontology: cardinality of one can be added to classes as long as not used in data ( #1958 ) ( 2cebac7 ) Maintenance bump logging libraries (DEV-333) ( #1969 ) ( f680c4f ) 17.0.3 (2021-12-14) Maintenance bump Fuseki (log4shell fix) (IT-4) ( #1965 ) ( 86fa251 ) projectMetadataV2: remove projectMetadataV2 implementation ( #1962 ) ( 7b95d66 ) 17.0.2 (2021-12-10) Maintenance bump db version (add shiro.ini)(DEV-302)( #1961 ) ( d147bf6 ) 17.0.1 (2021-12-06) Maintenance fix issues with fuseki (DEV-277) ( #1953 ) ( 4c1a5f1 ) Documentation Updated readme ( #1956 ) ( 774b68d ) 17.0.0 (2021-11-25) \u26a0 BREAKING CHANGES add archive representation to DSP-API (DEV-17) (#1926) Maintenance bump fuseki base container version ( #1946 ) ( cf8bdec ) bump java and sipi version (only security updates) (DEV-263) ( #1950 ) ( fe6106f ) Enhancements add archive representation to DSP-API (DEV-17) ( #1926 ) ( 0123a8f ) 16.0.1 (2021-11-22) Bug Fixes canDeleteCardinalities: canDeleteCardinalities checks too eagerly (DEV-187) ( #1941 ) ( 298ba47 ) 16.0.0 (2021-11-19) \u26a0 BREAKING CHANGES listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) Bug Fixes projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 ) Maintenance groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) release v16.0.0 ( 8e5f494 ) release v16.0.0 ( ba6923d ) 15.1.3 (2021-11-19) \u26a0 BREAKING CHANGES listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) Bug Fixes projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 ) Maintenance groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) 15.1.2 (2021-11-12) Maintenance bump bazel ( #1938 ) ( 39417e6 ) improve validation handling (DEV-228) ( #1937 ) ( 94d7d3f ) 15.1.1 (2021-11-09) Bug Fixes list: add support for special characters in list update (DEV-200) ( #1934 ) ( 3c2865c ) Maintenance init-db: init db test data from test server (DEV-198) ( #1936 ) ( 1c24bea ) 15.1.0 (2021-11-03) Bug Fixes users: fix bug adding user to group or project (DEV-184) ( #1925 ) ( a24a320 ) Enhancements add value objects to list routes - old and new (DEV-65) ( #1917 ) ( 7752a36 ) Maintenance bump sipi version (DEV-188) ( #1931 ) ( d302b5e ) change license to Apache 2.0 (DEV-82) ( #1924 ) ( 2d39a1f ) deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #1927 ) ( cbbf1b6 ) fix warnings (DEV-80) ( #1929 ) ( 1368769 ) 15.0.3 (2021-10-21) Bug Fixes list: find list labels in full-text search ( #1922 ) ( cc3b06c ) 15.0.2 (2021-10-14) Bug Fixes authenticator: improve performance ( #1914 ) ( d6a0d27 ) groups: update test data and documentation to use language specific group descriptions (DEV-123) ( #1921 ) ( 0f45b51 ) removing cardinality of a link property (DEV-90) ( #1919 ) ( c79c194 ) Maintenance groups: refactor groups route using value objects (DEV-66) ( #1913 ) ( 1cd98e6 ) knora-base: fix typo ( #1918 ) ( 720aa65 ) projects: cleaner value objects usage in addProject route (DEV-119) ( #1920 ) ( 32b9e49 ) 15.0.1 (2021-09-29) Bug Fixes candeletecardinalities: return correct response on route negative case (DEV-36) ( #1910 ) ( 652c747 ) escape-special-characters: escape special characters in user routes (DSP-1557) ( #1902 ) ( 689d92a ) Maintenance contributors: remove contributors file (DEV-77) ( #1911 ) ( 7d925b6 ) projects: refactor projects route with value objects (DEV-64) ( #1909 ) ( 172cf77 ) reformatting Scala files (DSP-1897) ( #1908 ) ( 8df70a2 ) 15.0.0 (2021-09-14) \u26a0 BREAKING CHANGES ontology: use patch instead of delete for deleting cardinalities (DSP-1700) (#1903) Documentation add username to changeable attributes (DSP-1895) ( #1904 ) ( 719cd0d ) Maintenance ontology: use patch instead of delete for deleting cardinalities (DSP-1700) ( #1903 ) ( 91ef4ec ) 14.1.0 (2021-08-19) Bug Fixes ontology V2: use internal iri when updating a property (DSP-1868) ( #1898 ) ( a746f65 ) Enhancements v2-ontologies: add remove cardinalities from class if property not used in resources (DSP-1700) ( #1869 ) ( a30668b ) 14.0.1 (2021-08-04) Bug Fixes add-test-file: add response file for test case (DSP-1841) ( #1894 ) ( 028e685 ) 14.0.0 (2021-08-02) \u26a0 BREAKING CHANGES projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) (#1886) Bug Fixes api-v2, api-admin: ontology name and project name should be URL safe (DSP-1749) ( #1889 ) ( 17601a7 ) permissions: reject malformed doap and ap create/update request (DSP-1328) ( #1890 ) ( 3e3a3ce ) Enhancements customIRIs: custom IRIs must contain a UUID (DSP-1763) ( #1884 ) ( 593d9cb ) projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) ( #1886 ) ( b3c2d5f ) resource-metadata: return resource metadata after metadata update request (DSP-1828) ( #1893 ) ( a4e878a ) video: add support for video/mp4 to both v1 and v2 (DSP-1204) ( #1891 ) ( 83fb4b8 ) 13.12.0 (2021-06-24) Enhancements resourceHistoryEvents: route for resource history events (DSP-1749) ( #1882 ) ( f86de53 ) 13.11.0 (2021-06-17) Enhancements events: update resource last modification date event ( #1877 ) ( d5e70ba ) Maintenance build: cleanup ( #1880 ) ( 749e8ea ) cache-service: add in-memory implementation ( #1870 ) ( 61531ab ) gh-ci: update docs deployment (DSP-1741) ( #1878 ) ( ff65323 ) 13.10.0 (2021-06-09) Enhancements gravsearch: use layer info for topological order permutations (DSP-1389) ( #1872 ) ( b49d5ba ) Documentation prepare documentation for docs.dasch.swiss (DSP-1721) ( #1873 ) ( 66751a0 ) 13.9.2 (2021-06-02) Maintenance sipi: add comments ( #1864 ) ( 06e8b0c ) Documentation ontology: update term ( #1865 ) ( cd37580 ) 13.9.1 (2021-05-28) Maintenance bazel: bump bazel version ( #1866 ) ( c754cbf ) 13.9.0 (2021-05-25) Enhancements api-v2: Add routes for checking whether ontology entities can be changed (DSP-1621) ( #1861 ) ( fdd098f ) 13.8.0 (2021-05-19) Bug Fixes api-v2: Update subclasses in ontology cache when base class changes (DSP-1643) ( #1860 ) ( beb951d ) gravsearch: don't move the patterns with resource IRI after topological sorting (DSP-1620) ( #1856 ) ( 6022c91 ) Maintenance documentation: bug fix in documentation deployment (DSP-1605) ( bb852c9 ) documentation: bug fix in documentation deployment (DSP-1605) ( #1854 ) ( 999a2bb ) Enhancements api-v2: Change GUI element and attribute of a property (DSP-1600) ( #1855 ) ( ce9ba3a ) api-v2: Generate IIIF manifest (DSP-50) ( #1784 ) ( 74feb2c ) conf: Rule to dump prod data and load locally (DSP-1485) ( #1857 ) ( 161ea31 ) ontology: Allow adding new property to a resource class in use (DSP-1629) ( #1859 ) ( 061875e ) 13.7.0 (2021-05-06) Bug Fixes doc: correct remaining incorrect copyright dates ( #1847 ) ( d1473ed ) gravsearch: Keep rdf:type knora-api:Resource when needed. ( #1835 ) ( e561d94 ) lists: Escape special characters in comment, label, and name of a list node (DSP-1529) ( #1846 ) ( f96c069 ) test-data: change webern shortcode in test data (DSP-1520) ( #1843 ) ( 5f06a10 ) values v1 route: fix geoname case (DSP-1487) ( #1839 ) ( 9d0e93e ) Documentation replace knora by dsp or dsp-api in documentation (DSP-1469) ( #1836 ) ( 923abe8 ) v1: improve search docs ( #1848 ) ( 5a81f73 ) Enhancements api-v2: Add route for changing GUI order of cardinalities ( #1850 ) ( d8dbb4f ) api-v2: Return events describing version history of resources and values of a project ordered by data (DSP-1528) ( #1844 ) ( 84f7c14 ) ext search v1: add support for URI values (DSP-1522) ( #1842 ) ( b119757 ) Maintenance bumb Bazel to version with apple silicon support ( #1852 ) ( 286d289 ) bump scala to 2.13 ( #1851 ) ( 5feb915 ) deps: bump versions (DSP-1569) ( #1849 ) ( f69f008 ) 13.6.0 (2021-03-16) Enhancements api-v2: Improve error message when an XSLT transformation file is not found (DSP-1404) ( #1831 ) ( 153a674 ) 13.5.1 (2021-03-11) Bug Fixes OntologiesRouteV2: Reject internal ontology names in external schema (DSP-1394) ( #1827 ) ( e392bf1 ) OntologyResponderV2: Fix check when updating ontology label and comment (DSP-1390) ( #1826 ) ( 26cce48 ) 13.5.0 (2021-03-08) Bug Fixes replaceCardinalities.scala.txt: Fix blank node insertion. ( #1829 ) ( d24c5d2 ) Maintenance gh-ci: update release please configuration (DSP-1382) ( #1825 ) ( 7ce4b65 ) Enhancements Add support for audio files (DSP-1343) ( #1818 ) ( 7497023 ) gravsearch: Optimise Gravsearch queries using topological sort (DSP-1327) ( #1813 ) ( efbecee ) store: Return 404 if the triplestore returns 404. ( #1828 ) ( 5250f6d ) 13.4.0 (2021-02-17) Bug Fixes Lists: fix bug in shifting the second of two children after deletion of the first one. ( #1820 ) ( d92bb01 ) Enhancements projects: add default set of permissions when creating new project (DSP-1347) ( #1822 ) ( b7c71ca ) 13.3.1 (2021-02-09) Bug Fixes Lists: fix bug in deleting the single child of a node (DSP-1355) ( #1816 ) ( 1d06572 ) 13.3.0 (2021-02-05) Enhancements sipi: add storing of original and sidecar (DSP-1318) ( #1808 ) ( 022ed7e ) 13.2.0 (2021-02-04) Bug Fixes api-v1: Optimise SPARQL queries. ( #1814 ) ( 4edc27c ) Lists: Repositioning the node when new position equals length of new parent's children (DSP-1322) ( #1811 ) ( 3fead13 ) Enhancements api-v1: Add support for PDF files (DSP-1267) ( #1797 ) ( c3b2e84 ) api-v2: Allow resubmitting existing class/property lablels/comments. ( #1812 ) ( 6a13852 ) Maintenance make targets for adding metadata (DSP-1289) ( #1810 ) ( 9c1a70a ) salsah1: delete from repository ( #1805 )(DSP-1294) ( 3251a74 ) 13.1.1 (2021-01-30) Maintenance gh-ci: Bring back the client-test-data command to github actions ( #1804 ) ( e6b0fbf ) revert release 13.1.0 ( #1800 ) ( 565e5ac ) 13.1.0 (2021-01-29) Bug Fixes api-v1: Optimise link value queries for Fuseki (DSP-1243) ( #1791 ) ( b1e1b9e ) api-v2: Don't allow an invalid cardinality on a boolean property (DSP-1236) ( #1788 ) ( 3d5f802 ) gravsearch: Handle UNION scopes with FILTER correctly (DSP-1240) ( #1790 ) ( 61d2e86 ) HttpTriplestoreConnector: Always parse triplestore responses as UTF-8. ( #1789 ) ( 61d2e86 ) permissions : fix getting builtin groups while creating a permission (DSP-1296 ) ( #1799 ) ( d390014 ) Maintenance gh-ci: fix issue in the release process ( #1782 ) ( afe61b7 ) ghi-ci: google chat release notification ( #1785 ) ( 4718cdc ) Enhancements permissions: add delete permissions: (DSP-1169) ( #1787 ) ( 3fe8c14 ) store: Return a clearer exception when a triplestore read timeout occurs. ( #1795 ) ( 0eeb3b3 ) 13.0.0 (2021-01-11) \u26a0 BREAKING CHANGES New features and refactoring (#1779) Bug Fixes (dependencies) add the missing dependency ( #1755 ) ( 0e37d21 ) api-v2: Change link value comment ( #1582 ) ( faa2e55 ) api-v2: Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) ( #1749 ) ( 905766f ) api-v2: Fix custom datatypes in knora-api simple ontology ( #1601 ) ( e0cfd4e ) api-v2: Fix generated SPARQL for updating property comment ( #1693 ) ( 7b70339 ) api-v2: Fix ontology deletion ( #1584 ) ( 70b0841 ) api-v2: Fix post-update check for resource with standoff link (DSP-841) ( #1728 ) ( 35d449f ) failing repository upgrade at startup (DSP-654) ( #1712 ) ( 0d6b4ee ) gravsearch: Prevent duplicate results ( #1626 ) ( 9313b88 ) gravsearch: When link property compared in filter, don't compare link value property, too ( #1699 ) ( a3b1665 ) init db scripts (DSP-511) ( #1681 ) ( d4505ce ) loading of data (DSP-445) ( #1669 ) ( 3f8d406 ) OntologyResponderV2: Add a global ontology cache lock ( #1637 ) ( 1853865 ) OntologyResponderV2: Fix ontology cache update when ontology metadata changed ( #1709 ) ( 4f57977 ) server header (DSP-537) ( #1691 ) ( 8d7bee8 ) sipi makefile ( #1616 ) ( 73a0afe ) sipi: Don't expect API v1 status code (DSP-1114) ( #1763 ) ( 3236d25 ) sipi: Improve performance of file value query ( #1697 ) ( 8214877 ) test: Fix typos in IRIs in anything-data.ttl. ( #1625 ) ( 23d51ce ) upgrade: Fix log output. ( #1774 ) ( b43fab0 ) webapi: unique username/email check on change user ( #1561 ) ( 4f26e22 ) rdf-api : Use the Jena RDF API implementation by default (DSP-1153) ( 1772 ) ( 389feb4 ) Documentation api-v2: Document what happens when a resource has a link to a deleted resource ( #1685 ) ( 1c88651 ) fix broken links ( #1688 ) ( 9c0292c ) fix make targets docker-build and docker-publish ( #1694 ) ( d06b6a6 ) Update README (DSP-1142) ( #1771 ) ( 7ba7fc6 ) Update required mkdocs package ( #1725 ) ( 27de65e ) Maintenance api-v2: Delete obsolete files. ( #1634 ) ( e80bf52 ) api-v2: Switch from JSONLD-Java to Titanium ( #1715 ) ( 9e28e5b ) build: Bump testcontainers version. ( #1723 ) ( 24ae1d3 ) build: Update ScalaTest (DSP-919) ( #1745 ) ( bbaeadd ) build: Upgrade Sipi to 3.0.0-rc.8 (DSP-916) ( #1743 ) ( 23395fc ) bump sipi to rc.7 (DSP-733) ( #1721 ) ( b635495 ) gh-ci: Fix gren issue ( #1666 ) ( 2dc5361 ) gh-ci: Publish on release only ( #1662 ) ( 787dca8 ) rdf-api: Use the Jena RDF API implementation by default (DSP-1153) ( #1772 ) ( 389feb4 ) Remove obsolete functions from StringFormatter. ( #1640 ) ( 5fa6de4 ) Update ci workflow release notes ( #1707 ) ( d8e0b39 ) gh-ci CI is failing to test upgrade correctly (DSP-667) ( #1073 ) ( 13cbdab ) bazel Update Bazel maven rules to see if it fixes problems with macOS Big Sur (DSP-1099) ( #1761 ) ( a2c9941 ) Enhancements Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) ( #1759 ) ( 346873d ) Add feature toggles (DSP-910) ( #1742 ) ( 2e6db2e ) Add time value type ( #1403 ) ( d925c85 ) api-v1: Change API v1 file uploads to work like API v2 (DSP-41, PR 3) ( #1722 ) ( a824bcc ) api-v2: Accept custom new value IRI when updating value ( #1698 ) ( 4d8f867 ) api-v2: Accept custom timestamps in update/delete requests ( #1686 ) ( 0fbe5a8 ) api-v2: Add an RDF processing fa\u00e7ade (DSP-1020) ( #1754 ) ( 9170419 ) api-v2: Add metadata routes (DSP-662) ( #1734 ) ( bf48968 ) api-v2: Add support for text file upload (DSP-44) ( #1664 ) ( a88d20d ) api-v2: Add test data. ( #1704 ) ( de14ab1 ) api-v2: Allow querying for rdfs:label in Gravsearch ( #1649 ) ( d56004b ) api-v2: Control JSON-LD nesting via an HTTP header (DSP-1084) ( #1758 ) ( b13eecf ) api-v2: Make inference optional in Gravsearch ( #1696 ) ( 166a260 ) api-v2: Optionally return file values in full-text search results (DSP-1191) ( #1776 ) ( 01f59bd ) api-v2: Remove client code generation ( #1610 ) ( 6977ab3 ) api-v2: Remove ForbiddenResource ( #1615 ) ( 992596e ) api-v2: Return value UUID on value creation and update ( #1602 ) ( cbed601 ) api-v2: Specify custom IRIs when creating resources/values ( #1646 ) ( 135b039 ) clientapi: Change method signature. ( #1583 ) ( c2a2559 ) gh-ci: Release please and update gh actions (DSP-1168) ( #1777 ) ( 593ffab ) gravsearch: Allow comparing variables representing resource IRIs ( #1713 ) ( f359c8e ) gravsearch: Remove deprecated functions ( #1660 ) ( 5d3af46 ) New features and refactoring ( #1779 ) ( 9a5fb77 ) rdf-api: Add a general-purpose SHACL validation utility (DSP-930) ( #1762 ) ( bfd3192 ) sipi: Improve error message if XSL file not found ( #1590 ) ( bbb42f6 ) triplestores: Support Apache Jena Fuseki ( #1375 ) ( 82f8a55 ) upgrade: Update repository on startup ( #1643 ) ( 0127dca ) v13.0.0-rc.25 (08/12/2020) Enhancements #1768 | DSP-1106 Update Permission #1767 | enhancement(triplestore): Use N-Quads instead of TriG for repository upgrade (DSP-1129) #1764 | DSP-1033 Reposition List Nodes #1762 | feat(rdf-api): Add a general-purpose SHACL validation utility (DSP-930) #1759 | feat: Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) #1760 | (DSP-1031) Delete list items #1753 | Edit lists routes (DSP-597 ) #1758 | feat(api-v2): Control JSON-LD nesting via an HTTP header (DSP-1084) Bug fixes #1763 | fix(sipi): Don't expect API v1 status code (DSP-1114) Documentation #1771 | docs: Update README (DSP-1142) Maintenance #1770 | refactor: Use java.nio.file.Path instead of java.io.File (DSP-1124) #1765 | DSP-1094 Upgrade Swagger version #1766 | style: Add Scalafmt config file #1769 | style: Reformat code with Scalafmt (DSP-1137) #1754 | feat(api-v2): Add an RDF processing fa\u00e7ade (DSP-1020) #1757 | build: bazel workspace cleanup v13.0.0-rc.24 (13/11/2020) #1756 | DSP-1052 : Migration task to replace empty strings with dummy \"FIXME\" v13.0.0-rc.23 (09/11/2020) Bug fixes #1755 | DSP-1029: Add the missing dependency v13.0.0-rc.22 (09/11/2020) Breaking changes #1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions Enhancements #1403 | feat: Add time value type #1537 | build: Add env var to set triplestore actor pool #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30) Bug Fixes #1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1576 | Add missing env var #1571 | fixed date string format #1564 | enable click on save button in case of recoverable error #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445) Documentation #1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering Other #1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes Dependencies #1721 | chore: bump sipi to rc.7 (DSP-733) #1735 | DSP-496 Bump Apache Jena Fuseki and Apache Jena Libraries to 3.16 #1737 | DSP-842 Bump used Bazel version to newly released 3.7.0 #1743 | chore(build): Upgrade Sipi to 3.0.0-rc.8 (DSP-916) #1745 | chore(build): Update ScalaTest (DSP-919) #1752 | DSP-1017 Upgrade to Sipi v3.0.0-rc.9 v13.0.0-rc.21 (09/11/2020) Breaking changes #1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions Enhancements #1403 | feat: Add time value type #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30) Bug Fixes #1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445) Documentation #1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering Other #1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes v12.0.0 (27/01/2020) Breaking API Changes #1439 JSON-LD Serialization of an xsd:dateTimeStamp New Features and Enhancements #1509 Support lists admin endpoint #1466 Optimise generated SPARQL Bug Fixes #1569 broken ark #1559 Admin lists: createChildNode should send a httpPost request, not httpPut v11.0.0 (16/12/2019) Breaking Changes #1344 Gravsearch ForbiddenResource result and permissions of linked resources #1202 Implement upload of PDF and text files in API v2. Users with files in Sipi under /server must move them to /images when upgrading. Bug Fixes #1531 Sipi's mimetype_consistency fails with .bin file #1430 Creating the first resource with an image inside a project fails with Sipi not finding the project folder #924 Get dependent resources Iris v10.1.1 (27/11/2019) v10.1.0 (27/11/2019) v10.0.0 (22/10/2019) Breaking Changes #1346 Richtext/HTML in page anchor link Enhancements #1457 Upgrade sipi to 2.0.1 Bug Fixes #1460 Build banner in README is broken Documentation #1481 build badge in README has broken link Other #1449 Add Makefile-based task execution #1401 Enable testing docs generation in Travis v9.1.0 (26/09/2019) Enhancements #1421 Physically deleting a resource Documentation #1407 Document ARK URLs for projects v9.0.0 (29/08/2019) Breaking Changes #1411 Moved /admin/groups/members/GROUP_IRI to /admin/groups/GROUP_IRI/members #1231 Change value permissions #763 refactor splitMainResourcesAndValueRdfData so it uses SparqlExtendedConstructResponse Enhancements #1373 The startup ends in a thrown exception if the triplestore is not up-to-date #1364 Add support for Redis cache #1360 Build and publish Knora version specific docker images for GraphDB Free and SE #1358 Add admin route to dump project data Bug Fixes #1394 Using dockerComposeUp to start the stack, fails to find Redis at startup Documentation #1386 Add lists admin API documentation Other #1412 Change release notes to be based on issues v8.0.0 (14/06/2019) feature(webapi): Add GraphDB-Free startup support (#1351) - @subotic feature(webapi): Add returning of fixed public user information (#1348) - @subotic feat(api-v2): No custom permissions higher than defaults (#1337) - @benjamingeer feat(upgrade): Improve upgrade framework (#1345) - @benjamingeer test(webapi): Add new user authentication (#1201) - @subotic chore(webapi): Add request duration logging (#1347) - @subotic feat(api-v2): Make values citable (#1322) - @benjamingeer Leibniz ontology (#1326) - @SepidehAlassi feature(webapi): add CORS allow header (#1340) - @subotic fix(sipi): Return permissions for a previous version of a file value. (#1339) - @benjamingeer fix(scripts): add admin ontology data to correct graph (#1333) - @subotic fix(sipi): Don't try to read a file value in a deleted resource. (#1329) - @benjamingeer docs(api-v2): Fix sample responses. (#1327) - @benjamingeer fix(api-v2): Fix typo. (#1325) - @benjamingeer Handle List Nodes in Response (#1321) - @tobiasschweizer feat(api-v2): Return standoff markup separately from text values (#1307) - @benjamingeer BEOL: Import comments for Meditationes (#1281) - @tobiasschweizer feat(triplestore): Log SPARQL query if triplestore doesn't respond. (#1292) - @benjamingeer Support list nodes in Gravsearch (#1314) - @tobiasschweizer v7.0.0 (03/05/2019) fix(api-v2): Cache base class IRIs correctly when creating/updating class (#1311) - @benjamingeer chore(standoff): Use Base64-encoded UUIDs in standoff tags. (#1301) - @benjamingeer feat(api-v2): Allow a resource to be created as a specified user (#1306) - @benjamingeer feat(admin): Give the admin ontology an external schema (#1291) - @benjamingeer fix(api-v2): Remove INFORMATION SEPARATOR TWO from text in the simple schema. (#1299) - @benjamingeer test: Compare Knora response with its class definition (#1297) - @benjamingeer docs(api-admin): fix description of the change password payload (#1285) - @loicjaouen fix(api-v1): Fix double escaping of newline. (#1296) - @benjamingeer fix (tei beol): fix problems in XSLT (#1260) - @tobiasschweizer refactor(ontology): Make knora-admin a separate ontology (#1263) - @benjamingeer a handfull of changes in documentation and error messages (#1278) - @loicjaouen docs: fix missing username (#1269) - @loicjaouen feat(api-v2): Get resources in a particular class from a project (#1251) - @benjamingeer fix(sipi): Improve error checking of Sipi's knora.json response. (#1279) - @benjamingeer feat(api-v2): Return user's permission on resources and values (#1257) - @benjamingeer fix(api-v1): Escape rdfs:label in bulk import. (#1276) - @benjamingeer chore(webapi): Remove persistent map code (#1254) - @benjamingeer docs (api-v2): Update outdated ARK documentation. (#1252) - @benjamingeer Update build.properties (#1265) - @subotic v6.0.1 (22/03/2019) chore: releasing-v6.0.1 (#1270) - @subotic chore(webapi): Add script for loading of a minimal set of data (#1267) - @subotic fix (beolPersonLabel) typo in label of hasBirthPlace (#1248) - @SepidehAlassi fix (webapi): message typo (#1244) - @subotic Unescape standoff string attributes when verifying text value update (#1242) - @benjamingeer docs: fix user admin api (#1237) - @subotic v6.0.0 (28/02/2019) Release Notes MAJOR: Use HTTP POST to mark resources and values as deleted (#1203) MAJOR: Reorganize user and project routes (#1209) FEATURE: Secure routes returning user information (#961) MAJOR: Change all xsd:dateTimeStamp to xsd:dateTime in the triplestore (#1211). Existing data must be updated; see upgrade/1211-datetime for instructions. FIX: Ignore order of attributes when comparing standoff (#1224). FEATURE: Query version history (#1214) FIX: Don't allow conflicting cardinalities (#1229) MAJOR: Remove preview file values (#1230). Existing data must be updated; see upgrade/1230-delete-previews for instructions. v5.0.0 (05/02/2019) Release Notes MAJOR: Fix property names for incoming links (#1144)) MAJOR: Generate and resolve ARK URLs for resources (#1161). Projects that have resource IRIs that do not conform to the format specified in https://docs.knora.org/paradox/03-apis/api-v2/knora-iris.html#iris-for-data must update them. MAJOR: Use project shortcode in IIIF URLs (#1191). If you have file value IRIs containing the substring /reps/ , you must replace /reps/ with /values/ . FEATURE: Update resource metadata in API v2 (#1131) FEATURE: Allow setting resource creation date in bulk import #1151) FEATURE: The v2/authentication route now also initiates cookie creation (the same as v1/authentication ) (#1159) FEATURE: Allow to specify restricted view settings for a project which Sipi will adhere to (#690). FIX: Triplestore connection error when using dockerComposeUp (#1122) FIX: Reject link value properties in Gravsearch queries in the simple schema (#1145) FIX: Fix error-checking when updating cardinalities in ontology API (#1142) FIX: Allow hasRepresentation in an ontology used in a bulk import (#1171) FIX: Set cookie domain to the value specified in application.conf with the setting cookie-domain (#1169) FIX: Fix processing of shared property in bulk import (#1182) v4.0.0 (12/12/2018) v4.0.0 Release Notes MAJOR CHANGE: mapping creation request and response formats have changed (#1094) MINOR CHANGE: Update technical user docs (#1085) BUGFIX CHANGE: Fix permission checking in API v2 resource creation (#1104) v3.0.0 (30/11/2018) v3.0.0 Release Notes [BREAKING ONTOLOGY CHANGE] The property knora-base:username was added and is required for knora-base:User . (#1047) [BREAKING API CHANGE] The /admin/user API has changed due to adding the username property. (#1047) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Add default permission caching (#1062) [FIX] Fix unescaping in update check and reading standoff URL (#1074) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Create image file values in API v2 (#1011). Requires Sipi with tagged commit v1.4.1-SNAPSHOT or later. v2.1.0 (02/11/2018) New features Implement graph query in API v2 (#1009) Expose additional webapi settings as environment variables. Please see the Configuration section in the documentation for more information (#1025) Bugfixes sipi container config / sipi not able to talk to knora (#994) v2.1.0-snapshot (22/10/2018) v2.0.0 (13/09/2018) This is the first release with the new version numbering convention. From now on, if any changes to the existing data are necessary for a release, then this release will have its major number increased. Please see the Release Versioning Convention description. Required changes to existing data a knora-base:ListNode must have at least one rdfs:label . (@github #991 ) New features add developer-centric docker-compose.yml for starting the Knora / GraphDB / Sipi / Salsah1 (@github #979 ) configure webapi and salsah1 thorough environment variables (@github #979 ) update for Java 10 (@github #979 ) comment out the generation of fat jars from KnoraBuild.sbt (for now) (@github #979 ) update ehcache (@github #979 ) update sbt to 1.2.1 (@github #979 ) remove Kamon monitoring (for now) since we don't see anything meaningful there. We probably will have to instrument Knora by hand and then use Kamon for access. (@github #979 ) update Dockerfiles for webapi and salsah1 (@github #979 ) follow subClassOf when including ontologies in XML import schemas (@github #991 ) add support for adding list child nodes (@github #991 ) add support for shared ontologies (@github #987 ) Bugfixes trouble with xml-checker and/or consistency-checker during bulk import (@github #978 ) ontology API error with link values (@github #988 ) v1.7.1 (29/08/2018) Knora-Stack compatible versions Knora v1.7.1 - Salsah v2.1.2 - Sipi v1.4.0 - GraphDB v8.5.0 doc (webapi): add yourkit acknowledgment (#983) Don't allow class with cardinalities on P and on a subproperty of P (#982) doc (webapi): add LHTT project shortcode (#981) feature (webapi): not return or allow changing of built-in users (#975) fix (webapi): startup check does not detect running triplestore (#969) Fix bulk import parsing bug and limit concurrent client connections (#973) v1.7.0 (16/08/2018) See the closed tickets on the v1.7.0 milestone . Knora-Stack compatible versions Knora v1.7.0 - Salsah v2.1.0 - Sipi v1.4.0 - GraphDB v8.5.0 Required changes to existing data To use the inferred Gravsearch predicate knora-api:standoffTagHasStartAncestor , you must recreate your repository with the updated KnoraRules.pie . New features Gravsearch queries can now match standoff markup (#910). Add Graphdb-Free initialization scripts for local and docker installation (#955). Create temp dirs at startup (#951) Update versions of monitoring tools (#951) Bugfixes timeout or java.lang.OutOfMemoryError when using /v1/resources/xmlimportschemas/ for some ontologies (#944) Timeout cleanup (#951) Add separate dispatchers (#945) v1.6.0 (29/06/2018) v1.6.0 Release Notes See the release and closed tickets on the v1.6.0 milestone on Github. Required changes to existing data A project is now required to have at least one description, so potentially a description will need to be added to those projects that don't have one. New features General: Added a /health endpoint KnoraService waits on startup for a triplestore before trying to load the ontologies Gravsearch enhancements: Accept queries in POST requests (@github #650 ). Allow a Gravsearch query to specify the IRI of the main resource (@github #871 ) (by allowing BIND ). Allow lang to be used with != . A UNION or OPTIONAL can now be nested in an OPTIONAL (@github #882 ). Gravsearch now does type inference (@github #884 ). The Knora API v2 complex schema can now be used in Gravsearch, making it possible to search for list nodes (@github #899 ). Admin API: Make project description required (@github #875 ). Conversion to TEI: Conversion of standard standoff entities to TEI Custom conversion of project specific standoff entities and metadata to TEI Sipi integration: The Knora specific Sipi configuration and scripts can now be found under the sipi/ directory (@github #404 ). Documentation on how Sipi can be started changed (@github #404 ). Bugfixes Allow a class or property definition to have more than one object for rdf:type (@github #885 ). Exclude list values from v2 fulltext search (@github #906 ). Gravsearch fixes: Allow the lang function to be used in a comparison inside AND/OR (@github #846 ). Fix the processing of resources with multiple incoming links that use the same property (@github #878 ). Fix the parsing of a FILTER inside an OPTIONAL (@github #879 ). Require the match function to be the top-level expression in a FILTER . v1.5.0 (31/05/2018) See v1.5.0 milestone for a full list of closed tickets. New features Resources can be returned in the simple ontology schema (#833). Text values can specify the language of the text (#819). Responses can be returned in Turtle and RDF/XML (#851). Bugfixes Incorrect representation of IRI object values in JSON-LD (#835) GenerateContributorsFile broken (#797) v1.4.0 (30/04/2018) Required changes to existing data Every ontology must now have the property knora-base:attachedToProject , which points to the IRI of the project that is responsible for the ontology. This must be added to each project-specific ontology in existing repositories. All built-in ontologies have been updated to have this property, and must, therefore, be reloaded into existing repositories. The property knora-base:projectOntology has been removed, and must be removed from project definitions in existing repositories. Every project now needs to have the property knora-base:projectShortcode set. New features Added OpenAPI / Swagger API documentation route The Knora API server now checks the validity of ontologies on startup. The property knora-base:projectShortcode is now a required property (was optional). Bugfixes API v1 extended search was not properly handling multiple conditions on list values (issue #800) Fix image orientation in SALSAH 1 (issue #726) v1.3.1 (06/04/2018) v1.3.0 (28/03/2018) Required changes to existing data 1. Replace salsah-gui ontology You must replace the salsah-gui ontology that you have in the triplestore with the one in salsah-gui.ttl . New features More support for salsah-gui elements and attributes in ontologies Serve the salsah-gui ontology in API v2 in the default schema. Show salsah-gui:guiElement and salsah-gui:guiAttribute when serving ontologies in API v2 in the default schema. Allow salsah-gui:guiElement and salsah-gui:guiAttribute to be included in new property definitions created via API v2. Change salsah-gui so that GraphDB's consistency checker can check the use of guiElement and guiAttribute . Changes to application.conf . The sipi and web-api sections have received a big update, adding separate settings for internal and external host settings: app { knora-api { // relevant for direct communication inside the knora stack internal-host = \"0.0.0.0\" internal-port = 3333 // relevant for the client, i.e. browser external-protocol = \"http\" // optional ssl termination needs to be done by the proxy external-host = \"0.0.0.0\" external-port = 3333 } sipi { // relevant for direct communication inside the knora stack internal-protocol = \"http\" internal-host = \"localhost\" internal-port = 1024 // relevant for the client, i.e. browser external-protocol = \"http\" external-host = \"localhost\" external-port = 1024 prefix = \"knora\" file-server-path = \"server\" path-conversion-route = \"convert_from_binaries\" file-conversion-route = \"convert_from_file\" image-mime-types = [\"image/tiff\", \"image/jpeg\", \"image/png\", \"image/jp2\"] movie-mime-types = [] sound-mime-types = [] } salsah1 { base-url = \"http://localhost:3335/\" project-icons-basepath = \"project-icons/\" } } Bugfixes When API v2 served knora-api (default schema), salsah-gui:guiElement and salsah-gui:guiAttribute were not shown in properties in that ontology. The predicate salsah-gui:guiOrder was not accepted when creating a property via API v2.","title":"Changelog"},{"location":"DSP-API/00-release-notes/#changelog","text":"","title":"Changelog"},{"location":"DSP-API/00-release-notes/#1751-2022-02-16","text":"","title":"17.5.1 (2022-02-16)"},{"location":"DSP-API/00-release-notes/#maintenance","text":"deps: upgrade Jena Fuseki docker image to v2.0.8 ( #2001 ) ( 3e2eccc ) deps: upgrate Jena API to v4.4.0 ( #1999 ) ( 3eecc69 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#documentation","text":"fix markdown issues in documentation (DEV-504) ( #2003 ) ( ff6b4cf )","title":"Documentation"},{"location":"DSP-API/00-release-notes/#1750-2022-02-11","text":"","title":"17.5.0 (2022-02-11)"},{"location":"DSP-API/00-release-notes/#enhancements","text":"ontologies: make comments optional for property and class creation (DEV-342) ( #1996 ) ( a3c286c )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1741-2022-02-07","text":"","title":"17.4.1 (2022-02-07)"},{"location":"DSP-API/00-release-notes/#maintenance_1","text":"deps: upgrade Jena to v4.3.2 (DEV-473) ( #1995 ) ( 216dcb4 ) deps: upgrade titanium-json-ld to v1.2.0 & jakarta-json to v2.0.1 (DEV-335) ( #1993 ) ( ad01bf9 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1740-2022-02-04","text":"","title":"17.4.0 (2022-02-04)"},{"location":"DSP-API/00-release-notes/#bug-fixes","text":"version-upgrade: add upgrade plugin for ArchiveRepresentation and DeletedResource (DEV-467) ( #1992 ) ( e1566e9 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_2","text":"add support for building native API and Fuseki Docker images on Apple M1 (DEV-435) ( #1987 ) ( ab80e72 ) refactor test models (DEV-264) ( #1975 ) ( 65952f9 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#enhancements_1","text":"resource: add ArchiveRepresentation to API V1 (DEV-393) (DEV-394) ( #1984 ) ( 65b88a2 ) UUID: add IRI validation that allows only to create IRIs using UUID version 4 and 5 (DEV-402) ( #1990 ) ( 74d4344 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1731-2022-01-28","text":"","title":"17.3.1 (2022-01-28)"},{"location":"DSP-API/00-release-notes/#bug-fixes_1","text":"ontology: Sub-properties of link values aren't created correctly (DEV-426) ( #1985 ) ( 70a8b08 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_3","text":"deps: bump fuseki image to 2.0.7 (DEV-389) ( #1983 ) ( fcbfb1d ) license: update the license (DEV-374) ( #1981 ) ( 044fdc5 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1730-2022-01-17","text":"","title":"17.3.0 (2022-01-17)"},{"location":"DSP-API/00-release-notes/#bug-fixes_2","text":"ontology: DSP-API creates wrong partOfValue property (DEV-216) ( #1978 ) ( 27b5c86 ) resource: return sensible CreationDate for DeletedResource ( #1979 ) ( 1658103 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#enhancements_2","text":"resource: add support for 7z files in ArchiveRepresentation (DEV-322) ( #1977 ) ( 729689c )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#maintenance_4","text":"admin: refactor projects & users value objects (DEV-240) ( #1976 ) ( 563d252 ) CI: add disk cache and other cleanup (DEV-388) ( #1982 ) ( e590d12 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1720-2022-01-10","text":"","title":"17.2.0 (2022-01-10)"},{"location":"DSP-API/00-release-notes/#bug-fixes_3","text":"search: Return matching sub-nodes when searching for list label (DEV-158) ( #1973 ) ( 7e8c759 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#enhancements_3","text":"return a DeletedResource or DeletedValue instead of 404 if a deleted resource or value is requested (DEV-226) ( #1960 ) ( c78e252 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1710-2021-12-20","text":"","title":"17.1.0 (2021-12-20)"},{"location":"DSP-API/00-release-notes/#enhancements_4","text":"listsADM: add canDeleteList route ( #1968 ) ( c276625 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#maintenance_5","text":"deps: bump log4j to 2.17.0 and Fuseki to 4.3.2 (DEV-334) ( #1972 ) ( afb6587 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1704-2021-12-17","text":"","title":"17.0.4 (2021-12-17)"},{"location":"DSP-API/00-release-notes/#bug-fixes_4","text":"authentication: delete cookie (in chrome) on logout (DEV-325) ( #1970 ) ( b2c9204 ) candeletecardinalities: return canDoResponse of false instead of throwing an exception for inherited cardinalities (DEV-314) ( #1966 ) ( 55b5d4b ) ontology: cardinality of one can be added to classes as long as not used in data ( #1958 ) ( 2cebac7 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_6","text":"bump logging libraries (DEV-333) ( #1969 ) ( f680c4f )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1703-2021-12-14","text":"","title":"17.0.3 (2021-12-14)"},{"location":"DSP-API/00-release-notes/#maintenance_7","text":"bump Fuseki (log4shell fix) (IT-4) ( #1965 ) ( 86fa251 ) projectMetadataV2: remove projectMetadataV2 implementation ( #1962 ) ( 7b95d66 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1702-2021-12-10","text":"","title":"17.0.2 (2021-12-10)"},{"location":"DSP-API/00-release-notes/#maintenance_8","text":"bump db version (add shiro.ini)(DEV-302)( #1961 ) ( d147bf6 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1701-2021-12-06","text":"","title":"17.0.1 (2021-12-06)"},{"location":"DSP-API/00-release-notes/#maintenance_9","text":"fix issues with fuseki (DEV-277) ( #1953 ) ( 4c1a5f1 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#documentation_1","text":"Updated readme ( #1956 ) ( 774b68d )","title":"Documentation"},{"location":"DSP-API/00-release-notes/#1700-2021-11-25","text":"","title":"17.0.0 (2021-11-25)"},{"location":"DSP-API/00-release-notes/#breaking-changes","text":"add archive representation to DSP-API (DEV-17) (#1926)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/00-release-notes/#maintenance_10","text":"bump fuseki base container version ( #1946 ) ( cf8bdec ) bump java and sipi version (only security updates) (DEV-263) ( #1950 ) ( fe6106f )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#enhancements_5","text":"add archive representation to DSP-API (DEV-17) ( #1926 ) ( 0123a8f )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1601-2021-11-22","text":"","title":"16.0.1 (2021-11-22)"},{"location":"DSP-API/00-release-notes/#bug-fixes_5","text":"canDeleteCardinalities: canDeleteCardinalities checks too eagerly (DEV-187) ( #1941 ) ( 298ba47 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#1600-2021-11-19","text":"","title":"16.0.0 (2021-11-19)"},{"location":"DSP-API/00-release-notes/#breaking-changes_1","text":"listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/00-release-notes/#bug-fixes_6","text":"projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_11","text":"groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) release v16.0.0 ( 8e5f494 ) release v16.0.0 ( ba6923d )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1513-2021-11-19","text":"","title":"15.1.3 (2021-11-19)"},{"location":"DSP-API/00-release-notes/#breaking-changes_2","text":"listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/00-release-notes/#bug-fixes_7","text":"projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_12","text":"groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1512-2021-11-12","text":"","title":"15.1.2 (2021-11-12)"},{"location":"DSP-API/00-release-notes/#maintenance_13","text":"bump bazel ( #1938 ) ( 39417e6 ) improve validation handling (DEV-228) ( #1937 ) ( 94d7d3f )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1511-2021-11-09","text":"","title":"15.1.1 (2021-11-09)"},{"location":"DSP-API/00-release-notes/#bug-fixes_8","text":"list: add support for special characters in list update (DEV-200) ( #1934 ) ( 3c2865c )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_14","text":"init-db: init db test data from test server (DEV-198) ( #1936 ) ( 1c24bea )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1510-2021-11-03","text":"","title":"15.1.0 (2021-11-03)"},{"location":"DSP-API/00-release-notes/#bug-fixes_9","text":"users: fix bug adding user to group or project (DEV-184) ( #1925 ) ( a24a320 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#enhancements_6","text":"add value objects to list routes - old and new (DEV-65) ( #1917 ) ( 7752a36 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#maintenance_15","text":"bump sipi version (DEV-188) ( #1931 ) ( d302b5e ) change license to Apache 2.0 (DEV-82) ( #1924 ) ( 2d39a1f ) deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #1927 ) ( cbbf1b6 ) fix warnings (DEV-80) ( #1929 ) ( 1368769 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1503-2021-10-21","text":"","title":"15.0.3 (2021-10-21)"},{"location":"DSP-API/00-release-notes/#bug-fixes_10","text":"list: find list labels in full-text search ( #1922 ) ( cc3b06c )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#1502-2021-10-14","text":"","title":"15.0.2 (2021-10-14)"},{"location":"DSP-API/00-release-notes/#bug-fixes_11","text":"authenticator: improve performance ( #1914 ) ( d6a0d27 ) groups: update test data and documentation to use language specific group descriptions (DEV-123) ( #1921 ) ( 0f45b51 ) removing cardinality of a link property (DEV-90) ( #1919 ) ( c79c194 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_16","text":"groups: refactor groups route using value objects (DEV-66) ( #1913 ) ( 1cd98e6 ) knora-base: fix typo ( #1918 ) ( 720aa65 ) projects: cleaner value objects usage in addProject route (DEV-119) ( #1920 ) ( 32b9e49 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1501-2021-09-29","text":"","title":"15.0.1 (2021-09-29)"},{"location":"DSP-API/00-release-notes/#bug-fixes_12","text":"candeletecardinalities: return correct response on route negative case (DEV-36) ( #1910 ) ( 652c747 ) escape-special-characters: escape special characters in user routes (DSP-1557) ( #1902 ) ( 689d92a )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_17","text":"contributors: remove contributors file (DEV-77) ( #1911 ) ( 7d925b6 ) projects: refactor projects route with value objects (DEV-64) ( #1909 ) ( 172cf77 ) reformatting Scala files (DSP-1897) ( #1908 ) ( 8df70a2 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1500-2021-09-14","text":"","title":"15.0.0 (2021-09-14)"},{"location":"DSP-API/00-release-notes/#breaking-changes_3","text":"ontology: use patch instead of delete for deleting cardinalities (DSP-1700) (#1903)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/00-release-notes/#documentation_2","text":"add username to changeable attributes (DSP-1895) ( #1904 ) ( 719cd0d )","title":"Documentation"},{"location":"DSP-API/00-release-notes/#maintenance_18","text":"ontology: use patch instead of delete for deleting cardinalities (DSP-1700) ( #1903 ) ( 91ef4ec )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1410-2021-08-19","text":"","title":"14.1.0 (2021-08-19)"},{"location":"DSP-API/00-release-notes/#bug-fixes_13","text":"ontology V2: use internal iri when updating a property (DSP-1868) ( #1898 ) ( a746f65 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#enhancements_7","text":"v2-ontologies: add remove cardinalities from class if property not used in resources (DSP-1700) ( #1869 ) ( a30668b )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1401-2021-08-04","text":"","title":"14.0.1 (2021-08-04)"},{"location":"DSP-API/00-release-notes/#bug-fixes_14","text":"add-test-file: add response file for test case (DSP-1841) ( #1894 ) ( 028e685 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#1400-2021-08-02","text":"","title":"14.0.0 (2021-08-02)"},{"location":"DSP-API/00-release-notes/#breaking-changes_4","text":"projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) (#1886)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/00-release-notes/#bug-fixes_15","text":"api-v2, api-admin: ontology name and project name should be URL safe (DSP-1749) ( #1889 ) ( 17601a7 ) permissions: reject malformed doap and ap create/update request (DSP-1328) ( #1890 ) ( 3e3a3ce )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#enhancements_8","text":"customIRIs: custom IRIs must contain a UUID (DSP-1763) ( #1884 ) ( 593d9cb ) projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) ( #1886 ) ( b3c2d5f ) resource-metadata: return resource metadata after metadata update request (DSP-1828) ( #1893 ) ( a4e878a ) video: add support for video/mp4 to both v1 and v2 (DSP-1204) ( #1891 ) ( 83fb4b8 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#13120-2021-06-24","text":"","title":"13.12.0 (2021-06-24)"},{"location":"DSP-API/00-release-notes/#enhancements_9","text":"resourceHistoryEvents: route for resource history events (DSP-1749) ( #1882 ) ( f86de53 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#13110-2021-06-17","text":"","title":"13.11.0 (2021-06-17)"},{"location":"DSP-API/00-release-notes/#enhancements_10","text":"events: update resource last modification date event ( #1877 ) ( d5e70ba )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#maintenance_19","text":"build: cleanup ( #1880 ) ( 749e8ea ) cache-service: add in-memory implementation ( #1870 ) ( 61531ab ) gh-ci: update docs deployment (DSP-1741) ( #1878 ) ( ff65323 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#13100-2021-06-09","text":"","title":"13.10.0 (2021-06-09)"},{"location":"DSP-API/00-release-notes/#enhancements_11","text":"gravsearch: use layer info for topological order permutations (DSP-1389) ( #1872 ) ( b49d5ba )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#documentation_3","text":"prepare documentation for docs.dasch.swiss (DSP-1721) ( #1873 ) ( 66751a0 )","title":"Documentation"},{"location":"DSP-API/00-release-notes/#1392-2021-06-02","text":"","title":"13.9.2 (2021-06-02)"},{"location":"DSP-API/00-release-notes/#maintenance_20","text":"sipi: add comments ( #1864 ) ( 06e8b0c )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#documentation_4","text":"ontology: update term ( #1865 ) ( cd37580 )","title":"Documentation"},{"location":"DSP-API/00-release-notes/#1391-2021-05-28","text":"","title":"13.9.1 (2021-05-28)"},{"location":"DSP-API/00-release-notes/#maintenance_21","text":"bazel: bump bazel version ( #1866 ) ( c754cbf )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1390-2021-05-25","text":"","title":"13.9.0 (2021-05-25)"},{"location":"DSP-API/00-release-notes/#enhancements_12","text":"api-v2: Add routes for checking whether ontology entities can be changed (DSP-1621) ( #1861 ) ( fdd098f )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1380-2021-05-19","text":"","title":"13.8.0 (2021-05-19)"},{"location":"DSP-API/00-release-notes/#bug-fixes_16","text":"api-v2: Update subclasses in ontology cache when base class changes (DSP-1643) ( #1860 ) ( beb951d ) gravsearch: don't move the patterns with resource IRI after topological sorting (DSP-1620) ( #1856 ) ( 6022c91 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_22","text":"documentation: bug fix in documentation deployment (DSP-1605) ( bb852c9 ) documentation: bug fix in documentation deployment (DSP-1605) ( #1854 ) ( 999a2bb )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#enhancements_13","text":"api-v2: Change GUI element and attribute of a property (DSP-1600) ( #1855 ) ( ce9ba3a ) api-v2: Generate IIIF manifest (DSP-50) ( #1784 ) ( 74feb2c ) conf: Rule to dump prod data and load locally (DSP-1485) ( #1857 ) ( 161ea31 ) ontology: Allow adding new property to a resource class in use (DSP-1629) ( #1859 ) ( 061875e )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1370-2021-05-06","text":"","title":"13.7.0 (2021-05-06)"},{"location":"DSP-API/00-release-notes/#bug-fixes_17","text":"doc: correct remaining incorrect copyright dates ( #1847 ) ( d1473ed ) gravsearch: Keep rdf:type knora-api:Resource when needed. ( #1835 ) ( e561d94 ) lists: Escape special characters in comment, label, and name of a list node (DSP-1529) ( #1846 ) ( f96c069 ) test-data: change webern shortcode in test data (DSP-1520) ( #1843 ) ( 5f06a10 ) values v1 route: fix geoname case (DSP-1487) ( #1839 ) ( 9d0e93e )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#documentation_5","text":"replace knora by dsp or dsp-api in documentation (DSP-1469) ( #1836 ) ( 923abe8 ) v1: improve search docs ( #1848 ) ( 5a81f73 )","title":"Documentation"},{"location":"DSP-API/00-release-notes/#enhancements_14","text":"api-v2: Add route for changing GUI order of cardinalities ( #1850 ) ( d8dbb4f ) api-v2: Return events describing version history of resources and values of a project ordered by data (DSP-1528) ( #1844 ) ( 84f7c14 ) ext search v1: add support for URI values (DSP-1522) ( #1842 ) ( b119757 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#maintenance_23","text":"bumb Bazel to version with apple silicon support ( #1852 ) ( 286d289 ) bump scala to 2.13 ( #1851 ) ( 5feb915 ) deps: bump versions (DSP-1569) ( #1849 ) ( f69f008 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1360-2021-03-16","text":"","title":"13.6.0 (2021-03-16)"},{"location":"DSP-API/00-release-notes/#enhancements_15","text":"api-v2: Improve error message when an XSLT transformation file is not found (DSP-1404) ( #1831 ) ( 153a674 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1351-2021-03-11","text":"","title":"13.5.1 (2021-03-11)"},{"location":"DSP-API/00-release-notes/#bug-fixes_18","text":"OntologiesRouteV2: Reject internal ontology names in external schema (DSP-1394) ( #1827 ) ( e392bf1 ) OntologyResponderV2: Fix check when updating ontology label and comment (DSP-1390) ( #1826 ) ( 26cce48 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#1350-2021-03-08","text":"","title":"13.5.0 (2021-03-08)"},{"location":"DSP-API/00-release-notes/#bug-fixes_19","text":"replaceCardinalities.scala.txt: Fix blank node insertion. ( #1829 ) ( d24c5d2 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_24","text":"gh-ci: update release please configuration (DSP-1382) ( #1825 ) ( 7ce4b65 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#enhancements_16","text":"Add support for audio files (DSP-1343) ( #1818 ) ( 7497023 ) gravsearch: Optimise Gravsearch queries using topological sort (DSP-1327) ( #1813 ) ( efbecee ) store: Return 404 if the triplestore returns 404. ( #1828 ) ( 5250f6d )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1340-2021-02-17","text":"","title":"13.4.0 (2021-02-17)"},{"location":"DSP-API/00-release-notes/#bug-fixes_20","text":"Lists: fix bug in shifting the second of two children after deletion of the first one. ( #1820 ) ( d92bb01 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#enhancements_17","text":"projects: add default set of permissions when creating new project (DSP-1347) ( #1822 ) ( b7c71ca )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1331-2021-02-09","text":"","title":"13.3.1 (2021-02-09)"},{"location":"DSP-API/00-release-notes/#bug-fixes_21","text":"Lists: fix bug in deleting the single child of a node (DSP-1355) ( #1816 ) ( 1d06572 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#1330-2021-02-05","text":"","title":"13.3.0 (2021-02-05)"},{"location":"DSP-API/00-release-notes/#enhancements_18","text":"sipi: add storing of original and sidecar (DSP-1318) ( #1808 ) ( 022ed7e )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1320-2021-02-04","text":"","title":"13.2.0 (2021-02-04)"},{"location":"DSP-API/00-release-notes/#bug-fixes_22","text":"api-v1: Optimise SPARQL queries. ( #1814 ) ( 4edc27c ) Lists: Repositioning the node when new position equals length of new parent's children (DSP-1322) ( #1811 ) ( 3fead13 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#enhancements_19","text":"api-v1: Add support for PDF files (DSP-1267) ( #1797 ) ( c3b2e84 ) api-v2: Allow resubmitting existing class/property lablels/comments. ( #1812 ) ( 6a13852 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#maintenance_25","text":"make targets for adding metadata (DSP-1289) ( #1810 ) ( 9c1a70a ) salsah1: delete from repository ( #1805 )(DSP-1294) ( 3251a74 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1311-2021-01-30","text":"","title":"13.1.1 (2021-01-30)"},{"location":"DSP-API/00-release-notes/#maintenance_26","text":"gh-ci: Bring back the client-test-data command to github actions ( #1804 ) ( e6b0fbf ) revert release 13.1.0 ( #1800 ) ( 565e5ac )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#1310-2021-01-29","text":"","title":"13.1.0 (2021-01-29)"},{"location":"DSP-API/00-release-notes/#bug-fixes_23","text":"api-v1: Optimise link value queries for Fuseki (DSP-1243) ( #1791 ) ( b1e1b9e ) api-v2: Don't allow an invalid cardinality on a boolean property (DSP-1236) ( #1788 ) ( 3d5f802 ) gravsearch: Handle UNION scopes with FILTER correctly (DSP-1240) ( #1790 ) ( 61d2e86 ) HttpTriplestoreConnector: Always parse triplestore responses as UTF-8. ( #1789 ) ( 61d2e86 ) permissions : fix getting builtin groups while creating a permission (DSP-1296 ) ( #1799 ) ( d390014 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#maintenance_27","text":"gh-ci: fix issue in the release process ( #1782 ) ( afe61b7 ) ghi-ci: google chat release notification ( #1785 ) ( 4718cdc )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#enhancements_20","text":"permissions: add delete permissions: (DSP-1169) ( #1787 ) ( 3fe8c14 ) store: Return a clearer exception when a triplestore read timeout occurs. ( #1795 ) ( 0eeb3b3 )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#1300-2021-01-11","text":"","title":"13.0.0 (2021-01-11)"},{"location":"DSP-API/00-release-notes/#breaking-changes_5","text":"New features and refactoring (#1779)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/00-release-notes/#bug-fixes_24","text":"(dependencies) add the missing dependency ( #1755 ) ( 0e37d21 ) api-v2: Change link value comment ( #1582 ) ( faa2e55 ) api-v2: Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) ( #1749 ) ( 905766f ) api-v2: Fix custom datatypes in knora-api simple ontology ( #1601 ) ( e0cfd4e ) api-v2: Fix generated SPARQL for updating property comment ( #1693 ) ( 7b70339 ) api-v2: Fix ontology deletion ( #1584 ) ( 70b0841 ) api-v2: Fix post-update check for resource with standoff link (DSP-841) ( #1728 ) ( 35d449f ) failing repository upgrade at startup (DSP-654) ( #1712 ) ( 0d6b4ee ) gravsearch: Prevent duplicate results ( #1626 ) ( 9313b88 ) gravsearch: When link property compared in filter, don't compare link value property, too ( #1699 ) ( a3b1665 ) init db scripts (DSP-511) ( #1681 ) ( d4505ce ) loading of data (DSP-445) ( #1669 ) ( 3f8d406 ) OntologyResponderV2: Add a global ontology cache lock ( #1637 ) ( 1853865 ) OntologyResponderV2: Fix ontology cache update when ontology metadata changed ( #1709 ) ( 4f57977 ) server header (DSP-537) ( #1691 ) ( 8d7bee8 ) sipi makefile ( #1616 ) ( 73a0afe ) sipi: Don't expect API v1 status code (DSP-1114) ( #1763 ) ( 3236d25 ) sipi: Improve performance of file value query ( #1697 ) ( 8214877 ) test: Fix typos in IRIs in anything-data.ttl. ( #1625 ) ( 23d51ce ) upgrade: Fix log output. ( #1774 ) ( b43fab0 ) webapi: unique username/email check on change user ( #1561 ) ( 4f26e22 ) rdf-api : Use the Jena RDF API implementation by default (DSP-1153) ( 1772 ) ( 389feb4 )","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#documentation_6","text":"api-v2: Document what happens when a resource has a link to a deleted resource ( #1685 ) ( 1c88651 ) fix broken links ( #1688 ) ( 9c0292c ) fix make targets docker-build and docker-publish ( #1694 ) ( d06b6a6 ) Update README (DSP-1142) ( #1771 ) ( 7ba7fc6 ) Update required mkdocs package ( #1725 ) ( 27de65e )","title":"Documentation"},{"location":"DSP-API/00-release-notes/#maintenance_28","text":"api-v2: Delete obsolete files. ( #1634 ) ( e80bf52 ) api-v2: Switch from JSONLD-Java to Titanium ( #1715 ) ( 9e28e5b ) build: Bump testcontainers version. ( #1723 ) ( 24ae1d3 ) build: Update ScalaTest (DSP-919) ( #1745 ) ( bbaeadd ) build: Upgrade Sipi to 3.0.0-rc.8 (DSP-916) ( #1743 ) ( 23395fc ) bump sipi to rc.7 (DSP-733) ( #1721 ) ( b635495 ) gh-ci: Fix gren issue ( #1666 ) ( 2dc5361 ) gh-ci: Publish on release only ( #1662 ) ( 787dca8 ) rdf-api: Use the Jena RDF API implementation by default (DSP-1153) ( #1772 ) ( 389feb4 ) Remove obsolete functions from StringFormatter. ( #1640 ) ( 5fa6de4 ) Update ci workflow release notes ( #1707 ) ( d8e0b39 ) gh-ci CI is failing to test upgrade correctly (DSP-667) ( #1073 ) ( 13cbdab ) bazel Update Bazel maven rules to see if it fixes problems with macOS Big Sur (DSP-1099) ( #1761 ) ( a2c9941 )","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#enhancements_21","text":"Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) ( #1759 ) ( 346873d ) Add feature toggles (DSP-910) ( #1742 ) ( 2e6db2e ) Add time value type ( #1403 ) ( d925c85 ) api-v1: Change API v1 file uploads to work like API v2 (DSP-41, PR 3) ( #1722 ) ( a824bcc ) api-v2: Accept custom new value IRI when updating value ( #1698 ) ( 4d8f867 ) api-v2: Accept custom timestamps in update/delete requests ( #1686 ) ( 0fbe5a8 ) api-v2: Add an RDF processing fa\u00e7ade (DSP-1020) ( #1754 ) ( 9170419 ) api-v2: Add metadata routes (DSP-662) ( #1734 ) ( bf48968 ) api-v2: Add support for text file upload (DSP-44) ( #1664 ) ( a88d20d ) api-v2: Add test data. ( #1704 ) ( de14ab1 ) api-v2: Allow querying for rdfs:label in Gravsearch ( #1649 ) ( d56004b ) api-v2: Control JSON-LD nesting via an HTTP header (DSP-1084) ( #1758 ) ( b13eecf ) api-v2: Make inference optional in Gravsearch ( #1696 ) ( 166a260 ) api-v2: Optionally return file values in full-text search results (DSP-1191) ( #1776 ) ( 01f59bd ) api-v2: Remove client code generation ( #1610 ) ( 6977ab3 ) api-v2: Remove ForbiddenResource ( #1615 ) ( 992596e ) api-v2: Return value UUID on value creation and update ( #1602 ) ( cbed601 ) api-v2: Specify custom IRIs when creating resources/values ( #1646 ) ( 135b039 ) clientapi: Change method signature. ( #1583 ) ( c2a2559 ) gh-ci: Release please and update gh actions (DSP-1168) ( #1777 ) ( 593ffab ) gravsearch: Allow comparing variables representing resource IRIs ( #1713 ) ( f359c8e ) gravsearch: Remove deprecated functions ( #1660 ) ( 5d3af46 ) New features and refactoring ( #1779 ) ( 9a5fb77 ) rdf-api: Add a general-purpose SHACL validation utility (DSP-930) ( #1762 ) ( bfd3192 ) sipi: Improve error message if XSL file not found ( #1590 ) ( bbb42f6 ) triplestores: Support Apache Jena Fuseki ( #1375 ) ( 82f8a55 ) upgrade: Update repository on startup ( #1643 ) ( 0127dca )","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#v1300-rc25-08122020","text":"","title":"v13.0.0-rc.25 (08/12/2020)"},{"location":"DSP-API/00-release-notes/#enhancements_22","text":"#1768 | DSP-1106 Update Permission #1767 | enhancement(triplestore): Use N-Quads instead of TriG for repository upgrade (DSP-1129) #1764 | DSP-1033 Reposition List Nodes #1762 | feat(rdf-api): Add a general-purpose SHACL validation utility (DSP-930) #1759 | feat: Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) #1760 | (DSP-1031) Delete list items #1753 | Edit lists routes (DSP-597 ) #1758 | feat(api-v2): Control JSON-LD nesting via an HTTP header (DSP-1084)","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#bug-fixes_25","text":"#1763 | fix(sipi): Don't expect API v1 status code (DSP-1114)","title":"Bug fixes"},{"location":"DSP-API/00-release-notes/#documentation_7","text":"#1771 | docs: Update README (DSP-1142)","title":"Documentation"},{"location":"DSP-API/00-release-notes/#maintenance_29","text":"#1770 | refactor: Use java.nio.file.Path instead of java.io.File (DSP-1124) #1765 | DSP-1094 Upgrade Swagger version #1766 | style: Add Scalafmt config file #1769 | style: Reformat code with Scalafmt (DSP-1137) #1754 | feat(api-v2): Add an RDF processing fa\u00e7ade (DSP-1020) #1757 | build: bazel workspace cleanup","title":"Maintenance"},{"location":"DSP-API/00-release-notes/#v1300-rc24-13112020","text":"#1756 | DSP-1052 : Migration task to replace empty strings with dummy \"FIXME\"","title":"v13.0.0-rc.24 (13/11/2020)"},{"location":"DSP-API/00-release-notes/#v1300-rc23-09112020","text":"","title":"v13.0.0-rc.23 (09/11/2020)"},{"location":"DSP-API/00-release-notes/#bug-fixes_26","text":"#1755 | DSP-1029: Add the missing dependency","title":"Bug fixes"},{"location":"DSP-API/00-release-notes/#v1300-rc22-09112020","text":"","title":"v13.0.0-rc.22 (09/11/2020)"},{"location":"DSP-API/00-release-notes/#breaking-changes_6","text":"#1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions","title":"Breaking changes"},{"location":"DSP-API/00-release-notes/#enhancements_23","text":"#1403 | feat: Add time value type #1537 | build: Add env var to set triplestore actor pool #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30)","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#bug-fixes_27","text":"#1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1576 | Add missing env var #1571 | fixed date string format #1564 | enable click on save button in case of recoverable error #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445)","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#documentation_8","text":"#1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering","title":"Documentation"},{"location":"DSP-API/00-release-notes/#other","text":"#1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes","title":"Other"},{"location":"DSP-API/00-release-notes/#dependencies","text":"#1721 | chore: bump sipi to rc.7 (DSP-733) #1735 | DSP-496 Bump Apache Jena Fuseki and Apache Jena Libraries to 3.16 #1737 | DSP-842 Bump used Bazel version to newly released 3.7.0 #1743 | chore(build): Upgrade Sipi to 3.0.0-rc.8 (DSP-916) #1745 | chore(build): Update ScalaTest (DSP-919) #1752 | DSP-1017 Upgrade to Sipi v3.0.0-rc.9","title":"Dependencies"},{"location":"DSP-API/00-release-notes/#v1300-rc21-09112020","text":"","title":"v13.0.0-rc.21 (09/11/2020)"},{"location":"DSP-API/00-release-notes/#breaking-changes_7","text":"#1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions","title":"Breaking changes"},{"location":"DSP-API/00-release-notes/#enhancements_24","text":"#1403 | feat: Add time value type #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30)","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#bug-fixes_28","text":"#1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445)","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#documentation_9","text":"#1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering","title":"Documentation"},{"location":"DSP-API/00-release-notes/#other_1","text":"#1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes","title":"Other"},{"location":"DSP-API/00-release-notes/#v1200-27012020","text":"","title":"v12.0.0 (27/01/2020)"},{"location":"DSP-API/00-release-notes/#breaking-api-changes","text":"#1439 JSON-LD Serialization of an xsd:dateTimeStamp","title":"Breaking API Changes"},{"location":"DSP-API/00-release-notes/#new-features-and-enhancements","text":"#1509 Support lists admin endpoint #1466 Optimise generated SPARQL","title":"New Features and Enhancements"},{"location":"DSP-API/00-release-notes/#bug-fixes_29","text":"#1569 broken ark #1559 Admin lists: createChildNode should send a httpPost request, not httpPut","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#v1100-16122019","text":"","title":"v11.0.0 (16/12/2019)"},{"location":"DSP-API/00-release-notes/#breaking-changes_8","text":"#1344 Gravsearch ForbiddenResource result and permissions of linked resources #1202 Implement upload of PDF and text files in API v2. Users with files in Sipi under /server must move them to /images when upgrading.","title":"Breaking Changes"},{"location":"DSP-API/00-release-notes/#bug-fixes_30","text":"#1531 Sipi's mimetype_consistency fails with .bin file #1430 Creating the first resource with an image inside a project fails with Sipi not finding the project folder #924 Get dependent resources Iris","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#v1011-27112019","text":"","title":"v10.1.1 (27/11/2019)"},{"location":"DSP-API/00-release-notes/#v1010-27112019","text":"","title":"v10.1.0 (27/11/2019)"},{"location":"DSP-API/00-release-notes/#v1000-22102019","text":"","title":"v10.0.0 (22/10/2019)"},{"location":"DSP-API/00-release-notes/#breaking-changes_9","text":"#1346 Richtext/HTML in page anchor link","title":"Breaking Changes"},{"location":"DSP-API/00-release-notes/#enhancements_25","text":"#1457 Upgrade sipi to 2.0.1","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#bug-fixes_31","text":"#1460 Build banner in README is broken","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#documentation_10","text":"#1481 build badge in README has broken link","title":"Documentation"},{"location":"DSP-API/00-release-notes/#other_2","text":"#1449 Add Makefile-based task execution #1401 Enable testing docs generation in Travis","title":"Other"},{"location":"DSP-API/00-release-notes/#v910-26092019","text":"","title":"v9.1.0 (26/09/2019)"},{"location":"DSP-API/00-release-notes/#enhancements_26","text":"#1421 Physically deleting a resource","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#documentation_11","text":"#1407 Document ARK URLs for projects","title":"Documentation"},{"location":"DSP-API/00-release-notes/#v900-29082019","text":"","title":"v9.0.0 (29/08/2019)"},{"location":"DSP-API/00-release-notes/#breaking-changes_10","text":"#1411 Moved /admin/groups/members/GROUP_IRI to /admin/groups/GROUP_IRI/members #1231 Change value permissions #763 refactor splitMainResourcesAndValueRdfData so it uses SparqlExtendedConstructResponse","title":"Breaking Changes"},{"location":"DSP-API/00-release-notes/#enhancements_27","text":"#1373 The startup ends in a thrown exception if the triplestore is not up-to-date #1364 Add support for Redis cache #1360 Build and publish Knora version specific docker images for GraphDB Free and SE #1358 Add admin route to dump project data","title":"Enhancements"},{"location":"DSP-API/00-release-notes/#bug-fixes_32","text":"#1394 Using dockerComposeUp to start the stack, fails to find Redis at startup","title":"Bug Fixes"},{"location":"DSP-API/00-release-notes/#documentation_12","text":"#1386 Add lists admin API documentation","title":"Documentation"},{"location":"DSP-API/00-release-notes/#other_3","text":"#1412 Change release notes to be based on issues","title":"Other"},{"location":"DSP-API/00-release-notes/#v800-14062019","text":"feature(webapi): Add GraphDB-Free startup support (#1351) - @subotic feature(webapi): Add returning of fixed public user information (#1348) - @subotic feat(api-v2): No custom permissions higher than defaults (#1337) - @benjamingeer feat(upgrade): Improve upgrade framework (#1345) - @benjamingeer test(webapi): Add new user authentication (#1201) - @subotic chore(webapi): Add request duration logging (#1347) - @subotic feat(api-v2): Make values citable (#1322) - @benjamingeer Leibniz ontology (#1326) - @SepidehAlassi feature(webapi): add CORS allow header (#1340) - @subotic fix(sipi): Return permissions for a previous version of a file value. (#1339) - @benjamingeer fix(scripts): add admin ontology data to correct graph (#1333) - @subotic fix(sipi): Don't try to read a file value in a deleted resource. (#1329) - @benjamingeer docs(api-v2): Fix sample responses. (#1327) - @benjamingeer fix(api-v2): Fix typo. (#1325) - @benjamingeer Handle List Nodes in Response (#1321) - @tobiasschweizer feat(api-v2): Return standoff markup separately from text values (#1307) - @benjamingeer BEOL: Import comments for Meditationes (#1281) - @tobiasschweizer feat(triplestore): Log SPARQL query if triplestore doesn't respond. (#1292) - @benjamingeer Support list nodes in Gravsearch (#1314) - @tobiasschweizer","title":"v8.0.0 (14/06/2019)"},{"location":"DSP-API/00-release-notes/#v700-03052019","text":"fix(api-v2): Cache base class IRIs correctly when creating/updating class (#1311) - @benjamingeer chore(standoff): Use Base64-encoded UUIDs in standoff tags. (#1301) - @benjamingeer feat(api-v2): Allow a resource to be created as a specified user (#1306) - @benjamingeer feat(admin): Give the admin ontology an external schema (#1291) - @benjamingeer fix(api-v2): Remove INFORMATION SEPARATOR TWO from text in the simple schema. (#1299) - @benjamingeer test: Compare Knora response with its class definition (#1297) - @benjamingeer docs(api-admin): fix description of the change password payload (#1285) - @loicjaouen fix(api-v1): Fix double escaping of newline. (#1296) - @benjamingeer fix (tei beol): fix problems in XSLT (#1260) - @tobiasschweizer refactor(ontology): Make knora-admin a separate ontology (#1263) - @benjamingeer a handfull of changes in documentation and error messages (#1278) - @loicjaouen docs: fix missing username (#1269) - @loicjaouen feat(api-v2): Get resources in a particular class from a project (#1251) - @benjamingeer fix(sipi): Improve error checking of Sipi's knora.json response. (#1279) - @benjamingeer feat(api-v2): Return user's permission on resources and values (#1257) - @benjamingeer fix(api-v1): Escape rdfs:label in bulk import. (#1276) - @benjamingeer chore(webapi): Remove persistent map code (#1254) - @benjamingeer docs (api-v2): Update outdated ARK documentation. (#1252) - @benjamingeer Update build.properties (#1265) - @subotic","title":"v7.0.0 (03/05/2019)"},{"location":"DSP-API/00-release-notes/#v601-22032019","text":"chore: releasing-v6.0.1 (#1270) - @subotic chore(webapi): Add script for loading of a minimal set of data (#1267) - @subotic fix (beolPersonLabel) typo in label of hasBirthPlace (#1248) - @SepidehAlassi fix (webapi): message typo (#1244) - @subotic Unescape standoff string attributes when verifying text value update (#1242) - @benjamingeer docs: fix user admin api (#1237) - @subotic","title":"v6.0.1 (22/03/2019)"},{"location":"DSP-API/00-release-notes/#v600-28022019","text":"","title":"v6.0.0 (28/02/2019)"},{"location":"DSP-API/00-release-notes/#release-notes","text":"MAJOR: Use HTTP POST to mark resources and values as deleted (#1203) MAJOR: Reorganize user and project routes (#1209) FEATURE: Secure routes returning user information (#961) MAJOR: Change all xsd:dateTimeStamp to xsd:dateTime in the triplestore (#1211). Existing data must be updated; see upgrade/1211-datetime for instructions. FIX: Ignore order of attributes when comparing standoff (#1224). FEATURE: Query version history (#1214) FIX: Don't allow conflicting cardinalities (#1229) MAJOR: Remove preview file values (#1230). Existing data must be updated; see upgrade/1230-delete-previews for instructions.","title":"Release Notes"},{"location":"DSP-API/00-release-notes/#v500-05022019","text":"","title":"v5.0.0 (05/02/2019)"},{"location":"DSP-API/00-release-notes/#release-notes_1","text":"MAJOR: Fix property names for incoming links (#1144)) MAJOR: Generate and resolve ARK URLs for resources (#1161). Projects that have resource IRIs that do not conform to the format specified in https://docs.knora.org/paradox/03-apis/api-v2/knora-iris.html#iris-for-data must update them. MAJOR: Use project shortcode in IIIF URLs (#1191). If you have file value IRIs containing the substring /reps/ , you must replace /reps/ with /values/ . FEATURE: Update resource metadata in API v2 (#1131) FEATURE: Allow setting resource creation date in bulk import #1151) FEATURE: The v2/authentication route now also initiates cookie creation (the same as v1/authentication ) (#1159) FEATURE: Allow to specify restricted view settings for a project which Sipi will adhere to (#690). FIX: Triplestore connection error when using dockerComposeUp (#1122) FIX: Reject link value properties in Gravsearch queries in the simple schema (#1145) FIX: Fix error-checking when updating cardinalities in ontology API (#1142) FIX: Allow hasRepresentation in an ontology used in a bulk import (#1171) FIX: Set cookie domain to the value specified in application.conf with the setting cookie-domain (#1169) FIX: Fix processing of shared property in bulk import (#1182)","title":"Release Notes"},{"location":"DSP-API/00-release-notes/#v400-12122018","text":"","title":"v4.0.0 (12/12/2018)"},{"location":"DSP-API/00-release-notes/#v400-release-notes","text":"MAJOR CHANGE: mapping creation request and response formats have changed (#1094) MINOR CHANGE: Update technical user docs (#1085) BUGFIX CHANGE: Fix permission checking in API v2 resource creation (#1104)","title":"v4.0.0 Release Notes"},{"location":"DSP-API/00-release-notes/#v300-30112018","text":"","title":"v3.0.0 (30/11/2018)"},{"location":"DSP-API/00-release-notes/#v300-release-notes","text":"[BREAKING ONTOLOGY CHANGE] The property knora-base:username was added and is required for knora-base:User . (#1047) [BREAKING API CHANGE] The /admin/user API has changed due to adding the username property. (#1047) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Add default permission caching (#1062) [FIX] Fix unescaping in update check and reading standoff URL (#1074) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Create image file values in API v2 (#1011). Requires Sipi with tagged commit v1.4.1-SNAPSHOT or later.","title":"v3.0.0 Release Notes"},{"location":"DSP-API/00-release-notes/#v210-02112018","text":"","title":"v2.1.0 (02/11/2018)"},{"location":"DSP-API/00-release-notes/#new-features","text":"Implement graph query in API v2 (#1009) Expose additional webapi settings as environment variables. Please see the Configuration section in the documentation for more information (#1025)","title":"New features"},{"location":"DSP-API/00-release-notes/#bugfixes","text":"sipi container config / sipi not able to talk to knora (#994)","title":"Bugfixes"},{"location":"DSP-API/00-release-notes/#v210-snapshot-22102018","text":"","title":"v2.1.0-snapshot (22/10/2018)"},{"location":"DSP-API/00-release-notes/#v200-13092018","text":"This is the first release with the new version numbering convention. From now on, if any changes to the existing data are necessary for a release, then this release will have its major number increased. Please see the Release Versioning Convention description.","title":"v2.0.0 (13/09/2018)"},{"location":"DSP-API/00-release-notes/#required-changes-to-existing-data","text":"a knora-base:ListNode must have at least one rdfs:label . (@github #991 )","title":"Required changes to existing data"},{"location":"DSP-API/00-release-notes/#new-features_1","text":"add developer-centric docker-compose.yml for starting the Knora / GraphDB / Sipi / Salsah1 (@github #979 ) configure webapi and salsah1 thorough environment variables (@github #979 ) update for Java 10 (@github #979 ) comment out the generation of fat jars from KnoraBuild.sbt (for now) (@github #979 ) update ehcache (@github #979 ) update sbt to 1.2.1 (@github #979 ) remove Kamon monitoring (for now) since we don't see anything meaningful there. We probably will have to instrument Knora by hand and then use Kamon for access. (@github #979 ) update Dockerfiles for webapi and salsah1 (@github #979 ) follow subClassOf when including ontologies in XML import schemas (@github #991 ) add support for adding list child nodes (@github #991 ) add support for shared ontologies (@github #987 )","title":"New features"},{"location":"DSP-API/00-release-notes/#bugfixes_1","text":"trouble with xml-checker and/or consistency-checker during bulk import (@github #978 ) ontology API error with link values (@github #988 )","title":"Bugfixes"},{"location":"DSP-API/00-release-notes/#v171-29082018","text":"","title":"v1.7.1 (29/08/2018)"},{"location":"DSP-API/00-release-notes/#knora-stack-compatible-versions","text":"Knora v1.7.1 - Salsah v2.1.2 - Sipi v1.4.0 - GraphDB v8.5.0 doc (webapi): add yourkit acknowledgment (#983) Don't allow class with cardinalities on P and on a subproperty of P (#982) doc (webapi): add LHTT project shortcode (#981) feature (webapi): not return or allow changing of built-in users (#975) fix (webapi): startup check does not detect running triplestore (#969) Fix bulk import parsing bug and limit concurrent client connections (#973)","title":"Knora-Stack compatible versions"},{"location":"DSP-API/00-release-notes/#v170-16082018","text":"See the closed tickets on the v1.7.0 milestone .","title":"v1.7.0 (16/08/2018)"},{"location":"DSP-API/00-release-notes/#knora-stack-compatible-versions_1","text":"Knora v1.7.0 - Salsah v2.1.0 - Sipi v1.4.0 - GraphDB v8.5.0","title":"Knora-Stack compatible versions"},{"location":"DSP-API/00-release-notes/#required-changes-to-existing-data_1","text":"To use the inferred Gravsearch predicate knora-api:standoffTagHasStartAncestor , you must recreate your repository with the updated KnoraRules.pie .","title":"Required changes to existing data"},{"location":"DSP-API/00-release-notes/#new-features_2","text":"Gravsearch queries can now match standoff markup (#910). Add Graphdb-Free initialization scripts for local and docker installation (#955). Create temp dirs at startup (#951) Update versions of monitoring tools (#951)","title":"New features"},{"location":"DSP-API/00-release-notes/#bugfixes_2","text":"timeout or java.lang.OutOfMemoryError when using /v1/resources/xmlimportschemas/ for some ontologies (#944) Timeout cleanup (#951) Add separate dispatchers (#945)","title":"Bugfixes"},{"location":"DSP-API/00-release-notes/#v160-29062018","text":"","title":"v1.6.0 (29/06/2018)"},{"location":"DSP-API/00-release-notes/#v160-release-notes","text":"See the release and closed tickets on the v1.6.0 milestone on Github.","title":"v1.6.0 Release Notes"},{"location":"DSP-API/00-release-notes/#required-changes-to-existing-data_2","text":"A project is now required to have at least one description, so potentially a description will need to be added to those projects that don't have one.","title":"Required changes to existing data"},{"location":"DSP-API/00-release-notes/#new-features_3","text":"General: Added a /health endpoint KnoraService waits on startup for a triplestore before trying to load the ontologies Gravsearch enhancements: Accept queries in POST requests (@github #650 ). Allow a Gravsearch query to specify the IRI of the main resource (@github #871 ) (by allowing BIND ). Allow lang to be used with != . A UNION or OPTIONAL can now be nested in an OPTIONAL (@github #882 ). Gravsearch now does type inference (@github #884 ). The Knora API v2 complex schema can now be used in Gravsearch, making it possible to search for list nodes (@github #899 ). Admin API: Make project description required (@github #875 ). Conversion to TEI: Conversion of standard standoff entities to TEI Custom conversion of project specific standoff entities and metadata to TEI Sipi integration: The Knora specific Sipi configuration and scripts can now be found under the sipi/ directory (@github #404 ). Documentation on how Sipi can be started changed (@github #404 ).","title":"New features"},{"location":"DSP-API/00-release-notes/#bugfixes_3","text":"Allow a class or property definition to have more than one object for rdf:type (@github #885 ). Exclude list values from v2 fulltext search (@github #906 ). Gravsearch fixes: Allow the lang function to be used in a comparison inside AND/OR (@github #846 ). Fix the processing of resources with multiple incoming links that use the same property (@github #878 ). Fix the parsing of a FILTER inside an OPTIONAL (@github #879 ). Require the match function to be the top-level expression in a FILTER .","title":"Bugfixes"},{"location":"DSP-API/00-release-notes/#v150-31052018","text":"See v1.5.0 milestone for a full list of closed tickets.","title":"v1.5.0 (31/05/2018)"},{"location":"DSP-API/00-release-notes/#new-features_4","text":"Resources can be returned in the simple ontology schema (#833). Text values can specify the language of the text (#819). Responses can be returned in Turtle and RDF/XML (#851).","title":"New features"},{"location":"DSP-API/00-release-notes/#bugfixes_4","text":"Incorrect representation of IRI object values in JSON-LD (#835) GenerateContributorsFile broken (#797)","title":"Bugfixes"},{"location":"DSP-API/00-release-notes/#v140-30042018","text":"","title":"v1.4.0 (30/04/2018)"},{"location":"DSP-API/00-release-notes/#required-changes-to-existing-data_3","text":"Every ontology must now have the property knora-base:attachedToProject , which points to the IRI of the project that is responsible for the ontology. This must be added to each project-specific ontology in existing repositories. All built-in ontologies have been updated to have this property, and must, therefore, be reloaded into existing repositories. The property knora-base:projectOntology has been removed, and must be removed from project definitions in existing repositories. Every project now needs to have the property knora-base:projectShortcode set.","title":"Required changes to existing data"},{"location":"DSP-API/00-release-notes/#new-features_5","text":"Added OpenAPI / Swagger API documentation route The Knora API server now checks the validity of ontologies on startup. The property knora-base:projectShortcode is now a required property (was optional).","title":"New features"},{"location":"DSP-API/00-release-notes/#bugfixes_5","text":"API v1 extended search was not properly handling multiple conditions on list values (issue #800) Fix image orientation in SALSAH 1 (issue #726)","title":"Bugfixes"},{"location":"DSP-API/00-release-notes/#v131-06042018","text":"","title":"v1.3.1 (06/04/2018)"},{"location":"DSP-API/00-release-notes/#v130-28032018","text":"","title":"v1.3.0 (28/03/2018)"},{"location":"DSP-API/00-release-notes/#required-changes-to-existing-data_4","text":"","title":"Required changes to existing data"},{"location":"DSP-API/00-release-notes/#1-replace-salsah-gui-ontology","text":"You must replace the salsah-gui ontology that you have in the triplestore with the one in salsah-gui.ttl .","title":"1. Replace salsah-gui ontology"},{"location":"DSP-API/00-release-notes/#new-features_6","text":"More support for salsah-gui elements and attributes in ontologies Serve the salsah-gui ontology in API v2 in the default schema. Show salsah-gui:guiElement and salsah-gui:guiAttribute when serving ontologies in API v2 in the default schema. Allow salsah-gui:guiElement and salsah-gui:guiAttribute to be included in new property definitions created via API v2. Change salsah-gui so that GraphDB's consistency checker can check the use of guiElement and guiAttribute . Changes to application.conf . The sipi and web-api sections have received a big update, adding separate settings for internal and external host settings: app { knora-api { // relevant for direct communication inside the knora stack internal-host = \"0.0.0.0\" internal-port = 3333 // relevant for the client, i.e. browser external-protocol = \"http\" // optional ssl termination needs to be done by the proxy external-host = \"0.0.0.0\" external-port = 3333 } sipi { // relevant for direct communication inside the knora stack internal-protocol = \"http\" internal-host = \"localhost\" internal-port = 1024 // relevant for the client, i.e. browser external-protocol = \"http\" external-host = \"localhost\" external-port = 1024 prefix = \"knora\" file-server-path = \"server\" path-conversion-route = \"convert_from_binaries\" file-conversion-route = \"convert_from_file\" image-mime-types = [\"image/tiff\", \"image/jpeg\", \"image/png\", \"image/jp2\"] movie-mime-types = [] sound-mime-types = [] } salsah1 { base-url = \"http://localhost:3335/\" project-icons-basepath = \"project-icons/\" } }","title":"New features"},{"location":"DSP-API/00-release-notes/#bugfixes_6","text":"When API v2 served knora-api (default schema), salsah-gui:guiElement and salsah-gui:guiAttribute were not shown in properties in that ontology. The predicate salsah-gui:guiOrder was not accepted when creating a property via API v2.","title":"Bugfixes"},{"location":"DSP-API/01-introduction/","text":"Introduction What Is DSP and DSP-API (previous Knora)? Data Formats in DSP-API Standoff/RDF Text Markup An Example Project","title":"Index"},{"location":"DSP-API/01-introduction/#introduction","text":"What Is DSP and DSP-API (previous Knora)? Data Formats in DSP-API Standoff/RDF Text Markup An Example Project","title":"Introduction"},{"location":"DSP-API/01-introduction/data-formats/","text":"Data Formats in DSP-API As explained in What Is DSP and DSP-API (previous Knora)? , the DSP stores data in a small number of formats that are suitable for long-term preservation while facilitating data reuse. The following is a non-exhaustive list of data formats and how their content can be stored and managed by DSP-API: Original Format Format in DSP Text (XML, LaTeX, Microsoft Word, etc.) Knora resources (RDF) containing Standoff/RDF Tabular data, including relational databases Knora resources Data in tree or graph structures Knora resources Images (JPEG, PNG, etc.) JPEG 2000 files stored by Sipi Audio and video files Audio and video files stored by Sipi (in archival formats to be determined) PDF Can be stored by Sipi, but data reuse is improved by extracting the text for storage as Standoff/RDF","title":"Data Formats in DSP-API"},{"location":"DSP-API/01-introduction/data-formats/#data-formats-in-dsp-api","text":"As explained in What Is DSP and DSP-API (previous Knora)? , the DSP stores data in a small number of formats that are suitable for long-term preservation while facilitating data reuse. The following is a non-exhaustive list of data formats and how their content can be stored and managed by DSP-API: Original Format Format in DSP Text (XML, LaTeX, Microsoft Word, etc.) Knora resources (RDF) containing Standoff/RDF Tabular data, including relational databases Knora resources Data in tree or graph structures Knora resources Images (JPEG, PNG, etc.) JPEG 2000 files stored by Sipi Audio and video files Audio and video files stored by Sipi (in archival formats to be determined) PDF Can be stored by Sipi, but data reuse is improved by extracting the text for storage as Standoff/RDF","title":"Data Formats in DSP-API"},{"location":"DSP-API/01-introduction/example-project/","text":"An Example Project This section introduces some of the basic concepts involved in creating ontologies for DSP projects, by means of a relatively simple example project. Before reading this document, it will be helpful to have some familiarity with the basic concepts explained in knora-base. DSP-API comes with two example projects, called incunabula and images-demo . Here we will consider the incunabula example, which is a reduced version of a real research project on early printed books. It is designed to store an image of each page of each book, as well as RDF data about books, pages, their contents, and relationships between them. At the moment, only the RDF data is provided in the example project, not the images. The incunabula ontology is in the file incunabula-onto.ttl , and its data is in the file incunabula-demo-data.ttl . Both these files are in a standard RDF file format called Turtle . The DSP-API distribution includes sample scripts (in the webapi/scripts directory) for importing these files directly into different triplestores. If you are starting a new project from scratch, you can adapt these scripts to import your ontology (and any existing RDF data) into your triplestore for use with DSP-API. The syntax of Turtle is fairly simple: it is basically a sequence of triples. We will consider some details of Turtle syntax as we go along. The Incunabula Ontology Here we will just focus on some of the main aspects of the ontology. An ontology file typically begins by defining prefixes for the IRIs of other ontologies that will be referred to. First there are some prefixes for ontologies that are very commonly used in RDF: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix dcterms: <http://purl.org/dc/terms/> . The rdf , rdfs , and owl ontologies contain basic properties that are used to define ontology entities. The xsd ontology contains definitions of literal data types such as string and integer . (For more information about these ontologies, see the references in knora-base.) The foaf ontology contains classes and properties for representing people. The dcterms ontology represents Dublin Core metadata. Then we define prefixes for DSP ontologies: @prefix knora-base: <http://www.knora.org/ontology/knora-base#> . @prefix salsah-gui: <http://www.knora.org/ontology/salsah-gui#> . The knora-base ontology contains DSP-API's core abstractions, and is described in knora-base. The salsah-gui ontology includes properties that DSP projects must use to enable SALSAH, DSP-API's generic virtual research environment. For convenience, we can use the empty prefix to refer to the incunabula ontology itself: @prefix : <http://www.knora.org/ontology/0803/incunabula#> . However, outside the ontology file, it would make more sense to define an incunabula prefix to refer to the incunabula ontology. Properties All the content produced by a DSP project must be stored in Knora resources (see incunabula-resource-classes ). Resources have properties that point to different parts of their contents; for example, the incunabula project contains books, which have properties like title . Every property that poitns to a DSP value must be a subproperty of knora-base:hasValue , and every property that points to another Knora resource must be a subproperty of knora-base:hasLinkTo . Here is the definition of the incunabula:title property: :title rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:hasValue, dcterms:title ; rdfs:label \"Titel\"@de , \"Titre\"@fr , \"Titolo\"@it , \"Title\"@en ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue ; salsah-gui:guiElement salsah-gui:SimpleText ; salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" . The definition of incunabula:title consists of a list of triples, all of which have :title as their subject. To avoid repeating :title for each triple, Turtle syntax allows us to use a semicolon ( ; ) to separate triples that have the same subject. Moreover, some triples also have the same predicate; a comma ( , ) is used to avoid repeating the predicate. The definition of :title says: rdf:type owl:ObjectProperty : It is an owl:ObjectProperty . There are two kinds of OWL properties: object properties and datatype properties. Object properties point to objects, which have IRIs and can have their own properties. Datatype properties point to literal values, such as strings and integers. rdfs:subPropertyOf knora-base:hasValue, dcterms:title : It is a subproperty of knora-base:hasValue and dcterms:title . Since the objects of this property will be Knora values, it must be a subproperty of knora-base:hasValue . To facilitate searches, we have also chosen to make it a subproperty of dcterms:title . In the DSP-API v2, if you do a search for resources that have a certain dcterms:title , and there is a resource with a matching incunabula:title , the search results could include that resource. rdfs:label \"Titel\"@de , etc.: It has the specified labels in various languages. These are needed, for example, by user interfaces, to prompt the user to enter a value. knora-base:subjectClassConstraint :book : The subject of the property must be an incunabula:book . knora-base:objectClassConstraint knora-base:TextValue : The object of this property must be a knora-base:TextValue (which is a subclass of knora-base:Value ). salsah-gui:guiElement salsah-gui:SimpleText : When SALSAH asks a user to enter a value for this property, it should use a simple text field. salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" : The SALSAH text field for entering a value for this property should be 80 characters wide, and should accept at most 255 characters. The incunabula ontology contains several other property definitions that are basically similar. Note that different subclasses of Value are used. For example, incunabula:pubdate , which represents the publication date of a book, points to a knora-base:DateValue . The DateValue class stores a date range, with a specified degree of precision and a preferred calendar system for display. A property can point to a Knora resource instead of to a Knora value. For example, in the incunabula ontology, there are resources representing pages and books, and each page is part of some book. This relationship is expressed using the property incunabula:partOf : :partOf rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOf ; rdfs:label \"ist ein Teil von\"@de , \"est un part de\"@fr , \"e una parte di\"@it , \"is a part of\"@en ; rdfs:comment \"\"\"Diese Property bezeichnet eine Verbindung zu einer anderen Resource, in dem ausgesagt wird, dass die vorliegende Resource ein integraler Teil der anderen Resource ist. Zum Beispiel ist eine Buchseite ein integraler Bestandteil genau eines Buches.\"\"\"@de ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint :book ; salsah-gui:guiElement salsah-gui:Searchbox . The key things to notice here are: rdfs:subPropertyOf knora-base:isPartOf : The Knora base ontology provides a generic isPartOf property to express part-whole relationships. Like many properties defined in knora-base , a project cannot use knora-base:isPartOf directly, but must make a subproperty such as incunabula:partOf . It is important to note that knora-base:isPartOf is a subproperty of knora-base:hasLinkTo . Any property that points to a knora-base:Resource must be a subproperty of knora-base:hasLinkTo . In Knora terminology, such a property is called a link property . knora-base:objectClassConstraint :book : The object of this property must be a member of the class incunabula:book , which, as we will see below, is a subclass of knora-base:Resource . salsah-gui:guiElement salsah-gui:Searchbox : When SALSAH prompts a user to select the book that a page is part of, it should provide a search box enabling the user to find the desired book. Because incunabula:partOf is a link property, it must always accompanied by a link value property , which enables Knora to store metadata about each link that is created with the link property. This metadata includes the date and time when the link was created, its owner, the permissions it grants, and whether it has been deleted. Storing this metadata allows Knora to authorise users to see or modify the link, as well as to query a previous state of a repository in which a deleted link had not yet been deleted. (The ability to query previous states of a repository is planned for DSP-API version 2.) The name of a link property and its link value property must be related by the following naming convention: to determine the name of the link value property, add the word Value to the name of the link property. Hence, the incunabula ontology defines the property partOfValue : :partOfValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOfValue ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint knora-base:LinkValue . As a link value property, incunabula:partOfValue must point to a knora-base:LinkValue . The LinkValue class is an RDF reification of a triple (in this case, the triple that links a page to a book). For more details about this, see knora-base-linkvalue. Note that the property incunabula:hasAuthor points to a knora-base:TextValue , because the incunabula project represents authors simply by their names. A more complex project could represent each author as a resource, in which case incunabula:hasAuthor would need to be a subproperty of knora-base:hasLinkTo . Resource Classes The two main resource classes in the incunabula ontology are book and page . Here is incunabula:book : :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :title ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publisher ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publoc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"4\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :pubdate ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :location ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :url ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :physical_desc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"9\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :note ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :book_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"book.gif\" ; rdfs:label \"Buch\"@de , \"Livre\"@fr , \"Libro\"@it , \"Book\"@en ; rdfs:comment \"\"\"Diese Resource-Klasse beschreibt ein Buch\"\"\"@de . Like every Knora resource class, incunabula:book is a subclass of knora-base:Resource . It is also a subclass of a number of other classes of type owl:Restriction , which are defined in square brackets, using Turtle's syntax for anonymous blank nodes. Each owl:Restriction specifies a cardinality for a property that is allowed in resources of type incunabula:book . A cardinality is indeed a kind of restriction: it means that a resource of this type may have, or must have, a certain number of instances of the specified property. For example, incunabula:book has cardinalities saying that a book must have at least one title and at most one publication date. In the DSP-API version 1, the word 'occurrence' is used instead of 'cardinality'. The OWL cardinalities supported by Knora are described in OWL Cardinalities . Note that incunabula:book specifies a cardinality of owl:minCardinality 0 on the property incunabula:hasAuthor . At first glance, this might seem as if it serves no purpose, since it says that the property is optional and can have any number of instances. You may be wondering whether this cardinality could simply be omitted from the definition of incunabula:book . However, Knora requires every property of a resource to have some cardinality in the resource's class. This is because Knora uses the cardinalities to determine which properties are possible for instances of the class, and the DSP-API relies on this information. If there was no cardinality for incunabula:hasAuthor , Knora would not allow a book to have an author. Each owl:Restriction specifying a cardinality can include the predicate salsah-gui:guiOrder , which tells the SALSAH GUI the order the properties should be displayed in. Here is the definition of incunabula:page : :page rdf:type owl:Class ; rdfs:subClassOf knora-base:StillImageRepresentation , [ rdf:type owl:Restriction ; owl:onProperty :pagenum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOfValue ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOf ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :seqnum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :page_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :origname ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :transcription ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"page.gif\" ; rdfs:label \"Seite\"@de , \"Page\"@fr , \"Page\"@en ; rdfs:comment \"\"\"Eine Seite ist ein Teil eines Buchs\"\"\"@de , \"\"\"Une page est une partie d'un livre\"\"\"@fr , \"\"\"A page is a part of a book\"\"\"@en . The incunabula:page class is a subclass of knora-base:StillImageRepresentation , which is a subclass of knora-base:Representation , which is a subclass of knora-base:Resource . The class knora-base:Representation is used for resources that contain metadata about files stored by Knora. Each It has different subclasses that can hold different types of files, including still images, audio, and video files. A given Representation can store metadata about several different files, as long as they are of the same type and are semantically equivalent, e.g. are different versions of the same image with different colorspaces, so that coordinates in one file will work in the other files. In Knora, a subclass inherits the cardinalities defined in its superclasses. Let's look at the class hierarchy of incunabula:page , starting with knora-base:Representation : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can store one or more FileValues\"@en . This says that a Representation must have at least one instance of the property hasFileValue , which is defined like this: :hasFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasValue ; :subjectClassConstraint :Representation ; :objectClassConstraint :FileValue . The subject of hasFileValue must be a Representation , and its object must be a FileValue . There are different subclasses of FileValue for different kinds of files, but we'll skip the details here. This is the definition of knora-base:StillImageRepresentation : :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can contain two-dimensional still image files\"@en . It must have at least one instance of the property hasStillImageFileValue , which is defined as follows: :hasStillImageFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasFileValue ; :subjectClassConstraint :StillImageRepresentation ; :objectClassConstraint :StillImageFileValue . Because hasStillImageFileValue is a subproperty of hasFileValue , the cardinality on hasStillImageFileValue , defined in the subclass StillImageRepresentation , overrides the cardinality on hasFileValue , defined in the superclass Representation . In other words, the more general cardinality in the superclass is replaced by a more specific cardinality in the base class. Since incunabula:page is a subclass of StillImageRepresentation , it inherits the cardinality on hasStillImageFileValue . As a result, a page must have at least one image file attached to it. Here's another example of cardinality inheritance. The class knora-base:Resource has a cardinality for knora-base:seqnum . The idea is that resources of any type could be arranged in some sort of sequence. As we saw above, incunabula:page is a subclass of knora-base:Resource . But incunabula:page has its own cardinality for incunabula:seqnum , which is a subproperty of knora-base:seqnum . Once again, the subclass's cardinality on the subproperty replaces the superclass's cardinality on the superproperty: a page is allowed to have an incunabula:seqnum , but it is not allowed to have a knora-base:seqnum .","title":"An Example Project"},{"location":"DSP-API/01-introduction/example-project/#an-example-project","text":"This section introduces some of the basic concepts involved in creating ontologies for DSP projects, by means of a relatively simple example project. Before reading this document, it will be helpful to have some familiarity with the basic concepts explained in knora-base. DSP-API comes with two example projects, called incunabula and images-demo . Here we will consider the incunabula example, which is a reduced version of a real research project on early printed books. It is designed to store an image of each page of each book, as well as RDF data about books, pages, their contents, and relationships between them. At the moment, only the RDF data is provided in the example project, not the images. The incunabula ontology is in the file incunabula-onto.ttl , and its data is in the file incunabula-demo-data.ttl . Both these files are in a standard RDF file format called Turtle . The DSP-API distribution includes sample scripts (in the webapi/scripts directory) for importing these files directly into different triplestores. If you are starting a new project from scratch, you can adapt these scripts to import your ontology (and any existing RDF data) into your triplestore for use with DSP-API. The syntax of Turtle is fairly simple: it is basically a sequence of triples. We will consider some details of Turtle syntax as we go along.","title":"An Example Project"},{"location":"DSP-API/01-introduction/example-project/#the-incunabula-ontology","text":"Here we will just focus on some of the main aspects of the ontology. An ontology file typically begins by defining prefixes for the IRIs of other ontologies that will be referred to. First there are some prefixes for ontologies that are very commonly used in RDF: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix dcterms: <http://purl.org/dc/terms/> . The rdf , rdfs , and owl ontologies contain basic properties that are used to define ontology entities. The xsd ontology contains definitions of literal data types such as string and integer . (For more information about these ontologies, see the references in knora-base.) The foaf ontology contains classes and properties for representing people. The dcterms ontology represents Dublin Core metadata. Then we define prefixes for DSP ontologies: @prefix knora-base: <http://www.knora.org/ontology/knora-base#> . @prefix salsah-gui: <http://www.knora.org/ontology/salsah-gui#> . The knora-base ontology contains DSP-API's core abstractions, and is described in knora-base. The salsah-gui ontology includes properties that DSP projects must use to enable SALSAH, DSP-API's generic virtual research environment. For convenience, we can use the empty prefix to refer to the incunabula ontology itself: @prefix : <http://www.knora.org/ontology/0803/incunabula#> . However, outside the ontology file, it would make more sense to define an incunabula prefix to refer to the incunabula ontology.","title":"The Incunabula Ontology"},{"location":"DSP-API/01-introduction/example-project/#properties","text":"All the content produced by a DSP project must be stored in Knora resources (see incunabula-resource-classes ). Resources have properties that point to different parts of their contents; for example, the incunabula project contains books, which have properties like title . Every property that poitns to a DSP value must be a subproperty of knora-base:hasValue , and every property that points to another Knora resource must be a subproperty of knora-base:hasLinkTo . Here is the definition of the incunabula:title property: :title rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:hasValue, dcterms:title ; rdfs:label \"Titel\"@de , \"Titre\"@fr , \"Titolo\"@it , \"Title\"@en ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue ; salsah-gui:guiElement salsah-gui:SimpleText ; salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" . The definition of incunabula:title consists of a list of triples, all of which have :title as their subject. To avoid repeating :title for each triple, Turtle syntax allows us to use a semicolon ( ; ) to separate triples that have the same subject. Moreover, some triples also have the same predicate; a comma ( , ) is used to avoid repeating the predicate. The definition of :title says: rdf:type owl:ObjectProperty : It is an owl:ObjectProperty . There are two kinds of OWL properties: object properties and datatype properties. Object properties point to objects, which have IRIs and can have their own properties. Datatype properties point to literal values, such as strings and integers. rdfs:subPropertyOf knora-base:hasValue, dcterms:title : It is a subproperty of knora-base:hasValue and dcterms:title . Since the objects of this property will be Knora values, it must be a subproperty of knora-base:hasValue . To facilitate searches, we have also chosen to make it a subproperty of dcterms:title . In the DSP-API v2, if you do a search for resources that have a certain dcterms:title , and there is a resource with a matching incunabula:title , the search results could include that resource. rdfs:label \"Titel\"@de , etc.: It has the specified labels in various languages. These are needed, for example, by user interfaces, to prompt the user to enter a value. knora-base:subjectClassConstraint :book : The subject of the property must be an incunabula:book . knora-base:objectClassConstraint knora-base:TextValue : The object of this property must be a knora-base:TextValue (which is a subclass of knora-base:Value ). salsah-gui:guiElement salsah-gui:SimpleText : When SALSAH asks a user to enter a value for this property, it should use a simple text field. salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" : The SALSAH text field for entering a value for this property should be 80 characters wide, and should accept at most 255 characters. The incunabula ontology contains several other property definitions that are basically similar. Note that different subclasses of Value are used. For example, incunabula:pubdate , which represents the publication date of a book, points to a knora-base:DateValue . The DateValue class stores a date range, with a specified degree of precision and a preferred calendar system for display. A property can point to a Knora resource instead of to a Knora value. For example, in the incunabula ontology, there are resources representing pages and books, and each page is part of some book. This relationship is expressed using the property incunabula:partOf : :partOf rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOf ; rdfs:label \"ist ein Teil von\"@de , \"est un part de\"@fr , \"e una parte di\"@it , \"is a part of\"@en ; rdfs:comment \"\"\"Diese Property bezeichnet eine Verbindung zu einer anderen Resource, in dem ausgesagt wird, dass die vorliegende Resource ein integraler Teil der anderen Resource ist. Zum Beispiel ist eine Buchseite ein integraler Bestandteil genau eines Buches.\"\"\"@de ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint :book ; salsah-gui:guiElement salsah-gui:Searchbox . The key things to notice here are: rdfs:subPropertyOf knora-base:isPartOf : The Knora base ontology provides a generic isPartOf property to express part-whole relationships. Like many properties defined in knora-base , a project cannot use knora-base:isPartOf directly, but must make a subproperty such as incunabula:partOf . It is important to note that knora-base:isPartOf is a subproperty of knora-base:hasLinkTo . Any property that points to a knora-base:Resource must be a subproperty of knora-base:hasLinkTo . In Knora terminology, such a property is called a link property . knora-base:objectClassConstraint :book : The object of this property must be a member of the class incunabula:book , which, as we will see below, is a subclass of knora-base:Resource . salsah-gui:guiElement salsah-gui:Searchbox : When SALSAH prompts a user to select the book that a page is part of, it should provide a search box enabling the user to find the desired book. Because incunabula:partOf is a link property, it must always accompanied by a link value property , which enables Knora to store metadata about each link that is created with the link property. This metadata includes the date and time when the link was created, its owner, the permissions it grants, and whether it has been deleted. Storing this metadata allows Knora to authorise users to see or modify the link, as well as to query a previous state of a repository in which a deleted link had not yet been deleted. (The ability to query previous states of a repository is planned for DSP-API version 2.) The name of a link property and its link value property must be related by the following naming convention: to determine the name of the link value property, add the word Value to the name of the link property. Hence, the incunabula ontology defines the property partOfValue : :partOfValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOfValue ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint knora-base:LinkValue . As a link value property, incunabula:partOfValue must point to a knora-base:LinkValue . The LinkValue class is an RDF reification of a triple (in this case, the triple that links a page to a book). For more details about this, see knora-base-linkvalue. Note that the property incunabula:hasAuthor points to a knora-base:TextValue , because the incunabula project represents authors simply by their names. A more complex project could represent each author as a resource, in which case incunabula:hasAuthor would need to be a subproperty of knora-base:hasLinkTo .","title":"Properties"},{"location":"DSP-API/01-introduction/example-project/#resource-classes","text":"The two main resource classes in the incunabula ontology are book and page . Here is incunabula:book : :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :title ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publisher ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publoc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"4\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :pubdate ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :location ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :url ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :physical_desc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"9\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :note ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :book_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"book.gif\" ; rdfs:label \"Buch\"@de , \"Livre\"@fr , \"Libro\"@it , \"Book\"@en ; rdfs:comment \"\"\"Diese Resource-Klasse beschreibt ein Buch\"\"\"@de . Like every Knora resource class, incunabula:book is a subclass of knora-base:Resource . It is also a subclass of a number of other classes of type owl:Restriction , which are defined in square brackets, using Turtle's syntax for anonymous blank nodes. Each owl:Restriction specifies a cardinality for a property that is allowed in resources of type incunabula:book . A cardinality is indeed a kind of restriction: it means that a resource of this type may have, or must have, a certain number of instances of the specified property. For example, incunabula:book has cardinalities saying that a book must have at least one title and at most one publication date. In the DSP-API version 1, the word 'occurrence' is used instead of 'cardinality'. The OWL cardinalities supported by Knora are described in OWL Cardinalities . Note that incunabula:book specifies a cardinality of owl:minCardinality 0 on the property incunabula:hasAuthor . At first glance, this might seem as if it serves no purpose, since it says that the property is optional and can have any number of instances. You may be wondering whether this cardinality could simply be omitted from the definition of incunabula:book . However, Knora requires every property of a resource to have some cardinality in the resource's class. This is because Knora uses the cardinalities to determine which properties are possible for instances of the class, and the DSP-API relies on this information. If there was no cardinality for incunabula:hasAuthor , Knora would not allow a book to have an author. Each owl:Restriction specifying a cardinality can include the predicate salsah-gui:guiOrder , which tells the SALSAH GUI the order the properties should be displayed in. Here is the definition of incunabula:page : :page rdf:type owl:Class ; rdfs:subClassOf knora-base:StillImageRepresentation , [ rdf:type owl:Restriction ; owl:onProperty :pagenum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOfValue ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOf ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :seqnum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :page_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :origname ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :transcription ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"page.gif\" ; rdfs:label \"Seite\"@de , \"Page\"@fr , \"Page\"@en ; rdfs:comment \"\"\"Eine Seite ist ein Teil eines Buchs\"\"\"@de , \"\"\"Une page est une partie d'un livre\"\"\"@fr , \"\"\"A page is a part of a book\"\"\"@en . The incunabula:page class is a subclass of knora-base:StillImageRepresentation , which is a subclass of knora-base:Representation , which is a subclass of knora-base:Resource . The class knora-base:Representation is used for resources that contain metadata about files stored by Knora. Each It has different subclasses that can hold different types of files, including still images, audio, and video files. A given Representation can store metadata about several different files, as long as they are of the same type and are semantically equivalent, e.g. are different versions of the same image with different colorspaces, so that coordinates in one file will work in the other files. In Knora, a subclass inherits the cardinalities defined in its superclasses. Let's look at the class hierarchy of incunabula:page , starting with knora-base:Representation : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can store one or more FileValues\"@en . This says that a Representation must have at least one instance of the property hasFileValue , which is defined like this: :hasFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasValue ; :subjectClassConstraint :Representation ; :objectClassConstraint :FileValue . The subject of hasFileValue must be a Representation , and its object must be a FileValue . There are different subclasses of FileValue for different kinds of files, but we'll skip the details here. This is the definition of knora-base:StillImageRepresentation : :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can contain two-dimensional still image files\"@en . It must have at least one instance of the property hasStillImageFileValue , which is defined as follows: :hasStillImageFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasFileValue ; :subjectClassConstraint :StillImageRepresentation ; :objectClassConstraint :StillImageFileValue . Because hasStillImageFileValue is a subproperty of hasFileValue , the cardinality on hasStillImageFileValue , defined in the subclass StillImageRepresentation , overrides the cardinality on hasFileValue , defined in the superclass Representation . In other words, the more general cardinality in the superclass is replaced by a more specific cardinality in the base class. Since incunabula:page is a subclass of StillImageRepresentation , it inherits the cardinality on hasStillImageFileValue . As a result, a page must have at least one image file attached to it. Here's another example of cardinality inheritance. The class knora-base:Resource has a cardinality for knora-base:seqnum . The idea is that resources of any type could be arranged in some sort of sequence. As we saw above, incunabula:page is a subclass of knora-base:Resource . But incunabula:page has its own cardinality for incunabula:seqnum , which is a subproperty of knora-base:seqnum . Once again, the subclass's cardinality on the subproperty replaces the superclass's cardinality on the superproperty: a page is allowed to have an incunabula:seqnum , but it is not allowed to have a knora-base:seqnum .","title":"Resource Classes"},{"location":"DSP-API/01-introduction/standoff-rdf/","text":"Standoff/RDF Text Markup Standoff markup is text markup that is stored separately from the content it describes. Knora's Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. This approach has some advantages over commonly used markup systems such as XML: First, XML and other hierarchical markup systems assume that a document is a hierarchy, and have difficulty representing non-hierarchical structures or multiple overlapping hierarchies. Standoff markup can easily represent these structures. Second, markup languages are typically designed to be used in text files. But there is no standard system for searching and linking together many different text files containing markup. It is possible to do this in a non-standard way by using an XML database such as eXist , but this still does not allow for queries that include text as well as non-textual data not stored in XML. By storing markup as RDF, Knora can search for markup structures in the same way that it searches for any RDF data structure. This makes it possible to do searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as Knora resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. You could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. In Knora's Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, and has semantic properties of its own. You can define your own tag classes in your ontology by making subclasses of knora-base:StandoffTag , and attach your own properties to them. You can then search for those properties using Knora's search language, Gravsearch . The built-in knora-base and standoff ontologies provide some basic tags that can be reused or extended. These include tags that represent Knora data types. For example, knora-base:StandoffDateTag represents a date in exactly the same way as a Knora date value , i.e. as a calendar-independent astronomical date. You can use this tag as-is, or extend it by making a subclass, to represent dates in texts. Gravsearch includes built-in functionality for searching for these data type tags. For example, you can search for text containing a date that falls within a certain date range . Knora's APIs support automatic conversion between XML and Standoff/RDF. To make this work, Standoff/RDF stores the order of tags and their hierarchical relationships. You must define an XML-to-Standoff Mapping for your standoff tag classes and properties. Then you can import an XML document into Knora, which will store it as Standoff/RDF. The text and markup can then be searched using Gravsearch. When you retrieve the document, Knora converts it back to the original XML. To represent overlapping or non-hierarchical markup in exported and imported XML, Knora supports CLIX tags. Future plans for Standoff/RDF include: Creation and retrieval of standoff markup as such via the DSP-API, without using XML as an input/output format. A user interface for editing standoff markup. The ability to create resources that cite particular standoff tags in other resources.","title":"Standoff/RDF Text Markup"},{"location":"DSP-API/01-introduction/standoff-rdf/#standoffrdf-text-markup","text":"Standoff markup is text markup that is stored separately from the content it describes. Knora's Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. This approach has some advantages over commonly used markup systems such as XML: First, XML and other hierarchical markup systems assume that a document is a hierarchy, and have difficulty representing non-hierarchical structures or multiple overlapping hierarchies. Standoff markup can easily represent these structures. Second, markup languages are typically designed to be used in text files. But there is no standard system for searching and linking together many different text files containing markup. It is possible to do this in a non-standard way by using an XML database such as eXist , but this still does not allow for queries that include text as well as non-textual data not stored in XML. By storing markup as RDF, Knora can search for markup structures in the same way that it searches for any RDF data structure. This makes it possible to do searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as Knora resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. You could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. In Knora's Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, and has semantic properties of its own. You can define your own tag classes in your ontology by making subclasses of knora-base:StandoffTag , and attach your own properties to them. You can then search for those properties using Knora's search language, Gravsearch . The built-in knora-base and standoff ontologies provide some basic tags that can be reused or extended. These include tags that represent Knora data types. For example, knora-base:StandoffDateTag represents a date in exactly the same way as a Knora date value , i.e. as a calendar-independent astronomical date. You can use this tag as-is, or extend it by making a subclass, to represent dates in texts. Gravsearch includes built-in functionality for searching for these data type tags. For example, you can search for text containing a date that falls within a certain date range . Knora's APIs support automatic conversion between XML and Standoff/RDF. To make this work, Standoff/RDF stores the order of tags and their hierarchical relationships. You must define an XML-to-Standoff Mapping for your standoff tag classes and properties. Then you can import an XML document into Knora, which will store it as Standoff/RDF. The text and markup can then be searched using Gravsearch. When you retrieve the document, Knora converts it back to the original XML. To represent overlapping or non-hierarchical markup in exported and imported XML, Knora supports CLIX tags. Future plans for Standoff/RDF include: Creation and retrieval of standoff markup as such via the DSP-API, without using XML as an input/output format. A user interface for editing standoff markup. The ability to create resources that cite particular standoff tags in other resources.","title":"Standoff/RDF Text Markup"},{"location":"DSP-API/01-introduction/what-is-knora/","text":"What Is DSP and DSP-API (previous Knora)? The DaSCH Service Platform (DSP) is a a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP aims to solve key problems in the long-term preservation and reuse of humanities data: First, traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. You have to first identify an information package that might be of interest, then download it, and only then can you find out what's really in it. This is time-consuming, and makes it impractical to reuse data from many different sources. DSP solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different data formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old data files, or even all the operating systems that these programs ran on. Instead of preserving all these data formats, DSP supports the conversion of all sorts of data to a small number of formats that are suitable for long-term preservation, and that maintain the data's meaning and structure: Non-binary data is stored as RDF , in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by Sipi , with metadata stored in the triplestore. DSP then makes this data available for reuse via its generic, standards-based application programming interfaces (APIs = DSP-API). A virtual research environment (VRE) can then use these APIs to search, link together, and add to data from different research projects in a unified way. Humanities-Focused Data Storage Each project creates its own data model (or ontology ), describing the types of items it wishes to store, using basic data types defined in Knora's base ontology . This gives projects the freedom to describe their data in a way that makes sense to them, while allowing DSP to support searching and linking across projects. DSP has built-in support for data structures that are commonly needed in humanities data, and that present unique challenges for any type of database storage. Calendar-Independent Dates In the humanities, a date could be based on any sort of calendar (e.g. Gregorian, Julian, Islamic, or Hebrew). The DSP stores dates using a calendar-independent, astronomical representation, and converts between calendars as needed. This makes it possible to search for a date in one calendar, and get search results in other calendars. Flexible, Searchable Text Markup Commonly used text markup systems, such as TEI/XML , have to represent a text as a hierarchy, and therefore have trouble supporting overlapping markup. DSP supports Standoff/RDF markup : the markup is stored as RDF data, separately from the text, allowing for overlapping markup. DSP's RDF-based standoff is designed to support the needs of complex digital critical editions. The DSP can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time. Powerful Searches DSP-API provides a search language, Gravsearch , that is designed to meet the needs of humanities researchers. Gravsearch supports DSP-API's humanites-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows searches to combine text-related criteria with any other criteria. For example, you could search for a text that contains a certain word and also mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. Access Control The RDF standards do not include any concept of permissions. DSP-API's permission system allows project administrators and users to determine who can see or modify each item of data. DSP-API filters search results according to each user's permissions. Data History RDF does not have a concept of data history. DSP-API maintains all previous versions of each item of data. Ordinary searches return only the latest version, but you can obtain and cite an item as it was at any point in the past. Data Consistency RDF triplestores do not implement a standardised way of ensuring the consistency of data in a repository. DSP-API ensures that all data is consistent, conforms the project-specific data models, and meets DSP-API's minimum requirements for interoperability and reusability of data. Linked Open Data DSP-API supports publishing data online as as Linked Open Data , using open standards to allow interoperability between different repositories on the web. Build Your Own Application DSP-API can be used with a general-purpose, browser-based VRE called DSP-APP or SALSAH . Using the DSP-API and DSP-JS and/or DSP-UI , a set of reusable user-interface components, you can also create your own VRE or project-specific web site.","title":"What is DSP?"},{"location":"DSP-API/01-introduction/what-is-knora/#what-is-dsp-and-dsp-api-previous-knora","text":"The DaSCH Service Platform (DSP) is a a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP aims to solve key problems in the long-term preservation and reuse of humanities data: First, traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. You have to first identify an information package that might be of interest, then download it, and only then can you find out what's really in it. This is time-consuming, and makes it impractical to reuse data from many different sources. DSP solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different data formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old data files, or even all the operating systems that these programs ran on. Instead of preserving all these data formats, DSP supports the conversion of all sorts of data to a small number of formats that are suitable for long-term preservation, and that maintain the data's meaning and structure: Non-binary data is stored as RDF , in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by Sipi , with metadata stored in the triplestore. DSP then makes this data available for reuse via its generic, standards-based application programming interfaces (APIs = DSP-API). A virtual research environment (VRE) can then use these APIs to search, link together, and add to data from different research projects in a unified way.","title":"What Is DSP and DSP-API (previous Knora)?"},{"location":"DSP-API/01-introduction/what-is-knora/#humanities-focused-data-storage","text":"Each project creates its own data model (or ontology ), describing the types of items it wishes to store, using basic data types defined in Knora's base ontology . This gives projects the freedom to describe their data in a way that makes sense to them, while allowing DSP to support searching and linking across projects. DSP has built-in support for data structures that are commonly needed in humanities data, and that present unique challenges for any type of database storage.","title":"Humanities-Focused Data Storage"},{"location":"DSP-API/01-introduction/what-is-knora/#calendar-independent-dates","text":"In the humanities, a date could be based on any sort of calendar (e.g. Gregorian, Julian, Islamic, or Hebrew). The DSP stores dates using a calendar-independent, astronomical representation, and converts between calendars as needed. This makes it possible to search for a date in one calendar, and get search results in other calendars.","title":"Calendar-Independent Dates"},{"location":"DSP-API/01-introduction/what-is-knora/#flexible-searchable-text-markup","text":"Commonly used text markup systems, such as TEI/XML , have to represent a text as a hierarchy, and therefore have trouble supporting overlapping markup. DSP supports Standoff/RDF markup : the markup is stored as RDF data, separately from the text, allowing for overlapping markup. DSP's RDF-based standoff is designed to support the needs of complex digital critical editions. The DSP can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time.","title":"Flexible, Searchable Text Markup"},{"location":"DSP-API/01-introduction/what-is-knora/#powerful-searches","text":"DSP-API provides a search language, Gravsearch , that is designed to meet the needs of humanities researchers. Gravsearch supports DSP-API's humanites-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows searches to combine text-related criteria with any other criteria. For example, you could search for a text that contains a certain word and also mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period.","title":"Powerful Searches"},{"location":"DSP-API/01-introduction/what-is-knora/#access-control","text":"The RDF standards do not include any concept of permissions. DSP-API's permission system allows project administrators and users to determine who can see or modify each item of data. DSP-API filters search results according to each user's permissions.","title":"Access Control"},{"location":"DSP-API/01-introduction/what-is-knora/#data-history","text":"RDF does not have a concept of data history. DSP-API maintains all previous versions of each item of data. Ordinary searches return only the latest version, but you can obtain and cite an item as it was at any point in the past.","title":"Data History"},{"location":"DSP-API/01-introduction/what-is-knora/#data-consistency","text":"RDF triplestores do not implement a standardised way of ensuring the consistency of data in a repository. DSP-API ensures that all data is consistent, conforms the project-specific data models, and meets DSP-API's minimum requirements for interoperability and reusability of data.","title":"Data Consistency"},{"location":"DSP-API/01-introduction/what-is-knora/#linked-open-data","text":"DSP-API supports publishing data online as as Linked Open Data , using open standards to allow interoperability between different repositories on the web.","title":"Linked Open Data"},{"location":"DSP-API/01-introduction/what-is-knora/#build-your-own-application","text":"DSP-API can be used with a general-purpose, browser-based VRE called DSP-APP or SALSAH . Using the DSP-API and DSP-JS and/or DSP-UI , a set of reusable user-interface components, you can also create your own VRE or project-specific web site.","title":"Build Your Own Application"},{"location":"DSP-API/02-knora-ontologies/","text":"Knora Ontologies Introduction The Knora Base Ontology The SALSAH GUI Ontology The DSP ontologies provide a generic framework for describing humanities research data, allowing data from different projects to be combined, augmented, and reused.","title":"Index"},{"location":"DSP-API/02-knora-ontologies/#knora-ontologies","text":"Introduction The Knora Base Ontology The SALSAH GUI Ontology The DSP ontologies provide a generic framework for describing humanities research data, allowing data from different projects to be combined, augmented, and reused.","title":"Knora Ontologies"},{"location":"DSP-API/02-knora-ontologies/introduction/","text":"Introduction Resource Description Framework (RDF) DSP-API uses a hierarchy of ontologies based on the Resource Description Framework ( RDF ), RDF Schema ( RDFS ), and the Web Ontology Language ( OWL ). Both RDFS and OWL are expressed in RDF. RDF expresses information as a set of statements (called triples ). A triple consists of a subject, a predicate, and an object: The object may be either a literal value (such as a name or number) or another subject. Thus it is possible to create complex graphs that connect many subjects, like this: In RDF, each subject and predicate has a unique, URL-like identifier called an Internationalized Resource Identifier ( IRI ). Within a given project, IRIs typically differ only in their last component (the \"local part\"), which is often the fragment following a # character. Such IRIs share a long \"prefix\". In Turtle and similar formats for writing RDF, a short prefix label can be defined to represent the long prefix. Then an IRI can be written as a prefix label and a local part, separated by a colon ( : ). For example, if the \"example\" project's long prefix is http://www.example.org/rdf# , and it contains subjects with IRIs like http://www.example.org/rdf#book , we can define the prefix label ex to represent the prefix label, and write prefixed names for IRIs: Built-in Ontologies and User-Created Ontologies To ensure the interoperability of data produced by different projects, each project must describe its data model by creating one or more ontologies that extend Knora's built-in ontologies. The main built-in ontology in Knora is knora-base . Shared Ontologies Knora does not normally allow a project to use classes or properties defined in an ontology that belongs to another project. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. Specifically, in a shared ontology, existing classes and properties cannot safely be changed, but new ones can be added. (It is not even safe to add an optional cardinality to an existing class, because this could cause subclasses to violate the rule that a class cannot have a cardinality on property P as well as a cardinality on a subproperty of P; see Restrictions on Classes .) A standardisation process for shared ontologies is planned (issue @github #523 ). For more details about shared ontologies, see Shared Ontology IRIs .","title":"Introduction"},{"location":"DSP-API/02-knora-ontologies/introduction/#introduction","text":"","title":"Introduction"},{"location":"DSP-API/02-knora-ontologies/introduction/#resource-description-framework-rdf","text":"DSP-API uses a hierarchy of ontologies based on the Resource Description Framework ( RDF ), RDF Schema ( RDFS ), and the Web Ontology Language ( OWL ). Both RDFS and OWL are expressed in RDF. RDF expresses information as a set of statements (called triples ). A triple consists of a subject, a predicate, and an object: The object may be either a literal value (such as a name or number) or another subject. Thus it is possible to create complex graphs that connect many subjects, like this: In RDF, each subject and predicate has a unique, URL-like identifier called an Internationalized Resource Identifier ( IRI ). Within a given project, IRIs typically differ only in their last component (the \"local part\"), which is often the fragment following a # character. Such IRIs share a long \"prefix\". In Turtle and similar formats for writing RDF, a short prefix label can be defined to represent the long prefix. Then an IRI can be written as a prefix label and a local part, separated by a colon ( : ). For example, if the \"example\" project's long prefix is http://www.example.org/rdf# , and it contains subjects with IRIs like http://www.example.org/rdf#book , we can define the prefix label ex to represent the prefix label, and write prefixed names for IRIs:","title":"Resource Description Framework (RDF)"},{"location":"DSP-API/02-knora-ontologies/introduction/#built-in-ontologies-and-user-created-ontologies","text":"To ensure the interoperability of data produced by different projects, each project must describe its data model by creating one or more ontologies that extend Knora's built-in ontologies. The main built-in ontology in Knora is knora-base .","title":"Built-in Ontologies and User-Created Ontologies"},{"location":"DSP-API/02-knora-ontologies/introduction/#shared-ontologies","text":"Knora does not normally allow a project to use classes or properties defined in an ontology that belongs to another project. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. Specifically, in a shared ontology, existing classes and properties cannot safely be changed, but new ones can be added. (It is not even safe to add an optional cardinality to an existing class, because this could cause subclasses to violate the rule that a class cannot have a cardinality on property P as well as a cardinality on a subproperty of P; see Restrictions on Classes .) A standardisation process for shared ontologies is planned (issue @github #523 ). For more details about shared ontologies, see Shared Ontology IRIs .","title":"Shared Ontologies"},{"location":"DSP-API/02-knora-ontologies/knora-base/","text":"The Knora Base Ontology Overview The Knora base ontology is the main built-in Knora ontology. Each project that uses DSP-API must describe its data model by creating ontologies that extend this ontology. The Knora base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In the DSP-API documentation in general, it is identified by the prefix knora-base , but for brevity, in this document, we use kb or omit the prefix entirely. The Knora Data Model The Knora data model is based on the observation that, in the humanities, a value or literal is often itself structured and can be highly complex. Moreover, a value may have its own metadata, such as its creation date, information about permissions, and so on. Therefore, the Knora base ontology describes structured value types that can store this type of metadata. In the diagram below, a book ( ex:book2 ) has a title (identified by the predicate ex:title ) and a publication date ( ex:pubdate ), each of which has some metadata. Projects In Knora, each item of data belongs to some particular project. Each project using Knora must define a kb:knoraProject , which has these properties (cardinalities are indicated in parentheses after each property name): projectShortname (1): A short name that can be used to identify the project in configuration files and the like. projectLongname (1): The full name of the project. projectShortcode (1): A hexadecimal code that uniquely identifies the project. These codes are assigned to projects by the DaSCH . projectDescription (1-n): A description of the project. belongsToInstitution (0-1): The kb:Institution that the project belongs to. Ontologies and resources are associated with a project by means of the kb:attachedToProject property, as described in Ontologies and Properties of Resource ). Users are associated with a project by means of the kb:isInProject property, as described in Users and Groups . Ontologies Each user-created ontology must be defined as an owl:Ontology with the properties rdfs:label and kb:attachedToProject . Resources All the content produced by a project (e.g. digitised primary source materials or research data) must be stored in objects that belong to subclasses of kb:Resource , so that Knora can query and update that content. Each project using the Knora base ontology must define its own OWL classes, derived from kb:Resource , to represent the types of data it deals with. A subclass of kb:Resource may additionally be a subclass of any other class, e.g. an industry-standard class such as foaf:Person ; this can facilitate searches across projects. Resources have properties that point to different parts of the content they contain. For example, a resource representing a book could have a property called hasAuthor , pointing to the author of the book. There are two possible kinds of content in a Knora resource: Knora values (see Values ) or links to other resources (see Links Between Resources ). Properties that point to Knora values must be subproperties of kb:hasValue , and properties that point to other resources must be subproperties of kb:hasLinkTo . Either of these two types of properties may also be a subproperty of any other property, e.g. an industry-standard property such as foaf:name ; this can facilitate searches across projects. Each property definition must specify the types that its subjects and objects must belong to (see Constraints on the Types of Property Subjects and Objects for details). Each user-created resource class definition must use OWL cardinality restrictions to specify the properties that resources of that class can have (see OWL Cardinalities for details). Resources are not versioned; only their values are versioned (see Values ). Every resource is required to have an rdfs:label . The object of this property is an xsd:string , rather than a Knora value; hence it is not versioned. A user who has modify permission on a resource (see Authorisation ) can change its label. A resource can be marked as deleted; Knora does this by adding the predicate kb:isDeleted true to the resource. An optional kb:deleteComment may be added to explain why the resource has been marked as deleted. Deleted resources are normally hidden. They cannot be undeleted, because even though resources are not versioned, it is necessary to be able to find out when a resource was deleted. If desired, a new resource can be created by copying data from a deleted resource. Properties of Resource creationDate (1): The time when the resource was created. attachedToUser (1): The user who owns the resource. attachedToProject (1): The project that the resource is part of. lastModificationDate (0-1): A timestamp indicating when the resource (or one of its values) was last modified. seqnum (0-1): The sequence number of the resource, if it is part of an ordered group of resources, such as the pages in a book. isDeleted (1): Indicates whether the resource has been deleted. deleteDate (0-1): If the resource has been deleted, indicates when it was deleted. deleteComment (0-1): If the resource has been deleted, indicates why it was deleted. Resources can have properties that point to other resources; see Links Between Resources . A resource grants permissions to groups of users; see Authorisation . Representations It is not practical to store all data in RDF. In particular, RDF is not a good storage medium for binary data such as images. Therefore, Knora stores such data outside the triplestore, in ordinary files. A resource can have metadata about a file attached to it. The technical term for such a resource in Knora is a Representation . For each file, there is a kb:FileValue in the triplestore containing metadata about the file (see FileValue ). Knora uses Sipi to store files. The Knora APIs provide ways to create file values using Knora and Sipi. A resource that has a file value must belong to one of the subclasses of kb:Representation . Its subclasses include: StillImageRepresentation : A representation containing a still image file. MovingImageRepresentation : A representation containing a video file. AudioRepresentation : A representation containing an audio file. DDDrepresentation : A representation containing a 3D image file. TextRepresentation : A representation containing a formatted text file, such as an XML file. DocumentRepresentation : A representation containing a document (such as a PDF file) that is not a text file. ArchiveRepresentation : A representation containing an archive file (such as a zip archive). These classes can be used directly in data, but it is often better to make subclasses of them, to include metadata about the files being stored. The base class of all these classes is Representation , which is not intended to be used directly. It has this property, which its subclasses override: hasFileValue (1): Points to a file value. There are two ways for a project to design classes for representations. The simpler way is to create a resource class that represents a thing in the world (such as ex:Painting ) and also belongs to a subclass of Representation . This is adequate if the class can have only one type of file attached to it. For example, if paintings are represented only by still images, ex:Painting could be a subclass of StillImageRepresentation . This is the only approach supported in DSP-API v1 . The more flexible approach, which is supported by DSP-API v2 , is for each ex:Painting to link (using kb:hasRepresentation or a subproperty) to other resources containing files that represent the painting. Each of these other resources can extend a different subclass of Representation . For example, a painting could have a StillImageRepresentation as well as a DDDrepresentation . Standard Resource Classes In general, each project using Knora must define its own subclasses of kb:Resource . However, the Knora base ontology provides some standard subclasses of kb:Resource , which are intended to be used by any project: Region : Represents a region of a Representation (see Representations ). Annotation : Represents an annotation of a resource. The hasComment property points to the text of the annotation, represented as a kb:TextValue . LinkObj : Represents a link that connects two or more resources. A LinkObj has a hasLinkTo property pointing to each resource that it connects, as well as a hasLinkToValue property pointing to a reification of each of these direct links ( see Links Between Resources ). A LinkObj is more complex (and hence less convenient and readable) than a simple direct link, but it has the advantage that it can be annotated using an Annotation . For improved readability, a project can make its own subclasses of LinkObj with specific meanings. Values The Knora base ontology defines a set of OWL classes that are derived from kb:Value and represent different types of structured values found in humanities data. This set of classes may not be extended by user-created ontologies. A value is always part of one particular resource, which points to it using some property derived from hasValue . For example, a user-created ontology could specify a Book class with a property hasSummary (derived from hasValue ), and that property could have a knora-base:objectClassConstraint of TextValue . This would mean that the summary of each book is represented as a TextValue . Knora values are versioned. Existing values are not modified. Instead, a new version of an existing value is created. The new version is linked to the old version via the previousValue property. Since each value version has a different IRI, there is no IRI that can be used to cite the value, such that it will always refer to the latest version of the value. Therefore, the latest version of each value has a separate UUID, as the object of the property valueHasUUID . When a new version of the value is created, this UUID is moved to the new version. This makes it possible to cite the latest version of a value by searching for the UUID. \"Deleting\" a value means marking it with kb:isDeleted . An optional kb:deleteComment may be added to explain why the value has been marked as deleted. Deleted values are normally hidden. Most types of values are marked as deleted without creating a new version of the value. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. To simplify the enforcement of ontology constraints, and for consistency with resource updates, no new versions of a deleted value can be made; it is not possible to undelete. Instead, if desired, a new value can be created by copying data from a deleted value. Properties of Value valueCreationDate (1): The date and time when the value was created. attachedToUser (1): The user who owns the value. valueHasString (1): A human-readable string representation of the value's contents, which is available to Knora's full-text search index. valueHasOrder (0-1): A resource may have several properties of the same type with different values (which will be of the same class), and it may be necessary to indicate an order in which these values occur. For example, a book may have several authors which should appear in a defined order. Hence, valueHasOrder , when present, points to an integer literal indicating the order of a given value relative to the other values of the same property. These integers will not necessarily start at any particular number, and will not necessarily be consecutive. previousValue (0-1): The previous version of the value. valueHasUUID (0-1): The UUID that refers to all versions of the value. Only the latest version of the value has this property. isDeleted (1): Indicates whether the value has been deleted. deleteDate (0-1): If the value has been deleted, indicates when it was deleted. deleteComment (0-1): If the value has been deleted, indicates why it was deleted. Each Knora value can grant permissions (see Authorisation ). Subclasses of Value TextValue Represents text, possibly including markup. The text is the object of the valueHasString property. A line break is represented as a Unicode line feed character ( U+000A ). The non-printing Unicode character INFORMATION SEPARATOR TWO (U+001E) can be used to separate words that are separated only by standoff markup (see below), so they are recognised as separate in a full-text search index. Markup is stored using this property: valueHasStandoff (0-n): Points to a standoff markup tag. See Text with Standoff Markup . valueHasMapping (0-1): Points to the mapping used to create the standoff markup and to convert it back to the original XML. See Mapping to Create Standoff From XML . A text value can have a specified language: valueHasLanguage (0-1): An ISO 639-1 code as string specifying the language of the text. DateValue Humanities data includes many different types of dates. In Knora, a date has a specified calendar, and is always represented as a period with start and end points (which may be equal), each of which has a precision ( DAY , MONTH , or YEAR ). For GREGORIAN and JULIAN calendars, an optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Internally, the start and end points are stored as two Julian Day Numbers. This calendar-independent representation makes it possible to compare and search for dates regardless of the calendar in which they were entered. Properties: valueHasCalendar (1): The name of the calendar in which the date should be displayed. Currently GREGORIAN , JULIAN , and ISLAMIC civil calendars are supported. valueHasStartJDN (1): The Julian Day Number of the start of the period (an xsd:integer ). valueHasStartPrecision (1): The precision of the start of the period. valueHasEndJDN (1): The Julian Day Number of the end of the period (an xsd:integer ). valueHasEndPrecision (1): The precision of the end of the period. TimeValue A Knora time value represents a precise moment in time in the Gregorian calendar. Since nanosecond precision can be included, it is suitable for use as a timestamp. Properties: valueHasTimeStamp (1): An xsd:dateTimeStamp , stored as an xsd:dateTime (because SPARQL does not support xsd:dateTimeStamp ). IntValue Represents an integer. Property: valueHasInteger (1): An xsd:integer . ColorValue valueHasColor (1): A string representing a color. The string encodes a color as hexadecimal RGB values, e.g. \\#FF0000 . DecimalValue Represents an arbitrary-precision decimal number. Property: valueHasDecimal (1): An xsd:decimal . UriValue Represents a non-Knora URI. Property: valueHasUri (1): An xsd:anyURI . BooleanValue Represents a boolean value. Property: valueHasBoolean (1): An xsd:boolean . GeomValue Represents a geometrical object as a JSON string, using normalized coordinates. Property: valueHasGeometry (1): A JSON string. GeonameValue Represents a geolocation, using the identifiers found at GeoNames . Property: valueHasGeonameCode (1): The identifier of a geographical feature from GeoNames , represented as an xsd:string . IntervalValue Represents a time interval, with precise start and end times on a timeline, e.g. relative to the beginning of an audio or video file. Properties: valueHasIntervalStart (1): An xsd:decimal representing the start of the interval in seconds. valueHasIntervalEnd (1): An xsd:decimal representing the end of the interval in seconds. ListValue Projects often need to define lists or hierarchies of categories that can be assigned to many different resources. Then, for example, a user interface can provide a drop-down menu to allow the user to assign a category to a resource. The ListValue class provides a way to represent these sorts of data structures. It can represent either a flat list or a tree. A ListValue has this property: valueHasListNode (1): Points to a ListNode . Each ListNode can have the following properties: isRootNode (0-1): Set to true if this is the root node. hasSubListNode (0-n): Points to the node's child nodes, if any. hasRootNode (0-1): Points to the root node of the list (absent if isRootNode is true ). listNodePosition (0-1): An integer indicating the node's position in the list of its siblings (absent if isRootNode is true ). listNodeName (0-1): The node's human-readable name (absent if isRootNode is true ). FileValue Knora stores certain kinds of data outside the triplestore, in files (see Representations ). Each digital object that is stored outside the triplestore has associated metadata, which is stored in the triplestore in a kb:FileValue . The base class FileValue , which is not intended to be used directly, has these properties: internalFilename (1): The name of the file as stored by Knora. internalMimeType (1): The MIME type of the file as stored by Knora. originalFilename (0-1): The original name of the file when it was uploaded to the DSP-API server. originalMimeType (0-1): The original MIME type of the file when it was uploaded to the Knora API server. isPreview (0-1): A boolean indicating whether the file is a preview, i.e. a small image representing the contents of the file. A preview is always a StillImageFileValue , regardless of the type of the enclosing Representation . The subclasses of FileValue , which are intended to be used directly in data, include: StillImageFileValue : Contains metadata about a still image file. MovingImageFileValue : Contains metadata about a video file. AudioFileValue : Contains metadata about an audio file. DDDFileValue : Contains metadata about a 3D image file. TextFileValue : Contains metadata about a text file. DocumentFileValue : Contains metadata about a document (such as PDF) that is not a text file. ArchiveFileValue : Contains metadata about an archive (such as zio archive). Each of these classes contains properties that are specific to the type of file it describes. For example, still image files have dimensions, video files have frame rates, and so on. FileValue objects are versioned like other values, and the actual files stored by Knora are also versioned. Version 1 of the DSP-API does not provide a way to retrieve a previous version of a file, but this feature will be added in a subsequent version of the API. LinkValue A LinkValue is an RDF \"reification\" containing metadata about a link between two resources. It is therefore a subclass of rdf:Statement as well as of Value . It has these properties: rdf:subject (1) : The resource that is the source of the link. rdf:predicate (1) : The link property. rdf:object (1) : The resource that is the target of the link. valueHasRefCount (1) : The reference count of the link. This is meaningful when the LinkValue describes resource references in Standoff text markup (see StandoffLinkTag ). Otherwise, the reference count will always be 1 (if the link exists) or 0 (if it has been deleted). For details about how links are created in Knora, see Links Between Resources . ExternalResValue Represents a resource that is not stored in the RDF triplestore managed by Knora, but instead resides in an external repository managed by some other software. The ExternalResValue contains the information that Knora needs in order to access the resource, assuming that a suitable gateway plugin is installed. extResAccessInfo (1) : The location of the repository containing the external resource (e.g. its URL). extResId (1) : The repository-specific ID of the external resource. extResProvider (1) : The name of the external provider of the resource. Links Between Resources A link between two resources is expressed, first of all, as a triple, in which the subject is the resource that is the source of the link, the predicate is a \"link property\" (a subproperty of kb:hasLinkTo ), and the object is the resource that is the target of the link. It is also useful to store metadata about links. For example, Knora needs to know who owns the link, who has permission to modify it, when it was created, and so on. Such metadata cannot simply describe the link property, because then it would refer to that property in general, not to any particular instance in which that property is used to connect two particular resources. To attach metadata to a specific link in RDF, it is necessary to create an RDF \"reification\". A reification makes statements about a particular triple (subject, predicate, object), in this case the triple that expresses the link between the resources. Knora uses reifications of type kb:LinkValue (described in LinkValue to store metadata about links. For example, suppose a project describes paintings that belong to collections. The project can define an ontology as follows (expressed here in Turtle format, and simplified for the purposes of illustration): @prefix kb <http://www.knora.org/ontology/knora-base#> . @prefix : <http://www.knora.org/ontology/paintings#> . :Painting rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasArtist ; owl:cardinality 1 ] , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollection ; owl:minCardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollectionValue ; owl:minCardinality 1 ] . :Collection rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasCollectionName ; owl:cardinality 1 ] . :hasArtist rdf:type owl:ObjectProperty ; rdfs:label \"Name of artist\" ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasTitle rdf:type owl:ObjectProperty ; rdfs:label \"Title of painting\" kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasCollectionName rdf:type owl:ObjectProperty ; rdfs:label \"Name of collection\" ; kb:subjectClassConstraint :Collection ; kb:objectClassConstraint kb:TextValue . To link the paintings to the collection, we must add a \"link property\" to the ontology. In this case, the link property will point from a painting to the collection it belongs to. Every link property must be a subproperty of kb:hasLinkTo . :isInCollection rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkTo ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint :Collection . We must then add a \"link value property\", which will point from a painting to a kb:LinkValue (described in LinkValue ), which will contain metadata about the link between the property and the collection. In particular, the link value specifies the creator of the link, the date when it was created, and the permissions that determine who can view or modify it. The name of the link value property is constructed using a simple naming convention: the word Value is appended to the name of the link property. In this case, since our link property is called :isInCollection , the link value property must be called :isInCollectionValue . Every link value property must be a subproperty of kb:hasLinkToValue . :isInCollectionValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkToValue ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:LinkValue . Given this ontology, we can create some RDF data describing a painting and a collection: @prefix paintings <http://www.knora.org/ontology/paintings#> . @prefix data <http://www.knora.org/ontology/paintings/data#> . data:dali_4587 rdf:type paintings:Painting ; paintings:hasTitle data:value_A ; paintings:hasArtist data:value_B . data:value_A rdf:type kb:TextValue ; kb:valueHasString \"The Persistence of Memory\" . data:value_B rdf:type kb:TextValue ; kb:valueHasString \"Salvador Dali\" . data:pompidou rdf:type paintings:Collection ; paintings:hasCollectionName data:value_C . data:value_C rdf:type kb:TextValue ; kb:valueHasString \"Centre Pompidou, Paris\" . We can then state that the painting is in the collection: data:dali_4587 paintings:isInCollection data:pompidou ; paintings:isinCollectionValue data:value_D . data:value_D rdf:type kb:LinkValue ; rdf:subject data:dali_4587 ; rdf:predicate paintings:isInCollection ; rdf:object data:pompidou ; kb:valueHasRefCount 1 . This creates a link ( paintings:isInCollection ) between the painting and the collection, along with a reification containing metadata about the link. We can visualise the result as the following graph: Knora allows a user to see a link if the requesting user has permission to see the source and target resources as well as the kb:LinkValue . Part-of (part-whole) relation between resources A special case of linked resources are part-of related resources , i.e. a resource consisting of several other resources. In order to create a part-of relation between two resources, the resource that is part of another resource needs to have a property that is a subproperty of kb:isPartOf . This property needs to point to the resource class it is part of via its predicate knora-api:objectType . kb:isPartOf itself is a subproperty of kb:hasLinkTo . Same as described above for link properties, a corresponding part-of value property is created automatically. This value property has the same name as the part-of property with Value appended. For example, if in an ontology data a property data:partOf was defined, the corresponding value property would be named data:partOfValue . This newly created property data:partOfValue is defined as a subproperty of kb:isPartOfValue . Part-of relations are recommended for resources of type StillImageRepresentation . In that case, the resource that is part of another resource needs to have a property that is a subproperty of knora-api:seqnum with an integer as value. A client can then use this information to leaf through the parts of the compound resource (p.ex. to leaf through the pages of a book like in this example). Text with Standoff Markup Knora is designed to be able to store text with markup, which can indicate formatting and structure, as well as the complex observations involved in transcribing handwritten manuscripts. One popular way of representing text in the humanities is to encode it in XML using the Text Encoding Initiative ( TEI ) guidelines. In Knora, a TEI/XML document can be stored as a file with attached metadata, but this is not recommended, because it does not allow Knora to perform searches across multiple documents. The recommended way to store text with markup in Knora is to use Knora's built-in support for \"standoff\" markup, which is stored separately from the text. This has some advantages over embedded markup such as XML. While XML requires markup to have a hierarchical structure, and does not allow overlapping tags, standoff nodes do not have these limitations ( see Using Standoff Properties for Marking-up Historical Documents in the Humanities ) . A standoff tag can be attached to any substring in the text by giving its start and end positions. Unlike in corpus linguistics, we do not use any tokenisation resulting in a form of predefined segmentation, which would limit the user's ability to freely annotate any ranges in the text. For example, suppose we have the following text: This sentence has overlapping visual attributes. This would require just two standoff tags: (italic, start=5, end=29) and (bold, start=14, end=36) . Moreover, standoff makes it possible to mark up the same text in different, possibly incompatible ways, allowing for different interpretations without making redundant copies of the text. In the Knora base ontology, any text value can have standoff tags. By representing standoff as RDF triples, Knora makes markup searchable across multiple text documents in a repository. For example, if a repository contains documents in which references to persons are indicated in standoff, it is straightforward to find all the documents mentioning a particular person. Knora's standoff support is intended to make it possible to convert documents with embedded, hierarchical markup, such as TEI/XML, into RDF standoff and back again, with no data loss, thus bringing the benefits of RDF to existing TEI-encoded documents. In the Knora base ontology, a TextValue can have one or more standoff tags. Each standoff tag indicates the start and end positions of a substring in the text that has a particular attribute. The OWL class kb:StandoffTag , which is the base class of all standoff node classes, has these properties: standoffTagHasStart (1) : The index of the first character in the text that has the attribute. standoffTagHasEnd (1) : The index of the last character in the text that has the attribute, plus 1. standoffTagHasUUID (1) : A UUID identifying this instance and those corresponding to it in later versions of the TextValue it belongs to. The UUID is a means to maintain a reference to a particular range of a text also when new versions are made and standoff tag IRIs change. standoffTagHasOriginalXMLID (0-1) : The original id of the XML element that the standoff tag represents, if any. standoffTagHasStartIndex (1) : The start index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same start position, they can be nested correctly with this information when transforming them to XML. standoffTagHasEndIndex (1) : The end index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same end position, they can be nested correctly with this information when transforming them to XML. standoffTagHasStartParent (0-1) : Points to the parent standoff tag. This corresponds to the original nesting of tags in XML. If a standoff tag has no parent, it represents the XML root element. If the original XML element is a CLIX tag, it represents the start of a virtual (non syntactical) hierarchy. standoffTagHasEndParent (0-1) : Points to the parent standoff tag if the original XML element is a CLIX tag and represents the end of a virtual (non syntactical) hierarchy. The StandoffTag class is not used directly in RDF data; instead, its subclasses are used. A few subclasses are currently provided in standoff-onto.ttl , and more will be added to support TEI semantics. Projects are able to define their own custom standoff tag classes (direct subclasses of StandoffTag or one of the standoff data type classes or subclasses of one of the standoff classes defined in standoff-onto.ttl ). Subclasses of StandoffTag Standoff Data Type Tags Associates data in some Knora value type with a substring in a text. Standoff data type tags are subclasses of ValueBase classes. StandoffLinkTag Indicates that a substring refers to another kb:Resource . See StandoffLinkTag . StandoffInternalReferenceTag Indicates that a substring refers to another standoff tag in the same text value. See Internal Links in a TextValue . StandoffUriTag Indicates that a substring is associated with a URI, which is stored in the same form that is used for kb:UriValue . See UriValue . StandoffDateTag Indicates that a substring represents a date, which is stored in the same form that is used for kb:DateValue . See DateValue . StandoffColorTag Indicates that a substring represents a color, which is stored in the same form that is used for kb:ColorValue . See ColorValue . StandoffIntegerTag Indicates that a substring represents an integer, which is stored in the same form that is used for kb:IntegerValue . See IntValue . StandoffDecimalTag Indicates that a substring represents a number with fractions, which is stored in the same form that is used for kb:DecimalValue . See DecimalValue . StandoffIntervalTag Indicates that a substring represents an interval, which is stored in the same form that is used for kb:IntervalValue . See IntervalValue . StandoffBooleanTag Indicates that a substring represents a Boolean, which is stored in the same form that is used for kb:BooleanValue . See BooleanValue . StandoffTimeTag Indicates that a substring represents a timestamp, which is stored in the same form that is used for kb:TimeValue . See TimeValue . StandoffLinkTag A StandoffLinkTag Indicates that a substring is associated with a Knora resource. For example, if a repository contains resources representing persons, a text could be marked up so that each time a person's name is mentioned, a StandoffLinkTag connects the name to the Knora resource describing that person. Property: standoffTagHasLink (1) : The IRI of the resource that is referred to. One of the design goals of the Knora ontology is to make it easy and efficient to find out which resources contain references to a given resource. Direct links are easier and more efficient to query than indirect links. Therefore, when a text value contains a resource reference in its standoff nodes, Knora automatically creates a direct link between the containing resource and the target resource, along with an RDF reification (a kb:LinkValue ) describing the link, as discussed in Links Between Resources . In this case, the link property is always kb:hasStandoffLinkTo , and the link value property (which points to the LinkValue ) is always kb:hasStandoffLinkToValue . Knora automatically updates direct links and reifications for standoff resource references when text values are updated. To do this, it keeps track of the number of text values in each resource that contain at least one standoff reference to a given target resource. It stores this number as the reference count of the LinkValue (see LinkValue ) describing the direct link. Each time this number changes, it makes a new version of the LinkValue , with an updated reference count. When the reference count reaches zero, it removes the direct link and makes a new version of the LinkValue , marked with kb:isDeleted . For example, if data:R1 is a resource with a text value in which the resource data:R2 is referenced, the repository could contain the following triples: data:R1 ex:hasComment data:V1 . data:V1 rdf:type kb:TextValue ; kb:valueHasString \"This link is internal.\" ; kb:valueHasStandoff data:SO1 . data:SO1 rdf:type kb:StandoffLinkTag ; kb:standoffTagHasStart: 5 ; kb:standoffTagHasEnd: 9 ; kb:standoffTagHasLink data:R2 . data:R1 kb:hasStandoffLinkTo data:R2 . data:R1 kb:hasStandoffLinkToValue data:LV1 . data:LV1 rdf:type kb:LinkValue ; rdf:subject data:R1 ; rdf:predicate kb:hasStandoffLinkTo ; rdf:object data:R2 ; kb:valueHasRefCount 1 . The result can be visualized like this: Link values created automatically for resource references in standoff are visible to all users, and the creator of these link values is always kb:SystemUser (see Users and Groups ). The DSP-API server allows a user to see a standoff link if the user has permission to see the source and target resources. Internal Links in a TextValue Internal links in a TextValue can be represented using the data type standoff class StandoffInternalReferenceTag or a subclass of it. It has the following property: standoffTagHasInternalReference (1) : Points to a StandoffTag that belongs to the same TextValue . It has an objectClassConstraint of StandoffTag . For links to a kb:Resource , see StandoffLinkTag . Mapping to Create Standoff From XML A mapping allows for the conversion of an XML document to RDF-standoff and back. A mapping defines one-to-one relations between XML elements (with or without a class) and attributes and standoff classes and properties ( see XML to Standoff Mapping ). A mapping is represented by a kb:XMLToStandoffMapping which contains one or more kb:MappingElement . A kb:MappingElement maps an XML element (including attributes) to a standoff class and standoff properties. It has the following properties: mappingHasXMLTagname (1) : The name of the XML element that is mapped to a standoff class. mappingHasXMLNamespace (1) : The XML namespace of the XML element that is mapped to a standoff class. If no namespace is given, noNamespace is used. mappingHasXMLClass (1) : The name of the class of the XML element. If it has no class, noClass is used. mappingHasStandoffClass (1) : The standoff class the XML element is mapped to. mappingHasXMLAttribute (0-n) : Maps XML attributes to standoff properties using MappingXMLAttribute . See below. mappingHasStandoffDataTypeClass (0-1) : Indicates the standoff data type class of the standoff class the XML element is mapped to. mappingElementRequiresSeparator (1) : Indicates if there should be an invisible word separator inserted after the XML element in the RDF-standoff representation. Once the markup is stripped, text segments that belonged to different elements may be concatenated. A MappingXMLAttribute has the following properties: mappingHasXMLAttributename : The name of the XML attribute that is mapped to a standoff property. mappingHasXMLNamespace : The namespace of the XML attribute that is mapped to a standoff property. If no namespace is given, noNamespace is used. mappingHasStandoffProperty : The standoff property the XML attribute is mapped to. Knora includes a standard mapping used by the SALSAH GUI. It has the IRI http://rdfh.ch/standoff/mappings/StandardMapping and defines mappings for a few elements used to write texts with simple markup. Standoff in Digital Editions Knora's standoff is designed to make it possible to convert XML documents to standoff and back. One application for this feature is an editing workflow in which an editor works in an XML editor, and the resulting XML documents are converted to standoff and stored in Knora, where they can be searched and annotated. If an editor wants to correct text that has been imported from XML into standoff, the text can be exported as XML, edited, and imported again. To preserve annotations on standoff tags across edits, each tag can automatically be given a UUID. In a future version of the Knora base ontology, it will be possible to create annotations that point to UUIDs rather than to IRIs. When a text is exported to XML, the UUIDs can be included in the XML. When the edited XML is imported again, it can be converted to new standoff tags with the same UUIDs. Annotations that applied to standoff tags in the previous version of the text will therefore also apply to equivalent tags in the new version. When text is converted from XML into standoff, tags are also given indexes, which are numbered from 0 within the context of a particular text. This makes it possible to order tags that share the same position, and to preserve the hierarchy of the original XML document. An ordinary, hierarchical XML tag is converted to a standoff tag that has one index, as well as the index of its parent tag, if any. The Knora base ontology also supports non-hierarchical markup such as CLIX , which enables overlapping markup to be represented in XML. When non-hierarchical markup is converted to standoff, both the start position and the end position of the standoff tag have indexes and parent indexes. To support these features, a standoff tag can have these additional properties: standoffTagHasStartIndex (0-1) : The index of the start position. standoffTagHasEndIndex (0-1) : The index of the end position, if this is a non-hierarchical tag. standoffTagHasStartParent (0-1) : The IRI of the tag, if any, that contains the start position. standoffTagHasEndParent (0-1) : The IRI of the tag, if any, that contains the end position, if this is a non-hierarchical tag. standoffTagHasUUID (0-1) : A UUID that can be used to annotate a standoff tag that may be present in different versions of a text, or in different layers of a text (such as a diplomatic transcription and an edited critical text). Querying Standoff in SPARQL A future version of Knora will provide an API for querying standoff markup. In the meantime, it is possible to query it directly in SPARQL. For example, here is a SPARQL query (using RDFS inference) that finds all the text values texts that have a standoff date tag referring to Christmas Eve 2016, contained in a StandoffItalicTag : PREFIX knora-base: <http://www.knora.org/ontology/knora-base#> PREFIX standoff: <http://www.knora.org/ontology/standoff#> select * where { ?standoffTag a knora-base:StandoffDateTag . ?standoffTag knora-base:valueHasStartJDN ?dateStart . ?standoffTag knora-base:valueHasEndJDN ?dateEnd . FILTER (2457747 <= ?dateEnd && 2457747 >= ?dateStart) ?standoffTag knora-base:standoffTagHasStartParent ?parent . ?parent a standoff:StandoffItalicTag . ?textValue knora-base:valueHasStandoff ?standoffTag . ?textValue knora-base:valueHasString ?string . ?standoffTag knora-base:standoffTagHasStart ?startPos . ?standoffTag knora-base:standoffTagHasEnd ?endPos . } Authorisation Users and Groups Each Knora user is represented by an object belonging to the class kb:User , which is a subclass of foaf:Person , and has the following properties: userid (1) : A unique identifier that the user must provide when logging in. password (1) : A cryptographic hash of the user's password. email (0-n) : Email addresses belonging to the user. isInProject (0-n) : Projects that the user is a member of. isInGroup (0-n) : user-created groups that the user is a member of. foaf:familyName (1) : The user's family name. foaf:givenName (1) : The user's given name. Knora's concept of access control is that an object (a resource or value) can grant permissions to groups of users (but not to individual users). There are several built-in groups: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:ProjectMember : When checking a user's permissions on an object, the user is automatically assigned to this group if she is a member of the project that the object belongs to. knora-admin:Creator : When checking a user's permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectAdmin : When checking a user's permissions on an object, the user is automatically assigned to this group if she is an administrator of the project that the object belongs to. knora-admin:SystemAdmin : The group of Knora system administrators. A user-created ontology can define additional groups, which must belong to the OWL class knora-admin:UserGroup . There is one built-in knora-admin:SystemUser , which is the creator of link values created automatically for resource references in standoff markup (see StandoffLinkTag ). Permissions Each resource or value can grant certain permissions to specified user groups. These permissions are represented as the object of the predicate kb:hasPermissions , which is required on every kb:Resource and on the current version of every kb:Value . The permissions attached to the current version of a value also apply to previous versions of the value. Value versions other than the current one do not have this predicate. The following permissions can be granted: Restricted view permission (RV) Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) Allows an unrestricted view of the object. Having view permission on a resource only affects the user's ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) Allows the item to be marked as deleted. Change rights permission (CR) Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user's permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. To view a link between resources, a user needs permission to view the source and target resources. He also needs permission to view the LinkValue representing the link, unless the link property is hasStandoffLinkTo (see StandoffLinkTag ). The format of the object of kb:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar ( | ). For example, if an object grants view permission to unknown and known users, and modify permission to project members, the resulting permission literal would be: V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember Consistency Checking Knora tries to enforce repository consistency by checking constraints that are specified in the Knora base ontology and in user-created ontologies. Three types of consistency rules are enforced: Cardinalities in OWL class definitions must be satisfied. Constraints on the types of the subjects and objects of OWL object properties must be satisfied. A datatype property may not have an empty string as an object. The implementation of consistency checking is partly triplestore-dependent; Knora may be able to provide stricter checks with some triplestores than with others. OWL Cardinalities As noted in Resources , each subclass of Resource must use OWL cardinality restrictions to specify the properties it can have. More specifically, a resource is allowed to have a property that is a subproperty of kb:hasValue or kb:hasLinkTo only if the resource's class has some cardinality for that property. Similarly, a value is allowed to have a subproperty of kb:valueHas only if the value's class has some cardinality for that property. Knora supports, and attempts to enforce, the following cardinality constraints: owl:cardinality 1 : A resource of this class must have exactly one instance of the specified property. owl:minCardinality 1 : A resource of this class must have at least one instance of the specified property. owl:maxCardinality 1 : A resource of this class may have zero or one instance of the specified property. owl:minCardinality 0 : A resource of this class may have zero or more instances of the specified property. Knora requires cardinalities to be defined using blank nodes, as in the following example from knora-base : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . The cardinality of a link property must be the same as the cardinality of the corresponding link value property. Each owl:Restriction may have the predicate salsah-gui:guiOrder to indicate the order in which properties should be displayed in a GUI (see The SALSAH GUI Ontology ). A resource class inherits cardinalities from its superclasses. This follows from the rules of RDFS inference. Also, in Knora, cardinalities in the subclass can override cardinalities that would otherwise be inherited from the superclass. Specifically, if a superclass has a cardinality on a property P, and a subclass has a cardinality on a subproperty of P, the subclass's cardinality overrides the superclass's cardinality. In the example above, hasStillImageFileValue is a subproperty of hasFileValue . Therefore, the cardinality on hasStillImageFileValue overrides (i.e. replaces) the one on hasFileValue . Note that, unlike cardinalities, predicates of properties are not inherited. If :foo rdfs:subPropertyOf :bar , this does not mean that :foo inherits anything from :bar . Any predicates of :foo that are also needed by :bar must be defined explicitly on :bar . This design decision was made because property predicate inheritance is not provided by RDFS inference, and would make it more difficult to check the correctness of ontologies, while providing little practical benefit. For more information about OWL cardinalities, see the OWL 2 Primer . Constraints on the Types of Property Subjects and Objects When a user-created ontology defines a property, it must indicate the types that are allowed as objects (and, if possible, as subjects) of the property. This is done using the following Knora-specific properties: subjectClassConstraint : Specifies the class that subjects of the property must belong to. This constraint is recommended but not required. Knora will attempt to enforce this constraint. objectClassConstraint : If the property is an object property, specifies the class that objects of the property must belong to. Every subproperty of kb:hasValue or a kb:hasLinkTo (i.e. every property of a resource that points to a kb:Value or to another resource) is required to have this constraint, because Knora relies on it to know what type of object to expect for the property. Knora will attempt to enforce this constraint. objectDatatypeConstraint : If the property is a datatype property, specifies the type of literals that can be objects of the property. Knora will not attempt to enforce this constraint, but it is useful for documentation purposes. Note that it is possible for a subproperty to have a more restrictive contraint than its base property, by specifing a subject or object class that is a subclass of the one specified in the base property. However, it is not possible for the subproperty to make the base property's constraint less restrictive. See also Why doesn\u2019t Knora use rdfs:domain and rdfs:range for consistency checking? Consistency Constraint Example A user-created ontology could define consistency constraints as in this simplified example: :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ] . :hasTitle rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . :hasAuthor rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . Summary of Restrictions on User-Created Ontologies An ontology can refer to a Knora ontology in another project only if the other ontology is built-in or shared (see Shared Ontologies ). Restrictions on Classes Each class must be a subclass of either kb:Resource or kb:StandoffTag , but not both (note that this forbids user-created subclasses of kb:Value ). All the cardinalities that a class defines directly (i.e. does not inherit from kb:Resource ) must be on properties that are defined in the triplestore. Within the cardinalities of a class, there must be a link value property for each link property and vice versa. The cardinality of a link property must be the same as the cardinality of the corresponding link value property. A cardinality on a property with a boolean value must be owl:cardinality 1 or owl:maxCardinality 1 . Each class must be a subclass of all the classes that are subject class constraints of the properties in its cardinalities. If it's a resource class, all its directly defined cardinalities must be on Knora resource properties (subproperties of kb:hasValue or kb:hasLinkTo ), and all its base classes with Knora IRIs must also be resource classes. A cardinality on kb:resourceProperty or kb:hasValue is forbidden. It must also have an rdfs:label . If it's a standoff class, none of its cardinalities may be on Knora resource properties, and all its base classes with Knora IRIs must also be standoff classes. A class cannot have a cardinality on property P as well as a cardinality on a subproperty of P. Restrictions on properties The property's subject class constraint, if provided, must be a subclass of kb:Resource or kb:StandoffTag , and must be a subclass of the subject class constraints of all its base properties. Its object class constraint, if provided, must be a subclass of the object class constraints of all its base properties. If the property is a Knora resource property, it must have an object class constraint and an rdfs:label . It can't be a subproperty of both kb:hasValue and kb:hasLinkTo . It can't be a subproperty of kb:hasFileValue . Each of its base properties that has a Knora IRI must also be a Knora resource property. Standardisation The DaSCH intends to coordinate the standardisation of generally useful entities proposed in user-created ontologies. We envisage a process in which two or more projects would initiate the process by starting a public discussion on proposed entities to be shared. Once a consensus was reached, the DaSCH would publish these entities in a shared ontology ). Knora Ontology Versions The Knora base ontology has the property kb:ontologyVersion , whose object is a string that indicates the deployed version of all the Knora built-in ontologies. This allows the repository update program to determine which repository updates are needed when Knora is upgraded.","title":"The Knora Base Ontology"},{"location":"DSP-API/02-knora-ontologies/knora-base/#the-knora-base-ontology","text":"","title":"The Knora Base Ontology"},{"location":"DSP-API/02-knora-ontologies/knora-base/#overview","text":"The Knora base ontology is the main built-in Knora ontology. Each project that uses DSP-API must describe its data model by creating ontologies that extend this ontology. The Knora base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In the DSP-API documentation in general, it is identified by the prefix knora-base , but for brevity, in this document, we use kb or omit the prefix entirely.","title":"Overview"},{"location":"DSP-API/02-knora-ontologies/knora-base/#the-knora-data-model","text":"The Knora data model is based on the observation that, in the humanities, a value or literal is often itself structured and can be highly complex. Moreover, a value may have its own metadata, such as its creation date, information about permissions, and so on. Therefore, the Knora base ontology describes structured value types that can store this type of metadata. In the diagram below, a book ( ex:book2 ) has a title (identified by the predicate ex:title ) and a publication date ( ex:pubdate ), each of which has some metadata.","title":"The Knora Data Model"},{"location":"DSP-API/02-knora-ontologies/knora-base/#projects","text":"In Knora, each item of data belongs to some particular project. Each project using Knora must define a kb:knoraProject , which has these properties (cardinalities are indicated in parentheses after each property name): projectShortname (1): A short name that can be used to identify the project in configuration files and the like. projectLongname (1): The full name of the project. projectShortcode (1): A hexadecimal code that uniquely identifies the project. These codes are assigned to projects by the DaSCH . projectDescription (1-n): A description of the project. belongsToInstitution (0-1): The kb:Institution that the project belongs to. Ontologies and resources are associated with a project by means of the kb:attachedToProject property, as described in Ontologies and Properties of Resource ). Users are associated with a project by means of the kb:isInProject property, as described in Users and Groups .","title":"Projects"},{"location":"DSP-API/02-knora-ontologies/knora-base/#ontologies","text":"Each user-created ontology must be defined as an owl:Ontology with the properties rdfs:label and kb:attachedToProject .","title":"Ontologies"},{"location":"DSP-API/02-knora-ontologies/knora-base/#resources","text":"All the content produced by a project (e.g. digitised primary source materials or research data) must be stored in objects that belong to subclasses of kb:Resource , so that Knora can query and update that content. Each project using the Knora base ontology must define its own OWL classes, derived from kb:Resource , to represent the types of data it deals with. A subclass of kb:Resource may additionally be a subclass of any other class, e.g. an industry-standard class such as foaf:Person ; this can facilitate searches across projects. Resources have properties that point to different parts of the content they contain. For example, a resource representing a book could have a property called hasAuthor , pointing to the author of the book. There are two possible kinds of content in a Knora resource: Knora values (see Values ) or links to other resources (see Links Between Resources ). Properties that point to Knora values must be subproperties of kb:hasValue , and properties that point to other resources must be subproperties of kb:hasLinkTo . Either of these two types of properties may also be a subproperty of any other property, e.g. an industry-standard property such as foaf:name ; this can facilitate searches across projects. Each property definition must specify the types that its subjects and objects must belong to (see Constraints on the Types of Property Subjects and Objects for details). Each user-created resource class definition must use OWL cardinality restrictions to specify the properties that resources of that class can have (see OWL Cardinalities for details). Resources are not versioned; only their values are versioned (see Values ). Every resource is required to have an rdfs:label . The object of this property is an xsd:string , rather than a Knora value; hence it is not versioned. A user who has modify permission on a resource (see Authorisation ) can change its label. A resource can be marked as deleted; Knora does this by adding the predicate kb:isDeleted true to the resource. An optional kb:deleteComment may be added to explain why the resource has been marked as deleted. Deleted resources are normally hidden. They cannot be undeleted, because even though resources are not versioned, it is necessary to be able to find out when a resource was deleted. If desired, a new resource can be created by copying data from a deleted resource.","title":"Resources"},{"location":"DSP-API/02-knora-ontologies/knora-base/#properties-of-resource","text":"creationDate (1): The time when the resource was created. attachedToUser (1): The user who owns the resource. attachedToProject (1): The project that the resource is part of. lastModificationDate (0-1): A timestamp indicating when the resource (or one of its values) was last modified. seqnum (0-1): The sequence number of the resource, if it is part of an ordered group of resources, such as the pages in a book. isDeleted (1): Indicates whether the resource has been deleted. deleteDate (0-1): If the resource has been deleted, indicates when it was deleted. deleteComment (0-1): If the resource has been deleted, indicates why it was deleted. Resources can have properties that point to other resources; see Links Between Resources . A resource grants permissions to groups of users; see Authorisation .","title":"Properties of Resource"},{"location":"DSP-API/02-knora-ontologies/knora-base/#representations","text":"It is not practical to store all data in RDF. In particular, RDF is not a good storage medium for binary data such as images. Therefore, Knora stores such data outside the triplestore, in ordinary files. A resource can have metadata about a file attached to it. The technical term for such a resource in Knora is a Representation . For each file, there is a kb:FileValue in the triplestore containing metadata about the file (see FileValue ). Knora uses Sipi to store files. The Knora APIs provide ways to create file values using Knora and Sipi. A resource that has a file value must belong to one of the subclasses of kb:Representation . Its subclasses include: StillImageRepresentation : A representation containing a still image file. MovingImageRepresentation : A representation containing a video file. AudioRepresentation : A representation containing an audio file. DDDrepresentation : A representation containing a 3D image file. TextRepresentation : A representation containing a formatted text file, such as an XML file. DocumentRepresentation : A representation containing a document (such as a PDF file) that is not a text file. ArchiveRepresentation : A representation containing an archive file (such as a zip archive). These classes can be used directly in data, but it is often better to make subclasses of them, to include metadata about the files being stored. The base class of all these classes is Representation , which is not intended to be used directly. It has this property, which its subclasses override: hasFileValue (1): Points to a file value. There are two ways for a project to design classes for representations. The simpler way is to create a resource class that represents a thing in the world (such as ex:Painting ) and also belongs to a subclass of Representation . This is adequate if the class can have only one type of file attached to it. For example, if paintings are represented only by still images, ex:Painting could be a subclass of StillImageRepresentation . This is the only approach supported in DSP-API v1 . The more flexible approach, which is supported by DSP-API v2 , is for each ex:Painting to link (using kb:hasRepresentation or a subproperty) to other resources containing files that represent the painting. Each of these other resources can extend a different subclass of Representation . For example, a painting could have a StillImageRepresentation as well as a DDDrepresentation .","title":"Representations"},{"location":"DSP-API/02-knora-ontologies/knora-base/#standard-resource-classes","text":"In general, each project using Knora must define its own subclasses of kb:Resource . However, the Knora base ontology provides some standard subclasses of kb:Resource , which are intended to be used by any project: Region : Represents a region of a Representation (see Representations ). Annotation : Represents an annotation of a resource. The hasComment property points to the text of the annotation, represented as a kb:TextValue . LinkObj : Represents a link that connects two or more resources. A LinkObj has a hasLinkTo property pointing to each resource that it connects, as well as a hasLinkToValue property pointing to a reification of each of these direct links ( see Links Between Resources ). A LinkObj is more complex (and hence less convenient and readable) than a simple direct link, but it has the advantage that it can be annotated using an Annotation . For improved readability, a project can make its own subclasses of LinkObj with specific meanings.","title":"Standard Resource Classes"},{"location":"DSP-API/02-knora-ontologies/knora-base/#values","text":"The Knora base ontology defines a set of OWL classes that are derived from kb:Value and represent different types of structured values found in humanities data. This set of classes may not be extended by user-created ontologies. A value is always part of one particular resource, which points to it using some property derived from hasValue . For example, a user-created ontology could specify a Book class with a property hasSummary (derived from hasValue ), and that property could have a knora-base:objectClassConstraint of TextValue . This would mean that the summary of each book is represented as a TextValue . Knora values are versioned. Existing values are not modified. Instead, a new version of an existing value is created. The new version is linked to the old version via the previousValue property. Since each value version has a different IRI, there is no IRI that can be used to cite the value, such that it will always refer to the latest version of the value. Therefore, the latest version of each value has a separate UUID, as the object of the property valueHasUUID . When a new version of the value is created, this UUID is moved to the new version. This makes it possible to cite the latest version of a value by searching for the UUID. \"Deleting\" a value means marking it with kb:isDeleted . An optional kb:deleteComment may be added to explain why the value has been marked as deleted. Deleted values are normally hidden. Most types of values are marked as deleted without creating a new version of the value. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. To simplify the enforcement of ontology constraints, and for consistency with resource updates, no new versions of a deleted value can be made; it is not possible to undelete. Instead, if desired, a new value can be created by copying data from a deleted value.","title":"Values"},{"location":"DSP-API/02-knora-ontologies/knora-base/#properties-of-value","text":"valueCreationDate (1): The date and time when the value was created. attachedToUser (1): The user who owns the value. valueHasString (1): A human-readable string representation of the value's contents, which is available to Knora's full-text search index. valueHasOrder (0-1): A resource may have several properties of the same type with different values (which will be of the same class), and it may be necessary to indicate an order in which these values occur. For example, a book may have several authors which should appear in a defined order. Hence, valueHasOrder , when present, points to an integer literal indicating the order of a given value relative to the other values of the same property. These integers will not necessarily start at any particular number, and will not necessarily be consecutive. previousValue (0-1): The previous version of the value. valueHasUUID (0-1): The UUID that refers to all versions of the value. Only the latest version of the value has this property. isDeleted (1): Indicates whether the value has been deleted. deleteDate (0-1): If the value has been deleted, indicates when it was deleted. deleteComment (0-1): If the value has been deleted, indicates why it was deleted. Each Knora value can grant permissions (see Authorisation ).","title":"Properties of Value"},{"location":"DSP-API/02-knora-ontologies/knora-base/#subclasses-of-value","text":"","title":"Subclasses of Value"},{"location":"DSP-API/02-knora-ontologies/knora-base/#textvalue","text":"Represents text, possibly including markup. The text is the object of the valueHasString property. A line break is represented as a Unicode line feed character ( U+000A ). The non-printing Unicode character INFORMATION SEPARATOR TWO (U+001E) can be used to separate words that are separated only by standoff markup (see below), so they are recognised as separate in a full-text search index. Markup is stored using this property: valueHasStandoff (0-n): Points to a standoff markup tag. See Text with Standoff Markup . valueHasMapping (0-1): Points to the mapping used to create the standoff markup and to convert it back to the original XML. See Mapping to Create Standoff From XML . A text value can have a specified language: valueHasLanguage (0-1): An ISO 639-1 code as string specifying the language of the text.","title":"TextValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#datevalue","text":"Humanities data includes many different types of dates. In Knora, a date has a specified calendar, and is always represented as a period with start and end points (which may be equal), each of which has a precision ( DAY , MONTH , or YEAR ). For GREGORIAN and JULIAN calendars, an optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Internally, the start and end points are stored as two Julian Day Numbers. This calendar-independent representation makes it possible to compare and search for dates regardless of the calendar in which they were entered. Properties: valueHasCalendar (1): The name of the calendar in which the date should be displayed. Currently GREGORIAN , JULIAN , and ISLAMIC civil calendars are supported. valueHasStartJDN (1): The Julian Day Number of the start of the period (an xsd:integer ). valueHasStartPrecision (1): The precision of the start of the period. valueHasEndJDN (1): The Julian Day Number of the end of the period (an xsd:integer ). valueHasEndPrecision (1): The precision of the end of the period.","title":"DateValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#timevalue","text":"A Knora time value represents a precise moment in time in the Gregorian calendar. Since nanosecond precision can be included, it is suitable for use as a timestamp. Properties: valueHasTimeStamp (1): An xsd:dateTimeStamp , stored as an xsd:dateTime (because SPARQL does not support xsd:dateTimeStamp ).","title":"TimeValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#intvalue","text":"Represents an integer. Property: valueHasInteger (1): An xsd:integer .","title":"IntValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#colorvalue","text":"valueHasColor (1): A string representing a color. The string encodes a color as hexadecimal RGB values, e.g. \\#FF0000 .","title":"ColorValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#decimalvalue","text":"Represents an arbitrary-precision decimal number. Property: valueHasDecimal (1): An xsd:decimal .","title":"DecimalValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#urivalue","text":"Represents a non-Knora URI. Property: valueHasUri (1): An xsd:anyURI .","title":"UriValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#booleanvalue","text":"Represents a boolean value. Property: valueHasBoolean (1): An xsd:boolean .","title":"BooleanValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#geomvalue","text":"Represents a geometrical object as a JSON string, using normalized coordinates. Property: valueHasGeometry (1): A JSON string.","title":"GeomValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#geonamevalue","text":"Represents a geolocation, using the identifiers found at GeoNames . Property: valueHasGeonameCode (1): The identifier of a geographical feature from GeoNames , represented as an xsd:string .","title":"GeonameValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#intervalvalue","text":"Represents a time interval, with precise start and end times on a timeline, e.g. relative to the beginning of an audio or video file. Properties: valueHasIntervalStart (1): An xsd:decimal representing the start of the interval in seconds. valueHasIntervalEnd (1): An xsd:decimal representing the end of the interval in seconds.","title":"IntervalValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#listvalue","text":"Projects often need to define lists or hierarchies of categories that can be assigned to many different resources. Then, for example, a user interface can provide a drop-down menu to allow the user to assign a category to a resource. The ListValue class provides a way to represent these sorts of data structures. It can represent either a flat list or a tree. A ListValue has this property: valueHasListNode (1): Points to a ListNode . Each ListNode can have the following properties: isRootNode (0-1): Set to true if this is the root node. hasSubListNode (0-n): Points to the node's child nodes, if any. hasRootNode (0-1): Points to the root node of the list (absent if isRootNode is true ). listNodePosition (0-1): An integer indicating the node's position in the list of its siblings (absent if isRootNode is true ). listNodeName (0-1): The node's human-readable name (absent if isRootNode is true ).","title":"ListValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#filevalue","text":"Knora stores certain kinds of data outside the triplestore, in files (see Representations ). Each digital object that is stored outside the triplestore has associated metadata, which is stored in the triplestore in a kb:FileValue . The base class FileValue , which is not intended to be used directly, has these properties: internalFilename (1): The name of the file as stored by Knora. internalMimeType (1): The MIME type of the file as stored by Knora. originalFilename (0-1): The original name of the file when it was uploaded to the DSP-API server. originalMimeType (0-1): The original MIME type of the file when it was uploaded to the Knora API server. isPreview (0-1): A boolean indicating whether the file is a preview, i.e. a small image representing the contents of the file. A preview is always a StillImageFileValue , regardless of the type of the enclosing Representation . The subclasses of FileValue , which are intended to be used directly in data, include: StillImageFileValue : Contains metadata about a still image file. MovingImageFileValue : Contains metadata about a video file. AudioFileValue : Contains metadata about an audio file. DDDFileValue : Contains metadata about a 3D image file. TextFileValue : Contains metadata about a text file. DocumentFileValue : Contains metadata about a document (such as PDF) that is not a text file. ArchiveFileValue : Contains metadata about an archive (such as zio archive). Each of these classes contains properties that are specific to the type of file it describes. For example, still image files have dimensions, video files have frame rates, and so on. FileValue objects are versioned like other values, and the actual files stored by Knora are also versioned. Version 1 of the DSP-API does not provide a way to retrieve a previous version of a file, but this feature will be added in a subsequent version of the API.","title":"FileValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#linkvalue","text":"A LinkValue is an RDF \"reification\" containing metadata about a link between two resources. It is therefore a subclass of rdf:Statement as well as of Value . It has these properties: rdf:subject (1) : The resource that is the source of the link. rdf:predicate (1) : The link property. rdf:object (1) : The resource that is the target of the link. valueHasRefCount (1) : The reference count of the link. This is meaningful when the LinkValue describes resource references in Standoff text markup (see StandoffLinkTag ). Otherwise, the reference count will always be 1 (if the link exists) or 0 (if it has been deleted). For details about how links are created in Knora, see Links Between Resources .","title":"LinkValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#externalresvalue","text":"Represents a resource that is not stored in the RDF triplestore managed by Knora, but instead resides in an external repository managed by some other software. The ExternalResValue contains the information that Knora needs in order to access the resource, assuming that a suitable gateway plugin is installed. extResAccessInfo (1) : The location of the repository containing the external resource (e.g. its URL). extResId (1) : The repository-specific ID of the external resource. extResProvider (1) : The name of the external provider of the resource.","title":"ExternalResValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#links-between-resources","text":"A link between two resources is expressed, first of all, as a triple, in which the subject is the resource that is the source of the link, the predicate is a \"link property\" (a subproperty of kb:hasLinkTo ), and the object is the resource that is the target of the link. It is also useful to store metadata about links. For example, Knora needs to know who owns the link, who has permission to modify it, when it was created, and so on. Such metadata cannot simply describe the link property, because then it would refer to that property in general, not to any particular instance in which that property is used to connect two particular resources. To attach metadata to a specific link in RDF, it is necessary to create an RDF \"reification\". A reification makes statements about a particular triple (subject, predicate, object), in this case the triple that expresses the link between the resources. Knora uses reifications of type kb:LinkValue (described in LinkValue to store metadata about links. For example, suppose a project describes paintings that belong to collections. The project can define an ontology as follows (expressed here in Turtle format, and simplified for the purposes of illustration): @prefix kb <http://www.knora.org/ontology/knora-base#> . @prefix : <http://www.knora.org/ontology/paintings#> . :Painting rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasArtist ; owl:cardinality 1 ] , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollection ; owl:minCardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollectionValue ; owl:minCardinality 1 ] . :Collection rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasCollectionName ; owl:cardinality 1 ] . :hasArtist rdf:type owl:ObjectProperty ; rdfs:label \"Name of artist\" ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasTitle rdf:type owl:ObjectProperty ; rdfs:label \"Title of painting\" kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasCollectionName rdf:type owl:ObjectProperty ; rdfs:label \"Name of collection\" ; kb:subjectClassConstraint :Collection ; kb:objectClassConstraint kb:TextValue . To link the paintings to the collection, we must add a \"link property\" to the ontology. In this case, the link property will point from a painting to the collection it belongs to. Every link property must be a subproperty of kb:hasLinkTo . :isInCollection rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkTo ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint :Collection . We must then add a \"link value property\", which will point from a painting to a kb:LinkValue (described in LinkValue ), which will contain metadata about the link between the property and the collection. In particular, the link value specifies the creator of the link, the date when it was created, and the permissions that determine who can view or modify it. The name of the link value property is constructed using a simple naming convention: the word Value is appended to the name of the link property. In this case, since our link property is called :isInCollection , the link value property must be called :isInCollectionValue . Every link value property must be a subproperty of kb:hasLinkToValue . :isInCollectionValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkToValue ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:LinkValue . Given this ontology, we can create some RDF data describing a painting and a collection: @prefix paintings <http://www.knora.org/ontology/paintings#> . @prefix data <http://www.knora.org/ontology/paintings/data#> . data:dali_4587 rdf:type paintings:Painting ; paintings:hasTitle data:value_A ; paintings:hasArtist data:value_B . data:value_A rdf:type kb:TextValue ; kb:valueHasString \"The Persistence of Memory\" . data:value_B rdf:type kb:TextValue ; kb:valueHasString \"Salvador Dali\" . data:pompidou rdf:type paintings:Collection ; paintings:hasCollectionName data:value_C . data:value_C rdf:type kb:TextValue ; kb:valueHasString \"Centre Pompidou, Paris\" . We can then state that the painting is in the collection: data:dali_4587 paintings:isInCollection data:pompidou ; paintings:isinCollectionValue data:value_D . data:value_D rdf:type kb:LinkValue ; rdf:subject data:dali_4587 ; rdf:predicate paintings:isInCollection ; rdf:object data:pompidou ; kb:valueHasRefCount 1 . This creates a link ( paintings:isInCollection ) between the painting and the collection, along with a reification containing metadata about the link. We can visualise the result as the following graph: Knora allows a user to see a link if the requesting user has permission to see the source and target resources as well as the kb:LinkValue .","title":"Links Between Resources"},{"location":"DSP-API/02-knora-ontologies/knora-base/#part-of-part-whole-relation-between-resources","text":"A special case of linked resources are part-of related resources , i.e. a resource consisting of several other resources. In order to create a part-of relation between two resources, the resource that is part of another resource needs to have a property that is a subproperty of kb:isPartOf . This property needs to point to the resource class it is part of via its predicate knora-api:objectType . kb:isPartOf itself is a subproperty of kb:hasLinkTo . Same as described above for link properties, a corresponding part-of value property is created automatically. This value property has the same name as the part-of property with Value appended. For example, if in an ontology data a property data:partOf was defined, the corresponding value property would be named data:partOfValue . This newly created property data:partOfValue is defined as a subproperty of kb:isPartOfValue . Part-of relations are recommended for resources of type StillImageRepresentation . In that case, the resource that is part of another resource needs to have a property that is a subproperty of knora-api:seqnum with an integer as value. A client can then use this information to leaf through the parts of the compound resource (p.ex. to leaf through the pages of a book like in this example).","title":"Part-of (part-whole) relation between resources"},{"location":"DSP-API/02-knora-ontologies/knora-base/#text-with-standoff-markup","text":"Knora is designed to be able to store text with markup, which can indicate formatting and structure, as well as the complex observations involved in transcribing handwritten manuscripts. One popular way of representing text in the humanities is to encode it in XML using the Text Encoding Initiative ( TEI ) guidelines. In Knora, a TEI/XML document can be stored as a file with attached metadata, but this is not recommended, because it does not allow Knora to perform searches across multiple documents. The recommended way to store text with markup in Knora is to use Knora's built-in support for \"standoff\" markup, which is stored separately from the text. This has some advantages over embedded markup such as XML. While XML requires markup to have a hierarchical structure, and does not allow overlapping tags, standoff nodes do not have these limitations ( see Using Standoff Properties for Marking-up Historical Documents in the Humanities ) . A standoff tag can be attached to any substring in the text by giving its start and end positions. Unlike in corpus linguistics, we do not use any tokenisation resulting in a form of predefined segmentation, which would limit the user's ability to freely annotate any ranges in the text. For example, suppose we have the following text: This sentence has overlapping visual attributes. This would require just two standoff tags: (italic, start=5, end=29) and (bold, start=14, end=36) . Moreover, standoff makes it possible to mark up the same text in different, possibly incompatible ways, allowing for different interpretations without making redundant copies of the text. In the Knora base ontology, any text value can have standoff tags. By representing standoff as RDF triples, Knora makes markup searchable across multiple text documents in a repository. For example, if a repository contains documents in which references to persons are indicated in standoff, it is straightforward to find all the documents mentioning a particular person. Knora's standoff support is intended to make it possible to convert documents with embedded, hierarchical markup, such as TEI/XML, into RDF standoff and back again, with no data loss, thus bringing the benefits of RDF to existing TEI-encoded documents. In the Knora base ontology, a TextValue can have one or more standoff tags. Each standoff tag indicates the start and end positions of a substring in the text that has a particular attribute. The OWL class kb:StandoffTag , which is the base class of all standoff node classes, has these properties: standoffTagHasStart (1) : The index of the first character in the text that has the attribute. standoffTagHasEnd (1) : The index of the last character in the text that has the attribute, plus 1. standoffTagHasUUID (1) : A UUID identifying this instance and those corresponding to it in later versions of the TextValue it belongs to. The UUID is a means to maintain a reference to a particular range of a text also when new versions are made and standoff tag IRIs change. standoffTagHasOriginalXMLID (0-1) : The original id of the XML element that the standoff tag represents, if any. standoffTagHasStartIndex (1) : The start index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same start position, they can be nested correctly with this information when transforming them to XML. standoffTagHasEndIndex (1) : The end index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same end position, they can be nested correctly with this information when transforming them to XML. standoffTagHasStartParent (0-1) : Points to the parent standoff tag. This corresponds to the original nesting of tags in XML. If a standoff tag has no parent, it represents the XML root element. If the original XML element is a CLIX tag, it represents the start of a virtual (non syntactical) hierarchy. standoffTagHasEndParent (0-1) : Points to the parent standoff tag if the original XML element is a CLIX tag and represents the end of a virtual (non syntactical) hierarchy. The StandoffTag class is not used directly in RDF data; instead, its subclasses are used. A few subclasses are currently provided in standoff-onto.ttl , and more will be added to support TEI semantics. Projects are able to define their own custom standoff tag classes (direct subclasses of StandoffTag or one of the standoff data type classes or subclasses of one of the standoff classes defined in standoff-onto.ttl ).","title":"Text with Standoff Markup"},{"location":"DSP-API/02-knora-ontologies/knora-base/#subclasses-of-standofftag","text":"","title":"Subclasses of StandoffTag"},{"location":"DSP-API/02-knora-ontologies/knora-base/#standoff-data-type-tags","text":"Associates data in some Knora value type with a substring in a text. Standoff data type tags are subclasses of ValueBase classes. StandoffLinkTag Indicates that a substring refers to another kb:Resource . See StandoffLinkTag . StandoffInternalReferenceTag Indicates that a substring refers to another standoff tag in the same text value. See Internal Links in a TextValue . StandoffUriTag Indicates that a substring is associated with a URI, which is stored in the same form that is used for kb:UriValue . See UriValue . StandoffDateTag Indicates that a substring represents a date, which is stored in the same form that is used for kb:DateValue . See DateValue . StandoffColorTag Indicates that a substring represents a color, which is stored in the same form that is used for kb:ColorValue . See ColorValue . StandoffIntegerTag Indicates that a substring represents an integer, which is stored in the same form that is used for kb:IntegerValue . See IntValue . StandoffDecimalTag Indicates that a substring represents a number with fractions, which is stored in the same form that is used for kb:DecimalValue . See DecimalValue . StandoffIntervalTag Indicates that a substring represents an interval, which is stored in the same form that is used for kb:IntervalValue . See IntervalValue . StandoffBooleanTag Indicates that a substring represents a Boolean, which is stored in the same form that is used for kb:BooleanValue . See BooleanValue . StandoffTimeTag Indicates that a substring represents a timestamp, which is stored in the same form that is used for kb:TimeValue . See TimeValue .","title":"Standoff Data Type Tags"},{"location":"DSP-API/02-knora-ontologies/knora-base/#standofflinktag","text":"A StandoffLinkTag Indicates that a substring is associated with a Knora resource. For example, if a repository contains resources representing persons, a text could be marked up so that each time a person's name is mentioned, a StandoffLinkTag connects the name to the Knora resource describing that person. Property: standoffTagHasLink (1) : The IRI of the resource that is referred to. One of the design goals of the Knora ontology is to make it easy and efficient to find out which resources contain references to a given resource. Direct links are easier and more efficient to query than indirect links. Therefore, when a text value contains a resource reference in its standoff nodes, Knora automatically creates a direct link between the containing resource and the target resource, along with an RDF reification (a kb:LinkValue ) describing the link, as discussed in Links Between Resources . In this case, the link property is always kb:hasStandoffLinkTo , and the link value property (which points to the LinkValue ) is always kb:hasStandoffLinkToValue . Knora automatically updates direct links and reifications for standoff resource references when text values are updated. To do this, it keeps track of the number of text values in each resource that contain at least one standoff reference to a given target resource. It stores this number as the reference count of the LinkValue (see LinkValue ) describing the direct link. Each time this number changes, it makes a new version of the LinkValue , with an updated reference count. When the reference count reaches zero, it removes the direct link and makes a new version of the LinkValue , marked with kb:isDeleted . For example, if data:R1 is a resource with a text value in which the resource data:R2 is referenced, the repository could contain the following triples: data:R1 ex:hasComment data:V1 . data:V1 rdf:type kb:TextValue ; kb:valueHasString \"This link is internal.\" ; kb:valueHasStandoff data:SO1 . data:SO1 rdf:type kb:StandoffLinkTag ; kb:standoffTagHasStart: 5 ; kb:standoffTagHasEnd: 9 ; kb:standoffTagHasLink data:R2 . data:R1 kb:hasStandoffLinkTo data:R2 . data:R1 kb:hasStandoffLinkToValue data:LV1 . data:LV1 rdf:type kb:LinkValue ; rdf:subject data:R1 ; rdf:predicate kb:hasStandoffLinkTo ; rdf:object data:R2 ; kb:valueHasRefCount 1 . The result can be visualized like this: Link values created automatically for resource references in standoff are visible to all users, and the creator of these link values is always kb:SystemUser (see Users and Groups ). The DSP-API server allows a user to see a standoff link if the user has permission to see the source and target resources.","title":"StandoffLinkTag"},{"location":"DSP-API/02-knora-ontologies/knora-base/#internal-links-in-a-textvalue","text":"Internal links in a TextValue can be represented using the data type standoff class StandoffInternalReferenceTag or a subclass of it. It has the following property: standoffTagHasInternalReference (1) : Points to a StandoffTag that belongs to the same TextValue . It has an objectClassConstraint of StandoffTag . For links to a kb:Resource , see StandoffLinkTag .","title":"Internal Links in a TextValue"},{"location":"DSP-API/02-knora-ontologies/knora-base/#mapping-to-create-standoff-from-xml","text":"A mapping allows for the conversion of an XML document to RDF-standoff and back. A mapping defines one-to-one relations between XML elements (with or without a class) and attributes and standoff classes and properties ( see XML to Standoff Mapping ). A mapping is represented by a kb:XMLToStandoffMapping which contains one or more kb:MappingElement . A kb:MappingElement maps an XML element (including attributes) to a standoff class and standoff properties. It has the following properties: mappingHasXMLTagname (1) : The name of the XML element that is mapped to a standoff class. mappingHasXMLNamespace (1) : The XML namespace of the XML element that is mapped to a standoff class. If no namespace is given, noNamespace is used. mappingHasXMLClass (1) : The name of the class of the XML element. If it has no class, noClass is used. mappingHasStandoffClass (1) : The standoff class the XML element is mapped to. mappingHasXMLAttribute (0-n) : Maps XML attributes to standoff properties using MappingXMLAttribute . See below. mappingHasStandoffDataTypeClass (0-1) : Indicates the standoff data type class of the standoff class the XML element is mapped to. mappingElementRequiresSeparator (1) : Indicates if there should be an invisible word separator inserted after the XML element in the RDF-standoff representation. Once the markup is stripped, text segments that belonged to different elements may be concatenated. A MappingXMLAttribute has the following properties: mappingHasXMLAttributename : The name of the XML attribute that is mapped to a standoff property. mappingHasXMLNamespace : The namespace of the XML attribute that is mapped to a standoff property. If no namespace is given, noNamespace is used. mappingHasStandoffProperty : The standoff property the XML attribute is mapped to. Knora includes a standard mapping used by the SALSAH GUI. It has the IRI http://rdfh.ch/standoff/mappings/StandardMapping and defines mappings for a few elements used to write texts with simple markup.","title":"Mapping to Create Standoff From XML"},{"location":"DSP-API/02-knora-ontologies/knora-base/#standoff-in-digital-editions","text":"Knora's standoff is designed to make it possible to convert XML documents to standoff and back. One application for this feature is an editing workflow in which an editor works in an XML editor, and the resulting XML documents are converted to standoff and stored in Knora, where they can be searched and annotated. If an editor wants to correct text that has been imported from XML into standoff, the text can be exported as XML, edited, and imported again. To preserve annotations on standoff tags across edits, each tag can automatically be given a UUID. In a future version of the Knora base ontology, it will be possible to create annotations that point to UUIDs rather than to IRIs. When a text is exported to XML, the UUIDs can be included in the XML. When the edited XML is imported again, it can be converted to new standoff tags with the same UUIDs. Annotations that applied to standoff tags in the previous version of the text will therefore also apply to equivalent tags in the new version. When text is converted from XML into standoff, tags are also given indexes, which are numbered from 0 within the context of a particular text. This makes it possible to order tags that share the same position, and to preserve the hierarchy of the original XML document. An ordinary, hierarchical XML tag is converted to a standoff tag that has one index, as well as the index of its parent tag, if any. The Knora base ontology also supports non-hierarchical markup such as CLIX , which enables overlapping markup to be represented in XML. When non-hierarchical markup is converted to standoff, both the start position and the end position of the standoff tag have indexes and parent indexes. To support these features, a standoff tag can have these additional properties: standoffTagHasStartIndex (0-1) : The index of the start position. standoffTagHasEndIndex (0-1) : The index of the end position, if this is a non-hierarchical tag. standoffTagHasStartParent (0-1) : The IRI of the tag, if any, that contains the start position. standoffTagHasEndParent (0-1) : The IRI of the tag, if any, that contains the end position, if this is a non-hierarchical tag. standoffTagHasUUID (0-1) : A UUID that can be used to annotate a standoff tag that may be present in different versions of a text, or in different layers of a text (such as a diplomatic transcription and an edited critical text).","title":"Standoff in Digital Editions"},{"location":"DSP-API/02-knora-ontologies/knora-base/#querying-standoff-in-sparql","text":"A future version of Knora will provide an API for querying standoff markup. In the meantime, it is possible to query it directly in SPARQL. For example, here is a SPARQL query (using RDFS inference) that finds all the text values texts that have a standoff date tag referring to Christmas Eve 2016, contained in a StandoffItalicTag : PREFIX knora-base: <http://www.knora.org/ontology/knora-base#> PREFIX standoff: <http://www.knora.org/ontology/standoff#> select * where { ?standoffTag a knora-base:StandoffDateTag . ?standoffTag knora-base:valueHasStartJDN ?dateStart . ?standoffTag knora-base:valueHasEndJDN ?dateEnd . FILTER (2457747 <= ?dateEnd && 2457747 >= ?dateStart) ?standoffTag knora-base:standoffTagHasStartParent ?parent . ?parent a standoff:StandoffItalicTag . ?textValue knora-base:valueHasStandoff ?standoffTag . ?textValue knora-base:valueHasString ?string . ?standoffTag knora-base:standoffTagHasStart ?startPos . ?standoffTag knora-base:standoffTagHasEnd ?endPos . }","title":"Querying Standoff in SPARQL"},{"location":"DSP-API/02-knora-ontologies/knora-base/#authorisation","text":"","title":"Authorisation"},{"location":"DSP-API/02-knora-ontologies/knora-base/#users-and-groups","text":"Each Knora user is represented by an object belonging to the class kb:User , which is a subclass of foaf:Person , and has the following properties: userid (1) : A unique identifier that the user must provide when logging in. password (1) : A cryptographic hash of the user's password. email (0-n) : Email addresses belonging to the user. isInProject (0-n) : Projects that the user is a member of. isInGroup (0-n) : user-created groups that the user is a member of. foaf:familyName (1) : The user's family name. foaf:givenName (1) : The user's given name. Knora's concept of access control is that an object (a resource or value) can grant permissions to groups of users (but not to individual users). There are several built-in groups: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:ProjectMember : When checking a user's permissions on an object, the user is automatically assigned to this group if she is a member of the project that the object belongs to. knora-admin:Creator : When checking a user's permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectAdmin : When checking a user's permissions on an object, the user is automatically assigned to this group if she is an administrator of the project that the object belongs to. knora-admin:SystemAdmin : The group of Knora system administrators. A user-created ontology can define additional groups, which must belong to the OWL class knora-admin:UserGroup . There is one built-in knora-admin:SystemUser , which is the creator of link values created automatically for resource references in standoff markup (see StandoffLinkTag ).","title":"Users and Groups"},{"location":"DSP-API/02-knora-ontologies/knora-base/#permissions","text":"Each resource or value can grant certain permissions to specified user groups. These permissions are represented as the object of the predicate kb:hasPermissions , which is required on every kb:Resource and on the current version of every kb:Value . The permissions attached to the current version of a value also apply to previous versions of the value. Value versions other than the current one do not have this predicate. The following permissions can be granted: Restricted view permission (RV) Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) Allows an unrestricted view of the object. Having view permission on a resource only affects the user's ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) Allows the item to be marked as deleted. Change rights permission (CR) Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user's permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. To view a link between resources, a user needs permission to view the source and target resources. He also needs permission to view the LinkValue representing the link, unless the link property is hasStandoffLinkTo (see StandoffLinkTag ). The format of the object of kb:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar ( | ). For example, if an object grants view permission to unknown and known users, and modify permission to project members, the resulting permission literal would be: V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember","title":"Permissions"},{"location":"DSP-API/02-knora-ontologies/knora-base/#consistency-checking","text":"Knora tries to enforce repository consistency by checking constraints that are specified in the Knora base ontology and in user-created ontologies. Three types of consistency rules are enforced: Cardinalities in OWL class definitions must be satisfied. Constraints on the types of the subjects and objects of OWL object properties must be satisfied. A datatype property may not have an empty string as an object. The implementation of consistency checking is partly triplestore-dependent; Knora may be able to provide stricter checks with some triplestores than with others.","title":"Consistency Checking"},{"location":"DSP-API/02-knora-ontologies/knora-base/#owl-cardinalities","text":"As noted in Resources , each subclass of Resource must use OWL cardinality restrictions to specify the properties it can have. More specifically, a resource is allowed to have a property that is a subproperty of kb:hasValue or kb:hasLinkTo only if the resource's class has some cardinality for that property. Similarly, a value is allowed to have a subproperty of kb:valueHas only if the value's class has some cardinality for that property. Knora supports, and attempts to enforce, the following cardinality constraints: owl:cardinality 1 : A resource of this class must have exactly one instance of the specified property. owl:minCardinality 1 : A resource of this class must have at least one instance of the specified property. owl:maxCardinality 1 : A resource of this class may have zero or one instance of the specified property. owl:minCardinality 0 : A resource of this class may have zero or more instances of the specified property. Knora requires cardinalities to be defined using blank nodes, as in the following example from knora-base : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . The cardinality of a link property must be the same as the cardinality of the corresponding link value property. Each owl:Restriction may have the predicate salsah-gui:guiOrder to indicate the order in which properties should be displayed in a GUI (see The SALSAH GUI Ontology ). A resource class inherits cardinalities from its superclasses. This follows from the rules of RDFS inference. Also, in Knora, cardinalities in the subclass can override cardinalities that would otherwise be inherited from the superclass. Specifically, if a superclass has a cardinality on a property P, and a subclass has a cardinality on a subproperty of P, the subclass's cardinality overrides the superclass's cardinality. In the example above, hasStillImageFileValue is a subproperty of hasFileValue . Therefore, the cardinality on hasStillImageFileValue overrides (i.e. replaces) the one on hasFileValue . Note that, unlike cardinalities, predicates of properties are not inherited. If :foo rdfs:subPropertyOf :bar , this does not mean that :foo inherits anything from :bar . Any predicates of :foo that are also needed by :bar must be defined explicitly on :bar . This design decision was made because property predicate inheritance is not provided by RDFS inference, and would make it more difficult to check the correctness of ontologies, while providing little practical benefit. For more information about OWL cardinalities, see the OWL 2 Primer .","title":"OWL Cardinalities"},{"location":"DSP-API/02-knora-ontologies/knora-base/#constraints-on-the-types-of-property-subjects-and-objects","text":"When a user-created ontology defines a property, it must indicate the types that are allowed as objects (and, if possible, as subjects) of the property. This is done using the following Knora-specific properties: subjectClassConstraint : Specifies the class that subjects of the property must belong to. This constraint is recommended but not required. Knora will attempt to enforce this constraint. objectClassConstraint : If the property is an object property, specifies the class that objects of the property must belong to. Every subproperty of kb:hasValue or a kb:hasLinkTo (i.e. every property of a resource that points to a kb:Value or to another resource) is required to have this constraint, because Knora relies on it to know what type of object to expect for the property. Knora will attempt to enforce this constraint. objectDatatypeConstraint : If the property is a datatype property, specifies the type of literals that can be objects of the property. Knora will not attempt to enforce this constraint, but it is useful for documentation purposes. Note that it is possible for a subproperty to have a more restrictive contraint than its base property, by specifing a subject or object class that is a subclass of the one specified in the base property. However, it is not possible for the subproperty to make the base property's constraint less restrictive. See also Why doesn\u2019t Knora use rdfs:domain and rdfs:range for consistency checking?","title":"Constraints on the Types of Property Subjects and Objects"},{"location":"DSP-API/02-knora-ontologies/knora-base/#consistency-constraint-example","text":"A user-created ontology could define consistency constraints as in this simplified example: :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ] . :hasTitle rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . :hasAuthor rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue .","title":"Consistency Constraint Example"},{"location":"DSP-API/02-knora-ontologies/knora-base/#summary-of-restrictions-on-user-created-ontologies","text":"An ontology can refer to a Knora ontology in another project only if the other ontology is built-in or shared (see Shared Ontologies ).","title":"Summary of Restrictions on User-Created Ontologies"},{"location":"DSP-API/02-knora-ontologies/knora-base/#restrictions-on-classes","text":"Each class must be a subclass of either kb:Resource or kb:StandoffTag , but not both (note that this forbids user-created subclasses of kb:Value ). All the cardinalities that a class defines directly (i.e. does not inherit from kb:Resource ) must be on properties that are defined in the triplestore. Within the cardinalities of a class, there must be a link value property for each link property and vice versa. The cardinality of a link property must be the same as the cardinality of the corresponding link value property. A cardinality on a property with a boolean value must be owl:cardinality 1 or owl:maxCardinality 1 . Each class must be a subclass of all the classes that are subject class constraints of the properties in its cardinalities. If it's a resource class, all its directly defined cardinalities must be on Knora resource properties (subproperties of kb:hasValue or kb:hasLinkTo ), and all its base classes with Knora IRIs must also be resource classes. A cardinality on kb:resourceProperty or kb:hasValue is forbidden. It must also have an rdfs:label . If it's a standoff class, none of its cardinalities may be on Knora resource properties, and all its base classes with Knora IRIs must also be standoff classes. A class cannot have a cardinality on property P as well as a cardinality on a subproperty of P.","title":"Restrictions on Classes"},{"location":"DSP-API/02-knora-ontologies/knora-base/#restrictions-on-properties","text":"The property's subject class constraint, if provided, must be a subclass of kb:Resource or kb:StandoffTag , and must be a subclass of the subject class constraints of all its base properties. Its object class constraint, if provided, must be a subclass of the object class constraints of all its base properties. If the property is a Knora resource property, it must have an object class constraint and an rdfs:label . It can't be a subproperty of both kb:hasValue and kb:hasLinkTo . It can't be a subproperty of kb:hasFileValue . Each of its base properties that has a Knora IRI must also be a Knora resource property.","title":"Restrictions on properties"},{"location":"DSP-API/02-knora-ontologies/knora-base/#standardisation","text":"The DaSCH intends to coordinate the standardisation of generally useful entities proposed in user-created ontologies. We envisage a process in which two or more projects would initiate the process by starting a public discussion on proposed entities to be shared. Once a consensus was reached, the DaSCH would publish these entities in a shared ontology ).","title":"Standardisation"},{"location":"DSP-API/02-knora-ontologies/knora-base/#knora-ontology-versions","text":"The Knora base ontology has the property kb:ontologyVersion , whose object is a string that indicates the deployed version of all the Knora built-in ontologies. This allows the repository update program to determine which repository updates are needed when Knora is upgraded.","title":"Knora Ontology Versions"},{"location":"DSP-API/02-knora-ontologies/salsah-gui/","text":"The SALSAH GUI Ontology Overview The SALSAH GUI ontology provides entities that can be used in user-created ontologies to indicate to SALSAH (or to another GUI) how data should be entered and displayed. The SALSAH GUI ontology is identified by the IRI http://www.knora.org/ontology/salsah-gui . In the Knora documentation in general, it is identified by the prefix salsah-gui , but for brevity, we omit the prefix in this document. Properties guiOrder : Can be attached to an owl:Restriction representing a cardinality in a resource class, to indicate the order in which properties should be displayed in the GUI. The object is a non-negative integer. For example, a property with guiOrder 0 would be displayed first, followed by a property with guiOrder 1, and so on. guiElement : Can be attached to a property definition to indicate which SALSAH GUI element should be used to enter data for the property. This should be one of the individuals of class Guielement described below. guiAttribute : Can be attached to a property definition to provide attributes for the GUI element specified in guiElement . The objects of this predicate are written in a DSL with the following syntax: object = attribute name, \"=\", attribute value ; attribute name = identifier ; identifier = letter , { letter } ; attribute value = integer | decimal | percent | string | iri ; percent = integer, \"%\" ; iri = \"<\", string, \">\" ; The attributes used with each GUI element are described below under Individuals . guiAttributeDefinition : Used only in the salsah-gui ontology itself, as a predicate attached to instances of Guielement (see Individuals ), to specify the attributes that can be given as objects of guiAttribute when a given Guielement . is used. The objects of this predicate are written in a DSL with the following syntax: object = attribute name, [ \"(required)\" ], \":\", attribute type, [ enumerated values ] ; enumerated values = \"(\", enumerated value, { \"|\", enumerated value } \")\" ; attribute name = identifier ; attribute type = \"integer\" | \"decimal\" | \"percent\" | \"string\" | \"iri\" ; enumerated value = identifier ; identifier = letter , { letter } ; Enumerated values are allowed only if `attribute type` is `string`. If enumerated values are provided for an attribute, the attribute value given via `guiAttribute` must be one of the enumerated values. Classes Guielement : The instances of this class are individuals representing SALSAH GUI elements for data entry. Individuals Colorpicker : A GUI element for selecting a color. A property definition that uses this element may also contain a guiAttribute predicate whose object is a string in the form \"ncolors=N\" , where N is an integer specifying the number of colors to display. Date : A GUI element for selecting a date. Geometry : A GUI element for selecting the geometry of a two-dimensional region. Geonames : A GUI element for selecting a Geonames identifier. Interval : A GUI element for selecting a time interval in an audio or video recording. List : A GUI element for selecting an item in a hierarchical list (see ListValue ). A property definition that uses this element must also contain this guiAttribute predicate: - `\"hlist=<LIST_IRI>\"`, where `LIST_IRI` is the IRI of a `knora-base:ListNode` that is the root node of a hierarchical list. Pulldown : A GUI element for selecting an item in a flat list (see ListValue ) using a pull-down menu. A property definition that uses this element must also contain this guiAttribute predicate: - `\"hlist=<LIST_IRI>\"`, where `LIST_IRI` is the IRI of a `knora-base:ListNode` that is the root node of a hierarchical list. Radio : A GUI element for selecting an item in a flat list (see ListValue ) using radio buttons. A property definition that uses this element must also contain this guiAttribute predicate: - `\"hlist=<LIST_IRI>\"`, where `LIST_IRI` is the IRI of a `knora-base:ListNode` that is the root node of a hierarchical list. Richtext : A GUI element for editing multi-line formatted text. Searchbox : A GUI element for searching for a resource by matching text in its rdfs:label . For DSP-API v1, a property definition that uses this element may also contain this guiAttribute predicate: - `\"numprops=N\"`, where `N` is an integer specifying the number of describing properties to be returned for each found resource. For DSP-API v2, the `guiAttribute` has no effect. SimpleText : A GUI element for editing a single line of unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: - `\"size=N\"`, where `N` is an integer specifying the size of the text field. - `\"maxlength=N\"`, where `N` is an integer specifying the maximum length of the string to be input. Slider : A GUI element for choosing numerical values using a slider. A property definition that uses this element must also contain a guiAttribute predicate with both of the following objects: - `\"min=N\"`, where `N` is an integer specifying the minimum value of the input. - `\"max=N\"`, where `N` is an integer specifying the maximum value of the input. Spinbox : A GUI element for choosing numerical values using a spinbox. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: - `\"min=N\"`, where `N` is an integer specifying the minimum value of the input. - `\"max=N\"`, where `N` is an integer specifying the maximum value of the input. Textarea : A GUI element for editing multi-line unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or more of the following objects: - `\"width=N\"`, where `N` is a percentage of the window width (an integer followed by `%`). - `\"cols=N\"`, where `N` is an integer representing the number of colums in the text entry box. - `\"rows=N\"`, where `N` is an integer specifying the height of the text entry box in rows. - `\"wrap=W\"`, where `W` is `soft` or `hard` (see [wrap](https://www.w3.org/TR/html5/sec-forms.html#element-attrdef-textarea-wrap)). Checkbox : A GUI element for choosing a boolean value using a checkbox. Fileupload : A GUI element for uploading a file.","title":"The SALSAH GUI Ontology"},{"location":"DSP-API/02-knora-ontologies/salsah-gui/#the-salsah-gui-ontology","text":"","title":"The SALSAH GUI Ontology"},{"location":"DSP-API/02-knora-ontologies/salsah-gui/#overview","text":"The SALSAH GUI ontology provides entities that can be used in user-created ontologies to indicate to SALSAH (or to another GUI) how data should be entered and displayed. The SALSAH GUI ontology is identified by the IRI http://www.knora.org/ontology/salsah-gui . In the Knora documentation in general, it is identified by the prefix salsah-gui , but for brevity, we omit the prefix in this document.","title":"Overview"},{"location":"DSP-API/02-knora-ontologies/salsah-gui/#properties","text":"guiOrder : Can be attached to an owl:Restriction representing a cardinality in a resource class, to indicate the order in which properties should be displayed in the GUI. The object is a non-negative integer. For example, a property with guiOrder 0 would be displayed first, followed by a property with guiOrder 1, and so on. guiElement : Can be attached to a property definition to indicate which SALSAH GUI element should be used to enter data for the property. This should be one of the individuals of class Guielement described below. guiAttribute : Can be attached to a property definition to provide attributes for the GUI element specified in guiElement . The objects of this predicate are written in a DSL with the following syntax: object = attribute name, \"=\", attribute value ; attribute name = identifier ; identifier = letter , { letter } ; attribute value = integer | decimal | percent | string | iri ; percent = integer, \"%\" ; iri = \"<\", string, \">\" ; The attributes used with each GUI element are described below under Individuals . guiAttributeDefinition : Used only in the salsah-gui ontology itself, as a predicate attached to instances of Guielement (see Individuals ), to specify the attributes that can be given as objects of guiAttribute when a given Guielement . is used. The objects of this predicate are written in a DSL with the following syntax: object = attribute name, [ \"(required)\" ], \":\", attribute type, [ enumerated values ] ; enumerated values = \"(\", enumerated value, { \"|\", enumerated value } \")\" ; attribute name = identifier ; attribute type = \"integer\" | \"decimal\" | \"percent\" | \"string\" | \"iri\" ; enumerated value = identifier ; identifier = letter , { letter } ; Enumerated values are allowed only if `attribute type` is `string`. If enumerated values are provided for an attribute, the attribute value given via `guiAttribute` must be one of the enumerated values.","title":"Properties"},{"location":"DSP-API/02-knora-ontologies/salsah-gui/#classes","text":"Guielement : The instances of this class are individuals representing SALSAH GUI elements for data entry.","title":"Classes"},{"location":"DSP-API/02-knora-ontologies/salsah-gui/#individuals","text":"Colorpicker : A GUI element for selecting a color. A property definition that uses this element may also contain a guiAttribute predicate whose object is a string in the form \"ncolors=N\" , where N is an integer specifying the number of colors to display. Date : A GUI element for selecting a date. Geometry : A GUI element for selecting the geometry of a two-dimensional region. Geonames : A GUI element for selecting a Geonames identifier. Interval : A GUI element for selecting a time interval in an audio or video recording. List : A GUI element for selecting an item in a hierarchical list (see ListValue ). A property definition that uses this element must also contain this guiAttribute predicate: - `\"hlist=<LIST_IRI>\"`, where `LIST_IRI` is the IRI of a `knora-base:ListNode` that is the root node of a hierarchical list. Pulldown : A GUI element for selecting an item in a flat list (see ListValue ) using a pull-down menu. A property definition that uses this element must also contain this guiAttribute predicate: - `\"hlist=<LIST_IRI>\"`, where `LIST_IRI` is the IRI of a `knora-base:ListNode` that is the root node of a hierarchical list. Radio : A GUI element for selecting an item in a flat list (see ListValue ) using radio buttons. A property definition that uses this element must also contain this guiAttribute predicate: - `\"hlist=<LIST_IRI>\"`, where `LIST_IRI` is the IRI of a `knora-base:ListNode` that is the root node of a hierarchical list. Richtext : A GUI element for editing multi-line formatted text. Searchbox : A GUI element for searching for a resource by matching text in its rdfs:label . For DSP-API v1, a property definition that uses this element may also contain this guiAttribute predicate: - `\"numprops=N\"`, where `N` is an integer specifying the number of describing properties to be returned for each found resource. For DSP-API v2, the `guiAttribute` has no effect. SimpleText : A GUI element for editing a single line of unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: - `\"size=N\"`, where `N` is an integer specifying the size of the text field. - `\"maxlength=N\"`, where `N` is an integer specifying the maximum length of the string to be input. Slider : A GUI element for choosing numerical values using a slider. A property definition that uses this element must also contain a guiAttribute predicate with both of the following objects: - `\"min=N\"`, where `N` is an integer specifying the minimum value of the input. - `\"max=N\"`, where `N` is an integer specifying the maximum value of the input. Spinbox : A GUI element for choosing numerical values using a spinbox. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: - `\"min=N\"`, where `N` is an integer specifying the minimum value of the input. - `\"max=N\"`, where `N` is an integer specifying the maximum value of the input. Textarea : A GUI element for editing multi-line unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or more of the following objects: - `\"width=N\"`, where `N` is a percentage of the window width (an integer followed by `%`). - `\"cols=N\"`, where `N` is an integer representing the number of colums in the text entry box. - `\"rows=N\"`, where `N` is an integer specifying the height of the text entry box in rows. - `\"wrap=W\"`, where `W` is `soft` or `hard` (see [wrap](https://www.w3.org/TR/html5/sec-forms.html#element-attrdef-textarea-wrap)). Checkbox : A GUI element for choosing a boolean value using a checkbox. Fileupload : A GUI element for uploading a file.","title":"Individuals"},{"location":"DSP-API/03-apis/","text":"The DSP APIs The DSP APIs include: The DSP API versions 1 and 2 , which is intended to be used by virtual research environments and other clients for querying and updating data. The DSP Admin API , which is intended to be used only by the DSP-APP user interface, for administering projects that use Knora as well as Knora itself. The DSP Util API , which is intended to be used for information retrieval about the DSP-stack itself. DSP API v2 and the admin API support Feature Toggles .","title":"Index"},{"location":"DSP-API/03-apis/#the-dsp-apis","text":"The DSP APIs include: The DSP API versions 1 and 2 , which is intended to be used by virtual research environments and other clients for querying and updating data. The DSP Admin API , which is intended to be used only by the DSP-APP user interface, for administering projects that use Knora as well as Knora itself. The DSP Util API , which is intended to be used for information retrieval about the DSP-stack itself. DSP API v2 and the admin API support Feature Toggles .","title":"The DSP APIs"},{"location":"DSP-API/03-apis/feature-toggles/","text":"Feature Toggles Some Knora features can be turned on or off on a per-request basis. This mechanism is based on Feature Toggles (aka Feature Flags) . For example, a new feature that introduces a breaking API change may first be introduced with a feature toggle that leaves it disabled by default, so that clients can continue using the old functionality. When the new feature is ready to be tested with client code, the Knora release notes and documentation will indicate that it can be enabled on a per-request basis, as explained below. At a later date, the feature may be enabled by default, and the release notes will indicate that it can still be disabled on a per-request basis by clients that are not yet ready to use it. There may be more than one version of a feature toggle. Every feature toggle has at least one version number, which is an integer. The first version is 1. Most feature toggles have an expiration date, after which they will be removed. Request Header A client can override one or more feature toggles by submitting the HTTP header X-Knora-Feature-Toggles . Its value is a comma-separated list of toggles. Each toggle consists of: its name a colon the version number an equals sign a boolean value, which can be on / off , yes / no , or true / false Using on / off is recommended for clarity. For example: X-Knora-Feature-Toggles: new-foo:2=on,new-bar=off,fast-baz:1=on A version number must be given when enabling a toggle. Only one version of each toggle can be enabled at a time. If a toggle is enabled by default, and you want a version other than the default version, simply enable the toggle, specifying the desired version number. The version number you specify overrides the default. Disabling a toggle means disabling all its versions. When a toggle is disabled, you will get the functionality that you would have got before the toggle existed. Therefore, a version number cannot be given when disabling a toggle. Response Header DSP-API v2 and admin API responses contain the header X-Knora-Feature-Toggles . It lists all configured toggles, in the same format as the corresponding request header.","title":"Feature Toggles"},{"location":"DSP-API/03-apis/feature-toggles/#feature-toggles","text":"Some Knora features can be turned on or off on a per-request basis. This mechanism is based on Feature Toggles (aka Feature Flags) . For example, a new feature that introduces a breaking API change may first be introduced with a feature toggle that leaves it disabled by default, so that clients can continue using the old functionality. When the new feature is ready to be tested with client code, the Knora release notes and documentation will indicate that it can be enabled on a per-request basis, as explained below. At a later date, the feature may be enabled by default, and the release notes will indicate that it can still be disabled on a per-request basis by clients that are not yet ready to use it. There may be more than one version of a feature toggle. Every feature toggle has at least one version number, which is an integer. The first version is 1. Most feature toggles have an expiration date, after which they will be removed.","title":"Feature Toggles"},{"location":"DSP-API/03-apis/feature-toggles/#request-header","text":"A client can override one or more feature toggles by submitting the HTTP header X-Knora-Feature-Toggles . Its value is a comma-separated list of toggles. Each toggle consists of: its name a colon the version number an equals sign a boolean value, which can be on / off , yes / no , or true / false Using on / off is recommended for clarity. For example: X-Knora-Feature-Toggles: new-foo:2=on,new-bar=off,fast-baz:1=on A version number must be given when enabling a toggle. Only one version of each toggle can be enabled at a time. If a toggle is enabled by default, and you want a version other than the default version, simply enable the toggle, specifying the desired version number. The version number you specify overrides the default. Disabling a toggle means disabling all its versions. When a toggle is disabled, you will get the functionality that you would have got before the toggle existed. Therefore, a version number cannot be given when disabling a toggle.","title":"Request Header"},{"location":"DSP-API/03-apis/feature-toggles/#response-header","text":"DSP-API v2 and admin API responses contain the header X-Knora-Feature-Toggles . It lists all configured toggles, in the same format as the corresponding request header.","title":"Response Header"},{"location":"DSP-API/03-apis/api-admin/","text":"Knora Admin API The Knora admin API makes it possible to administer Knora projects, users, user groups, permissions, and hierarchical lists. Introduction Overview Users Endpoint Projects Endpoint Groups Endpoint Lists Endpoint Permissions Endpoint Stores Endpoint","title":"Index"},{"location":"DSP-API/03-apis/api-admin/#knora-admin-api","text":"The Knora admin API makes it possible to administer Knora projects, users, user groups, permissions, and hierarchical lists. Introduction Overview Users Endpoint Projects Endpoint Groups Endpoint Lists Endpoint Permissions Endpoint Stores Endpoint","title":"Knora Admin API"},{"location":"DSP-API/03-apis/api-admin/groups/","text":"Groups Endpoint Endpoint Overview Group Operations: GET: /admin/groups : return all groups GET: /admin/groups/<groupIri> : return single group identified by [IRI] POST: /admin/groups : create a new group PUT: /admin/groups/<groupIri> : update groups's basic information PUT: /admin/groups/<groupIri>/status : update group's status DELETE: /admin/groups/<groupIri> : delete group (set status to false) Member Operations: GET: /admin/groups/<groupIri>/members : return all group members Group Operations Create Group Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission Required information: name (unique inside project), project IRI Optional information: group descriptions Returns information about the newly created group TypeScript Docs: groupFormats - CreateGroupApiRequestV1 POST: /admin/groups BODY: { \"name\": \"NewGroup\", \"descriptions\": [ {\"value\": \"NewGroupDescription\", \"language\": \"en\"}, {\"value\": \"NeueGruppenBeschreibung\", \"language\": \"de\"} ], \"project\": \"http://rdfh.ch/projects/00FF\", \"status\": true, \"selfjoin\": false } Additionally, each group can have an optional custom IRI (of @ref: Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/groups/00FF/a95UWs71KUklnFOe1rcw1w\", \"name\": \"GroupWithCustomIRI\", \"descriptions\": [{\"value\": \"A new group with a custom IRI\", \"language\": \"en\"}], \"project\": \"http://rdfh.ch/projects/00FF\", \"status\": true, \"selfjoin\": false } Update group information Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) Changeable information: name , descriptions , selfjoin TypeScript Docs: groupFormats - ChangeGroupApiRequestADM PUT: /admin/groups/<groupIri> BODY: { \"name\": \"UpdatedGroupName\", \"descriptions\": [{\"value\": \"UpdatedGroupDescription\", \"language\": \"en\"}], \"selfjoin\": false } Change Group Status: Required permission: SystemAdmin / hasProjectAllAdminPermission Changeable information: status Remark: Deleting a group, removes all members from the group. PUT: /admin/groups/<groupIri>/status BODY: { \"status\": false } Delete Group: Required permission: SystemAdmin / hasProjectAllAdminPermission Remark: The same as changing the groups status to false . To un-delete, set status to true . DELETE: /admin/groups/<groupIri> Example Group Information stored in admin named graph: : <http://rdfh.ch/groups/[shortcode]/[UUID]> rdf:type knora-admin:UserGroup ; knora-admin:groupName \"Name of the group\" ; knora-admin:groupDescriptions \"A description of the group\"@en ; knora-admin:belongsToProject <http://rdfh.ch/projects/[UUID]> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean . Member Operations Get Group Members Returns all group members Required permission: SystemAdmin / ProjectAdmin GET: /admin/groups/<groupIri>/members","title":"Groups Endpoint"},{"location":"DSP-API/03-apis/api-admin/groups/#groups-endpoint","text":"","title":"Groups Endpoint"},{"location":"DSP-API/03-apis/api-admin/groups/#endpoint-overview","text":"Group Operations: GET: /admin/groups : return all groups GET: /admin/groups/<groupIri> : return single group identified by [IRI] POST: /admin/groups : create a new group PUT: /admin/groups/<groupIri> : update groups's basic information PUT: /admin/groups/<groupIri>/status : update group's status DELETE: /admin/groups/<groupIri> : delete group (set status to false) Member Operations: GET: /admin/groups/<groupIri>/members : return all group members","title":"Endpoint Overview"},{"location":"DSP-API/03-apis/api-admin/groups/#group-operations","text":"","title":"Group Operations"},{"location":"DSP-API/03-apis/api-admin/groups/#create-group","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission Required information: name (unique inside project), project IRI Optional information: group descriptions Returns information about the newly created group TypeScript Docs: groupFormats - CreateGroupApiRequestV1 POST: /admin/groups BODY: { \"name\": \"NewGroup\", \"descriptions\": [ {\"value\": \"NewGroupDescription\", \"language\": \"en\"}, {\"value\": \"NeueGruppenBeschreibung\", \"language\": \"de\"} ], \"project\": \"http://rdfh.ch/projects/00FF\", \"status\": true, \"selfjoin\": false } Additionally, each group can have an optional custom IRI (of @ref: Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/groups/00FF/a95UWs71KUklnFOe1rcw1w\", \"name\": \"GroupWithCustomIRI\", \"descriptions\": [{\"value\": \"A new group with a custom IRI\", \"language\": \"en\"}], \"project\": \"http://rdfh.ch/projects/00FF\", \"status\": true, \"selfjoin\": false }","title":"Create Group"},{"location":"DSP-API/03-apis/api-admin/groups/#update-group-information","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) Changeable information: name , descriptions , selfjoin TypeScript Docs: groupFormats - ChangeGroupApiRequestADM PUT: /admin/groups/<groupIri> BODY: { \"name\": \"UpdatedGroupName\", \"descriptions\": [{\"value\": \"UpdatedGroupDescription\", \"language\": \"en\"}], \"selfjoin\": false }","title":"Update group information"},{"location":"DSP-API/03-apis/api-admin/groups/#change-group-status","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission Changeable information: status Remark: Deleting a group, removes all members from the group. PUT: /admin/groups/<groupIri>/status BODY: { \"status\": false }","title":"Change Group Status:"},{"location":"DSP-API/03-apis/api-admin/groups/#delete-group","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission Remark: The same as changing the groups status to false . To un-delete, set status to true . DELETE: /admin/groups/<groupIri> Example Group Information stored in admin named graph: : <http://rdfh.ch/groups/[shortcode]/[UUID]> rdf:type knora-admin:UserGroup ; knora-admin:groupName \"Name of the group\" ; knora-admin:groupDescriptions \"A description of the group\"@en ; knora-admin:belongsToProject <http://rdfh.ch/projects/[UUID]> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean .","title":"Delete Group:"},{"location":"DSP-API/03-apis/api-admin/groups/#member-operations","text":"","title":"Member Operations"},{"location":"DSP-API/03-apis/api-admin/groups/#get-group-members","text":"Returns all group members Required permission: SystemAdmin / ProjectAdmin GET: /admin/groups/<groupIri>/members","title":"Get Group Members"},{"location":"DSP-API/03-apis/api-admin/introduction/","text":"Introduction: Using the Admin API RESTful API The Knora Admin API is a RESTful API that allows for reading and adding of administrative resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The various HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ). Knora IRIs in the Admin API Every resource that is created or hosted by Knora is identified by a unique ID called an Internationalized Resource Identifier ( IRI ). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike the DSP-API v2, the admin API uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ). Admin Path Segment Every request to Admin API includes admin as a path segment, e.g. http://host/admin/users/iri/http%3A%2F%2Frdfh.ch%2Fusers%2Froot . Admin API Response Format If an API request is handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON. Placeholder host in sample URLs Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on. Authentication For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. Credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). OpenAPI/Swagger The Admin API uses OpenAPI for documentation purposes. To try it out, run webapi and open http://host/api-docs/swagger.json in http://petstore.swagger.io . Alternatively, the documentation can be looked at by using ReDoc , which is provided in knora/docs/redoc/index.html and is published under https://docs.knora.org/api-admin/index.html . Admin API Endpoints TODO","title":"Introduction"},{"location":"DSP-API/03-apis/api-admin/introduction/#introduction-using-the-admin-api","text":"","title":"Introduction: Using the Admin API"},{"location":"DSP-API/03-apis/api-admin/introduction/#restful-api","text":"The Knora Admin API is a RESTful API that allows for reading and adding of administrative resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The various HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ).","title":"RESTful API"},{"location":"DSP-API/03-apis/api-admin/introduction/#knora-iris-in-the-admin-api","text":"Every resource that is created or hosted by Knora is identified by a unique ID called an Internationalized Resource Identifier ( IRI ). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike the DSP-API v2, the admin API uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ).","title":"Knora IRIs in the Admin API"},{"location":"DSP-API/03-apis/api-admin/introduction/#admin-path-segment","text":"Every request to Admin API includes admin as a path segment, e.g. http://host/admin/users/iri/http%3A%2F%2Frdfh.ch%2Fusers%2Froot .","title":"Admin Path Segment"},{"location":"DSP-API/03-apis/api-admin/introduction/#admin-api-response-format","text":"If an API request is handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON.","title":"Admin API Response Format"},{"location":"DSP-API/03-apis/api-admin/introduction/#placeholder-host-in-sample-urls","text":"Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on.","title":"Placeholder host in sample URLs"},{"location":"DSP-API/03-apis/api-admin/introduction/#authentication","text":"For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. Credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ).","title":"Authentication"},{"location":"DSP-API/03-apis/api-admin/introduction/#openapiswagger","text":"The Admin API uses OpenAPI for documentation purposes. To try it out, run webapi and open http://host/api-docs/swagger.json in http://petstore.swagger.io . Alternatively, the documentation can be looked at by using ReDoc , which is provided in knora/docs/redoc/index.html and is published under https://docs.knora.org/api-admin/index.html .","title":"OpenAPI/Swagger"},{"location":"DSP-API/03-apis/api-admin/introduction/#admin-api-endpoints","text":"TODO","title":"Admin API Endpoints"},{"location":"DSP-API/03-apis/api-admin/lists/","text":"Lists Endpoint Endpoint Overview List Item Operations: GET: /admin/lists[?projectIri=<projectIri>] : return all lists optionally filtered by project GET: /admin/lists/<listItemIri> : return complete list with all children if IRI of the list (i.e. root node) is given If IRI of the child node is given, return the node with its immediate children GET: /admin/lists/infos/<listIri> : return list information (without children) GET: /admin/lists/nodes/<nodeIri> : return list node information (without children) GET: /admin/lists/<listIri>/info : return list basic information (without children) POST: /admin/lists : create new list POST: /admin/lists/<parentNodeIri> : create new child node under the supplied parent node IRI PUT: /admin/lists/<listItemIri> : update node information (root or child) PUT: /admin/lists/<listItemIri>/name : update the name of the node (root or child) PUT: /admin/lists/<listItemIri>/labels : update labels of the node (root or child) PUT: /admin/lists/<listItemIri>/comments : update comments of the node (root or child) PUT: /admin/lists/<nodeIri>/position : update position of a child node within its current parent or by changing its parent node DELETE: /admin/lists/<listItemIri> : delete a list (i.e. root node) or a child node and all its children, if not used List Item Operations Get lists Required permission: none Return all lists optionally filtered by project GET: /admin/lists[?projectIri=<projectIri>] Get list Required permission: none Return complete list (or node ) including basic information of the list (or child node), listinfo (or nodeinfo ), and all its children GET: /admin/lists/<listIri> Get list's information Required permission: none Return list information, listinfo (without children). GET: /admin/lists/infos/<listIri> Get list node Information Required permission: none Return node information, nodeinfo , (without children). GET: /admin/lists/nodes/<nodeIri> Get list's information (merged) Required permission: none Return list (or node) basic information, listinfo (or nodeinfo ), without its children GET: /admin/lists/<listIri>/info Create new list Required permission: SystemAdmin / ProjectAdmin Required fields: projectIri , labels , comments POST: /admin/lists BODY: { \"projectIri\": \"someprojectiri\", \"labels\": [{ \"value\": \"New list\", \"language\": \"en\"}], \"comments\": [] } Additionally, each list can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"a new list\", \"labels\": [{ \"value\": \"New list with IRI\", \"language\": \"en\"}], \"comments\": [{ \"value\": \"New comment\", \"language\": \"en\"}] } The response will contain the basic information of the list, listinfo and an empty list of its children, as below: { \"list\": { \"children\": [], \"listinfo\": { \"comments\": [{ \"value\": \"New comment\", \"language\": \"en\"}], \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"isRootNode\": true, \"labels\": [ { \"value\": \"New list with IRI\", \"language\": \"en\" } ], \"name\": \"a new list\", \"projectIri\": \"http://rdfh.ch/projects/0001\" } } } Create new child node Required permission: SystemAdmin / ProjectAdmin Required fields: parentNodeIri , projectIri , labels , Appends a new child node under the supplied nodeIri. If the supplied nodeIri is the listIri, then a new child node is appended to the top level. If a position is given for the new child node, the node will be created and inserted in the specified position, otherwise the node is appended to the end of parent's children. POST: /admin/lists/<parentNodeIri> BODY: { \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"a child\", \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } Additionally, each child node can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\", \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"a child\", \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } The response will contain the basic information of the node, nodeinfo , as below: { \"nodeinfo\": { \"comments\": [], \"hasRootNode\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"id\": \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\", \"labels\": [ { \"value\": \"New List Node\", \"language\": \"en\" } ], \"name\": \"a new child\", \"position\": 1 } } The new node can be created and inserted in a specific position which must be given in the payload as shown below. If necessary, according to the given position, the sibling nodes will be shifted. Note that position cannot have a value higher than the number of existing children. { \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"Inserted new child\", \"position\": 0, \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } In case the new node should be appended to the list of current children, either position: -1 must be given in the payload or the position parameter must be left out of the payload. Update list's or node's information The basic information of a list (or node) such as its labels, comments, name, or all of them can be updated. The parameters that must be updated together with the new value must be given in the JSON body of the request together with the IRI of the list and the IRI of the project it belongs to. Required permission: SystemAdmin / ProjectAdmin Required fields: listIri , projectIri Update list information PUT: /admin/lists/<listIri> BODY: { \"listIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"new name for the list\", \"labels\": [{ \"value\": \"a new label for the list\", \"language\": \"en\"}], \"comments\": [{ \"value\": \"a new comment for the list\", \"language\": \"en\"}] } The response will contain the basic information of the list, listinfo (or nodeinfo ), without its children, as below: { \"listinfo\": { \"comments\": [ { \"value\": \"a new comment for the list\", \"language\": \"en\" } ], \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"isRootNode\": true, \"labels\": [ { \"value\": \"a new label for the list\", \"language\": \"en\" } ], \"name\": \"new name for the list\", \"projectIri\": \"http://rdfh.ch/projects/0001\" } } If only name of the list must be updated, it can be given as below in the body of the request: { \"listIri\": \"listIri\", \"projectIri\": \"someprojectiri\", \"name\": \"another name\" } Alternatively, basic information name , labels , or comments of the root node (i.e. list) can be updated individually as explained below. Update list or node's name Required permission: SystemAdmin / ProjectAdmin Update name of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/name BODY: The new name of the node must be given in the body of the request as shown below: ```json { \"name\": \"a new name\" } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Update list or node's labels - Required permission: SystemAdmin / ProjectAdmin - Update labels of the list (i.e. root node) or a child node whose IRI is specified by `<listItemIri>`. - PUT: `/admin/lists/<listItemIri>/labels` - BODY: The new set of labels of the node must be given in the body of the request as shown below: ```json { \"labels\": [{\"language\": \"se\", \"value\": \"nya m\u00e4rkningen\"}] } There is no need to specify the project IRI because it is automatically extracted using the given <listItemIRI> . Update list or node's comments Required permission: SystemAdmin / ProjectAdmin Update comments of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/labels BODY: The new set of comments of the node must be given in the body of the request as shown below: ```json { \"comments\": [{\"language\": \"se\", \"value\": \"nya kommentarer\"}] } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Repositioning a child node The position of an existing child node can be updated. The child node can be either repositioned within its current parent node, or can be added to another parent node in a specific position. The IRI of the parent node and the new position of the child node must be given in the request body. If a node is supposed to be repositioned to the end of a parent node's children, give `position: -1`. Suppose a parent node `parentNode1` has five children in positions 0-4, to change the position of its child node `childNode4` from its original position 3 to position 1 the request body should specify the IRI of its parent node and the new position as below: ```json { \"parentNodeIri\": \"<parentNode1-IRI>\", \"position\": 1 } Then the node childNode4 will be put in position 1, and its siblings will be shifted accordingly. The new position given in the request body cannot be the same as the child node's original position. If position: -1 is given, the node will be moved to the end of children list, and its siblings will be shifted to left. In case of repositioning the node within its current parent, the maximum permitted position is the length of its children list, i.e. in this example the highest allowed position is 4. To reposition a child node childNode4 to another parent node parentNode2 in a specific position, for example position: 3 , the IRI of the new parent node and the position the node must be placed within children of parentNode2 must be given as: { \"parentNodeIri\": \"<parentNode2-IRI>\", \"position\": 3 } In this case, the childNode4 is removed from the list of children of its old parent parentNode1 and its old siblings are shifted accordingly. Then the node childNode4 is added to the specified new parent, i.e. parentNode2 , in the given position. The new siblings are shifted accordingly. Note that, the furthest the node can be placed is at the end of the list of the children of parentNode2 . That means if parentNode2 had 3 children with positions 0-2, then childNode4 can be placed in position 0-3 within children of its new parent node. If the position: -1 is given, the node will be appended to the end of new parent's children, and new siblings will not be shifted. Values less than -1 are not permitted for parameter position . Required permission: SystemAdmin / ProjectAdmin Response: returns the updated parent node with all its children. Put /admin/lists/<nodeIri>/position Delete a list or a node An entire list or a single node of it can be completely deleted, if not in use. Before deleting an entire list (i.e. root node), the data and ontologies are checked for any usage of the list or its children. If not in use, the list and all its children are deleted. Similarily, before deleting a single node of a list, it is verified that the node itself and none of its children are used. If not in use, the node and all its children are deleted. Once a node is deleted, its parent node is updated by shifting the remaining child nodes with respect to the position of the deleted node. Required permission: SystemAdmin / ProjectAdmin Response: If the IRI of the list (i.e. root node) is given, the iri of the deleted list with a flag deleted: true is returned. If the IRI of a child node is given, the updated parent node is returned. Delete /admin/lists/<listItemIri>","title":"Lists Endpoint"},{"location":"DSP-API/03-apis/api-admin/lists/#lists-endpoint","text":"","title":"Lists Endpoint"},{"location":"DSP-API/03-apis/api-admin/lists/#endpoint-overview","text":"List Item Operations: GET: /admin/lists[?projectIri=<projectIri>] : return all lists optionally filtered by project GET: /admin/lists/<listItemIri> : return complete list with all children if IRI of the list (i.e. root node) is given If IRI of the child node is given, return the node with its immediate children GET: /admin/lists/infos/<listIri> : return list information (without children) GET: /admin/lists/nodes/<nodeIri> : return list node information (without children) GET: /admin/lists/<listIri>/info : return list basic information (without children) POST: /admin/lists : create new list POST: /admin/lists/<parentNodeIri> : create new child node under the supplied parent node IRI PUT: /admin/lists/<listItemIri> : update node information (root or child) PUT: /admin/lists/<listItemIri>/name : update the name of the node (root or child) PUT: /admin/lists/<listItemIri>/labels : update labels of the node (root or child) PUT: /admin/lists/<listItemIri>/comments : update comments of the node (root or child) PUT: /admin/lists/<nodeIri>/position : update position of a child node within its current parent or by changing its parent node DELETE: /admin/lists/<listItemIri> : delete a list (i.e. root node) or a child node and all its children, if not used","title":"Endpoint Overview"},{"location":"DSP-API/03-apis/api-admin/lists/#list-item-operations","text":"","title":"List Item Operations"},{"location":"DSP-API/03-apis/api-admin/lists/#get-lists","text":"Required permission: none Return all lists optionally filtered by project GET: /admin/lists[?projectIri=<projectIri>]","title":"Get lists"},{"location":"DSP-API/03-apis/api-admin/lists/#get-list","text":"Required permission: none Return complete list (or node ) including basic information of the list (or child node), listinfo (or nodeinfo ), and all its children GET: /admin/lists/<listIri>","title":"Get list"},{"location":"DSP-API/03-apis/api-admin/lists/#get-lists-information","text":"Required permission: none Return list information, listinfo (without children). GET: /admin/lists/infos/<listIri>","title":"Get list's information"},{"location":"DSP-API/03-apis/api-admin/lists/#get-list-node-information","text":"Required permission: none Return node information, nodeinfo , (without children). GET: /admin/lists/nodes/<nodeIri>","title":"Get list node Information"},{"location":"DSP-API/03-apis/api-admin/lists/#get-lists-information-merged","text":"Required permission: none Return list (or node) basic information, listinfo (or nodeinfo ), without its children GET: /admin/lists/<listIri>/info","title":"Get list's information (merged)"},{"location":"DSP-API/03-apis/api-admin/lists/#create-new-list","text":"Required permission: SystemAdmin / ProjectAdmin Required fields: projectIri , labels , comments POST: /admin/lists BODY: { \"projectIri\": \"someprojectiri\", \"labels\": [{ \"value\": \"New list\", \"language\": \"en\"}], \"comments\": [] } Additionally, each list can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"a new list\", \"labels\": [{ \"value\": \"New list with IRI\", \"language\": \"en\"}], \"comments\": [{ \"value\": \"New comment\", \"language\": \"en\"}] } The response will contain the basic information of the list, listinfo and an empty list of its children, as below: { \"list\": { \"children\": [], \"listinfo\": { \"comments\": [{ \"value\": \"New comment\", \"language\": \"en\"}], \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"isRootNode\": true, \"labels\": [ { \"value\": \"New list with IRI\", \"language\": \"en\" } ], \"name\": \"a new list\", \"projectIri\": \"http://rdfh.ch/projects/0001\" } } }","title":"Create new list"},{"location":"DSP-API/03-apis/api-admin/lists/#create-new-child-node","text":"Required permission: SystemAdmin / ProjectAdmin Required fields: parentNodeIri , projectIri , labels , Appends a new child node under the supplied nodeIri. If the supplied nodeIri is the listIri, then a new child node is appended to the top level. If a position is given for the new child node, the node will be created and inserted in the specified position, otherwise the node is appended to the end of parent's children. POST: /admin/lists/<parentNodeIri> BODY: { \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"a child\", \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } Additionally, each child node can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\", \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"a child\", \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } The response will contain the basic information of the node, nodeinfo , as below: { \"nodeinfo\": { \"comments\": [], \"hasRootNode\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"id\": \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\", \"labels\": [ { \"value\": \"New List Node\", \"language\": \"en\" } ], \"name\": \"a new child\", \"position\": 1 } } The new node can be created and inserted in a specific position which must be given in the payload as shown below. If necessary, according to the given position, the sibling nodes will be shifted. Note that position cannot have a value higher than the number of existing children. { \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"Inserted new child\", \"position\": 0, \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } In case the new node should be appended to the list of current children, either position: -1 must be given in the payload or the position parameter must be left out of the payload.","title":"Create new child node"},{"location":"DSP-API/03-apis/api-admin/lists/#update-lists-or-nodes-information","text":"The basic information of a list (or node) such as its labels, comments, name, or all of them can be updated. The parameters that must be updated together with the new value must be given in the JSON body of the request together with the IRI of the list and the IRI of the project it belongs to. Required permission: SystemAdmin / ProjectAdmin Required fields: listIri , projectIri Update list information PUT: /admin/lists/<listIri> BODY: { \"listIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/0001\", \"name\": \"new name for the list\", \"labels\": [{ \"value\": \"a new label for the list\", \"language\": \"en\"}], \"comments\": [{ \"value\": \"a new comment for the list\", \"language\": \"en\"}] } The response will contain the basic information of the list, listinfo (or nodeinfo ), without its children, as below: { \"listinfo\": { \"comments\": [ { \"value\": \"a new comment for the list\", \"language\": \"en\" } ], \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"isRootNode\": true, \"labels\": [ { \"value\": \"a new label for the list\", \"language\": \"en\" } ], \"name\": \"new name for the list\", \"projectIri\": \"http://rdfh.ch/projects/0001\" } } If only name of the list must be updated, it can be given as below in the body of the request: { \"listIri\": \"listIri\", \"projectIri\": \"someprojectiri\", \"name\": \"another name\" } Alternatively, basic information name , labels , or comments of the root node (i.e. list) can be updated individually as explained below.","title":"Update list's or node's information"},{"location":"DSP-API/03-apis/api-admin/lists/#update-list-or-nodes-name","text":"Required permission: SystemAdmin / ProjectAdmin Update name of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/name BODY: The new name of the node must be given in the body of the request as shown below: ```json { \"name\": \"a new name\" } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Update list or node's labels - Required permission: SystemAdmin / ProjectAdmin - Update labels of the list (i.e. root node) or a child node whose IRI is specified by `<listItemIri>`. - PUT: `/admin/lists/<listItemIri>/labels` - BODY: The new set of labels of the node must be given in the body of the request as shown below: ```json { \"labels\": [{\"language\": \"se\", \"value\": \"nya m\u00e4rkningen\"}] } There is no need to specify the project IRI because it is automatically extracted using the given <listItemIRI> .","title":"Update list or node's name"},{"location":"DSP-API/03-apis/api-admin/lists/#update-list-or-nodes-comments","text":"Required permission: SystemAdmin / ProjectAdmin Update comments of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/labels BODY: The new set of comments of the node must be given in the body of the request as shown below: ```json { \"comments\": [{\"language\": \"se\", \"value\": \"nya kommentarer\"}] } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Repositioning a child node The position of an existing child node can be updated. The child node can be either repositioned within its current parent node, or can be added to another parent node in a specific position. The IRI of the parent node and the new position of the child node must be given in the request body. If a node is supposed to be repositioned to the end of a parent node's children, give `position: -1`. Suppose a parent node `parentNode1` has five children in positions 0-4, to change the position of its child node `childNode4` from its original position 3 to position 1 the request body should specify the IRI of its parent node and the new position as below: ```json { \"parentNodeIri\": \"<parentNode1-IRI>\", \"position\": 1 } Then the node childNode4 will be put in position 1, and its siblings will be shifted accordingly. The new position given in the request body cannot be the same as the child node's original position. If position: -1 is given, the node will be moved to the end of children list, and its siblings will be shifted to left. In case of repositioning the node within its current parent, the maximum permitted position is the length of its children list, i.e. in this example the highest allowed position is 4. To reposition a child node childNode4 to another parent node parentNode2 in a specific position, for example position: 3 , the IRI of the new parent node and the position the node must be placed within children of parentNode2 must be given as: { \"parentNodeIri\": \"<parentNode2-IRI>\", \"position\": 3 } In this case, the childNode4 is removed from the list of children of its old parent parentNode1 and its old siblings are shifted accordingly. Then the node childNode4 is added to the specified new parent, i.e. parentNode2 , in the given position. The new siblings are shifted accordingly. Note that, the furthest the node can be placed is at the end of the list of the children of parentNode2 . That means if parentNode2 had 3 children with positions 0-2, then childNode4 can be placed in position 0-3 within children of its new parent node. If the position: -1 is given, the node will be appended to the end of new parent's children, and new siblings will not be shifted. Values less than -1 are not permitted for parameter position . Required permission: SystemAdmin / ProjectAdmin Response: returns the updated parent node with all its children. Put /admin/lists/<nodeIri>/position","title":"Update list or node's comments"},{"location":"DSP-API/03-apis/api-admin/lists/#delete-a-list-or-a-node","text":"An entire list or a single node of it can be completely deleted, if not in use. Before deleting an entire list (i.e. root node), the data and ontologies are checked for any usage of the list or its children. If not in use, the list and all its children are deleted. Similarily, before deleting a single node of a list, it is verified that the node itself and none of its children are used. If not in use, the node and all its children are deleted. Once a node is deleted, its parent node is updated by shifting the remaining child nodes with respect to the position of the deleted node. Required permission: SystemAdmin / ProjectAdmin Response: If the IRI of the list (i.e. root node) is given, the iri of the deleted list with a flag deleted: true is returned. If the IRI of a child node is given, the updated parent node is returned. Delete /admin/lists/<listItemIri>","title":"Delete a list or a node"},{"location":"DSP-API/03-apis/api-admin/overview/","text":"Admin Endpoint For the management of users , projects , and groups , the DSP-API following a resource centric approach, provides three endpoints corresponding to the three classes of objects that they have an effect on, namely: Users Endpoint: http://server:port/admin/users - knora-base:User Projects Endpoint: http://server:port/admin/projects - knora-base:knoraProject Groups Endpoint: http://server:port/admin/groups - knora-base:UserGroup All information regarding users, projects and groups is stored in the http://www.knora.org/admin named graph.","title":"Overview"},{"location":"DSP-API/03-apis/api-admin/overview/#admin-endpoint","text":"For the management of users , projects , and groups , the DSP-API following a resource centric approach, provides three endpoints corresponding to the three classes of objects that they have an effect on, namely: Users Endpoint: http://server:port/admin/users - knora-base:User Projects Endpoint: http://server:port/admin/projects - knora-base:knoraProject Groups Endpoint: http://server:port/admin/groups - knora-base:UserGroup All information regarding users, projects and groups is stored in the http://www.knora.org/admin named graph.","title":"Admin Endpoint"},{"location":"DSP-API/03-apis/api-admin/permissions/","text":"Permissions Endpoint Permission Operations: Note: For the following operations, the requesting user must be either a systemAdmin or a projectAdmin . Getting Permissions: GET: /admin/permissions/<projectIri> : return all permissions for a project. As a response, the IRI and the type of all permissions of a project are returned. GET: /admin/permissions/ap/<projectIri> : return all administrative permissions for a project. As a response, all administrative_permissions of a project are returned. GET: /admin/permissions/ap/<projectIri>/<groupIri> : return the administrative permissions for a project group. As a response, the administrative_permission defined for the group is returned. GET: /admin/permissions/doap/<projectIri> : return all default object access permissions for a project. As a response, all default_object_acces_permissions of a project are returned. Creating New Administrative Permissions: POST: /admin/permissions/ap : create a new administrative permission. The type of permissions, the project and group to which the permission should be added must be included in the request body, for example: { \"forGroup\":\"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\":\"http://rdfh.ch/projects/0001\", \"hasPermissions\":[{\"additionalInformation\":null,\"name\":\"ProjectAdminGroupAllPermission\",\"permissionCode\":null}] } In addition, in the body of the request, it is possible to specify a custom IRI (of Knora IRI form) for a permission through the @id attribute which will then be assigned to the permission; otherwise the permission will get a unique random IRI. A custom permission IRI must be http://rdfh.ch/permissions/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the permission belongs to), plus a custom ID string. For example: \"id\": \"http://rdfh.ch/permissions/0001/jKIYuaEUETBcyxpenUwRzQ\", As a response, the created administrative permission and its IRI are returned as below: { \"administrative_permission\": { \"forGroup\": \"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\": \"http://rdfh.ch/projects/0001\", \"hasPermissions\": [ { \"additionalInformation\": null, \"name\": \"ProjectAdminGroupAllPermission\", \"permissionCode\": null } ], \"iri\": \"http://rdfh.ch/permissions/0001/mFlyBEiMQtGzwy_hK0M-Ow\" } } hasPermissions contains permission types that must be granted. See the complete description of administrative permission types . In summary, each permission should contain followings: name : indicates the type of the permission that can be one of the followings: ProjectAdminAllPermission : gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ProjectAdminGroupAllPermission : gives the user the permission to modify group info and group membership on all groups belonging to the project. ProjectAdminGroupRestrictedPermission : gives the user the permission to modify group info and group membership on certain groups belonging to the project. ProjectAdminRightsAllPermission : gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). ProjectResourceCreateAllPermission : gives the permission to create resources inside the project. ProjectResourceCreateRestrictedPermission : gives restricted resource creation permission inside the project. additionalInformation : should be left empty, otherwise will be ignored. permissionCode : should be left empty, otherwise will be ignored. Note that during the creation of a new project, a default set of administrative permissions are added to its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new administrative permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified (See update permission ). Creating New Default Object Access Permissions: POST: /admin/permissions/doap : create a new default object access permission. A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. For example, to create a new default object access permission for a group of a project the request body would be { \"forGroup\":\"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\":\"http://rdfh.ch/projects/0001\", \"forProperty\":null, \"forResourceClass\":null, \"hasPermissions\":[{\"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\",\"name\":\"D\",\"permissionCode\":7}] } hasPermissions contains permission types that must be granted. See a complete description of object access permission types . In summary, each permission should contain followings: additionalInformation : To whom the permission should be granted: project members, known users, unknown users, etc. name : indicates the type of the permission that can be one of the followings. RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) permissionCode : The code assigned to a permission indicating its hierarchical level. These codes are as below: 1 : for restricted view permission (least privileged) 2 : for view permission 6 : for modify permission 7 : for delete permission 8 : for change rights permission (most privileged) Note that, at least either name or permissionCode must be provided. If one is missing, it will be extrapolated from the other. For example, if permissionCode= 1 is given but name was left empty, its value will be set to name = RV . Similar to the previous case a custom IRI can be assigned to a permission specified by the id in the request body. The example below shows the request body to create a new default object access permission with a custom IRI defined for a resource class of a specific project: { \"id\": \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\", \"forGroup\":null, \"forProject\":\"http://rdfh.ch/projects/00FF\", \"forProperty\":null, \"forResourceClass\":\"http://www.knora.org/ontology/00FF/images#bild\", \"hasPermissions\":[{\"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\",\"name\":\"D\",\"permissionCode\":7}] } The response contains the newly created permission and its IRI, as: { \"default_object_access_permission\": { \"forGroup\": null, \"forProject\": \"http://rdfh.ch/projects/00FF\", \"forProperty\": null, \"forResourceClass\": \"http://www.knora.org/ontology/00FF/images#bild\", \"hasPermissions\": [ { \"additionalInformation\": \"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\": \"D\", \"permissionCode\": 7 } ], \"iri\": \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\" } } Note that during the creation of a new project, a set of default object access permissions are created for its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new default object access permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified; see below for more information. Updating a Permission's Group: PUT: /admin/permissions/<permissionIri>/group to change the group for which an administrative or a default object access permission, identified by it IRI <permissionIri> , is defined. The request body must contain the IRI of the new group as below: { \"forGroup\": \"http://www.knora.org/ontology/knora-admin#ProjectMember\" } When updating an administrative permission, its previous forGroup value will be replaced with the new one. When updating a default object access permission, if it originally had a forGroup value defined, it will be replaced with the new group. Otherwise, if the default object access permission was defined for a resource class or a property or the combination of both, the permission will be defined for the newly specified group and its previous forResourceClass and forProperty values will be deleted. Updating a Permission's Scope: PUT: /admin/permissions/<permissionIri>/hasPermissions to change the scope of permissions assigned to an administrative or a default object access permission identified by it IRI, <permissionIri> . The request body must contain the new set of permission types as below: { \"hasPermissions\":[{\"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\",\"name\":\"D\",\"permissionCode\":7}] } Each permission item given in hasPermissions , must contain the necessary parameters with respect to the type of the permission. For example, if you wish to change the scope of an administrative permission, follow the guidelines for the content of its hasPermissions property. Similarly, if you wish to change the scope of a default object access permission, follow the guidelines given about the content of its hasPermissions property. Updating a Default Object Access Permission's Resource Class: PUT: /admin/permissions/<doap_permissionIri>/resourceClass to change the resource class for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object acceess permission. The IRI of the new resource class must be given in the request body as: { \"forResourceClass\": \"http://www.knora.org/ontology/0803/incunabula#book\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given resource class instead of the group. That means the value of the forGroup will be deleted. Updating a Default Object Access Permission's Property: PUT: /admin/permissions/<doap_permissionIri>/property to change the property for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object access permission. The IRI of the new property must be given in the request body as: { \"forProperty\":\"http://www.knora.org/ontology/00FF/images#titel\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given property instead of the group. That means the value of the forGroup will be deleted. Deleting a permission: DELETE: /admin/permissions/<permissionIri> to delete an administrative, or a default object access permission. The IRI of the permission must be given in encoded form.","title":"Permissions Endpoint"},{"location":"DSP-API/03-apis/api-admin/permissions/#permissions-endpoint","text":"","title":"Permissions Endpoint"},{"location":"DSP-API/03-apis/api-admin/permissions/#permission-operations","text":"Note: For the following operations, the requesting user must be either a systemAdmin or a projectAdmin .","title":"Permission Operations:"},{"location":"DSP-API/03-apis/api-admin/permissions/#getting-permissions","text":"GET: /admin/permissions/<projectIri> : return all permissions for a project. As a response, the IRI and the type of all permissions of a project are returned. GET: /admin/permissions/ap/<projectIri> : return all administrative permissions for a project. As a response, all administrative_permissions of a project are returned. GET: /admin/permissions/ap/<projectIri>/<groupIri> : return the administrative permissions for a project group. As a response, the administrative_permission defined for the group is returned. GET: /admin/permissions/doap/<projectIri> : return all default object access permissions for a project. As a response, all default_object_acces_permissions of a project are returned.","title":"Getting Permissions:"},{"location":"DSP-API/03-apis/api-admin/permissions/#creating-new-administrative-permissions","text":"POST: /admin/permissions/ap : create a new administrative permission. The type of permissions, the project and group to which the permission should be added must be included in the request body, for example: { \"forGroup\":\"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\":\"http://rdfh.ch/projects/0001\", \"hasPermissions\":[{\"additionalInformation\":null,\"name\":\"ProjectAdminGroupAllPermission\",\"permissionCode\":null}] } In addition, in the body of the request, it is possible to specify a custom IRI (of Knora IRI form) for a permission through the @id attribute which will then be assigned to the permission; otherwise the permission will get a unique random IRI. A custom permission IRI must be http://rdfh.ch/permissions/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the permission belongs to), plus a custom ID string. For example: \"id\": \"http://rdfh.ch/permissions/0001/jKIYuaEUETBcyxpenUwRzQ\", As a response, the created administrative permission and its IRI are returned as below: { \"administrative_permission\": { \"forGroup\": \"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\": \"http://rdfh.ch/projects/0001\", \"hasPermissions\": [ { \"additionalInformation\": null, \"name\": \"ProjectAdminGroupAllPermission\", \"permissionCode\": null } ], \"iri\": \"http://rdfh.ch/permissions/0001/mFlyBEiMQtGzwy_hK0M-Ow\" } } hasPermissions contains permission types that must be granted. See the complete description of administrative permission types . In summary, each permission should contain followings: name : indicates the type of the permission that can be one of the followings: ProjectAdminAllPermission : gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ProjectAdminGroupAllPermission : gives the user the permission to modify group info and group membership on all groups belonging to the project. ProjectAdminGroupRestrictedPermission : gives the user the permission to modify group info and group membership on certain groups belonging to the project. ProjectAdminRightsAllPermission : gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). ProjectResourceCreateAllPermission : gives the permission to create resources inside the project. ProjectResourceCreateRestrictedPermission : gives restricted resource creation permission inside the project. additionalInformation : should be left empty, otherwise will be ignored. permissionCode : should be left empty, otherwise will be ignored. Note that during the creation of a new project, a default set of administrative permissions are added to its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new administrative permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified (See update permission ).","title":"Creating New Administrative Permissions:"},{"location":"DSP-API/03-apis/api-admin/permissions/#creating-new-default-object-access-permissions","text":"POST: /admin/permissions/doap : create a new default object access permission. A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. For example, to create a new default object access permission for a group of a project the request body would be { \"forGroup\":\"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\":\"http://rdfh.ch/projects/0001\", \"forProperty\":null, \"forResourceClass\":null, \"hasPermissions\":[{\"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\",\"name\":\"D\",\"permissionCode\":7}] } hasPermissions contains permission types that must be granted. See a complete description of object access permission types . In summary, each permission should contain followings: additionalInformation : To whom the permission should be granted: project members, known users, unknown users, etc. name : indicates the type of the permission that can be one of the followings. RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) permissionCode : The code assigned to a permission indicating its hierarchical level. These codes are as below: 1 : for restricted view permission (least privileged) 2 : for view permission 6 : for modify permission 7 : for delete permission 8 : for change rights permission (most privileged) Note that, at least either name or permissionCode must be provided. If one is missing, it will be extrapolated from the other. For example, if permissionCode= 1 is given but name was left empty, its value will be set to name = RV . Similar to the previous case a custom IRI can be assigned to a permission specified by the id in the request body. The example below shows the request body to create a new default object access permission with a custom IRI defined for a resource class of a specific project: { \"id\": \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\", \"forGroup\":null, \"forProject\":\"http://rdfh.ch/projects/00FF\", \"forProperty\":null, \"forResourceClass\":\"http://www.knora.org/ontology/00FF/images#bild\", \"hasPermissions\":[{\"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\",\"name\":\"D\",\"permissionCode\":7}] } The response contains the newly created permission and its IRI, as: { \"default_object_access_permission\": { \"forGroup\": null, \"forProject\": \"http://rdfh.ch/projects/00FF\", \"forProperty\": null, \"forResourceClass\": \"http://www.knora.org/ontology/00FF/images#bild\", \"hasPermissions\": [ { \"additionalInformation\": \"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\": \"D\", \"permissionCode\": 7 } ], \"iri\": \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\" } } Note that during the creation of a new project, a set of default object access permissions are created for its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new default object access permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified; see below for more information.","title":"Creating New Default Object Access Permissions:"},{"location":"DSP-API/03-apis/api-admin/permissions/#updating-a-permissions-group","text":"PUT: /admin/permissions/<permissionIri>/group to change the group for which an administrative or a default object access permission, identified by it IRI <permissionIri> , is defined. The request body must contain the IRI of the new group as below: { \"forGroup\": \"http://www.knora.org/ontology/knora-admin#ProjectMember\" } When updating an administrative permission, its previous forGroup value will be replaced with the new one. When updating a default object access permission, if it originally had a forGroup value defined, it will be replaced with the new group. Otherwise, if the default object access permission was defined for a resource class or a property or the combination of both, the permission will be defined for the newly specified group and its previous forResourceClass and forProperty values will be deleted.","title":"Updating a Permission's Group:"},{"location":"DSP-API/03-apis/api-admin/permissions/#updating-a-permissions-scope","text":"PUT: /admin/permissions/<permissionIri>/hasPermissions to change the scope of permissions assigned to an administrative or a default object access permission identified by it IRI, <permissionIri> . The request body must contain the new set of permission types as below: { \"hasPermissions\":[{\"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\",\"name\":\"D\",\"permissionCode\":7}] } Each permission item given in hasPermissions , must contain the necessary parameters with respect to the type of the permission. For example, if you wish to change the scope of an administrative permission, follow the guidelines for the content of its hasPermissions property. Similarly, if you wish to change the scope of a default object access permission, follow the guidelines given about the content of its hasPermissions property.","title":"Updating a Permission's Scope:"},{"location":"DSP-API/03-apis/api-admin/permissions/#updating-a-default-object-access-permissions-resource-class","text":"PUT: /admin/permissions/<doap_permissionIri>/resourceClass to change the resource class for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object acceess permission. The IRI of the new resource class must be given in the request body as: { \"forResourceClass\": \"http://www.knora.org/ontology/0803/incunabula#book\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given resource class instead of the group. That means the value of the forGroup will be deleted.","title":"Updating a Default Object Access Permission's Resource Class:"},{"location":"DSP-API/03-apis/api-admin/permissions/#updating-a-default-object-access-permissions-property","text":"PUT: /admin/permissions/<doap_permissionIri>/property to change the property for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object access permission. The IRI of the new property must be given in the request body as: { \"forProperty\":\"http://www.knora.org/ontology/00FF/images#titel\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given property instead of the group. That means the value of the forGroup will be deleted.","title":"Updating a Default Object Access Permission's Property:"},{"location":"DSP-API/03-apis/api-admin/permissions/#deleting-a-permission","text":"DELETE: /admin/permissions/<permissionIri> to delete an administrative, or a default object access permission. The IRI of the permission must be given in encoded form.","title":"Deleting a permission:"},{"location":"DSP-API/03-apis/api-admin/projects/","text":"Projects Endpoint Endpoint Overview Project Operations: GET: /admin/projects : return all projects POST: /admin/projects : create a new project GET: /admin/projects/[iri | shortname | shortcode]/<identifier> : returns a single project identified either through iri, shortname, or shortcode PUT: /admin/projects/iri/<identifier> : update a project identified by iri DELETE: /admin/projects/iri/<identifier> : update project status to false GET: /admin/projects/iri/<identifier>/AllData : returns a TriG file containing the project's data Project Member Operations: GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/members : returns all members part of a project identified through iri, shortname or shortcode Project Admin Member Operations: GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/admin-members : returns all admin members part of a project identified through iri, shortname or shortcode Project Keyword Operations: GET: /admin/projects/Keywords : returns all unique keywords for all projects as a list GET: /admin/projects/iri/<identifier>/Keywords : returns all keywords for a single project Project Restricted View Settings Operations: GET: /admin/projects/iri/<identifier>/RestrictedViewSettings : returns the project's restricted view settings Project Operations Create a new project: Required permission: SystemAdmin Required information: shortcode (unique, 4-digits) shortname (unique; it should be in the form of a xsd:NCNAME and it should be URL safe.) description (collection of descriptions as strings with language tag.) keywords (collection of keywords) status (true, if project is active. false, if project is inactive) selfjoin Optional information: longname, logo Returns information about the newly created project Remark: There are two distinct use cases / payload combination: (1) change ontology and data graph: ontologygraph, datagraph, (2) basic project information: shortcode, shortname, longname, description, keywords, logo, institution, status, selfjoin POST: /admin/projects/ BODY: { \"shortname\": \"newproject\", \"longname\": \"project longname\", \"description\": [{\"value\": \"project description\", \"language\": \"en\"}], \"keywords\": [\"test project\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false } Additionally, each project can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/projects/9TaSVMUuiRhQsuWHDPr8rw\", \"shortname\": \"newprojectWithIri\", \"shortcode\": \"3333\", \"longname\": \"new project with a custom IRI\", \"description\": [{\"value\": \"a project created with a custom IRI\", \"language\": \"en\"}], \"keywords\": [\"projectWithIRI\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false } Default set of permissions for a new project: When a new project is created, following default permissions are added to its admins and members: - ProjectAdmin group receives an administrative permission to do all project level operations and to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForAdmin ProjectAdmin group also gets a default object access permission to change rights, delete, modify, view, and restricted view of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForAdmin ProjectMember group receives an administrative permission to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForMember ProjectMember group also gets a default object access permission to modify, view, and restricted view of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForMember Update project information: Required permission: SystemAdmin / ProjectAdmin Changeable information: shortname, longname, description, keywords, logo, status, selfjoin. The payload must at least contain a new value for one of these properties. TypeScript Docs: projectFormats - ChangeProjectApiRequestV1 PUT: /admin/projects/iri/<projectIri> BODY: { \"shortname\": \"newproject\", \"longname\": \"project longname\", \"description\": [{\"value\": \"a new description\", \"language\": \"en\"}], \"keywords\": [\"a new key\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false } Delete project (update project status): Required permission: SystemAdmin / ProjectAdmin Remark: The same as updating a project and changing status to false . To un-delete, set status to true . DELETE: /admin/projects/iri/<projectIri> BODY: empty Dump project data: Returns a TriG file containing the project's ontologies, resource data, admin data, and permissions. Required permission: SystemAdmin / ProjectAdmin Required information: project IRI GET: /admin/projects/iri/<identifier>/AllData Project Member Operations Get project members: Required permission: SystemAdmin / ProjectAdmin Required information: project identifier GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/members Project Admin Member Operations Get project members: Required permission: SystemAdmin / ProjectAdmin Required information: project identifier GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/admin-members Restricted View Settings Operations Operates on the following properties: - knora-admin:projectRestrictedViewSize - takes the IIIF size value - knora-admin:projectRestrictedViewWatermark - takes the path to the watermark image. Currently not used. Get the restricted view settings: Required permission: ProjectAdmin Required information: identifier . The identifier can be the project's IRI, shortname or shortcode. GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/RestrictedViewSettings Example Data The following is an example for project information stored in the admin named graph: <http://rdfh.ch/projects/00FF> rdf:type knora-admin:knoraProject ; knora-admin:projectShortname \"images\"^^xsd:string ; knora-admin:projectShortcode \"00FF\"^^xsd:string ; knora-admin:projectLongname \"Image Collection Demo\"^^xsd:string ; knora-admin:projectDescription \"A demo project of a collection of images\"@en ; knora-admin:projectKeyword \"images\"^^xsd:string, \"collection\"^^xsd:string ; knora-admin:projectRestrictedViewSize \"!512,512\"^^xsd:string ; knora-admin:projectRestrictedViewWatermark \"path_to_image\"^^xsd:string ; knora-admin:belongsToInstitution <http://rdfh.ch/institutions/dhlab-basel> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean .","title":"Projects Endpoint"},{"location":"DSP-API/03-apis/api-admin/projects/#projects-endpoint","text":"","title":"Projects Endpoint"},{"location":"DSP-API/03-apis/api-admin/projects/#endpoint-overview","text":"Project Operations: GET: /admin/projects : return all projects POST: /admin/projects : create a new project GET: /admin/projects/[iri | shortname | shortcode]/<identifier> : returns a single project identified either through iri, shortname, or shortcode PUT: /admin/projects/iri/<identifier> : update a project identified by iri DELETE: /admin/projects/iri/<identifier> : update project status to false GET: /admin/projects/iri/<identifier>/AllData : returns a TriG file containing the project's data Project Member Operations: GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/members : returns all members part of a project identified through iri, shortname or shortcode Project Admin Member Operations: GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/admin-members : returns all admin members part of a project identified through iri, shortname or shortcode Project Keyword Operations: GET: /admin/projects/Keywords : returns all unique keywords for all projects as a list GET: /admin/projects/iri/<identifier>/Keywords : returns all keywords for a single project Project Restricted View Settings Operations: GET: /admin/projects/iri/<identifier>/RestrictedViewSettings : returns the project's restricted view settings","title":"Endpoint Overview"},{"location":"DSP-API/03-apis/api-admin/projects/#project-operations","text":"","title":"Project Operations"},{"location":"DSP-API/03-apis/api-admin/projects/#create-a-new-project","text":"Required permission: SystemAdmin Required information: shortcode (unique, 4-digits) shortname (unique; it should be in the form of a xsd:NCNAME and it should be URL safe.) description (collection of descriptions as strings with language tag.) keywords (collection of keywords) status (true, if project is active. false, if project is inactive) selfjoin Optional information: longname, logo Returns information about the newly created project Remark: There are two distinct use cases / payload combination: (1) change ontology and data graph: ontologygraph, datagraph, (2) basic project information: shortcode, shortname, longname, description, keywords, logo, institution, status, selfjoin POST: /admin/projects/ BODY: { \"shortname\": \"newproject\", \"longname\": \"project longname\", \"description\": [{\"value\": \"project description\", \"language\": \"en\"}], \"keywords\": [\"test project\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false } Additionally, each project can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/projects/9TaSVMUuiRhQsuWHDPr8rw\", \"shortname\": \"newprojectWithIri\", \"shortcode\": \"3333\", \"longname\": \"new project with a custom IRI\", \"description\": [{\"value\": \"a project created with a custom IRI\", \"language\": \"en\"}], \"keywords\": [\"projectWithIRI\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false }","title":"Create a new project:"},{"location":"DSP-API/03-apis/api-admin/projects/#default-set-of-permissions-for-a-new-project","text":"When a new project is created, following default permissions are added to its admins and members: - ProjectAdmin group receives an administrative permission to do all project level operations and to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForAdmin ProjectAdmin group also gets a default object access permission to change rights, delete, modify, view, and restricted view of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForAdmin ProjectMember group receives an administrative permission to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForMember ProjectMember group also gets a default object access permission to modify, view, and restricted view of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForMember","title":"Default set of permissions for a new project:"},{"location":"DSP-API/03-apis/api-admin/projects/#update-project-information","text":"Required permission: SystemAdmin / ProjectAdmin Changeable information: shortname, longname, description, keywords, logo, status, selfjoin. The payload must at least contain a new value for one of these properties. TypeScript Docs: projectFormats - ChangeProjectApiRequestV1 PUT: /admin/projects/iri/<projectIri> BODY: { \"shortname\": \"newproject\", \"longname\": \"project longname\", \"description\": [{\"value\": \"a new description\", \"language\": \"en\"}], \"keywords\": [\"a new key\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false }","title":"Update project information:"},{"location":"DSP-API/03-apis/api-admin/projects/#delete-project-update-project-status","text":"Required permission: SystemAdmin / ProjectAdmin Remark: The same as updating a project and changing status to false . To un-delete, set status to true . DELETE: /admin/projects/iri/<projectIri> BODY: empty","title":"Delete project (update project status):"},{"location":"DSP-API/03-apis/api-admin/projects/#dump-project-data","text":"Returns a TriG file containing the project's ontologies, resource data, admin data, and permissions. Required permission: SystemAdmin / ProjectAdmin Required information: project IRI GET: /admin/projects/iri/<identifier>/AllData","title":"Dump project data:"},{"location":"DSP-API/03-apis/api-admin/projects/#project-member-operations","text":"","title":"Project Member Operations"},{"location":"DSP-API/03-apis/api-admin/projects/#get-project-members","text":"Required permission: SystemAdmin / ProjectAdmin Required information: project identifier GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/members","title":"Get project members:"},{"location":"DSP-API/03-apis/api-admin/projects/#project-admin-member-operations","text":"","title":"Project Admin Member Operations"},{"location":"DSP-API/03-apis/api-admin/projects/#get-project-members_1","text":"Required permission: SystemAdmin / ProjectAdmin Required information: project identifier GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/admin-members","title":"Get project members:"},{"location":"DSP-API/03-apis/api-admin/projects/#restricted-view-settings-operations","text":"Operates on the following properties: - knora-admin:projectRestrictedViewSize - takes the IIIF size value - knora-admin:projectRestrictedViewWatermark - takes the path to the watermark image. Currently not used.","title":"Restricted View Settings Operations"},{"location":"DSP-API/03-apis/api-admin/projects/#get-the-restricted-view-settings","text":"Required permission: ProjectAdmin Required information: identifier . The identifier can be the project's IRI, shortname or shortcode. GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/RestrictedViewSettings","title":"Get the restricted view settings:"},{"location":"DSP-API/03-apis/api-admin/projects/#example-data","text":"The following is an example for project information stored in the admin named graph: <http://rdfh.ch/projects/00FF> rdf:type knora-admin:knoraProject ; knora-admin:projectShortname \"images\"^^xsd:string ; knora-admin:projectShortcode \"00FF\"^^xsd:string ; knora-admin:projectLongname \"Image Collection Demo\"^^xsd:string ; knora-admin:projectDescription \"A demo project of a collection of images\"@en ; knora-admin:projectKeyword \"images\"^^xsd:string, \"collection\"^^xsd:string ; knora-admin:projectRestrictedViewSize \"!512,512\"^^xsd:string ; knora-admin:projectRestrictedViewWatermark \"path_to_image\"^^xsd:string ; knora-admin:belongsToInstitution <http://rdfh.ch/institutions/dhlab-basel> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean .","title":"Example Data"},{"location":"DSP-API/03-apis/api-admin/stores/","text":"Stores Endpoint","title":"Stores Endpoint"},{"location":"DSP-API/03-apis/api-admin/stores/#stores-endpoint","text":"","title":"Stores Endpoint"},{"location":"DSP-API/03-apis/api-admin/users/","text":"Users Endpoint Endpoint Overview User Operations: GET: /admin/users : return all users GET: /admin/users/[iri | email | username]/<identifier> : return single user identified by [IRI | email | username] POST: /admin/users/ : create new user PUT: /admin/users/iri/<userIri>/BasicUserInformation : update user's basic user information PUT: /admin/users/iri/<userIri>/Password : update user's password PUT: /admin/users/iri/<userIri>/Status : update user's status DELETE: /admin/users/iri/<userIri> : delete user (set status to false) User's project membership operations GET: /admin/users/iri/<userIri>/project-memberships : get user's project memberships POST: /admin/users/iri/<userIri>/project-memberships/<projectIri> : add user to project (to ProjectMember group) DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> : remove user from project (to ProjectMember group) User's group membership operations GET: /admin/users/iri/<userIri>/project-admin-memberships : get user's ProjectAdmin group memberships POST: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : add user to ProjectAdmin group DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : remove user from ProjectAdmin group GET: /admin/users/iri/<userIri>/group-memberships : get user's normal group memberships POST: /admin/users/iri/<userIri>/group-memberships/<groupIri> : add user to normal group DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> : remove user from normal group PUT: /admin/users/iri/<userIri>/SystemAdmin : Add/remove user to/from SystemAdmin group User Operations Get users Required permission: SystemAdmin GET: /admin/users Get user Required permission: SystemAdmin / self: for getting all properties All other users: for getting only the public properties ( givenName and familyName ) GET: /admin/users/[iri | email | username ]/<identifier> Create user Required permission: none, self-registration is allowed Required information: email (unique), given name, family name, password, status, systemAdmin Username restrictions: 4 - 50 characters long Only contains alphanumeric characters, underscore and dot. Underscore and dot can't be at the end or start of a username Underscore or dot can't be used multiple times in a row Returns information about the newly created user TypeScript Docs: userFormats - CreateUserApiRequestV1 POST: /admin/users BODY: { \"email\": \"donald.duck@example.org\", \"givenName\": \"Donald\", \"familyName\": \"Duck\", \"username\": \"donald.duck\", \"password\": \"test\", \"status\": true, \"lang\": \"en\", \"systemAdmin\": false } Additionally, each user can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/users/FnjFfIQFVDvI7ex8zSyUyw\", \"email\": \"donald.duck@example.org\", \"givenName\": \"Donald\", \"familyName\": \"Duck\", \"username\": \"donald.duck\", \"password\": \"test\", \"status\": true, \"lang\": \"en\", \"systemAdmin\": false } Update basic user information** Required permission: SystemAdmin / self Changeable information: username, email, given name, family name, password, status, SystemAdmin membership TypeScript Docs: userFormats - ChangeUserApiRequestADM PUT: /admin/users/iri/<userIri>/BasicUserInformation BODY: { \"username\": \"donald.big.duck\", \"email\": \"donald.big.duck@example.org\", \"givenName\": \"Big Donald\", \"familyName\": \"Duckmann\", \"lang\": \"de\" } Update user's password Required permission: SystemAdmin / self Changeable information: password PUT: /admin/users/iri/<userIri>/Password BODY: { \"requesterPassword\": \"test\", \"newPassword\": \"test1234\" } Delete user Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . PUT: /admin/users/iri/<userIri>/Status BODY: { \"status\": false // true or false } Delete user (-\\update user)** Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . DELETE: /admin/users/iri/<userIri> BODY: empty User's project membership operations Get user's project memberships GET: /admin/users/iri/<userIri>/project-memberships Add/remove user to/from project Required permission: SystemAdmin / ProjectAdmin / self (if project self-assignment is enabled) Required information: project IRI, user IRI Effects: knora-base:isInProject user property POST / DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> BODY: empty User's group membership operations Get user's project admin memberships GET: /admin/users/iri/<userIri>/project-admin-memberships Add/remove user to/from project admin group Required permission: SystemAdmin / ProjectAdmin Required information: project IRI, user IRI Effects: knora-base:isInProjectAdminGroup user property POST / DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> BODY: empty Get user's group memberships** GET: /admin/users/iri/<userIri>/group-memberships Add/remove user to/from 'normal' group (not SystemAdmin or ProjectAdmin ) Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) / User (if group self-assignment is enabled) Required information: group IRI, user IRI Effects: knora-base:isInGroup POST / DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> BODY: empty Add/remove user to/from system admin group Required permission: SystemAdmin / self Effects property: knora-base:isInSystemAdminGroup with value true or false PUT: /admin/users/iri/<userIri>/SystemAdmin BODY: { \"systemAdmin\": false } Example Data The following is an example for user information stored in the admin named graph: <http://rdfh.ch/users/c266a56709> rdf:type knora-admin:User ; knora-admin:username \"user01.user1\"^^xsd:string ; knora-admin:email \"user01.user1@example.com\"^^xsd:string ; knora-admin:givenName \"User01\"^^xsd:string ; knora-admin:familyName \"User\"^^xsd:string ; knora-admin:password \"$e0801$FGl9FDIWw+D83OeNPGmD9u2VTqIkJopIQECgmb2DSWQLS0TeKSvYoWAkbEv6KxePPlCI3CP9MmVHuvnWv8/kag==$mlegCYdGXt+ghuo8i0rLjgOiNnGDW604Q5g/v7zwBPU=\"^^xsd:string ; knora-admin:preferredLanguage \"de\"^^xsd:string ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:isInProject <http://rdfh.ch/projects/00FF> ; knora-admin:isInSystemAdminGroup \"false\"^^xsd:boolean ; knora-admin:isInProjectAdminGroup <http://rdfh.ch/projects/00FF> .","title":"Users Endpoint"},{"location":"DSP-API/03-apis/api-admin/users/#users-endpoint","text":"","title":"Users Endpoint"},{"location":"DSP-API/03-apis/api-admin/users/#endpoint-overview","text":"User Operations: GET: /admin/users : return all users GET: /admin/users/[iri | email | username]/<identifier> : return single user identified by [IRI | email | username] POST: /admin/users/ : create new user PUT: /admin/users/iri/<userIri>/BasicUserInformation : update user's basic user information PUT: /admin/users/iri/<userIri>/Password : update user's password PUT: /admin/users/iri/<userIri>/Status : update user's status DELETE: /admin/users/iri/<userIri> : delete user (set status to false) User's project membership operations GET: /admin/users/iri/<userIri>/project-memberships : get user's project memberships POST: /admin/users/iri/<userIri>/project-memberships/<projectIri> : add user to project (to ProjectMember group) DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> : remove user from project (to ProjectMember group) User's group membership operations GET: /admin/users/iri/<userIri>/project-admin-memberships : get user's ProjectAdmin group memberships POST: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : add user to ProjectAdmin group DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : remove user from ProjectAdmin group GET: /admin/users/iri/<userIri>/group-memberships : get user's normal group memberships POST: /admin/users/iri/<userIri>/group-memberships/<groupIri> : add user to normal group DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> : remove user from normal group PUT: /admin/users/iri/<userIri>/SystemAdmin : Add/remove user to/from SystemAdmin group","title":"Endpoint Overview"},{"location":"DSP-API/03-apis/api-admin/users/#user-operations","text":"","title":"User Operations"},{"location":"DSP-API/03-apis/api-admin/users/#get-users","text":"Required permission: SystemAdmin GET: /admin/users","title":"Get users"},{"location":"DSP-API/03-apis/api-admin/users/#get-user","text":"Required permission: SystemAdmin / self: for getting all properties All other users: for getting only the public properties ( givenName and familyName ) GET: /admin/users/[iri | email | username ]/<identifier>","title":"Get user"},{"location":"DSP-API/03-apis/api-admin/users/#create-user","text":"Required permission: none, self-registration is allowed Required information: email (unique), given name, family name, password, status, systemAdmin Username restrictions: 4 - 50 characters long Only contains alphanumeric characters, underscore and dot. Underscore and dot can't be at the end or start of a username Underscore or dot can't be used multiple times in a row Returns information about the newly created user TypeScript Docs: userFormats - CreateUserApiRequestV1 POST: /admin/users BODY: { \"email\": \"donald.duck@example.org\", \"givenName\": \"Donald\", \"familyName\": \"Duck\", \"username\": \"donald.duck\", \"password\": \"test\", \"status\": true, \"lang\": \"en\", \"systemAdmin\": false } Additionally, each user can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/users/FnjFfIQFVDvI7ex8zSyUyw\", \"email\": \"donald.duck@example.org\", \"givenName\": \"Donald\", \"familyName\": \"Duck\", \"username\": \"donald.duck\", \"password\": \"test\", \"status\": true, \"lang\": \"en\", \"systemAdmin\": false }","title":"Create user"},{"location":"DSP-API/03-apis/api-admin/users/#update-basic-user-information","text":"Required permission: SystemAdmin / self Changeable information: username, email, given name, family name, password, status, SystemAdmin membership TypeScript Docs: userFormats - ChangeUserApiRequestADM PUT: /admin/users/iri/<userIri>/BasicUserInformation BODY: { \"username\": \"donald.big.duck\", \"email\": \"donald.big.duck@example.org\", \"givenName\": \"Big Donald\", \"familyName\": \"Duckmann\", \"lang\": \"de\" }","title":"Update basic user information**"},{"location":"DSP-API/03-apis/api-admin/users/#update-users-password","text":"Required permission: SystemAdmin / self Changeable information: password PUT: /admin/users/iri/<userIri>/Password BODY: { \"requesterPassword\": \"test\", \"newPassword\": \"test1234\" }","title":"Update user's password"},{"location":"DSP-API/03-apis/api-admin/users/#delete-user","text":"Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . PUT: /admin/users/iri/<userIri>/Status BODY: { \"status\": false // true or false }","title":"Delete user"},{"location":"DSP-API/03-apis/api-admin/users/#delete-user-update-user","text":"Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . DELETE: /admin/users/iri/<userIri> BODY: empty","title":"Delete user (-\\update user)**"},{"location":"DSP-API/03-apis/api-admin/users/#users-project-membership-operations","text":"","title":"User's project membership operations"},{"location":"DSP-API/03-apis/api-admin/users/#get-users-project-memberships","text":"GET: /admin/users/iri/<userIri>/project-memberships","title":"Get user's project memberships"},{"location":"DSP-API/03-apis/api-admin/users/#addremove-user-tofrom-project","text":"Required permission: SystemAdmin / ProjectAdmin / self (if project self-assignment is enabled) Required information: project IRI, user IRI Effects: knora-base:isInProject user property POST / DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> BODY: empty","title":"Add/remove user to/from project"},{"location":"DSP-API/03-apis/api-admin/users/#users-group-membership-operations","text":"","title":"User's group membership operations"},{"location":"DSP-API/03-apis/api-admin/users/#get-users-project-admin-memberships","text":"GET: /admin/users/iri/<userIri>/project-admin-memberships","title":"Get user's project admin memberships"},{"location":"DSP-API/03-apis/api-admin/users/#addremove-user-tofrom-project-admin-group","text":"Required permission: SystemAdmin / ProjectAdmin Required information: project IRI, user IRI Effects: knora-base:isInProjectAdminGroup user property POST / DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> BODY: empty","title":"Add/remove user to/from project admin group"},{"location":"DSP-API/03-apis/api-admin/users/#get-users-group-memberships","text":"GET: /admin/users/iri/<userIri>/group-memberships","title":"Get user's group memberships**"},{"location":"DSP-API/03-apis/api-admin/users/#addremove-user-tofrom-normal-group-not-systemadmin-or-projectadmin","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) / User (if group self-assignment is enabled) Required information: group IRI, user IRI Effects: knora-base:isInGroup POST / DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> BODY: empty","title":"Add/remove user to/from 'normal' group (not SystemAdmin or ProjectAdmin)"},{"location":"DSP-API/03-apis/api-admin/users/#addremove-user-tofrom-system-admin-group","text":"Required permission: SystemAdmin / self Effects property: knora-base:isInSystemAdminGroup with value true or false PUT: /admin/users/iri/<userIri>/SystemAdmin BODY: { \"systemAdmin\": false }","title":"Add/remove user to/from system admin group"},{"location":"DSP-API/03-apis/api-admin/users/#example-data","text":"The following is an example for user information stored in the admin named graph: <http://rdfh.ch/users/c266a56709> rdf:type knora-admin:User ; knora-admin:username \"user01.user1\"^^xsd:string ; knora-admin:email \"user01.user1@example.com\"^^xsd:string ; knora-admin:givenName \"User01\"^^xsd:string ; knora-admin:familyName \"User\"^^xsd:string ; knora-admin:password \"$e0801$FGl9FDIWw+D83OeNPGmD9u2VTqIkJopIQECgmb2DSWQLS0TeKSvYoWAkbEv6KxePPlCI3CP9MmVHuvnWv8/kag==$mlegCYdGXt+ghuo8i0rLjgOiNnGDW604Q5g/v7zwBPU=\"^^xsd:string ; knora-admin:preferredLanguage \"de\"^^xsd:string ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:isInProject <http://rdfh.ch/projects/00FF> ; knora-admin:isInSystemAdminGroup \"false\"^^xsd:boolean ; knora-admin:isInProjectAdminGroup <http://rdfh.ch/projects/00FF> .","title":"Example Data"},{"location":"DSP-API/03-apis/api-util/","text":"Knora Util API The Knora Util API allows retrieving information about the Knora-stack itself. It consists of the following elements: * Health : Knora health state * Version : Versions of used stack components","title":"Index"},{"location":"DSP-API/03-apis/api-util/#knora-util-api","text":"The Knora Util API allows retrieving information about the Knora-stack itself. It consists of the following elements: * Health : Knora health state * Version : Versions of used stack components","title":"Knora Util API"},{"location":"DSP-API/03-apis/api-util/health/","text":"Health","title":"Health"},{"location":"DSP-API/03-apis/api-util/health/#health","text":"","title":"Health"},{"location":"DSP-API/03-apis/api-util/version/","text":"Version The version endpoint provides the versions of the used components in the Knora-stack. The response has the type application/json and contains the following information: name: has the value \"version\" version numbers for the following components: akkaHttp gdbFree gdbSE sbt scala sipi webapi Example request GET /version Example response { \"akkaHttp\": \"10.1.7\", \"gdbFree\": \"8.10.0-free\", \"gdbSE\": \"8.5.0-se\", \"name\": \"version\", \"sbt\": \"1.2.8\", \"scala\": \"2.12.8\", \"sipi\": \"v2.0.1\", \"webapi\": \"10.0.0-7-gc5a72b3-SNAPSHOT\" }","title":"Version"},{"location":"DSP-API/03-apis/api-util/version/#version","text":"The version endpoint provides the versions of the used components in the Knora-stack. The response has the type application/json and contains the following information: name: has the value \"version\" version numbers for the following components: akkaHttp gdbFree gdbSE sbt scala sipi webapi","title":"Version"},{"location":"DSP-API/03-apis/api-util/version/#example-request","text":"GET /version","title":"Example request"},{"location":"DSP-API/03-apis/api-util/version/#example-response","text":"{ \"akkaHttp\": \"10.1.7\", \"gdbFree\": \"8.10.0-free\", \"gdbSE\": \"8.5.0-se\", \"name\": \"version\", \"sbt\": \"1.2.8\", \"scala\": \"2.12.8\", \"sipi\": \"v2.0.1\", \"webapi\": \"10.0.0-7-gc5a72b3-SNAPSHOT\" }","title":"Example response"},{"location":"DSP-API/03-apis/api-v1/","text":"DSP-API v1 Introduction Authentication Reading and Searching Resources XML to Standoff Mapping Adding Resources Reading and Searching Resources Reading Values Adding a Value Changing a Value Deleting Resources and Values","title":"Index"},{"location":"DSP-API/03-apis/api-v1/#dsp-api-v1","text":"Introduction Authentication Reading and Searching Resources XML to Standoff Mapping Adding Resources Reading and Searching Resources Reading Values Adding a Value Changing a Value Deleting Resources and Values","title":"DSP-API v1"},{"location":"DSP-API/03-apis/api-v1/adding-resources/","text":"Adding Resources To create a resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the resources path segment: HTTP POST to http://host/v1/resources Unlike in the case of GET requests, the request body consists of JSON describing the resource to be created. Creating resources requires authentication since only known users may add resources. Adding Resources Without Image Files The format of the JSON used to create a resource without an image file is described in the TypeScript interface createResourceWithoutRepresentationRequest in module createResourceFormats . It requires the IRI of the resource class the new resource belongs to, a label describing the new resource, the IRI of the project the new resource belongs to, and the properties to be assigned to the new resource. The request header's content type has to be set to application/json . Adding Resources with Image Files The first step is to upload an image file to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The TOKEN is the sid returned by Knora in response to the client's login request (see Authentication ). The request must contain a body part providing the file as well as a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi will then convert the uploaded image file to JPEG 2000 format and store it in a temporary location. If this is successful, it will return a JSON response that looks something like this: { \"uploadedFiles\": [{ \"originalFilename\": \"manuscript-1234-page-1.tiff\", \"internalFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" }] } This provides: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file The client may now wish to get a thumbnail of the uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding the filename and IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image whose width and height are at most 128 pixels wide, you would request http://sipihost/tmp/3UIsXH9bP0j-BV0D4sN51Xz.jp2/full/!128,128/0/default.jpg . The request to Knora works similarly to Adding Resources Without Image Files , with the addition of file , whose value is the internalFilename that Sipi returned. See the TypeScript interface createResourceWithRepresentationRequest in module createResourceFormats for details. The request header's content type must be set to application/json . Response to a Resource Creation When a resource has been successfully created, Knora sends back a JSON containing the new resource's IRI ( res_id ) and its properties. The resource IRI identifies the resource and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface createResourceResponse in module createResourceFormats . Changing a Resource's Label A resource's label can be changed by making a PUT request to the path segments resources/label . The resource's IRI has to be provided in the URL (as its last segment). The new label has to submitted as JSON in the HTTP request's body. HTTP PUT to http://host/v1/resources/label/resourceIRI The JSON format of the request is described in the TypeScript interface changeResourceLabelRequest in module createResourceFormats . The response is described in the TypeScript interface changeResourceLabelResponse in module createResourceFormats . Bulk Import If you have a large amount of data to import into Knora, it can be more convenient to use the bulk import feature than to create resources one by one. In a bulk import operation, you submit an XML document to Knora, describing multiple resources to be created. This is especially useful if the resources to be created have links to one another. Knora checks the entire request for consistency as as a whole, and performs the update in a single database transaction. Only system or project administrators may use the bulk import. The procedure for using this feature is as follows (see the example below ). Make an HTTP GET request to Knora to get XML schemas describing the XML to be provided for the import. If you are importing image files, upload files to Sipi . Generate an XML import document representing the data to be imported, following the Knora import schemas that were generated in step 1. You will probably want to write a script to do this. Knora is not involved in this step. If you are also importing image files, this XML document needs to contain the filenames that Sipi returned for the files you uploaded in step 2. Validate your XML import document , using an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen . This will help ensure that the data you submit to Knora is correct. Knora is not involved in this step. Submit the XML import document to Knora . In this procedure, the person responsible for generating the XML import data need not be familiar with RDF or with the ontologies involved. When Knora receives an XML import, it validates it first using the relevant XML schemas, and then using the same internal checks that it performs when creating any resource. The details of the XML import format are illustrated in the following examples. Bulk Import Example Suppose we have a project with existing data (but no image files), which we want to import into Knora. We have created an ontology called http://www.knora.org/ontology/0801/biblio for the project, and this ontology also uses definitions from another ontology, called http://www.knora.org/ontology/0801/beol . 1. Get XML Schemas To get XML schemas for an import, we use the following route, specifying the (URL-encoded) IRI of our project's main ontology (in this case http://www.knora.org/ontology/0801/biblio ): HTTP GET to http://host/v1/resources/xmlimportschemas/ontologyIRI In our example, the URL could be: http://localhost:3333/v1/resources/xmlimportschemas/http%3A%2F%2Fwww.knora.org%2Fontology%2F0801%2Fbiblio This returns a Zip archive called p0801-biblio-xml-schemas.zip , containing three files: p0801-biblio.xsd : The schema for our main ontology. p0801-beol.xsd : A schema for another ontology that our main ontology depends on. knoraXmlImport.xsd : The standard Knora XML import schema, used by all XML imports. 2. Upload Files to Sipi See Upload Files to Sipi in the DSP-API v2 documentation. 3. Generate XML Import Document We now convert our existing data to XML, probably by writing a custom script. The resulting XML import document could look like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol=\"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <p0801-beol:person id=\"abel\"> <knoraXmlImport:label>Niels Henrik Abel</knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType=\"richtext_value\">Abel</p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType=\"richtext_value\">Niels Henrik</p0801-beol:hasGivenName> <p0801-beol:personHasTitle knoraType=\"richtext_value\" lang=\"en\">Sir</p0801-beol:personHasTitle> </p0801-beol:person> <p0801-beol:person id=\"holmes\"> <knoraXmlImport:label>Sherlock Holmes</knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType=\"richtext_value\">Holmes</p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType=\"richtext_value\">Sherlock</p0801-beol:hasGivenName> </p0801-beol:person> <p0801-biblio:Journal id=\"math_intelligencer\"> <knoraXmlImport:label>Math Intelligencer</knoraXmlImport:label> <p0801-biblio:hasName knoraType=\"richtext_value\">Math Intelligencer</p0801-biblio:hasName> </p0801-biblio:Journal> <p0801-biblio:JournalArticle id=\"strings_in_the_16th_and_17th_centuries\" creationDate=\"2019-01-09T15:45:54Z\"> <knoraXmlImport:label>Strings in the 16th and 17th Centuries</knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType=\"richtext_value\" mapping_id=\"http://rdfh.ch/standoff/mappings/StandardMapping\"> <text xmlns=\"\">The most <strong>interesting</strong> article in <a class=\"salsah-link\" href=\"ref:math_intelligencer\">Math Intelligencer</a>.</text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType=\"richtext_value\">73</p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType=\"link_value\" target=\"math_intelligencer\" linkType=\"ref\"/> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType=\"richtext_value\">27</p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"ref\" target=\"abel\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"ref\" target=\"holmes\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType=\"date_value\">GREGORIAN:1976</p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\" lang=\"en\">Strings in the 16th and 17th Centuries</p0801-biblio:publicationHasTitle> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\">An alternate title</p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType=\"richtext_value\">48</p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> This illustrates several aspects of XML imports: The root XML element must be knoraXmlImport:resources . There is an XML namespace corresponding each ontology used in the import. These namespaces can be found in the XML schema files returned by Knora. We have copied and pasted xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" from the main XML schema, p0801-biblio.xsd . This enables the Knora API server to identify the main ontology we are using. We have used xsi:schemaLocation to indicate the main schema's namespace and filename. If we put our XML document in the same directory as the schemas, and we run an XML validator to check the XML, it should load the schemas. The child elements of knoraXmlImport:resources represent resources to be created. The order of these elements is unimportant. Each resource must have an ID, which must be an XML NCName , and must be unique within the file. These IDs are used only during the import, and will not be stored in the triplestore. Each resource can optionally have a creationDate attribute, which can be an xsd:dateTime or an xsd:dateTimeStamp . If creationDate is not supplied, the current time is used. The first child element of each resource must be a knoraXmlImport:label , which will be stored as the resource's rdfs:label . Optionally, the second child element of a resource can provide metadata about a file to be attached to the resource (see bulk-import-with-digital-representations). The remaining child elements of each resource represent its property values. These must be sorted in alphabetical order by property name. If a property has mutliple values, these are represented as multiple adjacent property elements. The type of each value must be specified using the attribute knoraType . A link to another resource described in the XML import is represented as a child element of a property element, with attributes knoraType=\"link_value\" and linkType=\"ref\" , and a target attribute containing the ID of the target resource. There is a specfic syntax for referring to properties from other ontologies. In the example, p0801-beol:comment is defined in the ontology http://www.knora.org/ontology/0001/beol . In the XML, we refer to it as p0801-biblio:p0801-beol__comment . A text value can contain XML markup. If it does: The text value element must have the attribute mapping_id , specifying a mapping from XML to standoff markup (see XML-to-standoff-mapping). It is necessary to specify the appropriate XML namespace (in this case the null namespace, xmlns=\"\" ) for the XML markup in the text value. The XML markup in the text value will not be validated by the schema. In an XML tag that is mapped to a standoff link tag, the link target can refer either to the IRI of a resoruce that already exists in the triplestore, or to the ID of a resource described in the import. If a link points to a resource described in the import, the ID of the target resource must be prefixed with ref: . In the example above, using the standard mapping, the standoff link to math_intelligencer has the target ref:math_intelligencer . A text value can have a lang attribute, whose value is an ISO 639-1 code specifying the language of the text. 4. Validate XML Import Document You can use an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen , to check that your XML import document is valid according to the schemas you got from Knora. For example, using Saxon: java -cp ./saxon9ee.jar com.saxonica.Validate -xsd:p0801-biblio.xsd -s:data.xml 5. Submit XML Import Document to Knora To create these resources in Knora, make an HTTP post request with the XML import document as the request body. The URL must specify the (URL-encoded) IRI of the project in which the resources should be created: HTTP POST to http://host/v1/resources/xmlimport/projectIRI For example, using curl : curl -v -u root@example.com:test --data @data.xml --header \"Content-Type: application/xml\" http://localhost:3333/v1/resources/xmlimport/http%3A%2F%2Frdfh.ch%2Fprojects%2F0801 Bulk Import with Links to Existing Resources Having run the import in the previous example, we can import more data with links to the data that is now in the triplestore: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol=\"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <p0801-biblio:JournalArticle id=\"strings_in_the_18th_century\"> <knoraXmlImport:label>Strings in the 18th Century</knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType=\"richtext_value\" mapping_id=\"http://rdfh.ch/standoff/mappings/StandardMapping\"> <text xmlns=\"\">The most <strong>boring</strong> article in <a class=\"salsah-link\" href=\"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\">Math Intelligencer</a>.</text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType=\"richtext_value\">76</p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType=\"link_value\" linkType=\"iri\" target=\"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\"/> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType=\"richtext_value\">27</p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"iri\" target=\"http://rdfh.ch/biblio/c-xMB3qkRs232pWyjdUUvA\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType=\"date_value\">GREGORIAN:1977</p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\">Strings in the 18th Century</p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType=\"richtext_value\">52</p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> Note that in the link elements referring to existing resources, the linkType attribute has the value iri , and the target attribute contains the IRI of the target resource. Bulk Import with Image Files To attach an image file to a resource, we must provide the element knoraXmlImport:file before the property elements. In this element, we must provide a filename attribute, containing the internalFilename that Sipi returned for the file in 2. Upload Files to Sipi . <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/incunabula/xml-import/v1# incunabula.xsd\" xmlns:incunabula=\"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <incunabula:book id=\"test_book\"> <knoraXmlImport:label>a book with one page</knoraXmlImport:label> <incunabula:title knoraType=\"richtext_value\">the title of a book with one page</incunabula:title> </incunabula:book> <incunabula:page id=\"test_page\"> <knoraXmlImport:label>a page with an image</knoraXmlImport:label> <knoraXmlImport:file filename=\"67SEfNU1wK2-CSf5abe2eh3.jp2\"/> <incunabula:origname knoraType=\"richtext_value\">Chlaus</incunabula:origname> <incunabula:pagenum knoraType=\"richtext_value\">1a</incunabula:pagenum> <incunabula:partOf> <incunabula:book knoraType=\"link_value\" linkType=\"ref\" ref=\"test_book\"/> </incunabula:partOf> <incunabula:seqnum knoraType=\"int_value\">1</incunabula:seqnum> </incunabula:page> </knoraXmlImport:resources> During the processing of the bulk import, Knora will ask Sipi for the rest of the file's metadata, and store that metadata in a file value attached to the resource.","title":"Adding Resources"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#adding-resources","text":"To create a resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the resources path segment: HTTP POST to http://host/v1/resources Unlike in the case of GET requests, the request body consists of JSON describing the resource to be created. Creating resources requires authentication since only known users may add resources.","title":"Adding Resources"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#adding-resources-without-image-files","text":"The format of the JSON used to create a resource without an image file is described in the TypeScript interface createResourceWithoutRepresentationRequest in module createResourceFormats . It requires the IRI of the resource class the new resource belongs to, a label describing the new resource, the IRI of the project the new resource belongs to, and the properties to be assigned to the new resource. The request header's content type has to be set to application/json .","title":"Adding Resources Without Image Files"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#adding-resources-with-image-files","text":"The first step is to upload an image file to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The TOKEN is the sid returned by Knora in response to the client's login request (see Authentication ). The request must contain a body part providing the file as well as a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi will then convert the uploaded image file to JPEG 2000 format and store it in a temporary location. If this is successful, it will return a JSON response that looks something like this: { \"uploadedFiles\": [{ \"originalFilename\": \"manuscript-1234-page-1.tiff\", \"internalFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" }] } This provides: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file The client may now wish to get a thumbnail of the uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding the filename and IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image whose width and height are at most 128 pixels wide, you would request http://sipihost/tmp/3UIsXH9bP0j-BV0D4sN51Xz.jp2/full/!128,128/0/default.jpg . The request to Knora works similarly to Adding Resources Without Image Files , with the addition of file , whose value is the internalFilename that Sipi returned. See the TypeScript interface createResourceWithRepresentationRequest in module createResourceFormats for details. The request header's content type must be set to application/json .","title":"Adding Resources with Image Files"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#response-to-a-resource-creation","text":"When a resource has been successfully created, Knora sends back a JSON containing the new resource's IRI ( res_id ) and its properties. The resource IRI identifies the resource and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface createResourceResponse in module createResourceFormats .","title":"Response to a Resource Creation"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#changing-a-resources-label","text":"A resource's label can be changed by making a PUT request to the path segments resources/label . The resource's IRI has to be provided in the URL (as its last segment). The new label has to submitted as JSON in the HTTP request's body. HTTP PUT to http://host/v1/resources/label/resourceIRI The JSON format of the request is described in the TypeScript interface changeResourceLabelRequest in module createResourceFormats . The response is described in the TypeScript interface changeResourceLabelResponse in module createResourceFormats .","title":"Changing a Resource's Label"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#bulk-import","text":"If you have a large amount of data to import into Knora, it can be more convenient to use the bulk import feature than to create resources one by one. In a bulk import operation, you submit an XML document to Knora, describing multiple resources to be created. This is especially useful if the resources to be created have links to one another. Knora checks the entire request for consistency as as a whole, and performs the update in a single database transaction. Only system or project administrators may use the bulk import. The procedure for using this feature is as follows (see the example below ). Make an HTTP GET request to Knora to get XML schemas describing the XML to be provided for the import. If you are importing image files, upload files to Sipi . Generate an XML import document representing the data to be imported, following the Knora import schemas that were generated in step 1. You will probably want to write a script to do this. Knora is not involved in this step. If you are also importing image files, this XML document needs to contain the filenames that Sipi returned for the files you uploaded in step 2. Validate your XML import document , using an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen . This will help ensure that the data you submit to Knora is correct. Knora is not involved in this step. Submit the XML import document to Knora . In this procedure, the person responsible for generating the XML import data need not be familiar with RDF or with the ontologies involved. When Knora receives an XML import, it validates it first using the relevant XML schemas, and then using the same internal checks that it performs when creating any resource. The details of the XML import format are illustrated in the following examples.","title":"Bulk Import"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#bulk-import-example","text":"Suppose we have a project with existing data (but no image files), which we want to import into Knora. We have created an ontology called http://www.knora.org/ontology/0801/biblio for the project, and this ontology also uses definitions from another ontology, called http://www.knora.org/ontology/0801/beol .","title":"Bulk Import Example"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#1-get-xml-schemas","text":"To get XML schemas for an import, we use the following route, specifying the (URL-encoded) IRI of our project's main ontology (in this case http://www.knora.org/ontology/0801/biblio ): HTTP GET to http://host/v1/resources/xmlimportschemas/ontologyIRI In our example, the URL could be: http://localhost:3333/v1/resources/xmlimportschemas/http%3A%2F%2Fwww.knora.org%2Fontology%2F0801%2Fbiblio This returns a Zip archive called p0801-biblio-xml-schemas.zip , containing three files: p0801-biblio.xsd : The schema for our main ontology. p0801-beol.xsd : A schema for another ontology that our main ontology depends on. knoraXmlImport.xsd : The standard Knora XML import schema, used by all XML imports.","title":"1. Get XML Schemas"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#2-upload-files-to-sipi","text":"See Upload Files to Sipi in the DSP-API v2 documentation.","title":"2. Upload Files to Sipi"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#3-generate-xml-import-document","text":"We now convert our existing data to XML, probably by writing a custom script. The resulting XML import document could look like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol=\"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <p0801-beol:person id=\"abel\"> <knoraXmlImport:label>Niels Henrik Abel</knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType=\"richtext_value\">Abel</p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType=\"richtext_value\">Niels Henrik</p0801-beol:hasGivenName> <p0801-beol:personHasTitle knoraType=\"richtext_value\" lang=\"en\">Sir</p0801-beol:personHasTitle> </p0801-beol:person> <p0801-beol:person id=\"holmes\"> <knoraXmlImport:label>Sherlock Holmes</knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType=\"richtext_value\">Holmes</p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType=\"richtext_value\">Sherlock</p0801-beol:hasGivenName> </p0801-beol:person> <p0801-biblio:Journal id=\"math_intelligencer\"> <knoraXmlImport:label>Math Intelligencer</knoraXmlImport:label> <p0801-biblio:hasName knoraType=\"richtext_value\">Math Intelligencer</p0801-biblio:hasName> </p0801-biblio:Journal> <p0801-biblio:JournalArticle id=\"strings_in_the_16th_and_17th_centuries\" creationDate=\"2019-01-09T15:45:54Z\"> <knoraXmlImport:label>Strings in the 16th and 17th Centuries</knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType=\"richtext_value\" mapping_id=\"http://rdfh.ch/standoff/mappings/StandardMapping\"> <text xmlns=\"\">The most <strong>interesting</strong> article in <a class=\"salsah-link\" href=\"ref:math_intelligencer\">Math Intelligencer</a>.</text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType=\"richtext_value\">73</p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType=\"link_value\" target=\"math_intelligencer\" linkType=\"ref\"/> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType=\"richtext_value\">27</p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"ref\" target=\"abel\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"ref\" target=\"holmes\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType=\"date_value\">GREGORIAN:1976</p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\" lang=\"en\">Strings in the 16th and 17th Centuries</p0801-biblio:publicationHasTitle> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\">An alternate title</p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType=\"richtext_value\">48</p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> This illustrates several aspects of XML imports: The root XML element must be knoraXmlImport:resources . There is an XML namespace corresponding each ontology used in the import. These namespaces can be found in the XML schema files returned by Knora. We have copied and pasted xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" from the main XML schema, p0801-biblio.xsd . This enables the Knora API server to identify the main ontology we are using. We have used xsi:schemaLocation to indicate the main schema's namespace and filename. If we put our XML document in the same directory as the schemas, and we run an XML validator to check the XML, it should load the schemas. The child elements of knoraXmlImport:resources represent resources to be created. The order of these elements is unimportant. Each resource must have an ID, which must be an XML NCName , and must be unique within the file. These IDs are used only during the import, and will not be stored in the triplestore. Each resource can optionally have a creationDate attribute, which can be an xsd:dateTime or an xsd:dateTimeStamp . If creationDate is not supplied, the current time is used. The first child element of each resource must be a knoraXmlImport:label , which will be stored as the resource's rdfs:label . Optionally, the second child element of a resource can provide metadata about a file to be attached to the resource (see bulk-import-with-digital-representations). The remaining child elements of each resource represent its property values. These must be sorted in alphabetical order by property name. If a property has mutliple values, these are represented as multiple adjacent property elements. The type of each value must be specified using the attribute knoraType . A link to another resource described in the XML import is represented as a child element of a property element, with attributes knoraType=\"link_value\" and linkType=\"ref\" , and a target attribute containing the ID of the target resource. There is a specfic syntax for referring to properties from other ontologies. In the example, p0801-beol:comment is defined in the ontology http://www.knora.org/ontology/0001/beol . In the XML, we refer to it as p0801-biblio:p0801-beol__comment . A text value can contain XML markup. If it does: The text value element must have the attribute mapping_id , specifying a mapping from XML to standoff markup (see XML-to-standoff-mapping). It is necessary to specify the appropriate XML namespace (in this case the null namespace, xmlns=\"\" ) for the XML markup in the text value. The XML markup in the text value will not be validated by the schema. In an XML tag that is mapped to a standoff link tag, the link target can refer either to the IRI of a resoruce that already exists in the triplestore, or to the ID of a resource described in the import. If a link points to a resource described in the import, the ID of the target resource must be prefixed with ref: . In the example above, using the standard mapping, the standoff link to math_intelligencer has the target ref:math_intelligencer . A text value can have a lang attribute, whose value is an ISO 639-1 code specifying the language of the text.","title":"3. Generate XML Import Document"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#4-validate-xml-import-document","text":"You can use an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen , to check that your XML import document is valid according to the schemas you got from Knora. For example, using Saxon: java -cp ./saxon9ee.jar com.saxonica.Validate -xsd:p0801-biblio.xsd -s:data.xml","title":"4. Validate XML Import Document"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#5-submit-xml-import-document-to-knora","text":"To create these resources in Knora, make an HTTP post request with the XML import document as the request body. The URL must specify the (URL-encoded) IRI of the project in which the resources should be created: HTTP POST to http://host/v1/resources/xmlimport/projectIRI For example, using curl : curl -v -u root@example.com:test --data @data.xml --header \"Content-Type: application/xml\" http://localhost:3333/v1/resources/xmlimport/http%3A%2F%2Frdfh.ch%2Fprojects%2F0801","title":"5. Submit XML Import Document to Knora"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#bulk-import-with-links-to-existing-resources","text":"Having run the import in the previous example, we can import more data with links to the data that is now in the triplestore: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol=\"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <p0801-biblio:JournalArticle id=\"strings_in_the_18th_century\"> <knoraXmlImport:label>Strings in the 18th Century</knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType=\"richtext_value\" mapping_id=\"http://rdfh.ch/standoff/mappings/StandardMapping\"> <text xmlns=\"\">The most <strong>boring</strong> article in <a class=\"salsah-link\" href=\"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\">Math Intelligencer</a>.</text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType=\"richtext_value\">76</p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType=\"link_value\" linkType=\"iri\" target=\"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\"/> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType=\"richtext_value\">27</p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"iri\" target=\"http://rdfh.ch/biblio/c-xMB3qkRs232pWyjdUUvA\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType=\"date_value\">GREGORIAN:1977</p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\">Strings in the 18th Century</p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType=\"richtext_value\">52</p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> Note that in the link elements referring to existing resources, the linkType attribute has the value iri , and the target attribute contains the IRI of the target resource.","title":"Bulk Import with Links to Existing Resources"},{"location":"DSP-API/03-apis/api-v1/adding-resources/#bulk-import-with-image-files","text":"To attach an image file to a resource, we must provide the element knoraXmlImport:file before the property elements. In this element, we must provide a filename attribute, containing the internalFilename that Sipi returned for the file in 2. Upload Files to Sipi . <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/incunabula/xml-import/v1# incunabula.xsd\" xmlns:incunabula=\"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <incunabula:book id=\"test_book\"> <knoraXmlImport:label>a book with one page</knoraXmlImport:label> <incunabula:title knoraType=\"richtext_value\">the title of a book with one page</incunabula:title> </incunabula:book> <incunabula:page id=\"test_page\"> <knoraXmlImport:label>a page with an image</knoraXmlImport:label> <knoraXmlImport:file filename=\"67SEfNU1wK2-CSf5abe2eh3.jp2\"/> <incunabula:origname knoraType=\"richtext_value\">Chlaus</incunabula:origname> <incunabula:pagenum knoraType=\"richtext_value\">1a</incunabula:pagenum> <incunabula:partOf> <incunabula:book knoraType=\"link_value\" linkType=\"ref\" ref=\"test_book\"/> </incunabula:partOf> <incunabula:seqnum knoraType=\"int_value\">1</incunabula:seqnum> </incunabula:page> </knoraXmlImport:resources> During the processing of the bulk import, Knora will ask Sipi for the rest of the file's metadata, and store that metadata in a file value attached to the resource.","title":"Bulk Import with Image Files"},{"location":"DSP-API/03-apis/api-v1/adding-values/","text":"Adding a Value In order to add values to an existing resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the values path segment. Creating values requires authentication since only known users may add values. Adding a Property Value In order to add a value to a resource, its property type, value, and project has to be indicated in the JSON. Also the IRI of the resource the new value belongs has to be provided in the JSON. HTTP POST to http://host/v1/values Depending on the type of the new value, one of the following formats (all TypeScript interfaces defined in module addValueFormats ) has to be used in order to create a new value: addRichtextValueRequest addLinkValueRequest addIntegerValueRequest addDecimalValueRequest addBooleanValueRequest addUriValueRequest addDateValueRequest (see dateString in basicMessageComponents for the date format) addColorValueRequest addGeometryValueRequest addHierarchicalListValueRequest addintervalValueRequest addGeonameValueRequest Response on Value Creation When a value has been successfully created, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface addValueResponse in module addValueFormats .","title":"Adding Values"},{"location":"DSP-API/03-apis/api-v1/adding-values/#adding-a-value","text":"In order to add values to an existing resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the values path segment. Creating values requires authentication since only known users may add values.","title":"Adding a Value"},{"location":"DSP-API/03-apis/api-v1/adding-values/#adding-a-property-value","text":"In order to add a value to a resource, its property type, value, and project has to be indicated in the JSON. Also the IRI of the resource the new value belongs has to be provided in the JSON. HTTP POST to http://host/v1/values Depending on the type of the new value, one of the following formats (all TypeScript interfaces defined in module addValueFormats ) has to be used in order to create a new value: addRichtextValueRequest addLinkValueRequest addIntegerValueRequest addDecimalValueRequest addBooleanValueRequest addUriValueRequest addDateValueRequest (see dateString in basicMessageComponents for the date format) addColorValueRequest addGeometryValueRequest addHierarchicalListValueRequest addintervalValueRequest addGeonameValueRequest","title":"Adding a Property Value"},{"location":"DSP-API/03-apis/api-v1/adding-values/#response-on-value-creation","text":"When a value has been successfully created, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface addValueResponse in module addValueFormats .","title":"Response on Value Creation"},{"location":"DSP-API/03-apis/api-v1/authentication/","text":"Authentication Login and Logout When a client accesses the /v1/session?login route successfully, it gets back headers requesting that a cookie is created, which will store the session token. On all subsequent calls to any route, this session token needs to be sent with each request. Normally, a web browser does this automatically, i.e. sends the cookie on every request. The session token is used by the server to retrieve the user profile. If successful, the user is deemed authenticated. To logout the client can call the same route and provide the logout parameter /v1/session?logout . This will invalidate the session token and return headers for removing the cookie on the client. Submitting Credentials For login , credentials in form of email and password need to be sent with the request. There are two possibilities to do so: in the URL submitting the parameters email and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedEmail&password=pw ) in the HTTP authorization header ( HTTP basic authentication ) when doing a HTTP request to the API When using Python's module requests , the credentials (email / password) can simply be submitted as a tuple with each request using the param auth ( python requests ). An alternative way for accessing all routes is to simply supply the email and password credentials on each request either as URL parameters or in the HTTP authorization header. Checking Credentials To check the credentials, there is a special route called /v1/authenticate , which can be used to check if the credentials are valid. Usage Scenarios Create session by logging-in, send session token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Authentication"},{"location":"DSP-API/03-apis/api-v1/authentication/#authentication","text":"","title":"Authentication"},{"location":"DSP-API/03-apis/api-v1/authentication/#login-and-logout","text":"When a client accesses the /v1/session?login route successfully, it gets back headers requesting that a cookie is created, which will store the session token. On all subsequent calls to any route, this session token needs to be sent with each request. Normally, a web browser does this automatically, i.e. sends the cookie on every request. The session token is used by the server to retrieve the user profile. If successful, the user is deemed authenticated. To logout the client can call the same route and provide the logout parameter /v1/session?logout . This will invalidate the session token and return headers for removing the cookie on the client.","title":"Login and Logout"},{"location":"DSP-API/03-apis/api-v1/authentication/#submitting-credentials","text":"For login , credentials in form of email and password need to be sent with the request. There are two possibilities to do so: in the URL submitting the parameters email and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedEmail&password=pw ) in the HTTP authorization header ( HTTP basic authentication ) when doing a HTTP request to the API When using Python's module requests , the credentials (email / password) can simply be submitted as a tuple with each request using the param auth ( python requests ). An alternative way for accessing all routes is to simply supply the email and password credentials on each request either as URL parameters or in the HTTP authorization header.","title":"Submitting Credentials"},{"location":"DSP-API/03-apis/api-v1/authentication/#checking-credentials","text":"To check the credentials, there is a special route called /v1/authenticate , which can be used to check if the credentials are valid.","title":"Checking Credentials"},{"location":"DSP-API/03-apis/api-v1/authentication/#usage-scenarios","text":"Create session by logging-in, send session token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Usage Scenarios"},{"location":"DSP-API/03-apis/api-v1/changing-values/","text":"Changing a Value To add values to an existing resource, the HTTP method PUT has to be used. Changing values requires authentication since only known users may change values. Modifying a Property Value The request has to be sent to the Knora server using the values path segment followed by the value's IRI: HTTP PUT to http://host/values/valueIRI The value IRI has to be URL-encoded. To change an existing value (creating a new version of it), the value's current IRI and its new value have to be submitted as JSON in the HTTP body. Depending on the type of the new value, one of the following formats has to be used in order to create a new value (all these TypeScript interfaces are defined in module changeValueFormats ): changeRichtextValueRequest changeLinkValueRequest changeIntegerValueRequest changeDecimalValueRequest changeBooleanValueRequest changeUriValueRequest changeDateValueRequest changeColorValueRequest changeGeometryValueRequest changeHierarchicalListValueRequest changeIntervalValueRequest changeGeonameValueRequest Modifying a File Value To change a file value, the client first uploads the new file to Sipi, following the procedure described in Adding Resources with Image Files . Then the client sends a request to Knora, using this following route: HTTP PUT to http://host/filevalue/resourceIRI Here, resourceIRI is the URL-encoded IRI of the resource whose file value is to be changed. The body of the request is a JSON object described in the TypeScript interface changeFileValueRequest in module changeValueFormats , and contains file , whose value is the internalFilename that Sipi returned. The request header's content type must be set to application/json . Response on Value Change When a value has been successfully changed, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface changeValueResponse in module changeValueFormats .","title":"Changing Values"},{"location":"DSP-API/03-apis/api-v1/changing-values/#changing-a-value","text":"To add values to an existing resource, the HTTP method PUT has to be used. Changing values requires authentication since only known users may change values.","title":"Changing a Value"},{"location":"DSP-API/03-apis/api-v1/changing-values/#modifying-a-property-value","text":"The request has to be sent to the Knora server using the values path segment followed by the value's IRI: HTTP PUT to http://host/values/valueIRI The value IRI has to be URL-encoded. To change an existing value (creating a new version of it), the value's current IRI and its new value have to be submitted as JSON in the HTTP body. Depending on the type of the new value, one of the following formats has to be used in order to create a new value (all these TypeScript interfaces are defined in module changeValueFormats ): changeRichtextValueRequest changeLinkValueRequest changeIntegerValueRequest changeDecimalValueRequest changeBooleanValueRequest changeUriValueRequest changeDateValueRequest changeColorValueRequest changeGeometryValueRequest changeHierarchicalListValueRequest changeIntervalValueRequest changeGeonameValueRequest","title":"Modifying a Property Value"},{"location":"DSP-API/03-apis/api-v1/changing-values/#modifying-a-file-value","text":"To change a file value, the client first uploads the new file to Sipi, following the procedure described in Adding Resources with Image Files . Then the client sends a request to Knora, using this following route: HTTP PUT to http://host/filevalue/resourceIRI Here, resourceIRI is the URL-encoded IRI of the resource whose file value is to be changed. The body of the request is a JSON object described in the TypeScript interface changeFileValueRequest in module changeValueFormats , and contains file , whose value is the internalFilename that Sipi returned. The request header's content type must be set to application/json .","title":"Modifying a File Value"},{"location":"DSP-API/03-apis/api-v1/changing-values/#response-on-value-change","text":"When a value has been successfully changed, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface changeValueResponse in module changeValueFormats .","title":"Response on Value Change"},{"location":"DSP-API/03-apis/api-v1/delete-resources-and-values/","text":"Deleting Resources and Values Knora does not actually delete resources or values; it just marks them as deleted. To mark a resource or value as deleted, you must use the HTTP method DELETE has to be used. This requires authentication. Mark a Resource as Deleted The delete request has to be sent to the Knora server using the resources path segment. HTTP DELETE to http://host/resources/resourceIRI?deleteComment=String The resource IRI must be URL-encoded. The deleteComment is an optional comment explaining why the resource is being marked as deleted. Mark a Value as Deleted The delete request has to be sent to the Knora server using the values path segment, providing the valueIRI: HTTP DELETE to http://host/values/valueIRI?deleteComment=String The value IRI must be URL-encoded. The deleteComment is an optional comment explaining why the value is being marked as deleted. Once a value has been marked as deleted, no new versions of it can be made.","title":"Deleting Resources and Values"},{"location":"DSP-API/03-apis/api-v1/delete-resources-and-values/#deleting-resources-and-values","text":"Knora does not actually delete resources or values; it just marks them as deleted. To mark a resource or value as deleted, you must use the HTTP method DELETE has to be used. This requires authentication.","title":"Deleting Resources and Values"},{"location":"DSP-API/03-apis/api-v1/delete-resources-and-values/#mark-a-resource-as-deleted","text":"The delete request has to be sent to the Knora server using the resources path segment. HTTP DELETE to http://host/resources/resourceIRI?deleteComment=String The resource IRI must be URL-encoded. The deleteComment is an optional comment explaining why the resource is being marked as deleted.","title":"Mark a Resource as Deleted"},{"location":"DSP-API/03-apis/api-v1/delete-resources-and-values/#mark-a-value-as-deleted","text":"The delete request has to be sent to the Knora server using the values path segment, providing the valueIRI: HTTP DELETE to http://host/values/valueIRI?deleteComment=String The value IRI must be URL-encoded. The deleteComment is an optional comment explaining why the value is being marked as deleted. Once a value has been marked as deleted, no new versions of it can be made.","title":"Mark a Value as Deleted"},{"location":"DSP-API/03-apis/api-v1/introduction/","text":"Introduction: Using API V1 RESTful API DSP-API V1 is a RESTful API that allows for reading and adding of resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The diverse HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ). Knora IRIs Every resource that is created or hosted by Knora is identified by a unique id, a so called Internationalized Resource Identifier (IRI). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike DSP-API v2, DSP-API v1 uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ). V1 Path Segment Every request to API V1 includes v1 as a path segment, e.g. http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests to another version of the API will require another path segment. DSP-API Response Format In case an API request could be handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON (using UTF-8). In this JSON, an API specific status code is sent (member status ). The JSON formats are formally defined as TypeScript interfaces (located in salsah/src/typescript_interfaces ). Build the HTML documentation of these interfaces by executing make jsonformat (see docs/Readme.md for further instructions). Placeholder host in sample URLs Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on. Authentication For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. When using the SALSAH web interface, after logging in a session is established (cookie based). When using the API with another client application, credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). Also when reading resources authentication my be needed as resources and their values may have restricted view permissions.","title":"Introduction"},{"location":"DSP-API/03-apis/api-v1/introduction/#introduction-using-api-v1","text":"","title":"Introduction: Using API V1"},{"location":"DSP-API/03-apis/api-v1/introduction/#restful-api","text":"DSP-API V1 is a RESTful API that allows for reading and adding of resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The diverse HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ).","title":"RESTful API"},{"location":"DSP-API/03-apis/api-v1/introduction/#knora-iris","text":"Every resource that is created or hosted by Knora is identified by a unique id, a so called Internationalized Resource Identifier (IRI). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike DSP-API v2, DSP-API v1 uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ).","title":"Knora IRIs"},{"location":"DSP-API/03-apis/api-v1/introduction/#v1-path-segment","text":"Every request to API V1 includes v1 as a path segment, e.g. http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests to another version of the API will require another path segment.","title":"V1 Path Segment"},{"location":"DSP-API/03-apis/api-v1/introduction/#dsp-api-response-format","text":"In case an API request could be handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON (using UTF-8). In this JSON, an API specific status code is sent (member status ). The JSON formats are formally defined as TypeScript interfaces (located in salsah/src/typescript_interfaces ). Build the HTML documentation of these interfaces by executing make jsonformat (see docs/Readme.md for further instructions).","title":"DSP-API Response Format"},{"location":"DSP-API/03-apis/api-v1/introduction/#placeholder-host-in-sample-urls","text":"Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on.","title":"Placeholder host in sample URLs"},{"location":"DSP-API/03-apis/api-v1/introduction/#authentication","text":"For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. When using the SALSAH web interface, after logging in a session is established (cookie based). When using the API with another client application, credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). Also when reading resources authentication my be needed as resources and their values may have restricted view permissions.","title":"Authentication"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/","text":"Reading and Searching Resources In order to get an existing resource, the HTTP method GET has to be used. The request has to be sent to the Knora server using the resources path segment (depending on the type of request, this segment has to be exchanged, see below). Reading resources may require authentication since some resources may have restricted viewing permissions. Get the Representation of a Resource by its IRI Simple Request of a Resource (full Resource Request) A resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL encoded. In order to get the resource with the IRI http://rdfh.ch/c5058f3a (an incunabula book contained in the test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL encoded IRI: HTTP GET to http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a More formalized, the URL looks like this: HTTP GET to http://host/v1/resources/resourceIRI As an answer, the client receives a JSON that represents the requested resource. It has the following members: status : The Knora status code, 0 if everything went well userdata : Data about the user that made the request resinfo : Data describing the requested resource and its class resdata : Short information about the resource and its class (including information about the given user's permissions on the resource) incoming : Resources pointing to the requested resource props : Properties of the requested resource. For a complete and more formalized description of a full resource request, look at the TypeScript interface resourceFullResponse in the module resourceResponseFormats . Provide Request Parameters To make a request more specific, the following parameters can be appended to the URL ( http://www.knora.org/resources/resourceIRI?param1=value1&param2=value2 ): reqtype=info|context|rights : Specifies the type of request. Setting the parameter's to value info returns short information about the requested resource (contains only resinfo and no properties, see TypeScript interface resourceInfoResponse in module resourceResponseFormats ). Setting the parameter's value to context returns context information ( resource_context ) about the requested resource: Either the dependent parts of a compound resource (e.g. pages of a book) or the parent resource of a dependent resource (e.g. the book a pages belongs to). By default, a context query does not return information about the requested resource itself, but only about its context (see TypeScript interface resourceContextResponse in module resourceResponseFormats ). See below how to get additional information about the resource. The parameter rights returns only the given user's permissions on the requested resource (see TypeScript interface resourceRightsResponse in module resourceResponseFormats ). resinfo=true : Can be used in combination with reqtype=context : If set, resinfo is added to the response representing information about the requested resource (complementary to its context), see TypeScript interface resourceContextResponse in module resourceResponseFormats . Obtain an HTML Representation of a Resource In order to get an HTML representation of a resource (not a JSON), the path segment resources.html can be used: HTTP GET to http://host/v1/resources.html/resourceIRI?reqtype=properties The request returns the properties of the requested resource as an HTML document. Get only the Properties belonging to a Resource In order to get only the properties of a resource without any other information, the path segment properties can be used: HTTP GET to http://host/v1/properties/resourceIRI The JSON contains just the member properties representing the requested resource's properties (see TypeScript interface resourcePropertiesResponse in module resourceResponseFormats ). Get Information about a Resource Class Get a Resource Class by its IRI In order to get information about a resource class, the path segment resourcetypes can be used. Append the IRI of the resource class to the URL (e.g. http://www.knora.org/ontology/0803/incunabula#book ). HTTP GET to http://host/v1/resourcetypes/resourceClassIRI In the JSON, the information about the resource class and all the property types that it may have are returned. None of these are actual instances of a property, but only types (see TypeScript interface resourceTypeResponse in module resourceResponseFormats ). Get all the Property Types of a Resource Class or a Vocabulary To get a list of all the available property types, the path segment propertylists can be used. It can be restricted to a certain vocbulary using the parameter vocabulary or to a certain resource class using the parameter restype . # returns all the property types for incunabula:page HTTP GET to http://host/v1/propertylists?restype=resourceClassIRI # returns all the property types for the incunabula vocabulary HTTP GET to http://host/v1/propertylists?vocabulary=vocabularyIRI Both of these queries return a list of property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface propertyTypesInResourceClassResponse in module resourceResponseFormats . Get the Resource Classes of a Vocabulary Resource classes and property types are organized in (project specific) name spaces, so called vocabularies. In order to get all the resource classes defined for a specific vocabulary (e.g. incunabula ), the parameter vocabulary has to be used and assigned the vocabulary's IRI: HTTP GET to http://host/v1/resourcetypes?vocabulary=vocabularyIRI This returns all the resource classes defined for the specified vocabulary and their property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface resourceTypesInVocabularyResponse in module resourceResponseFormats . Get all the Vocabularies To get a list of all available vocabularies, the path segment vocabularies can be used: HTTP GET to http://host/v1/vocabularies The response will list all the available vocabularies. See TypeScript interface vocabularyResponse in module resourceResponseFormats . Search for Resources Search for Resources by their Label This is a simplified way for searching for resources just by their label. Search by label automatically adds Lucene operators, search strings are expected not to contain any characters with a special meaning in Lucene Query Parser syntax . It is a simple string-based method: HTTP GET to http://host/v1/resources?searchstr=searchValue Additionally, the following parameters can be appended to the URL (search value is Zeitgl\u00f6cklein ): restype_id=resourceClassIRI : This restricts the search to resources of the specified class (subclasses of that class will also match). -1 is the default value and means no restriction to a specific class. If a resource class IRI is specified, it has to be URL encoded (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&restype_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book ). numprops=Integer : Specifies the number of properties returned for each resource that was found (sorted by GUI order), e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&numprops=4 . limit=Integer : Limits the amount of results returned (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&limit=1 ). The response lists the resources that matched the search criteria (see TypeScript interface resourceLabelSearchResponse in module resourceResponseFormats ). Fulltext Search Knora offers a fulltext search that searches through all textual representations of values. The search terms have to be URL encoded. Fulltext search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. HTTP GET to http://host/v1/search/searchValue?searchtype=fulltext[&filter_by_restype=resourceClassIRI] [&filter_by_project=projectIRI][&show_nrows=Integer]{[&start_at=Integer] The parameter searchtype is required and has to be set to fulltext . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See TypeScript interface searchResponse in module searchResponseFormats . Extended Search for Resources HTTP GET to http://host/v1/search/?searchtype=extended [&filter_by_restype=resourceClassIRI][&filter_by_project=projectIRI][&filter_by_owner=userIRI] (&property_id=propertyTypeIRI&compop=comparisonOperator&searchval=searchValue)+ [&show_nrows=Integer][&start_at=Integer] The parameter searchtype is required and has to be set to extended . An extended search requires at least one set of parameters consisting of: property_id=propertyTypeIRI : the property the resource has to have (subproperties of that property will also match). compop=comparisonOperator : the comparison operator to be used to match between the resource's property value and the search term. searchval=searchTerm : the search value to look for. You can also provide several of these sets to make your query more specific. The following table indicates the possible combinations of value types and comparison operators: Value Type Comparison Operator Date Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Integer Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Float Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Text Value MATCH_BOOLEAN, MATCH, EQ, !EQ, LIKE, !LIKE, EXISTS Geometry Value EXISTS Geoname Value EQ, EXISTS URI Value EQ, EXISTS Resource Pointer EQ, EXISTS Color Value EQ, EXISTS List Value EQ, EXISTS Boolean Value EQ, !EQ, EXISTS Explanation of the comparison operators: EQ (equal): checks if a resource's value equals the search value. In case of a text value type, it checks for identity of the strings compared. In case of a date value type, equality is given if the dates overlap in any way. Since dates are internally always treated as periods, equality is given if a date value's period ends after or equals the start of the defined period and a date value's period starts before or equals the end of the defined period. !EQ (not equal): checks if a resource's value does not equal the search value. In case of a text value type, it checks if the compared strings are different. In case of a date value type, inequality is given if the dates do not overlap in any way, meaning that a date starts after the end of the defined period or ends before the beginning of the defined period (dates are internally always treated as periods, see above). GT (greater than): checks if a resource's value is greater than the search value. In case of a date value type, it assures that a period begins after the indicated period's end. GT_EQ (greater than or equal): checks if a resource's value equals or is greater than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period starts after the indicated period's end (see GT ). LT (less than): checks if a resource's value is lower than the search value. In case of a date value type, it assures that a period ends before the indicated period's start. LT_EQ (less than or equal): checks if a resource's value equals or is lower than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period ends before the indicated period's start (see LT ). EXISTS : checks if an instance of the indicated property type exists for a resource. Please always provide an empty search value when using EXISTS: \"searchval=\" . Otherwise, the query syntax rules would be violated. MATCH : checks if a resource's text value matches the search value, see Lucene Query Parser Syntax . LIKE : checks if the search value is contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. !LIKE (not like): checks if the search value is not contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. MATCH_BOOLEAN : checks if a resource's text value matches the provided list of positive (exist) and negative (do not exist) terms. The list takes this form: ([+-]term\\s)+ . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. filter_by_owner : restricts the search to resources owned by the specified user. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. Some sample searches: http://localhost:3333/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=!EQ&searchval=Zeitgl%C3%B6cklein%20des%20Lebens%20und%20Leidens%20Christi : searches for books that have a title that does not equal \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\". http://www.knora.org/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=MATCH&searchval=Zeitgl%C3%B6cklein&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23pubdate&compop=EQ&searchval=JULIAN:1490 : searches for resources of type incunabula:book whose titles match \"Zeitgl\u00f6cklein\" and were published in the year 1490 (according to the Julian calendar). The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See the TypeScript interface searchResponse in module searchResponseFormats . Get a Graph of Resources The path segment graphdata returns a graph of resources that are reachable via links to or from an initial resource. HTTP GET to http://host/v1/graphdata/resourceIRI?depth=Integer The parameter depth specifies the maximum depth of the graph, and defaults to 4. If depth is 1, the operation will return only the initial resource and any resources that are directly linked to or from it. The graph includes any link that is a subproperty of knora-base:hasLinkTo , except for links that are subproperties of knora-base:isPartOf . Specifically, if resource R1 has a link that is a subproperty of knora-base:isPartOf pointing to resource R2 , no link from R1 to R2 is included in the graph. The response represents the graph as a list of nodes (resources) and a list of edges (links). For details, see the TypeScript interface graphDataResponse in module graphDataResponseFormats . Get Hierarchical Lists The knora-base ontology allows for the definition of hierarchical lists. These can be queried by providing the IRI of the root node. Selections are hierarchical list that are just one level deep. Internally, they are represented as hierarchical lists. You can get a hierarchical by using the path segment hlists and appending the hierarchical list's IRI (URL encoded): HTTP GET to http://host/v1/hlists/rootNodeIRI The response shows all of the list nodes that are element of the requested hierarchical list as a tree structure. See TypeScript interface hierarchicalListResponse in module hierarchicalListResponseFormats . For each node, the full path leading to it from the top level can be requested by making a query providing the node's IRI and setting the param reqtype=node : HTTP GET to http://host/v1/hlists/nodeIri?reqtype=node The response presents the full path to the current node. See the TypeScript interface nodePathResponse in module hierarchicalListResponseFormats .","title":"Reading and Searching Resources"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#reading-and-searching-resources","text":"In order to get an existing resource, the HTTP method GET has to be used. The request has to be sent to the Knora server using the resources path segment (depending on the type of request, this segment has to be exchanged, see below). Reading resources may require authentication since some resources may have restricted viewing permissions.","title":"Reading and Searching Resources"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-the-representation-of-a-resource-by-its-iri","text":"","title":"Get the Representation of a Resource by its IRI"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#simple-request-of-a-resource-full-resource-request","text":"A resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL encoded. In order to get the resource with the IRI http://rdfh.ch/c5058f3a (an incunabula book contained in the test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL encoded IRI: HTTP GET to http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a More formalized, the URL looks like this: HTTP GET to http://host/v1/resources/resourceIRI As an answer, the client receives a JSON that represents the requested resource. It has the following members: status : The Knora status code, 0 if everything went well userdata : Data about the user that made the request resinfo : Data describing the requested resource and its class resdata : Short information about the resource and its class (including information about the given user's permissions on the resource) incoming : Resources pointing to the requested resource props : Properties of the requested resource. For a complete and more formalized description of a full resource request, look at the TypeScript interface resourceFullResponse in the module resourceResponseFormats .","title":"Simple Request of a Resource (full Resource Request)"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#provide-request-parameters","text":"To make a request more specific, the following parameters can be appended to the URL ( http://www.knora.org/resources/resourceIRI?param1=value1&param2=value2 ): reqtype=info|context|rights : Specifies the type of request. Setting the parameter's to value info returns short information about the requested resource (contains only resinfo and no properties, see TypeScript interface resourceInfoResponse in module resourceResponseFormats ). Setting the parameter's value to context returns context information ( resource_context ) about the requested resource: Either the dependent parts of a compound resource (e.g. pages of a book) or the parent resource of a dependent resource (e.g. the book a pages belongs to). By default, a context query does not return information about the requested resource itself, but only about its context (see TypeScript interface resourceContextResponse in module resourceResponseFormats ). See below how to get additional information about the resource. The parameter rights returns only the given user's permissions on the requested resource (see TypeScript interface resourceRightsResponse in module resourceResponseFormats ). resinfo=true : Can be used in combination with reqtype=context : If set, resinfo is added to the response representing information about the requested resource (complementary to its context), see TypeScript interface resourceContextResponse in module resourceResponseFormats .","title":"Provide Request Parameters"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#obtain-an-html-representation-of-a-resource","text":"In order to get an HTML representation of a resource (not a JSON), the path segment resources.html can be used: HTTP GET to http://host/v1/resources.html/resourceIRI?reqtype=properties The request returns the properties of the requested resource as an HTML document.","title":"Obtain an HTML Representation of a Resource"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-only-the-properties-belonging-to-a-resource","text":"In order to get only the properties of a resource without any other information, the path segment properties can be used: HTTP GET to http://host/v1/properties/resourceIRI The JSON contains just the member properties representing the requested resource's properties (see TypeScript interface resourcePropertiesResponse in module resourceResponseFormats ).","title":"Get only the Properties belonging to a Resource"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-information-about-a-resource-class","text":"","title":"Get Information about a Resource Class"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-a-resource-class-by-its-iri","text":"In order to get information about a resource class, the path segment resourcetypes can be used. Append the IRI of the resource class to the URL (e.g. http://www.knora.org/ontology/0803/incunabula#book ). HTTP GET to http://host/v1/resourcetypes/resourceClassIRI In the JSON, the information about the resource class and all the property types that it may have are returned. None of these are actual instances of a property, but only types (see TypeScript interface resourceTypeResponse in module resourceResponseFormats ).","title":"Get a Resource Class by its IRI"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-all-the-property-types-of-a-resource-class-or-a-vocabulary","text":"To get a list of all the available property types, the path segment propertylists can be used. It can be restricted to a certain vocbulary using the parameter vocabulary or to a certain resource class using the parameter restype . # returns all the property types for incunabula:page HTTP GET to http://host/v1/propertylists?restype=resourceClassIRI # returns all the property types for the incunabula vocabulary HTTP GET to http://host/v1/propertylists?vocabulary=vocabularyIRI Both of these queries return a list of property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface propertyTypesInResourceClassResponse in module resourceResponseFormats .","title":"Get all the Property Types of a Resource Class or a Vocabulary"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-the-resource-classes-of-a-vocabulary","text":"Resource classes and property types are organized in (project specific) name spaces, so called vocabularies. In order to get all the resource classes defined for a specific vocabulary (e.g. incunabula ), the parameter vocabulary has to be used and assigned the vocabulary's IRI: HTTP GET to http://host/v1/resourcetypes?vocabulary=vocabularyIRI This returns all the resource classes defined for the specified vocabulary and their property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface resourceTypesInVocabularyResponse in module resourceResponseFormats .","title":"Get the Resource Classes of a Vocabulary"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-all-the-vocabularies","text":"To get a list of all available vocabularies, the path segment vocabularies can be used: HTTP GET to http://host/v1/vocabularies The response will list all the available vocabularies. See TypeScript interface vocabularyResponse in module resourceResponseFormats .","title":"Get all the Vocabularies"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#search-for-resources","text":"","title":"Search for Resources"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#search-for-resources-by-their-label","text":"This is a simplified way for searching for resources just by their label. Search by label automatically adds Lucene operators, search strings are expected not to contain any characters with a special meaning in Lucene Query Parser syntax . It is a simple string-based method: HTTP GET to http://host/v1/resources?searchstr=searchValue Additionally, the following parameters can be appended to the URL (search value is Zeitgl\u00f6cklein ): restype_id=resourceClassIRI : This restricts the search to resources of the specified class (subclasses of that class will also match). -1 is the default value and means no restriction to a specific class. If a resource class IRI is specified, it has to be URL encoded (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&restype_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book ). numprops=Integer : Specifies the number of properties returned for each resource that was found (sorted by GUI order), e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&numprops=4 . limit=Integer : Limits the amount of results returned (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&limit=1 ). The response lists the resources that matched the search criteria (see TypeScript interface resourceLabelSearchResponse in module resourceResponseFormats ).","title":"Search for Resources by their Label"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#fulltext-search","text":"Knora offers a fulltext search that searches through all textual representations of values. The search terms have to be URL encoded. Fulltext search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. HTTP GET to http://host/v1/search/searchValue?searchtype=fulltext[&filter_by_restype=resourceClassIRI] [&filter_by_project=projectIRI][&show_nrows=Integer]{[&start_at=Integer] The parameter searchtype is required and has to be set to fulltext . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See TypeScript interface searchResponse in module searchResponseFormats .","title":"Fulltext Search"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#extended-search-for-resources","text":"HTTP GET to http://host/v1/search/?searchtype=extended [&filter_by_restype=resourceClassIRI][&filter_by_project=projectIRI][&filter_by_owner=userIRI] (&property_id=propertyTypeIRI&compop=comparisonOperator&searchval=searchValue)+ [&show_nrows=Integer][&start_at=Integer] The parameter searchtype is required and has to be set to extended . An extended search requires at least one set of parameters consisting of: property_id=propertyTypeIRI : the property the resource has to have (subproperties of that property will also match). compop=comparisonOperator : the comparison operator to be used to match between the resource's property value and the search term. searchval=searchTerm : the search value to look for. You can also provide several of these sets to make your query more specific. The following table indicates the possible combinations of value types and comparison operators: Value Type Comparison Operator Date Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Integer Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Float Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Text Value MATCH_BOOLEAN, MATCH, EQ, !EQ, LIKE, !LIKE, EXISTS Geometry Value EXISTS Geoname Value EQ, EXISTS URI Value EQ, EXISTS Resource Pointer EQ, EXISTS Color Value EQ, EXISTS List Value EQ, EXISTS Boolean Value EQ, !EQ, EXISTS Explanation of the comparison operators: EQ (equal): checks if a resource's value equals the search value. In case of a text value type, it checks for identity of the strings compared. In case of a date value type, equality is given if the dates overlap in any way. Since dates are internally always treated as periods, equality is given if a date value's period ends after or equals the start of the defined period and a date value's period starts before or equals the end of the defined period. !EQ (not equal): checks if a resource's value does not equal the search value. In case of a text value type, it checks if the compared strings are different. In case of a date value type, inequality is given if the dates do not overlap in any way, meaning that a date starts after the end of the defined period or ends before the beginning of the defined period (dates are internally always treated as periods, see above). GT (greater than): checks if a resource's value is greater than the search value. In case of a date value type, it assures that a period begins after the indicated period's end. GT_EQ (greater than or equal): checks if a resource's value equals or is greater than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period starts after the indicated period's end (see GT ). LT (less than): checks if a resource's value is lower than the search value. In case of a date value type, it assures that a period ends before the indicated period's start. LT_EQ (less than or equal): checks if a resource's value equals or is lower than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period ends before the indicated period's start (see LT ). EXISTS : checks if an instance of the indicated property type exists for a resource. Please always provide an empty search value when using EXISTS: \"searchval=\" . Otherwise, the query syntax rules would be violated. MATCH : checks if a resource's text value matches the search value, see Lucene Query Parser Syntax . LIKE : checks if the search value is contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. !LIKE (not like): checks if the search value is not contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. MATCH_BOOLEAN : checks if a resource's text value matches the provided list of positive (exist) and negative (do not exist) terms. The list takes this form: ([+-]term\\s)+ . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. filter_by_owner : restricts the search to resources owned by the specified user. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. Some sample searches: http://localhost:3333/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=!EQ&searchval=Zeitgl%C3%B6cklein%20des%20Lebens%20und%20Leidens%20Christi : searches for books that have a title that does not equal \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\". http://www.knora.org/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=MATCH&searchval=Zeitgl%C3%B6cklein&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23pubdate&compop=EQ&searchval=JULIAN:1490 : searches for resources of type incunabula:book whose titles match \"Zeitgl\u00f6cklein\" and were published in the year 1490 (according to the Julian calendar). The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See the TypeScript interface searchResponse in module searchResponseFormats .","title":"Extended Search for Resources"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-a-graph-of-resources","text":"The path segment graphdata returns a graph of resources that are reachable via links to or from an initial resource. HTTP GET to http://host/v1/graphdata/resourceIRI?depth=Integer The parameter depth specifies the maximum depth of the graph, and defaults to 4. If depth is 1, the operation will return only the initial resource and any resources that are directly linked to or from it. The graph includes any link that is a subproperty of knora-base:hasLinkTo , except for links that are subproperties of knora-base:isPartOf . Specifically, if resource R1 has a link that is a subproperty of knora-base:isPartOf pointing to resource R2 , no link from R1 to R2 is included in the graph. The response represents the graph as a list of nodes (resources) and a list of edges (links). For details, see the TypeScript interface graphDataResponse in module graphDataResponseFormats .","title":"Get a Graph of Resources"},{"location":"DSP-API/03-apis/api-v1/reading-and-searching-resources/#get-hierarchical-lists","text":"The knora-base ontology allows for the definition of hierarchical lists. These can be queried by providing the IRI of the root node. Selections are hierarchical list that are just one level deep. Internally, they are represented as hierarchical lists. You can get a hierarchical by using the path segment hlists and appending the hierarchical list's IRI (URL encoded): HTTP GET to http://host/v1/hlists/rootNodeIRI The response shows all of the list nodes that are element of the requested hierarchical list as a tree structure. See TypeScript interface hierarchicalListResponse in module hierarchicalListResponseFormats . For each node, the full path leading to it from the top level can be requested by making a query providing the node's IRI and setting the param reqtype=node : HTTP GET to http://host/v1/hlists/nodeIri?reqtype=node The response presents the full path to the current node. See the TypeScript interface nodePathResponse in module hierarchicalListResponseFormats .","title":"Get Hierarchical Lists"},{"location":"DSP-API/03-apis/api-v1/reading-values/","text":"Reading Values In order to get an existing value, the HTTP method GET has to be used. The request has to be sent to the Knora server using the values path segment. Reading values may require authentication since some resources may have restricted viewing permissions. Reading a Value The representation of a value can be obtained by making a GET request providing the value's IRI: HTTP GET to http://host/v1/values/valueIRI In the response, the value's type and value are returned (see TypeScript interface valueResponse in module valueResponseFormats ). Getting a Value's Version History In order to get the history of a value (its current and previous versions), the IRI of the resource it belongs to, the IRI of the property type that connects the resource to the value, and its current value IRI have to be submitted. Each of these elements is appended to the URL and separated by a slash. Please note that all of these have to be URL encoded. Additionally to values , the path segment history has to be used: HTTP GET to http://host/v1/values/history/resourceIRI/propertyTypeIRI/valueIRI In the response, the value's versions returned (see TypeScript interface valueVersionsResponse in module valueResponseFormats ). Getting a Linking Value In order to get information about a link between two resources, the path segment links has to be used. The IRI of the source object, the IRI of the property type linking the the two objects, and the IRI of the target object have to be provided in the URL separated by slashes. Each of these has to be URL encoded. HTTP GET to http://host/links/sourceObjectIRI/linkingPropertyIRI/targetObjectIRI In the response, information about the link is returned such as a reference count indicating how many links of the specified direction (source to target) and type (property) between the two objects exist (see TypeScript interface linkResponse in module valueResponseFormats ).","title":"Reading Values"},{"location":"DSP-API/03-apis/api-v1/reading-values/#reading-values","text":"In order to get an existing value, the HTTP method GET has to be used. The request has to be sent to the Knora server using the values path segment. Reading values may require authentication since some resources may have restricted viewing permissions.","title":"Reading Values"},{"location":"DSP-API/03-apis/api-v1/reading-values/#reading-a-value","text":"The representation of a value can be obtained by making a GET request providing the value's IRI: HTTP GET to http://host/v1/values/valueIRI In the response, the value's type and value are returned (see TypeScript interface valueResponse in module valueResponseFormats ).","title":"Reading a Value"},{"location":"DSP-API/03-apis/api-v1/reading-values/#getting-a-values-version-history","text":"In order to get the history of a value (its current and previous versions), the IRI of the resource it belongs to, the IRI of the property type that connects the resource to the value, and its current value IRI have to be submitted. Each of these elements is appended to the URL and separated by a slash. Please note that all of these have to be URL encoded. Additionally to values , the path segment history has to be used: HTTP GET to http://host/v1/values/history/resourceIRI/propertyTypeIRI/valueIRI In the response, the value's versions returned (see TypeScript interface valueVersionsResponse in module valueResponseFormats ).","title":"Getting a Value's Version History"},{"location":"DSP-API/03-apis/api-v1/reading-values/#getting-a-linking-value","text":"In order to get information about a link between two resources, the path segment links has to be used. The IRI of the source object, the IRI of the property type linking the the two objects, and the IRI of the target object have to be provided in the URL separated by slashes. Each of these has to be URL encoded. HTTP GET to http://host/links/sourceObjectIRI/linkingPropertyIRI/targetObjectIRI In the response, information about the link is returned such as a reference count indicating how many links of the specified direction (source to target) and type (property) between the two objects exist (see TypeScript interface linkResponse in module valueResponseFormats ).","title":"Getting a Linking Value"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/","text":"XML to Standoff Mapping in API v1 The Knora Standard Mapping Description A mapping allows for the conversion of XML to standoff representation in RDF and back. In order to create a TextValue with markup, the text has to be provided in XML format, along with the IRI of the mapping that will be used to convert the markup to standoff. However, a mapping is only needed if a TextValue with markup should be created. If a text has no markup, it is submitted as a mere sequence of characters. The two cases are described in the TypeScript interfaces simpletext and richtext in module basicMessageComponents . Knora offers a standard mapping with the IRI http://rdfh.ch/standoff/mappings/StandardMapping . The standard mapping covers the HTML elements and attributes supported by the GUI's text editor, CKEditor . (Please note that the HTML has to be encoded in strict XML syntax. CKeditor offers the possibility to define filter rules. They should reflect the elements supported by the mapping; see jquery.htmleditor.js .) The standard mapping contains the following elements and attributes that are mapped to standoff classes and properties defined in the ontology: <text> \u2192 standoff:StandoffRootTag <p> \u2192 standoff:StandoffParagraphTag <em> \u2192 standoff:StandoffItalicTag <strong> \u2192 standoff:StandoffBoldTag <u> \u2192 standoff:StandoffUnderlineTag <sub> \u2192 standoff:StandoffSubscriptTag <sup> \u2192 standoff:StandoffSuperscriptTag <strike> \u2192 standoff:StandoffStrikeTag <a href=\"URL\"> \u2192 knora-base:StandoffUriTag <a class=\"salsah-link\" href=\"Knora IRI\"> \u2192 knora-base:StandoffLinkTag <a class=\"internal-link\" href=\"#fragment\"> \u2192 knora-base:StandoffInternalReferenceTag <h1> to <h6> \u2192 standoff:StandoffHeader1Tag to standoff:StandoffHeader6Tag <ol> \u2192 standoff:StandoffOrderedListTag <ul> \u2192 standoff:StandoffUnrderedListTag <li> \u2192 standoff:StandoffListElementTag <tbody> \u2192 standoff:StandoffTableBodyTag <table> \u2192 standoff:StandoffTableTag <tr> \u2192 standoff:StandoffTableRowTag <td> \u2192 standoff:StandoffTableCellTag <br> \u2192 standoff:StandoffBrTag <hr> \u2192 standoff:StandoffLineTag <pre> \u2192 standoff:StandoffPreTag <cite> \u2192 standoff:StandoffCiteTag <blockquote> \u2192 standoff:StandoffBlockquoteTag <code> \u2192 standoff:StandoffCodeTag The HTML produced by CKEditor is wrapped in an XML doctype and a pair of root tags <text>...</text> and then sent to Knora. The XML sent to the GUI by Knora is unwrapped accordingly (see jquery.htmleditor.js ). Although the GUI supports HTML5, it is treated as if it was XHTML in strict XML notation. Maintenance The standard mapping definition can be found at test_data/test_route/texts/mappingForStandardHTML.xml . It was used to generate the default mapping, distributed as knora-ontologies/standoff-data.ttl and that is loaded at a Knora installation. It should be used to re-generate it, whenever we want to amend or extend it. Note: once the mapping has been generated, one has to rework the resources' UUID in order to maintain backward compatibility. Creating a custom Mapping The Knora standard mapping only supports a few HTML tags. In order to submit more complex XML markup to Knora, a custom mapping has to be created first. Basically, a mapping expresses the relations between XML elements and attributes and their corresponding standoff classes and properties. The relations expressed in a mapping are one-to-one relations, so the XML can be recreated from the data in RDF. However, since HTML offers a very limited set of elements, Knora mappings support the combination of element names and classes. In this way, the same element can be used several times in combination with another classname (please note that <a> without a class is a mere hyperlink whereas <a class=\"salsah-link\"> is an internal link/standoff link). With a mapping, a default XSL transformation may be provided to transform the XML to HTML before sending it back to the client. This is useful when the client is a web-browser expecting HTML (instead of XML). Basic Structure of a Mapping The mapping is written in XML itself (for a formal description, see webapi/src/resources/mappingXMLToStandoff.xsd ). It has the following structure (the indentation corresponds to the nesting in XML): <mapping> : the root element <defaultXSLTransformation> (optional) : the Iri of the default XSL transformation to be applied to the XML when reading it back from Knora. The XSL transformation is expected to produce HTML. If given, the Iri has to refer to a resource of type knora-base:XSLTransformation . <mappingElement> : an element of the mapping (at least one) <tag> : information about the XML element that is mapped to a standoff class <name> : name of the XML element <class> : value of the class attribute of the XML element, if any. If the element has no class attribute, the keyword noClass has to be used. <namespace> : the namespace the XML element belongs to, if any. If the element does not belong to a namespace, the keyword noNamespace has to be used. <separatesWords> : a Boolean value indicating whether this tag separates words in the text. Once an XML document is converted to RDF-standoff the markup is stripped from the text, possibly leading to continuous text that has been separated by tags before. For structural tags like paragraphs etc., <separatesWords> can be set to true in which case a special separator is inserted in the the text in the RDF representation. In this way, words stay separated and are represented in the fulltext index as such. <standoffClass> : information about the standoff class the XML element is mapped to <classIri> : Iri of the standoff class the XML element is mapped to <attributes> : XML attributes to be mapped to standoff properties (other than id or class ), if any <attribute> : an XML attribute to be mapped to a standoff property, may be repeated <attributeName> : the name of the XML attribute <namespace> : the namespace the attribute belongs to, if any. If the attribute does not belong to a namespace, the keyword noNamespace has to be used. <propertyIri> : the Iri of the standoff property the XML attribute is mapped to. <datatype> : the data type of the standoff class, if any. <type> : the Iri of the data type standoff class <attributeName> : the name of the attribute holding the typed value in the expected Knora standard format XML structure of a mapping: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <defaultXSLTransformation>Iri of a knora-base:XSLTransformation</defaultXSLTransformation> <mappingElement> <tag> <name>XML element name</name> <class>XML class name or \"noClass\"</class> <namespace>XML namespace or \"noNamespace\"</namespace> <separatesWords>true or false</separatesWords> </tag> <standoffClass> <classIri>standoff class Iri</classIri> <attributes> <attribute> <attributeName>XML attribute name</attributeName> <namespace>XML namespace or \"noNamespace\"</namespace> <propertyIri>standoff property Iri</propertyIri> </attribute> </attributes> <datatype> <type>standoff data type class</type> <attributeName>XML attribute with the typed value</attributeName> </datatype> </standoffClass> </mappingElement> <mappingElement> ... </mappingElement> </mapping> Please note that the absence of an XML namespace and/or a class have to be explicitly stated using the keywords noNamespace and noClass . (This is because we use XML Schema validation to ensure the one-to-one relations between XML elements and standoff classes. XML Schema validation's unique checks do not support optional values.) id and class Attributes The id and class attributes are supported by default and do not have to be included in the mapping like other attributes. The id attribute identifies an element and must be unique in the document. id is an optional attribute. The class attribute allows for the reuse of an element in the mapping, i.e. the same element can be combined with different class names and mapped to different standoff classes (mapping element <class> in <tag> ). Respecting Cardinalities A mapping from XML elements and attributes to standoff classes and standoff properties must respect the cardinalities defined in the ontology for those very standoff classes. If an XML element is mapped to a certain standoff class and this class requires a standoff property, an attribute must be defined for the XML element mapping to that very standoff property. Equally, all mappings for attributes of an XML element must have corresponding cardinalities for standoff properties defined for the standoff class the XML element maps to. However, since an XML attribute may occur once at maximum, it makes sense to make the corresponding standoff property required ( owl:cardinality of one) in the ontology or optional ( owl:maxCardinality of one), but not allowing it more than once. Standoff Data Types Knora allows the use of all its value types as standoff data types (defined in knora-base.ttl ): knora-base:StandoffLinkTag : Represents a reference to a Knora resource (the IRI of the target resource must be submitted in the data type attribute). knora-base:StandoffInternalReferenceTag : Represents an internal reference inside a document (the id of the target element inside the same document must be indicated in the data type attribute); see Internal References in an XML Document . knora-base:StandoffUriTag : Represents a reference to a URI (the URI of the target resource must be submitted in the data type attribute). knora-base:StandoffDateTag : Represents a date (a Knora date string must be submitted in the data type attribute, e.g. GREGORIAN:2017-01-27 ). knora-base:StandoffColorTag : Represents a color (a hexadecimal RGB color string must be submitted in the data type attribute, e.g. #0000FF ). knora-base:StandoffIntegerTag : Represents an integer (the integer must be submitted in the data type attribute). knora-base:StandoffDecimalTag : Represents a number with fractions (the decimal number must be submitted in the data type attribute, e.g. 1.1 ). knora-base:StandoffIntervalTag : Represents an interval (two decimal numbers separated with a comma must be submitted in the data type attribute, e.g. 1.1,2.2 ). knora-base:StandoffBooleanTag : Represents a Boolean value ( true or false must be submitted in the data type attribute). knora-base:StandoffTimeTag : Represents a timestamp value (an xsd:dateTimeStamp must be submitted in the data type attribute). The basic idea is that parts of a text can be marked up in a way that allows using Knora's built-in data types. In order to do so, the typed values have to be provided in a standardized way in an attribute that has to be defined in the mapping. Data type standoff classes are standoff classes with predefined properties (e.g., a knora-base:StandoffLinkTag has a knora-base:standoffTagHasLink and a knora-base:StandoffIntegerTag has a knora-base:valueHasInteger ). Please note the data type standoff classes can not be combined, i.e. a standoff class can only be the subclass of one data type standoff class. However, standoff data type classes can be subclassed and extended further by assigning properties to them (see below). The following simple mapping illustrates this principle: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>text</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>mydate</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/0001/anything#StandoffEventTag</classIri> <attributes> <attribute> <attributeName>description</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription</propertyIri> </attribute> </attributes> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffDateTag</type> <attributeName>knoraDate</attributeName> </datatype> </standoffClass> </mappingElement> </mapping> <datatype> must hold the Iri of a standoff data type class (see list above). The <classIri> must be a subclass of this type or this type itself (the latter is probably not recommendable since semantics are missing: what is the meaning of the date?). In the example above, the standoff class is anything:StandoffEventTag which has the following definition in the ontology anything-onto.ttl : anything:StandoffEventTag rdf:type owl:Class ; rdfs:subClassOf knora-base:StandoffDateTag, [ rdf:type owl:Restriction ; owl:onProperty :standoffEventTagHasDescription ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:label \"Represents an event in a TextValue\"@en ; rdfs:comment \"\"\"Represents an event in a TextValue\"\"\"@en . anything:StandoffEventTag is a subclass of knora-base:StandoffDateTag and therefore has the data type date. It also requires the standoff property anything:standoffEventTagHasDescription which is defined as an attribute in the mapping. Once the mapping has been created, an XML like the following could be sent to Knora and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description=\"new year\" knoraDate=\"GREGORIAN:2016-12-31\">New Year's Eve</mydate>. It was a lot of fun. </text> The attribute holds the date in the format of a Knora date string (the format is also documented in the typescript type alias dateString in module basicMessageComponents . There you will also find documentation about the other types like color etc.). Knora date strings have this format: GREGORIAN|JULIAN):YYYY[-MM[-DD]][:YYYY[-MM[-DD]]] . This allows for different formats as well as for imprecision and periods. Intervals are submitted as one attribute in the following format: interval-attribute=\"1.0,2.0\" (two decimal numbers separated with a comma). You will find a sample mapping with all the data types and a sample XML file in the the test data: test_data/test_route/texts/mappingForHTML.xml and test_data/test_route/texts/HTML.xml . Internal References in an XML Document Internal references inside an XML document can be represented using the data type standoff class knora-base:StandoffInternalReferenceTag or a subclass of it. This class has a standoff property that points to a standoff node representing the target XML element when converted to RDF. The following example shows the definition of a mapping element for an internal reference (for reasons of simplicity, only the mapping element for the element is question is depicted): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mappingElement> <tag> <name>ref</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag</classIri> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag</type> <attributeName>internalRef</attributeName> </datatype> </standoffClass> </mappingElement> Now, an internal reference to an element in the same document can be made that will be converted to a pointer in RDF: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This is an <sample id=\"1\">element</sample> and here is a reference to <ref internalRef=\"#1\">it</ref>. </text> An internal reference in XML has to start with a # followed by the value of the id attribute of the element referred to. Predefined Standoff Classes and Properties The standoff ontology standoff-onto.ttl offers a set of predefined standoff classes that can be used in a custom mapping like the following: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>myDoc</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> <attributes> <attribute> <attributeName>documentType</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/standoff#standoffRootTagHasDocumentType</propertyIri> </attribute> </attributes> </standoffClass> </mappingElement> <mappingElement> <tag> <name>p</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>true</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffParagraphTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>i</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffItalicTag</classIri> </standoffClass> </mappingElement> </mapping> Predefined standoff classes may be used by various projects, each providing a custom mapping to be able to recreate the original XML from RDF. Predefined standoff classes may also be inherited and extended in project specific ontologies. The mapping above allows for an XML like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <myDoc documentType=\"letter\"> <p> This my text that is <i>very</i> interesting. </p> <p> And here it goes on. </p> </myDoc> Respecting Property Types When mapping XML attributes to standoff properties, attention has to be paid to the properties' object constraints. In the ontology, standoff property literals may have one of the following knora-base:objectDatatypeConstraint : xsd:string xsd:integer xsd:boolean xsd:decimal xsd:anyURI In XML, all attribute values are submitted as strings. However, these string representations need to be convertible to the types defined in the ontology. If they are not, the request will be rejected. It is recommended to enforce types on attributes by applying XML Schema validations (restrictions). Links (object property) to a knora-base:Resource can be represented using the data type standoff class knora-base:StandoffLinkTag , internal links using the data type standoff class knora-base:StandoffInternalReferenceTag . Validating a Mapping and sending it to Knora A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v1/mapping The multipart request consists of two named parts: \"json\": { \"project_id\": \"projectIRI\", \"label\": \"my mapping\", \"mappingName\": \"MappingNameSegment\" } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the mappingName submitted in the JSON (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the typescript interfaces addMappingRequest and addMappingResponse in module mappingFormats","title":"XML to Standoff Mapping"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#xml-to-standoff-mapping-in-api-v1","text":"","title":"XML to Standoff Mapping in API v1"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#the-knora-standard-mapping","text":"","title":"The Knora Standard Mapping"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#description","text":"A mapping allows for the conversion of XML to standoff representation in RDF and back. In order to create a TextValue with markup, the text has to be provided in XML format, along with the IRI of the mapping that will be used to convert the markup to standoff. However, a mapping is only needed if a TextValue with markup should be created. If a text has no markup, it is submitted as a mere sequence of characters. The two cases are described in the TypeScript interfaces simpletext and richtext in module basicMessageComponents . Knora offers a standard mapping with the IRI http://rdfh.ch/standoff/mappings/StandardMapping . The standard mapping covers the HTML elements and attributes supported by the GUI's text editor, CKEditor . (Please note that the HTML has to be encoded in strict XML syntax. CKeditor offers the possibility to define filter rules. They should reflect the elements supported by the mapping; see jquery.htmleditor.js .) The standard mapping contains the following elements and attributes that are mapped to standoff classes and properties defined in the ontology: <text> \u2192 standoff:StandoffRootTag <p> \u2192 standoff:StandoffParagraphTag <em> \u2192 standoff:StandoffItalicTag <strong> \u2192 standoff:StandoffBoldTag <u> \u2192 standoff:StandoffUnderlineTag <sub> \u2192 standoff:StandoffSubscriptTag <sup> \u2192 standoff:StandoffSuperscriptTag <strike> \u2192 standoff:StandoffStrikeTag <a href=\"URL\"> \u2192 knora-base:StandoffUriTag <a class=\"salsah-link\" href=\"Knora IRI\"> \u2192 knora-base:StandoffLinkTag <a class=\"internal-link\" href=\"#fragment\"> \u2192 knora-base:StandoffInternalReferenceTag <h1> to <h6> \u2192 standoff:StandoffHeader1Tag to standoff:StandoffHeader6Tag <ol> \u2192 standoff:StandoffOrderedListTag <ul> \u2192 standoff:StandoffUnrderedListTag <li> \u2192 standoff:StandoffListElementTag <tbody> \u2192 standoff:StandoffTableBodyTag <table> \u2192 standoff:StandoffTableTag <tr> \u2192 standoff:StandoffTableRowTag <td> \u2192 standoff:StandoffTableCellTag <br> \u2192 standoff:StandoffBrTag <hr> \u2192 standoff:StandoffLineTag <pre> \u2192 standoff:StandoffPreTag <cite> \u2192 standoff:StandoffCiteTag <blockquote> \u2192 standoff:StandoffBlockquoteTag <code> \u2192 standoff:StandoffCodeTag The HTML produced by CKEditor is wrapped in an XML doctype and a pair of root tags <text>...</text> and then sent to Knora. The XML sent to the GUI by Knora is unwrapped accordingly (see jquery.htmleditor.js ). Although the GUI supports HTML5, it is treated as if it was XHTML in strict XML notation.","title":"Description"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#maintenance","text":"The standard mapping definition can be found at test_data/test_route/texts/mappingForStandardHTML.xml . It was used to generate the default mapping, distributed as knora-ontologies/standoff-data.ttl and that is loaded at a Knora installation. It should be used to re-generate it, whenever we want to amend or extend it. Note: once the mapping has been generated, one has to rework the resources' UUID in order to maintain backward compatibility.","title":"Maintenance"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#creating-a-custom-mapping","text":"The Knora standard mapping only supports a few HTML tags. In order to submit more complex XML markup to Knora, a custom mapping has to be created first. Basically, a mapping expresses the relations between XML elements and attributes and their corresponding standoff classes and properties. The relations expressed in a mapping are one-to-one relations, so the XML can be recreated from the data in RDF. However, since HTML offers a very limited set of elements, Knora mappings support the combination of element names and classes. In this way, the same element can be used several times in combination with another classname (please note that <a> without a class is a mere hyperlink whereas <a class=\"salsah-link\"> is an internal link/standoff link). With a mapping, a default XSL transformation may be provided to transform the XML to HTML before sending it back to the client. This is useful when the client is a web-browser expecting HTML (instead of XML).","title":"Creating a custom Mapping"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#basic-structure-of-a-mapping","text":"The mapping is written in XML itself (for a formal description, see webapi/src/resources/mappingXMLToStandoff.xsd ). It has the following structure (the indentation corresponds to the nesting in XML): <mapping> : the root element <defaultXSLTransformation> (optional) : the Iri of the default XSL transformation to be applied to the XML when reading it back from Knora. The XSL transformation is expected to produce HTML. If given, the Iri has to refer to a resource of type knora-base:XSLTransformation . <mappingElement> : an element of the mapping (at least one) <tag> : information about the XML element that is mapped to a standoff class <name> : name of the XML element <class> : value of the class attribute of the XML element, if any. If the element has no class attribute, the keyword noClass has to be used. <namespace> : the namespace the XML element belongs to, if any. If the element does not belong to a namespace, the keyword noNamespace has to be used. <separatesWords> : a Boolean value indicating whether this tag separates words in the text. Once an XML document is converted to RDF-standoff the markup is stripped from the text, possibly leading to continuous text that has been separated by tags before. For structural tags like paragraphs etc., <separatesWords> can be set to true in which case a special separator is inserted in the the text in the RDF representation. In this way, words stay separated and are represented in the fulltext index as such. <standoffClass> : information about the standoff class the XML element is mapped to <classIri> : Iri of the standoff class the XML element is mapped to <attributes> : XML attributes to be mapped to standoff properties (other than id or class ), if any <attribute> : an XML attribute to be mapped to a standoff property, may be repeated <attributeName> : the name of the XML attribute <namespace> : the namespace the attribute belongs to, if any. If the attribute does not belong to a namespace, the keyword noNamespace has to be used. <propertyIri> : the Iri of the standoff property the XML attribute is mapped to. <datatype> : the data type of the standoff class, if any. <type> : the Iri of the data type standoff class <attributeName> : the name of the attribute holding the typed value in the expected Knora standard format XML structure of a mapping: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <defaultXSLTransformation>Iri of a knora-base:XSLTransformation</defaultXSLTransformation> <mappingElement> <tag> <name>XML element name</name> <class>XML class name or \"noClass\"</class> <namespace>XML namespace or \"noNamespace\"</namespace> <separatesWords>true or false</separatesWords> </tag> <standoffClass> <classIri>standoff class Iri</classIri> <attributes> <attribute> <attributeName>XML attribute name</attributeName> <namespace>XML namespace or \"noNamespace\"</namespace> <propertyIri>standoff property Iri</propertyIri> </attribute> </attributes> <datatype> <type>standoff data type class</type> <attributeName>XML attribute with the typed value</attributeName> </datatype> </standoffClass> </mappingElement> <mappingElement> ... </mappingElement> </mapping> Please note that the absence of an XML namespace and/or a class have to be explicitly stated using the keywords noNamespace and noClass . (This is because we use XML Schema validation to ensure the one-to-one relations between XML elements and standoff classes. XML Schema validation's unique checks do not support optional values.)","title":"Basic Structure of a Mapping"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#id-and-class-attributes","text":"The id and class attributes are supported by default and do not have to be included in the mapping like other attributes. The id attribute identifies an element and must be unique in the document. id is an optional attribute. The class attribute allows for the reuse of an element in the mapping, i.e. the same element can be combined with different class names and mapped to different standoff classes (mapping element <class> in <tag> ).","title":"id and class Attributes"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#respecting-cardinalities","text":"A mapping from XML elements and attributes to standoff classes and standoff properties must respect the cardinalities defined in the ontology for those very standoff classes. If an XML element is mapped to a certain standoff class and this class requires a standoff property, an attribute must be defined for the XML element mapping to that very standoff property. Equally, all mappings for attributes of an XML element must have corresponding cardinalities for standoff properties defined for the standoff class the XML element maps to. However, since an XML attribute may occur once at maximum, it makes sense to make the corresponding standoff property required ( owl:cardinality of one) in the ontology or optional ( owl:maxCardinality of one), but not allowing it more than once.","title":"Respecting Cardinalities"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#standoff-data-types","text":"Knora allows the use of all its value types as standoff data types (defined in knora-base.ttl ): knora-base:StandoffLinkTag : Represents a reference to a Knora resource (the IRI of the target resource must be submitted in the data type attribute). knora-base:StandoffInternalReferenceTag : Represents an internal reference inside a document (the id of the target element inside the same document must be indicated in the data type attribute); see Internal References in an XML Document . knora-base:StandoffUriTag : Represents a reference to a URI (the URI of the target resource must be submitted in the data type attribute). knora-base:StandoffDateTag : Represents a date (a Knora date string must be submitted in the data type attribute, e.g. GREGORIAN:2017-01-27 ). knora-base:StandoffColorTag : Represents a color (a hexadecimal RGB color string must be submitted in the data type attribute, e.g. #0000FF ). knora-base:StandoffIntegerTag : Represents an integer (the integer must be submitted in the data type attribute). knora-base:StandoffDecimalTag : Represents a number with fractions (the decimal number must be submitted in the data type attribute, e.g. 1.1 ). knora-base:StandoffIntervalTag : Represents an interval (two decimal numbers separated with a comma must be submitted in the data type attribute, e.g. 1.1,2.2 ). knora-base:StandoffBooleanTag : Represents a Boolean value ( true or false must be submitted in the data type attribute). knora-base:StandoffTimeTag : Represents a timestamp value (an xsd:dateTimeStamp must be submitted in the data type attribute). The basic idea is that parts of a text can be marked up in a way that allows using Knora's built-in data types. In order to do so, the typed values have to be provided in a standardized way in an attribute that has to be defined in the mapping. Data type standoff classes are standoff classes with predefined properties (e.g., a knora-base:StandoffLinkTag has a knora-base:standoffTagHasLink and a knora-base:StandoffIntegerTag has a knora-base:valueHasInteger ). Please note the data type standoff classes can not be combined, i.e. a standoff class can only be the subclass of one data type standoff class. However, standoff data type classes can be subclassed and extended further by assigning properties to them (see below). The following simple mapping illustrates this principle: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>text</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>mydate</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/0001/anything#StandoffEventTag</classIri> <attributes> <attribute> <attributeName>description</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription</propertyIri> </attribute> </attributes> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffDateTag</type> <attributeName>knoraDate</attributeName> </datatype> </standoffClass> </mappingElement> </mapping> <datatype> must hold the Iri of a standoff data type class (see list above). The <classIri> must be a subclass of this type or this type itself (the latter is probably not recommendable since semantics are missing: what is the meaning of the date?). In the example above, the standoff class is anything:StandoffEventTag which has the following definition in the ontology anything-onto.ttl : anything:StandoffEventTag rdf:type owl:Class ; rdfs:subClassOf knora-base:StandoffDateTag, [ rdf:type owl:Restriction ; owl:onProperty :standoffEventTagHasDescription ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:label \"Represents an event in a TextValue\"@en ; rdfs:comment \"\"\"Represents an event in a TextValue\"\"\"@en . anything:StandoffEventTag is a subclass of knora-base:StandoffDateTag and therefore has the data type date. It also requires the standoff property anything:standoffEventTagHasDescription which is defined as an attribute in the mapping. Once the mapping has been created, an XML like the following could be sent to Knora and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description=\"new year\" knoraDate=\"GREGORIAN:2016-12-31\">New Year's Eve</mydate>. It was a lot of fun. </text> The attribute holds the date in the format of a Knora date string (the format is also documented in the typescript type alias dateString in module basicMessageComponents . There you will also find documentation about the other types like color etc.). Knora date strings have this format: GREGORIAN|JULIAN):YYYY[-MM[-DD]][:YYYY[-MM[-DD]]] . This allows for different formats as well as for imprecision and periods. Intervals are submitted as one attribute in the following format: interval-attribute=\"1.0,2.0\" (two decimal numbers separated with a comma). You will find a sample mapping with all the data types and a sample XML file in the the test data: test_data/test_route/texts/mappingForHTML.xml and test_data/test_route/texts/HTML.xml .","title":"Standoff Data Types"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#internal-references-in-an-xml-document","text":"Internal references inside an XML document can be represented using the data type standoff class knora-base:StandoffInternalReferenceTag or a subclass of it. This class has a standoff property that points to a standoff node representing the target XML element when converted to RDF. The following example shows the definition of a mapping element for an internal reference (for reasons of simplicity, only the mapping element for the element is question is depicted): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mappingElement> <tag> <name>ref</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag</classIri> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag</type> <attributeName>internalRef</attributeName> </datatype> </standoffClass> </mappingElement> Now, an internal reference to an element in the same document can be made that will be converted to a pointer in RDF: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This is an <sample id=\"1\">element</sample> and here is a reference to <ref internalRef=\"#1\">it</ref>. </text> An internal reference in XML has to start with a # followed by the value of the id attribute of the element referred to.","title":"Internal References in an XML Document"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#predefined-standoff-classes-and-properties","text":"The standoff ontology standoff-onto.ttl offers a set of predefined standoff classes that can be used in a custom mapping like the following: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>myDoc</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> <attributes> <attribute> <attributeName>documentType</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/standoff#standoffRootTagHasDocumentType</propertyIri> </attribute> </attributes> </standoffClass> </mappingElement> <mappingElement> <tag> <name>p</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>true</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffParagraphTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>i</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffItalicTag</classIri> </standoffClass> </mappingElement> </mapping> Predefined standoff classes may be used by various projects, each providing a custom mapping to be able to recreate the original XML from RDF. Predefined standoff classes may also be inherited and extended in project specific ontologies. The mapping above allows for an XML like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <myDoc documentType=\"letter\"> <p> This my text that is <i>very</i> interesting. </p> <p> And here it goes on. </p> </myDoc>","title":"Predefined Standoff Classes and Properties"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#respecting-property-types","text":"When mapping XML attributes to standoff properties, attention has to be paid to the properties' object constraints. In the ontology, standoff property literals may have one of the following knora-base:objectDatatypeConstraint : xsd:string xsd:integer xsd:boolean xsd:decimal xsd:anyURI In XML, all attribute values are submitted as strings. However, these string representations need to be convertible to the types defined in the ontology. If they are not, the request will be rejected. It is recommended to enforce types on attributes by applying XML Schema validations (restrictions). Links (object property) to a knora-base:Resource can be represented using the data type standoff class knora-base:StandoffLinkTag , internal links using the data type standoff class knora-base:StandoffInternalReferenceTag .","title":"Respecting Property Types"},{"location":"DSP-API/03-apis/api-v1/xml-to-standoff-mapping/#validating-a-mapping-and-sending-it-to-knora","text":"A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v1/mapping The multipart request consists of two named parts: \"json\": { \"project_id\": \"projectIRI\", \"label\": \"my mapping\", \"mappingName\": \"MappingNameSegment\" } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the mappingName submitted in the JSON (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the typescript interfaces addMappingRequest and addMappingResponse in module mappingFormats","title":"Validating a Mapping and sending it to Knora"},{"location":"DSP-API/03-apis/api-v2/","text":"DSP-API v2 Introduction Authentication Knora IRIs Reading and Searching Resources Reading the User's Permissions on Resources and Values Getting Lists XML to Standoff Mapping Gravsearch: Virtual Graph Search Editing Resources Editing Values Querying, Creating, and Updating Ontologies TEI/XML Permalinks","title":"Index"},{"location":"DSP-API/03-apis/api-v2/#dsp-api-v2","text":"Introduction Authentication Knora IRIs Reading and Searching Resources Reading the User's Permissions on Resources and Values Getting Lists XML to Standoff Mapping Gravsearch: Virtual Graph Search Editing Resources Editing Values Querying, Creating, and Updating Ontologies TEI/XML Permalinks","title":"DSP-API v2"},{"location":"DSP-API/03-apis/api-v2/authentication/","text":"Authentication Access to the DSP-API can for certain operations require a user to authenticate. Authentication can be performed in two ways: By providing password credentials , which are a combination of a identifier and password . The user identifier can be one of the following: the user's IRI, the user's Email, or the user's Username. By providing an access token Submitting Password Credentials When accessing any route and password credentials would need to be sent, we support two options to do so: in the URL submitting the parameters iri / email / username and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedIdentifier&password=pw ), and in the HTTP header ( HTTP basic authentication ), where the identifier can be the user's email (IRI and username not supported). When using Python's module requests , the credentials can simply be submitted as a tuple with each request using the param auth ( python requests ). Access Token / Session / Login and Logout A client can generate an access token by sending a POST request (e.g., {\"identifier_type\":\"identifier_value\", \"password\":\"password_value\"} ) to the /v2/authentication route with identifier and password in the body. The identifier_type can be iri , email , or username . If the credentials are valid, a JSON WEB Token (JWT) will be sent back in the response (e.g., {\"token\": \"eyJ0eXAiOiJ...\"} ). Additionally, for web browser clients a session cookie containing the JWT token is also created, containing KnoraAuthentication=eyJ0eXAiOiJ... . When accessing any route, the access token would need to be supplied, we support three options to do so: the session cookie, in the URL submitting the parameter token (e.g., http://knora-host/v1/resources/resIri?token=1234567890 ), and in the HTTP authorization header with the HTTP bearer scheme . If the token is successfully validated, then the user is deemed authenticated. To logout , the client sends a DELETE request to the same route /v2/authentication and the access token in one of the three described ways. This will invalidate the access token, thus not allowing further request that would supply the invalidated token. Checking Credentials To check the credentials, send a GET request to /v2/authentication with the credentials supplied as URL parameters or HTTP authentication headers as described before. Usage Scenarios Create token by logging-in, send token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Authentication"},{"location":"DSP-API/03-apis/api-v2/authentication/#authentication","text":"Access to the DSP-API can for certain operations require a user to authenticate. Authentication can be performed in two ways: By providing password credentials , which are a combination of a identifier and password . The user identifier can be one of the following: the user's IRI, the user's Email, or the user's Username. By providing an access token","title":"Authentication"},{"location":"DSP-API/03-apis/api-v2/authentication/#submitting-password-credentials","text":"When accessing any route and password credentials would need to be sent, we support two options to do so: in the URL submitting the parameters iri / email / username and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedIdentifier&password=pw ), and in the HTTP header ( HTTP basic authentication ), where the identifier can be the user's email (IRI and username not supported). When using Python's module requests , the credentials can simply be submitted as a tuple with each request using the param auth ( python requests ).","title":"Submitting Password Credentials"},{"location":"DSP-API/03-apis/api-v2/authentication/#access-token-session-login-and-logout","text":"A client can generate an access token by sending a POST request (e.g., {\"identifier_type\":\"identifier_value\", \"password\":\"password_value\"} ) to the /v2/authentication route with identifier and password in the body. The identifier_type can be iri , email , or username . If the credentials are valid, a JSON WEB Token (JWT) will be sent back in the response (e.g., {\"token\": \"eyJ0eXAiOiJ...\"} ). Additionally, for web browser clients a session cookie containing the JWT token is also created, containing KnoraAuthentication=eyJ0eXAiOiJ... . When accessing any route, the access token would need to be supplied, we support three options to do so: the session cookie, in the URL submitting the parameter token (e.g., http://knora-host/v1/resources/resIri?token=1234567890 ), and in the HTTP authorization header with the HTTP bearer scheme . If the token is successfully validated, then the user is deemed authenticated. To logout , the client sends a DELETE request to the same route /v2/authentication and the access token in one of the three described ways. This will invalidate the access token, thus not allowing further request that would supply the invalidated token.","title":"Access Token / Session / Login and Logout"},{"location":"DSP-API/03-apis/api-v2/authentication/#checking-credentials","text":"To check the credentials, send a GET request to /v2/authentication with the credentials supplied as URL parameters or HTTP authentication headers as described before.","title":"Checking Credentials"},{"location":"DSP-API/03-apis/api-v2/authentication/#usage-scenarios","text":"Create token by logging-in, send token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Usage Scenarios"},{"location":"DSP-API/03-apis/api-v2/editing-resources/","text":"Editing Resources Creating a Resource To create a new resources, use this route: HTTP POST to http://host/v2/resources The body of the request is a JSON-LD document in the complex API schema , specifying the type, rdfs:label , and its Knora resource properties and their values. The representation of the resource is the same as when it is returned in a GET request, except that its knora-api:attachedToUser is not given, and the resource IRI and those of its values can be optionally specified. The format of the values submitted is described in Editing Values . If there are multiple values for a property, these must be given in an array. For example, here is a request to create a resource with various value types: { \"@type\" : \"anything:Thing\", \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\", \"knora-api:booleanValueAsBoolean\" : true }, \"anything:hasColor\" : { \"@type\" : \"knora-api:ColorValue\", \"knora-api:colorValueAsColor\" : \"#ff3333\" }, \"anything:hasDate\" : { \"@type\" : \"knora-api:DateValue\", \"knora-api:dateValueHasCalendar\" : \"GREGORIAN\", \"knora-api:dateValueHasEndEra\" : \"CE\", \"knora-api:dateValueHasEndYear\" : 1489, \"knora-api:dateValueHasStartEra\" : \"CE\", \"knora-api:dateValueHasStartYear\" : 1489 }, \"anything:hasDecimal\" : { \"@type\" : \"knora-api:DecimalValue\", \"knora-api:decimalValueAsDecimal\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"100000000000000.000000000000001\" } }, \"anything:hasGeometry\" : { \"@type\" : \"knora-api:GeomValue\", \"knora-api:geometryValueAsGeometry\" : \"{\\\"status\\\":\\\"active\\\",\\\"lineColor\\\":\\\"#ff3333\\\",\\\"lineWidth\\\":2,\\\"points\\\":[{\\\"x\\\":0.08098591549295775,\\\"y\\\":0.16741071428571427},{\\\"x\\\":0.7394366197183099,\\\"y\\\":0.7299107142857143}],\\\"type\\\":\\\"rectangle\\\",\\\"original_index\\\":0}\" }, \"anything:hasGeoname\" : { \"@type\" : \"knora-api:GeonameValue\", \"knora-api:geonameValueAsGeonameCode\" : \"2661604\" }, \"anything:hasInteger\" : [ { \"@type\" : \"knora-api:IntValue\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\", \"knora-api:intValueAsInt\" : 5, \"knora-api:valueHasComment\" : \"this is the number five\" }, { \"@type\" : \"knora-api:IntValue\", \"knora-api:intValueAsInt\" : 6 } ], \"anything:hasInterval\" : { \"@type\" : \"knora-api:IntervalValue\", \"knora-api:intervalValueHasEnd\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"3.4\" }, \"knora-api:intervalValueHasStart\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"1.2\" } }, \"anything:hasListItem\" : { \"@type\" : \"knora-api:ListValue\", \"knora-api:listValueAsListNode\" : { \"@id\" : \"http://rdfh.ch/lists/0001/treeList03\" } }, \"anything:hasOtherThingValue\" : { \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" } }, \"anything:hasRichtext\" : { \"@type\" : \"knora-api:TextValue\", \"knora-api:textValueAsXml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text><p><strong>this is</strong> text</p> with standoff</text>\", \"knora-api:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\", \"knora-api:valueAsString\" : \"this is text without standoff\" }, \"anything:hasUri\" : { \"@type\" : \"knora-api:UriValue\", \"knora-api:uriValueAsUri\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"https://www.knora.org\" } }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"rdfs:label\" : \"test thing\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new resource can be given by adding knora-api:hasPermissions , a custom creation date can be specified by adding knora-api:creationDate (an xsd:dateTimeStamp ), and the resource's creator can be specfied by adding knora-api:attachedToUser . For example: { \"@type\" : \"anything:Thing\", \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\", \"knora-api:booleanValueAsBoolean\" : true }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"rdfs:label\" : \"test thing\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a resource, the user must have permission to create resources of that class in that project. The predicate knora-api:attachedToUser can be used to specify a creator other than the requesting user only if the requesting user is an administrator of the project or a system administrator. The specified creator must also have permission to create resources of that class in that project. In addition to the creation date, in the body of the request, it is possible to specify a custom IRI ( of Knora IRI form) for a resource through the @id attribute which will then be assigned to the resource; otherwise the resource will get a unique random IRI. A custom resource IRI must be http://rdfh.ch/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the resource belongs to) plus a custom ID string. Similarly, it is possible to assign a custom IRI to the values using their @id attributes; if not given, random IRIs will be assigned to the values. A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. An optional custom UUID of a value can also be given by adding knora-api:valueHasUUID . Each custom UUID must be base64url-encoded without padding. Each value of the new resource can also have a custom creation date specified by adding knora-api:creationDate (an xsd:dateTimeStamp ). For example: { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw\", \"@type\" : \"anything:Thing\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw/values/IN4R19yYR0ygi3K2VEHpUQ\", \"@type\" : \"knora-api:IntValue\", \"knora-api:intValueAsInt\" : 10, \"knora-api:valueHasUUID\" : \"IN4R19yYR0ygi3K2VEHpUQ\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2020-06-04T12:58:54.502951Z\" } }, \"rdfs:label\" : \"test thing with custom IRI\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The response is a JSON-LD document containing a preview of the resource. Modifying a Resource's Values See Editing Values . Modifying a Resource's Metadata You can modify the following metadata attached to a resource: label permissions last modification date To do this, use this route: HTTP PUT to http://host/v2/resources The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. The submitted JSON-LD object must also contain one or more of the following predicates, representing the metadata you want to change: rdfs:label : a string knora-api:hasPermissions , in the format described in Permissions knora-api:newModificationDate : an xsd:dateTimeStamp . Here is an example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"this is the new label\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:ProjectMember\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2017-11-20T15:55:17Z\" }, \"knora-api:newModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2018-12-21T16:56:18Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } If you submit a knora-api:lastModificationDate that is different from the resource's actual last modification date, you will get an HTTP 409 (Conflict) error. If you submit a knora-api:newModificationDate that is earlier than the resource's knora-api:lastModificationDate , you will get an HTTP 400 (Bad Request) error. A successful response is an HTTP 200 (OK) status containing the resource's metadata. Deleting a Resource Knora does not normally delete resources; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a resource as deleted, use this route: HTTP POST to http://host/v2/resources/delete The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. { \"@id\" : \"http://rdfh.ch/0001/a-thing\", \"@type\" : \"anything:Thing\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-05T17:05:35.776747Z\" }, \"knora-api:deleteComment\" : \"This resource was created by mistake.\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the resource, explaining why it has been marked as deleted. The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) indicates when the resource was marked as deleted; if not given, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message. Requesting Deleted Resources Resources marked as deleted are not found in search queries. It is however possible to request them directly or from an ARK URL. In these instances, the API will not return the deleted resource, but instead a generic resource of type knora-base:DeletedResource . This resource will be similar to the requested resource, having e.g. the same IRI. The resource will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"rdfs:label\": \"Deleted Resource\", \"knora-api:versionArkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO.20211214T084407677335Z\", \"@type\": \"xsd:anyURI\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/0001\" }, \"knora-api:userHasPermission\": \"CR\", \"knora-api:attachedToUser\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\": \"CR knora-admin:ProjectMember|V knora-admin:ProjectMember\", \"knora-api:isDeleted\": true, \"@type\": \"knora-api:DeletedResource\", \"@id\": \"http://rdfh.ch/0001/a-thing\", \"knora-api:deleteComment\": \"This resource is too boring.\", \"knora-api:arkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO\", \"@type\": \"xsd:anyURI\" }, \"knora-api:creationDate\": { \"@value\": \"2021-12-14T08:44:07.677335Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2021-12-14T08:44:07.372543Z\" }, \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Links to Deleted Resources If resource A has a link to resource B , and resource B is later marked as deleted, A 's link will still exist. DSP-API v2 will still return the link when A is queried, but without any information about B (except for B 's IRI). If A 's link is necessary to meet the requirements of a cardinality, marking B as deleted will not violate the cardinality. The reason for this design is that A and B might be in different projects, and each project must retain control of its resources and be able to mark them as deleted, even if they are used by another project. Erasing a Resource from the Triplestore Normally, resources are not actually removed from the triplestore; they are only marked as deleted (see Deleting a Resource ). However, sometimes it is necessary to erase a resource from the triplestore. To do so, use this route: HTTP POST to http://host/v2/resources/erase The request body is the same as for Deleting a Resource , except that knora-api:deleteComment is not relevant and will be ignored. To do this, a user must be a system administrator or an administrator of the project containing the resource. The user's permissions on the resource are not otherwise checked. A resource cannot be erased if any other resource has a link to it. Any such links must first be changed or marked as deleted (see Updating a Value and Deleting a Value ). Then, when the resource is erased, the deleted link values that referred to it will also be erased. This operation cannot be undone (except by restoring the repository from a backup), so use it with care.","title":"Editing Resources"},{"location":"DSP-API/03-apis/api-v2/editing-resources/#editing-resources","text":"","title":"Editing Resources"},{"location":"DSP-API/03-apis/api-v2/editing-resources/#creating-a-resource","text":"To create a new resources, use this route: HTTP POST to http://host/v2/resources The body of the request is a JSON-LD document in the complex API schema , specifying the type, rdfs:label , and its Knora resource properties and their values. The representation of the resource is the same as when it is returned in a GET request, except that its knora-api:attachedToUser is not given, and the resource IRI and those of its values can be optionally specified. The format of the values submitted is described in Editing Values . If there are multiple values for a property, these must be given in an array. For example, here is a request to create a resource with various value types: { \"@type\" : \"anything:Thing\", \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\", \"knora-api:booleanValueAsBoolean\" : true }, \"anything:hasColor\" : { \"@type\" : \"knora-api:ColorValue\", \"knora-api:colorValueAsColor\" : \"#ff3333\" }, \"anything:hasDate\" : { \"@type\" : \"knora-api:DateValue\", \"knora-api:dateValueHasCalendar\" : \"GREGORIAN\", \"knora-api:dateValueHasEndEra\" : \"CE\", \"knora-api:dateValueHasEndYear\" : 1489, \"knora-api:dateValueHasStartEra\" : \"CE\", \"knora-api:dateValueHasStartYear\" : 1489 }, \"anything:hasDecimal\" : { \"@type\" : \"knora-api:DecimalValue\", \"knora-api:decimalValueAsDecimal\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"100000000000000.000000000000001\" } }, \"anything:hasGeometry\" : { \"@type\" : \"knora-api:GeomValue\", \"knora-api:geometryValueAsGeometry\" : \"{\\\"status\\\":\\\"active\\\",\\\"lineColor\\\":\\\"#ff3333\\\",\\\"lineWidth\\\":2,\\\"points\\\":[{\\\"x\\\":0.08098591549295775,\\\"y\\\":0.16741071428571427},{\\\"x\\\":0.7394366197183099,\\\"y\\\":0.7299107142857143}],\\\"type\\\":\\\"rectangle\\\",\\\"original_index\\\":0}\" }, \"anything:hasGeoname\" : { \"@type\" : \"knora-api:GeonameValue\", \"knora-api:geonameValueAsGeonameCode\" : \"2661604\" }, \"anything:hasInteger\" : [ { \"@type\" : \"knora-api:IntValue\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\", \"knora-api:intValueAsInt\" : 5, \"knora-api:valueHasComment\" : \"this is the number five\" }, { \"@type\" : \"knora-api:IntValue\", \"knora-api:intValueAsInt\" : 6 } ], \"anything:hasInterval\" : { \"@type\" : \"knora-api:IntervalValue\", \"knora-api:intervalValueHasEnd\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"3.4\" }, \"knora-api:intervalValueHasStart\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"1.2\" } }, \"anything:hasListItem\" : { \"@type\" : \"knora-api:ListValue\", \"knora-api:listValueAsListNode\" : { \"@id\" : \"http://rdfh.ch/lists/0001/treeList03\" } }, \"anything:hasOtherThingValue\" : { \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" } }, \"anything:hasRichtext\" : { \"@type\" : \"knora-api:TextValue\", \"knora-api:textValueAsXml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text><p><strong>this is</strong> text</p> with standoff</text>\", \"knora-api:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\", \"knora-api:valueAsString\" : \"this is text without standoff\" }, \"anything:hasUri\" : { \"@type\" : \"knora-api:UriValue\", \"knora-api:uriValueAsUri\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"https://www.knora.org\" } }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"rdfs:label\" : \"test thing\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new resource can be given by adding knora-api:hasPermissions , a custom creation date can be specified by adding knora-api:creationDate (an xsd:dateTimeStamp ), and the resource's creator can be specfied by adding knora-api:attachedToUser . For example: { \"@type\" : \"anything:Thing\", \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\", \"knora-api:booleanValueAsBoolean\" : true }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"rdfs:label\" : \"test thing\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a resource, the user must have permission to create resources of that class in that project. The predicate knora-api:attachedToUser can be used to specify a creator other than the requesting user only if the requesting user is an administrator of the project or a system administrator. The specified creator must also have permission to create resources of that class in that project. In addition to the creation date, in the body of the request, it is possible to specify a custom IRI ( of Knora IRI form) for a resource through the @id attribute which will then be assigned to the resource; otherwise the resource will get a unique random IRI. A custom resource IRI must be http://rdfh.ch/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the resource belongs to) plus a custom ID string. Similarly, it is possible to assign a custom IRI to the values using their @id attributes; if not given, random IRIs will be assigned to the values. A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. An optional custom UUID of a value can also be given by adding knora-api:valueHasUUID . Each custom UUID must be base64url-encoded without padding. Each value of the new resource can also have a custom creation date specified by adding knora-api:creationDate (an xsd:dateTimeStamp ). For example: { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw\", \"@type\" : \"anything:Thing\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw/values/IN4R19yYR0ygi3K2VEHpUQ\", \"@type\" : \"knora-api:IntValue\", \"knora-api:intValueAsInt\" : 10, \"knora-api:valueHasUUID\" : \"IN4R19yYR0ygi3K2VEHpUQ\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2020-06-04T12:58:54.502951Z\" } }, \"rdfs:label\" : \"test thing with custom IRI\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The response is a JSON-LD document containing a preview of the resource.","title":"Creating a Resource"},{"location":"DSP-API/03-apis/api-v2/editing-resources/#modifying-a-resources-values","text":"See Editing Values .","title":"Modifying a Resource's Values"},{"location":"DSP-API/03-apis/api-v2/editing-resources/#modifying-a-resources-metadata","text":"You can modify the following metadata attached to a resource: label permissions last modification date To do this, use this route: HTTP PUT to http://host/v2/resources The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. The submitted JSON-LD object must also contain one or more of the following predicates, representing the metadata you want to change: rdfs:label : a string knora-api:hasPermissions , in the format described in Permissions knora-api:newModificationDate : an xsd:dateTimeStamp . Here is an example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"this is the new label\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:ProjectMember\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2017-11-20T15:55:17Z\" }, \"knora-api:newModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2018-12-21T16:56:18Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } If you submit a knora-api:lastModificationDate that is different from the resource's actual last modification date, you will get an HTTP 409 (Conflict) error. If you submit a knora-api:newModificationDate that is earlier than the resource's knora-api:lastModificationDate , you will get an HTTP 400 (Bad Request) error. A successful response is an HTTP 200 (OK) status containing the resource's metadata.","title":"Modifying a Resource's Metadata"},{"location":"DSP-API/03-apis/api-v2/editing-resources/#deleting-a-resource","text":"Knora does not normally delete resources; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a resource as deleted, use this route: HTTP POST to http://host/v2/resources/delete The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. { \"@id\" : \"http://rdfh.ch/0001/a-thing\", \"@type\" : \"anything:Thing\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-05T17:05:35.776747Z\" }, \"knora-api:deleteComment\" : \"This resource was created by mistake.\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the resource, explaining why it has been marked as deleted. The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) indicates when the resource was marked as deleted; if not given, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message.","title":"Deleting a Resource"},{"location":"DSP-API/03-apis/api-v2/editing-resources/#requesting-deleted-resources","text":"Resources marked as deleted are not found in search queries. It is however possible to request them directly or from an ARK URL. In these instances, the API will not return the deleted resource, but instead a generic resource of type knora-base:DeletedResource . This resource will be similar to the requested resource, having e.g. the same IRI. The resource will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"rdfs:label\": \"Deleted Resource\", \"knora-api:versionArkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO.20211214T084407677335Z\", \"@type\": \"xsd:anyURI\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/0001\" }, \"knora-api:userHasPermission\": \"CR\", \"knora-api:attachedToUser\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\": \"CR knora-admin:ProjectMember|V knora-admin:ProjectMember\", \"knora-api:isDeleted\": true, \"@type\": \"knora-api:DeletedResource\", \"@id\": \"http://rdfh.ch/0001/a-thing\", \"knora-api:deleteComment\": \"This resource is too boring.\", \"knora-api:arkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO\", \"@type\": \"xsd:anyURI\" }, \"knora-api:creationDate\": { \"@value\": \"2021-12-14T08:44:07.677335Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2021-12-14T08:44:07.372543Z\" }, \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Requesting Deleted Resources"},{"location":"DSP-API/03-apis/api-v2/editing-resources/#links-to-deleted-resources","text":"If resource A has a link to resource B , and resource B is later marked as deleted, A 's link will still exist. DSP-API v2 will still return the link when A is queried, but without any information about B (except for B 's IRI). If A 's link is necessary to meet the requirements of a cardinality, marking B as deleted will not violate the cardinality. The reason for this design is that A and B might be in different projects, and each project must retain control of its resources and be able to mark them as deleted, even if they are used by another project.","title":"Links to Deleted Resources"},{"location":"DSP-API/03-apis/api-v2/editing-resources/#erasing-a-resource-from-the-triplestore","text":"Normally, resources are not actually removed from the triplestore; they are only marked as deleted (see Deleting a Resource ). However, sometimes it is necessary to erase a resource from the triplestore. To do so, use this route: HTTP POST to http://host/v2/resources/erase The request body is the same as for Deleting a Resource , except that knora-api:deleteComment is not relevant and will be ignored. To do this, a user must be a system administrator or an administrator of the project containing the resource. The user's permissions on the resource are not otherwise checked. A resource cannot be erased if any other resource has a link to it. Any such links must first be changed or marked as deleted (see Updating a Value and Deleting a Value ). Then, when the resource is erased, the deleted link values that referred to it will also be erased. This operation cannot be undone (except by restoring the repository from a backup), so use it with care.","title":"Erasing a Resource from the Triplestore"},{"location":"DSP-API/03-apis/api-v2/editing-values/","text":"Editing Values Creating a Value To create a value in an existing resource, use this route: HTTP POST to http://host/v2/values The body of the request is a JSON-LD document in the complex API schema , specifying the resource's IRI and type, the resource property, and the content of the value. The representation of the value is the same as when it is returned in a GET request, except that its IRI and knora-api:attachedToUser are not given. For example, to create an integer value: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4 }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have a comment, given in knora-api:valueHasComment . For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4, \"knora-api:valueHasComment\": \"This is a comment.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new value can be given by adding knora-api:hasPermissions . For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4, \"knora-api:hasPermissions\": \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have an optional custom IRI (of Knora IRI form) specified by the @id attribute, a custom creation date specified by adding knora-api:valueCreationDate (an xsd:dateTimeStamp ), or a custom UUID given by knora-api:valueHasUUID . Each custom UUID must be base64url-encoded , without padding. If a custom UUID is provided, it will be used in value IRI. If a custom IRI is given for the value, its UUID should match the given custom UUID. If a custom IRI is provided, but there is no custom UUID provided, then the UUID given in the IRI will be assigned to the knora-api:valueHasUUID . A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/IN4R19yYR0ygi3K2VEHpUQ\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 21, \"knora-api:valueHasUUID\": \"IN4R19yYR0ygi3K2VEHpUQ\", \"knora-api:valueCreationDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2020-06-04T12:58:54.502951Z\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a value, the user must have modify permission on the containing resource. The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions (except for link values, as explained below). Creating a Link Between Resources To create a link, you must create a knora-api:LinkValue , which represents metadata about the link. The property that connects the resource to the LinkValue is a link value property, whose name is constructed by adding Value to the name of the link property (see Links Between Resources ). The triple representing the direct link between the resources is created automatically. For example, if the link property that should connect the resources is anything:hasOtherThing , we can create a link like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasOtherThingValue\": { \"@type\": \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\": { \"@id\": \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } }, \"@context\": { \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } As with ordinary values, permissions on links can be specified by adding knora-api:hasPermissions . The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the link is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Changing a link's metadata, without changing its target, creates a new version of the link value with the same UUID. Creating a Text Value Without Standoff Markup Use the predicate knora-api:valueAsString of knora-api:TextValue : { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasText\": { \"@type\": \"knora-api:TextValue\", \"knora-api:valueAsString\": \"This is a text without markup.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Creating a Text Value with Standoff Markup Currently, the only way to create a text value with standoff markup is to submit it in XML format using an XML-to-standoff mapping . For example, suppose we use the standard mapping, http://rdfh.ch/standoff/mappings/StandardMapping . We can then make an XML document like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This text links to another <a class=\"salsah-link\" href=\"http://rdfh.ch/0001/another-thing\">resource</a>. </text> This document can then be embedded in a JSON-LD request, using the predicate knora-api:textValueAsXml : { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasText\": { \"@type\": \"knora-api:TextValue\", \"knora-api:textValueAsXml\": \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text>\\n This text links to another <a class=\\\"salsah-link\\\" href=\\\"http://rdfh.ch/0001/another-thing\\\">resource</a>.\\n</text>\", \"knora-api:textValueHasMapping\": { \"@id\": \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Note that quotation marks and line breaks in the XML must be escaped, and that the IRI of the mapping must be provided. Creating File Values Knora supports the storage of certain types of data as files, using Sipi (see FileValue ). DSP-API v2 currently supports using Sipi to store the following types of files: Images: JPEG, JPEG2000, TIFF, or PNG which are stored internally as JPEG2000 Documents: PDF Audio: MPEG, MP4, or Waveform audio file format (.wav, .x-wav, .vnd.wave) Text files: TXT, XML, or CSV Video files: MP4 Archive files: ZIP, TAR, GZIP Support for other types of files will be added in the future. The following sections describe the steps for creating a file value. Upload Files to Sipi The first step is to upload one or more files to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The token parameter must provide the JSON Web Token that Knora returned when the client logged in. Each body part in the request must contain a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi stores the file in a temporary location. If the file is an image, it is converted first to JPEG2000 format, and the converted file is stored. Sipi then returns a JSON response that looks something like this: { \"uploadedFiles\": [ { \"originalFilename\": \"manuscript-1234-page-1.tiff\", \"internalFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" }, { \"originalFilename\": \"manuscript-1234-page-2.tiff\", \"internalFilename\": \"2RvJgguglpe-B45EOk0Gx8H.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" } ] } In this example, we uploaded two files to Sipi, so uploadedFiles is an array with two elements. For each file, we have: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file In the case of an image file, the client may now wish to get a thumbnail of each uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image that is 150 pixels wide, you would add /full/150,/0/default.jpg . Submit A File Value to Knora A Knora Representation (i.e. a resource containing information about a file) must always have exactly one file value attached to it. (see Representations ). Therefore, a request to create a new file value must always be submitted as part of a request to create a new resource (see Creating a Resource ). You can also update a file value in an existing Representation ; see Updating a Value . Instead of providing the file's complete metadata to Knora, you just provide the unique internal filename generated by Sipi. Here is an example of a request to create a resource of class anything:ThingPicture , which is a subclass of knora-api:StillImageRepresentation and therefore has the property knora-api:hasStillImageFileValue : { \"@type\": \"anything:ThingPicture\", \"knora-api:hasStillImageFileValue\": { \"@type\": \"knora-api:StillImageFileValue\", \"knora-api:fileValueHasFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/0001\" }, \"rdfs:label\": \"test thing\", \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Knora then gets the rest of the file's metadata from Sipi. If the client's request to Knora is valid, Knora saves the file value in the triplestore and instructs Sipi to move the file to permanent storage. Otherwise, the temporary file that was stored by Sipi is deleted. If you're submitting a PDF document, use the resource class knora-api:DocumentRepresentation , which has the property knora-api:hasDocumentFileValue , pointing to a knora-api:DocumentFileValue . For a text file, use knora-api:TextRepresentation , which has the property knora-api:hasTextFileValue , pointing to a knora-api:TextFileValue . For an archive like zip, use knora-api:ArchiveRepresentation , which has the property knora-api:hasArchiveFileValue , pointing to a knora-api:ArchiveFileValue . Updating a Value To update a value, use this route: HTTP PUT to http://host/v2/values Updating a value means creating a new version of an existing value. The new version will have a different IRI. The request is the same as for creating a value, except that the @id of the current value version is given. For example, to update an integer value: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 5 }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The value can be given a comment by using knora-api:valueHasComment . To change only the comment of a value, you can resubmit the existing value with the updated comment. Permissions can be specified by adding knora-api:hasPermissions . Otherwise, the new version has the same permissions as the previous one. To change the permissions on a value, the user must have change rights permission on the value. To update only the permissions on a value, submit it with the new permissions and with its @id and @type but without any other content, like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|V knora-admin:KnownUser\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } To update a link, the user must have modify permission on the containing resource as well as on the value. To update a value and give it a custom timestamp, add knora-api:valueCreationDate (an xsd:dateTimeStamp ). To update a value and give the new version a custom IRI, add knora-api:newValueVersionIri , like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 21, \"knora-api:newValueVersionIri\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/int-value-IRI\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. The response is a JSON-LD document containing only @id and @type , returning the IRI and type of the new value version. If you submit an outdated value ID in a request to update a value, the response will be an HTTP 404 (Not Found) error. The response to a value update request contains: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the value is a link value and is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Deleting a Value Knora does not normally delete values; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a value as deleted, use this route: HTTP POST to http://host/v2/values/delete The request must include the resource's ID and type, the property that points from the resource to the value, and the value's ID and type. For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:deleteComment\": \"This value was created by mistake.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the value, explaining why it has been marked as deleted The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) specifies a custom timestamp indicating when the value was deleted. If not specified, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message. Requesting Deleted Values Values marked as deleted are not found in search queries. But when requesting a resource that has deleted values, these will show up as generic knora-api:DeletedValue values. This value will be similar to the deleted value, having e.g. the same IRI. The DeletedValue will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"knora-api:DeletedValue\": [ { \"knora-api:versionArkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU.20211216T18193124797Z\", \"@type\": \"xsd:anyURI\" }, \"knora-api:userHasPermission\": \"RV\", \"knora-api:valueCreationDate\": { \"@value\": \"2021-12-16T18:19:31.247970Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2021-12-16T18:20:02.550828Z\" }, \"knora-api:attachedToUser\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:valueHasUUID\": \"sWSymIzAS_qXqyHLhwbwwA\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser|RV knora-admin:UnknownUser\", \"knora-api:isDeleted\": true, \"@type\": \"knora-api:DeletedValue\", \"http://www.knora.org/ontology/knora-base#DeletedValue\": \"DeletedValue\", \"@id\": \"http://rdfh.ch/0001/a-thing/values/DrXts3Up3DijGriI403nhg\", \"knora-api:deleteComment\": \"This value is obsolete\", \"knora-api:arkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU\", \"@type\": \"xsd:anyURI\" } }, {} ] }","title":"Editing Values"},{"location":"DSP-API/03-apis/api-v2/editing-values/#editing-values","text":"","title":"Editing Values"},{"location":"DSP-API/03-apis/api-v2/editing-values/#creating-a-value","text":"To create a value in an existing resource, use this route: HTTP POST to http://host/v2/values The body of the request is a JSON-LD document in the complex API schema , specifying the resource's IRI and type, the resource property, and the content of the value. The representation of the value is the same as when it is returned in a GET request, except that its IRI and knora-api:attachedToUser are not given. For example, to create an integer value: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4 }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have a comment, given in knora-api:valueHasComment . For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4, \"knora-api:valueHasComment\": \"This is a comment.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new value can be given by adding knora-api:hasPermissions . For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4, \"knora-api:hasPermissions\": \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have an optional custom IRI (of Knora IRI form) specified by the @id attribute, a custom creation date specified by adding knora-api:valueCreationDate (an xsd:dateTimeStamp ), or a custom UUID given by knora-api:valueHasUUID . Each custom UUID must be base64url-encoded , without padding. If a custom UUID is provided, it will be used in value IRI. If a custom IRI is given for the value, its UUID should match the given custom UUID. If a custom IRI is provided, but there is no custom UUID provided, then the UUID given in the IRI will be assigned to the knora-api:valueHasUUID . A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/IN4R19yYR0ygi3K2VEHpUQ\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 21, \"knora-api:valueHasUUID\": \"IN4R19yYR0ygi3K2VEHpUQ\", \"knora-api:valueCreationDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2020-06-04T12:58:54.502951Z\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a value, the user must have modify permission on the containing resource. The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions (except for link values, as explained below).","title":"Creating a Value"},{"location":"DSP-API/03-apis/api-v2/editing-values/#creating-a-link-between-resources","text":"To create a link, you must create a knora-api:LinkValue , which represents metadata about the link. The property that connects the resource to the LinkValue is a link value property, whose name is constructed by adding Value to the name of the link property (see Links Between Resources ). The triple representing the direct link between the resources is created automatically. For example, if the link property that should connect the resources is anything:hasOtherThing , we can create a link like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasOtherThingValue\": { \"@type\": \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\": { \"@id\": \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } }, \"@context\": { \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } As with ordinary values, permissions on links can be specified by adding knora-api:hasPermissions . The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the link is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Changing a link's metadata, without changing its target, creates a new version of the link value with the same UUID.","title":"Creating a Link Between Resources"},{"location":"DSP-API/03-apis/api-v2/editing-values/#creating-a-text-value-without-standoff-markup","text":"Use the predicate knora-api:valueAsString of knora-api:TextValue : { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasText\": { \"@type\": \"knora-api:TextValue\", \"knora-api:valueAsString\": \"This is a text without markup.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } }","title":"Creating a Text Value Without Standoff Markup"},{"location":"DSP-API/03-apis/api-v2/editing-values/#creating-a-text-value-with-standoff-markup","text":"Currently, the only way to create a text value with standoff markup is to submit it in XML format using an XML-to-standoff mapping . For example, suppose we use the standard mapping, http://rdfh.ch/standoff/mappings/StandardMapping . We can then make an XML document like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This text links to another <a class=\"salsah-link\" href=\"http://rdfh.ch/0001/another-thing\">resource</a>. </text> This document can then be embedded in a JSON-LD request, using the predicate knora-api:textValueAsXml : { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasText\": { \"@type\": \"knora-api:TextValue\", \"knora-api:textValueAsXml\": \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text>\\n This text links to another <a class=\\\"salsah-link\\\" href=\\\"http://rdfh.ch/0001/another-thing\\\">resource</a>.\\n</text>\", \"knora-api:textValueHasMapping\": { \"@id\": \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Note that quotation marks and line breaks in the XML must be escaped, and that the IRI of the mapping must be provided.","title":"Creating a Text Value with Standoff Markup"},{"location":"DSP-API/03-apis/api-v2/editing-values/#creating-file-values","text":"Knora supports the storage of certain types of data as files, using Sipi (see FileValue ). DSP-API v2 currently supports using Sipi to store the following types of files: Images: JPEG, JPEG2000, TIFF, or PNG which are stored internally as JPEG2000 Documents: PDF Audio: MPEG, MP4, or Waveform audio file format (.wav, .x-wav, .vnd.wave) Text files: TXT, XML, or CSV Video files: MP4 Archive files: ZIP, TAR, GZIP Support for other types of files will be added in the future. The following sections describe the steps for creating a file value.","title":"Creating File Values"},{"location":"DSP-API/03-apis/api-v2/editing-values/#upload-files-to-sipi","text":"The first step is to upload one or more files to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The token parameter must provide the JSON Web Token that Knora returned when the client logged in. Each body part in the request must contain a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi stores the file in a temporary location. If the file is an image, it is converted first to JPEG2000 format, and the converted file is stored. Sipi then returns a JSON response that looks something like this: { \"uploadedFiles\": [ { \"originalFilename\": \"manuscript-1234-page-1.tiff\", \"internalFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" }, { \"originalFilename\": \"manuscript-1234-page-2.tiff\", \"internalFilename\": \"2RvJgguglpe-B45EOk0Gx8H.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" } ] } In this example, we uploaded two files to Sipi, so uploadedFiles is an array with two elements. For each file, we have: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file In the case of an image file, the client may now wish to get a thumbnail of each uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image that is 150 pixels wide, you would add /full/150,/0/default.jpg .","title":"Upload Files to Sipi"},{"location":"DSP-API/03-apis/api-v2/editing-values/#submit-a-file-value-to-knora","text":"A Knora Representation (i.e. a resource containing information about a file) must always have exactly one file value attached to it. (see Representations ). Therefore, a request to create a new file value must always be submitted as part of a request to create a new resource (see Creating a Resource ). You can also update a file value in an existing Representation ; see Updating a Value . Instead of providing the file's complete metadata to Knora, you just provide the unique internal filename generated by Sipi. Here is an example of a request to create a resource of class anything:ThingPicture , which is a subclass of knora-api:StillImageRepresentation and therefore has the property knora-api:hasStillImageFileValue : { \"@type\": \"anything:ThingPicture\", \"knora-api:hasStillImageFileValue\": { \"@type\": \"knora-api:StillImageFileValue\", \"knora-api:fileValueHasFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/0001\" }, \"rdfs:label\": \"test thing\", \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Knora then gets the rest of the file's metadata from Sipi. If the client's request to Knora is valid, Knora saves the file value in the triplestore and instructs Sipi to move the file to permanent storage. Otherwise, the temporary file that was stored by Sipi is deleted. If you're submitting a PDF document, use the resource class knora-api:DocumentRepresentation , which has the property knora-api:hasDocumentFileValue , pointing to a knora-api:DocumentFileValue . For a text file, use knora-api:TextRepresentation , which has the property knora-api:hasTextFileValue , pointing to a knora-api:TextFileValue . For an archive like zip, use knora-api:ArchiveRepresentation , which has the property knora-api:hasArchiveFileValue , pointing to a knora-api:ArchiveFileValue .","title":"Submit A File Value to Knora"},{"location":"DSP-API/03-apis/api-v2/editing-values/#updating-a-value","text":"To update a value, use this route: HTTP PUT to http://host/v2/values Updating a value means creating a new version of an existing value. The new version will have a different IRI. The request is the same as for creating a value, except that the @id of the current value version is given. For example, to update an integer value: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 5 }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The value can be given a comment by using knora-api:valueHasComment . To change only the comment of a value, you can resubmit the existing value with the updated comment. Permissions can be specified by adding knora-api:hasPermissions . Otherwise, the new version has the same permissions as the previous one. To change the permissions on a value, the user must have change rights permission on the value. To update only the permissions on a value, submit it with the new permissions and with its @id and @type but without any other content, like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|V knora-admin:KnownUser\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } To update a link, the user must have modify permission on the containing resource as well as on the value. To update a value and give it a custom timestamp, add knora-api:valueCreationDate (an xsd:dateTimeStamp ). To update a value and give the new version a custom IRI, add knora-api:newValueVersionIri , like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 21, \"knora-api:newValueVersionIri\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/int-value-IRI\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. The response is a JSON-LD document containing only @id and @type , returning the IRI and type of the new value version. If you submit an outdated value ID in a request to update a value, the response will be an HTTP 404 (Not Found) error. The response to a value update request contains: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the value is a link value and is changed to point to a different resource, in which case it is considered a new link and gets a new UUID.","title":"Updating a Value"},{"location":"DSP-API/03-apis/api-v2/editing-values/#deleting-a-value","text":"Knora does not normally delete values; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a value as deleted, use this route: HTTP POST to http://host/v2/values/delete The request must include the resource's ID and type, the property that points from the resource to the value, and the value's ID and type. For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:deleteComment\": \"This value was created by mistake.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the value, explaining why it has been marked as deleted The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) specifies a custom timestamp indicating when the value was deleted. If not specified, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message.","title":"Deleting a Value"},{"location":"DSP-API/03-apis/api-v2/editing-values/#requesting-deleted-values","text":"Values marked as deleted are not found in search queries. But when requesting a resource that has deleted values, these will show up as generic knora-api:DeletedValue values. This value will be similar to the deleted value, having e.g. the same IRI. The DeletedValue will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"knora-api:DeletedValue\": [ { \"knora-api:versionArkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU.20211216T18193124797Z\", \"@type\": \"xsd:anyURI\" }, \"knora-api:userHasPermission\": \"RV\", \"knora-api:valueCreationDate\": { \"@value\": \"2021-12-16T18:19:31.247970Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2021-12-16T18:20:02.550828Z\" }, \"knora-api:attachedToUser\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:valueHasUUID\": \"sWSymIzAS_qXqyHLhwbwwA\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser|RV knora-admin:UnknownUser\", \"knora-api:isDeleted\": true, \"@type\": \"knora-api:DeletedValue\", \"http://www.knora.org/ontology/knora-base#DeletedValue\": \"DeletedValue\", \"@id\": \"http://rdfh.ch/0001/a-thing/values/DrXts3Up3DijGriI403nhg\", \"knora-api:deleteComment\": \"This value is obsolete\", \"knora-api:arkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU\", \"@type\": \"xsd:anyURI\" } }, {} ] }","title":"Requesting Deleted Values"},{"location":"DSP-API/03-apis/api-v2/getting-lists/","text":"Getting Lists Getting a complete List In order to request a complete list, make a HTTP GET request to the lists route appending the Iri of the list's root node (URL-encoded): HTTP GET to http://host/v2/lists/listRootNodeIri Lists are only returned in the complex schema. The response to a list request is a List (see interface List in module ListResponse ). Getting a single Node In order to request a single node of a list, make a HTTP GET request to the node route appending the node's Iri (URL-encoded): HTTP GET to http://host/v2/node/nodeIri Nodes are only returned in the complex schema. The response to a node request is a ListNode (see interface List in module ListResponse ).","title":"Getting Lists"},{"location":"DSP-API/03-apis/api-v2/getting-lists/#getting-lists","text":"","title":"Getting Lists"},{"location":"DSP-API/03-apis/api-v2/getting-lists/#getting-a-complete-list","text":"In order to request a complete list, make a HTTP GET request to the lists route appending the Iri of the list's root node (URL-encoded): HTTP GET to http://host/v2/lists/listRootNodeIri Lists are only returned in the complex schema. The response to a list request is a List (see interface List in module ListResponse ).","title":"Getting a complete List"},{"location":"DSP-API/03-apis/api-v2/getting-lists/#getting-a-single-node","text":"In order to request a single node of a list, make a HTTP GET request to the node route appending the node's Iri (URL-encoded): HTTP GET to http://host/v2/node/nodeIri Nodes are only returned in the complex schema. The response to a node request is a ListNode (see interface List in module ListResponse ).","title":"Getting a single Node"},{"location":"DSP-API/03-apis/api-v2/introduction/","text":"Introduction: Using API v2 Version 2 of the DSP-API aims to make both the response and request formats more generic and consistent. Version 1 was basically the result of the reimplementation of the existing API of the SALSAH prototype. Since the development of this prototype has a long history and the specification of API V1 was an evolving process, V1 has various inconsistencies and peculiarities. With V2, we would like to offer a format that is consistent and hence easier to use for a client. Please note that V2 is still in development. We do not yet recommend using it on productive systems. API v2 Path Segment Every request to API v2 includes v2 as a path segment, e.g. http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests using any other version of the API will require another path segment. Response Formats All API v2 responses can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation . The client can request these formats using the following MIME types: Format MIME Type JSON-LD application/ld+json Turtle text/turtle RDF/XML application/rdf+xml JSON-LD Our preferred format for data exchange is JSON-LD . JSON-LD allows the DSP-API server to provide responses that are relatively easy for automated processes to interpret, since their structure and semantics is explicitly defined. For example, each user-created Knora resource property is identified by an IRI, which can be dereferenced to get more information about it (e.g. its label in different languages). Moreover, each value has a type represented by an IRI. These are either standard RDF types (e.g. XSD datatypes) or more complex types whose IRIs can be dereferenced to get more information about their structure. At the same time, JSON-LD responses are relatively easy for software developers to work with, and are more concise and easier to read than the equivalent XML. Items in a response can have human-readable names, which can nevertheless be expanded to full IRIs. Also, while a format such as Turtle just provides a set of RDF triples, an equivalent JSON-LD response can explicitly provide data in a hierarchical structure, with objects nested inside other objects. Hierarchical vs. Flat JSON-LD The client can choose between hierarchical and flat JSON-LD. In hierarchical JSON-LD, entities with IRIs are inlined (nested) where they are used. If the same entity is used in more than one place, it is inlined only once, and other uses just refer to its IRI. In Knora's flat JSON-LD, all entities with IRIs are located at the top level of the document (in a @graph if there is more than one of them). This setting does not affect blank nodes, which are always inlined (unlike in standard flat JSON-LD). DSP ontologies are always returned in the flat rendering; other kinds of responses default to hierarchical . To use this setting, submit the HTTP header X-Knora-JSON-LD-Rendering with the value hierarchical or flat . Knora IRIs Resources and entities are identified by IRIs. The format of these IRIs is explained in Knora IRIs . API Schema DSP-API v2 uses RDF data structures that are simpler than the ones actually stored in the triplestore, and more suitable for the development of client software. Thus we refer to the internal schema of data as it is stored in the triplestore, and to external schemas which are used to represent that data in API v2. DSP-API v2 offers a complex schema and a simple one. The main difference is that the complex schema exposes the complexity of value objects, while the simple version does not. A client that needs to edit values must use the complex schema in order to obtain the IRI of each value. A client that reads but does not update data can use the simplified schema. The simple schema is mainly intended to facilitate interoperability with other RDF-based systems in the context of Linked Open Data. It is therefore designed to use the simplest possible datatypes and to require minimal knowledge of Knora. In either case, the client deals only with data whose structure and semantics are defined by external DSP-API ontologies, which are distinct from the internal ontologies that are used to store date in the triplestore. The Knora API server automatically converts back and forth between these internal and external representations. This approach encapsulates the internals and adds a layer of abstraction to them. IRIs representing ontologies and ontology entities are different in different schemas; see Knora IRIs . Some API operations inherently require the client to accept responses in the complex schema. For example, if an ontology is requested using an IRI indicating the simple schema, the ontology will be returned in the simple schema (see Querying, Creating, and Updating Ontologies ). Other API operations can return data in either schema. In this case, the complex schema is used by default in the response, unless the request specifically asks for the simple schema. The client can specify the desired schema by using an HTTP header or a URL parameter: the HTTP header X-Knora-Accept-Schema the URL parameter schema Both the HTTP header and the URL parameter accept the values simple or complex .","title":"Introduction"},{"location":"DSP-API/03-apis/api-v2/introduction/#introduction-using-api-v2","text":"Version 2 of the DSP-API aims to make both the response and request formats more generic and consistent. Version 1 was basically the result of the reimplementation of the existing API of the SALSAH prototype. Since the development of this prototype has a long history and the specification of API V1 was an evolving process, V1 has various inconsistencies and peculiarities. With V2, we would like to offer a format that is consistent and hence easier to use for a client. Please note that V2 is still in development. We do not yet recommend using it on productive systems.","title":"Introduction: Using API v2"},{"location":"DSP-API/03-apis/api-v2/introduction/#api-v2-path-segment","text":"Every request to API v2 includes v2 as a path segment, e.g. http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests using any other version of the API will require another path segment.","title":"API v2 Path Segment"},{"location":"DSP-API/03-apis/api-v2/introduction/#response-formats","text":"All API v2 responses can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation . The client can request these formats using the following MIME types: Format MIME Type JSON-LD application/ld+json Turtle text/turtle RDF/XML application/rdf+xml","title":"Response Formats"},{"location":"DSP-API/03-apis/api-v2/introduction/#json-ld","text":"Our preferred format for data exchange is JSON-LD . JSON-LD allows the DSP-API server to provide responses that are relatively easy for automated processes to interpret, since their structure and semantics is explicitly defined. For example, each user-created Knora resource property is identified by an IRI, which can be dereferenced to get more information about it (e.g. its label in different languages). Moreover, each value has a type represented by an IRI. These are either standard RDF types (e.g. XSD datatypes) or more complex types whose IRIs can be dereferenced to get more information about their structure. At the same time, JSON-LD responses are relatively easy for software developers to work with, and are more concise and easier to read than the equivalent XML. Items in a response can have human-readable names, which can nevertheless be expanded to full IRIs. Also, while a format such as Turtle just provides a set of RDF triples, an equivalent JSON-LD response can explicitly provide data in a hierarchical structure, with objects nested inside other objects.","title":"JSON-LD"},{"location":"DSP-API/03-apis/api-v2/introduction/#hierarchical-vs-flat-json-ld","text":"The client can choose between hierarchical and flat JSON-LD. In hierarchical JSON-LD, entities with IRIs are inlined (nested) where they are used. If the same entity is used in more than one place, it is inlined only once, and other uses just refer to its IRI. In Knora's flat JSON-LD, all entities with IRIs are located at the top level of the document (in a @graph if there is more than one of them). This setting does not affect blank nodes, which are always inlined (unlike in standard flat JSON-LD). DSP ontologies are always returned in the flat rendering; other kinds of responses default to hierarchical . To use this setting, submit the HTTP header X-Knora-JSON-LD-Rendering with the value hierarchical or flat .","title":"Hierarchical vs. Flat JSON-LD"},{"location":"DSP-API/03-apis/api-v2/introduction/#knora-iris","text":"Resources and entities are identified by IRIs. The format of these IRIs is explained in Knora IRIs .","title":"Knora IRIs"},{"location":"DSP-API/03-apis/api-v2/introduction/#api-schema","text":"DSP-API v2 uses RDF data structures that are simpler than the ones actually stored in the triplestore, and more suitable for the development of client software. Thus we refer to the internal schema of data as it is stored in the triplestore, and to external schemas which are used to represent that data in API v2. DSP-API v2 offers a complex schema and a simple one. The main difference is that the complex schema exposes the complexity of value objects, while the simple version does not. A client that needs to edit values must use the complex schema in order to obtain the IRI of each value. A client that reads but does not update data can use the simplified schema. The simple schema is mainly intended to facilitate interoperability with other RDF-based systems in the context of Linked Open Data. It is therefore designed to use the simplest possible datatypes and to require minimal knowledge of Knora. In either case, the client deals only with data whose structure and semantics are defined by external DSP-API ontologies, which are distinct from the internal ontologies that are used to store date in the triplestore. The Knora API server automatically converts back and forth between these internal and external representations. This approach encapsulates the internals and adds a layer of abstraction to them. IRIs representing ontologies and ontology entities are different in different schemas; see Knora IRIs . Some API operations inherently require the client to accept responses in the complex schema. For example, if an ontology is requested using an IRI indicating the simple schema, the ontology will be returned in the simple schema (see Querying, Creating, and Updating Ontologies ). Other API operations can return data in either schema. In this case, the complex schema is used by default in the response, unless the request specifically asks for the simple schema. The client can specify the desired schema by using an HTTP header or a URL parameter: the HTTP header X-Knora-Accept-Schema the URL parameter schema Both the HTTP header and the URL parameter accept the values simple or complex .","title":"API Schema"},{"location":"DSP-API/03-apis/api-v2/knora-iris/","text":"Knora IRIs The IRIs used in Knora repositories and in the DSP-API v2 follow certain conventions. Project Short-Codes A project short-code is a hexadecimal number of at least four digits, assigned by the DaSCH to uniquely identify a Knora project regardless of where it is hosted. The IRIs of ontologies that are built into Knora do not contain shortcodes; these ontologies implicitly belong to the Knora system project. A user-created ontology IRI must always include its project shortcode. Project ID 0000 is reserved for shared ontologies (see Shared Ontologies ). The range of project IDs from 0001 to 00FF inclusive is reserved for local testing. Thus, the first useful project will be 0100 . In the beginning, Unil will use the IDs 0100 to 07FF , and Unibas 0800 to 08FF . IRIs for Ontologies and Ontology Entities Internal Ontology IRIs Knora makes a distinction between internal and external ontologies. Internal ontologies are used in the triplestore, while external ontologies are used in API v2. For each internal ontology, there is a corresponding external ontology. Some internal ontologies are built into Knora, while others are user-created. Knora automatically generates external ontologies based on user-created internal ontologies. Each internal ontology has an IRI, which is also the IRI of the named graph that contains the ontology in the triplestore. An internal ontology IRI has the form: http://www.knora.org/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME For example, the internal ontology IRI based on project code 0001 and ontology name example would be: http://www.knora.org/ontology/0001/example An ontology name must be a valid XML NCName and must be URL safe. The following names are reserved for built-in internal DSP ontologies: knora-base standoff salsah-gui Names starting with knora are reserved for future built-in Knora ontologies. A user-created ontology name may not start with the letter v followed by a digit, and may not contain these reserved words: knora ontology simple shared External Ontology IRIs Unlike internal ontology IRIs, external ontology IRIs are meant to be dereferenced as URLs. When an ontology IRI is dereferenced, the ontology itself can be served either in a machine-readable format or as human-readable documentation. The IRI of an external Knora ontology has the form: http://HOST[:PORT]/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME/API_VERSION For built-in and shared ontologies, the host is always api.knora.org . Otherwise, the hostname and port configured in application.conf under app.http.knora-api.host and app.http.knora-api.http-port are used (the port is omitted if it is 80). This means that when a built-in or shared external ontology IRI is dereferenced, the ontology can be served by a DSP-API server running at api.knora.org . When the external IRI of a non-shared, project-specific ontology is dereferenced, the ontology can be served by Knora that hosts the project. During development and testing, this could be localhost . The name of an external ontology is the same as the name of the corresponding internal ontology, with one exception: the external form of knora-base is called knora-api . The API version identifier indicates not only the version of the API, but also an API 'schema'. The DSP-API v2 is available in two schemas: A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. Its version identifier is v2 . A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Its version identifier is simple/v2 . Other schemas could be added in the future for more specific use cases. When requesting an ontology, the client requests a particular schema. (This will also be true of most DSP-API v2 requests: the client will be able to specify which schema the response should be provided in.) For example, suppose a DSP-API server is running at knora.example.org and hosts an ontology whose internal IRI is http://www.knora.org/ontology/0001/example . That ontology can then be requested using either of these IRIs: http://knora.example.org/ontology/0001/example/v2 (in the complex schema) http://knora.example.org/ontology/0001/example/simple/v2 (in the simple schema) While the internal example ontology refers to definitions in knora-base , the external example ontology that is served by the API refers instead to a knora-api ontology, whose IRI depends on the schema being used: http://api.knora.org/ontology/knora-api/v2 (in the complex schema) http://api.knora.org/ontology/knora-api/simple/v2 (in the simple schema) Ontology Entity IRIs DSP ontologies use 'hash namespaces' (see URI Namespaces ). This means that the IRI of an ontology entity (a class or property definition) is constructed by adding a hash character ( # ) to the ontology IRI, followed by the name of the entity. In Knora, an entity name must be a valid XML NCName . Thus, if there is a class called ExampleThing in an ontology whose internal IRI is http://www.knora.org/ontology/0001/example , that class has the following IRIs: http://www.knora.org/ontology/0001/example#ExampleThing (in the internal ontology) http://HOST[:PORT]/ontology/0001/example/v2#ExampleThing (in the API v2 complex schema) http://HOST[:PORT]/ontology/0001/example/simple/v2#ExampleThing (in the API v2 simple schema) Shared Ontology IRIs As explained in Shared Ontologies , a user-created ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. There is currently one project for shared ontologies: http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject Its project code is 0000 . Additional projects for shared ontologies may be supported in future. The internal and external IRIs of shared ontologies always use the hostname api.knora.org , and have an additional segment, shared , after ontology . The project code can be omitted, in which case the default shared ontology project, 0000 , is assumed. The sample shared ontology, example-box , has these IRIs: http://www.knora.org/ontology/shared/example-box (internal) http://api.knora.org/ontology/shared/example-box/v2 (external, complex schema) http://api.knora.org/ontology/shared/example-box/simple/v2 (external, simple schema) IRIs for Data Knora generates IRIs for data that it creates in the triplestore. Each generated data IRI contains one or more UUID identifiers to make it unique. To keep data IRIs relatively short, each UUID is base64url-encoded , without padding; thus each UUID is a 22-character string. Data IRIs are not currently intended to be dereferenced as URLs. Instead, each Knora resource has a separate permalink . A Knora value does not have a stable IRI throughout its version history. Each time a new version of a value is made, the new version gets a new IRI. Therefore, it would not make sense to publish Knora value IRIs. When designing ontologies for Knora projects, keep in mind that if you want something be directly citable, it needs to be a resource, not a value. The formats of generated data IRIs for different types of objects are as follows: Resource: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID . Value: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID Standoff tag: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID/STANDOFF_UUID XML-to-standoff mapping: http://rdfh.ch/PROJECT_SHORTCODE/mappings/MAPPING_NAME XML-to-standoff mapping element: http://rdfh.ch/PROJECT_SHORTCODE/mappings/MAPPING_NAME/elements/MAPPING_ELEMENT_UUID Project: http://rdfh.ch/projects/PROJECT_SHORTCODE (or http://rdfh.ch/projects/PROJECT_UUID ) Group: http://rdfh.ch/groups/PROJECT_SHORTCODE/GROUP_UUID Permission: http://rdfh.ch/permissions/PROJECT_SHORTCODE/PERMISSION_UUID Lists: http://rdfh.ch/lists/PROJECT_SHORTCODE/LIST_UUID User: http://rdfh.ch/users/USER_UUID","title":"Knora IRIs"},{"location":"DSP-API/03-apis/api-v2/knora-iris/#knora-iris","text":"The IRIs used in Knora repositories and in the DSP-API v2 follow certain conventions.","title":"Knora IRIs"},{"location":"DSP-API/03-apis/api-v2/knora-iris/#project-short-codes","text":"A project short-code is a hexadecimal number of at least four digits, assigned by the DaSCH to uniquely identify a Knora project regardless of where it is hosted. The IRIs of ontologies that are built into Knora do not contain shortcodes; these ontologies implicitly belong to the Knora system project. A user-created ontology IRI must always include its project shortcode. Project ID 0000 is reserved for shared ontologies (see Shared Ontologies ). The range of project IDs from 0001 to 00FF inclusive is reserved for local testing. Thus, the first useful project will be 0100 . In the beginning, Unil will use the IDs 0100 to 07FF , and Unibas 0800 to 08FF .","title":"Project Short-Codes"},{"location":"DSP-API/03-apis/api-v2/knora-iris/#iris-for-ontologies-and-ontology-entities","text":"","title":"IRIs for Ontologies and Ontology Entities"},{"location":"DSP-API/03-apis/api-v2/knora-iris/#internal-ontology-iris","text":"Knora makes a distinction between internal and external ontologies. Internal ontologies are used in the triplestore, while external ontologies are used in API v2. For each internal ontology, there is a corresponding external ontology. Some internal ontologies are built into Knora, while others are user-created. Knora automatically generates external ontologies based on user-created internal ontologies. Each internal ontology has an IRI, which is also the IRI of the named graph that contains the ontology in the triplestore. An internal ontology IRI has the form: http://www.knora.org/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME For example, the internal ontology IRI based on project code 0001 and ontology name example would be: http://www.knora.org/ontology/0001/example An ontology name must be a valid XML NCName and must be URL safe. The following names are reserved for built-in internal DSP ontologies: knora-base standoff salsah-gui Names starting with knora are reserved for future built-in Knora ontologies. A user-created ontology name may not start with the letter v followed by a digit, and may not contain these reserved words: knora ontology simple shared","title":"Internal Ontology IRIs"},{"location":"DSP-API/03-apis/api-v2/knora-iris/#external-ontology-iris","text":"Unlike internal ontology IRIs, external ontology IRIs are meant to be dereferenced as URLs. When an ontology IRI is dereferenced, the ontology itself can be served either in a machine-readable format or as human-readable documentation. The IRI of an external Knora ontology has the form: http://HOST[:PORT]/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME/API_VERSION For built-in and shared ontologies, the host is always api.knora.org . Otherwise, the hostname and port configured in application.conf under app.http.knora-api.host and app.http.knora-api.http-port are used (the port is omitted if it is 80). This means that when a built-in or shared external ontology IRI is dereferenced, the ontology can be served by a DSP-API server running at api.knora.org . When the external IRI of a non-shared, project-specific ontology is dereferenced, the ontology can be served by Knora that hosts the project. During development and testing, this could be localhost . The name of an external ontology is the same as the name of the corresponding internal ontology, with one exception: the external form of knora-base is called knora-api . The API version identifier indicates not only the version of the API, but also an API 'schema'. The DSP-API v2 is available in two schemas: A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. Its version identifier is v2 . A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Its version identifier is simple/v2 . Other schemas could be added in the future for more specific use cases. When requesting an ontology, the client requests a particular schema. (This will also be true of most DSP-API v2 requests: the client will be able to specify which schema the response should be provided in.) For example, suppose a DSP-API server is running at knora.example.org and hosts an ontology whose internal IRI is http://www.knora.org/ontology/0001/example . That ontology can then be requested using either of these IRIs: http://knora.example.org/ontology/0001/example/v2 (in the complex schema) http://knora.example.org/ontology/0001/example/simple/v2 (in the simple schema) While the internal example ontology refers to definitions in knora-base , the external example ontology that is served by the API refers instead to a knora-api ontology, whose IRI depends on the schema being used: http://api.knora.org/ontology/knora-api/v2 (in the complex schema) http://api.knora.org/ontology/knora-api/simple/v2 (in the simple schema)","title":"External Ontology IRIs"},{"location":"DSP-API/03-apis/api-v2/knora-iris/#ontology-entity-iris","text":"DSP ontologies use 'hash namespaces' (see URI Namespaces ). This means that the IRI of an ontology entity (a class or property definition) is constructed by adding a hash character ( # ) to the ontology IRI, followed by the name of the entity. In Knora, an entity name must be a valid XML NCName . Thus, if there is a class called ExampleThing in an ontology whose internal IRI is http://www.knora.org/ontology/0001/example , that class has the following IRIs: http://www.knora.org/ontology/0001/example#ExampleThing (in the internal ontology) http://HOST[:PORT]/ontology/0001/example/v2#ExampleThing (in the API v2 complex schema) http://HOST[:PORT]/ontology/0001/example/simple/v2#ExampleThing (in the API v2 simple schema)","title":"Ontology Entity IRIs"},{"location":"DSP-API/03-apis/api-v2/knora-iris/#shared-ontology-iris","text":"As explained in Shared Ontologies , a user-created ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. There is currently one project for shared ontologies: http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject Its project code is 0000 . Additional projects for shared ontologies may be supported in future. The internal and external IRIs of shared ontologies always use the hostname api.knora.org , and have an additional segment, shared , after ontology . The project code can be omitted, in which case the default shared ontology project, 0000 , is assumed. The sample shared ontology, example-box , has these IRIs: http://www.knora.org/ontology/shared/example-box (internal) http://api.knora.org/ontology/shared/example-box/v2 (external, complex schema) http://api.knora.org/ontology/shared/example-box/simple/v2 (external, simple schema)","title":"Shared Ontology IRIs"},{"location":"DSP-API/03-apis/api-v2/knora-iris/#iris-for-data","text":"Knora generates IRIs for data that it creates in the triplestore. Each generated data IRI contains one or more UUID identifiers to make it unique. To keep data IRIs relatively short, each UUID is base64url-encoded , without padding; thus each UUID is a 22-character string. Data IRIs are not currently intended to be dereferenced as URLs. Instead, each Knora resource has a separate permalink . A Knora value does not have a stable IRI throughout its version history. Each time a new version of a value is made, the new version gets a new IRI. Therefore, it would not make sense to publish Knora value IRIs. When designing ontologies for Knora projects, keep in mind that if you want something be directly citable, it needs to be a resource, not a value. The formats of generated data IRIs for different types of objects are as follows: Resource: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID . Value: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID Standoff tag: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID/STANDOFF_UUID XML-to-standoff mapping: http://rdfh.ch/PROJECT_SHORTCODE/mappings/MAPPING_NAME XML-to-standoff mapping element: http://rdfh.ch/PROJECT_SHORTCODE/mappings/MAPPING_NAME/elements/MAPPING_ELEMENT_UUID Project: http://rdfh.ch/projects/PROJECT_SHORTCODE (or http://rdfh.ch/projects/PROJECT_UUID ) Group: http://rdfh.ch/groups/PROJECT_SHORTCODE/GROUP_UUID Permission: http://rdfh.ch/permissions/PROJECT_SHORTCODE/PERMISSION_UUID Lists: http://rdfh.ch/lists/PROJECT_SHORTCODE/LIST_UUID User: http://rdfh.ch/users/USER_UUID","title":"IRIs for Data"},{"location":"DSP-API/03-apis/api-v2/ontology-information/","text":"Querying, Creating, and Updating Ontologies Querying Ontology Information Before reading this document, you should have a basic understanding of DSP-API v2 external ontology schemas (see API Schema ). Each request returns a single RDF graph, which can be represented in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). The response format uses prefixes to shorten IRIs, making them more human-readable. A client may wish to convert these to full IRIs for processing. This can be done with responses in JSON-LD by using a library that implements the JSON-LD API to compact the document with an empty JSON-LD @context . Querying Ontology Metadata Requests for ontology metadata can return information about more than one ontology, unlike other requests for ontology information. To get metadata about all ontologies: HTTP GET to http://host/v2/ontologies/metadata If you submit a project IRI in the X-Knora-Accept-Project header, only the ontologies for that project will be returned. The response is in the complex API v2 schema. Sample response: { \"@graph\" : [ { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/00FF\" }, \"rdfs:label\" : \"The images demo ontology\" }, { \"@id\" : \"http://0.0.0.0:3333/ontology/0801/beol/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yTerZGyxjZVqFMNNKXCDPF\" }, \"rdfs:label\" : \"The BEOL ontology\" }, { \"@id\" : \"http://0.0.0.0:3333/ontology/0804/dokubib/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0804\" }, \"rdfs:label\" : \"The dokubib ontology\" }, { \"@id\" : \"http://api.knora.org/ontology/salsah-gui/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-base#SystemProject\" }, \"rdfs:label\" : \"The salsah-gui ontology\" }, { \"@id\" : \"http://api.knora.org/ontology/standoff/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-base#SystemProject\" }, \"rdfs:label\" : \"The standoff ontology\" }, { \"@id\": \"http://knora.unil.ch/ontology/0001/anything/v2\", \"@type\": \"owl:Ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/0001\" }, \"knora-api:lastModificationDate\": \"2017-12-19T15:23:42.166Z\", \"rdfs:label\": \"The anything ontology\" } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\" } } To get metadata about the ontologies that belong to one or more particular projects: HTTP GET to http://host/v2/ontologies/metadata/PROJECT_IRI[/PROJECT_IRI...] The project IRIs must be URL-encoded. Example response for the anything test project (project IRI http://rdfh.ch/projects/0001 ): { \"@id\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:lastModificationDate\": \"2017-12-19T15:23:42.166Z\", \"rdfs:label\" : \"The anything ontology\", \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\" } } Querying an Ontology An ontology can be queried either by using an API route directly or by simply dereferencing the ontology IRI. The API route is as follows: HTTP GET to http://host/v2/ontologies/allentities/ONTOLOGY_IRI The ontology IRI must be URL-encoded, and may be in either the complex or the simple schema. The response will be in the same schema. For example, if the server is running on 0.0.0.0:3333 , you can request the knora-api ontology in the complex schema as follows: HTTP GET to http://0.0.0.0:3333/v2/ontologies/allentities/http%3A%2F%2Fapi.knora.org%2Fontology%2Fknora-api%2Fv2 By default, this returns the ontology in JSON-LD; to request Turtle or RDF/XML, add an HTTP Accept header (see Response Formats ). If the client dereferences a project-specific ontology IRI as a URL, the DSP-API server running on the hostname in the IRI will serve the ontology. For example, if the server is running on 0.0.0.0:3333 , the IRI http://0.0.0.0:3333/ontology/00FF/images/simple/v2 can be dereferenced to request the images sample ontology in the simple schema. If the client dereferences a built-in Knora ontology, such as http://api.knora.org/ontology/knora-api/simple/v2 , there must be a DSP-API server running at api.knora.org that can serve the ontology. The DaSCH intends to run such as server. For testing, you can configure your local /etc/hosts file to resolve api.knora.org as localhost . Differences Between Internal and External Ontologies The external ontologies used by DSP-API v2 are different to the internal ontologies that are actually stored in the triplestore (see API Schema ). In general, the external ontologies use simpler data structures, but they also provide additional information to make it easier for clients to use them. This is illustrated in the examples in the next sections. The internal predicates knora-base:subjectClassConstraint and knora-base:objectClassConstraint (see Constraints on the Types of Property Subjects and Objects ) are represented as knora-api:subjectType and knora-api:objectType in external ontologies. JSON-LD Representation of an Ontology in the Simple Schema The simple schema is suitable for client applications that need to read but not update data in Knora. For example, here is the response for the images sample ontology in the simple schema, http://0.0.0.0:3333/ontology/00FF/images/simple/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2\", \"@type\" : \"owl:Ontology\", \"rdfs:label\" : \"The images demo ontology\", \"@graph\" : [ { \"@id\" : \"images:bild\", \"@type\" : \"owl:Class\", \"knora-api:resourceIcon\" : \"bild.png\", \"rdfs:comment\" : \"An image of the demo image collection\", \"rdfs:label\" : \"Image\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFile\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } } ] }, { \"@id\" : \"images:description\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Description\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"knora-api:Date\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Date of acquisition\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"First name of a person\", \"rdfs:label\" : \"First name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"Last name of a person\", \"rdfs:label\" : \"Name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\", \"@type\" : \"owl:Class\", \"knora-api:resourceIcon\" : \"person.png\", \"rdfs:comment\" : \"Person\", \"rdfs:label\" : \"Person\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } The response format is an RDF graph. The top level object describes the ontology itself, providing its IRI (in the @id member) and its rdfs:label . The @graph member (see Named Graphs in the JSON-LD specification) contains an array of entities that belong to the ontology. In a class definition, cardinalities for properties of the class are represented as in OWL, using objects of type owl:Restriction . The supported cardinalities are the ones indicated in OWL Cardinalities . The class definitions include cardinalities that are directly defined on each class, as well as cardinalities inherited from base classes. For example, we can see cardinalities inherited from knora-api:Resource , such as knora-api:hasStandoffLinkTo and http://schema.org/name (which represents rdfs:label ). In the simple schema, Knora value properties can be datatype properties. The knora-base:objectType of a Knora value property such as images:description is a literal datatype, in this case xsd:string . Moreover, images:description is a subproperty of the standard property dcterms:description , whose object can be a literal value. A client that understands rdfs:subPropertyOf , and is familiar with dcterms:description , can then work with images:description on the basis of its knowledge about dcterms:description . By default, values for rdfs:label and rdfs:comment are returned only in the user's preferred language, or in the system default language. To obtain these values in all available languages, add the URL parameter ?allLanguages=true . For example, with this parameter, the definition of images:description becomes: { \"@id\" : \"images:description\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : [ { \"@language\" : \"en\", \"@value\" : \"Description\" }, { \"@language\" : \"de\", \"@value\" : \"Beschreibung\" }, { \"@language\" : \"fr\", \"@value\" : \"Description\" }, { \"@language\" : \"it\", \"@value\" : \"Descrizione\" } ], \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] } To find out more about the knora-api entities used in the response, the client can request the knora-api ontology in the simple schema: http://api.knora.org/ontology/knora-api/simple/v2 . For example, images:erfassungsdatum has a knora-api:objectType of knora-api:Date , which is a subtype of xsd:string with a Knora-specific, human-readable format. In the knora-api simple ontology, there is a definition of this type: { \"@id\" : \"http://api.knora.org/ontology/knora-api/simple/v2\", \"@type\" : \"owl:Ontology\", \"rdfs:label\" : \"The knora-api ontology in the simple schema\", \"@graph\" : [ { \"@id\" : \"knora-api:Date\", \"@type\" : \"rdfs:Datatype\", \"rdfs:comment\" : \"Represents a date as a period with different possible precisions.\", \"rdfs:label\" : \"Date literal\", \"rdfs:subClassOf\" : { \"@type\" : \"rdfs:Datatype\", \"owl:onDatatype\" : { \"@id\" : \"xsd:string\" }, \"owl:withRestrictions\" : { \"xsd:pattern\" : \"(GREGORIAN|JULIAN|ISLAMIC):\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?)?\" } } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } JSON-LD Representation of an Ontology in the Complex Schema The complex schema is suitable for client applications that need to update data in Knora. For example, here is the response for the images sample ontology in the complex schema, http://0.0.0.0:3333/ontology/00FF/images/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/00FF\" }, \"rdfs:label\" : \"The images demo ontology\", \"@graph\" : [ { \"@id\" : \"images:bild\", \"@type\" : \"owl:Class\", \"knora-api:canBeInstantiated\" : true, \"knora-api:isResourceClass\" : true, \"knora-api:resourceIcon\" : \"bild.png\", \"rdfs:comment\" : \"An image of the demo image collection\", \"rdfs:label\" : \"Image\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFileValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 3, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 8, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 12, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 12, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheberValue\" } } ] }, { \"@id\" : \"images:description\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : [ \"rows=10\", \"width=95%\", \"wrap=soft\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Textarea\" }, \"rdfs:label\" : \"Description\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:DateValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Date\" }, \"rdfs:label\" : \"Date of acquisition\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\", \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"First name of a person\", \"rdfs:label\" : \"First name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\", \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"Last name of a person\", \"rdfs:label\" : \"Name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\", \"@type\" : \"owl:Class\", \"knora-api:canBeInstantiated\" : true, \"knora-api:isResourceClass\" : true, \"knora-api:resourceIcon\" : \"person.png\", \"rdfs:comment\" : \"Person\", \"rdfs:label\" : \"Person\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 0, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 1, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isLinkProperty\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\", \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } }, { \"@id\" : \"images:urheberValue\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isLinkValueProperty\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:LinkValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\", \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkToValue\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the complex schema, all Knora value properties are object properties, whose objects are IRIs, each of which uniquely identifies a value that contains metadata and can potentially be edited. The knora-base:objectType of a Knora value property such as images:description is a Knora value class, in this case knora-api:TextValue . Similarly, images:erfassungsdatum has a knora-api:objectType of knora-api:DateValue , which has a more complex structure than the knora-api:Date datatype shown in the previous section. A client can find out more about these value classes by requesting the knora-api ontology in the complex schema, http://api.knora.org/ontology/knora-api/v2 . Moreover, additional information is provided in the complex schema, to help clients that wish to create or update resources and values. A Knora resource class that can be instantiated is identified with the boolean properties knora-api:isResourceClass and knora-api:canBeInstantiated , to distinguish it from built-in abstract classes. Knora resource properties whose values can be edited by clients are identified with knora-api:isResourceProperty and knora-api:isEditable , to distinguish them from properties whose values are maintained automatically by Knora. Link value properties are shown along with link properties, because a client that updates links will need the IRIs of their link values. The predicate salsah-gui:guiOrder tells a GUI client in what order to display the properties of a class, and the predicates salsah-gui:guiElement and salsah-gui:guiAttribute specify how to configure a GUI element for editing the value of a property. For more information on the salsah-gui ontology, see The SALSAH GUI Ontology . Ontology Updates The ontology update API must ensure that the ontologies it creates are valid and consistent, and that existing data is not invalidated by a change to an ontology. To make this easier to enforce, the ontology update API allows only one entity to be created or modified at a time. It is not possible to submit an entire ontology all at once. Each update request is a JSON-LD document providing only the information that is relevant to the update. Moreover, the API enforces the following rules: An entity (i.e. a class or property) cannot be referred to until it has been created. An entity cannot be modified or deleted if it is used in data, except for changes to its rdfs:label or rdfs:comment . An entity cannot be modified if another entity refers to it, with one exception: a knora-api:subjectType or knora-api:objectType that refers to a class will not prevent the class's cardinalities from being modified. Because of these rules, some operations have to be done in a specific order: Properties have to be defined before they can be used in the cardinalities of a class, but a property's knora-api:subjectType cannot refer to a class that does not yet exist. The recommended approach is to first create a class with no cardinalities, then create the properties that it needs, then add cardinalities for those properties to the class. To delete a class along with its properties, the client must first remove the cardinalities from the class, then delete the property definitions, then delete the class definition. When changing an existing ontology, the client must always supply the ontology's knora-api:lastModificationDate , which is returned in the response to each update or when querying the ontology . If user A attempts to update an ontology, but user B has already updated it since the last time user A received the ontology's knora-api:lastModificationDate , user A's update will be rejected with an HTTP 409 Conflict error. This means that it is possible for two different users to work concurrently on the same ontology, but this is discouraged since it is likely to lead to confusion. An ontology can be created or updated only by a system administrator, or by a project administrator in the ontology's project. Ontology updates always use the complex schema. Creating a New Ontology An ontology is always created within a particular project. HTTP POST to http://host/v2/ontologies { \"knora-api:ontologyName\" : \"ONTOLOGY_NAME\", \"knora-api:attachedToProject\" : { \"@id\" : \"PROJECT_IRI\" }, \"rdfs:label\" : \"ONTOLOGY_NAME\", \"@context\" : { \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The ontology name must follow the rules given in Knora IRIs . The ontology metadata can have an optional comment given in the request body as: \"rdfs:comment\": \"some comment\", If the ontology is to be shared by multiple projects, it must be created in the default shared ontologies project, http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject , and the request must have this additional boolean property: \"knora-api:isShared\" : true See Shared Ontologies for details about shared ontologies. A successful response will be a JSON-LD document providing only the ontology's metadata, which includes the ontology's IRI. When the client makes further requests to create entities (classes and properties) in the ontology, it must construct entity IRIs by concatenating the ontology IRI, a # character, and the entity name. An entity name must be a valid XML NCName . Changing an Ontology's Metadata One can modify an ontology's metadata by updating its rdfs:label or rdfs:comment or both. The example below shows the request for changing the label of an ontology. HTTP PUT to http://host/v2/ontologies/metadata { \"@id\" : \"ONTOLOGY_IRI\", \"rdfs:label\" : \"NEW_ONTOLOGY_LABEL\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Similarly, a user can change an ontology's existing comment or add one by specifying the new comment in the request body: { \"@id\" : \"ONTOLOGY_IRI\", \"rdfs:comment\" : \"NEW_ONTOLOGY_COMMENT\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The request body can also contain a new label and a new comment for the ontology's metadata. A successful response will be a JSON-LD document providing only the ontology's metadata. Deleting an Ontology's comment HTTP DELETE to http://host/v2/ontologies/comment/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing the ontology's updated metadata. Deleting an Ontology An ontology can be deleted only if it is not used in data. HTTP DELETE to http://host/v2/ontologies/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing a confirmation message. To check whether an ontology can be deleted: HTTP GET to http://host/v2/ontologies/candeleteontology/ONTOLOGY_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Creating a Class Without Cardinalities HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : { \"@id\" : \"BASE_CLASS_IRI\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label and rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided, which can be knora-api:Resource or any of its subclasses. A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Creating a Class With Cardinalities This can work if the new class will have cardinalities for properties that have no knora-api:subjectType , or if the new class will be a subclass of their knora-api:subjectType . HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : [ { \"@id\" : \"BASE_CLASS_IRI\" }, { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) Values for rdfs:label and rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided. When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Changing the Labels of a Class This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. The submitted labels will replace the existing ones. Changing the Comments of a Class This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. The submitted comments will replace the existing ones. Creating a Property HTTP POST to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:subjectType\" : { \"@id\" : \"SUBJECT_TYPE\" }, \"knora-api:objectType\" : { \"@id\" : \"OBJECT_TYPE\" }, \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subPropertyOf\" : { \"@id\" : \"BASE_PROPERTY_IRI\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"GUI_ELEMENT_IRI\" }, \"salsah-gui:guiAttribute\" : [ \"GUI_ATTRIBUTE\" ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label and rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. At least one base property must be provided, which can be knora-api:hasValue , knora-api:hasLinkTo , or any of their subproperties, with the exception of file properties (subproperties of knora-api:hasFileValue ) and link value properties (subproperties of knora-api:hasLinkToValue ). If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be created. The property definition must specify its knora-api:objectType . If the new property is a subproperty of knora-api:hasValue , its knora-api:objectType must be one of the built-in subclasses of knora-api:Value , which are defined in the knora-api ontology in the complex schema. If the new property is a subproperty of knora-base:hasLinkTo , its knora-api:objectType must be a subclass of knora-api:Resource . To improve consistency checking, it is recommended, but not required, to provide knora-api:subjectType , which must be a subclass of knora-api:Resource . The predicates salsah-gui:guiElement and salsah-gui:guiAttribute are optional. If provided, the object of guiElement must be one of the OWL named individuals defined in The SALSAH GUI Ontology . Some GUI elements take required or optional attributes, which are provided as objects of salsah-gui:guiAttribute ; see The SALSAH GUI Ontology for details. A successful response will be a JSON-LD document providing the new property definition (but not any of the other entities in the ontology). Changing the Labels of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. Changing the Comments of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. Changing the GUI Element and GUI Attributes of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties/guielement { \"@id\": \"ONTOLOGY_IRI\", \"@type\": \"owl:Ontology\", \"knora-api:lastModificationDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\": [ { \"@id\": \"PROPERTY_IRI\", \"@type\": \"owl:ObjectProperty\", \"salsah-gui:guiElement\": { \"@id\": \"salsah-gui:Textarea\" }, \"salsah-gui:guiAttribute\": [ \"cols=80\", \"rows=24\" ] } ], \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\": \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\": \"http://www.w3.org/2002/07/owl#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\" } } To remove the values of salsah-gui:guiElement and salsah-gui:guiAttribute from the property definition, submit the request without those predicates. Adding Cardinalities to a Class If the class (or any of its sub-classes) is used in data, it is not allowed to add cardinalities owl:minCardinality greater than 0 or owl:cardinality 1 to the class. HTTP POST to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } At least one cardinality must be submitted. OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Replacing the Cardinalities of a Class This removes all the cardinalities from the class and replaces them with the submitted cardinalities. If no cardinalities are submitted (i.e. the request contains no rdfs:subClassOf ), the class is left with no cardinalities. This operation is not permitted if the class is used in data, or if it has a subclass. HTTP PUT to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinalities can be replaced: HTTP GET to http://host/v2/ontologies/canreplacecardinalities/CLASS_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Delete a single cardinality from a class If a class is used in data, it is only allowed to delete a cardinality, if the property a cardinality refers to, is not used inside the data. Also, the property isn't allowed to be used inside the data in any subclasses of this class. HTTP PATCH to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinality can be deleted: HTTP POST to http://host/v2/ontologies/candeletecardinalities The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Changing the GUI Order of Cardinalities To change the GUI order of one or more cardinalities in a class: HTTP PUT to http://host/v2/ontologies/guiorder This can be done even if the class is used in data. The request body includes the cardinalities whose GUI order should be changed, using the predicate salsah-gui:guiOrder , whose object is an integer: { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" }, \"salsah-gui:guiOrder\": \"GUI_ORDER_VALUE\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Only the cardinalities whose GUI order is to be changed need to be included in the request. The OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE are ignored; only the GUI_ORDER_VALUE is changed. Deleting a Property A property can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/properties/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be deleted. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a property can be deleted: HTTP GET to http://host/v2/ontologies/candeleteproperty/PROPERTY_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Deleting a Class A class can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/classes/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a class can be deleted: HTTP GET to http://host/v2/ontologies/candeleteclass/CLASS_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Querying, Creating, and Updating Ontologies"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#querying-creating-and-updating-ontologies","text":"","title":"Querying, Creating, and Updating Ontologies"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#querying-ontology-information","text":"Before reading this document, you should have a basic understanding of DSP-API v2 external ontology schemas (see API Schema ). Each request returns a single RDF graph, which can be represented in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). The response format uses prefixes to shorten IRIs, making them more human-readable. A client may wish to convert these to full IRIs for processing. This can be done with responses in JSON-LD by using a library that implements the JSON-LD API to compact the document with an empty JSON-LD @context .","title":"Querying Ontology Information"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#querying-ontology-metadata","text":"Requests for ontology metadata can return information about more than one ontology, unlike other requests for ontology information. To get metadata about all ontologies: HTTP GET to http://host/v2/ontologies/metadata If you submit a project IRI in the X-Knora-Accept-Project header, only the ontologies for that project will be returned. The response is in the complex API v2 schema. Sample response: { \"@graph\" : [ { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/00FF\" }, \"rdfs:label\" : \"The images demo ontology\" }, { \"@id\" : \"http://0.0.0.0:3333/ontology/0801/beol/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yTerZGyxjZVqFMNNKXCDPF\" }, \"rdfs:label\" : \"The BEOL ontology\" }, { \"@id\" : \"http://0.0.0.0:3333/ontology/0804/dokubib/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0804\" }, \"rdfs:label\" : \"The dokubib ontology\" }, { \"@id\" : \"http://api.knora.org/ontology/salsah-gui/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-base#SystemProject\" }, \"rdfs:label\" : \"The salsah-gui ontology\" }, { \"@id\" : \"http://api.knora.org/ontology/standoff/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-base#SystemProject\" }, \"rdfs:label\" : \"The standoff ontology\" }, { \"@id\": \"http://knora.unil.ch/ontology/0001/anything/v2\", \"@type\": \"owl:Ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/0001\" }, \"knora-api:lastModificationDate\": \"2017-12-19T15:23:42.166Z\", \"rdfs:label\": \"The anything ontology\" } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\" } } To get metadata about the ontologies that belong to one or more particular projects: HTTP GET to http://host/v2/ontologies/metadata/PROJECT_IRI[/PROJECT_IRI...] The project IRIs must be URL-encoded. Example response for the anything test project (project IRI http://rdfh.ch/projects/0001 ): { \"@id\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:lastModificationDate\": \"2017-12-19T15:23:42.166Z\", \"rdfs:label\" : \"The anything ontology\", \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\" } }","title":"Querying Ontology Metadata"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#querying-an-ontology","text":"An ontology can be queried either by using an API route directly or by simply dereferencing the ontology IRI. The API route is as follows: HTTP GET to http://host/v2/ontologies/allentities/ONTOLOGY_IRI The ontology IRI must be URL-encoded, and may be in either the complex or the simple schema. The response will be in the same schema. For example, if the server is running on 0.0.0.0:3333 , you can request the knora-api ontology in the complex schema as follows: HTTP GET to http://0.0.0.0:3333/v2/ontologies/allentities/http%3A%2F%2Fapi.knora.org%2Fontology%2Fknora-api%2Fv2 By default, this returns the ontology in JSON-LD; to request Turtle or RDF/XML, add an HTTP Accept header (see Response Formats ). If the client dereferences a project-specific ontology IRI as a URL, the DSP-API server running on the hostname in the IRI will serve the ontology. For example, if the server is running on 0.0.0.0:3333 , the IRI http://0.0.0.0:3333/ontology/00FF/images/simple/v2 can be dereferenced to request the images sample ontology in the simple schema. If the client dereferences a built-in Knora ontology, such as http://api.knora.org/ontology/knora-api/simple/v2 , there must be a DSP-API server running at api.knora.org that can serve the ontology. The DaSCH intends to run such as server. For testing, you can configure your local /etc/hosts file to resolve api.knora.org as localhost .","title":"Querying an Ontology"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#differences-between-internal-and-external-ontologies","text":"The external ontologies used by DSP-API v2 are different to the internal ontologies that are actually stored in the triplestore (see API Schema ). In general, the external ontologies use simpler data structures, but they also provide additional information to make it easier for clients to use them. This is illustrated in the examples in the next sections. The internal predicates knora-base:subjectClassConstraint and knora-base:objectClassConstraint (see Constraints on the Types of Property Subjects and Objects ) are represented as knora-api:subjectType and knora-api:objectType in external ontologies.","title":"Differences Between Internal and External Ontologies"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#json-ld-representation-of-an-ontology-in-the-simple-schema","text":"The simple schema is suitable for client applications that need to read but not update data in Knora. For example, here is the response for the images sample ontology in the simple schema, http://0.0.0.0:3333/ontology/00FF/images/simple/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2\", \"@type\" : \"owl:Ontology\", \"rdfs:label\" : \"The images demo ontology\", \"@graph\" : [ { \"@id\" : \"images:bild\", \"@type\" : \"owl:Class\", \"knora-api:resourceIcon\" : \"bild.png\", \"rdfs:comment\" : \"An image of the demo image collection\", \"rdfs:label\" : \"Image\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFile\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } } ] }, { \"@id\" : \"images:description\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Description\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"knora-api:Date\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Date of acquisition\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"First name of a person\", \"rdfs:label\" : \"First name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"Last name of a person\", \"rdfs:label\" : \"Name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\", \"@type\" : \"owl:Class\", \"knora-api:resourceIcon\" : \"person.png\", \"rdfs:comment\" : \"Person\", \"rdfs:label\" : \"Person\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } The response format is an RDF graph. The top level object describes the ontology itself, providing its IRI (in the @id member) and its rdfs:label . The @graph member (see Named Graphs in the JSON-LD specification) contains an array of entities that belong to the ontology. In a class definition, cardinalities for properties of the class are represented as in OWL, using objects of type owl:Restriction . The supported cardinalities are the ones indicated in OWL Cardinalities . The class definitions include cardinalities that are directly defined on each class, as well as cardinalities inherited from base classes. For example, we can see cardinalities inherited from knora-api:Resource , such as knora-api:hasStandoffLinkTo and http://schema.org/name (which represents rdfs:label ). In the simple schema, Knora value properties can be datatype properties. The knora-base:objectType of a Knora value property such as images:description is a literal datatype, in this case xsd:string . Moreover, images:description is a subproperty of the standard property dcterms:description , whose object can be a literal value. A client that understands rdfs:subPropertyOf , and is familiar with dcterms:description , can then work with images:description on the basis of its knowledge about dcterms:description . By default, values for rdfs:label and rdfs:comment are returned only in the user's preferred language, or in the system default language. To obtain these values in all available languages, add the URL parameter ?allLanguages=true . For example, with this parameter, the definition of images:description becomes: { \"@id\" : \"images:description\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : [ { \"@language\" : \"en\", \"@value\" : \"Description\" }, { \"@language\" : \"de\", \"@value\" : \"Beschreibung\" }, { \"@language\" : \"fr\", \"@value\" : \"Description\" }, { \"@language\" : \"it\", \"@value\" : \"Descrizione\" } ], \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] } To find out more about the knora-api entities used in the response, the client can request the knora-api ontology in the simple schema: http://api.knora.org/ontology/knora-api/simple/v2 . For example, images:erfassungsdatum has a knora-api:objectType of knora-api:Date , which is a subtype of xsd:string with a Knora-specific, human-readable format. In the knora-api simple ontology, there is a definition of this type: { \"@id\" : \"http://api.knora.org/ontology/knora-api/simple/v2\", \"@type\" : \"owl:Ontology\", \"rdfs:label\" : \"The knora-api ontology in the simple schema\", \"@graph\" : [ { \"@id\" : \"knora-api:Date\", \"@type\" : \"rdfs:Datatype\", \"rdfs:comment\" : \"Represents a date as a period with different possible precisions.\", \"rdfs:label\" : \"Date literal\", \"rdfs:subClassOf\" : { \"@type\" : \"rdfs:Datatype\", \"owl:onDatatype\" : { \"@id\" : \"xsd:string\" }, \"owl:withRestrictions\" : { \"xsd:pattern\" : \"(GREGORIAN|JULIAN|ISLAMIC):\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?)?\" } } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } }","title":"JSON-LD Representation of an Ontology in the Simple Schema"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#json-ld-representation-of-an-ontology-in-the-complex-schema","text":"The complex schema is suitable for client applications that need to update data in Knora. For example, here is the response for the images sample ontology in the complex schema, http://0.0.0.0:3333/ontology/00FF/images/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/00FF\" }, \"rdfs:label\" : \"The images demo ontology\", \"@graph\" : [ { \"@id\" : \"images:bild\", \"@type\" : \"owl:Class\", \"knora-api:canBeInstantiated\" : true, \"knora-api:isResourceClass\" : true, \"knora-api:resourceIcon\" : \"bild.png\", \"rdfs:comment\" : \"An image of the demo image collection\", \"rdfs:label\" : \"Image\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFileValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 3, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 8, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 12, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 12, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheberValue\" } } ] }, { \"@id\" : \"images:description\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : [ \"rows=10\", \"width=95%\", \"wrap=soft\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Textarea\" }, \"rdfs:label\" : \"Description\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:DateValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Date\" }, \"rdfs:label\" : \"Date of acquisition\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\", \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"First name of a person\", \"rdfs:label\" : \"First name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\", \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"Last name of a person\", \"rdfs:label\" : \"Name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\", \"@type\" : \"owl:Class\", \"knora-api:canBeInstantiated\" : true, \"knora-api:isResourceClass\" : true, \"knora-api:resourceIcon\" : \"person.png\", \"rdfs:comment\" : \"Person\", \"rdfs:label\" : \"Person\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 0, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 1, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isLinkProperty\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\", \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } }, { \"@id\" : \"images:urheberValue\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isLinkValueProperty\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:LinkValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\", \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkToValue\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the complex schema, all Knora value properties are object properties, whose objects are IRIs, each of which uniquely identifies a value that contains metadata and can potentially be edited. The knora-base:objectType of a Knora value property such as images:description is a Knora value class, in this case knora-api:TextValue . Similarly, images:erfassungsdatum has a knora-api:objectType of knora-api:DateValue , which has a more complex structure than the knora-api:Date datatype shown in the previous section. A client can find out more about these value classes by requesting the knora-api ontology in the complex schema, http://api.knora.org/ontology/knora-api/v2 . Moreover, additional information is provided in the complex schema, to help clients that wish to create or update resources and values. A Knora resource class that can be instantiated is identified with the boolean properties knora-api:isResourceClass and knora-api:canBeInstantiated , to distinguish it from built-in abstract classes. Knora resource properties whose values can be edited by clients are identified with knora-api:isResourceProperty and knora-api:isEditable , to distinguish them from properties whose values are maintained automatically by Knora. Link value properties are shown along with link properties, because a client that updates links will need the IRIs of their link values. The predicate salsah-gui:guiOrder tells a GUI client in what order to display the properties of a class, and the predicates salsah-gui:guiElement and salsah-gui:guiAttribute specify how to configure a GUI element for editing the value of a property. For more information on the salsah-gui ontology, see The SALSAH GUI Ontology .","title":"JSON-LD Representation of an Ontology in the Complex Schema"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#ontology-updates","text":"The ontology update API must ensure that the ontologies it creates are valid and consistent, and that existing data is not invalidated by a change to an ontology. To make this easier to enforce, the ontology update API allows only one entity to be created or modified at a time. It is not possible to submit an entire ontology all at once. Each update request is a JSON-LD document providing only the information that is relevant to the update. Moreover, the API enforces the following rules: An entity (i.e. a class or property) cannot be referred to until it has been created. An entity cannot be modified or deleted if it is used in data, except for changes to its rdfs:label or rdfs:comment . An entity cannot be modified if another entity refers to it, with one exception: a knora-api:subjectType or knora-api:objectType that refers to a class will not prevent the class's cardinalities from being modified. Because of these rules, some operations have to be done in a specific order: Properties have to be defined before they can be used in the cardinalities of a class, but a property's knora-api:subjectType cannot refer to a class that does not yet exist. The recommended approach is to first create a class with no cardinalities, then create the properties that it needs, then add cardinalities for those properties to the class. To delete a class along with its properties, the client must first remove the cardinalities from the class, then delete the property definitions, then delete the class definition. When changing an existing ontology, the client must always supply the ontology's knora-api:lastModificationDate , which is returned in the response to each update or when querying the ontology . If user A attempts to update an ontology, but user B has already updated it since the last time user A received the ontology's knora-api:lastModificationDate , user A's update will be rejected with an HTTP 409 Conflict error. This means that it is possible for two different users to work concurrently on the same ontology, but this is discouraged since it is likely to lead to confusion. An ontology can be created or updated only by a system administrator, or by a project administrator in the ontology's project. Ontology updates always use the complex schema.","title":"Ontology Updates"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#creating-a-new-ontology","text":"An ontology is always created within a particular project. HTTP POST to http://host/v2/ontologies { \"knora-api:ontologyName\" : \"ONTOLOGY_NAME\", \"knora-api:attachedToProject\" : { \"@id\" : \"PROJECT_IRI\" }, \"rdfs:label\" : \"ONTOLOGY_NAME\", \"@context\" : { \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The ontology name must follow the rules given in Knora IRIs . The ontology metadata can have an optional comment given in the request body as: \"rdfs:comment\": \"some comment\", If the ontology is to be shared by multiple projects, it must be created in the default shared ontologies project, http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject , and the request must have this additional boolean property: \"knora-api:isShared\" : true See Shared Ontologies for details about shared ontologies. A successful response will be a JSON-LD document providing only the ontology's metadata, which includes the ontology's IRI. When the client makes further requests to create entities (classes and properties) in the ontology, it must construct entity IRIs by concatenating the ontology IRI, a # character, and the entity name. An entity name must be a valid XML NCName .","title":"Creating a New Ontology"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#changing-an-ontologys-metadata","text":"One can modify an ontology's metadata by updating its rdfs:label or rdfs:comment or both. The example below shows the request for changing the label of an ontology. HTTP PUT to http://host/v2/ontologies/metadata { \"@id\" : \"ONTOLOGY_IRI\", \"rdfs:label\" : \"NEW_ONTOLOGY_LABEL\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Similarly, a user can change an ontology's existing comment or add one by specifying the new comment in the request body: { \"@id\" : \"ONTOLOGY_IRI\", \"rdfs:comment\" : \"NEW_ONTOLOGY_COMMENT\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The request body can also contain a new label and a new comment for the ontology's metadata. A successful response will be a JSON-LD document providing only the ontology's metadata.","title":"Changing an Ontology's Metadata"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#deleting-an-ontologys-comment","text":"HTTP DELETE to http://host/v2/ontologies/comment/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing the ontology's updated metadata.","title":"Deleting an Ontology's comment"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#deleting-an-ontology","text":"An ontology can be deleted only if it is not used in data. HTTP DELETE to http://host/v2/ontologies/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing a confirmation message. To check whether an ontology can be deleted: HTTP GET to http://host/v2/ontologies/candeleteontology/ONTOLOGY_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting an Ontology"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#creating-a-class-without-cardinalities","text":"HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : { \"@id\" : \"BASE_CLASS_IRI\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label and rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided, which can be knora-api:Resource or any of its subclasses. A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Creating a Class Without Cardinalities"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#creating-a-class-with-cardinalities","text":"This can work if the new class will have cardinalities for properties that have no knora-api:subjectType , or if the new class will be a subclass of their knora-api:subjectType . HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : [ { \"@id\" : \"BASE_CLASS_IRI\" }, { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) Values for rdfs:label and rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided. When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Creating a Class With Cardinalities"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#changing-the-labels-of-a-class","text":"This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. The submitted labels will replace the existing ones.","title":"Changing the Labels of a Class"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#changing-the-comments-of-a-class","text":"This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. The submitted comments will replace the existing ones.","title":"Changing the Comments of a Class"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#creating-a-property","text":"HTTP POST to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:subjectType\" : { \"@id\" : \"SUBJECT_TYPE\" }, \"knora-api:objectType\" : { \"@id\" : \"OBJECT_TYPE\" }, \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subPropertyOf\" : { \"@id\" : \"BASE_PROPERTY_IRI\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"GUI_ELEMENT_IRI\" }, \"salsah-gui:guiAttribute\" : [ \"GUI_ATTRIBUTE\" ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label and rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. At least one base property must be provided, which can be knora-api:hasValue , knora-api:hasLinkTo , or any of their subproperties, with the exception of file properties (subproperties of knora-api:hasFileValue ) and link value properties (subproperties of knora-api:hasLinkToValue ). If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be created. The property definition must specify its knora-api:objectType . If the new property is a subproperty of knora-api:hasValue , its knora-api:objectType must be one of the built-in subclasses of knora-api:Value , which are defined in the knora-api ontology in the complex schema. If the new property is a subproperty of knora-base:hasLinkTo , its knora-api:objectType must be a subclass of knora-api:Resource . To improve consistency checking, it is recommended, but not required, to provide knora-api:subjectType , which must be a subclass of knora-api:Resource . The predicates salsah-gui:guiElement and salsah-gui:guiAttribute are optional. If provided, the object of guiElement must be one of the OWL named individuals defined in The SALSAH GUI Ontology . Some GUI elements take required or optional attributes, which are provided as objects of salsah-gui:guiAttribute ; see The SALSAH GUI Ontology for details. A successful response will be a JSON-LD document providing the new property definition (but not any of the other entities in the ontology).","title":"Creating a Property"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#changing-the-labels-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects.","title":"Changing the Labels of a Property"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#changing-the-comments-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects.","title":"Changing the Comments of a Property"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#changing-the-gui-element-and-gui-attributes-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties/guielement { \"@id\": \"ONTOLOGY_IRI\", \"@type\": \"owl:Ontology\", \"knora-api:lastModificationDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\": [ { \"@id\": \"PROPERTY_IRI\", \"@type\": \"owl:ObjectProperty\", \"salsah-gui:guiElement\": { \"@id\": \"salsah-gui:Textarea\" }, \"salsah-gui:guiAttribute\": [ \"cols=80\", \"rows=24\" ] } ], \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\": \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\": \"http://www.w3.org/2002/07/owl#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\" } } To remove the values of salsah-gui:guiElement and salsah-gui:guiAttribute from the property definition, submit the request without those predicates.","title":"Changing the GUI Element and GUI Attributes of a Property"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#adding-cardinalities-to-a-class","text":"If the class (or any of its sub-classes) is used in data, it is not allowed to add cardinalities owl:minCardinality greater than 0 or owl:cardinality 1 to the class. HTTP POST to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } At least one cardinality must be submitted. OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Adding Cardinalities to a Class"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#replacing-the-cardinalities-of-a-class","text":"This removes all the cardinalities from the class and replaces them with the submitted cardinalities. If no cardinalities are submitted (i.e. the request contains no rdfs:subClassOf ), the class is left with no cardinalities. This operation is not permitted if the class is used in data, or if it has a subclass. HTTP PUT to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinalities can be replaced: HTTP GET to http://host/v2/ontologies/canreplacecardinalities/CLASS_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Replacing the Cardinalities of a Class"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#delete-a-single-cardinality-from-a-class","text":"If a class is used in data, it is only allowed to delete a cardinality, if the property a cardinality refers to, is not used inside the data. Also, the property isn't allowed to be used inside the data in any subclasses of this class. HTTP PATCH to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinality can be deleted: HTTP POST to http://host/v2/ontologies/candeletecardinalities The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Delete a single cardinality from a class"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#changing-the-gui-order-of-cardinalities","text":"To change the GUI order of one or more cardinalities in a class: HTTP PUT to http://host/v2/ontologies/guiorder This can be done even if the class is used in data. The request body includes the cardinalities whose GUI order should be changed, using the predicate salsah-gui:guiOrder , whose object is an integer: { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" }, \"salsah-gui:guiOrder\": \"GUI_ORDER_VALUE\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Only the cardinalities whose GUI order is to be changed need to be included in the request. The OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE are ignored; only the GUI_ORDER_VALUE is changed.","title":"Changing the GUI Order of Cardinalities"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#deleting-a-property","text":"A property can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/properties/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be deleted. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a property can be deleted: HTTP GET to http://host/v2/ontologies/candeleteproperty/PROPERTY_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting a Property"},{"location":"DSP-API/03-apis/api-v2/ontology-information/#deleting-a-class","text":"A class can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/classes/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a class can be deleted: HTTP GET to http://host/v2/ontologies/candeleteclass/CLASS_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting a Class"},{"location":"DSP-API/03-apis/api-v2/permalinks/","text":"Permalinks Knora provides a permanent, citable URL for each resource and value. These URLs use Archival Resource Key (ARK) Identifiers , and are designed to remain valid even if the resource itself is moved from one Knora repository to another. Obtaining ARK URLs In the complex schema , a resource or value is always returned with two ARK URLs: one that will always refer to the latest version of the resource or value ( knora-api:arkUrl ), and one that refers specifically to the version being returned ( knora-api:versionArkUrl ). For example: { \"@id\" : \"http://rdfh.ch/0803/2a6221216701\", \"@type\" : \"incunabula:book\", \"incunabula:book_comment\" : { \"@id\" : \"http://rdfh.ch/0803/2a6221216701/values/56c287fc9505\", \"@type\" : \"knora-api:TextValue\", \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB.20160302T150521Z\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:userHasPermission\" : \"V\", \"knora-api:valueAsString\" : \"Katalogaufnahme anhand ISTC und v.d.Haegen\", \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:valueHasUUID\" : \"dhaRsvZATjmOxhCOOzHqew\" }, \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W.20160302T150521Z\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0803\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:userHasPermission\" : \"V\", \"rdfs:label\" : \"Reise ins Heilige Land\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"incunabula\" : \"http://0.0.0.0:3333/ontology/0803/incunabula/v2#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the simple schema , resources are returned with ARK URLs, but values are returned as literals, so ARK URLs are not provided for values. For more information on getting past versions of resources and values, see: Get a Full Representation of a Version of a Resource by IRI Get a Version of a Value in a Resource Get the Version History of a Resource Resolving Knora ARK URLs A Knora ARK URL is intended to be resolved by the Knora ARK resolver . Knora ARK URL Format For details, see Archival Resource Key (ARK) Identifiers . ARK URLs for Projects The format of a Knora project ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), and PROJECT is the project's short-code . For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 This could redirect to a page describing the project. ARK URLs for Resources The format of a Knora resource ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , and RESOURCE_UUID is the resource's UUID . For example, given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180604T085622513Z Without a timestamp, a Knora resource ARK URL refers to the latest version of the resource at the time when the URL is resolved. ARK URLs for Values The format of a Knora value ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID/VALUE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , RESOURCE_UUID is the resource's UUID , and VALUE_UUID is the value's knora-api:valueHasUUID . For example, given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Without a timestamp, a Knora value ARK URL refers to the latest version of the value at the time when the URL is resolved.","title":"Permalinks"},{"location":"DSP-API/03-apis/api-v2/permalinks/#permalinks","text":"Knora provides a permanent, citable URL for each resource and value. These URLs use Archival Resource Key (ARK) Identifiers , and are designed to remain valid even if the resource itself is moved from one Knora repository to another.","title":"Permalinks"},{"location":"DSP-API/03-apis/api-v2/permalinks/#obtaining-ark-urls","text":"In the complex schema , a resource or value is always returned with two ARK URLs: one that will always refer to the latest version of the resource or value ( knora-api:arkUrl ), and one that refers specifically to the version being returned ( knora-api:versionArkUrl ). For example: { \"@id\" : \"http://rdfh.ch/0803/2a6221216701\", \"@type\" : \"incunabula:book\", \"incunabula:book_comment\" : { \"@id\" : \"http://rdfh.ch/0803/2a6221216701/values/56c287fc9505\", \"@type\" : \"knora-api:TextValue\", \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB.20160302T150521Z\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:userHasPermission\" : \"V\", \"knora-api:valueAsString\" : \"Katalogaufnahme anhand ISTC und v.d.Haegen\", \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:valueHasUUID\" : \"dhaRsvZATjmOxhCOOzHqew\" }, \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W.20160302T150521Z\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0803\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:userHasPermission\" : \"V\", \"rdfs:label\" : \"Reise ins Heilige Land\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"incunabula\" : \"http://0.0.0.0:3333/ontology/0803/incunabula/v2#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the simple schema , resources are returned with ARK URLs, but values are returned as literals, so ARK URLs are not provided for values. For more information on getting past versions of resources and values, see: Get a Full Representation of a Version of a Resource by IRI Get a Version of a Value in a Resource Get the Version History of a Resource","title":"Obtaining ARK URLs"},{"location":"DSP-API/03-apis/api-v2/permalinks/#resolving-knora-ark-urls","text":"A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Resolving Knora ARK URLs"},{"location":"DSP-API/03-apis/api-v2/permalinks/#knora-ark-url-format","text":"For details, see Archival Resource Key (ARK) Identifiers .","title":"Knora ARK URL Format"},{"location":"DSP-API/03-apis/api-v2/permalinks/#ark-urls-for-projects","text":"The format of a Knora project ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), and PROJECT is the project's short-code . For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 This could redirect to a page describing the project.","title":"ARK URLs for Projects"},{"location":"DSP-API/03-apis/api-v2/permalinks/#ark-urls-for-resources","text":"The format of a Knora resource ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , and RESOURCE_UUID is the resource's UUID . For example, given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180604T085622513Z Without a timestamp, a Knora resource ARK URL refers to the latest version of the resource at the time when the URL is resolved.","title":"ARK URLs for Resources"},{"location":"DSP-API/03-apis/api-v2/permalinks/#ark-urls-for-values","text":"The format of a Knora value ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID/VALUE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , RESOURCE_UUID is the resource's UUID , and VALUE_UUID is the value's knora-api:valueHasUUID . For example, given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Without a timestamp, a Knora value ARK URL refers to the latest version of the value at the time when the URL is resolved.","title":"ARK URLs for Values"},{"location":"DSP-API/03-apis/api-v2/query-language/","text":"Gravsearch: Virtual Graph Search Basic Concept Gravsearch is intended to offer the advantages of SPARQL endpoints (particularly the ability to perform queries using complex search criteria) while avoiding their drawbacks in terms of performance and security (see The Enduring Myth of the SPARQL Endpoint ). It also has the benefit of enabling clients to work with a simpler RDF data model than the one Knora actually uses to store data in the triplestore, and makes it possible to provide better error-checking. Rather than being processed directly by the triplestore, a Gravsearch query is interpreted by Knora, which enforces certain restrictions on the query, and implements paging and permission checking. The API server generates SPARQL based on the Gravsearch query submitted, queries the triplestore, filters the results according to the user's permissions, and returns each page of query results as a Knora API response. Thus, Gravsearch is a hybrid between a RESTful API and a SPARQL endpoint. A Gravsearch query conforms to a subset of the syntax of a SPARQL CONSTRUCT query, with some additional restrictions and functionality. In particular, the variable representing the top-level (or 'main') resource that will appear in each search result must be identified, statements must be included to specify the types of the entities being queried, OFFSET is used to control paging, and ORDER BY is used to sort the results. It is certainly possible to write Gravsearch queries by hand, but we expect that in general, they will be automatically generated by client software, e.g. by a client user interface. For a more detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data . Submitting Gravsearch Queries The recommended way to submit a Gravsearch query is via HTTP POST: HTTP POST to http://host/v2/searchextended This works like query via POST directly in the SPARQL 1.1 Protocol : the query is sent unencoded as the HTTP request message body, in the UTF-8 charset. It is also possible to submit a Gravsearch query using HTTP GET. The entire query must be URL-encoded and included as the last element of the URL path: HTTP GET to http://host/v2/searchextended/QUERY The response to a Gravsearch query is an RDF graph, which can be requested in various formats (see Responses Describing Resources ). To request the number of results rather than the results themselves, you can do a count query: HTTP POST to http://host/v2/searchextended/count The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. Gravsearch and API Schemas A Gravsearch query can be written in either of the two DSP-API v2 schemas . The simple schema is easier to work with, and is sufficient if you don't need to query anything below the level of a Knora value. If your query needs to refer to standoff markup, you must use the complex schema. Each query must use a single schema, with one exception (see Date Comparisons ). Gravsearch query results can be requested in the simple or complex schema; see API Schema . All examples hereafter run with Knora started locally as documented in the section Getting Started with DSP-API . If you access another Knora-Stack, you can check the IRI of the ontology you are targeting by requesting the ontologies metadata . Using the Simple Schema To write a query in the simple schema, use the knora-api ontology in the simple schema, and use the simple schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> In the simple schema, Knora values are represented as literals, which can be used FILTER expressions (see Filtering on Values in the Simple Schema ). Using the Complex Schema To write a query in the complex schema, use the knora-api ontology in the complex schema, and use the complex schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> In the complex schema, Knora values are represented as objects belonging to subclasses of knora-api:Value , e.g. knora-api:TextValue , and have predicates of their own, which can be used in FILTER expressions (see Filtering on Values in the Complex Schema ). Main and Dependent Resources The main resource is the top-level resource in a search result. Other resources that are in some way connected to the main resource are referred to as dependent resources. If the client asks for a resource A relating to a resource B, then all matches for A will be presented as main resources and those for B as dependent resources. The main resource must be represented by a variable, marked with knora-api:isMainResource , as explained under CONSTRUCT Clause . Virtual incoming Links Depending on the ontology design, a resource A points to B or vice versa. For example, a page A is part of a book B using the property incunabula:partOf . If A is marked as the main resource, then B is nested as a dependent resource in its link value incunabula:partOfValue . But in case B is marked as the main resource, B does not have a link value pointing to A because in fact B is pointed to by A. Instead, B has a virtual property knora-api:hasIncomingLink containing A's link value: \"knora-api:hasIncomingLinkValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasSource\" : { \"@id\" : \"http://rdfh.ch/A\", \"@type\" : \"incunabula:page\", \"incunabula:partOfValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/B\" } } } }, Note that the virtually inserted link value inverts the relation by using knora-api:linkValueHasSource . The source of the link is A and its target B is only represented by an Iri ( knora-api:linkValueHasTargetIri ) since B is the main resource. Graph Patterns and Result Graphs The WHERE clause of a Gravsearch query specifies a graph pattern. Each query result will match this graph pattern, and will have the form of a graph whose starting point is a main resource. The query's graph pattern, and hence each query result graph, can span zero more levels of relations between resources. For example, a query could request regions in images on pages of books written by a certain author, articles by authors who were students of a particular professor, or authors of texts that refer to events that took place within a certain date range. Permission Checking Each matching resource is returned with the values that the user has permission to see. If the user does not have permission to see a matching main resource, it is hidden in the results. If a user does not have permission to see a matching dependent resource, the link value is hidden. Paging Gravsearch results are returned in pages. The maximum number of main resources per page is determined by Knora (and can be configured in application.conf via the setting app/v2/resources-sequence/results-per-page ). If some resources have been filtered out because the user does not have permission to see them, a page could contain fewer results, or no results. If it is possible that more results are available in subsequent pages, the Gravsearch response will contain the predicate knora-api:mayHaveMoreResults with the boolean value true , otherwise it will not contain this predicate. Therefore, to retrieve all available results, the client must request each page one at a time, until the response does not contain knora-api:mayHaveMoreResults . Inference Gravsearch queries are understood to imply a subset of RDFS reasoning . Depending on the triplestore being used, this may be implemented using the triplestore's own reasoner or by query expansion in Knora. Specifically, if a statement pattern specifies a property, the pattern will also match subproperties of that property, and if a statement specifies that a subject has a particular rdf:type , the statement will also match subjects belonging to subclasses of that type. If you know that reasoning will not return any additional results for your query, you can disable it by adding this line to the WHERE clause: knora-api:GravsearchOptions knora-api:useInference false . If Knora is implementing reasoning by query expansion, disabling it can improve the performance of some queries. Gravsearch Syntax Every Gravsearch query is a valid SPARQL 1.1 CONSTRUCT query. However, Gravsearch only supports a subset of the elements that can be used in a SPARQL Construct query, and a Gravsearch CONSTRUCT Clause has to indicate which variable is to be used for the main resource in each search result. Supported SPARQL Syntax The current version of Gravsearch accepts CONSTRUCT queries whose WHERE clauses use the following patterns, with the specified restrictions: OPTIONAL : cannot be nested in a UNION . UNION : cannot be nested in a UNION . FILTER : may contain a complex expression using the Boolean operators AND and OR, as well as comparison operators. The left argument of a comparison operator must be a query variable. A Knora ontology entity IRI used in a FILTER must be a property IRI. FILTER NOT EXISTS MINUS OFFSET : the OFFSET is needed for paging. It does not actually refer to the number of triples to be returned, but to the requested page of results. The default value is 0, which refers to the first page of results. ORDER BY : In SPARQL, the result of a CONSTRUCT query is an unordered set of triples. However, a Gravsearch query returns an ordered list of resources, which can be ordered by the values of specified properties. If the query is written in the complex schema, items below the level of Knora values may not be used in ORDER BY . BIND : The value assigned must be a Knora resource IRI. Resources, Properties, and Values Resources can be represented either by an IRI or by a variable, except for the main resource, which must be represented by a variable. It is possible to do a Gravsearch query in which the IRI of the main resource is already known, e.g. to request specific information about that resource and perhaps about linked resources. In this case, the IRI of the main resource must be assigned to a variable using BIND . Note that BIND statements slow the query down, therefore we recommend that you do not use them unless you have to. Properties can be represented by an IRI or a query variable. If a property is represented by a query variable, it can be restricted to certain property IRIs using a FILTER . A Knora value (i.e. a value attached to a knora-api:Resource ) must be represented as a query variable. Filtering on Values Filtering on Values in the Simple Schema In the simple schema, a variable representing a Knora value can be used directly in a FILTER expression. For example: ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Here the type of ?title is xsd:string . The following Knora value types can be compared with literals in FILTER expressions in the simple schema: Text values ( xsd:string ) Uri values ( xsd:anyURI ) Integer values ( xsd:integer ) Decimal values ( xsd:decimal ) Boolean values ( xsd:boolean ) Date values ( knora-api:Date ) List values ( knora-api:ListNode ) List values can only be searched for using the equal operator ( = ), performing an exact match on a list node's label. Labels can be given in different languages for a specific list node. If one of the given list node labels matches, it is considered a match. Note that in the simple schema, uniqueness is not guaranteed (as opposed to the complex schema). A Knora value may not be represented as the literal object of a predicate; for example, this is not allowed: ?book incunabula:title \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Filtering on Values in the Complex Schema In the complex schema, variables representing Knora values are not literals. You must add something to the query (generally a statement) to get a literal from a Knora value. For example: ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Here the type of ?title is knora-api:TextValue . Note that no FILTER is needed in this example. But if you want to use a different comparison operator, you need a FILTER : ?page incunabula:seqnum ?seqnum . ?seqnum knora-api:intValueAsInt ?seqnumInt . FILTER(?seqnumInt <= 10) To match a date value in the complex schema, you must use the knora-api:toSimpleDate function in a FILTER (see Date Comparisons ). The predicates of knora-api:DateValue ( knora-api:dateValueHasStartYear , etc.) are not available in Gravsearch. Date Comparisons In the simple schema, you can compare a date value directly with a knora-api:Date in a FILTER : ?book incunabula:pubdate ?pubdate . FILTER(?pubdate < \"JULIAN:1497\"^^knora-api:Date) In the complex schema, you must use the function knora-api:toSimpleDate , passing it the variable representing the date value. The date literal used in the comparison must still be a knora-api:Date in the simple schema. This is the only case in which you can use both schemas in a single query: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true . ?book incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book . ?book incunabula:pubdate ?pubdate . FILTER(knora-api:toSimpleDate(?pubdate) < \"JULIAN:1497\"^^knora-api-simple:Date) } ORDER BY ?pubdate You can also use knora-api:toSimpleDate with to search for date tags in standoff text markup (see Matching Standoff Dates ). Note that the given date value for comparison must have the following format: ``` (GREGORIAN|JULIAN|ISLAMIC):\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?)? ``` E.g. an exact date like GREGORIAN:2015-12-03 or a period like GREGORIAN:2015-12-03:2015-12-04 . Dates may also have month or year precision, e.g. ISLAMIC:1407-02 (the whole month of december) or JULIAN:1330 (the whole year 1330). An optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Era can be given as GREGORIAN:1220 BC or in range as GREGORIAN:600 BC:480 BC . Searching for Matching Words The function knora-api:matchText searches for matching words anywhere in a text value, and is implemented using a full-text search index if available. The first argument must represent a text value (a knore-api:TextValue in the complex schema, or an xsd:string in the simple schema). The second argument is a string literal containing the words to be matched, separated by spaces. The function supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. This function can only be used as the top-level expression in a FILTER . For example, to search for titles that contain the words 'Zeitgl\u00f6cklein' and 'Lebens': ?book incunabule:title ?title . FILTER knora-api:matchText(?title, \"Zeitgl\u00f6cklein Lebens\") Filtering Text by Language To filter a text value by language in the simple schema, use the SPARQL lang function on the text value, e.g.: FILTER(lang(?text) = \"fr\") In the complex schema, the lang function is not supported. Use the text value's knora-api:textValueHasLanguage predicate instead: ?text knora-api:textValueHasLanguage \"fr\" . Regular Expressions The SPARQL regex function is supported. In the simple schema, you can use it directly on the text value, e.g. ?book incunabula:title ?title . FILTER regex(?title, \"Zeit\", \"i\") In the complex schema, use it on the object of the text value's knora-api:valueAsString predicate: ?book incunabula:title ?title . ?title knora-api:valueAsString ?titleStr . FILTER regex(?titleStr, \"Zeit\", \"i\") Searching for Text Markup To refer to standoff markup in text values, you must write your query in the complex schema. A knora-api:TextValue can have the property knora-api:textValueHasStandoff , whose objects are the standoff markup tags in the text. You can match the tags you're interested in using rdf:type or other properties of each tag. Matching Text in a Standoff Tag The function knora-api:matchTextInStandoff searches for standoff tags containing certain terms. The implementation is optimised using the full-text search index if available. The function takes three arguments: A variable representing a text value. A variable representing a standoff tag. A string literal containing space-separated search terms. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . FILTER knora-api:matchTextInStandoff(?text, ?standoffParagraphTag, \"Grund Richtigkeit\") } Here we are looking for letters containing the words \"Grund\" and \"Richtigkeit\" within a single paragraph. Matching Standoff Links If you are only interested in specifying that a resource has some text value containing a standoff link to another resource, the most efficient way is to use the property knora-api:hasStandoffLinkTo , whose subjects and objects are resources. This property is automatically maintained by Knora. For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . } Here we are looking for letters containing a link to the historian Claude Jordan, who is identified by his Integrated Authority File identifier, (VIAF)271899510 . However, if you need to specify the context in which the link tag occurs, you must use the function knora-api:standoffLink . It takes three arguments: A variable or IRI representing the resource that is the source of the link. A variable representing the standoff link tag. A variable or IRI representing the resource that is the target of the link. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . } This has the same effect as the previous example, except that because we are matching the link tag itself, we can specify that its immediate parent is a StandoffItalicTag . If you actually want to get the target of the link (in this example, ?person ) in the search results, you need to add a statement like ?letter knora-api:hasStandoffLinkTo ?person . to the WHERE clause and to the CONSTRUCT clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . ?letter knora-api:hasStandoffLinkTo ?person . } Matching Standoff Dates You can use the knora-api:toSimpleDate function (see @ref Date Comparisons ) to match dates in standoff date tags, i.e. instances of knora-api:StandoffDateTag or of one of its subclasses. For example, here we are looking for a text containing an anything:StandoffEventTag (which is a project-specific subclass of knora-api:StandoffDateTag ) representing an event that occurred sometime during the month of December 2016: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffEventTag . ?standoffEventTag a anything:StandoffEventTag . FILTER(knora-api:toSimpleDate(?standoffEventTag) = \"GREGORIAN:2016-12 CE\"^^knora-api-simple:Date) } Matching Ancestor Tags Suppose we want to search for a standoff date in a paragraph, but we know that the paragraph tag might not be the immediate parent of the date tag. For example, the date tag might be in an italics tag, which is in a paragraph tag. In that case, we can use the inferred property knora-api:standoffTagHasStartAncestor . We can modify the previous example to do this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffDateTag . ?standoffDateTag a knora-api:StandoffDateTag . FILTER(knora-api:toSimpleDate(?standoffDateTag) = \"GREGORIAN:2016-12-24 CE\"^^knora-api-simple:Date) ?standoffDateTag knora-api:standoffTagHasStartAncestor ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . } Filtering on rdfs:label The rdfs:label of a resource is not a Knora value, but you can still search for it. This can be done in the same ways in the simple or complex schema: Using a string literal object: ?book rdfs:label \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Using a variable and a FILTER: ?book rdfs:label ?label . FILTER(?label = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Using the regex function: ?book rdfs:label ?bookLabel . FILTER regex(?bookLabel, \"Zeit\", \"i\") To match words in an rdfs:label using the full-text search index, use the knora-api:matchLabel function, which works like knora-api:matchText , except that the first argument is a variable representing a resource: FILTER knora-api:matchLabel(?book, \"Zeitgl\u00f6cklein\") Filtering on Resource IRIs A FILTER can compare a variable with another variable or IRI representing a resource. For example, to find a letter whose author and recipient are different persons: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != ?person2) . } OFFSET 0 To find a letter whose author is not a person with a specified IRI: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != <http://rdfh.ch/0801/F4n1xKa3TCiR4llJeElAGA>) . } OFFSET 0 CONSTRUCT Clause In the CONSTRUCT clause of a Gravsearch query, the variable representing the main resource must be indicated with knora-api:isMainResource true . Exactly one variable representing a resource must be marked in this way. Any other statements in the CONSTRUCT clause must also be present in the WHERE clause. If a variable representing a resource or value is used in the WHERE clause but not in the CONSTRUCT clause, the matching resources or values will not be included in the results. If the query is written in the complex schema, all variables in the CONSTRUCT clause must refer to Knora resources, Knora values, or properties. Data below the level of Knora values may not be mentioned in the CONSTRUCT clause. Predicates from the rdf , rdfs , and owl ontologies may not be used in the CONSTRUCT clause. The rdfs:label of each matching resource is always returned, so there is no need to mention it in the query. Gravsearch by Example In this section, we provide some sample queries of different complexity to illustrate the usage of Gravsearch. Getting All the Components of a Compound Resource In order to get all the components of a compound resource, the following Gravsearch query can be sent to the API. In this case, the compound resource is an incunabula:book identified by the IRI http://rdfh.ch/0803/c5058f3a and the components are of type incunabula:page (test data for the Incunabula project). Since inference is assumed, we can use knora-api:StillImageRepresentation ( incunabula:page is one of its subclasses). This makes the query more generic and allows for reuse (for instance, a client would like to query different types of compound resources defined in different ontologies). ORDER BY is used to sort the components by their sequence number. OFFSET is set to 0 to get the first page of results. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?component knora-api:isMainResource true . # marking of the component searched for as the main resource, required ?component knora-api:seqnum ?seqnum . # return the sequence number in the response ?component knora-api:hasStillImageFileValue ?file . # return the StillImageFile in the response } WHERE { ?component a knora-api:StillImageRepresentation . # restriction of the type of component ?component knora-api:isPartOf <http://rdfh.ch/0803/c5058f3a> . # component relates to a compound resource via this property ?component knora-api:seqnum ?seqnum . # component must have a sequence number ?component knora-api:hasStillImageFileValue ?file . # component must have a StillImageFile } ORDER BY ASC(?seqnum) # order by sequence number, ascending OFFSET 0 # get first page of results The incunabula:book with the IRI http://rdfh.ch/0803/c5058f3a has 402 pages. (This result can be obtained by doing a count query; see Submitting Gravsearch Queries .) However, with OFFSET 0 , only the first page of results is returned. The same query can be sent again with OFFSET 1 to get the next page of results, and so forth. When a page of results is not full (see settings in app/v2 in application.conf ) or is empty, no more results are available. By design, it is not possible for the client to get more than one page of results at a time; this is intended to prevent performance problems that would be caused by huge responses. A client that wants to download all the results of a query must request each page sequentially. Let's assume the client is not interested in all of the book's pages, but just in first ten of them. In that case, the sequence number can be restricted using a FILTER that is added to the query's WHERE clause: FILTER (?seqnum <= 10) The first page starts with sequence number 1, so with this FILTER only the first ten pages are returned. This query would be exactly the same in the complex schema, except for the expansion of the knora-api prefix: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> Traversing Multiple Links Here we are looking for regions of pages that are part of books that have a particular title. In the simple schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") } In the complex schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . } If we remove the line ?book incunabula:title ?title . from the CONSTRUCT clause, so that the CONSTRUCT clause no longer mentions ?title , the response will contain the same matching resources, but the titles of those resources will not be included in the response. Requesting a Graph Starting with a Known Resource Here the IRI of the main resource is already known, and we want specific information about it, as well as about related resources. In this case, the IRI of the main resource must be assigned to a variable using BIND : PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?letter knora-api:isMainResource true ; beol:creationDate ?date ; ?linkingProp1 ?person1 . ?person1 beol:hasFamilyName ?familyName . } WHERE { BIND(<http://rdfh.ch/0801/_B3lQa6tSymIq7_7SowBsA> AS ?letter) ?letter a beol:letter ; beol:creationDate ?date ; ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient) ?person1 beol:hasFamilyName ?familyName . } ORDER BY ?date This query would be the same in the complex schema, except for the prefix expansions: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> Searching for a List Value Referring to a Particular List Node Since list nodes are represented by their Iri in the complex schema, uniqueness is guranteed (as opposed to the simple schema). Also all the subnodes of the given list node are considered a match. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasListItem ?listItem . } WHERE { ?thing anything:hasListItem ?listItem . ?listItem knora-api:listValueAsListNode <http://rdfh.ch/lists/0001/treeList02> . } Type Inference Gravsearch needs to be able to determine the types of the entities that query variables and IRIs refer to in the WHERE clause. In most cases, it can infer these from context and from the ontologies used. In particular, it needs to know: The type of the subject and object of each statement. The type that is expected as the object of each predicate. Type Annotations When one or more types cannot be inferred, Gravsearch will return an error message indicating the entities for which it could not determine types. The missing information must then be given by adding type annotations to the query. This can always done by adding statements with the predicate rdf:type . The subject must be a resource or value, and the object must either be knora-api:Resource (if the subject is a resource) or the subject's specific type (if it is a value). For example, consider this query that uses a non-Knora property: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book dcterms:title ?title . } This produces the error message: The types of one or more entities could not be determined: ?book, <http://purl.org/dc/terms/title>, ?title To solve this problem, it is enough to specify the types of ?book and ?title ; the type of the expected object of dcterms:title can then be inferred from the type of ?title . PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . ?title rdf:type xsd:string . } It would also be possible to annotate the property itself, using the predicate knora-api:objectType ; then the type of ?title would be inferred: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . dcterms:title knora-api:objectType xsd:string . } Note that it only makes sense to use dcterms:title in the simple schema, because its object is supposed to be a literal. Here is another example, using a non-Knora class: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } This produces the error message: Types could not be determined for one or more entities: ?person The solution is to specify that ?person is a knora-api:Resource : PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person a knora-api:Resource . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } Inconsistent Types Gravsearch will also reject a query if an entity is used with inconsistent types. For example: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\") . } This returns the error message: One or more entities have inconsistent types: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#pubdate> knora-api:objectType <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; knora-api:objectType <http://www.w3.org/2001/XMLSchema#string> . ?pubdate rdf:type <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; rdf:type <http://www.w3.org/2001/XMLSchema#string> . This is because the incunabula ontology says that the object of incunabula:pubdate must be a knora-api:Date , but the FILTER expression compares ?pubdate with an xsd:string . The solution is to specify the type of the literal in the FILTER : PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\"^^knora-api:Date) . } Scoping Issues SPARQL is evaluated from the bottom up . A UNION block therefore opens a new scope, in which variables bound at higher levels are not necessarily in scope. This can cause unexpected results if queries are not carefully designed. Gravsearch tries to prevent this by rejecting queries in the following cases. FILTER in UNION A FILTER in a UNION block can only use variables that are bound in the same block, otherwise the query will be rejected. This query is invalid because ?text is not bound in the UNION block containing the FILTER where the variable is used: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls: <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api:isMainResource true . ?lemma mls:hasLemmaText ?text . } WHERE { ?lemma a mls:Lemma . ?lemma mls:hasLemmaText ?text . { ?lemma mls:hasPseudonym ?pseudo . FILTER regex(?pseudo, \"Abel\", \"i\") . } UNION { FILTER regex(?text, \"Abel\", \"i\") . } } ORDER BY ASC(?text) OFFSET 0 It can be corrected like this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls: <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api:isMainResource true . ?lemma mls:hasLemmaText ?text . } WHERE { ?lemma a mls:Lemma . ?lemma mls:hasLemmaText ?text . { ?lemma mls:hasPseudonym ?pseudo . FILTER regex(?pseudo, \"Abel\", \"i\") . } UNION { ?lemma mls:hasLemmaText ?text . FILTER regex(?text, \"Abel\", \"i\") . } } ORDER BY ASC(?text) OFFSET 0 ORDER BY A variable used in ORDER BY must be bound at the top level of the WHERE clause. This query is invalid, because ?int is not bound at the top level of the WHERE clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasInteger ?int . ?thing anything:hasRichtext ?richtext . ?thing anything:hasText ?text . } WHERE { ?thing a knora-api:Resource . ?thing a anything:Thing . { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") ?thing anything:hasInteger ?int . } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") ?thing anything:hasInteger ?int . } } ORDER BY (?int) It can be corrected like this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasInteger ?int . ?thing anything:hasRichtext ?richtext . ?thing anything:hasText ?text . } WHERE { ?thing a knora-api:Resource . ?thing a anything:Thing . ?thing anything:hasInteger ?int . { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") } } ORDER BY (?int) Query Optimization by Dependency The query performance of triplestores, such as Fuseki, is highly dependent on the order of query patterns. To improve performance, Gravsearch automatically reorders the statement patterns in the WHERE clause according to their dependencies on each other, to minimise the number of possible matches for each pattern. This optimization can be controlled using gravsearch-dependency-optimisation feature toggle , which is turned on by default. Consider the following Gravsearch query: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?letter beol:creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?person1 beol:hasIAFIdentifier ?gnd1 . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . } ORDER BY ?date Gravsearch optimises the performance of this query by moving these statements to the top of the WHERE clause: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the WHERE clause then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date .","title":"Gravsearch - Virtual Graph Search"},{"location":"DSP-API/03-apis/api-v2/query-language/#gravsearch-virtual-graph-search","text":"","title":"Gravsearch: Virtual Graph Search"},{"location":"DSP-API/03-apis/api-v2/query-language/#basic-concept","text":"Gravsearch is intended to offer the advantages of SPARQL endpoints (particularly the ability to perform queries using complex search criteria) while avoiding their drawbacks in terms of performance and security (see The Enduring Myth of the SPARQL Endpoint ). It also has the benefit of enabling clients to work with a simpler RDF data model than the one Knora actually uses to store data in the triplestore, and makes it possible to provide better error-checking. Rather than being processed directly by the triplestore, a Gravsearch query is interpreted by Knora, which enforces certain restrictions on the query, and implements paging and permission checking. The API server generates SPARQL based on the Gravsearch query submitted, queries the triplestore, filters the results according to the user's permissions, and returns each page of query results as a Knora API response. Thus, Gravsearch is a hybrid between a RESTful API and a SPARQL endpoint. A Gravsearch query conforms to a subset of the syntax of a SPARQL CONSTRUCT query, with some additional restrictions and functionality. In particular, the variable representing the top-level (or 'main') resource that will appear in each search result must be identified, statements must be included to specify the types of the entities being queried, OFFSET is used to control paging, and ORDER BY is used to sort the results. It is certainly possible to write Gravsearch queries by hand, but we expect that in general, they will be automatically generated by client software, e.g. by a client user interface. For a more detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data .","title":"Basic Concept"},{"location":"DSP-API/03-apis/api-v2/query-language/#submitting-gravsearch-queries","text":"The recommended way to submit a Gravsearch query is via HTTP POST: HTTP POST to http://host/v2/searchextended This works like query via POST directly in the SPARQL 1.1 Protocol : the query is sent unencoded as the HTTP request message body, in the UTF-8 charset. It is also possible to submit a Gravsearch query using HTTP GET. The entire query must be URL-encoded and included as the last element of the URL path: HTTP GET to http://host/v2/searchextended/QUERY The response to a Gravsearch query is an RDF graph, which can be requested in various formats (see Responses Describing Resources ). To request the number of results rather than the results themselves, you can do a count query: HTTP POST to http://host/v2/searchextended/count The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value.","title":"Submitting Gravsearch Queries"},{"location":"DSP-API/03-apis/api-v2/query-language/#gravsearch-and-api-schemas","text":"A Gravsearch query can be written in either of the two DSP-API v2 schemas . The simple schema is easier to work with, and is sufficient if you don't need to query anything below the level of a Knora value. If your query needs to refer to standoff markup, you must use the complex schema. Each query must use a single schema, with one exception (see Date Comparisons ). Gravsearch query results can be requested in the simple or complex schema; see API Schema . All examples hereafter run with Knora started locally as documented in the section Getting Started with DSP-API . If you access another Knora-Stack, you can check the IRI of the ontology you are targeting by requesting the ontologies metadata .","title":"Gravsearch and API Schemas"},{"location":"DSP-API/03-apis/api-v2/query-language/#using-the-simple-schema","text":"To write a query in the simple schema, use the knora-api ontology in the simple schema, and use the simple schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> In the simple schema, Knora values are represented as literals, which can be used FILTER expressions (see Filtering on Values in the Simple Schema ).","title":"Using the Simple Schema"},{"location":"DSP-API/03-apis/api-v2/query-language/#using-the-complex-schema","text":"To write a query in the complex schema, use the knora-api ontology in the complex schema, and use the complex schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> In the complex schema, Knora values are represented as objects belonging to subclasses of knora-api:Value , e.g. knora-api:TextValue , and have predicates of their own, which can be used in FILTER expressions (see Filtering on Values in the Complex Schema ).","title":"Using the Complex Schema"},{"location":"DSP-API/03-apis/api-v2/query-language/#main-and-dependent-resources","text":"The main resource is the top-level resource in a search result. Other resources that are in some way connected to the main resource are referred to as dependent resources. If the client asks for a resource A relating to a resource B, then all matches for A will be presented as main resources and those for B as dependent resources. The main resource must be represented by a variable, marked with knora-api:isMainResource , as explained under CONSTRUCT Clause .","title":"Main and Dependent Resources"},{"location":"DSP-API/03-apis/api-v2/query-language/#virtual-incoming-links","text":"Depending on the ontology design, a resource A points to B or vice versa. For example, a page A is part of a book B using the property incunabula:partOf . If A is marked as the main resource, then B is nested as a dependent resource in its link value incunabula:partOfValue . But in case B is marked as the main resource, B does not have a link value pointing to A because in fact B is pointed to by A. Instead, B has a virtual property knora-api:hasIncomingLink containing A's link value: \"knora-api:hasIncomingLinkValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasSource\" : { \"@id\" : \"http://rdfh.ch/A\", \"@type\" : \"incunabula:page\", \"incunabula:partOfValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/B\" } } } }, Note that the virtually inserted link value inverts the relation by using knora-api:linkValueHasSource . The source of the link is A and its target B is only represented by an Iri ( knora-api:linkValueHasTargetIri ) since B is the main resource.","title":"Virtual incoming Links"},{"location":"DSP-API/03-apis/api-v2/query-language/#graph-patterns-and-result-graphs","text":"The WHERE clause of a Gravsearch query specifies a graph pattern. Each query result will match this graph pattern, and will have the form of a graph whose starting point is a main resource. The query's graph pattern, and hence each query result graph, can span zero more levels of relations between resources. For example, a query could request regions in images on pages of books written by a certain author, articles by authors who were students of a particular professor, or authors of texts that refer to events that took place within a certain date range.","title":"Graph Patterns and Result Graphs"},{"location":"DSP-API/03-apis/api-v2/query-language/#permission-checking","text":"Each matching resource is returned with the values that the user has permission to see. If the user does not have permission to see a matching main resource, it is hidden in the results. If a user does not have permission to see a matching dependent resource, the link value is hidden.","title":"Permission Checking"},{"location":"DSP-API/03-apis/api-v2/query-language/#paging","text":"Gravsearch results are returned in pages. The maximum number of main resources per page is determined by Knora (and can be configured in application.conf via the setting app/v2/resources-sequence/results-per-page ). If some resources have been filtered out because the user does not have permission to see them, a page could contain fewer results, or no results. If it is possible that more results are available in subsequent pages, the Gravsearch response will contain the predicate knora-api:mayHaveMoreResults with the boolean value true , otherwise it will not contain this predicate. Therefore, to retrieve all available results, the client must request each page one at a time, until the response does not contain knora-api:mayHaveMoreResults .","title":"Paging"},{"location":"DSP-API/03-apis/api-v2/query-language/#inference","text":"Gravsearch queries are understood to imply a subset of RDFS reasoning . Depending on the triplestore being used, this may be implemented using the triplestore's own reasoner or by query expansion in Knora. Specifically, if a statement pattern specifies a property, the pattern will also match subproperties of that property, and if a statement specifies that a subject has a particular rdf:type , the statement will also match subjects belonging to subclasses of that type. If you know that reasoning will not return any additional results for your query, you can disable it by adding this line to the WHERE clause: knora-api:GravsearchOptions knora-api:useInference false . If Knora is implementing reasoning by query expansion, disabling it can improve the performance of some queries.","title":"Inference"},{"location":"DSP-API/03-apis/api-v2/query-language/#gravsearch-syntax","text":"Every Gravsearch query is a valid SPARQL 1.1 CONSTRUCT query. However, Gravsearch only supports a subset of the elements that can be used in a SPARQL Construct query, and a Gravsearch CONSTRUCT Clause has to indicate which variable is to be used for the main resource in each search result.","title":"Gravsearch Syntax"},{"location":"DSP-API/03-apis/api-v2/query-language/#supported-sparql-syntax","text":"The current version of Gravsearch accepts CONSTRUCT queries whose WHERE clauses use the following patterns, with the specified restrictions: OPTIONAL : cannot be nested in a UNION . UNION : cannot be nested in a UNION . FILTER : may contain a complex expression using the Boolean operators AND and OR, as well as comparison operators. The left argument of a comparison operator must be a query variable. A Knora ontology entity IRI used in a FILTER must be a property IRI. FILTER NOT EXISTS MINUS OFFSET : the OFFSET is needed for paging. It does not actually refer to the number of triples to be returned, but to the requested page of results. The default value is 0, which refers to the first page of results. ORDER BY : In SPARQL, the result of a CONSTRUCT query is an unordered set of triples. However, a Gravsearch query returns an ordered list of resources, which can be ordered by the values of specified properties. If the query is written in the complex schema, items below the level of Knora values may not be used in ORDER BY . BIND : The value assigned must be a Knora resource IRI.","title":"Supported SPARQL Syntax"},{"location":"DSP-API/03-apis/api-v2/query-language/#resources-properties-and-values","text":"Resources can be represented either by an IRI or by a variable, except for the main resource, which must be represented by a variable. It is possible to do a Gravsearch query in which the IRI of the main resource is already known, e.g. to request specific information about that resource and perhaps about linked resources. In this case, the IRI of the main resource must be assigned to a variable using BIND . Note that BIND statements slow the query down, therefore we recommend that you do not use them unless you have to. Properties can be represented by an IRI or a query variable. If a property is represented by a query variable, it can be restricted to certain property IRIs using a FILTER . A Knora value (i.e. a value attached to a knora-api:Resource ) must be represented as a query variable.","title":"Resources, Properties, and Values"},{"location":"DSP-API/03-apis/api-v2/query-language/#filtering-on-values","text":"","title":"Filtering on Values"},{"location":"DSP-API/03-apis/api-v2/query-language/#filtering-on-values-in-the-simple-schema","text":"In the simple schema, a variable representing a Knora value can be used directly in a FILTER expression. For example: ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Here the type of ?title is xsd:string . The following Knora value types can be compared with literals in FILTER expressions in the simple schema: Text values ( xsd:string ) Uri values ( xsd:anyURI ) Integer values ( xsd:integer ) Decimal values ( xsd:decimal ) Boolean values ( xsd:boolean ) Date values ( knora-api:Date ) List values ( knora-api:ListNode ) List values can only be searched for using the equal operator ( = ), performing an exact match on a list node's label. Labels can be given in different languages for a specific list node. If one of the given list node labels matches, it is considered a match. Note that in the simple schema, uniqueness is not guaranteed (as opposed to the complex schema). A Knora value may not be represented as the literal object of a predicate; for example, this is not allowed: ?book incunabula:title \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" .","title":"Filtering on Values in the Simple Schema"},{"location":"DSP-API/03-apis/api-v2/query-language/#filtering-on-values-in-the-complex-schema","text":"In the complex schema, variables representing Knora values are not literals. You must add something to the query (generally a statement) to get a literal from a Knora value. For example: ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Here the type of ?title is knora-api:TextValue . Note that no FILTER is needed in this example. But if you want to use a different comparison operator, you need a FILTER : ?page incunabula:seqnum ?seqnum . ?seqnum knora-api:intValueAsInt ?seqnumInt . FILTER(?seqnumInt <= 10) To match a date value in the complex schema, you must use the knora-api:toSimpleDate function in a FILTER (see Date Comparisons ). The predicates of knora-api:DateValue ( knora-api:dateValueHasStartYear , etc.) are not available in Gravsearch.","title":"Filtering on Values in the Complex Schema"},{"location":"DSP-API/03-apis/api-v2/query-language/#date-comparisons","text":"In the simple schema, you can compare a date value directly with a knora-api:Date in a FILTER : ?book incunabula:pubdate ?pubdate . FILTER(?pubdate < \"JULIAN:1497\"^^knora-api:Date) In the complex schema, you must use the function knora-api:toSimpleDate , passing it the variable representing the date value. The date literal used in the comparison must still be a knora-api:Date in the simple schema. This is the only case in which you can use both schemas in a single query: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true . ?book incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book . ?book incunabula:pubdate ?pubdate . FILTER(knora-api:toSimpleDate(?pubdate) < \"JULIAN:1497\"^^knora-api-simple:Date) } ORDER BY ?pubdate You can also use knora-api:toSimpleDate with to search for date tags in standoff text markup (see Matching Standoff Dates ). Note that the given date value for comparison must have the following format: ``` (GREGORIAN|JULIAN|ISLAMIC):\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?)? ``` E.g. an exact date like GREGORIAN:2015-12-03 or a period like GREGORIAN:2015-12-03:2015-12-04 . Dates may also have month or year precision, e.g. ISLAMIC:1407-02 (the whole month of december) or JULIAN:1330 (the whole year 1330). An optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Era can be given as GREGORIAN:1220 BC or in range as GREGORIAN:600 BC:480 BC .","title":"Date Comparisons"},{"location":"DSP-API/03-apis/api-v2/query-language/#searching-for-matching-words","text":"The function knora-api:matchText searches for matching words anywhere in a text value, and is implemented using a full-text search index if available. The first argument must represent a text value (a knore-api:TextValue in the complex schema, or an xsd:string in the simple schema). The second argument is a string literal containing the words to be matched, separated by spaces. The function supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. This function can only be used as the top-level expression in a FILTER . For example, to search for titles that contain the words 'Zeitgl\u00f6cklein' and 'Lebens': ?book incunabule:title ?title . FILTER knora-api:matchText(?title, \"Zeitgl\u00f6cklein Lebens\")","title":"Searching for Matching Words"},{"location":"DSP-API/03-apis/api-v2/query-language/#filtering-text-by-language","text":"To filter a text value by language in the simple schema, use the SPARQL lang function on the text value, e.g.: FILTER(lang(?text) = \"fr\") In the complex schema, the lang function is not supported. Use the text value's knora-api:textValueHasLanguage predicate instead: ?text knora-api:textValueHasLanguage \"fr\" .","title":"Filtering Text by Language"},{"location":"DSP-API/03-apis/api-v2/query-language/#regular-expressions","text":"The SPARQL regex function is supported. In the simple schema, you can use it directly on the text value, e.g. ?book incunabula:title ?title . FILTER regex(?title, \"Zeit\", \"i\") In the complex schema, use it on the object of the text value's knora-api:valueAsString predicate: ?book incunabula:title ?title . ?title knora-api:valueAsString ?titleStr . FILTER regex(?titleStr, \"Zeit\", \"i\")","title":"Regular Expressions"},{"location":"DSP-API/03-apis/api-v2/query-language/#searching-for-text-markup","text":"To refer to standoff markup in text values, you must write your query in the complex schema. A knora-api:TextValue can have the property knora-api:textValueHasStandoff , whose objects are the standoff markup tags in the text. You can match the tags you're interested in using rdf:type or other properties of each tag.","title":"Searching for Text Markup"},{"location":"DSP-API/03-apis/api-v2/query-language/#matching-text-in-a-standoff-tag","text":"The function knora-api:matchTextInStandoff searches for standoff tags containing certain terms. The implementation is optimised using the full-text search index if available. The function takes three arguments: A variable representing a text value. A variable representing a standoff tag. A string literal containing space-separated search terms. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . FILTER knora-api:matchTextInStandoff(?text, ?standoffParagraphTag, \"Grund Richtigkeit\") } Here we are looking for letters containing the words \"Grund\" and \"Richtigkeit\" within a single paragraph.","title":"Matching Text in a Standoff Tag"},{"location":"DSP-API/03-apis/api-v2/query-language/#matching-standoff-links","text":"If you are only interested in specifying that a resource has some text value containing a standoff link to another resource, the most efficient way is to use the property knora-api:hasStandoffLinkTo , whose subjects and objects are resources. This property is automatically maintained by Knora. For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . } Here we are looking for letters containing a link to the historian Claude Jordan, who is identified by his Integrated Authority File identifier, (VIAF)271899510 . However, if you need to specify the context in which the link tag occurs, you must use the function knora-api:standoffLink . It takes three arguments: A variable or IRI representing the resource that is the source of the link. A variable representing the standoff link tag. A variable or IRI representing the resource that is the target of the link. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . } This has the same effect as the previous example, except that because we are matching the link tag itself, we can specify that its immediate parent is a StandoffItalicTag . If you actually want to get the target of the link (in this example, ?person ) in the search results, you need to add a statement like ?letter knora-api:hasStandoffLinkTo ?person . to the WHERE clause and to the CONSTRUCT clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . ?letter knora-api:hasStandoffLinkTo ?person . }","title":"Matching Standoff Links"},{"location":"DSP-API/03-apis/api-v2/query-language/#matching-standoff-dates","text":"You can use the knora-api:toSimpleDate function (see @ref Date Comparisons ) to match dates in standoff date tags, i.e. instances of knora-api:StandoffDateTag or of one of its subclasses. For example, here we are looking for a text containing an anything:StandoffEventTag (which is a project-specific subclass of knora-api:StandoffDateTag ) representing an event that occurred sometime during the month of December 2016: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffEventTag . ?standoffEventTag a anything:StandoffEventTag . FILTER(knora-api:toSimpleDate(?standoffEventTag) = \"GREGORIAN:2016-12 CE\"^^knora-api-simple:Date) }","title":"Matching Standoff Dates"},{"location":"DSP-API/03-apis/api-v2/query-language/#matching-ancestor-tags","text":"Suppose we want to search for a standoff date in a paragraph, but we know that the paragraph tag might not be the immediate parent of the date tag. For example, the date tag might be in an italics tag, which is in a paragraph tag. In that case, we can use the inferred property knora-api:standoffTagHasStartAncestor . We can modify the previous example to do this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffDateTag . ?standoffDateTag a knora-api:StandoffDateTag . FILTER(knora-api:toSimpleDate(?standoffDateTag) = \"GREGORIAN:2016-12-24 CE\"^^knora-api-simple:Date) ?standoffDateTag knora-api:standoffTagHasStartAncestor ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . }","title":"Matching Ancestor Tags"},{"location":"DSP-API/03-apis/api-v2/query-language/#filtering-on-rdfslabel","text":"The rdfs:label of a resource is not a Knora value, but you can still search for it. This can be done in the same ways in the simple or complex schema: Using a string literal object: ?book rdfs:label \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Using a variable and a FILTER: ?book rdfs:label ?label . FILTER(?label = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Using the regex function: ?book rdfs:label ?bookLabel . FILTER regex(?bookLabel, \"Zeit\", \"i\") To match words in an rdfs:label using the full-text search index, use the knora-api:matchLabel function, which works like knora-api:matchText , except that the first argument is a variable representing a resource: FILTER knora-api:matchLabel(?book, \"Zeitgl\u00f6cklein\")","title":"Filtering on rdfs:label"},{"location":"DSP-API/03-apis/api-v2/query-language/#filtering-on-resource-iris","text":"A FILTER can compare a variable with another variable or IRI representing a resource. For example, to find a letter whose author and recipient are different persons: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != ?person2) . } OFFSET 0 To find a letter whose author is not a person with a specified IRI: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != <http://rdfh.ch/0801/F4n1xKa3TCiR4llJeElAGA>) . } OFFSET 0","title":"Filtering on Resource IRIs"},{"location":"DSP-API/03-apis/api-v2/query-language/#construct-clause","text":"In the CONSTRUCT clause of a Gravsearch query, the variable representing the main resource must be indicated with knora-api:isMainResource true . Exactly one variable representing a resource must be marked in this way. Any other statements in the CONSTRUCT clause must also be present in the WHERE clause. If a variable representing a resource or value is used in the WHERE clause but not in the CONSTRUCT clause, the matching resources or values will not be included in the results. If the query is written in the complex schema, all variables in the CONSTRUCT clause must refer to Knora resources, Knora values, or properties. Data below the level of Knora values may not be mentioned in the CONSTRUCT clause. Predicates from the rdf , rdfs , and owl ontologies may not be used in the CONSTRUCT clause. The rdfs:label of each matching resource is always returned, so there is no need to mention it in the query.","title":"CONSTRUCT Clause"},{"location":"DSP-API/03-apis/api-v2/query-language/#gravsearch-by-example","text":"In this section, we provide some sample queries of different complexity to illustrate the usage of Gravsearch.","title":"Gravsearch by Example"},{"location":"DSP-API/03-apis/api-v2/query-language/#getting-all-the-components-of-a-compound-resource","text":"In order to get all the components of a compound resource, the following Gravsearch query can be sent to the API. In this case, the compound resource is an incunabula:book identified by the IRI http://rdfh.ch/0803/c5058f3a and the components are of type incunabula:page (test data for the Incunabula project). Since inference is assumed, we can use knora-api:StillImageRepresentation ( incunabula:page is one of its subclasses). This makes the query more generic and allows for reuse (for instance, a client would like to query different types of compound resources defined in different ontologies). ORDER BY is used to sort the components by their sequence number. OFFSET is set to 0 to get the first page of results. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?component knora-api:isMainResource true . # marking of the component searched for as the main resource, required ?component knora-api:seqnum ?seqnum . # return the sequence number in the response ?component knora-api:hasStillImageFileValue ?file . # return the StillImageFile in the response } WHERE { ?component a knora-api:StillImageRepresentation . # restriction of the type of component ?component knora-api:isPartOf <http://rdfh.ch/0803/c5058f3a> . # component relates to a compound resource via this property ?component knora-api:seqnum ?seqnum . # component must have a sequence number ?component knora-api:hasStillImageFileValue ?file . # component must have a StillImageFile } ORDER BY ASC(?seqnum) # order by sequence number, ascending OFFSET 0 # get first page of results The incunabula:book with the IRI http://rdfh.ch/0803/c5058f3a has 402 pages. (This result can be obtained by doing a count query; see Submitting Gravsearch Queries .) However, with OFFSET 0 , only the first page of results is returned. The same query can be sent again with OFFSET 1 to get the next page of results, and so forth. When a page of results is not full (see settings in app/v2 in application.conf ) or is empty, no more results are available. By design, it is not possible for the client to get more than one page of results at a time; this is intended to prevent performance problems that would be caused by huge responses. A client that wants to download all the results of a query must request each page sequentially. Let's assume the client is not interested in all of the book's pages, but just in first ten of them. In that case, the sequence number can be restricted using a FILTER that is added to the query's WHERE clause: FILTER (?seqnum <= 10) The first page starts with sequence number 1, so with this FILTER only the first ten pages are returned. This query would be exactly the same in the complex schema, except for the expansion of the knora-api prefix: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#>","title":"Getting All the Components of a Compound Resource"},{"location":"DSP-API/03-apis/api-v2/query-language/#traversing-multiple-links","text":"Here we are looking for regions of pages that are part of books that have a particular title. In the simple schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") } In the complex schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . } If we remove the line ?book incunabula:title ?title . from the CONSTRUCT clause, so that the CONSTRUCT clause no longer mentions ?title , the response will contain the same matching resources, but the titles of those resources will not be included in the response.","title":"Traversing Multiple Links"},{"location":"DSP-API/03-apis/api-v2/query-language/#requesting-a-graph-starting-with-a-known-resource","text":"Here the IRI of the main resource is already known, and we want specific information about it, as well as about related resources. In this case, the IRI of the main resource must be assigned to a variable using BIND : PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?letter knora-api:isMainResource true ; beol:creationDate ?date ; ?linkingProp1 ?person1 . ?person1 beol:hasFamilyName ?familyName . } WHERE { BIND(<http://rdfh.ch/0801/_B3lQa6tSymIq7_7SowBsA> AS ?letter) ?letter a beol:letter ; beol:creationDate ?date ; ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient) ?person1 beol:hasFamilyName ?familyName . } ORDER BY ?date This query would be the same in the complex schema, except for the prefix expansions: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#>","title":"Requesting a Graph Starting with a Known Resource"},{"location":"DSP-API/03-apis/api-v2/query-language/#searching-for-a-list-value-referring-to-a-particular-list-node","text":"Since list nodes are represented by their Iri in the complex schema, uniqueness is guranteed (as opposed to the simple schema). Also all the subnodes of the given list node are considered a match. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasListItem ?listItem . } WHERE { ?thing anything:hasListItem ?listItem . ?listItem knora-api:listValueAsListNode <http://rdfh.ch/lists/0001/treeList02> . }","title":"Searching for a List Value Referring to a Particular List Node"},{"location":"DSP-API/03-apis/api-v2/query-language/#type-inference","text":"Gravsearch needs to be able to determine the types of the entities that query variables and IRIs refer to in the WHERE clause. In most cases, it can infer these from context and from the ontologies used. In particular, it needs to know: The type of the subject and object of each statement. The type that is expected as the object of each predicate.","title":"Type Inference"},{"location":"DSP-API/03-apis/api-v2/query-language/#type-annotations","text":"When one or more types cannot be inferred, Gravsearch will return an error message indicating the entities for which it could not determine types. The missing information must then be given by adding type annotations to the query. This can always done by adding statements with the predicate rdf:type . The subject must be a resource or value, and the object must either be knora-api:Resource (if the subject is a resource) or the subject's specific type (if it is a value). For example, consider this query that uses a non-Knora property: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book dcterms:title ?title . } This produces the error message: The types of one or more entities could not be determined: ?book, <http://purl.org/dc/terms/title>, ?title To solve this problem, it is enough to specify the types of ?book and ?title ; the type of the expected object of dcterms:title can then be inferred from the type of ?title . PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . ?title rdf:type xsd:string . } It would also be possible to annotate the property itself, using the predicate knora-api:objectType ; then the type of ?title would be inferred: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . dcterms:title knora-api:objectType xsd:string . } Note that it only makes sense to use dcterms:title in the simple schema, because its object is supposed to be a literal. Here is another example, using a non-Knora class: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } This produces the error message: Types could not be determined for one or more entities: ?person The solution is to specify that ?person is a knora-api:Resource : PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person a knora-api:Resource . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") }","title":"Type Annotations"},{"location":"DSP-API/03-apis/api-v2/query-language/#inconsistent-types","text":"Gravsearch will also reject a query if an entity is used with inconsistent types. For example: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\") . } This returns the error message: One or more entities have inconsistent types: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#pubdate> knora-api:objectType <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; knora-api:objectType <http://www.w3.org/2001/XMLSchema#string> . ?pubdate rdf:type <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; rdf:type <http://www.w3.org/2001/XMLSchema#string> . This is because the incunabula ontology says that the object of incunabula:pubdate must be a knora-api:Date , but the FILTER expression compares ?pubdate with an xsd:string . The solution is to specify the type of the literal in the FILTER : PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\"^^knora-api:Date) . }","title":"Inconsistent Types"},{"location":"DSP-API/03-apis/api-v2/query-language/#scoping-issues","text":"SPARQL is evaluated from the bottom up . A UNION block therefore opens a new scope, in which variables bound at higher levels are not necessarily in scope. This can cause unexpected results if queries are not carefully designed. Gravsearch tries to prevent this by rejecting queries in the following cases.","title":"Scoping Issues"},{"location":"DSP-API/03-apis/api-v2/query-language/#filter-in-union","text":"A FILTER in a UNION block can only use variables that are bound in the same block, otherwise the query will be rejected. This query is invalid because ?text is not bound in the UNION block containing the FILTER where the variable is used: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls: <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api:isMainResource true . ?lemma mls:hasLemmaText ?text . } WHERE { ?lemma a mls:Lemma . ?lemma mls:hasLemmaText ?text . { ?lemma mls:hasPseudonym ?pseudo . FILTER regex(?pseudo, \"Abel\", \"i\") . } UNION { FILTER regex(?text, \"Abel\", \"i\") . } } ORDER BY ASC(?text) OFFSET 0 It can be corrected like this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls: <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api:isMainResource true . ?lemma mls:hasLemmaText ?text . } WHERE { ?lemma a mls:Lemma . ?lemma mls:hasLemmaText ?text . { ?lemma mls:hasPseudonym ?pseudo . FILTER regex(?pseudo, \"Abel\", \"i\") . } UNION { ?lemma mls:hasLemmaText ?text . FILTER regex(?text, \"Abel\", \"i\") . } } ORDER BY ASC(?text) OFFSET 0","title":"FILTER in UNION"},{"location":"DSP-API/03-apis/api-v2/query-language/#order-by","text":"A variable used in ORDER BY must be bound at the top level of the WHERE clause. This query is invalid, because ?int is not bound at the top level of the WHERE clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasInteger ?int . ?thing anything:hasRichtext ?richtext . ?thing anything:hasText ?text . } WHERE { ?thing a knora-api:Resource . ?thing a anything:Thing . { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") ?thing anything:hasInteger ?int . } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") ?thing anything:hasInteger ?int . } } ORDER BY (?int) It can be corrected like this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasInteger ?int . ?thing anything:hasRichtext ?richtext . ?thing anything:hasText ?text . } WHERE { ?thing a knora-api:Resource . ?thing a anything:Thing . ?thing anything:hasInteger ?int . { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") } } ORDER BY (?int)","title":"ORDER BY"},{"location":"DSP-API/03-apis/api-v2/query-language/#query-optimization-by-dependency","text":"The query performance of triplestores, such as Fuseki, is highly dependent on the order of query patterns. To improve performance, Gravsearch automatically reorders the statement patterns in the WHERE clause according to their dependencies on each other, to minimise the number of possible matches for each pattern. This optimization can be controlled using gravsearch-dependency-optimisation feature toggle , which is turned on by default. Consider the following Gravsearch query: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?letter beol:creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?person1 beol:hasIAFIdentifier ?gnd1 . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . } ORDER BY ?date Gravsearch optimises the performance of this query by moving these statements to the top of the WHERE clause: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the WHERE clause then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date .","title":"Query Optimization by Dependency"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/","text":"Reading and Searching Resources To retrieve an existing resource, the HTTP method GET has to be used. Reading resources may require authentication, since some resources may have restricted viewing permissions. Responses Describing Resources Resources can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). Operations for reading and searching resources can return responses in either the simple or the complex ontology schema. The complex schema is used by default. To receive a response in the simple schema, use the HTTP request header or URL parameter described in API Schema . Each DSP-API v2 response describing one or more resources returns a single RDF graph. For example, a request for a single resource returns that resource and all its values. In a full-text search, the resource is returned with the values that matched the search criteria. A response to an extended search may represent a whole graph of interconnected resources. In JSON-LD, if only one resource is returned, it is the top-level object; if more than one resource is returned, they are represented as an array of objects of the @graph member of the top-level object (see Named Graphs in the JSON-LD specification). In the complex schema, dependent resources, i.e. resources that are referred to by other resources on the top level, are nested in link value objects. If resources on the top level are referred to by other resources and these links are part of the response, virtual incoming links are generated; see Gravsearch: Virtual Graph Search ). See the interfaces Resource and ResourcesSequence in module ResourcesResponse (exists for both API schemas: ApiV2Simple and ApiV2WithValueObjects ). Text Markup Options Text markup can be returned in one of two ways: As XML embedded in the response, using an XML to Standoff Mapping . As standoff/RDF , which is Knora's internal markup representation. Embedded XML is the default. Implementation of support for standoff/RDF in API v2 is in its early stages. The basic procedure works like this: First, request a resource in the complex schema , using any relevant API v2 route, submitting the string standoff as the value of either: the HTTP header X-Knora-Accept-Markup the URL parameter markup If a text value in the resource contains markup, the text value will look something like this: { \"@id\" : \"http://rdfh.ch/0001/LK-wKXDNQJaRHOf0F0aJ2g/values/1Er1OpVwQR2u6peTwyNpJw\", \"@type\" : \"knora-api:TextValue\", \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V knora-admin:UnknownUser\", \"knora-api:textValueHasMarkup\" : true, \"knora-api:textValueHasMaxStandoffStartIndex\" : 6737, \"knora-api:userHasPermission\" : \"CR\", \"knora-api:valueAsString\" : \"\\nHamlet\\nACT I\\nSCENE I. Elsinore. A platform before the castle...\", \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-05-08T17:08:32.158401Z\" } } The object knora-api:valueAsString contains the text without markup. The predicate knora-api:textValueHasMarkup indicates that the text value has markup, and the value of the predicate knora-api:textValueHasMaxStandoffStartIndex gives the start index of the last standoff tag; this gives the client some idea of how much markup there is. You can then request the text value's standoff/RDF, which is returned in pages of a limited size. To get each page: HTTP GET to http://host/v2/standoff/RESOURCE_IRI/TEXT_VALUE_IRI/OFFSET Both RESOURCE_IRI and TEXT_VALUE_IRI must be URL-encoded. The offset is an integer whose initial value is 0. The response will look like this: { \"@graph\" : [ { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffRootTag\", \"knora-api:standoffTagHasEnd\" : 184716, \"knora-api:standoffTagHasStart\" : 0, \"knora-api:standoffTagHasStartIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"sbBzeAaNTzaUXl90UtlYzw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader1Tag\", \"knora-api:standoffTagHasEnd\" : 7, \"knora-api:standoffTagHasStart\" : 1, \"knora-api:standoffTagHasStartIndex\" : 1, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"HhXjcdSTS_G6eSQ0apdjUw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\", \"knora-api:standoffTagHasEnd\" : 14, \"knora-api:standoffTagHasStart\" : 9, \"knora-api:standoffTagHasStartIndex\" : 2, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"Ymr2aDUqTx6nMwGZGiqduA\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\", \"knora-api:standoffTagHasEnd\" : 64, \"knora-api:standoffTagHasStart\" : 16, \"knora-api:standoffTagHasStartIndex\" : 3, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"_Zk0B1edRK6mgdtokmosXg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffBlockquoteTag\", \"knora-api:standoffTagHasEnd\" : 112, \"knora-api:standoffTagHasStart\" : 66, \"knora-api:standoffTagHasStartIndex\" : 4, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"1DLdI0LJTCy07w6ZsOM_Sg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffItalicTag\", \"knora-api:standoffTagHasEnd\" : 111, \"knora-api:standoffTagHasStart\" : 67, \"knora-api:standoffTagHasStartIndex\" : 5, \"knora-api:standoffTagHasStartParentIndex\" : 4, \"knora-api:standoffTagHasUUID\" : \"XJ6GVO1VQSqrTyLHGnHqcA\" } ], \"knora-api:nextStandoffStartIndex\" : 100, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } See Text with Standoff Markup for details of the predicates in each standoff tag. If there are more pages of standoff to be requested, the response will contain knora-api:nextStandoffStartIndex , whose object should be submitted as the next OFFSET to the same route. This continues until you receive a response without knora-api:nextStandoffStartIndex . Get the Representation of a Resource by IRI Get a Full Representation of a Resource by IRI A full representation of resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL-encoded. To get the resource with the IRI http://rdfh.ch/c5058f3a (a book from the sample Incunabula project, which is included in the Knora API server's test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL-encoded IRI: HTTP GET to http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a If necessary, several resources can be queried at the same time, their IRIs separated by slashes. Please note that the amount of resources that can be queried in one requested is limited. See the settings for app/v2 in application.conf . More formally, the URL looks like this: HTTP GET to http://host/v2/resources/resourceIRI(/anotherResourceIri)* Get a Full Representation of a Version of a Resource by IRI To get a specific past version of a resource, use the route described in Get a Full Representation of a Resource by IRI , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The resource will be returned with the values that it had at the specified time. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current metadata will be returned. Each value will be returned with the permissions that are attached to the current version of the value (see Permissions ). The returned resource will include the predicate knora-api:versionDate , containing the timestamp that was submitted, and its knora-api:versionArkUrl (see Resource Permalinks ) will contain the same timestamp. Get a Value in a Resource To get a specific value of a resource, use this route: HTTP GET to http://host/v2/values/resourceIRI/valueUUID The resource IRI must be URL-encoded. The path element valueUUID is the string object of the value's knora-api:valueHasUUID . The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Get a Version of a Value in a Resource To get a particular version of a specific value of a resource, use the route described in Get a Value in a Resource , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current resource metadata will be returned. The value will be returned with the permissions that are attached to its current version (see Permissions ). Get the Version History of a Resource To get a list of the changes that have been made to a resource since its creation, use this route: HTTP GET to http://host/v2/resources/history/resourceIRI[?startDate=START_DATE&endDate=END_DATE] The resource IRI must be URL-encoded. The start and end dates are optional, and are URL-encoded timestamps in xsd:dateTimeStamp format. The start date is inclusive, and the end date is exclusive. If the start date is not provided, the resource's history since its creation is returned. If the end date is not provided, the resource's history up to the present is returned. The response is a list of changes made to the resource, in reverse chronological order. Each entry has the properties knora-api:author (the IRI of the user who made the change) and knora-api:versionDate (the date when the change was made). For example: { \"@graph\" : [ { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-11T09:05:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-10T10:30:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-10T10:05:10Z\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The entries include all the dates when the resource's values were created or modified (within the requested date range), as well as the date when the resource was created (if the requested date range allows it). Each date is included only once. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), changes to a resource's metadata are not included in its version history. To request the resource as it was at each of these dates, see Get a Full Representation of a Version of a Resource by IRI . For consistency in citation, we recommend using these dates when requesting resource versions. Get the preview of a resource by IRI In some cases, the client may only want to request the preview of a resource, which just provides its metadata (e.g. its IRI, rdfs:label , and type), without its values. This works exactly like making a conventional resource request, using the path segment resourcespreview : HTTP GET to http://host/v2/resourcespreview/resourceIRI(/anotherResourceIri)* Get a Graph of Resources Knora can return a graph of connections between resources, e.g. for generating a network diagram. HTTP GET to http://host/v2/graph/resourceIRI[depth=Integer] [direction=outbound|inbound|both][excludeProperty=propertyIri] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . depth must be at least 1. The maximum depth is an Knora configuration setting. The default is 4. direction specifies the direction of the links to be queried, i.e. links to and/or from the given resource. The default is outbound . excludeProperty is an optional link property to be excluded from the results. To accommodate large graphs, the graph response format is very concise, and is therefore simpler than the usual resources response format. Each resource represented only by its IRI, class, and label. Direct links are shown instead of link values. For example: { \"@graph\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Sierra\" }, { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Victor\" }, { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Foxtrot\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\" }, \"rdfs:label\" : \"Tango\" }, { \"@id\" : \"http://rdfh.ch/0001/start\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } ], \"rdfs:label\" : \"Romeo\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\" }, \"rdfs:label\" : \"Echo\" } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Search for Resources Search for a Resource by its rdfs:label Knora offers the possibility to search for resources by their rdfs:label . The use case for this search is to find a specific resource as you type. E.g., the user wants to get a list of resources whose rdfs:label contain some search terms separated by a whitespace character: Zeit Zeitg ... Zeitgl\u00f6cklein d ... Zeitgl\u00f6cklein des Lebens With each character added to the last term, the selection gets more specific. The first term should at least contain four characters. To make this kind of \"search as you type\" possible, a wildcard character is automatically added to the last search term. Search by label automatically adds Lucene operators, search strings are expected not to contain any characters with a special meaning in Lucene Query Parser syntax . HTTP GET to http://host/v2/searchbylabel/searchValue[limitToResourceClass=resourceClassIRI] [limitToProject=projectIRI][offset=Integer] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . The default value for the parameter offset is 0, which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . For performance reasons, standoff markup is not queried for this route. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/searchbylabel/count/searchValue[limitToResourceClass=resourceClassIRI][limitToProject=projectIRI][offset=Integer] The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. Full-text Search Knora offers a full-text search that searches through all textual representations of values and rdfs:label of resources. Full-text search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. Please note that the search terms have to be URL-encoded. HTTP GET to http://host/v2/search/searchValue[limitToResourceClass=resourceClassIRI] [limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . A search value must have a minimal length of three characters (default value) as defined in app/v2 in application.conf . A search term may contain wildcards. A ? represents a single character. It has to be URL-encoded as %3F since it has a special meaning in the URL syntax. For example, the term Uniform can be search for like this: HTTP GET to http://host/v2/search/Unif%3Frm A * represents zero, one or multiple characters. For example, the term Uniform can be searched for like this: HTTP GET to http://host/v2/search/Uni*m The default value for the parameter offset is 0 which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . If the parameter limitToStandoffClass is provided, Knora will look for search terms that are marked up with the indicated standoff class. If the parameter returnFiles=true is provided, Knora will return any file value attached to each matching resource. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/search/count/searchValue[limitToResourceClass=resourceClassIRI][limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. Gravsearch For more complex queries than a full-text search, Knora offers a query language called Gravsearch: Virtual Graph Search ). Support of TEI/XML To convert standoff markup to TEI/XML, see TEI/XML . IIIF Manifests This is an experimental feature and may change. To generate a IIIF manifest for a resource, containing the still image representations that have knora-api:isPartOf (or a subproperty) pointing to that resource: HTTP GET to http://host/v2/resources//iiifmanifest/RESOURCE_IRI Reading Resources by Class from a Project To facilitate the development of tabular user interfaces for data entry, it is possible to get a paged list of all the resources belonging to a particular class in a given project, sorted by the value of a property: HTTP GET to http://host/v2/resources?resourceClass=RESOURCE_CLASS_IRI&page=PAGE[&orderByProperty=PROPERTY_IRI] This is useful only if the project does not contain a large amount of data; otherwise, you should use Gravsearch to search using more specific criteria. The specified class and property are used without inference; they will not match subclasses or subproperties. The HTTP header X-Knora-Accept-Project must be submitted; its value is a Knora project IRI. In the request URL, the values of resourceClass and orderByProperty are URL-encoded IRIs in the complex schema . The orderByProperty parameter is optional; if it is not supplied, resources will be sorted alphabetically by resource IRI (an arbitrary but consistent order). The value of page is a 0-based integer page number. Paging works as it does in Gravsearch ). Get the Full History of a Resource and its Values as Events To get a list of the changes that have been made to a resource and its values since its creation as events ordered by date: HTTP GET to http://host/v2/resources/resourceHistoryEvents/<resourceIRI> The resource IRI must be URL-encoded. The response is a list of events describing changes made to the resource and its values, in chronological order. Each entry has the properties: knora-api:eventType (the type of the operation performed on a specific date. The operation can be either createdResource , updatedResourceMetadata , deletedResource , createdValue , updatedValueContent , updatedValuePermissions , or deletedValue .), knora-api:versionDate (the date when the change was made), knora-api:author (the IRI of the user who made the change), knora-api:eventBody (the information necessary to make the same request). For example, the following response contains the list of events describing the version history of the resource http://rdfh.ch/0001/thing-with-history ordered by date: { \"@graph\" : [ { \"knora-api:eventType\": \"createdResource\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"rdfs:label\": \"A thing with version history\", \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:creationDate\": { \"@value\": \"2019-02-08T15:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/0001\" } }, \"knora-api:versionDate\": { \"@value\": \"2019-02-08T15:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"createdValue\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-api:valueCreationDate\": { \"@value\": \"2019-02-10T10:30:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:valueHasUUID\": \"IZGOjVqxTfSNO4ieKyp0SA\", \"knora-api:hasPermissions\": \"V knora-admin:UnknownUser|M knora-admin:ProjectMember\", \"@type\": \"knora-base:LinkValue\", \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\": { \"knora-api:linkValueHasTargetIri\": { \"@id\": \"http://rdfh.ch/0001/2qMtTWvVRXWMBcRNlduvCQ\" } }, \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/3a\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-10T10:30:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"updatedValueContent\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\" \"http://www.knora.org/ontology/0001/anything#hasText\": { \"knora-api:valueAsString\": \"two\" }, \"knora-api:valueCreationDate\": { \"@value\": \"2019-02-11T10:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-base:previousValue\": \"http://rdfh.ch/0001/thing-with-history/values/2a\", \"knora-api:valueHasUUID\": \"W5fm67e0QDWxRZumcXcs6g\", \"@type\": \"knora-base:TextValue\", \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasText\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/2b\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-11T10:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"deletedValue\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-base:previousValue\": \"http://rdfh.ch/0001/thing-with-history/values/3a\", \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2019-02-13T09:00:10Z\" }, \"knora-api:isDeleted\": true, \"@type\": \"knora-base:LinkValue\", \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/3b\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-13T09:00:10Z\", \"@type\": \"xsd:dateTimeStamp\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Since the history of changes made to the metadata of a resource is not part of resouce's version history, there are no events describing the changes on metadata elements like its rdfs:label or rdfs:comment . The only record depicting a change in a resource's metadata is the knora-api:lastModificationDate of the resource. Thus the event updatedResourceMetadata indicates a change in a resource's metadata, its knora-api:eventBody contains the payload needed to update the value of the resource's lastModificationDate , see modifying metadata of a resource . Get the Full History of all Resources of a Project as Events To get a list of the changes that have been made to the resources and their values of a project as events ordered by date: HTTP GET to http://host/v2/resources/projectHistoryEvents/<projectIRI> The project IRI must be URL-encoded. The response contains the resource history events of all resources that belong to the specified project.","title":"Reading and Searching Resources"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#reading-and-searching-resources","text":"To retrieve an existing resource, the HTTP method GET has to be used. Reading resources may require authentication, since some resources may have restricted viewing permissions.","title":"Reading and Searching Resources"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#responses-describing-resources","text":"Resources can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). Operations for reading and searching resources can return responses in either the simple or the complex ontology schema. The complex schema is used by default. To receive a response in the simple schema, use the HTTP request header or URL parameter described in API Schema . Each DSP-API v2 response describing one or more resources returns a single RDF graph. For example, a request for a single resource returns that resource and all its values. In a full-text search, the resource is returned with the values that matched the search criteria. A response to an extended search may represent a whole graph of interconnected resources. In JSON-LD, if only one resource is returned, it is the top-level object; if more than one resource is returned, they are represented as an array of objects of the @graph member of the top-level object (see Named Graphs in the JSON-LD specification). In the complex schema, dependent resources, i.e. resources that are referred to by other resources on the top level, are nested in link value objects. If resources on the top level are referred to by other resources and these links are part of the response, virtual incoming links are generated; see Gravsearch: Virtual Graph Search ). See the interfaces Resource and ResourcesSequence in module ResourcesResponse (exists for both API schemas: ApiV2Simple and ApiV2WithValueObjects ).","title":"Responses Describing Resources"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#text-markup-options","text":"Text markup can be returned in one of two ways: As XML embedded in the response, using an XML to Standoff Mapping . As standoff/RDF , which is Knora's internal markup representation. Embedded XML is the default. Implementation of support for standoff/RDF in API v2 is in its early stages. The basic procedure works like this: First, request a resource in the complex schema , using any relevant API v2 route, submitting the string standoff as the value of either: the HTTP header X-Knora-Accept-Markup the URL parameter markup If a text value in the resource contains markup, the text value will look something like this: { \"@id\" : \"http://rdfh.ch/0001/LK-wKXDNQJaRHOf0F0aJ2g/values/1Er1OpVwQR2u6peTwyNpJw\", \"@type\" : \"knora-api:TextValue\", \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V knora-admin:UnknownUser\", \"knora-api:textValueHasMarkup\" : true, \"knora-api:textValueHasMaxStandoffStartIndex\" : 6737, \"knora-api:userHasPermission\" : \"CR\", \"knora-api:valueAsString\" : \"\\nHamlet\\nACT I\\nSCENE I. Elsinore. A platform before the castle...\", \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-05-08T17:08:32.158401Z\" } } The object knora-api:valueAsString contains the text without markup. The predicate knora-api:textValueHasMarkup indicates that the text value has markup, and the value of the predicate knora-api:textValueHasMaxStandoffStartIndex gives the start index of the last standoff tag; this gives the client some idea of how much markup there is. You can then request the text value's standoff/RDF, which is returned in pages of a limited size. To get each page: HTTP GET to http://host/v2/standoff/RESOURCE_IRI/TEXT_VALUE_IRI/OFFSET Both RESOURCE_IRI and TEXT_VALUE_IRI must be URL-encoded. The offset is an integer whose initial value is 0. The response will look like this: { \"@graph\" : [ { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffRootTag\", \"knora-api:standoffTagHasEnd\" : 184716, \"knora-api:standoffTagHasStart\" : 0, \"knora-api:standoffTagHasStartIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"sbBzeAaNTzaUXl90UtlYzw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader1Tag\", \"knora-api:standoffTagHasEnd\" : 7, \"knora-api:standoffTagHasStart\" : 1, \"knora-api:standoffTagHasStartIndex\" : 1, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"HhXjcdSTS_G6eSQ0apdjUw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\", \"knora-api:standoffTagHasEnd\" : 14, \"knora-api:standoffTagHasStart\" : 9, \"knora-api:standoffTagHasStartIndex\" : 2, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"Ymr2aDUqTx6nMwGZGiqduA\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\", \"knora-api:standoffTagHasEnd\" : 64, \"knora-api:standoffTagHasStart\" : 16, \"knora-api:standoffTagHasStartIndex\" : 3, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"_Zk0B1edRK6mgdtokmosXg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffBlockquoteTag\", \"knora-api:standoffTagHasEnd\" : 112, \"knora-api:standoffTagHasStart\" : 66, \"knora-api:standoffTagHasStartIndex\" : 4, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"1DLdI0LJTCy07w6ZsOM_Sg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffItalicTag\", \"knora-api:standoffTagHasEnd\" : 111, \"knora-api:standoffTagHasStart\" : 67, \"knora-api:standoffTagHasStartIndex\" : 5, \"knora-api:standoffTagHasStartParentIndex\" : 4, \"knora-api:standoffTagHasUUID\" : \"XJ6GVO1VQSqrTyLHGnHqcA\" } ], \"knora-api:nextStandoffStartIndex\" : 100, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } See Text with Standoff Markup for details of the predicates in each standoff tag. If there are more pages of standoff to be requested, the response will contain knora-api:nextStandoffStartIndex , whose object should be submitted as the next OFFSET to the same route. This continues until you receive a response without knora-api:nextStandoffStartIndex .","title":"Text Markup Options"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-the-representation-of-a-resource-by-iri","text":"","title":"Get the Representation of a Resource by IRI"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-a-full-representation-of-a-resource-by-iri","text":"A full representation of resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL-encoded. To get the resource with the IRI http://rdfh.ch/c5058f3a (a book from the sample Incunabula project, which is included in the Knora API server's test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL-encoded IRI: HTTP GET to http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a If necessary, several resources can be queried at the same time, their IRIs separated by slashes. Please note that the amount of resources that can be queried in one requested is limited. See the settings for app/v2 in application.conf . More formally, the URL looks like this: HTTP GET to http://host/v2/resources/resourceIRI(/anotherResourceIri)*","title":"Get a Full Representation of a Resource by IRI"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-a-full-representation-of-a-version-of-a-resource-by-iri","text":"To get a specific past version of a resource, use the route described in Get a Full Representation of a Resource by IRI , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The resource will be returned with the values that it had at the specified time. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current metadata will be returned. Each value will be returned with the permissions that are attached to the current version of the value (see Permissions ). The returned resource will include the predicate knora-api:versionDate , containing the timestamp that was submitted, and its knora-api:versionArkUrl (see Resource Permalinks ) will contain the same timestamp.","title":"Get a Full Representation of a Version of a Resource by IRI"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-a-value-in-a-resource","text":"To get a specific value of a resource, use this route: HTTP GET to http://host/v2/values/resourceIRI/valueUUID The resource IRI must be URL-encoded. The path element valueUUID is the string object of the value's knora-api:valueHasUUID . The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values.","title":"Get a Value in a Resource"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-a-version-of-a-value-in-a-resource","text":"To get a particular version of a specific value of a resource, use the route described in Get a Value in a Resource , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current resource metadata will be returned. The value will be returned with the permissions that are attached to its current version (see Permissions ).","title":"Get a Version of a Value in a Resource"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-the-version-history-of-a-resource","text":"To get a list of the changes that have been made to a resource since its creation, use this route: HTTP GET to http://host/v2/resources/history/resourceIRI[?startDate=START_DATE&endDate=END_DATE] The resource IRI must be URL-encoded. The start and end dates are optional, and are URL-encoded timestamps in xsd:dateTimeStamp format. The start date is inclusive, and the end date is exclusive. If the start date is not provided, the resource's history since its creation is returned. If the end date is not provided, the resource's history up to the present is returned. The response is a list of changes made to the resource, in reverse chronological order. Each entry has the properties knora-api:author (the IRI of the user who made the change) and knora-api:versionDate (the date when the change was made). For example: { \"@graph\" : [ { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-11T09:05:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-10T10:30:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-10T10:05:10Z\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The entries include all the dates when the resource's values were created or modified (within the requested date range), as well as the date when the resource was created (if the requested date range allows it). Each date is included only once. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), changes to a resource's metadata are not included in its version history. To request the resource as it was at each of these dates, see Get a Full Representation of a Version of a Resource by IRI . For consistency in citation, we recommend using these dates when requesting resource versions.","title":"Get the Version History of a Resource"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-the-preview-of-a-resource-by-iri","text":"In some cases, the client may only want to request the preview of a resource, which just provides its metadata (e.g. its IRI, rdfs:label , and type), without its values. This works exactly like making a conventional resource request, using the path segment resourcespreview : HTTP GET to http://host/v2/resourcespreview/resourceIRI(/anotherResourceIri)*","title":"Get the preview of a resource by IRI"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-a-graph-of-resources","text":"Knora can return a graph of connections between resources, e.g. for generating a network diagram. HTTP GET to http://host/v2/graph/resourceIRI[depth=Integer] [direction=outbound|inbound|both][excludeProperty=propertyIri] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . depth must be at least 1. The maximum depth is an Knora configuration setting. The default is 4. direction specifies the direction of the links to be queried, i.e. links to and/or from the given resource. The default is outbound . excludeProperty is an optional link property to be excluded from the results. To accommodate large graphs, the graph response format is very concise, and is therefore simpler than the usual resources response format. Each resource represented only by its IRI, class, and label. Direct links are shown instead of link values. For example: { \"@graph\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Sierra\" }, { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Victor\" }, { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Foxtrot\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\" }, \"rdfs:label\" : \"Tango\" }, { \"@id\" : \"http://rdfh.ch/0001/start\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } ], \"rdfs:label\" : \"Romeo\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\" }, \"rdfs:label\" : \"Echo\" } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } }","title":"Get a Graph of Resources"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#search-for-resources","text":"","title":"Search for Resources"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#search-for-a-resource-by-its-rdfslabel","text":"Knora offers the possibility to search for resources by their rdfs:label . The use case for this search is to find a specific resource as you type. E.g., the user wants to get a list of resources whose rdfs:label contain some search terms separated by a whitespace character: Zeit Zeitg ... Zeitgl\u00f6cklein d ... Zeitgl\u00f6cklein des Lebens With each character added to the last term, the selection gets more specific. The first term should at least contain four characters. To make this kind of \"search as you type\" possible, a wildcard character is automatically added to the last search term. Search by label automatically adds Lucene operators, search strings are expected not to contain any characters with a special meaning in Lucene Query Parser syntax . HTTP GET to http://host/v2/searchbylabel/searchValue[limitToResourceClass=resourceClassIRI] [limitToProject=projectIRI][offset=Integer] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . The default value for the parameter offset is 0, which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . For performance reasons, standoff markup is not queried for this route. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/searchbylabel/count/searchValue[limitToResourceClass=resourceClassIRI][limitToProject=projectIRI][offset=Integer] The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value.","title":"Search for a Resource by its rdfs:label"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#full-text-search","text":"Knora offers a full-text search that searches through all textual representations of values and rdfs:label of resources. Full-text search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. Please note that the search terms have to be URL-encoded. HTTP GET to http://host/v2/search/searchValue[limitToResourceClass=resourceClassIRI] [limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . A search value must have a minimal length of three characters (default value) as defined in app/v2 in application.conf . A search term may contain wildcards. A ? represents a single character. It has to be URL-encoded as %3F since it has a special meaning in the URL syntax. For example, the term Uniform can be search for like this: HTTP GET to http://host/v2/search/Unif%3Frm A * represents zero, one or multiple characters. For example, the term Uniform can be searched for like this: HTTP GET to http://host/v2/search/Uni*m The default value for the parameter offset is 0 which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . If the parameter limitToStandoffClass is provided, Knora will look for search terms that are marked up with the indicated standoff class. If the parameter returnFiles=true is provided, Knora will return any file value attached to each matching resource. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/search/count/searchValue[limitToResourceClass=resourceClassIRI][limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value.","title":"Full-text Search"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#gravsearch","text":"For more complex queries than a full-text search, Knora offers a query language called Gravsearch: Virtual Graph Search ).","title":"Gravsearch"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#support-of-teixml","text":"To convert standoff markup to TEI/XML, see TEI/XML .","title":"Support of TEI/XML"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#iiif-manifests","text":"This is an experimental feature and may change. To generate a IIIF manifest for a resource, containing the still image representations that have knora-api:isPartOf (or a subproperty) pointing to that resource: HTTP GET to http://host/v2/resources//iiifmanifest/RESOURCE_IRI","title":"IIIF Manifests"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#reading-resources-by-class-from-a-project","text":"To facilitate the development of tabular user interfaces for data entry, it is possible to get a paged list of all the resources belonging to a particular class in a given project, sorted by the value of a property: HTTP GET to http://host/v2/resources?resourceClass=RESOURCE_CLASS_IRI&page=PAGE[&orderByProperty=PROPERTY_IRI] This is useful only if the project does not contain a large amount of data; otherwise, you should use Gravsearch to search using more specific criteria. The specified class and property are used without inference; they will not match subclasses or subproperties. The HTTP header X-Knora-Accept-Project must be submitted; its value is a Knora project IRI. In the request URL, the values of resourceClass and orderByProperty are URL-encoded IRIs in the complex schema . The orderByProperty parameter is optional; if it is not supplied, resources will be sorted alphabetically by resource IRI (an arbitrary but consistent order). The value of page is a 0-based integer page number. Paging works as it does in Gravsearch ).","title":"Reading Resources by Class from a Project"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-the-full-history-of-a-resource-and-its-values-as-events","text":"To get a list of the changes that have been made to a resource and its values since its creation as events ordered by date: HTTP GET to http://host/v2/resources/resourceHistoryEvents/<resourceIRI> The resource IRI must be URL-encoded. The response is a list of events describing changes made to the resource and its values, in chronological order. Each entry has the properties: knora-api:eventType (the type of the operation performed on a specific date. The operation can be either createdResource , updatedResourceMetadata , deletedResource , createdValue , updatedValueContent , updatedValuePermissions , or deletedValue .), knora-api:versionDate (the date when the change was made), knora-api:author (the IRI of the user who made the change), knora-api:eventBody (the information necessary to make the same request). For example, the following response contains the list of events describing the version history of the resource http://rdfh.ch/0001/thing-with-history ordered by date: { \"@graph\" : [ { \"knora-api:eventType\": \"createdResource\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"rdfs:label\": \"A thing with version history\", \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:creationDate\": { \"@value\": \"2019-02-08T15:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/0001\" } }, \"knora-api:versionDate\": { \"@value\": \"2019-02-08T15:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"createdValue\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-api:valueCreationDate\": { \"@value\": \"2019-02-10T10:30:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:valueHasUUID\": \"IZGOjVqxTfSNO4ieKyp0SA\", \"knora-api:hasPermissions\": \"V knora-admin:UnknownUser|M knora-admin:ProjectMember\", \"@type\": \"knora-base:LinkValue\", \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\": { \"knora-api:linkValueHasTargetIri\": { \"@id\": \"http://rdfh.ch/0001/2qMtTWvVRXWMBcRNlduvCQ\" } }, \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/3a\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-10T10:30:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"updatedValueContent\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\" \"http://www.knora.org/ontology/0001/anything#hasText\": { \"knora-api:valueAsString\": \"two\" }, \"knora-api:valueCreationDate\": { \"@value\": \"2019-02-11T10:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-base:previousValue\": \"http://rdfh.ch/0001/thing-with-history/values/2a\", \"knora-api:valueHasUUID\": \"W5fm67e0QDWxRZumcXcs6g\", \"@type\": \"knora-base:TextValue\", \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasText\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/2b\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-11T10:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"deletedValue\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-base:previousValue\": \"http://rdfh.ch/0001/thing-with-history/values/3a\", \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2019-02-13T09:00:10Z\" }, \"knora-api:isDeleted\": true, \"@type\": \"knora-base:LinkValue\", \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/3b\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-13T09:00:10Z\", \"@type\": \"xsd:dateTimeStamp\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Since the history of changes made to the metadata of a resource is not part of resouce's version history, there are no events describing the changes on metadata elements like its rdfs:label or rdfs:comment . The only record depicting a change in a resource's metadata is the knora-api:lastModificationDate of the resource. Thus the event updatedResourceMetadata indicates a change in a resource's metadata, its knora-api:eventBody contains the payload needed to update the value of the resource's lastModificationDate , see modifying metadata of a resource .","title":"Get the Full History of a Resource and its Values as Events"},{"location":"DSP-API/03-apis/api-v2/reading-and-searching-resources/#get-the-full-history-of-all-resources-of-a-project-as-events","text":"To get a list of the changes that have been made to the resources and their values of a project as events ordered by date: HTTP GET to http://host/v2/resources/projectHistoryEvents/<projectIRI> The project IRI must be URL-encoded. The response contains the resource history events of all resources that belong to the specified project.","title":"Get the Full History of all Resources of a Project as Events"},{"location":"DSP-API/03-apis/api-v2/reading-user-permissions/","text":"Reading the User's Permissions on Resources and Values In the complex API schema , each resource and value is returned with the predicate knora-api:userHasPermission . The object of this predicate is a string containing a permission code, which indicates the requesting user's maximum permission on the resource or value. These are the possible permission codes, in ascending order: RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) Each permission implies all lesser permissions. For more details, see Permissions .","title":"Reading the User's Permissions on Resources and Values"},{"location":"DSP-API/03-apis/api-v2/reading-user-permissions/#reading-the-users-permissions-on-resources-and-values","text":"In the complex API schema , each resource and value is returned with the predicate knora-api:userHasPermission . The object of this predicate is a string containing a permission code, which indicates the requesting user's maximum permission on the resource or value. These are the possible permission codes, in ascending order: RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) Each permission implies all lesser permissions. For more details, see Permissions .","title":"Reading the User's Permissions on Resources and Values"},{"location":"DSP-API/03-apis/api-v2/tei-xml/","text":"TEI/XML: Converting Standoff to TEI/XML General Knora offers a way to convert standoff markup to TEI/XML. The conversion is based on the assumption that a whole resource is to be turned into a TEI document. There is a basic distinction between the body and the header of a TEI document. The resource's property that contains the text with standoff markup is mapped to the TEI document's body. Other of the resource's property may be mapped to the TEI header. Standard Standoff to TEI Conversion Knora offers a built-in conversion form standard standoff entities (defined in the standoff ontology) tags to TEI. In order to obtain a resource as a TEI document, the following request has to be performed. Please note that the URL parameters have to be URL-encoded. HTTP GET to http://host/v2/tei/resourceIri?textProperty=textPropertyIri In addition to the resource's Iri, the Iri of the property containing the text with standoff has to be submitted. This will be converted to the TEI body. Please note that the resource can only have one instance of this property and the text must have standoff markup. The Knora test data contain the resource http://rdfh.ch/0001/thing_with_richtext_with_markup with the text property http://0.0.0.0:3333/ontology/0001/anything/v2#hasRichtext that can be converted to TEI as follows: HTTP GET to http://host/v2/tei/http%3A%2F%2Frdfh.ch%2F0001%2Fthing_with_richtext_with_markup?textProperty=http%3A%2F%2F0.0.0.0%3A3333%2Fontology%2F0001%2Fanything%2Fv2%23hasRichtext The answer to this request is a TEI XML document: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" version=\"3.3.0\"> <teiHeader> <fileDesc> <titleStmt> <title>test thing with markup</title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of a resource identified by the Iri http://rdfh.ch/0001/thing_with_richtext_with_markup. </p> </publicationStmt> <sourceDesc> <p>Representation of the resource's text as TEI/XML</p> </sourceDesc> </fileDesc> </teiHeader> <text> <body> <p>This is a test that contains marked up elements. This is <hi rend=\"italic\">interesting text</hi> in italics. This is <hi rend=\"italic\">boring text</hi> in italics.</p> </body> </text> </TEI> The body of the TEI document contains the standoff markup as XML. The header contains contains some basic metadata about the resource such as the rdfs:label an its IRI. However, this might not be sufficient for more advanced use cases like digital edition projects. In that case, a custom conversion has to be performed (see below). Custom Conversion If a project defines its own standoff entities, a custom conversion can be provided (body of the TEI document). Also for the TEI header, a custom conversion can be provided. For the custom conversion, additional configuration is required. TEI body: additional mapping from standoff to XML (URL parameter mappingIri ) XSL transformation to turn the XML into a valid TEI body (referred to by the mapping). The mapping has to refer to a defaultXSLTransformation that transforms the XML that was created from standoff markup (see XML To Standoff Mapping in API v1 ). This step is necessary because the mapping assumes a one to one relation between standoff classes and properties and XML elements and attributes. For example, we may want to convert a standoff:StandoffItalicTag into TEI/XML. TEI expresses this as <hi rend=\"italic\">...</hi> . In the mapping, the standoff:StandoffItalicTag may be mapped to a a temporary XML element that is going to be converted to <hi rend=\"italic\">...</hi> in a further step by the XSLT. For sample data, see webapi/_test_data/test_route/texts/beol/BEOLTEIMapping.xml (mapping) and webapi/_test_data/test_route/texts/beol/standoffToTEI.xsl . The standoff entities are defined in beol-onto.ttl . TEI header: Gravsearch template to query the resources metadata, results are serialized to RDF/XML (URL parameter gravsearchTemplateIri ) XSL transformation to turn that RDF/XML into a valid TEI header (URL parameter teiHeaderXSLTIri ) The Gravsearch template is expected to be of type knora-base:TextRepresentation and to contain a placeholder $resourceIri that is to be replaced by the actual resource Iri. The Gravsearch template is expected to contain a query involving the text property (URL parameter textProperty ) and more properties that are going to be mapped to the TEI header. The Gravsearch template is a simple text file with the files extension .txt . A Gravsearch template may look like this (see test_data/test_route/texts/beol/gravsearch.txt ): PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:creationDate ?date . ?letter beol:hasText ?text . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?letter beol:hasRecipient ?person2 . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . } WHERE { BIND(<$resourceIri> as ?letter) ?letter a knora-api:Resource . ?letter a beol:letter . ?letter beol:creationDate ?date . beol:creationDate knora-api:objectType knora-api:Date . ?date a knora-api:Date . ?letter beol:hasText ?text . beol:hasText knora-api:objectType xsd:string . ?text a xsd:string . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?name1 a xsd:string . ?givenName1 a xsd:string . ?iaf1 a xsd:string . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . ?name2 a xsd:string . ?givenName2 a xsd:string . ?iaf2 a xsd:string . beol:hasGivenName knora-api:objectType xsd:string . beol:hasFamilyName knora-api:objectType xsd:string . beol:hasIAFIdentifier knora-api:objectType xsd:string . beol:hasAuthor knora-api:objectType knora-api:Resource . ?letter beol:hasRecipient ?person2 . beol:hasRecipient knora-api:objectType knora-api:Resource . ?person1 a knora-api:Resource . ?person2 a knora-api:Resource . } Note the placeholder BIND(<$resourceIri> as ?letter) that is going to be replaced by the Iri of the resource the request is performed for. The query asks for information about the letter's text beol:hasText and information about its author and recipient. This information is converted to the TEI header in the format required by correspSearch . To write the XSLT, do the Gravsearch query and request the data as RDF/XML using content negotiation (see Introduction ). The Gravsearch query's result may look like this ( RDF/XML ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:knora-api=\"http://api.knora.org/ontology/knora-api/v2#\" xmlns:beol=\"http://0.0.0.0:3333/ontology/0801/beol/v2#\"> <beol:letter rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA\"> <beol:creationDate rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\"/> <beol:hasAuthorValue rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\"/> <beol:hasRecipientValue rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Testletter</rdfs:label> </beol:letter> <knora-api:DateValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\"> <knora-api:dateValueHasCalendar rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">GREGORIAN</knora-api:dateValueHasCalendar> <knora-api:dateValueHasEndDay rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">10</knora-api:dateValueHasEndDay> <knora-api:dateValueHasEndEra rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">CE</knora-api:dateValueHasEndEra> <knora-api:dateValueHasEndMonth rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">6</knora-api:dateValueHasEndMonth> <knora-api:dateValueHasEndYear rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">1703</knora-api:dateValueHasEndYear> <knora-api:dateValueHasStartDay rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">10</knora-api:dateValueHasStartDay> <knora-api:dateValueHasStartEra rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">CE</knora-api:dateValueHasStartEra> <knora-api:dateValueHasStartMonth rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">6</knora-api:dateValueHasStartMonth> <knora-api:dateValueHasStartYear rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">1703</knora-api:dateValueHasStartYear> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">GREGORIAN:1703-06-10 CE</knora-api:valueAsString> </knora-api:DateValue> <knora-api:LinkValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\"> <knora-api:linkValueHasTarget> <beol:person rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ\"> <beol:hasFamilyName rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\"/> <beol:hasGivenName rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\"/> <beol:hasIAFIdentifier rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Johann Jacob Scheuchzer</rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Scheuchzer</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Johann Jacob</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">(DE-588)118607308</knora-api:valueAsString> </knora-api:TextValue> <knora-api:LinkValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\"> <knora-api:linkValueHasTarget> <beol:person rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw\"> <beol:hasFamilyName rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\"/> <beol:hasGivenName rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\"/> <beol:hasIAFIdentifier rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Jacob Hermann</rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Hermann</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Jacob</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">(DE-588)119112450</knora-api:valueAsString> </knora-api:TextValue> </rdf:RDF> In order to convert the metadata (not the actual standoff markup), a knora-base:knora-base:XSLTransformation has to be provided. For our example, it looks like this (see test_data/test_route/texts/beol/header.xsl ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <xsl:transform xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs1=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:beol=\"http://0.0.0.0:3333/ontology/0801/beol/v2#\" xmlns:knora-api=\"http://api.knora.org/ontology/knora-api/v2#\" exclude-result-prefixes=\"rdf beol knora-api xs rdfs1\" version=\"2.0\"> <xsl:output method=\"xml\" omit-xml-declaration=\"yes\" encoding=\"utf-8\" indent=\"yes\"/> <!-- make IAF id a URL --> <xsl:function name=\"knora-api:iaf\" as=\"xs:anyURI\"> <xsl:param name=\"input\" as=\"xs:string\"/> <xsl:value-of select=\"replace($input, '\\(DE-588\\)', 'http://d-nb.info/gnd/')\"/> </xsl:function> <!-- make a standard date (Gregorian calendar assumed) --> <xsl:function name=\"knora-api:dateformat\" as=\"element()*\"> <xsl:param name=\"input\" as=\"element()*\"/> <xsl:choose> <xsl:when test=\"$input/knora-api:dateValueHasStartYear/text() = $input/knora-api:dateValueHasEndYear/text() and $input/knora-api:dateValueHasStartMonth/text() = $input/knora-api:dateValueHasEndMonth/text() and $input/knora-api:dateValueHasStartDay/text() = $input/knora-api:dateValueHasEndDay/text()\"> <!-- no period, day precision --> <date> <xsl:attribute name=\"when\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/> </xsl:attribute> </date> </xsl:when> <xsl:otherwise> <!-- period --> <date> <xsl:attribute name=\"notBefore\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartDay/text(), '00')\"/> </xsl:attribute> <xsl:attribute name=\"notAfter\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndDay/text(), '00')\"/> </xsl:attribute> </date> </xsl:otherwise> </xsl:choose> </xsl:function> <xsl:template match=\"rdf:RDF\"> <xsl:variable name=\"resourceIri\" select=\"beol:letter/@rdf:about\"/> <xsl:variable name=\"label\" select=\"beol:letter/rdfs1:label/text()\"/> <teiHeader> <fileDesc> <titleStmt> <title> <xsl:value-of select=\"$label\"/> </title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of the resource identified by the Iri <xsl:value-of select=\"$resourceIri\"/>. </p> </publicationStmt> <sourceDesc> <p>Representation of the resource's text as TEI/XML</p> </sourceDesc> </fileDesc> <profileDesc> <correspDesc> <xsl:attribute name=\"ref\"> <xsl:value-of select=\"$resourceIri\"/> </xsl:attribute> <xsl:apply-templates/> </correspDesc> </profileDesc> </teiHeader> </xsl:template> <xsl:template match=\"beol:letter/beol:hasAuthorValue\"> <xsl:variable name=\"authorValue\" select=\"@rdf:resource\"/> <xsl:variable name=\"authorIAFValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasIAFIdentifier/@rdf:resource\"/> <xsl:variable name=\"authorFamilyNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasFamilyName/@rdf:resource\"/> <xsl:variable name=\"authorGivenNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasGivenName/@rdf:resource\"/> <correspAction type=\"sent\"> <xsl:variable name=\"authorIAFText\" select=\"//knora-api:TextValue[@rdf:about=$authorIAFValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"authorFamilyNameText\" select=\"//knora-api:TextValue[@rdf:about=$authorFamilyNameValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"authorGivenNameText\" select=\"//knora-api:TextValue[@rdf:about=$authorGivenNameValue]/knora-api:valueAsString/text()\"/> <persName> <xsl:attribute name=\"ref\"><xsl:value-of select=\"knora-api:iaf($authorIAFText)\" /></xsl:attribute> <xsl:value-of select=\"$authorFamilyNameText\"/>, <xsl:value-of select=\"$authorGivenNameText\"/> </persName> <xsl:variable name=\"dateValue\" select=\"//beol:creationDate/@rdf:resource\"/> <xsl:variable name=\"dateObj\" select=\"//knora-api:DateValue[@rdf:about=$dateValue]\"/> <xsl:copy-of select=\"knora-api:dateformat($dateObj)\"/> </correspAction> </xsl:template> <xsl:template match=\"beol:letter/beol:hasRecipientValue\"> <xsl:variable name=\"recipientValue\" select=\"@rdf:resource\"/> <xsl:variable name=\"recipientIAFValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasIAFIdentifier/@rdf:resource\"/> <xsl:variable name=\"recipientFamilyNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasFamilyName/@rdf:resource\"/> <xsl:variable name=\"recipientGivenNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasGivenName/@rdf:resource\"/> <correspAction type=\"received\"> <xsl:variable name=\"recipientIAFText\" select=\"//knora-api:TextValue[@rdf:about=$recipientIAFValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"recipientFamilyNameText\" select=\"//knora-api:TextValue[@rdf:about=$recipientFamilyNameValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"recipientGivenNameText\" select=\"//knora-api:TextValue[@rdf:about=$recipientGivenNameValue]/knora-api:valueAsString/text()\"/> <persName> <xsl:attribute name=\"ref\"><xsl:value-of select=\"knora-api:iaf($recipientIAFText)\" /></xsl:attribute> <xsl:value-of select=\"$recipientFamilyNameText\"/>, <xsl:value-of select=\"$recipientGivenNameText\"/> </persName> </correspAction> </xsl:template> <!-- ignore text if there is no template for the element containing it --> <xsl:template match=\"text()\"> </xsl:template> </xsl:transform> You can use the functions knora-api:iaf and knora-api:dateformat in your own XSLT in case you want to support correspSearch . The complete request looks like this: HTTP GET request to http://host/v2/tei/resourceIri&textProperty=textPropertyIri&mappingIri=mappingIri&gravsearchTemplateIri=gravsearchTemplateIri&teiHeaderXSLTIri=teiHeaderXSLTIri See webapi/src/it/scala/org/knora/webapi/e2e/v1/KnoraSipiIntegrationV1ITSpec.scala for a complete test case involving the sample data (\"create a mapping for standoff conversion to TEI referring to an XSLT and also create a Gravsearch template and an XSLT for transforming TEI header data\"). When you provide a custom conversion, it is up to you to ensure the validity of the TEI document. You can use this service to validate: TEI by example validator . Problems and bugs caused by XSL transformations are out of scope of the responsibility of the Knora software.","title":"TEI/XML"},{"location":"DSP-API/03-apis/api-v2/tei-xml/#teixml-converting-standoff-to-teixml","text":"","title":"TEI/XML: Converting Standoff to TEI/XML"},{"location":"DSP-API/03-apis/api-v2/tei-xml/#general","text":"Knora offers a way to convert standoff markup to TEI/XML. The conversion is based on the assumption that a whole resource is to be turned into a TEI document. There is a basic distinction between the body and the header of a TEI document. The resource's property that contains the text with standoff markup is mapped to the TEI document's body. Other of the resource's property may be mapped to the TEI header.","title":"General"},{"location":"DSP-API/03-apis/api-v2/tei-xml/#standard-standoff-to-tei-conversion","text":"Knora offers a built-in conversion form standard standoff entities (defined in the standoff ontology) tags to TEI. In order to obtain a resource as a TEI document, the following request has to be performed. Please note that the URL parameters have to be URL-encoded. HTTP GET to http://host/v2/tei/resourceIri?textProperty=textPropertyIri In addition to the resource's Iri, the Iri of the property containing the text with standoff has to be submitted. This will be converted to the TEI body. Please note that the resource can only have one instance of this property and the text must have standoff markup. The Knora test data contain the resource http://rdfh.ch/0001/thing_with_richtext_with_markup with the text property http://0.0.0.0:3333/ontology/0001/anything/v2#hasRichtext that can be converted to TEI as follows: HTTP GET to http://host/v2/tei/http%3A%2F%2Frdfh.ch%2F0001%2Fthing_with_richtext_with_markup?textProperty=http%3A%2F%2F0.0.0.0%3A3333%2Fontology%2F0001%2Fanything%2Fv2%23hasRichtext The answer to this request is a TEI XML document: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" version=\"3.3.0\"> <teiHeader> <fileDesc> <titleStmt> <title>test thing with markup</title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of a resource identified by the Iri http://rdfh.ch/0001/thing_with_richtext_with_markup. </p> </publicationStmt> <sourceDesc> <p>Representation of the resource's text as TEI/XML</p> </sourceDesc> </fileDesc> </teiHeader> <text> <body> <p>This is a test that contains marked up elements. This is <hi rend=\"italic\">interesting text</hi> in italics. This is <hi rend=\"italic\">boring text</hi> in italics.</p> </body> </text> </TEI> The body of the TEI document contains the standoff markup as XML. The header contains contains some basic metadata about the resource such as the rdfs:label an its IRI. However, this might not be sufficient for more advanced use cases like digital edition projects. In that case, a custom conversion has to be performed (see below).","title":"Standard Standoff to TEI Conversion"},{"location":"DSP-API/03-apis/api-v2/tei-xml/#custom-conversion","text":"If a project defines its own standoff entities, a custom conversion can be provided (body of the TEI document). Also for the TEI header, a custom conversion can be provided. For the custom conversion, additional configuration is required. TEI body: additional mapping from standoff to XML (URL parameter mappingIri ) XSL transformation to turn the XML into a valid TEI body (referred to by the mapping). The mapping has to refer to a defaultXSLTransformation that transforms the XML that was created from standoff markup (see XML To Standoff Mapping in API v1 ). This step is necessary because the mapping assumes a one to one relation between standoff classes and properties and XML elements and attributes. For example, we may want to convert a standoff:StandoffItalicTag into TEI/XML. TEI expresses this as <hi rend=\"italic\">...</hi> . In the mapping, the standoff:StandoffItalicTag may be mapped to a a temporary XML element that is going to be converted to <hi rend=\"italic\">...</hi> in a further step by the XSLT. For sample data, see webapi/_test_data/test_route/texts/beol/BEOLTEIMapping.xml (mapping) and webapi/_test_data/test_route/texts/beol/standoffToTEI.xsl . The standoff entities are defined in beol-onto.ttl . TEI header: Gravsearch template to query the resources metadata, results are serialized to RDF/XML (URL parameter gravsearchTemplateIri ) XSL transformation to turn that RDF/XML into a valid TEI header (URL parameter teiHeaderXSLTIri ) The Gravsearch template is expected to be of type knora-base:TextRepresentation and to contain a placeholder $resourceIri that is to be replaced by the actual resource Iri. The Gravsearch template is expected to contain a query involving the text property (URL parameter textProperty ) and more properties that are going to be mapped to the TEI header. The Gravsearch template is a simple text file with the files extension .txt . A Gravsearch template may look like this (see test_data/test_route/texts/beol/gravsearch.txt ): PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:creationDate ?date . ?letter beol:hasText ?text . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?letter beol:hasRecipient ?person2 . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . } WHERE { BIND(<$resourceIri> as ?letter) ?letter a knora-api:Resource . ?letter a beol:letter . ?letter beol:creationDate ?date . beol:creationDate knora-api:objectType knora-api:Date . ?date a knora-api:Date . ?letter beol:hasText ?text . beol:hasText knora-api:objectType xsd:string . ?text a xsd:string . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?name1 a xsd:string . ?givenName1 a xsd:string . ?iaf1 a xsd:string . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . ?name2 a xsd:string . ?givenName2 a xsd:string . ?iaf2 a xsd:string . beol:hasGivenName knora-api:objectType xsd:string . beol:hasFamilyName knora-api:objectType xsd:string . beol:hasIAFIdentifier knora-api:objectType xsd:string . beol:hasAuthor knora-api:objectType knora-api:Resource . ?letter beol:hasRecipient ?person2 . beol:hasRecipient knora-api:objectType knora-api:Resource . ?person1 a knora-api:Resource . ?person2 a knora-api:Resource . } Note the placeholder BIND(<$resourceIri> as ?letter) that is going to be replaced by the Iri of the resource the request is performed for. The query asks for information about the letter's text beol:hasText and information about its author and recipient. This information is converted to the TEI header in the format required by correspSearch . To write the XSLT, do the Gravsearch query and request the data as RDF/XML using content negotiation (see Introduction ). The Gravsearch query's result may look like this ( RDF/XML ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:knora-api=\"http://api.knora.org/ontology/knora-api/v2#\" xmlns:beol=\"http://0.0.0.0:3333/ontology/0801/beol/v2#\"> <beol:letter rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA\"> <beol:creationDate rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\"/> <beol:hasAuthorValue rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\"/> <beol:hasRecipientValue rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Testletter</rdfs:label> </beol:letter> <knora-api:DateValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\"> <knora-api:dateValueHasCalendar rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">GREGORIAN</knora-api:dateValueHasCalendar> <knora-api:dateValueHasEndDay rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">10</knora-api:dateValueHasEndDay> <knora-api:dateValueHasEndEra rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">CE</knora-api:dateValueHasEndEra> <knora-api:dateValueHasEndMonth rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">6</knora-api:dateValueHasEndMonth> <knora-api:dateValueHasEndYear rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">1703</knora-api:dateValueHasEndYear> <knora-api:dateValueHasStartDay rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">10</knora-api:dateValueHasStartDay> <knora-api:dateValueHasStartEra rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">CE</knora-api:dateValueHasStartEra> <knora-api:dateValueHasStartMonth rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">6</knora-api:dateValueHasStartMonth> <knora-api:dateValueHasStartYear rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">1703</knora-api:dateValueHasStartYear> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">GREGORIAN:1703-06-10 CE</knora-api:valueAsString> </knora-api:DateValue> <knora-api:LinkValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\"> <knora-api:linkValueHasTarget> <beol:person rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ\"> <beol:hasFamilyName rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\"/> <beol:hasGivenName rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\"/> <beol:hasIAFIdentifier rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Johann Jacob Scheuchzer</rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Scheuchzer</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Johann Jacob</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">(DE-588)118607308</knora-api:valueAsString> </knora-api:TextValue> <knora-api:LinkValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\"> <knora-api:linkValueHasTarget> <beol:person rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw\"> <beol:hasFamilyName rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\"/> <beol:hasGivenName rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\"/> <beol:hasIAFIdentifier rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Jacob Hermann</rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Hermann</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Jacob</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">(DE-588)119112450</knora-api:valueAsString> </knora-api:TextValue> </rdf:RDF> In order to convert the metadata (not the actual standoff markup), a knora-base:knora-base:XSLTransformation has to be provided. For our example, it looks like this (see test_data/test_route/texts/beol/header.xsl ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <xsl:transform xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs1=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:beol=\"http://0.0.0.0:3333/ontology/0801/beol/v2#\" xmlns:knora-api=\"http://api.knora.org/ontology/knora-api/v2#\" exclude-result-prefixes=\"rdf beol knora-api xs rdfs1\" version=\"2.0\"> <xsl:output method=\"xml\" omit-xml-declaration=\"yes\" encoding=\"utf-8\" indent=\"yes\"/> <!-- make IAF id a URL --> <xsl:function name=\"knora-api:iaf\" as=\"xs:anyURI\"> <xsl:param name=\"input\" as=\"xs:string\"/> <xsl:value-of select=\"replace($input, '\\(DE-588\\)', 'http://d-nb.info/gnd/')\"/> </xsl:function> <!-- make a standard date (Gregorian calendar assumed) --> <xsl:function name=\"knora-api:dateformat\" as=\"element()*\"> <xsl:param name=\"input\" as=\"element()*\"/> <xsl:choose> <xsl:when test=\"$input/knora-api:dateValueHasStartYear/text() = $input/knora-api:dateValueHasEndYear/text() and $input/knora-api:dateValueHasStartMonth/text() = $input/knora-api:dateValueHasEndMonth/text() and $input/knora-api:dateValueHasStartDay/text() = $input/knora-api:dateValueHasEndDay/text()\"> <!-- no period, day precision --> <date> <xsl:attribute name=\"when\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/> </xsl:attribute> </date> </xsl:when> <xsl:otherwise> <!-- period --> <date> <xsl:attribute name=\"notBefore\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartDay/text(), '00')\"/> </xsl:attribute> <xsl:attribute name=\"notAfter\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndDay/text(), '00')\"/> </xsl:attribute> </date> </xsl:otherwise> </xsl:choose> </xsl:function> <xsl:template match=\"rdf:RDF\"> <xsl:variable name=\"resourceIri\" select=\"beol:letter/@rdf:about\"/> <xsl:variable name=\"label\" select=\"beol:letter/rdfs1:label/text()\"/> <teiHeader> <fileDesc> <titleStmt> <title> <xsl:value-of select=\"$label\"/> </title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of the resource identified by the Iri <xsl:value-of select=\"$resourceIri\"/>. </p> </publicationStmt> <sourceDesc> <p>Representation of the resource's text as TEI/XML</p> </sourceDesc> </fileDesc> <profileDesc> <correspDesc> <xsl:attribute name=\"ref\"> <xsl:value-of select=\"$resourceIri\"/> </xsl:attribute> <xsl:apply-templates/> </correspDesc> </profileDesc> </teiHeader> </xsl:template> <xsl:template match=\"beol:letter/beol:hasAuthorValue\"> <xsl:variable name=\"authorValue\" select=\"@rdf:resource\"/> <xsl:variable name=\"authorIAFValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasIAFIdentifier/@rdf:resource\"/> <xsl:variable name=\"authorFamilyNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasFamilyName/@rdf:resource\"/> <xsl:variable name=\"authorGivenNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasGivenName/@rdf:resource\"/> <correspAction type=\"sent\"> <xsl:variable name=\"authorIAFText\" select=\"//knora-api:TextValue[@rdf:about=$authorIAFValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"authorFamilyNameText\" select=\"//knora-api:TextValue[@rdf:about=$authorFamilyNameValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"authorGivenNameText\" select=\"//knora-api:TextValue[@rdf:about=$authorGivenNameValue]/knora-api:valueAsString/text()\"/> <persName> <xsl:attribute name=\"ref\"><xsl:value-of select=\"knora-api:iaf($authorIAFText)\" /></xsl:attribute> <xsl:value-of select=\"$authorFamilyNameText\"/>, <xsl:value-of select=\"$authorGivenNameText\"/> </persName> <xsl:variable name=\"dateValue\" select=\"//beol:creationDate/@rdf:resource\"/> <xsl:variable name=\"dateObj\" select=\"//knora-api:DateValue[@rdf:about=$dateValue]\"/> <xsl:copy-of select=\"knora-api:dateformat($dateObj)\"/> </correspAction> </xsl:template> <xsl:template match=\"beol:letter/beol:hasRecipientValue\"> <xsl:variable name=\"recipientValue\" select=\"@rdf:resource\"/> <xsl:variable name=\"recipientIAFValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasIAFIdentifier/@rdf:resource\"/> <xsl:variable name=\"recipientFamilyNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasFamilyName/@rdf:resource\"/> <xsl:variable name=\"recipientGivenNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasGivenName/@rdf:resource\"/> <correspAction type=\"received\"> <xsl:variable name=\"recipientIAFText\" select=\"//knora-api:TextValue[@rdf:about=$recipientIAFValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"recipientFamilyNameText\" select=\"//knora-api:TextValue[@rdf:about=$recipientFamilyNameValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"recipientGivenNameText\" select=\"//knora-api:TextValue[@rdf:about=$recipientGivenNameValue]/knora-api:valueAsString/text()\"/> <persName> <xsl:attribute name=\"ref\"><xsl:value-of select=\"knora-api:iaf($recipientIAFText)\" /></xsl:attribute> <xsl:value-of select=\"$recipientFamilyNameText\"/>, <xsl:value-of select=\"$recipientGivenNameText\"/> </persName> </correspAction> </xsl:template> <!-- ignore text if there is no template for the element containing it --> <xsl:template match=\"text()\"> </xsl:template> </xsl:transform> You can use the functions knora-api:iaf and knora-api:dateformat in your own XSLT in case you want to support correspSearch . The complete request looks like this: HTTP GET request to http://host/v2/tei/resourceIri&textProperty=textPropertyIri&mappingIri=mappingIri&gravsearchTemplateIri=gravsearchTemplateIri&teiHeaderXSLTIri=teiHeaderXSLTIri See webapi/src/it/scala/org/knora/webapi/e2e/v1/KnoraSipiIntegrationV1ITSpec.scala for a complete test case involving the sample data (\"create a mapping for standoff conversion to TEI referring to an XSLT and also create a Gravsearch template and an XSLT for transforming TEI header data\"). When you provide a custom conversion, it is up to you to ensure the validity of the TEI document. You can use this service to validate: TEI by example validator . Problems and bugs caused by XSL transformations are out of scope of the responsibility of the Knora software.","title":"Custom Conversion"},{"location":"DSP-API/03-apis/api-v2/xml-to-standoff-mapping/","text":"XML to Standoff Mapping in API v2 General Information Please see v1 documentation for general information about the XML to standoff mapping: XML To Standoff Mapping in API v1 . Validating a Mapping and sending it to Knora A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v2/mapping The multipart request consists of two named parts: \"json\": { \"knora-api:mappingHasName\": \"My Mapping\", \"knora-api:attachedToProject\": \"projectIRI\", \"rdfs:label\": \"MappingNameSegment\", \"@context\": { \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the knora-api:mappingHasName submitted in the JSON-LD (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the v2 typescript interfaces AddMappingRequest and AddMappingResponse in module MappingFormats","title":"XML to Standoff Mapping"},{"location":"DSP-API/03-apis/api-v2/xml-to-standoff-mapping/#xml-to-standoff-mapping-in-api-v2","text":"","title":"XML to Standoff Mapping in API v2"},{"location":"DSP-API/03-apis/api-v2/xml-to-standoff-mapping/#general-information","text":"Please see v1 documentation for general information about the XML to standoff mapping: XML To Standoff Mapping in API v1 .","title":"General Information"},{"location":"DSP-API/03-apis/api-v2/xml-to-standoff-mapping/#validating-a-mapping-and-sending-it-to-knora","text":"A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v2/mapping The multipart request consists of two named parts: \"json\": { \"knora-api:mappingHasName\": \"My Mapping\", \"knora-api:attachedToProject\": \"projectIRI\", \"rdfs:label\": \"MappingNameSegment\", \"@context\": { \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the knora-api:mappingHasName submitted in the JSON-LD (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the v2 typescript interfaces AddMappingRequest and AddMappingResponse in module MappingFormats","title":"Validating a Mapping and sending it to Knora"},{"location":"DSP-API/04-publishing-deployment/","text":"Deploying DSP-API Publishing Getting Started with DSP-API Configuration Updating Repositories When Upgrading DSP-API","title":"Index"},{"location":"DSP-API/04-publishing-deployment/#deploying-dsp-api","text":"Publishing Getting Started with DSP-API Configuration Updating Repositories When Upgrading DSP-API","title":"Deploying DSP-API"},{"location":"DSP-API/04-publishing-deployment/configuration/","text":"Configuration All configuration for Knora is done in application.conf . Besides the Knora application specific configuration, there we can also find configuration for the underlying Akka library. For optimal performance it is important to tune the configuration to the hardware used, mainly to the number of CPUs and cores per CPU. The relevant sections for tuning are: akka.actor.deployment knora-actor-dispatcher knora-blocking-dispatcher System Environment Variables A number of core settings is additionally configurable through system environment variables. These are: key in application.conf environment variable default value akka.log-config-on-start KNORA_AKKA_LOG_CONFIG_ON_START off akka.loglevel KNORA_AKKA_LOGLEVEL INFO akka.actor.deployment.httpTriplestoreRouter.nr-of-instances KNORA_WEBAPI_DB_CONNECTIONS 2 akka.stdout-loglevel KNORA_AKKA_STDOUT_LOGLEVEL INFO app.print-extended-config KNORA_WEBAPI_PRINT_EXTENDED_CONFIG false app.bcrypt-password-strength KNORA_WEBAPI_BCRYPT_PASSWORD_STRENGTH 12 app.jwt-secret-key KNORA_WEBAPI_JWT_SECRET_KEY super-secret-key app.jwt-longevity KNORA_WEBAPI_JWT_LONGEVITY 30 days app.cookie-domain KNORA_WEBAPI_COOKIE_DOMAIN localhost app.allow-reload-over-http KNORA_WEBAPI_ALLOW_RELOAD_OVER_HTTP false app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.knora-api.internal-host KNORA_WEBAPI_KNORA_API_INTERNAL_HOST 0.0.0.0 app.knora-api.internal-port KNORA_WEBAPI_KNORA_API_INTERNAL_PORT 3333 app.knora-api.external-protocol KNORA_WEBAPI_KNORA_API_EXTERNAL_PROTOCOL http app.knora-api.external-host KNORA_WEBAPI_KNORA_API_EXTERNAL_HOST 0.0.0.0 app.knora-api.external-port KNORA_WEBAPI_KNORA_API_EXTERNAL_PORT 3333 app.sipi.internal-protocol KNORA_WEBAPI_SIPI_INTERNAL_PROTOCOL http app.sipi.internal-host KNORA_WEBAPI_SIPI_INTERNAL_HOST localhost app.sipi.internal-port KNORA_WEBAPI_SIPI_INTERNAL_PORT 1024 app.sipi.external-protocol KNORA_WEBAPI_SIPI_EXTERNAL_PROTOCOL http app.sipi.external-host KNORA_WEBAPI_SIPI_EXTERNAL_HOST localhost app.sipi.external-port KNORA_WEBAPI_SIPI_EXTERNAL_PORT 443 app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.salsah1.base-url KNORA_WEBAPI_SALSAH1_BASE_URL http://localhost:3335 app.triplestore.dbtype KNORA_WEBAPI_TRIPLESTORE_DBTYPE fuseki app.triplestore.use-https KNORA_WEBAPI_TRIPLESTORE_USE_HTTPS false app.triplestore.host KNORA_WEBAPI_TRIPLESTORE_HOST localhost app.triplestore.auto-init KNORA_WEBAPI_TRIPLESTORE_AUTOINIT false app.triplestore.graphdb.port KNORA_WEBAPI_TRIPLESTORE_GRAPHDB_PORT 7200 app.triplestore.graphdb.repository-name KNORA_WEBAPI_TRIPLESTORE_GRAPHDB_REPOSITORY_NAME knora-test app.triplestore.graphdb.username KNORA_WEBAPI_TRIPLESTORE_GRAPHDB_USERNAME admin app.triplestore.graphdb.password KNORA_WEBAPI_TRIPLESTORE_GRAPHDB_PASSWORD root app.triplestore.fuseki.port KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PORT 3030 app.triplestore.fuseki.repository-name KNORA_WEBAPI_TRIPLESTORE_FUSEKI_REPOSITORY_NAME knora-test app.triplestore.fuseki.username KNORA_WEBAPI_TRIPLESTORE_FUSEKI_USERNAME admin app.triplestore.fuseki.password KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PASSWORD test app.cache-service.enabled KNORA_WEBAPI_CACHE_SERVICE_ENABLED true app.cache-service.redis.host KNORA_WEBAPI_CACHE_SERVICE_REDIS_HOST localhost app.cache-service.redis.port KNORA_WEBAPI_CACHE_SERVICE_REDIS_PORT 6379 Selectively Disabling Routes In application.conf the setting app.routes-to-reject contains a list of strings, representing routes which should be rejected. For Example, the string \"v1/users\" would lead to rejection of any route which contains this string. Startup Flags There is a number of flags that can be set on startup, they will override any value set in the application configuration file: loadDemoData , --loadDemoData , -d : Loads the demo data. allowReloadOverHTTP , --allow-reload-over-http , -r : Allows reloading of data over HTTP. -c : Print the configuration at startup. --help : Shows the help message with all startup flags.","title":"Configuration"},{"location":"DSP-API/04-publishing-deployment/configuration/#configuration","text":"All configuration for Knora is done in application.conf . Besides the Knora application specific configuration, there we can also find configuration for the underlying Akka library. For optimal performance it is important to tune the configuration to the hardware used, mainly to the number of CPUs and cores per CPU. The relevant sections for tuning are: akka.actor.deployment knora-actor-dispatcher knora-blocking-dispatcher","title":"Configuration"},{"location":"DSP-API/04-publishing-deployment/configuration/#system-environment-variables","text":"A number of core settings is additionally configurable through system environment variables. These are: key in application.conf environment variable default value akka.log-config-on-start KNORA_AKKA_LOG_CONFIG_ON_START off akka.loglevel KNORA_AKKA_LOGLEVEL INFO akka.actor.deployment.httpTriplestoreRouter.nr-of-instances KNORA_WEBAPI_DB_CONNECTIONS 2 akka.stdout-loglevel KNORA_AKKA_STDOUT_LOGLEVEL INFO app.print-extended-config KNORA_WEBAPI_PRINT_EXTENDED_CONFIG false app.bcrypt-password-strength KNORA_WEBAPI_BCRYPT_PASSWORD_STRENGTH 12 app.jwt-secret-key KNORA_WEBAPI_JWT_SECRET_KEY super-secret-key app.jwt-longevity KNORA_WEBAPI_JWT_LONGEVITY 30 days app.cookie-domain KNORA_WEBAPI_COOKIE_DOMAIN localhost app.allow-reload-over-http KNORA_WEBAPI_ALLOW_RELOAD_OVER_HTTP false app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.knora-api.internal-host KNORA_WEBAPI_KNORA_API_INTERNAL_HOST 0.0.0.0 app.knora-api.internal-port KNORA_WEBAPI_KNORA_API_INTERNAL_PORT 3333 app.knora-api.external-protocol KNORA_WEBAPI_KNORA_API_EXTERNAL_PROTOCOL http app.knora-api.external-host KNORA_WEBAPI_KNORA_API_EXTERNAL_HOST 0.0.0.0 app.knora-api.external-port KNORA_WEBAPI_KNORA_API_EXTERNAL_PORT 3333 app.sipi.internal-protocol KNORA_WEBAPI_SIPI_INTERNAL_PROTOCOL http app.sipi.internal-host KNORA_WEBAPI_SIPI_INTERNAL_HOST localhost app.sipi.internal-port KNORA_WEBAPI_SIPI_INTERNAL_PORT 1024 app.sipi.external-protocol KNORA_WEBAPI_SIPI_EXTERNAL_PROTOCOL http app.sipi.external-host KNORA_WEBAPI_SIPI_EXTERNAL_HOST localhost app.sipi.external-port KNORA_WEBAPI_SIPI_EXTERNAL_PORT 443 app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.salsah1.base-url KNORA_WEBAPI_SALSAH1_BASE_URL http://localhost:3335 app.triplestore.dbtype KNORA_WEBAPI_TRIPLESTORE_DBTYPE fuseki app.triplestore.use-https KNORA_WEBAPI_TRIPLESTORE_USE_HTTPS false app.triplestore.host KNORA_WEBAPI_TRIPLESTORE_HOST localhost app.triplestore.auto-init KNORA_WEBAPI_TRIPLESTORE_AUTOINIT false app.triplestore.graphdb.port KNORA_WEBAPI_TRIPLESTORE_GRAPHDB_PORT 7200 app.triplestore.graphdb.repository-name KNORA_WEBAPI_TRIPLESTORE_GRAPHDB_REPOSITORY_NAME knora-test app.triplestore.graphdb.username KNORA_WEBAPI_TRIPLESTORE_GRAPHDB_USERNAME admin app.triplestore.graphdb.password KNORA_WEBAPI_TRIPLESTORE_GRAPHDB_PASSWORD root app.triplestore.fuseki.port KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PORT 3030 app.triplestore.fuseki.repository-name KNORA_WEBAPI_TRIPLESTORE_FUSEKI_REPOSITORY_NAME knora-test app.triplestore.fuseki.username KNORA_WEBAPI_TRIPLESTORE_FUSEKI_USERNAME admin app.triplestore.fuseki.password KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PASSWORD test app.cache-service.enabled KNORA_WEBAPI_CACHE_SERVICE_ENABLED true app.cache-service.redis.host KNORA_WEBAPI_CACHE_SERVICE_REDIS_HOST localhost app.cache-service.redis.port KNORA_WEBAPI_CACHE_SERVICE_REDIS_PORT 6379","title":"System Environment Variables"},{"location":"DSP-API/04-publishing-deployment/configuration/#selectively-disabling-routes","text":"In application.conf the setting app.routes-to-reject contains a list of strings, representing routes which should be rejected. For Example, the string \"v1/users\" would lead to rejection of any route which contains this string.","title":"Selectively Disabling Routes"},{"location":"DSP-API/04-publishing-deployment/configuration/#startup-flags","text":"There is a number of flags that can be set on startup, they will override any value set in the application configuration file: loadDemoData , --loadDemoData , -d : Loads the demo data. allowReloadOverHTTP , --allow-reload-over-http , -r : Allows reloading of data over HTTP. -c : Print the configuration at startup. --help : Shows the help message with all startup flags.","title":"Startup Flags"},{"location":"DSP-API/04-publishing-deployment/getting-started/","text":"Getting Started with DSP-API Running DSP-API locally or on a server requires Docker , which can be freely downloaded. Please follow the instructions for installing Docker Desktop . Additional software: Apple Xcode git expect sbt java 11 These can be easily installed on macOS using Homebrew : $ brew install git $ brew install expect $ brew install sbt To install Adoptopenjdk Java 11 with Homebrew : $ brew tap AdoptOpenJDK/openjdk $ brew cask install AdoptOpenJDK/openjdk/adoptopenjdk11 To pin the version of Java, please add this environment variable to you startup script (bashrc, etc.): export JAVA_HOME=`/usr/libexec/java_home -v 11` Choosing a Triplestore DSP-API requires a standards-compliant RDF triplestore. A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Apache Jena Fuseki , an open source triplestore. Built-in support and configuration for a high-performance, proprietary triplestore Ontotext GraphDB is provided but unmaintained (GraphDB must be licensed separately by the user). Other triplestores are planned. Running the DSP-Stack Use git to clone the DSP-API repository from Github . The following environment variables are optional : KNORA_DB_HOME : sets the path to the folder where the triplestore will store the database files KNORA_DB_IMPORT : sets the path to the import directory accessible from inside the docker image $ export KNORA_DB_IMPORT=/path/to/some/folder $ export KNORA_DB_HOME=/path/to/some/other_folder Then from inside the cloned DSP-API repository folder, run: $ make stack-up Creating Repositories and Loading Test Data To create a test repository called knora-test and load test data, run: $ make init-db-test The scripts called by make can be found under webapi/scripts . You can create your own scripts based on these scripts, to create new repositories and optionally to load existing DSP-compliant RDF data into them. If you need to reload the test data, you need to stop and delete the running Apache Fuseki instance. Make sure you don't delete important data. To stop the instance and delete the repository, run the following command: $ make stack-down-delete-volumes after which you can start the stack again with make stack-up , recreate the repository and load the data with make init-db-test .","title":"Getting Started with DSP-API"},{"location":"DSP-API/04-publishing-deployment/getting-started/#getting-started-with-dsp-api","text":"Running DSP-API locally or on a server requires Docker , which can be freely downloaded. Please follow the instructions for installing Docker Desktop . Additional software: Apple Xcode git expect sbt java 11 These can be easily installed on macOS using Homebrew : $ brew install git $ brew install expect $ brew install sbt To install Adoptopenjdk Java 11 with Homebrew : $ brew tap AdoptOpenJDK/openjdk $ brew cask install AdoptOpenJDK/openjdk/adoptopenjdk11 To pin the version of Java, please add this environment variable to you startup script (bashrc, etc.): export JAVA_HOME=`/usr/libexec/java_home -v 11`","title":"Getting Started with DSP-API"},{"location":"DSP-API/04-publishing-deployment/getting-started/#choosing-a-triplestore","text":"DSP-API requires a standards-compliant RDF triplestore. A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Apache Jena Fuseki , an open source triplestore. Built-in support and configuration for a high-performance, proprietary triplestore Ontotext GraphDB is provided but unmaintained (GraphDB must be licensed separately by the user). Other triplestores are planned.","title":"Choosing a Triplestore"},{"location":"DSP-API/04-publishing-deployment/getting-started/#running-the-dsp-stack","text":"Use git to clone the DSP-API repository from Github . The following environment variables are optional : KNORA_DB_HOME : sets the path to the folder where the triplestore will store the database files KNORA_DB_IMPORT : sets the path to the import directory accessible from inside the docker image $ export KNORA_DB_IMPORT=/path/to/some/folder $ export KNORA_DB_HOME=/path/to/some/other_folder Then from inside the cloned DSP-API repository folder, run: $ make stack-up","title":"Running the DSP-Stack"},{"location":"DSP-API/04-publishing-deployment/getting-started/#creating-repositories-and-loading-test-data","text":"To create a test repository called knora-test and load test data, run: $ make init-db-test The scripts called by make can be found under webapi/scripts . You can create your own scripts based on these scripts, to create new repositories and optionally to load existing DSP-compliant RDF data into them. If you need to reload the test data, you need to stop and delete the running Apache Fuseki instance. Make sure you don't delete important data. To stop the instance and delete the repository, run the following command: $ make stack-down-delete-volumes after which you can start the stack again with make stack-up , recreate the repository and load the data with make init-db-test .","title":"Creating Repositories and Loading Test Data"},{"location":"DSP-API/04-publishing-deployment/publishing/","text":"Publishing Knora is published as a set of Docker images under the DaSCH Basel Dockerhub Organization . The following Docker images are published: Knora-API: https://hub.docker.com/r/daschswiss/knora-api Jena Fuseki: https://hub.docker.com/r/daschswiss/knora-jena-fuseki Sipi (includes Knora's Sipi scripts): https://hub.docker.com/r/daschswiss/knora-sipi Salsah 1: https://hub.docker.com/r/daschswiss/knora-salsah1 Salsah 2: https://hub.docker.com/r/daschswiss/knora-app-web Knora's Docker images are published automatically through Github CI each time a pull-request is merged into the main branch. Each image is tagged with a version number, where the version is derived by using the result of git describe . The describe version is built from the last tag + number of commits since tag + short hash , e.g., 8.0.0-7-ga7827e9 . The images can be published locally by running: $ make docker-build or to Dockerhub: $ make docker-publish","title":"Publishing"},{"location":"DSP-API/04-publishing-deployment/publishing/#publishing","text":"Knora is published as a set of Docker images under the DaSCH Basel Dockerhub Organization . The following Docker images are published: Knora-API: https://hub.docker.com/r/daschswiss/knora-api Jena Fuseki: https://hub.docker.com/r/daschswiss/knora-jena-fuseki Sipi (includes Knora's Sipi scripts): https://hub.docker.com/r/daschswiss/knora-sipi Salsah 1: https://hub.docker.com/r/daschswiss/knora-salsah1 Salsah 2: https://hub.docker.com/r/daschswiss/knora-app-web Knora's Docker images are published automatically through Github CI each time a pull-request is merged into the main branch. Each image is tagged with a version number, where the version is derived by using the result of git describe . The describe version is built from the last tag + number of commits since tag + short hash , e.g., 8.0.0-7-ga7827e9 . The images can be published locally by running: $ make docker-build or to Dockerhub: $ make docker-publish","title":"Publishing"},{"location":"DSP-API/04-publishing-deployment/updates/","text":"Updating Repositories When Upgrading Knora When a new version of Knora introduces changes that are not backwards-compatible with existing data, your repository will need to be updated. Upgrading from Knora Version 7.0.0 or Later In most cases, Knora will update your repository automatically when it starts. If manual changes are needed, these will be described in the release notes, and must be done first. Before starting a new version of Knora, back up your repository, so you can restore it in case the automatic repository update fails. You can use one of these scripts in webapi/scripts : fuseki-dump-repository.sh for Fuseki graphdb-dump-repository.sh for GraphDB For information on command-line options, run the script with no arguments. Upgrading from a Knora Version Before 7.0.0 WARNING : If you do not follow this procedure, your data may be corrupted, and Knora may not work. You must first upgrade to Knora 7.0.0, then upgrade again to the current version. The overall procedure is: Back up your repository as described above. Install Knora release 7.0.0, and read the general instructions in upgrade/graphdb-se/old/README.md in that release. Follow the instructions in one of the subsections below for the version you are upgrading from. Back up your repository again. Install the current release of Knore, and follow any manual update instructions in its release notes. Start Knora to continue the automatic upgrade. Upgrading from Knora 6.0.0 or 6.0.1 Follow the instructions in upgrade/graphdb-se/old/1263-knora-admin/README.md . Follow the instructions in Upgrading from Knora 7.0.0 or Later . Upgrading from Knora 5.0.0 Follow the instructions in upgrade/graphdb-se/old/1211-datetime/README.md . Follow the instructions in upgrade/graphdb-se/old/1230-delete-previews/README.md . Follow the instructions in upgrade/graphdb-se/old/1263-knora-admin/README.md . Follow the instructions in Upgrading from Knora 7.0.0 or Later .","title":"Updating Repositories when Upgrading DSP-API"},{"location":"DSP-API/04-publishing-deployment/updates/#updating-repositories-when-upgrading-knora","text":"When a new version of Knora introduces changes that are not backwards-compatible with existing data, your repository will need to be updated.","title":"Updating Repositories When Upgrading Knora"},{"location":"DSP-API/04-publishing-deployment/updates/#upgrading-from-knora-version-700-or-later","text":"In most cases, Knora will update your repository automatically when it starts. If manual changes are needed, these will be described in the release notes, and must be done first. Before starting a new version of Knora, back up your repository, so you can restore it in case the automatic repository update fails. You can use one of these scripts in webapi/scripts : fuseki-dump-repository.sh for Fuseki graphdb-dump-repository.sh for GraphDB For information on command-line options, run the script with no arguments.","title":"Upgrading from Knora Version 7.0.0 or Later"},{"location":"DSP-API/04-publishing-deployment/updates/#upgrading-from-a-knora-version-before-700","text":"WARNING : If you do not follow this procedure, your data may be corrupted, and Knora may not work. You must first upgrade to Knora 7.0.0, then upgrade again to the current version. The overall procedure is: Back up your repository as described above. Install Knora release 7.0.0, and read the general instructions in upgrade/graphdb-se/old/README.md in that release. Follow the instructions in one of the subsections below for the version you are upgrading from. Back up your repository again. Install the current release of Knore, and follow any manual update instructions in its release notes. Start Knora to continue the automatic upgrade.","title":"Upgrading from a Knora Version Before 7.0.0"},{"location":"DSP-API/04-publishing-deployment/updates/#upgrading-from-knora-600-or-601","text":"Follow the instructions in upgrade/graphdb-se/old/1263-knora-admin/README.md . Follow the instructions in Upgrading from Knora 7.0.0 or Later .","title":"Upgrading from Knora 6.0.0 or 6.0.1"},{"location":"DSP-API/04-publishing-deployment/updates/#upgrading-from-knora-500","text":"Follow the instructions in upgrade/graphdb-se/old/1211-datetime/README.md . Follow the instructions in upgrade/graphdb-se/old/1230-delete-previews/README.md . Follow the instructions in upgrade/graphdb-se/old/1263-knora-admin/README.md . Follow the instructions in Upgrading from Knora 7.0.0 or Later .","title":"Upgrading from Knora 5.0.0"},{"location":"DSP-API/05-internals/design/api-admin/","text":"Admin API Design Administration","title":"Index"},{"location":"DSP-API/05-internals/design/api-admin/#admin-api-design","text":"Administration","title":"Admin API Design"},{"location":"DSP-API/05-internals/design/api-admin/administration/","text":"Administration (Users, Projects, Groups, Institutions, Permissions) Scope This Section includes management (creation, updating, deletion) of Users , Projects , Groups , Institutions , and Permissions . Implementation All administration functions will be implemented as part of the Knora API in the webapi codebase. There is also a separate web-application as part of the salsah codebase using this API, allowing basic management operations. Overview During the initial deployment of a Knora server, the main administration user ( root ) is created. This root user has the right to do anything. Knora\u2019s concept of access control is that permissions can only be granted to groups (or the whole project, i.e. all members of a project) and not to individual users. There are two distinct ways of granting permission. Firstly, an object (a resource or value) can grant permissions to groups of users, and secondly, permissions can be granted directly to a group of users (not bound to a specific object). There are six built-in groups: UnknownUser , KnownUser , Creator , ProjectMember , ProjectAdmin , and SystemAdmin . These groups can be used in the same way as normal user created groups for permission management, i.e. can be used to give certain groups of users, certain permissions, without the need to explicitly create them. A user becomes implicitly a member of such a group by satisfying certain conditions: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:Creator : When checking a user\u2019s permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectMember : When checking a user\u2019s permissions, the user is automatically assigned to this group by being a member of a project designated by the knora-admin:isInProject property. knora-admin:ProjectAdmin : When checking a user's permission, the user is automatically assigned to this group through the knora-admin:isInProjectAdminGroup property, which points to the project in question. knora-admin:SystemAdmin : Membership is received by setting the property knora-admin:isInSystemAdminGroup to true on a knora-admin:User . To use these build-in groups as values for properties (Object Access and Default Permissions), the IRI is constructed by appending the name of the built-in group to knora-admin , e.g., knora-admin:KnownUser where knora-admin corresponds to http://www.knora.org/ontology/knora-admin# . Permissions Up until know, we have mentioned two groups of permissions. The first called object access permissions , which contains permissions that point from explicit objects (resources/values) to groups. The second group of permissions called administrative permissions , and which contains permissions that are put on instances of knora-admin:Permission objects directly affecting groups. There is another, third group of permissions, called default object access permissions which is also put on instances of knora-admin:Permission , and which also directly affect groups. Object Access Permissions An object (resource / value) can grant the following permissions, which are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions : Restricted view permission (RV) : Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) : Allows an unrestricted view of the object. Having view permission on a resource only affects the user\u2019s ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) : For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) : Allows the item to be marked as deleted. Change rights permission (CR) : Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user\u2019s permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember and/or ProjectAdmin if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar (|). For example, if an object grants view permission to unknown and known users , and modify permission to project members , the resulting permission literal would be: : V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember Administrative Permissions The following permissions can be set via instances of knora-admin:AdministrativePermission on any group belonging to a project. For users that are members of a number of groups with administrative permissions attached, the final set of permissions is additive and most permissive. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The following permission values can be used: Resource / Value Creation Permissions: 1) ProjectResourceCreateAllPermission : description: gives the permission to create resources inside the project. usage: used as a value for knora-base:hasPermissions . 2) ProjectResourceCreateRestrictedPermission : description: gives restricted resource creation permission inside the project. usage: used as a value for knora-base:hasPermissions . value: RestrictedProjectResourceCreatePermission followed by a comma-separated list of ResourceClasses the user should only be able to create instances of. Project Administration Permissions: 1) ProjectAdminAllPermission : description: gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ( group info , group membership , resource creation permissions , project administration permissions , and default permissions ). usage: used as a value for knora-base:hasPermissions . 2) ProjectAdminGroupAllPermission : description: gives the user the permission to modify group info and group membership on all groups belonging to the project. usage: used as a value for the knora-base:hasPermissions property. 3) ProjectAdminGroupRestrictedPermission : description: gives the user the permission to modify group info and group membership on certain groups belonging to the project. usage: used as a value for knora-base:hasPermissions value: ProjectGroupAdminRestrictedPermission followed by a comma-separated list of knora-admin:UserGroup . 4) ProjectAdminRightsAllPermission : description: gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). usage: used as a value for the knora-base:hasPermissions property. Ontology Administration Permissions: 1) ProjectAdminOntologyAllPermission : description: gives the user the permission to administer the project ontologies usage: used as a value for the knora-base:hasPermissions property. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the name given above. Each permission is followed by a space, then if applicable, by a comma separated list of IRIs, as defined above. The IRIs of built-in values (e.g., built-in groups, resource classes, etc.) are shortened using the knora-admin prefix knora-admin: . Multiple permissions are separated by a vertical bar (|). For example, if an administrative permission grants the knora-admin:ProjectMember group the permission to create all resources ( ProjectResourceCreateAllPermission ), the resulting administrative permission object with the compact form literal would be: : <http://rdfh.ch/permissions/001 rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Default Object Access Permissions Default Object Access Permissions are used when new objects (resources and/or values) are created. They represent object access permissions with which the new object will be initially outfitted. As with administrative permissions, these default object access permissions can be defined for any number of groups. Additionally, they can be also defined for resource classes and properties. The following default object access permissions can be attached to groups, resource classes and/or properties via instances of knora-admin:DefaultObjectAccessPermission (described further bellow). The default object access permissions correspond to the earlier described object access permission: Default Restricted View Permission (RV) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: RV followed by a comma-separated list of knora-admin:UserGroup Default View Permission (V) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: V followed by a comma-separated list of knora-admin:UserGroup Default Modify Permission (M) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: M followed by a comma-separated list of knora-admin:UserGroup Default Delete Permission (D) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: D followed by a comma-separated list of knora-admin:UserGroup Default Change Rights Permission (CR) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: CR followed by a comma-separated list of knora-admin:UserGroup A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. Example default object access permission instance: <http://rdfh.ch/permissions/002 rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser\"^^xsd:string . This instance is setting default object access permissions to the project member group of a project, giving change right permission to the creator, modify permission to all project members, and view permission to known users. Further, this implicitly applies to all resource classes and all their properties inside the project. Permission Precedence Rules For both administrative permissions and default object access permissions, the resulting permissions are derived by applying precedence rules, for the case that the user is member of more than one group. The following list is sorted by the permission precedence level in descending order: permissions on knora-admin:ProjectAdmin (highest level) permissions on resource classes and property combination (own project) permissions on resource classes and property combination ( knora-admin:SystemProject ) permissions on resource classes / properties (own project) permissions on resource classes / properties ( knora-admin:SystemProject ) permissions on custom groups permissions on knora-admin:ProjectMember permissions on knora-admin:KnownUser (lowest level) The permissions on resource classes / properties are only relevant for default object access permissions. Administrative Permissions : When a user performs an operation requiring administrative permissions, then only the permissions from the highest level are taken into account. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and all are taken into account. Default Object Access Permissions : When a user creates a resource or value, then only the default object permissions from the highest level are applied. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and the most permissive are applied. In the case of users belonging to the SystemAdmin group, but which are not members of a project and thus no group belonging to the project, the default object access permissions from the highest defined level will apply. In the case of users belonging to the SystemAdmin group , but which are not members of a project and thus not members of any group belonging to the project, the default object access permissions from the ProjectAdmin , ProjectMember , or KnownUser group will be applied in the order of precedence. If no permissions are defined on either of these groups, then the resulting permission will be CR knora-admin:Creator . Also, in the case that no default object access permissions are defined for the project, the resulting permission will be CR knora-admin:Creator . Implicit Permissions The knora-admin:SystemAdmin group receives implicitly the following permissions: receives implicitly ProjectAllAdminPermission for all projects. receives implicitly ProjectResourceCreateAllPermission for all projects. receives implicitly CR on all objects from all projects. Theses permissions are baked into the system, and cannot be changed. Permission Templates The permission capabilities of Knora are very large, as it needs to be able to satisfy a broad set of requirements. To simplify permission management for the users, we provide permission templates, which can be used during creation of new projects, or applied to existing projects. A permission template defines a set of administrative and default object access permission. Currently, two different templates will be defined OPEN , CLOSED . Template: OPEN The OPEN template defines the following permissions: The knora-admin:ProjectAdmin group: receives explicitly ProjectResourceCreateAllPermission . receives explicitly ProjectAllAdminPermission . The knora-admin:ProjectMember group: receives explicitly ProjectResourceCreateAllPermission . receives explicitly CR for the knora-admin:Creator and knora-admin:ProjectAdmin group. receives explicitly M for the ProjectMember group. receives explicitly V for the knora-admin:KnownUser group. Template: CLOSED The CLOSED template, defined the following permissions: The knora-admin:ProjectAdmin group: receives explicitly ProjectResourceCreateAllPermission . receives explicitly ProjectAllAdminPermission . The knora-admin:ProjectMember group: receives explicitly ProjectResourceCreateAllPermission . receives explicitly CR for the knora-admin:ProjectAdmin group. receives explicitly M for the ProjectMember group. Default Permissions Matrix for new Projects The access control matrix defines what are the default operations a subject (i.e. User), being a member of a built-in group (represented by row headers), is permitted to perform on an object (represented by column headers). The different operation abbreviations used are defined as follows: C : Create - the subject inside the group is allowed to create the object. U : Update - the subject inside the group is allowed to update the object. R : Read - the subject inside the group is allowed to read all information about the object. D : Delete - the subject inside the group is allowed to delete the object. P : Permission - the subject inside the group is allowed to change the permissions on the object. - : none - none or not applicable Built-In Group Project Group User Resource Value SystemAdmin CRUD CRUDP CRUDP all CRUDP all CRUDP all ProjectAdmin -RUD CRUDP CRUDP +/- project CRUDP (in project) CRUDP (in project) ProjectMember ---- ----- ----- CRUD- (in project) ----- (in project) Creator ---- ----- ----- -RUDP (his resource) ----- (his value) KnownUser C--- C---- CRUD- himself R---- (in project) R---- (in project) Default Permissions Matrix for new Projects Basic Workflows involving Permissions Creating a new Resource Accessing a Resource/Value Project / Group Administration Implementation The requirements for defining default permissions imposed by all the different use cases are very broad. Potentially, we need to be able to define default permissions per project, per group, per resource class, per resource property, and all their possible combinations. For this reason, we introduce the knora-admin:Permission class with two sub-classes, namely knora-admin:AdministrativePermission and knora-admin:DefaultObjectAccessPermission , which instances will carry all the necessary information. Permission Class Hierarchy and Structure The following graphs show the class hierarchy and the structure of each permission class. Permission Class Hierarchy Administrative Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectResourceCreateRestrictedPermission \"<Resource Class IRI>\"| ProjectAdminAllPermission| ProjectAdminGroupAllPermission| ProjectAdminGroupRestrictedPermission \"<http://rdfh.ch/groups/[shortcode]/[UUID]>, <http://rdfh.ch/groups/[shortcode]/[UUID]>\"| ProjectAdminRightsAllPermission| ProjectAdminOntologyAllPermission\"^^xsd:string . Default Object Access Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-admin:forResourceClass \"Resource Class Name\" ; knora-admin:forProperty \"Resource Property Name\" ; knora-base:hasPermissions \"RV <http://rdfh.ch/groups/[shortcode]/[UUID]>| V <http://rdfh.ch/groups/[shortcode]/[UUID]>| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| D <http://rdfh.ch/groups/[shortcode]/[UUID]>| CR <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Querying Permission Instances The properties forProject and either of forGroup , forResourceClass , and forProperty form together a compound key , allowing finding existing permission instances, that address the same set of Project / Group / ResourceClass / Property combination, thus making it possible to extend or change the attached permissions. Administrative Permission Instances : For each group inside the project, there can be zero or one instance holding administrative permission information. Querying is straitforward by using the knora-admin:forProject and knora-admin:forGroup properties as the compound key. Default Object Access Permission Instances : For each group, resource class, or property inside the project, there can be zero or one instances holding default object access permission informations. Querying is straitforward by using the knora-admin:forProject and either knora-admin:forGroup , knora-admin:forResourceClass , or knora-admin:forProperty properties as part of the compound key. Example Data stored in the permissions graph Administrative permissions on a 'ProjectAdmin' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectAdmin ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectAdminAllPermission\"^^xsd:string . Administrative permissions on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Administrative permission restricting project admin permission on a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:Permission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectGroupAdminRestrictedPermission <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Administrative permission restricting resource creation for a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateRestrictedPermission <http://www.knora.org/ontology/00FF/images#Person>\"^^xsd:string . Default object access permission on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| V knora-admin:KnownUser\"^^xsd:string . Default object access permission on a resource class: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a resource property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"D knora-admin:ProjectMember,knora-admin:Creator| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^ . Default object access permission on a resource class and property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a knora-admin property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject knora-admin:SystemProject ; knora-admin:forProperty <http://www.knora.org/ontology/knora-admin#hasStillImageFileValue> ; knora-base:hasPermissions \"RV knora-admin:UnknownUser| V knora-admin:KnownUser| M knora-admin:ProjectMember,knora-admin:Creator\"^^xsd:string . A the time the user's UserProfile is queried, all permissions for all projects and groups the user is a member of are also queried. This information is then stored as an easy accessible object inside the UserProfile , being readily available wherever needed. As this is a somewhat expensive operation, built-in caching mechanism at different levels (e.g., UsersResponder, PermissionsResponder), will be applied. Use Cases UC01: Teaching a Class Description : I'm teaching a class and I have the names and email addresses of all the students. I want to create a project, divide the students into groups (which will only be relevant to this project, e.g. one group for each section of the class), and put some students in each group. I don't want people to be able to join the project or the group by themselves. Solution : The teacher creates different groups and adds users to those groups. Additionally, the teacher can give TA's GroupAdmin privileges, and let the TA's add students to the different groups. UC02: Unibas Librarian Description : I'm a Unibas librarian managing several archiving projects. I need to give everyone at the university permission to view all these projects. I want to create a group called UnibasUser that everyone with a Unibas email address will automatically belong to. Most of the resources in those projects can then grant view permission to UnibasUser . Or perhaps the group will be SwitchUser , for anyone at a Swiss university. Or something even broader. Solution : These can be solved by creating Smart Groups , where the user can define what properties need to be set, so that an user is automatically part of this group. This will be implemented at a later time, as it is not trivial and should also include all special groups (e.g., KnownUser, ProjectMember, ProjectAdmin, etc.) that are currently hard-coded inside the system. UC03: Crowdsourcing Project Description : I'm doing a crowdsourcing project, which involves several different groups that work on different tasks. I'm hoping for thousands of users, and I'd like anyone to be able to join the project and add themselves to any group they want (as long as Knora verifies their email address), without needing approval from me. Solution : This can be solved by allowing self-assignment to a group. UC04: User \"left\" Knora Description : An user who was an active collaborator, decides to \"quit\", and wants to delete his user. Solution : The user's IRI is saved on each value change as part of the versioning mechanism. Exchanging the user's IRI in those places would count as 'rewriting history'. So deleting a user will not be possible, instead the user will be set as not active . Redesign / Questions June 2016 Permissions constrained to groups Why this constraint? This is just the way we are doing it. Makes it a bit simpler. Resource owner permission to disruptive knora-base:attachedToUser gives owner status to the person who created the resource. Proposed change: remove this altogether or make institution/project owner of the resource. Should hiwis be \"owners\" of resources they create on behalf of their professor? If the creator should have max permission, then give it explicitly. Owner will be renamed to creator. We need this for provenance. Does not give any permissions automatically. The permissions depend on what is defined for the project and the creator smart group. Resource creation permission to course being part of a projects gives resource creation permission. What if some project members are not allowed to create new resources (or only certain types; Lumiere Lausanne requirement), but are only allowed to change existing resources? These kind of permissions can be set on groups. A project can have different groups, giving different kind of permissions. Support Default Permissions Allow for a project to define permissions that a newly created resource inside a project should receive (current Salsah behavior) Lumiere Lausanne requirement Will be allowed. Groups Do groups belong to projects, i.e. are they seen as extensions to projects? Does someone need to be part of a project to belong to a group of that project? Every group needs to belong to a project. No GroupAdmins. ProjectAdmins with additional GroupAdmin permissions. root Should the 'root' / SystemAdmin user have 'implicitly' or 'explicitly' all permissions? Has implicitly all permissions. Does the has all permissions also extend to projects? Is the root user going to be part of every project? If yes, then again implicitly or explicitly? Since 'root' / SystemAdmin already has all permissions, doesn't really matter if part of a project or group Ivan's Use Case The system administrator creates the project and sets Ivan as the project administrator. As the project administrator, I have all permissions on all objects (Resources/Values; Project Groups) belonging to the project (knora-base:attachedToProject). Nobody outside of the project should be allowed to see anything that is created as part of Ivan's project. He wants to be able to create two groups: Reviewer , Creator . The Reviewer group should only give read-access to someone inside the group to resources pointing to this group, but allow the creation of annotations. Further, annotations should only be readable by users inside the Reviewer group. The Creator group should give a user create permission and modify permission on the objects the user has created. Any resources created belong to the project. The Creator group is meant for contributors helping out with the project, e.g., Hiwis. Covered Lausanne Projects A project wants to restrict the permissions of newly created resources to a fixed set Covered. Will be able do define 'default permissions' and restrict the creation of new resources to these permissions This means for the current implementation, that any permissions supplied during the resource creation request need to be checked and if needed overriden. Covered. Also in the new design, the backend will need to always check the suplied permissions for newly created resources as we cannot ve sure that the GUI will behave correctly (e.g., many different \"Salsah\" implementations) Restrict creation/access of certain classes of resources to certain groups, e.g., group A is able to create/access resources of class A but not of class B. Covered. Will be able to give a certain group only create permission for specific classes Results Owner renamed to Creator Some permissions are attached to groups (e.g., Add Resource (Class), Modify Ontology, etc.), and some are attached to resources (e.g., this group has read/modify permission, etc.) Ontologien Benutzung einschr\u00e4nken (nur auf bestimmte Gruppen, oder frei zur Verf\u00fcgung) System Admin Rechte implizit Gruppen immer an Projekt gebunden Keine Gruppen-Admins. Soll \u00fcber Rollen vom Projekt-Admin geregelt werden k\u00f6nnen.","title":"Administration"},{"location":"DSP-API/05-internals/design/api-admin/administration/#administration-users-projects-groups-institutions-permissions","text":"","title":"Administration (Users, Projects, Groups, Institutions, Permissions)"},{"location":"DSP-API/05-internals/design/api-admin/administration/#scope","text":"This Section includes management (creation, updating, deletion) of Users , Projects , Groups , Institutions , and Permissions .","title":"Scope"},{"location":"DSP-API/05-internals/design/api-admin/administration/#implementation","text":"All administration functions will be implemented as part of the Knora API in the webapi codebase. There is also a separate web-application as part of the salsah codebase using this API, allowing basic management operations.","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-admin/administration/#overview","text":"During the initial deployment of a Knora server, the main administration user ( root ) is created. This root user has the right to do anything. Knora\u2019s concept of access control is that permissions can only be granted to groups (or the whole project, i.e. all members of a project) and not to individual users. There are two distinct ways of granting permission. Firstly, an object (a resource or value) can grant permissions to groups of users, and secondly, permissions can be granted directly to a group of users (not bound to a specific object). There are six built-in groups: UnknownUser , KnownUser , Creator , ProjectMember , ProjectAdmin , and SystemAdmin . These groups can be used in the same way as normal user created groups for permission management, i.e. can be used to give certain groups of users, certain permissions, without the need to explicitly create them. A user becomes implicitly a member of such a group by satisfying certain conditions: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:Creator : When checking a user\u2019s permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectMember : When checking a user\u2019s permissions, the user is automatically assigned to this group by being a member of a project designated by the knora-admin:isInProject property. knora-admin:ProjectAdmin : When checking a user's permission, the user is automatically assigned to this group through the knora-admin:isInProjectAdminGroup property, which points to the project in question. knora-admin:SystemAdmin : Membership is received by setting the property knora-admin:isInSystemAdminGroup to true on a knora-admin:User . To use these build-in groups as values for properties (Object Access and Default Permissions), the IRI is constructed by appending the name of the built-in group to knora-admin , e.g., knora-admin:KnownUser where knora-admin corresponds to http://www.knora.org/ontology/knora-admin# .","title":"Overview"},{"location":"DSP-API/05-internals/design/api-admin/administration/#permissions","text":"Up until know, we have mentioned two groups of permissions. The first called object access permissions , which contains permissions that point from explicit objects (resources/values) to groups. The second group of permissions called administrative permissions , and which contains permissions that are put on instances of knora-admin:Permission objects directly affecting groups. There is another, third group of permissions, called default object access permissions which is also put on instances of knora-admin:Permission , and which also directly affect groups.","title":"Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#object-access-permissions","text":"An object (resource / value) can grant the following permissions, which are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions : Restricted view permission (RV) : Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) : Allows an unrestricted view of the object. Having view permission on a resource only affects the user\u2019s ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) : For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) : Allows the item to be marked as deleted. Change rights permission (CR) : Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user\u2019s permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember and/or ProjectAdmin if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar (|). For example, if an object grants view permission to unknown and known users , and modify permission to project members , the resulting permission literal would be: : V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember","title":"Object Access Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#administrative-permissions","text":"The following permissions can be set via instances of knora-admin:AdministrativePermission on any group belonging to a project. For users that are members of a number of groups with administrative permissions attached, the final set of permissions is additive and most permissive. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The following permission values can be used: Resource / Value Creation Permissions: 1) ProjectResourceCreateAllPermission : description: gives the permission to create resources inside the project. usage: used as a value for knora-base:hasPermissions . 2) ProjectResourceCreateRestrictedPermission : description: gives restricted resource creation permission inside the project. usage: used as a value for knora-base:hasPermissions . value: RestrictedProjectResourceCreatePermission followed by a comma-separated list of ResourceClasses the user should only be able to create instances of. Project Administration Permissions: 1) ProjectAdminAllPermission : description: gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ( group info , group membership , resource creation permissions , project administration permissions , and default permissions ). usage: used as a value for knora-base:hasPermissions . 2) ProjectAdminGroupAllPermission : description: gives the user the permission to modify group info and group membership on all groups belonging to the project. usage: used as a value for the knora-base:hasPermissions property. 3) ProjectAdminGroupRestrictedPermission : description: gives the user the permission to modify group info and group membership on certain groups belonging to the project. usage: used as a value for knora-base:hasPermissions value: ProjectGroupAdminRestrictedPermission followed by a comma-separated list of knora-admin:UserGroup . 4) ProjectAdminRightsAllPermission : description: gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). usage: used as a value for the knora-base:hasPermissions property. Ontology Administration Permissions: 1) ProjectAdminOntologyAllPermission : description: gives the user the permission to administer the project ontologies usage: used as a value for the knora-base:hasPermissions property. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the name given above. Each permission is followed by a space, then if applicable, by a comma separated list of IRIs, as defined above. The IRIs of built-in values (e.g., built-in groups, resource classes, etc.) are shortened using the knora-admin prefix knora-admin: . Multiple permissions are separated by a vertical bar (|). For example, if an administrative permission grants the knora-admin:ProjectMember group the permission to create all resources ( ProjectResourceCreateAllPermission ), the resulting administrative permission object with the compact form literal would be: : <http://rdfh.ch/permissions/001 rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string .","title":"Administrative Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#default-object-access-permissions","text":"Default Object Access Permissions are used when new objects (resources and/or values) are created. They represent object access permissions with which the new object will be initially outfitted. As with administrative permissions, these default object access permissions can be defined for any number of groups. Additionally, they can be also defined for resource classes and properties. The following default object access permissions can be attached to groups, resource classes and/or properties via instances of knora-admin:DefaultObjectAccessPermission (described further bellow). The default object access permissions correspond to the earlier described object access permission: Default Restricted View Permission (RV) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: RV followed by a comma-separated list of knora-admin:UserGroup Default View Permission (V) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: V followed by a comma-separated list of knora-admin:UserGroup Default Modify Permission (M) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: M followed by a comma-separated list of knora-admin:UserGroup Default Delete Permission (D) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: D followed by a comma-separated list of knora-admin:UserGroup Default Change Rights Permission (CR) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: CR followed by a comma-separated list of knora-admin:UserGroup A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. Example default object access permission instance: <http://rdfh.ch/permissions/002 rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser\"^^xsd:string . This instance is setting default object access permissions to the project member group of a project, giving change right permission to the creator, modify permission to all project members, and view permission to known users. Further, this implicitly applies to all resource classes and all their properties inside the project.","title":"Default Object Access Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#permission-precedence-rules","text":"For both administrative permissions and default object access permissions, the resulting permissions are derived by applying precedence rules, for the case that the user is member of more than one group. The following list is sorted by the permission precedence level in descending order: permissions on knora-admin:ProjectAdmin (highest level) permissions on resource classes and property combination (own project) permissions on resource classes and property combination ( knora-admin:SystemProject ) permissions on resource classes / properties (own project) permissions on resource classes / properties ( knora-admin:SystemProject ) permissions on custom groups permissions on knora-admin:ProjectMember permissions on knora-admin:KnownUser (lowest level) The permissions on resource classes / properties are only relevant for default object access permissions. Administrative Permissions : When a user performs an operation requiring administrative permissions, then only the permissions from the highest level are taken into account. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and all are taken into account. Default Object Access Permissions : When a user creates a resource or value, then only the default object permissions from the highest level are applied. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and the most permissive are applied. In the case of users belonging to the SystemAdmin group, but which are not members of a project and thus no group belonging to the project, the default object access permissions from the highest defined level will apply. In the case of users belonging to the SystemAdmin group , but which are not members of a project and thus not members of any group belonging to the project, the default object access permissions from the ProjectAdmin , ProjectMember , or KnownUser group will be applied in the order of precedence. If no permissions are defined on either of these groups, then the resulting permission will be CR knora-admin:Creator . Also, in the case that no default object access permissions are defined for the project, the resulting permission will be CR knora-admin:Creator .","title":"Permission Precedence Rules"},{"location":"DSP-API/05-internals/design/api-admin/administration/#implicit-permissions","text":"The knora-admin:SystemAdmin group receives implicitly the following permissions: receives implicitly ProjectAllAdminPermission for all projects. receives implicitly ProjectResourceCreateAllPermission for all projects. receives implicitly CR on all objects from all projects. Theses permissions are baked into the system, and cannot be changed.","title":"Implicit Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#permission-templates","text":"The permission capabilities of Knora are very large, as it needs to be able to satisfy a broad set of requirements. To simplify permission management for the users, we provide permission templates, which can be used during creation of new projects, or applied to existing projects. A permission template defines a set of administrative and default object access permission. Currently, two different templates will be defined OPEN , CLOSED .","title":"Permission Templates"},{"location":"DSP-API/05-internals/design/api-admin/administration/#template-open","text":"The OPEN template defines the following permissions: The knora-admin:ProjectAdmin group: receives explicitly ProjectResourceCreateAllPermission . receives explicitly ProjectAllAdminPermission . The knora-admin:ProjectMember group: receives explicitly ProjectResourceCreateAllPermission . receives explicitly CR for the knora-admin:Creator and knora-admin:ProjectAdmin group. receives explicitly M for the ProjectMember group. receives explicitly V for the knora-admin:KnownUser group.","title":"Template: OPEN"},{"location":"DSP-API/05-internals/design/api-admin/administration/#template-closed","text":"The CLOSED template, defined the following permissions: The knora-admin:ProjectAdmin group: receives explicitly ProjectResourceCreateAllPermission . receives explicitly ProjectAllAdminPermission . The knora-admin:ProjectMember group: receives explicitly ProjectResourceCreateAllPermission . receives explicitly CR for the knora-admin:ProjectAdmin group. receives explicitly M for the ProjectMember group.","title":"Template: CLOSED"},{"location":"DSP-API/05-internals/design/api-admin/administration/#default-permissions-matrix-for-new-projects","text":"The access control matrix defines what are the default operations a subject (i.e. User), being a member of a built-in group (represented by row headers), is permitted to perform on an object (represented by column headers). The different operation abbreviations used are defined as follows: C : Create - the subject inside the group is allowed to create the object. U : Update - the subject inside the group is allowed to update the object. R : Read - the subject inside the group is allowed to read all information about the object. D : Delete - the subject inside the group is allowed to delete the object. P : Permission - the subject inside the group is allowed to change the permissions on the object. - : none - none or not applicable Built-In Group Project Group User Resource Value SystemAdmin CRUD CRUDP CRUDP all CRUDP all CRUDP all ProjectAdmin -RUD CRUDP CRUDP +/- project CRUDP (in project) CRUDP (in project) ProjectMember ---- ----- ----- CRUD- (in project) ----- (in project) Creator ---- ----- ----- -RUDP (his resource) ----- (his value) KnownUser C--- C---- CRUD- himself R---- (in project) R---- (in project) Default Permissions Matrix for new Projects","title":"Default Permissions Matrix for new Projects"},{"location":"DSP-API/05-internals/design/api-admin/administration/#basic-workflows-involving-permissions","text":"","title":"Basic Workflows involving Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#creating-a-new-resource","text":"","title":"Creating a new Resource"},{"location":"DSP-API/05-internals/design/api-admin/administration/#accessing-a-resourcevalue","text":"","title":"Accessing a Resource/Value"},{"location":"DSP-API/05-internals/design/api-admin/administration/#project-group-administration","text":"","title":"Project / Group Administration"},{"location":"DSP-API/05-internals/design/api-admin/administration/#implementation_1","text":"The requirements for defining default permissions imposed by all the different use cases are very broad. Potentially, we need to be able to define default permissions per project, per group, per resource class, per resource property, and all their possible combinations. For this reason, we introduce the knora-admin:Permission class with two sub-classes, namely knora-admin:AdministrativePermission and knora-admin:DefaultObjectAccessPermission , which instances will carry all the necessary information.","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-admin/administration/#permission-class-hierarchy-and-structure","text":"The following graphs show the class hierarchy and the structure of each permission class. Permission Class Hierarchy Administrative Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectResourceCreateRestrictedPermission \"<Resource Class IRI>\"| ProjectAdminAllPermission| ProjectAdminGroupAllPermission| ProjectAdminGroupRestrictedPermission \"<http://rdfh.ch/groups/[shortcode]/[UUID]>, <http://rdfh.ch/groups/[shortcode]/[UUID]>\"| ProjectAdminRightsAllPermission| ProjectAdminOntologyAllPermission\"^^xsd:string . Default Object Access Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-admin:forResourceClass \"Resource Class Name\" ; knora-admin:forProperty \"Resource Property Name\" ; knora-base:hasPermissions \"RV <http://rdfh.ch/groups/[shortcode]/[UUID]>| V <http://rdfh.ch/groups/[shortcode]/[UUID]>| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| D <http://rdfh.ch/groups/[shortcode]/[UUID]>| CR <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string .","title":"Permission Class Hierarchy and Structure"},{"location":"DSP-API/05-internals/design/api-admin/administration/#querying-permission-instances","text":"The properties forProject and either of forGroup , forResourceClass , and forProperty form together a compound key , allowing finding existing permission instances, that address the same set of Project / Group / ResourceClass / Property combination, thus making it possible to extend or change the attached permissions. Administrative Permission Instances : For each group inside the project, there can be zero or one instance holding administrative permission information. Querying is straitforward by using the knora-admin:forProject and knora-admin:forGroup properties as the compound key. Default Object Access Permission Instances : For each group, resource class, or property inside the project, there can be zero or one instances holding default object access permission informations. Querying is straitforward by using the knora-admin:forProject and either knora-admin:forGroup , knora-admin:forResourceClass , or knora-admin:forProperty properties as part of the compound key.","title":"Querying Permission Instances"},{"location":"DSP-API/05-internals/design/api-admin/administration/#example-data-stored-in-the-permissions-graph","text":"Administrative permissions on a 'ProjectAdmin' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectAdmin ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectAdminAllPermission\"^^xsd:string . Administrative permissions on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Administrative permission restricting project admin permission on a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:Permission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectGroupAdminRestrictedPermission <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Administrative permission restricting resource creation for a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateRestrictedPermission <http://www.knora.org/ontology/00FF/images#Person>\"^^xsd:string . Default object access permission on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| V knora-admin:KnownUser\"^^xsd:string . Default object access permission on a resource class: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a resource property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"D knora-admin:ProjectMember,knora-admin:Creator| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^ . Default object access permission on a resource class and property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a knora-admin property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject knora-admin:SystemProject ; knora-admin:forProperty <http://www.knora.org/ontology/knora-admin#hasStillImageFileValue> ; knora-base:hasPermissions \"RV knora-admin:UnknownUser| V knora-admin:KnownUser| M knora-admin:ProjectMember,knora-admin:Creator\"^^xsd:string . A the time the user's UserProfile is queried, all permissions for all projects and groups the user is a member of are also queried. This information is then stored as an easy accessible object inside the UserProfile , being readily available wherever needed. As this is a somewhat expensive operation, built-in caching mechanism at different levels (e.g., UsersResponder, PermissionsResponder), will be applied.","title":"Example Data stored in the permissions graph"},{"location":"DSP-API/05-internals/design/api-admin/administration/#use-cases","text":"","title":"Use Cases"},{"location":"DSP-API/05-internals/design/api-admin/administration/#uc01-teaching-a-class","text":"Description : I'm teaching a class and I have the names and email addresses of all the students. I want to create a project, divide the students into groups (which will only be relevant to this project, e.g. one group for each section of the class), and put some students in each group. I don't want people to be able to join the project or the group by themselves. Solution : The teacher creates different groups and adds users to those groups. Additionally, the teacher can give TA's GroupAdmin privileges, and let the TA's add students to the different groups.","title":"UC01: Teaching a Class"},{"location":"DSP-API/05-internals/design/api-admin/administration/#uc02-unibas-librarian","text":"Description : I'm a Unibas librarian managing several archiving projects. I need to give everyone at the university permission to view all these projects. I want to create a group called UnibasUser that everyone with a Unibas email address will automatically belong to. Most of the resources in those projects can then grant view permission to UnibasUser . Or perhaps the group will be SwitchUser , for anyone at a Swiss university. Or something even broader. Solution : These can be solved by creating Smart Groups , where the user can define what properties need to be set, so that an user is automatically part of this group. This will be implemented at a later time, as it is not trivial and should also include all special groups (e.g., KnownUser, ProjectMember, ProjectAdmin, etc.) that are currently hard-coded inside the system.","title":"UC02: Unibas Librarian"},{"location":"DSP-API/05-internals/design/api-admin/administration/#uc03-crowdsourcing-project","text":"Description : I'm doing a crowdsourcing project, which involves several different groups that work on different tasks. I'm hoping for thousands of users, and I'd like anyone to be able to join the project and add themselves to any group they want (as long as Knora verifies their email address), without needing approval from me. Solution : This can be solved by allowing self-assignment to a group.","title":"UC03: Crowdsourcing Project"},{"location":"DSP-API/05-internals/design/api-admin/administration/#uc04-user-left-knora","text":"Description : An user who was an active collaborator, decides to \"quit\", and wants to delete his user. Solution : The user's IRI is saved on each value change as part of the versioning mechanism. Exchanging the user's IRI in those places would count as 'rewriting history'. So deleting a user will not be possible, instead the user will be set as not active .","title":"UC04: User \"left\" Knora"},{"location":"DSP-API/05-internals/design/api-admin/administration/#redesign-questions-june-2016","text":"Permissions constrained to groups Why this constraint? This is just the way we are doing it. Makes it a bit simpler. Resource owner permission to disruptive knora-base:attachedToUser gives owner status to the person who created the resource. Proposed change: remove this altogether or make institution/project owner of the resource. Should hiwis be \"owners\" of resources they create on behalf of their professor? If the creator should have max permission, then give it explicitly. Owner will be renamed to creator. We need this for provenance. Does not give any permissions automatically. The permissions depend on what is defined for the project and the creator smart group. Resource creation permission to course being part of a projects gives resource creation permission. What if some project members are not allowed to create new resources (or only certain types; Lumiere Lausanne requirement), but are only allowed to change existing resources? These kind of permissions can be set on groups. A project can have different groups, giving different kind of permissions. Support Default Permissions Allow for a project to define permissions that a newly created resource inside a project should receive (current Salsah behavior) Lumiere Lausanne requirement Will be allowed. Groups Do groups belong to projects, i.e. are they seen as extensions to projects? Does someone need to be part of a project to belong to a group of that project? Every group needs to belong to a project. No GroupAdmins. ProjectAdmins with additional GroupAdmin permissions. root Should the 'root' / SystemAdmin user have 'implicitly' or 'explicitly' all permissions? Has implicitly all permissions. Does the has all permissions also extend to projects? Is the root user going to be part of every project? If yes, then again implicitly or explicitly? Since 'root' / SystemAdmin already has all permissions, doesn't really matter if part of a project or group Ivan's Use Case The system administrator creates the project and sets Ivan as the project administrator. As the project administrator, I have all permissions on all objects (Resources/Values; Project Groups) belonging to the project (knora-base:attachedToProject). Nobody outside of the project should be allowed to see anything that is created as part of Ivan's project. He wants to be able to create two groups: Reviewer , Creator . The Reviewer group should only give read-access to someone inside the group to resources pointing to this group, but allow the creation of annotations. Further, annotations should only be readable by users inside the Reviewer group. The Creator group should give a user create permission and modify permission on the objects the user has created. Any resources created belong to the project. The Creator group is meant for contributors helping out with the project, e.g., Hiwis. Covered Lausanne Projects A project wants to restrict the permissions of newly created resources to a fixed set Covered. Will be able do define 'default permissions' and restrict the creation of new resources to these permissions This means for the current implementation, that any permissions supplied during the resource creation request need to be checked and if needed overriden. Covered. Also in the new design, the backend will need to always check the suplied permissions for newly created resources as we cannot ve sure that the GUI will behave correctly (e.g., many different \"Salsah\" implementations) Restrict creation/access of certain classes of resources to certain groups, e.g., group A is able to create/access resources of class A but not of class B. Covered. Will be able to give a certain group only create permission for specific classes Results Owner renamed to Creator Some permissions are attached to groups (e.g., Add Resource (Class), Modify Ontology, etc.), and some are attached to resources (e.g., this group has read/modify permission, etc.) Ontologien Benutzung einschr\u00e4nken (nur auf bestimmte Gruppen, oder frei zur Verf\u00fcgung) System Admin Rechte implizit Gruppen immer an Projekt gebunden Keine Gruppen-Admins. Soll \u00fcber Rollen vom Projekt-Admin geregelt werden k\u00f6nnen.","title":"Redesign / Questions June 2016"},{"location":"DSP-API/05-internals/design/api-v1/","text":"DSP-API v1 Design JSON in API v1 How to Add an API v1 Route","title":"Index"},{"location":"DSP-API/05-internals/design/api-v1/#dsp-api-v1-design","text":"JSON in API v1 How to Add an API v1 Route","title":"DSP-API v1 Design"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/","text":"How to Add an API v1 Route Write SPARQL templates Add any SPARQL templates you need to src/main/twirl/queries/sparql/v1 , using the Twirl template engine. Write Responder Request and Response Messages Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Response message classes that represent a complete API response must extend KnoraResponseV1 , and must therefore have a toJsValue method that converts the response message to a JSON AST using spray-json . Write a Responder Write a class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v1 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. See Triplestore Access for details of how to access the triplestore in your responder. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate an object for your responder class. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them to the responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details. Write a Route Add a class to the org.knora.webapi.routing.v1 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV1.runRdfRouteWithFuture to handle the request. Finally, add your knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"How to Add an API v1 Route"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#how-to-add-an-api-v1-route","text":"","title":"How to Add an API v1 Route"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#write-sparql-templates","text":"Add any SPARQL templates you need to src/main/twirl/queries/sparql/v1 , using the Twirl template engine.","title":"Write SPARQL templates"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#write-responder-request-and-response-messages","text":"Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Response message classes that represent a complete API response must extend KnoraResponseV1 , and must therefore have a toJsValue method that converts the response message to a JSON AST using spray-json .","title":"Write Responder Request and Response Messages"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#write-a-responder","text":"Write a class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v1 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. See Triplestore Access for details of how to access the triplestore in your responder. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate an object for your responder class. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them to the responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details.","title":"Write a Responder"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#write-a-route","text":"Add a class to the org.knora.webapi.routing.v1 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV1.runRdfRouteWithFuture to handle the request. Finally, add your knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"Write a Route"},{"location":"DSP-API/05-internals/design/api-v1/json/","text":"JSON in API v1 DSP-API v1 parses and generates JSON using the spray-json library. The triplestore returns results in JSON, and these are parsed into SparqlSelectResponse objects in the store package (by SparqlUtils , which can be used by any actor in that package). A SparqlSelectResponse has a structure that's very close to the JSON returned by a triplestore via the SPARQL 1.1 Protocol : it contains a header (listing the variables that were used in the query) and a body (containing rows of query results). Each row of query results is represented by a VariableResultsRow , which contains a Map[String, String] of variable names to values. The Jsonable trait marks classes that can convert themselves into spray-json AST objects when you call their toJsValue method; it returns a JsValue object, which can then be converted to text by calling its prettyPrint or compactPrint methods. Case classes representing complete API responses extend the KnoraResponseV1 trait, which extends Jsonable . Case classes representing Knora values extend the ApiValueV1 trait, which also extends Jsonable . To make the responders reusable, the JSON for API responses is generated only at the last moment, by the RouteUtilV1.runJsonRoute() function.","title":"JSON in API v1"},{"location":"DSP-API/05-internals/design/api-v1/json/#json-in-api-v1","text":"DSP-API v1 parses and generates JSON using the spray-json library. The triplestore returns results in JSON, and these are parsed into SparqlSelectResponse objects in the store package (by SparqlUtils , which can be used by any actor in that package). A SparqlSelectResponse has a structure that's very close to the JSON returned by a triplestore via the SPARQL 1.1 Protocol : it contains a header (listing the variables that were used in the query) and a body (containing rows of query results). Each row of query results is represented by a VariableResultsRow , which contains a Map[String, String] of variable names to values. The Jsonable trait marks classes that can convert themselves into spray-json AST objects when you call their toJsValue method; it returns a JsValue object, which can then be converted to text by calling its prettyPrint or compactPrint methods. Case classes representing complete API responses extend the KnoraResponseV1 trait, which extends Jsonable . Case classes representing Knora values extend the ApiValueV1 trait, which also extends Jsonable . To make the responders reusable, the JSON for API responses is generated only at the last moment, by the RouteUtilV1.runJsonRoute() function.","title":"JSON in API v1"},{"location":"DSP-API/05-internals/design/api-v2/","text":"DSP-API v2 Design API v2 Design Overview Ontology Schemas Smart IRIs Content Wrappers How to Add an API v2 Route JSON-LD Parsing and Formatting Ontology Management Knora and Sipi Gravsearch Design Standoff Markup Archival Resource Key (ARK) Identifiers SPARQL Query Design","title":"Index"},{"location":"DSP-API/05-internals/design/api-v2/#dsp-api-v2-design","text":"API v2 Design Overview Ontology Schemas Smart IRIs Content Wrappers How to Add an API v2 Route JSON-LD Parsing and Formatting Ontology Management Knora and Sipi Gravsearch Design Standoff Markup Archival Resource Key (ARK) Identifiers SPARQL Query Design","title":"DSP-API v2 Design"},{"location":"DSP-API/05-internals/design/api-v2/ark/","text":"Archival Resource Key (ARK) Identifiers Requirements Knora must produce an ARK URL for each resource and each value. The ARK identifiers used by Knora must respect the draft ARK specification . The format of Knora\u2019s ARK URLs must be able to change over time, while ensuring that previously generated ARK URLs still work. Design ARK URL Format The format of a Knora ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[/VALUE_UUID][.TIMESTAMP] HOST : the hostname of the ARK resolver. NAAN : the Name Assigning Authority Number (NAAN) that the ARK resolver uses. VERSION : the version of the Knora ARK URL format being used (always 1 for now). PROJECT : the short code of the project that the resource belongs to. RESOURCE_UUID : the resource's unique ID, which is normally a base64url-encoded UUID, as described in IRIs for Data . VALUE_UUID : optionally, the knora-base:valueHasUUID of one of the resource's values, normally a base64url-encoded UUID, as described in IRIs for Data . TIMESTAMP : an optional timestamp indicating that the ARK URL represents the state of the resource at a specific time in the past. The format of the timestamp is an ISO 8601 date in Coordinated universal time (UTC), including date, time, and an optional nano-of-second field (of at most 9 digits), without the characters - , : , and . (because - and . are reserved characters in ARK, and : would have to be URL-encoded). Example: 20180528T155203897Z . Following the ARK ID spec, / represents object hierarchy and . represents an object variant . A value is thus contained in a resource, which is contained in its project, which is contained in a repository (represented by the URL version number). A timestamp is a type of variant. Since sub-objects are optional, there is also implicitly an ARK URL for each project, as well as for the repository as a whole. The RESOURCE_UUID and VALUE_UUID are processed as follows: A check digit is calculated, using the algorithm in the Scala class org.knora.webapi.util.Base64UrlCheckDigit , and appended to the UUID. Any - characters in the resulting string are replaced with = , because base64url encoding uses - , which is a reserved character in ARK URLs. For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 Given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180528T155203897Z Given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Serving ARK URLs SmartIri converts Knora resource IRIs to ARK URLs. This conversion is invoked in ReadResourceV2.toJsonLD , when returning a resource's metadata in JSON-LD format. Resolving Knora ARK URLs A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Archival Resource Key (ARK) Identifiers"},{"location":"DSP-API/05-internals/design/api-v2/ark/#archival-resource-key-ark-identifiers","text":"","title":"Archival Resource Key (ARK) Identifiers"},{"location":"DSP-API/05-internals/design/api-v2/ark/#requirements","text":"Knora must produce an ARK URL for each resource and each value. The ARK identifiers used by Knora must respect the draft ARK specification . The format of Knora\u2019s ARK URLs must be able to change over time, while ensuring that previously generated ARK URLs still work.","title":"Requirements"},{"location":"DSP-API/05-internals/design/api-v2/ark/#design","text":"","title":"Design"},{"location":"DSP-API/05-internals/design/api-v2/ark/#ark-url-format","text":"The format of a Knora ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[/VALUE_UUID][.TIMESTAMP] HOST : the hostname of the ARK resolver. NAAN : the Name Assigning Authority Number (NAAN) that the ARK resolver uses. VERSION : the version of the Knora ARK URL format being used (always 1 for now). PROJECT : the short code of the project that the resource belongs to. RESOURCE_UUID : the resource's unique ID, which is normally a base64url-encoded UUID, as described in IRIs for Data . VALUE_UUID : optionally, the knora-base:valueHasUUID of one of the resource's values, normally a base64url-encoded UUID, as described in IRIs for Data . TIMESTAMP : an optional timestamp indicating that the ARK URL represents the state of the resource at a specific time in the past. The format of the timestamp is an ISO 8601 date in Coordinated universal time (UTC), including date, time, and an optional nano-of-second field (of at most 9 digits), without the characters - , : , and . (because - and . are reserved characters in ARK, and : would have to be URL-encoded). Example: 20180528T155203897Z . Following the ARK ID spec, / represents object hierarchy and . represents an object variant . A value is thus contained in a resource, which is contained in its project, which is contained in a repository (represented by the URL version number). A timestamp is a type of variant. Since sub-objects are optional, there is also implicitly an ARK URL for each project, as well as for the repository as a whole. The RESOURCE_UUID and VALUE_UUID are processed as follows: A check digit is calculated, using the algorithm in the Scala class org.knora.webapi.util.Base64UrlCheckDigit , and appended to the UUID. Any - characters in the resulting string are replaced with = , because base64url encoding uses - , which is a reserved character in ARK URLs. For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 Given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180528T155203897Z Given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z","title":"ARK URL Format"},{"location":"DSP-API/05-internals/design/api-v2/ark/#serving-ark-urls","text":"SmartIri converts Knora resource IRIs to ARK URLs. This conversion is invoked in ReadResourceV2.toJsonLD , when returning a resource's metadata in JSON-LD format.","title":"Serving ARK URLs"},{"location":"DSP-API/05-internals/design/api-v2/ark/#resolving-knora-ark-urls","text":"A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Resolving Knora ARK URLs"},{"location":"DSP-API/05-internals/design/api-v2/content-wrappers/","text":"Content Wrappers Whenever possible, the same data structures are used to represent the same types of data, regardless of the API operation (reading, creating, or modifying). However, often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. The implementation of API v2 therefore uses content wrappers. For each type, there is a case class that represents the lowest common denominator of the type, the data that will be present regardless of the API operation. For example, the trait ValueContentV2 represents a Knora value, regardless of whether it is received as input or returned as output. Case classes such as DateValueContentV2 and TextValueContentV2 implement this trait. An instance of this lowest-common-denominator class, or \"content class\", can then be wrapped in an instance of an operation-specific class that carries additional data. For example, when a Knora value is returned from the triplestore, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A read wrapper can be wrapped in another read wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. In general, DSP-API v2 responders deal only with the internal schema. (The exception is OntologyResponderV2 , which can return ontology information that exists only in an external schema.) Therefore, a content class needs to be able to convert itself from the internal schema to an external schema (when it is being used for output) and vice versa (when it is being used for input). Each content class class should therefore extend KnoraContentV2 , and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction: /** * A trait for content classes that can convert themselves between internal and internal schemas. * * @tparam C the type of the content class that extends this trait. */ trait KnoraContentV2[C <: KnoraContentV2[C]] { this: C => def toOntologySchema(targetSchema: OntologySchema): C } Since read wrappers are used only for output, they need to be able convert themselves only from the internal schema to an external schema. Each read wrapper class should extend KnoraReadV2 , and thus have a method for doing this: /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C }","title":"Content Wrappers"},{"location":"DSP-API/05-internals/design/api-v2/content-wrappers/#content-wrappers","text":"Whenever possible, the same data structures are used to represent the same types of data, regardless of the API operation (reading, creating, or modifying). However, often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. The implementation of API v2 therefore uses content wrappers. For each type, there is a case class that represents the lowest common denominator of the type, the data that will be present regardless of the API operation. For example, the trait ValueContentV2 represents a Knora value, regardless of whether it is received as input or returned as output. Case classes such as DateValueContentV2 and TextValueContentV2 implement this trait. An instance of this lowest-common-denominator class, or \"content class\", can then be wrapped in an instance of an operation-specific class that carries additional data. For example, when a Knora value is returned from the triplestore, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A read wrapper can be wrapped in another read wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. In general, DSP-API v2 responders deal only with the internal schema. (The exception is OntologyResponderV2 , which can return ontology information that exists only in an external schema.) Therefore, a content class needs to be able to convert itself from the internal schema to an external schema (when it is being used for output) and vice versa (when it is being used for input). Each content class class should therefore extend KnoraContentV2 , and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction: /** * A trait for content classes that can convert themselves between internal and internal schemas. * * @tparam C the type of the content class that extends this trait. */ trait KnoraContentV2[C <: KnoraContentV2[C]] { this: C => def toOntologySchema(targetSchema: OntologySchema): C } Since read wrappers are used only for output, they need to be able convert themselves only from the internal schema to an external schema. Each read wrapper class should extend KnoraReadV2 , and thus have a method for doing this: /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C }","title":"Content Wrappers"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/","text":"Gravsearch Design For a detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data . Gravsearch Package The classes that process Gravsearch queries and results can be found in org.knora.webapi.messages.util.search.gravsearch . Type Inspection The code that converts Gravserch queries into SPARQL queries, and processes the query results, needs to know the types of the entities that are used in the input query. As explained in Type Inference , these types can be inferred, or they can be specified in the query using type annotations. Type inspection is implemented in the package org.knora.webapi.messages.util.search.gravsearch.types . The entry point to this package is GravsearchTypeInspectionRunner , which is instantiated by SearchResponderV2 . The result of type inspection is a GravsearchTypeInspectionResult , in which each typeable entity in the input query is associated with a GravsearchEntityTypeInfo , which can be either: A PropertyTypeInfo , which specifies the type of object that a property is expected to have. A NonPropertyTypeInfo , which specifies the type of a variable, or the type of an IRI representing a resource or value. Identifying Typeable Entities After parsing a Gravsearch query, SearchResponderV2 calls GravsearchTypeInspectionRunner.inspectTypes , passing the WHERE clause of the input query. This method first identifies the entities whose types need to be determined. Each of these entities is represented as a TypeableEntity . To do this, GravsearchTypeInspectionRunner uses QueryTraverser to traverse the WHERE clause, collecting typeable entities in a visitor called TypeableEntityCollectingWhereVisitor . The entities that are considered to need type information are: All variables. All IRIs except for those that represent type annotations or types. The Type Inspection Pipeline GravsearchTypeInspectionRunner contains a pipeline of type inspectors, each of which extends GravsearchTypeInspector . There are two type inspectors in the pipeline: AnnotationReadingGravsearchTypeInspector : reads type annotations included in a Gravsearch query. InferringGravsearchTypeInspector : infers the types of entities from the context in which they are used, as well as from ontology information that it requests from OntologyResponderV2 . Each type inspector takes as input, and returns as output, an IntermediateTypeInspectionResult , which associates each TypeableEntity with zero or more types. Initially, each TypeableEntity has no types. Each type inspector adds whatever types it finds for each entity. At the end of the pipeline, each entity should have exactly one type. Therefore, to only keep the most specific type for an entity, the method refineDeterminedTypes refines the determined types by removing those that are base classes of others. However, it can be that inconsistent types are determined for entities. For example, in cases where multiple resource class types are determined, but one is not a base class of the others. From the following statement { ?document a beol:manuscript . } UNION { ?document a beol:letter .} two inconsistent types can be inferred for ?document : beol:letter and beol:manuscript . In these cases, a sanitizer sanitizeInconsistentResourceTypes replaces the inconsistent resource types by their common base resource class (in the above example, it would be beol:writtenSource ). Lastly, an error is returned if An entity's type could not be determined. The client must add a type annotation to make the query work. Inconsistent types could not be sanitized (an entity appears to have more than one type). The client must correct the query. If there are no errors, GravsearchTypeInspectionRunner converts the pipeline's output to a GravsearchTypeInspectionResult , in which each entity is associated with exactly one type. AnnotationReadingGravsearchTypeInspector This inspector uses QueryTraverser to traverse the WHERE clause, collecting type annotations in a visitor called AnnotationCollectingWhereVisitor . It then converts each annotation to a GravsearchEntityTypeInfo . InferringGravsearchTypeInspector This inspector first uses QueryTraverser to traverse the WHERE clause, assembling an index of usage information about typeable entities in a visitor called UsageIndexCollectingWhereVisitor . The UsageIndex contains, for example, an index of all the entities that are used as subjects, predicates, or objects, along with the statements in which they are used. It also contains sets of all the Knora class and property IRIs that are used in the WHERE clause. InferringGravsearchTypeInspector then asks OntologyResponderV2 for information about those classes and properties, as well as about the classes that are subject types or object types of those properties. Next, the inspector runs inference rules (which extend InferenceRule ) on each TypeableEntity . Each rule takes as input a TypeableEntity , the usage index, the ontology information, and the IntermediateTypeInspectionResult , and returns a new IntermediateTypeInspectionResult . For example, TypeOfObjectFromPropertyRule infers an entity's type if the entity is used as the object of a statement and the predicate's knora-api:objectType is known. For each TypeableEntity , if a type is inferred from a property, the entity and the inferred type are added to IntermediateTypeInspectionResult.entitiesInferredFromProperty . The inference rules are run repeatedly, because the output of one rule may allow another rule to infer additional information. There are two pipelines of rules: a pipeline for the first iteration of type inference, and a pipeline for subsequent iterations. This is because some rules can return additional information if they are run more than once on the same entity, while others cannot. The number of iterations is limited to InferringGravsearchTypeInspector.MAX_ITERATIONS , but in practice two iterations are sufficient for most realistic queries, and it is difficult to design a query that requires more than six iterations. Transformation of a Gravsearch Query A Gravsearch query submitted by the client is parsed by GravsearchParser and preprocessed by GravsearchTypeInspector to get type information about the elements used in the query (resources, values, properties etc.) and do some basic sanity checks. In SearchResponderV2 , two queries are generated from a given Gravsearch query: a prequery and a main query. Query Transformers The Gravsearch query is passed to QueryTraverser along with a query transformer. Query transformers are classes that implement traits supported by QueryTraverser : WhereTransformer : instructions how to convert statements in the WHERE clause of a SPARQL query (to generate the prequery's Where clause). To improve query performance, this trait defines the method optimiseQueryPatterns whose implementation can call private methods to optimise the generated SPARQL. For example, before transformation of statements in WHERE clause, query pattern orders must be optimised by moving LuceneQueryPatterns to the beginning and isDeleted statement patterns to the end of the WHERE clause. ConstructToSelectTransformer (extends WhereTransformer ): instructions how to turn a Construct query into a Select query (converts a Gravsearch query into a prequery) SelectToSelectTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Select query into a triplestore dependent Select query (implementation of inference). ConstructToConstructTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Construct query into a triplestore dependent Construct query (implementation of inference). The traits listed above define methods that are implemented in the transformer classes and called by QueryTraverser to perform SPARQL to SPARQL conversions. When iterating over the statements of the input query, the transformer class's transformation methods are called to perform the conversion. Prequery The purpose of the prequery is to get an ordered collection of results representing only the IRIs of one page of matching resources and values. Sort criteria can be submitted by the user, but the result is always deterministic also without sort criteria. This is necessary to support paging. A prequery is a SPARQL SELECT query. The classes involved in generating prequeries can be found in org.knora.webapi.messages.util.search.gravsearch.prequery . If the client submits a count query, the prequery returns the overall number of hits, but not the results themselves. In a first step, before transforming the WHERE clause, query patterns must be further optimised by removing the rdfs:type statement for entities whose type could be inferred from their use with a property IRI, since there would be no need for explicit rdfs:type statements for them (unless the property IRI from which the type of an entity must be inferred from is wrapped in an OPTIONAL block). This optimisation takes the Gravsearch query as input (rather than the generated SPARQL), because it uses type information that refers to entities in the Gravsearch query, and the generated SPARQL might have different entities. Next, the Gravsearch query's WHERE clause is transformed and the prequery (SELECT and WHERE clause) is generated from this result. The transformation of the Gravsearch query's WHERE clause relies on the implementation of the abstract class AbstractPrequeryGenerator . AbstractPrequeryGenerator contains members whose state is changed during the iteration over the statements of the input query. They can then by used to create the converted query. mainResourceVariable: Option[QueryVariable] : SPARQL variable representing the main resource of the input query. Present in the prequery's SELECT clause. dependentResourceVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing dependent resources in the input query. Used in an aggregation function in the prequery's SELECT clause (see below). dependentResourceVariablesGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of dependent resources. Present in the prequery's SELECT clause. valueObjectVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing value objects. Used in an aggregation function in the prequery's SELECT clause (see below). valueObjectVarsGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of value objects. Present in the prequery's SELECT clause. The variables mentioned above are present in the prequery's result rows because they are part of the prequery's SELECT clause. The following example illustrates the handling of variables. The following Gravsearch query looks for pages with a sequence number of 10 that are part of a book: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?page knora-api:isMainResource true . ?page knora-api:isPartOf ?book . ?page incunabula:seqnum ?seqnum . } WHERE { ?page a incunabula:page . ?page knora-api:isPartOf ?book . ?book a incunabula:book . ?page incunabula:seqnum ?seqnum . FILTER(?seqnum = 10) } The prequery's SELECT clause is built by NonTriplestoreSpecificGravsearchToPrequeryTransformer.getSelectColumns , based on the variables used in the input query's CONSTRUCT clause. The resulting SELECT clause looks as follows: SELECT DISTINCT ?page (GROUP_CONCAT(DISTINCT(IF(BOUND(?book), STR(?book), \"\")); SEPARATOR='') AS ?book__Concat) (GROUP_CONCAT(DISTINCT(IF(BOUND(?seqnum), STR(?seqnum), \"\")); SEPARATOR='') AS ?seqnum__Concat) (GROUP_CONCAT(DISTINCT(IF(BOUND(?book__LinkValue), STR(?book__LinkValue), \"\")); SEPARATOR='') AS ?book__LinkValue__Concat) WHERE {...} GROUP BY ?page ORDER BY ASC(?page) LIMIT 25 ?page represents the main resource. When accessing the prequery's result rows, ?page contains the IRI of the main resource. The prequery's results are grouped by the main resource so that there is exactly one result row per matching main resource. ?page is also used as a sort criterion although none has been defined in the input query. This is necessary to make paging work: results always have to be returned in the same order (the prequery is always deterministic). Like this, results can be fetched page by page using LIMIT and OFFSET. Grouping by main resource requires other results to be aggregated using the function GROUP_CONCAT . ?book is used as an argument of the aggregation function. The aggregation's result is accessible in the prequery's result rows as ?book__Concat . The variable ?book is bound to an IRI. Since more than one IRI could be bound to a variable representing a dependent resource, the results have to be aggregated. GROUP_CONCAT takes two arguments: a collection of strings (IRIs in our use case) and a separator (we use the non-printing Unicode character INFORMATION SEPARATOR ONE ). When accessing ?book__Concat in the prequery's results containing the IRIs of dependent resources, the string has to be split with the separator used in the aggregation function. The result is a collection of IRIs representing dependent resources. The same logic applies to value objects. Each GROUP_CONCAT checks whether the concatenated variable is bound in each result in the group; if a variable is unbound, we concatenate an empty string. This is necessary because, in Apache Jena (and perhaps other triplestores), \"If GROUP_CONCAT has an unbound value in the list of values to concat, the overall result is 'error'\" (see this Jena issue ). If the input query contains a UNION , and a variable is bound in one branch of the UNION and not in another branch, it is possible that the prequery will return more than one row per main resource. To deal with this situation, SearchResponderV2 merges rows that contain the same main resource IRI. Main Query The purpose of the main query is to get all requested information about the main resource, dependent resources, and value objects. The IRIs of those resources and value objects were returned by the prequery. Since the prequery only returns resources and value objects matching the input query's criteria, the main query can specifically ask for more detailed information on these resources and values without having to reconsider these criteria. Generating the Main Query The classes involved in generating the main query can be found in org.knora.webapi.messages.util.search.gravsearch.mainquery . The main query is a SPARQL CONSTRUCT query. Its generation is handled by the method GravsearchMainQueryGenerator.createMainQuery . It takes three arguments: mainResourceIris: Set[IriRef], dependentResourceIris: Set[IriRef], valueObjectIris: Set[IRI] . These sets are constructed based on information about variables representing dependent resources and value objects in the prequery, which is provided by NonTriplestoreSpecificGravsearchToPrequeryTransformer : dependentResourceVariablesGroupConcat : Set(QueryVariable(book__Concat)) valueObjectVariablesGroupConcat : Set(QueryVariable(seqnum__Concat), QueryVariable(book__LinkValue__Concat)) From the given Iris, statements are generated that ask for complete information on exactly these resources and values. For any given resource Iri, only the values present in valueObjectIris are to be queried. This is achieved by using SPARQL's VALUES expression for the main resource and dependent resources as well as for values. Processing the Main Query's results To do the permission checking, the results of the main query are passed to ConstructResponseUtilV2.splitMainResourcesAndValueRdfData , which transforms a SparqlConstructResponse (a set of RDF triples) into a structure organized by main resource Iris. In this structure, dependent resources and values are nested and can be accessed via their main resource, and resources and values that the user does not have permission to see are filtered out. As a result, a page of results may contain fewer than the maximum allowed number of results per page, even if more pages of results are available. MainQueryResultProcessor.getRequestedValuesFromResultsWithFullGraphPattern then filters out values that the user did not explicitly ask for in the input query. Finally, ConstructResponseUtilV2.createApiResponse transforms the query results into an API response (a ReadResourcesSequenceV2 ). If the number of main resources found (even if filtered out because of permissions) is equal to the maximum allowed page size, the predicate knora-api:mayHaveMoreResults: true is included in the response. Inference Gravsearch queries support a subset of RDFS reasoning (see Inference in the API documentation on Gravsearch). This is implemented as follows: When the non-triplestore-specific version of a SPARQL query is generated, statements that do not need inference are marked with the virtual named graph <http://www.knora.org/explicit> . When the triplestore-specific version of the query is generated: If the triplestore is GraphDB, SparqlTransformer.transformKnoraExplicitToGraphDBExplicit changes statements with the virtual graph <http://www.knora.org/explicit> so that they are marked with the GraphDB-specific graph <http://www.ontotext.com/explicit> , and leaves other statements unchanged. SparqlTransformer.transformKnoraExplicitToGraphDBExplicit also adds the valueHasString statements which GraphDB needs for text searches. If Knora is not using the triplestore's inference (e.g. with Fuseki), SparqlTransformer.transformStatementInWhereForNoInference removes <http://www.knora.org/explicit> , and expands unmarked statements using rdfs:subClassOf* and rdfs:subPropertyOf* . Gravsearch also provides some virtual properties, which take advantage of forward-chaining inference as an optimisation if the triplestore provides it. For example, the virtual property knora-api:standoffTagHasStartAncestor is equivalent to knora-base:standoffTagHasStartParent* , but with GraphDB it is implemented using a custom inference rule (in KnoraRules.pie ) and is therefore more efficient. If Knora is not using the triplestore's inference, SparqlTransformer.transformStatementInWhereForNoInference replaces knora-api:standoffTagHasStartAncestor with knora-base:standoffTagHasStartParent* . Optimisation of generated SPARQL The triplestore-specific transformers in SparqlTransformer.scala can run optimisations on the generated SPARQL, in the method optimiseQueryPatterns inherited from WhereTransformer . For example, moveLuceneToBeginning moves Lucene queries to the beginning of the block in which they occur. Query Optimization by Topological Sorting of Statements GraphDB seems to have inherent algorithms to optimize the query time, however query performance of Fuseki highly depends on the order of the query statements. For example, a query such as the one below: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?letter beol:creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?person1 beol:hasIAFIdentifier ?gnd1 . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . } ORDER BY ?date takes a very long time with Fuseki. The performance of this query can be improved by moving up the statements with literal objects that are not dependent on any other statement: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the query then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date . Since we cannot expect clients to know about performance of triplestores in order to write efficient queries, we have implemented an optimization method to automatically rearrange the statements of the given queries. Upon receiving the Gravsearch query, the algorithm converts the query to a graph. For each statement pattern, the subject of the statement is the origin node, the predicate is a directed edge, and the object is the target node. For the query above, this conversion would result in the following graph: The Graph for Scala library is used to construct the graph and sort it using Kahn's topological sorting algorithm . The algorithm returns the nodes of the graph ordered in several layers, where the root element ?letter is in layer 0, [?date, ?person1, ?person2] are in layer 1, [?gnd1, ?gnd2] in layer 2, and the leaf nodes [(DE-588)118531379, (DE-588)118696149] are given in the last layer (i.e. layer 3). According to Kahn's algorithm, there are multiple valid permutations of the topological order. The graph in the example above has 24 valid permutations of topological order. Here are two of them (nodes are ordered from left to right with the highest order to the lowest): (?letter, ?date, ?person2, ?person1, ?gnd2, ?gnd1, (DE-588)118696149, (DE-588)118531379) (?letter, ?date, ?person1, ?person2, ?gnd1, ?gnd2, (DE-588)118531379, (DE-588)118696149) . From all valid topological orders, one is chosen based on certain criteria; for example, the leaf should node should not belong to a statement that has predicate rdf:type , since that could match all resources of the specified type. Once the best order is chosen, it is used to re-arrange the query statements. Starting from the last leaf node, i.e. (DE-588)118696149 , the method finds the statement pattern which has this node as its object, and brings this statement to the top of the query. This rearrangement continues so that the statements with the fewest dependencies on other statements are all brought to the top of the query. The resulting query is as follows: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?person1 beol:hasIAFIdentifier ?gnd1 . ?letter ?linkingProp2 ?person2 . ?letter ?linkingProp1 ?person1 . ?letter beol:creationDate ?date . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) } ORDER BY ?date Note that position of the FILTER statements does not play a significant role in the optimization. If a Gravsearch query contains statements in UNION , OPTIONAL , MINUS , or FILTER NOT EXISTS , they are reordered by defining a graph per block. For example, consider the following query with UNION : { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") ?thing anything:hasInteger ?int . ?int knora-api:intValueAsInt 1 . } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") ?thing anything:hasInteger ?int . ?int knora-api:intValueAsInt 3 . } This would result in one graph per block of the UNION . Each graph is then sorted, and the statements of its block are rearranged according to the topological order of graph. This is the result: { ?int knora-api:intValueAsInt 1 . ?thing anything:hasRichtext ?richtext . ?thing anything:hasInteger ?int . FILTER(knora-api:matchText(?richtext, \"test\")) } UNION { ?int knora-api:intValueAsInt 3 . ?thing anything:hasText ?text . ?thing anything:hasInteger ?int . FILTER(knora-api:matchText(?text, \"test\")) } Cyclic Graphs The topological sorting algorithm can only be used for DAGs (directed acyclic graphs). However, a Gravsearch query can contains statements that result in a cyclic graph, e.g.: PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . } WHERE { ?thing anything:hasOtherThing ?thing1 . ?thing1 anything:hasOtherThing ?thing2 . ?thing2 anything:hasOtherThing ?thing . In this case, the algorithm tries to break the cycles in order to sort the graph. If this is not possible, the query statements are not reordered.","title":"Gravsearch Design"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#gravsearch-design","text":"For a detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data .","title":"Gravsearch Design"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#gravsearch-package","text":"The classes that process Gravsearch queries and results can be found in org.knora.webapi.messages.util.search.gravsearch .","title":"Gravsearch Package"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#type-inspection","text":"The code that converts Gravserch queries into SPARQL queries, and processes the query results, needs to know the types of the entities that are used in the input query. As explained in Type Inference , these types can be inferred, or they can be specified in the query using type annotations. Type inspection is implemented in the package org.knora.webapi.messages.util.search.gravsearch.types . The entry point to this package is GravsearchTypeInspectionRunner , which is instantiated by SearchResponderV2 . The result of type inspection is a GravsearchTypeInspectionResult , in which each typeable entity in the input query is associated with a GravsearchEntityTypeInfo , which can be either: A PropertyTypeInfo , which specifies the type of object that a property is expected to have. A NonPropertyTypeInfo , which specifies the type of a variable, or the type of an IRI representing a resource or value.","title":"Type Inspection"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#identifying-typeable-entities","text":"After parsing a Gravsearch query, SearchResponderV2 calls GravsearchTypeInspectionRunner.inspectTypes , passing the WHERE clause of the input query. This method first identifies the entities whose types need to be determined. Each of these entities is represented as a TypeableEntity . To do this, GravsearchTypeInspectionRunner uses QueryTraverser to traverse the WHERE clause, collecting typeable entities in a visitor called TypeableEntityCollectingWhereVisitor . The entities that are considered to need type information are: All variables. All IRIs except for those that represent type annotations or types.","title":"Identifying Typeable Entities"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#the-type-inspection-pipeline","text":"GravsearchTypeInspectionRunner contains a pipeline of type inspectors, each of which extends GravsearchTypeInspector . There are two type inspectors in the pipeline: AnnotationReadingGravsearchTypeInspector : reads type annotations included in a Gravsearch query. InferringGravsearchTypeInspector : infers the types of entities from the context in which they are used, as well as from ontology information that it requests from OntologyResponderV2 . Each type inspector takes as input, and returns as output, an IntermediateTypeInspectionResult , which associates each TypeableEntity with zero or more types. Initially, each TypeableEntity has no types. Each type inspector adds whatever types it finds for each entity. At the end of the pipeline, each entity should have exactly one type. Therefore, to only keep the most specific type for an entity, the method refineDeterminedTypes refines the determined types by removing those that are base classes of others. However, it can be that inconsistent types are determined for entities. For example, in cases where multiple resource class types are determined, but one is not a base class of the others. From the following statement { ?document a beol:manuscript . } UNION { ?document a beol:letter .} two inconsistent types can be inferred for ?document : beol:letter and beol:manuscript . In these cases, a sanitizer sanitizeInconsistentResourceTypes replaces the inconsistent resource types by their common base resource class (in the above example, it would be beol:writtenSource ). Lastly, an error is returned if An entity's type could not be determined. The client must add a type annotation to make the query work. Inconsistent types could not be sanitized (an entity appears to have more than one type). The client must correct the query. If there are no errors, GravsearchTypeInspectionRunner converts the pipeline's output to a GravsearchTypeInspectionResult , in which each entity is associated with exactly one type.","title":"The Type Inspection Pipeline"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#annotationreadinggravsearchtypeinspector","text":"This inspector uses QueryTraverser to traverse the WHERE clause, collecting type annotations in a visitor called AnnotationCollectingWhereVisitor . It then converts each annotation to a GravsearchEntityTypeInfo .","title":"AnnotationReadingGravsearchTypeInspector"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#inferringgravsearchtypeinspector","text":"This inspector first uses QueryTraverser to traverse the WHERE clause, assembling an index of usage information about typeable entities in a visitor called UsageIndexCollectingWhereVisitor . The UsageIndex contains, for example, an index of all the entities that are used as subjects, predicates, or objects, along with the statements in which they are used. It also contains sets of all the Knora class and property IRIs that are used in the WHERE clause. InferringGravsearchTypeInspector then asks OntologyResponderV2 for information about those classes and properties, as well as about the classes that are subject types or object types of those properties. Next, the inspector runs inference rules (which extend InferenceRule ) on each TypeableEntity . Each rule takes as input a TypeableEntity , the usage index, the ontology information, and the IntermediateTypeInspectionResult , and returns a new IntermediateTypeInspectionResult . For example, TypeOfObjectFromPropertyRule infers an entity's type if the entity is used as the object of a statement and the predicate's knora-api:objectType is known. For each TypeableEntity , if a type is inferred from a property, the entity and the inferred type are added to IntermediateTypeInspectionResult.entitiesInferredFromProperty . The inference rules are run repeatedly, because the output of one rule may allow another rule to infer additional information. There are two pipelines of rules: a pipeline for the first iteration of type inference, and a pipeline for subsequent iterations. This is because some rules can return additional information if they are run more than once on the same entity, while others cannot. The number of iterations is limited to InferringGravsearchTypeInspector.MAX_ITERATIONS , but in practice two iterations are sufficient for most realistic queries, and it is difficult to design a query that requires more than six iterations.","title":"InferringGravsearchTypeInspector"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#transformation-of-a-gravsearch-query","text":"A Gravsearch query submitted by the client is parsed by GravsearchParser and preprocessed by GravsearchTypeInspector to get type information about the elements used in the query (resources, values, properties etc.) and do some basic sanity checks. In SearchResponderV2 , two queries are generated from a given Gravsearch query: a prequery and a main query.","title":"Transformation of a Gravsearch Query"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#query-transformers","text":"The Gravsearch query is passed to QueryTraverser along with a query transformer. Query transformers are classes that implement traits supported by QueryTraverser : WhereTransformer : instructions how to convert statements in the WHERE clause of a SPARQL query (to generate the prequery's Where clause). To improve query performance, this trait defines the method optimiseQueryPatterns whose implementation can call private methods to optimise the generated SPARQL. For example, before transformation of statements in WHERE clause, query pattern orders must be optimised by moving LuceneQueryPatterns to the beginning and isDeleted statement patterns to the end of the WHERE clause. ConstructToSelectTransformer (extends WhereTransformer ): instructions how to turn a Construct query into a Select query (converts a Gravsearch query into a prequery) SelectToSelectTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Select query into a triplestore dependent Select query (implementation of inference). ConstructToConstructTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Construct query into a triplestore dependent Construct query (implementation of inference). The traits listed above define methods that are implemented in the transformer classes and called by QueryTraverser to perform SPARQL to SPARQL conversions. When iterating over the statements of the input query, the transformer class's transformation methods are called to perform the conversion.","title":"Query Transformers"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#prequery","text":"The purpose of the prequery is to get an ordered collection of results representing only the IRIs of one page of matching resources and values. Sort criteria can be submitted by the user, but the result is always deterministic also without sort criteria. This is necessary to support paging. A prequery is a SPARQL SELECT query. The classes involved in generating prequeries can be found in org.knora.webapi.messages.util.search.gravsearch.prequery . If the client submits a count query, the prequery returns the overall number of hits, but not the results themselves. In a first step, before transforming the WHERE clause, query patterns must be further optimised by removing the rdfs:type statement for entities whose type could be inferred from their use with a property IRI, since there would be no need for explicit rdfs:type statements for them (unless the property IRI from which the type of an entity must be inferred from is wrapped in an OPTIONAL block). This optimisation takes the Gravsearch query as input (rather than the generated SPARQL), because it uses type information that refers to entities in the Gravsearch query, and the generated SPARQL might have different entities. Next, the Gravsearch query's WHERE clause is transformed and the prequery (SELECT and WHERE clause) is generated from this result. The transformation of the Gravsearch query's WHERE clause relies on the implementation of the abstract class AbstractPrequeryGenerator . AbstractPrequeryGenerator contains members whose state is changed during the iteration over the statements of the input query. They can then by used to create the converted query. mainResourceVariable: Option[QueryVariable] : SPARQL variable representing the main resource of the input query. Present in the prequery's SELECT clause. dependentResourceVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing dependent resources in the input query. Used in an aggregation function in the prequery's SELECT clause (see below). dependentResourceVariablesGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of dependent resources. Present in the prequery's SELECT clause. valueObjectVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing value objects. Used in an aggregation function in the prequery's SELECT clause (see below). valueObjectVarsGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of value objects. Present in the prequery's SELECT clause. The variables mentioned above are present in the prequery's result rows because they are part of the prequery's SELECT clause. The following example illustrates the handling of variables. The following Gravsearch query looks for pages with a sequence number of 10 that are part of a book: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?page knora-api:isMainResource true . ?page knora-api:isPartOf ?book . ?page incunabula:seqnum ?seqnum . } WHERE { ?page a incunabula:page . ?page knora-api:isPartOf ?book . ?book a incunabula:book . ?page incunabula:seqnum ?seqnum . FILTER(?seqnum = 10) } The prequery's SELECT clause is built by NonTriplestoreSpecificGravsearchToPrequeryTransformer.getSelectColumns , based on the variables used in the input query's CONSTRUCT clause. The resulting SELECT clause looks as follows: SELECT DISTINCT ?page (GROUP_CONCAT(DISTINCT(IF(BOUND(?book), STR(?book), \"\")); SEPARATOR='') AS ?book__Concat) (GROUP_CONCAT(DISTINCT(IF(BOUND(?seqnum), STR(?seqnum), \"\")); SEPARATOR='') AS ?seqnum__Concat) (GROUP_CONCAT(DISTINCT(IF(BOUND(?book__LinkValue), STR(?book__LinkValue), \"\")); SEPARATOR='') AS ?book__LinkValue__Concat) WHERE {...} GROUP BY ?page ORDER BY ASC(?page) LIMIT 25 ?page represents the main resource. When accessing the prequery's result rows, ?page contains the IRI of the main resource. The prequery's results are grouped by the main resource so that there is exactly one result row per matching main resource. ?page is also used as a sort criterion although none has been defined in the input query. This is necessary to make paging work: results always have to be returned in the same order (the prequery is always deterministic). Like this, results can be fetched page by page using LIMIT and OFFSET. Grouping by main resource requires other results to be aggregated using the function GROUP_CONCAT . ?book is used as an argument of the aggregation function. The aggregation's result is accessible in the prequery's result rows as ?book__Concat . The variable ?book is bound to an IRI. Since more than one IRI could be bound to a variable representing a dependent resource, the results have to be aggregated. GROUP_CONCAT takes two arguments: a collection of strings (IRIs in our use case) and a separator (we use the non-printing Unicode character INFORMATION SEPARATOR ONE ). When accessing ?book__Concat in the prequery's results containing the IRIs of dependent resources, the string has to be split with the separator used in the aggregation function. The result is a collection of IRIs representing dependent resources. The same logic applies to value objects. Each GROUP_CONCAT checks whether the concatenated variable is bound in each result in the group; if a variable is unbound, we concatenate an empty string. This is necessary because, in Apache Jena (and perhaps other triplestores), \"If GROUP_CONCAT has an unbound value in the list of values to concat, the overall result is 'error'\" (see this Jena issue ). If the input query contains a UNION , and a variable is bound in one branch of the UNION and not in another branch, it is possible that the prequery will return more than one row per main resource. To deal with this situation, SearchResponderV2 merges rows that contain the same main resource IRI.","title":"Prequery"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#main-query","text":"The purpose of the main query is to get all requested information about the main resource, dependent resources, and value objects. The IRIs of those resources and value objects were returned by the prequery. Since the prequery only returns resources and value objects matching the input query's criteria, the main query can specifically ask for more detailed information on these resources and values without having to reconsider these criteria.","title":"Main Query"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#generating-the-main-query","text":"The classes involved in generating the main query can be found in org.knora.webapi.messages.util.search.gravsearch.mainquery . The main query is a SPARQL CONSTRUCT query. Its generation is handled by the method GravsearchMainQueryGenerator.createMainQuery . It takes three arguments: mainResourceIris: Set[IriRef], dependentResourceIris: Set[IriRef], valueObjectIris: Set[IRI] . These sets are constructed based on information about variables representing dependent resources and value objects in the prequery, which is provided by NonTriplestoreSpecificGravsearchToPrequeryTransformer : dependentResourceVariablesGroupConcat : Set(QueryVariable(book__Concat)) valueObjectVariablesGroupConcat : Set(QueryVariable(seqnum__Concat), QueryVariable(book__LinkValue__Concat)) From the given Iris, statements are generated that ask for complete information on exactly these resources and values. For any given resource Iri, only the values present in valueObjectIris are to be queried. This is achieved by using SPARQL's VALUES expression for the main resource and dependent resources as well as for values.","title":"Generating the Main Query"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#processing-the-main-querys-results","text":"To do the permission checking, the results of the main query are passed to ConstructResponseUtilV2.splitMainResourcesAndValueRdfData , which transforms a SparqlConstructResponse (a set of RDF triples) into a structure organized by main resource Iris. In this structure, dependent resources and values are nested and can be accessed via their main resource, and resources and values that the user does not have permission to see are filtered out. As a result, a page of results may contain fewer than the maximum allowed number of results per page, even if more pages of results are available. MainQueryResultProcessor.getRequestedValuesFromResultsWithFullGraphPattern then filters out values that the user did not explicitly ask for in the input query. Finally, ConstructResponseUtilV2.createApiResponse transforms the query results into an API response (a ReadResourcesSequenceV2 ). If the number of main resources found (even if filtered out because of permissions) is equal to the maximum allowed page size, the predicate knora-api:mayHaveMoreResults: true is included in the response.","title":"Processing the Main Query's results"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#inference","text":"Gravsearch queries support a subset of RDFS reasoning (see Inference in the API documentation on Gravsearch). This is implemented as follows: When the non-triplestore-specific version of a SPARQL query is generated, statements that do not need inference are marked with the virtual named graph <http://www.knora.org/explicit> . When the triplestore-specific version of the query is generated: If the triplestore is GraphDB, SparqlTransformer.transformKnoraExplicitToGraphDBExplicit changes statements with the virtual graph <http://www.knora.org/explicit> so that they are marked with the GraphDB-specific graph <http://www.ontotext.com/explicit> , and leaves other statements unchanged. SparqlTransformer.transformKnoraExplicitToGraphDBExplicit also adds the valueHasString statements which GraphDB needs for text searches. If Knora is not using the triplestore's inference (e.g. with Fuseki), SparqlTransformer.transformStatementInWhereForNoInference removes <http://www.knora.org/explicit> , and expands unmarked statements using rdfs:subClassOf* and rdfs:subPropertyOf* . Gravsearch also provides some virtual properties, which take advantage of forward-chaining inference as an optimisation if the triplestore provides it. For example, the virtual property knora-api:standoffTagHasStartAncestor is equivalent to knora-base:standoffTagHasStartParent* , but with GraphDB it is implemented using a custom inference rule (in KnoraRules.pie ) and is therefore more efficient. If Knora is not using the triplestore's inference, SparqlTransformer.transformStatementInWhereForNoInference replaces knora-api:standoffTagHasStartAncestor with knora-base:standoffTagHasStartParent* .","title":"Inference"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#optimisation-of-generated-sparql","text":"The triplestore-specific transformers in SparqlTransformer.scala can run optimisations on the generated SPARQL, in the method optimiseQueryPatterns inherited from WhereTransformer . For example, moveLuceneToBeginning moves Lucene queries to the beginning of the block in which they occur.","title":"Optimisation of generated SPARQL"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#query-optimization-by-topological-sorting-of-statements","text":"GraphDB seems to have inherent algorithms to optimize the query time, however query performance of Fuseki highly depends on the order of the query statements. For example, a query such as the one below: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?letter beol:creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?person1 beol:hasIAFIdentifier ?gnd1 . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . } ORDER BY ?date takes a very long time with Fuseki. The performance of this query can be improved by moving up the statements with literal objects that are not dependent on any other statement: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the query then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date . Since we cannot expect clients to know about performance of triplestores in order to write efficient queries, we have implemented an optimization method to automatically rearrange the statements of the given queries. Upon receiving the Gravsearch query, the algorithm converts the query to a graph. For each statement pattern, the subject of the statement is the origin node, the predicate is a directed edge, and the object is the target node. For the query above, this conversion would result in the following graph: The Graph for Scala library is used to construct the graph and sort it using Kahn's topological sorting algorithm . The algorithm returns the nodes of the graph ordered in several layers, where the root element ?letter is in layer 0, [?date, ?person1, ?person2] are in layer 1, [?gnd1, ?gnd2] in layer 2, and the leaf nodes [(DE-588)118531379, (DE-588)118696149] are given in the last layer (i.e. layer 3). According to Kahn's algorithm, there are multiple valid permutations of the topological order. The graph in the example above has 24 valid permutations of topological order. Here are two of them (nodes are ordered from left to right with the highest order to the lowest): (?letter, ?date, ?person2, ?person1, ?gnd2, ?gnd1, (DE-588)118696149, (DE-588)118531379) (?letter, ?date, ?person1, ?person2, ?gnd1, ?gnd2, (DE-588)118531379, (DE-588)118696149) . From all valid topological orders, one is chosen based on certain criteria; for example, the leaf should node should not belong to a statement that has predicate rdf:type , since that could match all resources of the specified type. Once the best order is chosen, it is used to re-arrange the query statements. Starting from the last leaf node, i.e. (DE-588)118696149 , the method finds the statement pattern which has this node as its object, and brings this statement to the top of the query. This rearrangement continues so that the statements with the fewest dependencies on other statements are all brought to the top of the query. The resulting query is as follows: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?person1 beol:hasIAFIdentifier ?gnd1 . ?letter ?linkingProp2 ?person2 . ?letter ?linkingProp1 ?person1 . ?letter beol:creationDate ?date . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) } ORDER BY ?date Note that position of the FILTER statements does not play a significant role in the optimization. If a Gravsearch query contains statements in UNION , OPTIONAL , MINUS , or FILTER NOT EXISTS , they are reordered by defining a graph per block. For example, consider the following query with UNION : { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") ?thing anything:hasInteger ?int . ?int knora-api:intValueAsInt 1 . } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") ?thing anything:hasInteger ?int . ?int knora-api:intValueAsInt 3 . } This would result in one graph per block of the UNION . Each graph is then sorted, and the statements of its block are rearranged according to the topological order of graph. This is the result: { ?int knora-api:intValueAsInt 1 . ?thing anything:hasRichtext ?richtext . ?thing anything:hasInteger ?int . FILTER(knora-api:matchText(?richtext, \"test\")) } UNION { ?int knora-api:intValueAsInt 3 . ?thing anything:hasText ?text . ?thing anything:hasInteger ?int . FILTER(knora-api:matchText(?text, \"test\")) }","title":"Query Optimization by Topological Sorting of Statements"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#cyclic-graphs","text":"The topological sorting algorithm can only be used for DAGs (directed acyclic graphs). However, a Gravsearch query can contains statements that result in a cyclic graph, e.g.: PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . } WHERE { ?thing anything:hasOtherThing ?thing1 . ?thing1 anything:hasOtherThing ?thing2 . ?thing2 anything:hasOtherThing ?thing . In this case, the algorithm tries to break the cycles in order to sort the graph. If this is not possible, the query statements are not reordered.","title":"Cyclic Graphs"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/","text":"How to Add an API v2 Route Write SPARQL templates Add any SPARQL templates you need to src/main/twirl/queries/sparql/v2 , using the Twirl template engine. Write Responder Request and Response Messages Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Request and response messages should be designed following the patterns described in JSON-LD Parsing and Formatting . Each responder's request messages should extend a responder-specific trait, so that ResponderManager will know which responder to route those messages to. Write a Responder Write an Akka actor class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v2 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. See Triplestore Access for details of how to access the triplestore in your responder. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate the new responder. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them them to that responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details. Write a Route Add a class to the org.knora.webapi.routing.v2 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV2.runRdfRouteWithFuture to handle the request. Finally, add your route's knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"How to Add an API v2 Route"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#how-to-add-an-api-v2-route","text":"","title":"How to Add an API v2 Route"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#write-sparql-templates","text":"Add any SPARQL templates you need to src/main/twirl/queries/sparql/v2 , using the Twirl template engine.","title":"Write SPARQL templates"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#write-responder-request-and-response-messages","text":"Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Request and response messages should be designed following the patterns described in JSON-LD Parsing and Formatting . Each responder's request messages should extend a responder-specific trait, so that ResponderManager will know which responder to route those messages to.","title":"Write Responder Request and Response Messages"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#write-a-responder","text":"Write an Akka actor class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v2 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. See Triplestore Access for details of how to access the triplestore in your responder. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate the new responder. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them them to that responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details.","title":"Write a Responder"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#write-a-route","text":"Add a class to the org.knora.webapi.routing.v2 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV2.runRdfRouteWithFuture to handle the request. Finally, add your route's knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"Write a Route"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/","text":"JSON-LD Parsing and Formatting JsonLDUtil Knora provides a utility object called JsonLDUtil , which wraps the titanium-json-ld Java library , and parses JSON-LD text to a Knora data structure called JsonLDDocument . These classes provide commonly needed functionality for extracting and validating data from JSON-LD documents, as well as for constructing new documents. Parsing JSON-LD A route that expects a JSON-LD request must first parse the JSON-LD using JsonLDUtil . For example, this is how ValuesRouteV2 parses a JSON-LD request to create a value: post { entity(as[String]) { jsonRequest => requestContext => { val requestDoc: JsonLDDocument = JsonLDUtil.parseJsonLD(jsonRequest) The result is a JsonLDDocument in which all prefixes have been expanded to full IRIs, with an empty JSON-LD context. The next step is to convert the JsonLDDocument to a request message that can be sent to the Knora responder that will handle the request. val requestMessageFuture: Future[CreateValueRequestV2] = for { requestingUser <- getUserADM(requestContext) requestMessage: CreateValueRequestV2 <- CreateValueRequestV2.fromJsonLD( requestDoc, apiRequestID = UUID.randomUUID, requestingUser = requestingUser, responderManager = responderManager, storeManager = storeManager, settings = settings, log = log ) } yield requestMessage This is done in a Future , because the processing of JSON-LD input could in itself involve sending messages to responders. Each request message case class (in this case CreateValueRequestV2 ) has a companion object that implements the KnoraJsonLDRequestReaderV2 trait: /** * A trait for objects that can generate case class instances based on JSON-LD input. * * @tparam C the type of the case class that can be generated. */ trait KnoraJsonLDRequestReaderV2[C] { /** * Converts JSON-LD input into a case class instance. * * @param jsonLDDocument the JSON-LD input. * @param apiRequestID the UUID of the API request. * @param requestingUser the user making the request. * @param responderManager a reference to the responder manager. * @param storeManager a reference to the store manager. * @param settings the application settings. * @param log a logging adapter. * @param timeout a timeout for `ask` messages. * @param executionContext an execution context for futures. * @return a case class instance representing the input. */ def fromJsonLD(jsonLDDocument: JsonLDDocument, apiRequestID: UUID, requestingUser: UserADM, responderManager: ActorRef, storeManager: ActorRef, settings: KnoraSettingsImpl, log: LoggingAdapter)(implicit timeout: Timeout, executionContext: ExecutionContext): Future[C] } This means that the companion object has a method fromJsonLD that takes a JsonLDDocument and returns an instance of the case class. The fromJsonLD method can use the functionality of the JsonLDDocument data structure for extracting and validating the content of the request. For example, JsonLDObject.requireStringWithValidation gets a required member of a JSON-LD object, and validates it using a function that is passed as an argument. Here is an example of getting and validating a SmartIri : for { valueType: SmartIri <- Future(jsonLDObject.requireStringWithValidation(JsonLDConstants.TYPE, stringFormatter.toSmartIriWithErr)) The validation function (in this case stringFormatter.toSmartIriWithErr ) has to take two arguments: a string to be validated, and a function that that throws an exception if the string is invalid. The return value of requireStringWithValidation is the return value of the validation function, which in this case is a SmartIri . If the string is invalid, requireStringWithValidation throws BadRequestException . It is also possible to get and validate an optional JSON-LD object member: val maybeDateValueHasStartEra: Option[DateEraV2] = jsonLDObject.maybeStringWithValidation(OntologyConstants.KnoraApiV2Complex.DateValueHasStartEra, DateEraV2.parse) Here JsonLDObject.maybeStringWithValidation returns an Option that contains the return value of the validation function ( DateEraV2.parse ) if it was given, otherwise None . Returning a JSON-LD Response Each API response is represented by a message class that extends KnoraJsonLDResponseV2 , which has a method toJsonLDDocument that specifies the target ontology schema. The implementation of this method constructs a JsonLDDocument , in which all object keys are full IRIs (no prefixes are used), but in which the JSON-LD context also specifies the prefixes that will be used when the document is returned to the client. The function JsonLDUtil.makeContext is a convenient way to construct the JSON-LD context. Since toJsonLDDocument has to return an object that uses the specified ontology schema, the recommended design is to separate schema conversion as much as possible from JSON-LD generation. As a first step, schema conversion (or at the very least, the conversion of Knora type IRIs to the target schema) can be done via an implementation of KnoraReadV2 : /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C } This means that the response message class has the method toOntologySchema , which returns a copy of the same message, with Knora type IRIs (and perhaps other content) adjusted for the target schema. (See Smart IRIs on how to convert Knora type IRIs to the target schema.) The response message class could then have a private method called generateJsonLD , which generates a JsonLDDocument that has the correct structure for the target schema, like this: private def generateJsonLD(targetSchema: ApiV2Schema, settings: KnoraSettingsImpl, schemaOptions: Set[SchemaOption]): JsonLDDocument This way, the implementation of toJsonLDDocument can call toOntologySchema , then construct a JsonLDDocument from the resulting object. For example: override def toJsonLDDocument(targetSchema: ApiV2Schema, settings: KnoraSettingsImpl, schemaOptions: Set[SchemaOption] = Set.empty): JsonLDDocument = { toOntologySchema(targetSchema).generateJsonLD( targetSchema = targetSchema, settings = settings, schemaOptions = schemaOptions ) } Selecting the Response Schema Most routes complete by calling RouteUtilV2.runRdfRouteWithFuture , which calls the response message's toJsonLDDocument method. The runRdfRouteWithFuture function has a parameter that enables the route to select the schema that should be used in the response. It is up to each route to determine what the appropriate response schema should be. Some routes support only one response schema. Others allow the client to choose. To use the schema requested by the client, the route can call RouteUtilV2.getOntologySchema : RouteUtilV2.runRdfRouteWithFuture( requestMessageF = requestMessageFuture, requestContext = requestContext, settings = settings, responderManager = responderManager, log = log, targetSchema = targetSchema, schemaOptions = schemaOptions ) If the route only supports one schema, it can specify the schema directly instead: RouteUtilV2.runRdfRouteWithFuture( requestMessageF = requestMessageFuture, requestContext = requestContext, settings = settings, responderManager = responderManager, log = log, targetSchema = ApiV2Complex, schemaOptions = RouteUtilV2.getSchemaOptions(requestContext) ) Generating Other RDF Formats RouteUtilV2.runRdfRouteWithFuture implements HTTP content negotiation . After determining the client's preferred format, it asks the KnoraResponseV2 to convert itself into that format. KnoraResponseV2 has an abstract format method, whose implementations select the most efficient conversion between the response message's internal representation (which could be JSON-LD or Turtle) and the requested format.","title":"JSON-LD Parsing and Formatting"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#json-ld-parsing-and-formatting","text":"","title":"JSON-LD Parsing and Formatting"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#jsonldutil","text":"Knora provides a utility object called JsonLDUtil , which wraps the titanium-json-ld Java library , and parses JSON-LD text to a Knora data structure called JsonLDDocument . These classes provide commonly needed functionality for extracting and validating data from JSON-LD documents, as well as for constructing new documents.","title":"JsonLDUtil"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#parsing-json-ld","text":"A route that expects a JSON-LD request must first parse the JSON-LD using JsonLDUtil . For example, this is how ValuesRouteV2 parses a JSON-LD request to create a value: post { entity(as[String]) { jsonRequest => requestContext => { val requestDoc: JsonLDDocument = JsonLDUtil.parseJsonLD(jsonRequest) The result is a JsonLDDocument in which all prefixes have been expanded to full IRIs, with an empty JSON-LD context. The next step is to convert the JsonLDDocument to a request message that can be sent to the Knora responder that will handle the request. val requestMessageFuture: Future[CreateValueRequestV2] = for { requestingUser <- getUserADM(requestContext) requestMessage: CreateValueRequestV2 <- CreateValueRequestV2.fromJsonLD( requestDoc, apiRequestID = UUID.randomUUID, requestingUser = requestingUser, responderManager = responderManager, storeManager = storeManager, settings = settings, log = log ) } yield requestMessage This is done in a Future , because the processing of JSON-LD input could in itself involve sending messages to responders. Each request message case class (in this case CreateValueRequestV2 ) has a companion object that implements the KnoraJsonLDRequestReaderV2 trait: /** * A trait for objects that can generate case class instances based on JSON-LD input. * * @tparam C the type of the case class that can be generated. */ trait KnoraJsonLDRequestReaderV2[C] { /** * Converts JSON-LD input into a case class instance. * * @param jsonLDDocument the JSON-LD input. * @param apiRequestID the UUID of the API request. * @param requestingUser the user making the request. * @param responderManager a reference to the responder manager. * @param storeManager a reference to the store manager. * @param settings the application settings. * @param log a logging adapter. * @param timeout a timeout for `ask` messages. * @param executionContext an execution context for futures. * @return a case class instance representing the input. */ def fromJsonLD(jsonLDDocument: JsonLDDocument, apiRequestID: UUID, requestingUser: UserADM, responderManager: ActorRef, storeManager: ActorRef, settings: KnoraSettingsImpl, log: LoggingAdapter)(implicit timeout: Timeout, executionContext: ExecutionContext): Future[C] } This means that the companion object has a method fromJsonLD that takes a JsonLDDocument and returns an instance of the case class. The fromJsonLD method can use the functionality of the JsonLDDocument data structure for extracting and validating the content of the request. For example, JsonLDObject.requireStringWithValidation gets a required member of a JSON-LD object, and validates it using a function that is passed as an argument. Here is an example of getting and validating a SmartIri : for { valueType: SmartIri <- Future(jsonLDObject.requireStringWithValidation(JsonLDConstants.TYPE, stringFormatter.toSmartIriWithErr)) The validation function (in this case stringFormatter.toSmartIriWithErr ) has to take two arguments: a string to be validated, and a function that that throws an exception if the string is invalid. The return value of requireStringWithValidation is the return value of the validation function, which in this case is a SmartIri . If the string is invalid, requireStringWithValidation throws BadRequestException . It is also possible to get and validate an optional JSON-LD object member: val maybeDateValueHasStartEra: Option[DateEraV2] = jsonLDObject.maybeStringWithValidation(OntologyConstants.KnoraApiV2Complex.DateValueHasStartEra, DateEraV2.parse) Here JsonLDObject.maybeStringWithValidation returns an Option that contains the return value of the validation function ( DateEraV2.parse ) if it was given, otherwise None .","title":"Parsing JSON-LD"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#returning-a-json-ld-response","text":"Each API response is represented by a message class that extends KnoraJsonLDResponseV2 , which has a method toJsonLDDocument that specifies the target ontology schema. The implementation of this method constructs a JsonLDDocument , in which all object keys are full IRIs (no prefixes are used), but in which the JSON-LD context also specifies the prefixes that will be used when the document is returned to the client. The function JsonLDUtil.makeContext is a convenient way to construct the JSON-LD context. Since toJsonLDDocument has to return an object that uses the specified ontology schema, the recommended design is to separate schema conversion as much as possible from JSON-LD generation. As a first step, schema conversion (or at the very least, the conversion of Knora type IRIs to the target schema) can be done via an implementation of KnoraReadV2 : /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C } This means that the response message class has the method toOntologySchema , which returns a copy of the same message, with Knora type IRIs (and perhaps other content) adjusted for the target schema. (See Smart IRIs on how to convert Knora type IRIs to the target schema.) The response message class could then have a private method called generateJsonLD , which generates a JsonLDDocument that has the correct structure for the target schema, like this: private def generateJsonLD(targetSchema: ApiV2Schema, settings: KnoraSettingsImpl, schemaOptions: Set[SchemaOption]): JsonLDDocument This way, the implementation of toJsonLDDocument can call toOntologySchema , then construct a JsonLDDocument from the resulting object. For example: override def toJsonLDDocument(targetSchema: ApiV2Schema, settings: KnoraSettingsImpl, schemaOptions: Set[SchemaOption] = Set.empty): JsonLDDocument = { toOntologySchema(targetSchema).generateJsonLD( targetSchema = targetSchema, settings = settings, schemaOptions = schemaOptions ) }","title":"Returning a JSON-LD Response"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#selecting-the-response-schema","text":"Most routes complete by calling RouteUtilV2.runRdfRouteWithFuture , which calls the response message's toJsonLDDocument method. The runRdfRouteWithFuture function has a parameter that enables the route to select the schema that should be used in the response. It is up to each route to determine what the appropriate response schema should be. Some routes support only one response schema. Others allow the client to choose. To use the schema requested by the client, the route can call RouteUtilV2.getOntologySchema : RouteUtilV2.runRdfRouteWithFuture( requestMessageF = requestMessageFuture, requestContext = requestContext, settings = settings, responderManager = responderManager, log = log, targetSchema = targetSchema, schemaOptions = schemaOptions ) If the route only supports one schema, it can specify the schema directly instead: RouteUtilV2.runRdfRouteWithFuture( requestMessageF = requestMessageFuture, requestContext = requestContext, settings = settings, responderManager = responderManager, log = log, targetSchema = ApiV2Complex, schemaOptions = RouteUtilV2.getSchemaOptions(requestContext) )","title":"Selecting the Response Schema"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#generating-other-rdf-formats","text":"RouteUtilV2.runRdfRouteWithFuture implements HTTP content negotiation . After determining the client's preferred format, it asks the KnoraResponseV2 to convert itself into that format. KnoraResponseV2 has an abstract format method, whose implementations select the most efficient conversion between the response message's internal representation (which could be JSON-LD or Turtle) and the requested format.","title":"Generating Other RDF Formats"},{"location":"DSP-API/05-internals/design/api-v2/ontology-management/","text":"Ontology Management The core of Knora's ontology management logic is OntologyResponderV2 . It is responsible for: Loading ontologies from the triplestore when Knora starts. Maintaining an ontology cache to improve performance. Returning requested ontology entities from the cache. Requests for ontology information never access the triplestore. Creating and updating ontologies in response to API requests. Ensuring that all user-created ontologies are consistent and conform to knora-base . When Knora starts, the ontology responder receives a LoadOntologiesRequestV2 message. It then: Loads all ontologies found in the triplestore into suitable Scala data structures, which include indexes of relations between entities (e.g. rdfs:subClassOf relations), to facilitate validity checks. Checks user-created ontologies for consistency and conformance to knora-base , according to the rules described in Summary of Restrictions on User-Created Ontologies . Caches all the loaded ontologies using CacheUtil . The ontology responder assumes that nothing except itself modifies ontologies in the triplestore while Knora is running. Therefore, the ontology cache is updated only when the ontology responder processes a request to update an ontology. By design, the ontology responder can update only one ontology entity per request, to simplify the necessary validity checks. This requires the client to construct an ontology by submitting a sequence of requests in a certain order, as explained in Ontology Updates . The ontology responder mainly works with ontologies in the internal schema. However, it knows that some entities in built-in ontologies have hard-coded definitions in external schemas, and it checks the relevant transformation rules and returns those entities directly when they are requested (see Generation of Ontologies in External Schemas ).","title":"Ontology Management"},{"location":"DSP-API/05-internals/design/api-v2/ontology-management/#ontology-management","text":"The core of Knora's ontology management logic is OntologyResponderV2 . It is responsible for: Loading ontologies from the triplestore when Knora starts. Maintaining an ontology cache to improve performance. Returning requested ontology entities from the cache. Requests for ontology information never access the triplestore. Creating and updating ontologies in response to API requests. Ensuring that all user-created ontologies are consistent and conform to knora-base . When Knora starts, the ontology responder receives a LoadOntologiesRequestV2 message. It then: Loads all ontologies found in the triplestore into suitable Scala data structures, which include indexes of relations between entities (e.g. rdfs:subClassOf relations), to facilitate validity checks. Checks user-created ontologies for consistency and conformance to knora-base , according to the rules described in Summary of Restrictions on User-Created Ontologies . Caches all the loaded ontologies using CacheUtil . The ontology responder assumes that nothing except itself modifies ontologies in the triplestore while Knora is running. Therefore, the ontology cache is updated only when the ontology responder processes a request to update an ontology. By design, the ontology responder can update only one ontology entity per request, to simplify the necessary validity checks. This requires the client to construct an ontology by submitting a sequence of requests in a certain order, as explained in Ontology Updates . The ontology responder mainly works with ontologies in the internal schema. However, it knows that some entities in built-in ontologies have hard-coded definitions in external schemas, and it checks the relevant transformation rules and returns those entities directly when they are requested (see Generation of Ontologies in External Schemas ).","title":"Ontology Management"},{"location":"DSP-API/05-internals/design/api-v2/ontology-schemas/","text":"Ontology Schemas OntologySchema Type As explained in API Schema , Knora can represent the same RDF data in different forms: an \"internal schema\" for use in the triplestore, and different \"external schemas\" for use in Knora API v2. Different schemas use different IRIs, as explained in Knora IRIs . Internally, Knora uses a SmartIri class to convert IRIs between schemas. The data type representing a schema itself is OntologySchema , which uses the sealed trait pattern: package org.knora.webapi /** * Indicates the schema that a Knora ontology or ontology entity conforms to. */ sealed trait OntologySchema /** * The schema of DSP ontologies and entities that are used in the triplestore. */ case object InternalSchema extends OntologySchema /** * The schema of DSP ontologies and entities that are used in API v2. */ sealed trait ApiV2Schema extends OntologySchema /** * The simple schema for representing DSP ontologies and entities. This schema represents values as literals * when possible. */ case object ApiV2Simple extends ApiV2Schema /** * The default (or complex) schema for representing DSP ontologies and entities. This * schema always represents values as objects. */ case object ApiV2Complex extends ApiV2Schema /** * A trait representing options that can be submitted to configure an ontology schema. */ sealed trait SchemaOption /** * A trait representing options that affect the rendering of markup when text values are returned. */ sealed trait MarkupRendering extends SchemaOption /** * Indicates that markup should be rendered as XML when text values are returned. */ case object MarkupAsXml extends MarkupRendering /** * Indicates that markup should not be returned with text values, because it will be requested * separately as standoff. */ case object MarkupAsStandoff extends MarkupRendering /** * Indicates that no markup should be returned with text values. Used only internally. */ case object NoMarkup extends MarkupRendering /** * Utility functions for working with schema options. */ object SchemaOptions { /** * A set of schema options for querying all standoff markup along with text values. */ val ForStandoffWithTextValues: Set[SchemaOption] = Set(MarkupAsXml) /** * A set of schema options for querying standoff markup separately from text values. */ val ForStandoffSeparateFromTextValues: Set[SchemaOption] = Set(MarkupAsStandoff) /** * Determines whether standoff should be queried when a text value is queried. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if standoff should be queried. */ def queryStandoffWithTextValues(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && !schemaOptions.contains(MarkupAsStandoff) } /** * Determines whether markup should be rendered as XML. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as XML. */ def renderMarkupAsXml(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && !schemaOptions.contains(MarkupAsStandoff) } /** * Determines whether markup should be rendered as standoff, separately from text values. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as standoff. */ def renderMarkupAsStandoff(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && schemaOptions.contains(MarkupAsStandoff) } } This class hierarchy allows method declarations to restrict the schemas they accept. A method that can accept any schema can take a parameter of type OntologySchema , while a method that accepts only external schemas can take a parameter of type ApiV2Schema . For examples, see Content Wrappers . Generation of Ontologies in External Schemas Ontologies are stored only in the internal schema, and are converted on the fly to external schemas. For each external schema, there is a Scala object in org.knora.webapi.messages.v2.responder.ontologymessages that provides rules for this conversion: KnoraApiV2SimpleTransformationRules for the API v2 simple schema KnoraApiV2WithValueObjectsTransformationRules for the API v2 complex schema Since these are Scala objects rather than classes, they are initialised before the Akka ActorSystem starts, and therefore need a special instance of Knora's StringFormatter class (see Smart IRIs ). Each of these rule objects implements this trait: /** * A trait for objects that provide rules for converting an ontology from the internal schema to an external schema. * * See also [[OntologyConstants.CorrespondingIris]]. */ trait OntologyTransformationRules { /** * The metadata to be used for the transformed ontology. */ val ontologyMetadata: OntologyMetadataV2 /** * Properties to remove from the ontology before converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val internalPropertiesToRemove: Set[SmartIri] /** * Classes to remove from the ontology before converting it to the target schema. */ val internalClassesToRemove: Set[SmartIri] /** * After the ontology has been converted to the target schema, these cardinalities must be * added to the specified classes. */ val externalCardinalitiesToAdd: Map[SmartIri, Map[SmartIri, KnoraCardinalityInfo]] /** * Classes that need to be added to the ontology after converting it to the target schema. */ val externalClassesToAdd: Map[SmartIri, ReadClassInfoV2] /** * Properties that need to be added to the ontology after converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val externalPropertiesToAdd: Map[SmartIri, ReadPropertyInfoV2] } These rules are applied to knora-base as well as to user-created ontologies. For example, knora-base:Resource has different cardinalities depending on its schema ( knora-api:Resource has an additional cardinality on knora-api:hasIncomingLink ), and this is therefore also true of its user-created subclasses. The transformation is implemented: In the implementations of the toOntologySchema method in classes defined in OntologyMessagesV2.scala : ReadOntologyV2 , ReadClassInfoV2 , ClassInfoContentV2 , PropertyInfoContentV2 , and OntologyMetadataV2 . In OntologyResponderV2.getEntityInfoResponseV2 , which handles requests for specific ontology entities. If the requested entity is hard-coded in a transformation rule, this method returns the hard-coded external entity, otherwise it returns the relevant internal entity.","title":"Ontology Schemas"},{"location":"DSP-API/05-internals/design/api-v2/ontology-schemas/#ontology-schemas","text":"","title":"Ontology Schemas"},{"location":"DSP-API/05-internals/design/api-v2/ontology-schemas/#ontologyschema-type","text":"As explained in API Schema , Knora can represent the same RDF data in different forms: an \"internal schema\" for use in the triplestore, and different \"external schemas\" for use in Knora API v2. Different schemas use different IRIs, as explained in Knora IRIs . Internally, Knora uses a SmartIri class to convert IRIs between schemas. The data type representing a schema itself is OntologySchema , which uses the sealed trait pattern: package org.knora.webapi /** * Indicates the schema that a Knora ontology or ontology entity conforms to. */ sealed trait OntologySchema /** * The schema of DSP ontologies and entities that are used in the triplestore. */ case object InternalSchema extends OntologySchema /** * The schema of DSP ontologies and entities that are used in API v2. */ sealed trait ApiV2Schema extends OntologySchema /** * The simple schema for representing DSP ontologies and entities. This schema represents values as literals * when possible. */ case object ApiV2Simple extends ApiV2Schema /** * The default (or complex) schema for representing DSP ontologies and entities. This * schema always represents values as objects. */ case object ApiV2Complex extends ApiV2Schema /** * A trait representing options that can be submitted to configure an ontology schema. */ sealed trait SchemaOption /** * A trait representing options that affect the rendering of markup when text values are returned. */ sealed trait MarkupRendering extends SchemaOption /** * Indicates that markup should be rendered as XML when text values are returned. */ case object MarkupAsXml extends MarkupRendering /** * Indicates that markup should not be returned with text values, because it will be requested * separately as standoff. */ case object MarkupAsStandoff extends MarkupRendering /** * Indicates that no markup should be returned with text values. Used only internally. */ case object NoMarkup extends MarkupRendering /** * Utility functions for working with schema options. */ object SchemaOptions { /** * A set of schema options for querying all standoff markup along with text values. */ val ForStandoffWithTextValues: Set[SchemaOption] = Set(MarkupAsXml) /** * A set of schema options for querying standoff markup separately from text values. */ val ForStandoffSeparateFromTextValues: Set[SchemaOption] = Set(MarkupAsStandoff) /** * Determines whether standoff should be queried when a text value is queried. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if standoff should be queried. */ def queryStandoffWithTextValues(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && !schemaOptions.contains(MarkupAsStandoff) } /** * Determines whether markup should be rendered as XML. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as XML. */ def renderMarkupAsXml(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && !schemaOptions.contains(MarkupAsStandoff) } /** * Determines whether markup should be rendered as standoff, separately from text values. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as standoff. */ def renderMarkupAsStandoff(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && schemaOptions.contains(MarkupAsStandoff) } } This class hierarchy allows method declarations to restrict the schemas they accept. A method that can accept any schema can take a parameter of type OntologySchema , while a method that accepts only external schemas can take a parameter of type ApiV2Schema . For examples, see Content Wrappers .","title":"OntologySchema Type"},{"location":"DSP-API/05-internals/design/api-v2/ontology-schemas/#generation-of-ontologies-in-external-schemas","text":"Ontologies are stored only in the internal schema, and are converted on the fly to external schemas. For each external schema, there is a Scala object in org.knora.webapi.messages.v2.responder.ontologymessages that provides rules for this conversion: KnoraApiV2SimpleTransformationRules for the API v2 simple schema KnoraApiV2WithValueObjectsTransformationRules for the API v2 complex schema Since these are Scala objects rather than classes, they are initialised before the Akka ActorSystem starts, and therefore need a special instance of Knora's StringFormatter class (see Smart IRIs ). Each of these rule objects implements this trait: /** * A trait for objects that provide rules for converting an ontology from the internal schema to an external schema. * * See also [[OntologyConstants.CorrespondingIris]]. */ trait OntologyTransformationRules { /** * The metadata to be used for the transformed ontology. */ val ontologyMetadata: OntologyMetadataV2 /** * Properties to remove from the ontology before converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val internalPropertiesToRemove: Set[SmartIri] /** * Classes to remove from the ontology before converting it to the target schema. */ val internalClassesToRemove: Set[SmartIri] /** * After the ontology has been converted to the target schema, these cardinalities must be * added to the specified classes. */ val externalCardinalitiesToAdd: Map[SmartIri, Map[SmartIri, KnoraCardinalityInfo]] /** * Classes that need to be added to the ontology after converting it to the target schema. */ val externalClassesToAdd: Map[SmartIri, ReadClassInfoV2] /** * Properties that need to be added to the ontology after converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val externalPropertiesToAdd: Map[SmartIri, ReadPropertyInfoV2] } These rules are applied to knora-base as well as to user-created ontologies. For example, knora-base:Resource has different cardinalities depending on its schema ( knora-api:Resource has an additional cardinality on knora-api:hasIncomingLink ), and this is therefore also true of its user-created subclasses. The transformation is implemented: In the implementations of the toOntologySchema method in classes defined in OntologyMessagesV2.scala : ReadOntologyV2 , ReadClassInfoV2 , ClassInfoContentV2 , PropertyInfoContentV2 , and OntologyMetadataV2 . In OntologyResponderV2.getEntityInfoResponseV2 , which handles requests for specific ontology entities. If the requested entity is hard-coded in a transformation rule, this method returns the hard-coded external entity, otherwise it returns the relevant internal entity.","title":"Generation of Ontologies in External Schemas"},{"location":"DSP-API/05-internals/design/api-v2/overview/","text":"API v2 Design Overview General Principles DSP-API v2 requests and responses are RDF documents. Any API v2 response can be returned as JSON-LD , Turtle , or RDF/XML . Each class or property used in a request or response has a definition in an ontology, which Knora can serve. Response formats are reused for different requests whenever possible, to minimise the number of different response formats a client has to handle. For example, any request for one or more resources (such as a search result, or a request for one specific resource) returns a response in the same format. Response size is limited by design. Large amounts of data must be retrieved by requesting small pages of data, one after the other. Responses that provide data are distinct from responses that provide definitions (i.e. ontology entities). Data responses indicate which types are used, and the client can request information about these types separately. API Schemas The types used in the triplestore are not exposed directly in the API. Instead, they are mapped onto API 'schemas'. Two schemas are currently provided. A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Each schema has its own type IRIs, which are derived from the ones used in the triplestore. For details of these different IRI formats, see Knora IRIs . Implementation JSON-LD Parsing and Formatting Each API response is represented by a class that extends KnoraResponseV2 , which has a method toJsonLDDocument that specifies the target schema. It is currently up to each route to determine what the appropriate response schema should be. Some routes will support only one response schema. Others will allow the client to choose, and there will be one or more standard ways for the client to specify the desired response schema. A route calls RouteUtilV2.runRdfRoute , passing a request message and a response schema. When RouteUtilV2 gets the response message from the responder, it calls toJsonLDDocument on it, specifying that schema. The response message returns a JsonLDDocument , which is a simple data structure that is then converted to Java objects and passed to the JSON-LD Java library for formatting. In general, toJsonLDDocument is implemented in two stages: first the object converts itself to the target schema, and then the resulting object is converted to a JsonLDDocument . A route that receives JSON-LD requests should use JsonLDUtil.parseJsonLD to convert each request to a JsonLDDocument . Generation of Other RDF Formats RouteUtilV2.runRdfRoute implements HTTP content negotiation , and converts JSON-LD responses into Turtle or RDF/XML as appropriate. Operation Wrappers Whenever possible, the same data structures are used for input and output. Often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. In such cases, there is a class like ValueContentV2 , which represents the data that is used both for input and for output. When a value is read, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A Read* wrapper can be wrapped in another Read* wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. Each *Content* class should extend KnoraContentV2 and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction. Each Read* wrapper class should have a method for converting itself to JSON-LD in a particular external schema. If the Read* wrapper is a KnoraResponseV2 , this method is toJsonLDDocument . Smart IRIs Usage The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org.knora.webapi.messages.{SmartIri, StringFormatter} import org.knora.webapi.messages.IriConversions._ Ensure that an implicit instance of StringFormatter is in scope: implicit val stringFormatter: StringFormatter = StringFormatter.getGeneralInstance Then, if iriStr is a string representing an IRI, you can can convert it to a SmartIri like this: val iri: SmartIri = iriStr.toSmartIri If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: val iri: SmartIri = iriStr.toSmartIriWithErr( () => throw BadRequestException(s\"Invalid IRI: $iriStr\") ) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. Parsing and caching a SmartIri instance takes about 10-20 \u00b5s, and retrieving a cached SmartIri takes about 1 \u00b5s. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri . Implementation The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies. This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"API v2 Design Overview"},{"location":"DSP-API/05-internals/design/api-v2/overview/#api-v2-design-overview","text":"","title":"API v2 Design Overview"},{"location":"DSP-API/05-internals/design/api-v2/overview/#general-principles","text":"DSP-API v2 requests and responses are RDF documents. Any API v2 response can be returned as JSON-LD , Turtle , or RDF/XML . Each class or property used in a request or response has a definition in an ontology, which Knora can serve. Response formats are reused for different requests whenever possible, to minimise the number of different response formats a client has to handle. For example, any request for one or more resources (such as a search result, or a request for one specific resource) returns a response in the same format. Response size is limited by design. Large amounts of data must be retrieved by requesting small pages of data, one after the other. Responses that provide data are distinct from responses that provide definitions (i.e. ontology entities). Data responses indicate which types are used, and the client can request information about these types separately.","title":"General Principles"},{"location":"DSP-API/05-internals/design/api-v2/overview/#api-schemas","text":"The types used in the triplestore are not exposed directly in the API. Instead, they are mapped onto API 'schemas'. Two schemas are currently provided. A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Each schema has its own type IRIs, which are derived from the ones used in the triplestore. For details of these different IRI formats, see Knora IRIs .","title":"API Schemas"},{"location":"DSP-API/05-internals/design/api-v2/overview/#implementation","text":"","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-v2/overview/#json-ld-parsing-and-formatting","text":"Each API response is represented by a class that extends KnoraResponseV2 , which has a method toJsonLDDocument that specifies the target schema. It is currently up to each route to determine what the appropriate response schema should be. Some routes will support only one response schema. Others will allow the client to choose, and there will be one or more standard ways for the client to specify the desired response schema. A route calls RouteUtilV2.runRdfRoute , passing a request message and a response schema. When RouteUtilV2 gets the response message from the responder, it calls toJsonLDDocument on it, specifying that schema. The response message returns a JsonLDDocument , which is a simple data structure that is then converted to Java objects and passed to the JSON-LD Java library for formatting. In general, toJsonLDDocument is implemented in two stages: first the object converts itself to the target schema, and then the resulting object is converted to a JsonLDDocument . A route that receives JSON-LD requests should use JsonLDUtil.parseJsonLD to convert each request to a JsonLDDocument .","title":"JSON-LD Parsing and Formatting"},{"location":"DSP-API/05-internals/design/api-v2/overview/#generation-of-other-rdf-formats","text":"RouteUtilV2.runRdfRoute implements HTTP content negotiation , and converts JSON-LD responses into Turtle or RDF/XML as appropriate.","title":"Generation of Other RDF Formats"},{"location":"DSP-API/05-internals/design/api-v2/overview/#operation-wrappers","text":"Whenever possible, the same data structures are used for input and output. Often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. In such cases, there is a class like ValueContentV2 , which represents the data that is used both for input and for output. When a value is read, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A Read* wrapper can be wrapped in another Read* wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. Each *Content* class should extend KnoraContentV2 and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction. Each Read* wrapper class should have a method for converting itself to JSON-LD in a particular external schema. If the Read* wrapper is a KnoraResponseV2 , this method is toJsonLDDocument .","title":"Operation Wrappers"},{"location":"DSP-API/05-internals/design/api-v2/overview/#smart-iris","text":"","title":"Smart IRIs"},{"location":"DSP-API/05-internals/design/api-v2/overview/#usage","text":"The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org.knora.webapi.messages.{SmartIri, StringFormatter} import org.knora.webapi.messages.IriConversions._ Ensure that an implicit instance of StringFormatter is in scope: implicit val stringFormatter: StringFormatter = StringFormatter.getGeneralInstance Then, if iriStr is a string representing an IRI, you can can convert it to a SmartIri like this: val iri: SmartIri = iriStr.toSmartIri If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: val iri: SmartIri = iriStr.toSmartIriWithErr( () => throw BadRequestException(s\"Invalid IRI: $iriStr\") ) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. Parsing and caching a SmartIri instance takes about 10-20 \u00b5s, and retrieving a cached SmartIri takes about 1 \u00b5s. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri .","title":"Usage"},{"location":"DSP-API/05-internals/design/api-v2/overview/#implementation_1","text":"The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies. This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-v2/query-design/","text":"SPARQL Query Design Inference Knora does not require the triplestore to perform inference, but may be able to take advantage of inference if the triplestore provides it. In particular, Knora's SPARQL queries currently need to do the following: Given a base property, find triples using a subproperty as predicate, and return the subproperty used in each case. Given a base class, find triples using an instance of subclass as subject or object, and return the subclass used in each case. Without inference, this can be done using property path syntax. CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject. WHERE { ?resource a ?resourceClass . ?resourceType rdfs:subClassOf* knora-base:Resource . ?resource ?resourceValueProperty ?valueObject . ?resourceValueProperty rdfs:subPropertyOf* knora-base:hasValue . This query: Checks that the queried resource belongs to a subclass of knora-base:Resource . Returns the class that the resource explicitly belongs to. Finds the Knora values attached to the resource, and returns each value along with the property that explicitly attaches it to the resource. In some triplestores, it can be more efficient to use RDFS inference than to use property path syntax, depending on how inference is implemented. For example, Ontotext GraphDB does inference when data is inserted, and stores inferred triples in the repository ( forward chaining with full materialisation ). Moreover, it provides a way of choosing whether to return explicit or inferred triples. This allows the query above to be optimised as follows, querying inferred triples but returning explicit triples: CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject. WHERE { ?resource a knora-base:Resource . # inferred triple GRAPH <http://www.ontotext.com/explicit> { ?resource a ?resourceClass . # explicit triple } ?resource knora-base:hasValue ?valueObject . # inferred triple GRAPH <http://www.ontotext.com/explicit> { ?resource ?resourceValueProperty ?valueObject . # explicit triple } By querying inferred triples that are already stored in the repository, the optimised query avoids property path syntax and is therefore more efficient, while still only returning explicit triples in the query result. Other triplestores use a backward-chaining inference strategy, meaning that inference is performed during the execution of a SPARQL query, by expanding the query itself. The expanded query is likely to look like the first example, using property path syntax, and therefore it is not likely to be more efficient. Moreover, other triplestores may not provide a way to return explicit rather than inferred triples. To support such a triplestore, Knora uses property path syntax rather than inference. See the Gravsearch design documentation for information on how this is done for Gravsearch queries. The support for Apache Jena Fuseki currently works in this way. However, Fuseki supports both forward-chaining and backward-chaining rule engines, although it does not seem to have anything like GraphDB's <http://www.ontotext.com/explicit> . It would be worth exploring whether Knora's query result processing could be changed so that it could use forward-chaining inference as an optimisation, even if nothing like <http://www.ontotext.com/explicit> is available. For example, the example query= could be written like this: CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject . WHERE { ?resource a knora-base:Resource . ?resource a ?resourceClass . ?resource knora-base:hasValue ?valueObject . ?resource ?resourceValueProperty ?valueObject . This would return inferred triples as well as explicit ones: a triple for each base class of the explicit ?resourceClass , and a triple for each base property of the explicit ?resourceValueProperty . But since Knora knows the class and property inheritance hierarchies, it could ignore the additional triples. Querying Past Value Versions Value versions are a linked list, starting with the current version. Each value points to the previous version via knora-base:previousValue . The resource points only to the current version. Past value versions are queried in getResourcePropertiesAndValues.scala.txt , which can take a timestamp argument. Given the current value version, we must find the most recent past version that existed at the target date. First, we get the set of previous values that were created on or before the target date: ?currentValue knora-base:previousValue* ?valueObject . ?valueObject knora-base:valueCreationDate ?valueObjectCreationDate . FILTER(?valueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) The resulting versions are now possible values of ?valueObject . Next, out of this set of versions, we exclude all versions except for the most recent one. We do this by checking, for each ?valueObject , whether there is another version, ?otherValueObject , that is more recent and was also created before the target date. If such a version exists, we exclude the one we are looking at. FILTER NOT EXISTS { ?currentValue knora-base:previousValue* ?otherValueObject . ?otherValueObject knora-base:valueCreationDate ?otherValueObjectCreationDate . FILTER( (?otherValueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) && (?otherValueObjectCreationDate > ?valueObjectCreationDate) ) } This excludes all past versions except the one we are interested in.","title":"SPARQL Query Design"},{"location":"DSP-API/05-internals/design/api-v2/query-design/#sparql-query-design","text":"","title":"SPARQL Query Design"},{"location":"DSP-API/05-internals/design/api-v2/query-design/#inference","text":"Knora does not require the triplestore to perform inference, but may be able to take advantage of inference if the triplestore provides it. In particular, Knora's SPARQL queries currently need to do the following: Given a base property, find triples using a subproperty as predicate, and return the subproperty used in each case. Given a base class, find triples using an instance of subclass as subject or object, and return the subclass used in each case. Without inference, this can be done using property path syntax. CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject. WHERE { ?resource a ?resourceClass . ?resourceType rdfs:subClassOf* knora-base:Resource . ?resource ?resourceValueProperty ?valueObject . ?resourceValueProperty rdfs:subPropertyOf* knora-base:hasValue . This query: Checks that the queried resource belongs to a subclass of knora-base:Resource . Returns the class that the resource explicitly belongs to. Finds the Knora values attached to the resource, and returns each value along with the property that explicitly attaches it to the resource. In some triplestores, it can be more efficient to use RDFS inference than to use property path syntax, depending on how inference is implemented. For example, Ontotext GraphDB does inference when data is inserted, and stores inferred triples in the repository ( forward chaining with full materialisation ). Moreover, it provides a way of choosing whether to return explicit or inferred triples. This allows the query above to be optimised as follows, querying inferred triples but returning explicit triples: CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject. WHERE { ?resource a knora-base:Resource . # inferred triple GRAPH <http://www.ontotext.com/explicit> { ?resource a ?resourceClass . # explicit triple } ?resource knora-base:hasValue ?valueObject . # inferred triple GRAPH <http://www.ontotext.com/explicit> { ?resource ?resourceValueProperty ?valueObject . # explicit triple } By querying inferred triples that are already stored in the repository, the optimised query avoids property path syntax and is therefore more efficient, while still only returning explicit triples in the query result. Other triplestores use a backward-chaining inference strategy, meaning that inference is performed during the execution of a SPARQL query, by expanding the query itself. The expanded query is likely to look like the first example, using property path syntax, and therefore it is not likely to be more efficient. Moreover, other triplestores may not provide a way to return explicit rather than inferred triples. To support such a triplestore, Knora uses property path syntax rather than inference. See the Gravsearch design documentation for information on how this is done for Gravsearch queries. The support for Apache Jena Fuseki currently works in this way. However, Fuseki supports both forward-chaining and backward-chaining rule engines, although it does not seem to have anything like GraphDB's <http://www.ontotext.com/explicit> . It would be worth exploring whether Knora's query result processing could be changed so that it could use forward-chaining inference as an optimisation, even if nothing like <http://www.ontotext.com/explicit> is available. For example, the example query= could be written like this: CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject . WHERE { ?resource a knora-base:Resource . ?resource a ?resourceClass . ?resource knora-base:hasValue ?valueObject . ?resource ?resourceValueProperty ?valueObject . This would return inferred triples as well as explicit ones: a triple for each base class of the explicit ?resourceClass , and a triple for each base property of the explicit ?resourceValueProperty . But since Knora knows the class and property inheritance hierarchies, it could ignore the additional triples.","title":"Inference"},{"location":"DSP-API/05-internals/design/api-v2/query-design/#querying-past-value-versions","text":"Value versions are a linked list, starting with the current version. Each value points to the previous version via knora-base:previousValue . The resource points only to the current version. Past value versions are queried in getResourcePropertiesAndValues.scala.txt , which can take a timestamp argument. Given the current value version, we must find the most recent past version that existed at the target date. First, we get the set of previous values that were created on or before the target date: ?currentValue knora-base:previousValue* ?valueObject . ?valueObject knora-base:valueCreationDate ?valueObjectCreationDate . FILTER(?valueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) The resulting versions are now possible values of ?valueObject . Next, out of this set of versions, we exclude all versions except for the most recent one. We do this by checking, for each ?valueObject , whether there is another version, ?otherValueObject , that is more recent and was also created before the target date. If such a version exists, we exclude the one we are looking at. FILTER NOT EXISTS { ?currentValue knora-base:previousValue* ?otherValueObject . ?otherValueObject knora-base:valueCreationDate ?otherValueObjectCreationDate . FILTER( (?otherValueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) && (?otherValueObjectCreationDate > ?valueObjectCreationDate) ) } This excludes all past versions except the one we are interested in.","title":"Querying Past Value Versions"},{"location":"DSP-API/05-internals/design/api-v2/sipi/","text":"Knora and Sipi Configuration The Knora-specific configuration and scripts for Sipi are in the sipi subdirectory of the Knora source tree. See the README.md there for instructions on how to start Sipi with Knora. Lua Scripts DSP-API v2 uses custom Lua scripts to control Sipi. These scripts can be found in sipi/scripts in the Knora source tree. Each of these scripts expects a JSON Web Token in the URL parameter token . In all cases, the token must be signed by Knora, it must have an expiration date and not have expired, its issuer must be Knora , and its audience must include Sipi . The other contents of the expected tokens are described below. upload.lua The upload.lua script is available at Sipi's upload route. It processes one or more file uploads submitted to Sipi. It converts uploaded images to JPEG 2000 format, and stores them in Sipi's tmp directory. The usage of this script is described in Upload Files to Sipi . Each time upload.lua processes a request, it also deletes old temporary files from tmp and (recursively) from any subdirectories. The maximum allowed age of temporary files can be set in Sipi's configuration file, using the parameter max_temp_file_age , which takes a value in seconds, and defaults to 86400 (1 day). store.lua The store.lua script is available at Sipi's store route. It moves a file from temporary to permanent storage. It expects an HTTP POST request containing application/x-www-form-urlencoded data with the parameters prefix (the project shortcode) and filename (the internal Sipi-generated filename of the file to be moved). The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be StoreFile prefix : the project shortcode submitted in the form data filename : the filename submitted in the form data delete_temp_file.lua The delete_temp_file.lua script is available at Sipi's delete_temp_file route. It is used only if Knora rejects a file value update request. It expects an HTTP DELETE request, with a filename as the last component of the URL. The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be DeleteTempFile filename : must be the same as the filename submitted in the URL SipiConnector In Knora, the org.knora.webapi.iiif.SipiConnector handles all communication with Sipi. It blocks while processing each request, to ensure that the number of concurrent requests to Sipi is not greater than akka.actor.deployment./storeManager/iiifManager/sipiConnector.nr-of-instances . If it encounters an error, it returns SipiException . The Image File Upload Workflow The client uploads an image file to the upload route, which runs upload.lua . The image is converted to JPEG 2000 and stored in Sipi's tmp directory. In the response, the client receives the JPEG 2000's unique, randomly generated filename. The client submits a JSON-LD request to a Knora route ( /v2/values or /v2/resources ) to create or change a file value. The request includes Sipi's internal filename. During parsing of this JSON-LD request, a StillImageFileValueContentV2 is constructed to represent the file value. During the construction of this object, a GetFileMetadataRequestV2 is sent to SipiConnector , which uses Sipi's built-in knora.json route to get the rest of the file's metadata. A responder ( ResourcesResponderV2 or ValuesResponderV2 ) validates the request and updates the triplestore. (If it is ResourcesResponderV2 , it asks ValuesResponderV2 to generate SPARQL for the values.) The responder that did the update calls ValueUtilV2.doSipiPostUpdate . If the triplestore update was successful, this method sends MoveTemporaryFileToPermanentStorageRequestV2 to SipiConnector , which makes a request to Sipi's store route. Otherwise, the same method sends DeleteTemporaryFileRequestV2 to SipiConnector , which makes a request to Sipi's delete_temp_file route. If the request to Knora cannot be parsed, the temporary file is not deleted immediately, but it will be deleted during the processing of a subsequent request by Sipi's upload route. If Sipi's store route fails, Knora returns the SipiException to the client. In this case, manual intervention may be necessary to restore consistency between Knora and Sipi. If Sipi's delete_temp_file route fails, the error is not returned to the client, because there is already a Knora error that needs to be returned to the client. In this case, the Sipi error is simply logged.","title":"DSP-API and Sipi"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#knora-and-sipi","text":"","title":"Knora and Sipi"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#configuration","text":"The Knora-specific configuration and scripts for Sipi are in the sipi subdirectory of the Knora source tree. See the README.md there for instructions on how to start Sipi with Knora.","title":"Configuration"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#lua-scripts","text":"DSP-API v2 uses custom Lua scripts to control Sipi. These scripts can be found in sipi/scripts in the Knora source tree. Each of these scripts expects a JSON Web Token in the URL parameter token . In all cases, the token must be signed by Knora, it must have an expiration date and not have expired, its issuer must be Knora , and its audience must include Sipi . The other contents of the expected tokens are described below.","title":"Lua Scripts"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#uploadlua","text":"The upload.lua script is available at Sipi's upload route. It processes one or more file uploads submitted to Sipi. It converts uploaded images to JPEG 2000 format, and stores them in Sipi's tmp directory. The usage of this script is described in Upload Files to Sipi . Each time upload.lua processes a request, it also deletes old temporary files from tmp and (recursively) from any subdirectories. The maximum allowed age of temporary files can be set in Sipi's configuration file, using the parameter max_temp_file_age , which takes a value in seconds, and defaults to 86400 (1 day).","title":"upload.lua"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#storelua","text":"The store.lua script is available at Sipi's store route. It moves a file from temporary to permanent storage. It expects an HTTP POST request containing application/x-www-form-urlencoded data with the parameters prefix (the project shortcode) and filename (the internal Sipi-generated filename of the file to be moved). The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be StoreFile prefix : the project shortcode submitted in the form data filename : the filename submitted in the form data","title":"store.lua"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#delete_temp_filelua","text":"The delete_temp_file.lua script is available at Sipi's delete_temp_file route. It is used only if Knora rejects a file value update request. It expects an HTTP DELETE request, with a filename as the last component of the URL. The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be DeleteTempFile filename : must be the same as the filename submitted in the URL","title":"delete_temp_file.lua"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#sipiconnector","text":"In Knora, the org.knora.webapi.iiif.SipiConnector handles all communication with Sipi. It blocks while processing each request, to ensure that the number of concurrent requests to Sipi is not greater than akka.actor.deployment./storeManager/iiifManager/sipiConnector.nr-of-instances . If it encounters an error, it returns SipiException .","title":"SipiConnector"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#the-image-file-upload-workflow","text":"The client uploads an image file to the upload route, which runs upload.lua . The image is converted to JPEG 2000 and stored in Sipi's tmp directory. In the response, the client receives the JPEG 2000's unique, randomly generated filename. The client submits a JSON-LD request to a Knora route ( /v2/values or /v2/resources ) to create or change a file value. The request includes Sipi's internal filename. During parsing of this JSON-LD request, a StillImageFileValueContentV2 is constructed to represent the file value. During the construction of this object, a GetFileMetadataRequestV2 is sent to SipiConnector , which uses Sipi's built-in knora.json route to get the rest of the file's metadata. A responder ( ResourcesResponderV2 or ValuesResponderV2 ) validates the request and updates the triplestore. (If it is ResourcesResponderV2 , it asks ValuesResponderV2 to generate SPARQL for the values.) The responder that did the update calls ValueUtilV2.doSipiPostUpdate . If the triplestore update was successful, this method sends MoveTemporaryFileToPermanentStorageRequestV2 to SipiConnector , which makes a request to Sipi's store route. Otherwise, the same method sends DeleteTemporaryFileRequestV2 to SipiConnector , which makes a request to Sipi's delete_temp_file route. If the request to Knora cannot be parsed, the temporary file is not deleted immediately, but it will be deleted during the processing of a subsequent request by Sipi's upload route. If Sipi's store route fails, Knora returns the SipiException to the client. In this case, manual intervention may be necessary to restore consistency between Knora and Sipi. If Sipi's delete_temp_file route fails, the error is not returned to the client, because there is already a Knora error that needs to be returned to the client. In this case, the Sipi error is simply logged.","title":"The Image File Upload Workflow"},{"location":"DSP-API/05-internals/design/api-v2/smart-iris/","text":"Smart IRIs Usage The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org.knora.webapi.messages.SmartIri import org.knora.webapi.messages.IriConversions._ Ensure that an implicit instance of StringFormatter is in scope: import org.knora.webapi.messages.StringFormatter implicit val stringFormatter: StringFormatter = StringFormatter.getGeneralInstance Then, if you have a string representing an IRI, you can can convert it to a SmartIri like this: val propertyIri: SmartIri = \"http://0.0.0.0:3333/ontology/0001/anything/v2#hasInteger\".toSmartIri ```` If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: ```scala val propertyIri: SmartIri = propertyIriStr.toSmartIriWithErr(throw BadRequestException(s\"Invalid property IRI: <$propertyIriStr>\")) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri , and represent it as an org.knora.webapi.IRI (an alias for String ). Implementation The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the Scala type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance , which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies (see Generation of Ontologies in External Schemas ). This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Smart IRIs"},{"location":"DSP-API/05-internals/design/api-v2/smart-iris/#smart-iris","text":"","title":"Smart IRIs"},{"location":"DSP-API/05-internals/design/api-v2/smart-iris/#usage","text":"The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org.knora.webapi.messages.SmartIri import org.knora.webapi.messages.IriConversions._ Ensure that an implicit instance of StringFormatter is in scope: import org.knora.webapi.messages.StringFormatter implicit val stringFormatter: StringFormatter = StringFormatter.getGeneralInstance Then, if you have a string representing an IRI, you can can convert it to a SmartIri like this: val propertyIri: SmartIri = \"http://0.0.0.0:3333/ontology/0001/anything/v2#hasInteger\".toSmartIri ```` If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: ```scala val propertyIri: SmartIri = propertyIriStr.toSmartIriWithErr(throw BadRequestException(s\"Invalid property IRI: <$propertyIriStr>\")) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri , and represent it as an org.knora.webapi.IRI (an alias for String ).","title":"Usage"},{"location":"DSP-API/05-internals/design/api-v2/smart-iris/#implementation","text":"The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the Scala type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance , which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies (see Generation of Ontologies in External Schemas ). This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-v2/standoff/","text":"Standoff Markup Requirements In Knora, text with markup is stored using standoff markup , i.e. markup that is stored separately from the content it applies to. Knora's standoff design is based on these requirements: Overlapping markup should be supported. Markup should be stored as RDF, so it can be searched and analysed using the same tools that are used with other data managed by Knora. In particular, Gravsearch queries should be able to specify search criteria that refer to the markup tags attached to a text, together with any other search criteria relating to the resource that contains the text. It should be possible to import any XML document into Knora, store the markup as standoff, and at any time export the document as an equivalent XML document. RDF Design See Text with Standoff Markup . Querying Standoff Since the number of standoff tags that can be attached to a text value is unlimited, standoff is queried in pages of a limited size, to avoid requesting huge SPARQL query results from the triplestore. When ResourcesResponderV2 or SearchResponderV2 need to return a text value with all its markup, they first query the text value with at most one page of standoff. If the text value has more than one page of standoff, ConstructResponseUtilV2.makeTextValueContentV2 then sends a GetRemainingStandoffFromTextValueRequestV2 message to StandoffResponderV2 , which queries the rest of the standoff in the text value, one page at a time. The resulting standoff is concatenated together and returned. To optimise query performance: Each text value with standoff has the predicate knora-base:valueHasMaxStandoffStartIndex , so that when Knora queries a page of standoff, it knows whether it has reached the last page. The last path component of the IRI of a standoff tag is the integer object of its knora-base:standoffTagHasStartIndex predicate. When querying standoff, it is necessary to convert the IRI objects of knora-base:standoffTagHasStartParent and knora-base:standoffTagHasEndParent to integer indexes (the start indexes of those tags). Including each tag's start index in its IRI makes it unnecessary to query the parent tags to determine their start indexes. Conversion Between Standoff and XML XMLToStandoffUtil does the low-level conversion of documents between standoff and XML, using a simple data structure to represent standoff. This data structure knows nothing about RDF, and each standoff tag contains its XML element name and namespace and those of its attributes. In Knora, it is possible to define mappings to control how standoff/RDF is converted to XML and vice versa. Different mappings can be used to convert the same standoff/RDF to different sorts of XML documents. StandoffTagUtilV2 converts between standoff/RDF and XML using mappings, delegating the lower-level work to XMLToStandoffUtil .","title":"Standoff Markup"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#standoff-markup","text":"","title":"Standoff Markup"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#requirements","text":"In Knora, text with markup is stored using standoff markup , i.e. markup that is stored separately from the content it applies to. Knora's standoff design is based on these requirements: Overlapping markup should be supported. Markup should be stored as RDF, so it can be searched and analysed using the same tools that are used with other data managed by Knora. In particular, Gravsearch queries should be able to specify search criteria that refer to the markup tags attached to a text, together with any other search criteria relating to the resource that contains the text. It should be possible to import any XML document into Knora, store the markup as standoff, and at any time export the document as an equivalent XML document.","title":"Requirements"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#rdf-design","text":"See Text with Standoff Markup .","title":"RDF Design"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#querying-standoff","text":"Since the number of standoff tags that can be attached to a text value is unlimited, standoff is queried in pages of a limited size, to avoid requesting huge SPARQL query results from the triplestore. When ResourcesResponderV2 or SearchResponderV2 need to return a text value with all its markup, they first query the text value with at most one page of standoff. If the text value has more than one page of standoff, ConstructResponseUtilV2.makeTextValueContentV2 then sends a GetRemainingStandoffFromTextValueRequestV2 message to StandoffResponderV2 , which queries the rest of the standoff in the text value, one page at a time. The resulting standoff is concatenated together and returned. To optimise query performance: Each text value with standoff has the predicate knora-base:valueHasMaxStandoffStartIndex , so that when Knora queries a page of standoff, it knows whether it has reached the last page. The last path component of the IRI of a standoff tag is the integer object of its knora-base:standoffTagHasStartIndex predicate. When querying standoff, it is necessary to convert the IRI objects of knora-base:standoffTagHasStartParent and knora-base:standoffTagHasEndParent to integer indexes (the start indexes of those tags). Including each tag's start index in its IRI makes it unnecessary to query the parent tags to determine their start indexes.","title":"Querying Standoff"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#conversion-between-standoff-and-xml","text":"XMLToStandoffUtil does the low-level conversion of documents between standoff and XML, using a simple data structure to represent standoff. This data structure knows nothing about RDF, and each standoff tag contains its XML element name and namespace and those of its attributes. In Knora, it is possible to define mappings to control how standoff/RDF is converted to XML and vice versa. Different mappings can be used to convert the same standoff/RDF to different sorts of XML documents. StandoffTagUtilV2 converts between standoff/RDF and XML using mappings, delegating the lower-level work to XMLToStandoffUtil .","title":"Conversion Between Standoff and XML"},{"location":"DSP-API/05-internals/design/principles/","text":"DSP-API Design Principles Design Overview Futures with Akka HTTP Module Store Module RDF Processing API Triplestore Updates Consistency Checking Authentication Feature Toggles","title":"Index"},{"location":"DSP-API/05-internals/design/principles/#dsp-api-design-principles","text":"Design Overview Futures with Akka HTTP Module Store Module RDF Processing API Triplestore Updates Consistency Checking Authentication Feature Toggles","title":"DSP-API Design Principles"},{"location":"DSP-API/05-internals/design/principles/authentication/","text":"Authentication in Knora Scope Authentication is the process of making sure that if someone is accessing something then this someone is actually also the someone he pretends to be. The process of making sure that someone is authorized, i.e. has the permission to access something, is handled as described in Authorisation ). Implementation The authentication in Knora is based on Basic Auth HTTP basic authentication , URL parameters, JSON Web Token , and cookies. This means that on every request (to any of the routes), credentials need to be sent either via authorization header, URL parameters or cookie header. All routes are always accessible and if there are no credentials provided, a default user is assumed. If credentials are sent and they are not correct (e.g., wrong username, password incorrect, token expired), then the request will end in an error message. There are some differences in V1 and V2 of the API regarding authentication. They differ mainly in the format of the response and that creation of session cookies are only supported in V1 and tokens in V2 . After login via either version, all routes ( V1 and V2 ) are accessible. Skipping Authentication There is the possibility to turn skipping authentication on and use a hardcoded user (Test User). In application.conf set the skip-authentication = true and Test User will be always assumed.","title":"Authentication"},{"location":"DSP-API/05-internals/design/principles/authentication/#authentication-in-knora","text":"","title":"Authentication in Knora"},{"location":"DSP-API/05-internals/design/principles/authentication/#scope","text":"Authentication is the process of making sure that if someone is accessing something then this someone is actually also the someone he pretends to be. The process of making sure that someone is authorized, i.e. has the permission to access something, is handled as described in Authorisation ).","title":"Scope"},{"location":"DSP-API/05-internals/design/principles/authentication/#implementation","text":"The authentication in Knora is based on Basic Auth HTTP basic authentication , URL parameters, JSON Web Token , and cookies. This means that on every request (to any of the routes), credentials need to be sent either via authorization header, URL parameters or cookie header. All routes are always accessible and if there are no credentials provided, a default user is assumed. If credentials are sent and they are not correct (e.g., wrong username, password incorrect, token expired), then the request will end in an error message. There are some differences in V1 and V2 of the API regarding authentication. They differ mainly in the format of the response and that creation of session cookies are only supported in V1 and tokens in V2 . After login via either version, all routes ( V1 and V2 ) are accessible.","title":"Implementation"},{"location":"DSP-API/05-internals/design/principles/authentication/#skipping-authentication","text":"There is the possibility to turn skipping authentication on and use a hardcoded user (Test User). In application.conf set the skip-authentication = true and Test User will be always assumed.","title":"Skipping Authentication"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/","text":"Consistency Checking Requirements Knora is designed to prevent inconsistencies in RDF data, as far as is practical, in a triplestore-independent way (see Triplestore Updates ). However, it is also useful to enforce consistency constraints in the triplestore itself, for two reasons: To prevent inconsistencies resulting from bugs in the DSP-API server. To prevent users from inserting inconsistent data directly into the triplestore, bypassing Knora. The design of the knora-base ontology supports two ways of specifying constraints on data (see knora-base: Consistency Checking for details): A property definition should specify the types that are allowed as subjects and objects of the property, using knora-base:subjectClassConstraint and (if it is an object property) knora-base:objectClassConstraint . Every subproperty of knora-base:hasValue or a knora-base:hasLinkTo (i.e. every property of a resource that points to a knora-base:Value or to another resource) is required have this constraint, because the DSP-API server relies on it to know what type of object to expect for the property. Use of knora-base:subjectClassConstraint is recommended but not required. A class definition should use OWL cardinalities (see OWL 2 Quick Reference Guide ) to indicate the properties that instances of the class are allowed to have, and to constrain the number of objects that each property can have. Subclasses of knora-base:Resource are required to have a cardinality for each subproperty of knora-base:hasValue or a knora-base:hasLinkTo that resources of that class can have. Specifically, consistency checking should prevent the following: An object property or datatype property has a subject of the wrong class, or an object property has an object of the wrong class (GraphDB's consistency checke cannot check the types of literals). An object property has an object that does not exist (i.e. the object is an IRI that is not used as the subject of any statements in the repository). This can be treated as if the object is of the wrong type (i.e. it can cause a violation of knora-base:objectClassConstraint , because there is no compatible rdf:type statement for the object). A class has owl:cardinality 1 or owl:minCardinality 1 on an object property or datatype property, and an instance of the class does not have that property. A class has owl:cardinality 1 or owl:maxCardinality 1 on an object property or datatype property, and an instance of the class has more than one object for that property. An instance of knora-base:Resource has an object property pointing to a knora-base:Value or to another Resource , and its class has no cardinality for that property. An instance of knora-base:Value has a subproperty of knora-base:valueHas , and its class has no cardinality for that property. A datatype property has an empty string as an object. Cardinalities in base classes are inherited by derived classes. Derived classes can override inherited cardinalities by making them more restrictive, i.e. by specifying a subproperty of the one specified in the original cardinality. Instances of Resource and Value can be marked as deleted, using the property isDeleted . This must be taken into account as follows: With owl:cardinality 1 or owl:maxCardinality 1 , if the object of the property can be marked as deleted, the property must not have more than one object that has not been marked as deleted. In other words, it's OK if there is more than one object, as long only one of them has knora-base:isDeleted false . With owl:cardinality 1 or owl:minCardinality 1 , the property must have an object, but it's OK if the property's only object is marked as deleted. We allow this because the subject and object may have different owners, and it may not be feasible for them to coordinate their work. The owner of the object should always be able to mark it as deleted. (It could be useful to notify the owner of the subject when this happens, but that is beyond the scope of consistency checking.) Design Ontotext GraphDB provides a mechanism for checking the consistency of data in a repository each time an update transaction is committed. Knora provides GraphDB-specific consistency rules that take advantage of this feature to provide an extra layer of consistency checks, in addition to the checks that are implemented in Knora. When a repository is created in GraphDB, a set of consistency rules can be provided, and GraphDB's consistency checker can be turned on to ensure that each update transaction respects these rules, as described in the section Reasoning of the GraphDB documentation. Like custom inference rules, consistency rules are defined in files with the .pie filename extension, in a GraphDB-specific syntax. We have added rules to the standard RDFS inference rules file builtin_RdfsRules.pie , to create the file KnoraRules.pie . The .ttl configuration file that is used to create the repository must contain these settings: owlim:ruleset \"/path/to/KnoraRules.pie\" ; owlim:check-for-inconsistencies \"true\" ; The path to KnoraRules.pie must be an absolute path. The scripts provided with Knora to create test repositories set this path automatically. Consistency checking in GraphDB relies on reasoning. GraphDB's reasoning is Forward-chaining , which means that reasoning is applied to the contents of each update, before the update transaction is committed, and the inferred statements are added to the repository. A GraphDB rules file can contain two types of rules: inference rules and consistency rules. Before committing an update transaction, GraphDB applies inference rules, then consistency rules. If any of the consistency rules are violated, the transaction is rolled back. An inference rule has this form: Id: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The premises are a pattern that tries to match statements found in the data. Optional constraints, which are enclosed in square brackets, make it possible to specify the premises more precisely, or to specify a named graph (see examples below). Consequences are the statements that will be inferred if the premises match. A line of hyphens separates premises from consequences. A GraphDB consistency rule has a similar form: Consistency: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The differences between inference rules and consistency rules are: A consistency rule begins with Consistency instead of Id . In a consistency rule, the consequences are optional. Instead of representing statements to be inferred, they represent statements that must exist if the premises are satisfied. In other words, if the premises are satisfied and the consequences are not found, the rule is violated. If a consistency rule doesn't specify any consequences, and the premises are satisfied, the rule is violated. Rules use variable names for subjects, predicates, and objects, and they can use actual property names. Empty string as object If subject i has a predicate p whose object is an empty string, the constraint is violated: Consistency: empty_string i p \"\" ------------------------------------ Subject and object class constraints If subject i has a predicate p that requires a subject of type t , and i is not a t , the constraint is violated: Consistency: subject_class_constraint p <knora-base:subjectClassConstraint> t i p j ------------------------------------ i <rdf:type> t If subject i has a predicate p that requires an object of type t , and the object of p is not a t , the constraint is violated: Consistency: object_class_constraint p <knora-base:objectClassConstraint> t i p j ------------------------------------ j <rdf:type> t Cardinality constraints A simple implementation of a consistency rule to check owl:maxCardinality 1 , for objects that can be marked as deleted, could look like this: Consistency: max_cardinality_1_with_deletion_flag i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p i p j i p k [Constraint j != k] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ This means: if resource i is a subclass of an owl:Restriction r with owl:maxCardinality 1 on property p , and the resource has two different objects for that property, neither of which is marked as deleted, the rule is violated. Note that this takes advantage of the fact that Resource and Value have owl:cardinality 1 on isDeleted ( isDeleted must be present even if false), so we do not need to check whether i is actually something that can be marked as deleted. However, this implementation would be much too slow. We therefore use two optimisations suggested by Ontotext: Add custom inference rules to make tables (i.e. named graphs) of pre-calculated information about the cardinalities on properties of subjects, and use those tables to simplify the consistency rules. Use the [Cut] constraint to avoid generating certain redundant compiled rules (see Entailment rules ). For example, to construct a table of subjects belonging to classes that have owl:maxCardinality 1 on some property p , we use the following custom inference rule: Id: maxCardinality_1_table i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p ------------------------------------ i p r [Context <onto:_maxCardinality_1_table>] The constraint [Context <onto:_maxCardinality_1_table>] means that the inferred triples are added to the context (i.e. the named graph) http://www.ontotext.com/_maxCardinality_1_table . (Note that we have defined the prefix onto as http://www.ontotext.com/ in the Prefices section of the rules file.) As the GraphDB documentation on Rules explains: If the context is provided, the statements produced as rule consequences are not \u2018visible\u2019 during normal query answering. Instead, they can only be used as input to this or other rules and only when the rule premise explicitly uses the given context. Now, to find out whether a subject belongs to a class with that cardinality on a given property, we only need to match one triple. The revised implementation of the rule max_cardinality_1_with_deletion_flag is as follows: Consistency: max_cardinality_1_with_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ The constraint [Constraint j != k] means that the premises will be satisfied only if the variables j and k do not refer to the same thing. With these optimisations, the rule is faster by several orders of magnitude. Since properties whose objects can be marked as deleted must be handled differently to properties whose objects cannot be marked as deleted, the knora-base ontology provides a property called objectCannotBeMarkedAsDeleted . All properties in knora-base whose objects cannot take the isDeleted flag (including datatype properties) should be derived from this property. This is how it is used to check owl:maxCardinality 1 for objects that cannot be marked as deleted: Consistency: max_cardinality_1_without_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] p <rdfs:subPropertyOf> <knora-base:objectCannotBeMarkedAsDeleted> i p j [Constraint j != k] i p k [Cut] ------------------------------------ To check owl:minCardinality 1 , we do not care whether the object can be marked as deleted, so we can use this simple rule: Consistency: min_cardinality_1_any_object i p r [Context <onto:_minCardinality_1_table>] ------------------------------------ i p j This means: if a subject i belongs to a class that has owl:minCardinality 1 on property p , and i has no object for p , the rule is violated. To check owl:cardinality 1 , we need two rules: one that checks whether there are too few objects, and one that checks whether there are too many. To check whether there are too few objects, we don't care whether the objects can be marked as deleted, so the rule is the same as min_cardinality_1_any_object , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j To check whether there are too many objects, we need to know whether the objects can be marked as deleted or not. In the case where the objects can be marked as deleted, the rule is the same as max_cardinality_1_with_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_greater_with_deletion_flag i p r [Context <onto:_cardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ In the case where the objects cannot be marked as deleted, the rule is the same as max_cardinality_1_without_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j Knora allows a subproperty of knora-base:hasValue or knora-base:hasLinkTo to be a predicate of a resource only if the resource's class has some cardinality for the property. For convenience, knora-base:hasValue and knora-base:hasLinkTo are subproperties of knora-base:resourceProperty , which is used to check this constraint in the following rule: Consistency: resource_prop_cardinality_any i <knora-base:resourceProperty> j ------------------------------------ i p j i <rdf:type> r r <owl:onProperty> p If resource i has a subproperty of knora-base:resourceProperty , and i is not a member of a subclass of an owl:Restriction r with a cardinality on that property (or on one of its base properties), the rule is violated. A similar rule, value_prop_cardinality_any , ensures that if a value has a subproperty of knora-base:valueHas , the value's class has some cardinality for that property.","title":"Consistency Checking"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#consistency-checking","text":"","title":"Consistency Checking"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#requirements","text":"Knora is designed to prevent inconsistencies in RDF data, as far as is practical, in a triplestore-independent way (see Triplestore Updates ). However, it is also useful to enforce consistency constraints in the triplestore itself, for two reasons: To prevent inconsistencies resulting from bugs in the DSP-API server. To prevent users from inserting inconsistent data directly into the triplestore, bypassing Knora. The design of the knora-base ontology supports two ways of specifying constraints on data (see knora-base: Consistency Checking for details): A property definition should specify the types that are allowed as subjects and objects of the property, using knora-base:subjectClassConstraint and (if it is an object property) knora-base:objectClassConstraint . Every subproperty of knora-base:hasValue or a knora-base:hasLinkTo (i.e. every property of a resource that points to a knora-base:Value or to another resource) is required have this constraint, because the DSP-API server relies on it to know what type of object to expect for the property. Use of knora-base:subjectClassConstraint is recommended but not required. A class definition should use OWL cardinalities (see OWL 2 Quick Reference Guide ) to indicate the properties that instances of the class are allowed to have, and to constrain the number of objects that each property can have. Subclasses of knora-base:Resource are required to have a cardinality for each subproperty of knora-base:hasValue or a knora-base:hasLinkTo that resources of that class can have. Specifically, consistency checking should prevent the following: An object property or datatype property has a subject of the wrong class, or an object property has an object of the wrong class (GraphDB's consistency checke cannot check the types of literals). An object property has an object that does not exist (i.e. the object is an IRI that is not used as the subject of any statements in the repository). This can be treated as if the object is of the wrong type (i.e. it can cause a violation of knora-base:objectClassConstraint , because there is no compatible rdf:type statement for the object). A class has owl:cardinality 1 or owl:minCardinality 1 on an object property or datatype property, and an instance of the class does not have that property. A class has owl:cardinality 1 or owl:maxCardinality 1 on an object property or datatype property, and an instance of the class has more than one object for that property. An instance of knora-base:Resource has an object property pointing to a knora-base:Value or to another Resource , and its class has no cardinality for that property. An instance of knora-base:Value has a subproperty of knora-base:valueHas , and its class has no cardinality for that property. A datatype property has an empty string as an object. Cardinalities in base classes are inherited by derived classes. Derived classes can override inherited cardinalities by making them more restrictive, i.e. by specifying a subproperty of the one specified in the original cardinality. Instances of Resource and Value can be marked as deleted, using the property isDeleted . This must be taken into account as follows: With owl:cardinality 1 or owl:maxCardinality 1 , if the object of the property can be marked as deleted, the property must not have more than one object that has not been marked as deleted. In other words, it's OK if there is more than one object, as long only one of them has knora-base:isDeleted false . With owl:cardinality 1 or owl:minCardinality 1 , the property must have an object, but it's OK if the property's only object is marked as deleted. We allow this because the subject and object may have different owners, and it may not be feasible for them to coordinate their work. The owner of the object should always be able to mark it as deleted. (It could be useful to notify the owner of the subject when this happens, but that is beyond the scope of consistency checking.)","title":"Requirements"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#design","text":"Ontotext GraphDB provides a mechanism for checking the consistency of data in a repository each time an update transaction is committed. Knora provides GraphDB-specific consistency rules that take advantage of this feature to provide an extra layer of consistency checks, in addition to the checks that are implemented in Knora. When a repository is created in GraphDB, a set of consistency rules can be provided, and GraphDB's consistency checker can be turned on to ensure that each update transaction respects these rules, as described in the section Reasoning of the GraphDB documentation. Like custom inference rules, consistency rules are defined in files with the .pie filename extension, in a GraphDB-specific syntax. We have added rules to the standard RDFS inference rules file builtin_RdfsRules.pie , to create the file KnoraRules.pie . The .ttl configuration file that is used to create the repository must contain these settings: owlim:ruleset \"/path/to/KnoraRules.pie\" ; owlim:check-for-inconsistencies \"true\" ; The path to KnoraRules.pie must be an absolute path. The scripts provided with Knora to create test repositories set this path automatically. Consistency checking in GraphDB relies on reasoning. GraphDB's reasoning is Forward-chaining , which means that reasoning is applied to the contents of each update, before the update transaction is committed, and the inferred statements are added to the repository. A GraphDB rules file can contain two types of rules: inference rules and consistency rules. Before committing an update transaction, GraphDB applies inference rules, then consistency rules. If any of the consistency rules are violated, the transaction is rolled back. An inference rule has this form: Id: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The premises are a pattern that tries to match statements found in the data. Optional constraints, which are enclosed in square brackets, make it possible to specify the premises more precisely, or to specify a named graph (see examples below). Consequences are the statements that will be inferred if the premises match. A line of hyphens separates premises from consequences. A GraphDB consistency rule has a similar form: Consistency: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The differences between inference rules and consistency rules are: A consistency rule begins with Consistency instead of Id . In a consistency rule, the consequences are optional. Instead of representing statements to be inferred, they represent statements that must exist if the premises are satisfied. In other words, if the premises are satisfied and the consequences are not found, the rule is violated. If a consistency rule doesn't specify any consequences, and the premises are satisfied, the rule is violated. Rules use variable names for subjects, predicates, and objects, and they can use actual property names.","title":"Design"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#empty-string-as-object","text":"If subject i has a predicate p whose object is an empty string, the constraint is violated: Consistency: empty_string i p \"\" ------------------------------------","title":"Empty string as object"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#subject-and-object-class-constraints","text":"If subject i has a predicate p that requires a subject of type t , and i is not a t , the constraint is violated: Consistency: subject_class_constraint p <knora-base:subjectClassConstraint> t i p j ------------------------------------ i <rdf:type> t If subject i has a predicate p that requires an object of type t , and the object of p is not a t , the constraint is violated: Consistency: object_class_constraint p <knora-base:objectClassConstraint> t i p j ------------------------------------ j <rdf:type> t","title":"Subject and object class constraints"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#cardinality-constraints","text":"A simple implementation of a consistency rule to check owl:maxCardinality 1 , for objects that can be marked as deleted, could look like this: Consistency: max_cardinality_1_with_deletion_flag i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p i p j i p k [Constraint j != k] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ This means: if resource i is a subclass of an owl:Restriction r with owl:maxCardinality 1 on property p , and the resource has two different objects for that property, neither of which is marked as deleted, the rule is violated. Note that this takes advantage of the fact that Resource and Value have owl:cardinality 1 on isDeleted ( isDeleted must be present even if false), so we do not need to check whether i is actually something that can be marked as deleted. However, this implementation would be much too slow. We therefore use two optimisations suggested by Ontotext: Add custom inference rules to make tables (i.e. named graphs) of pre-calculated information about the cardinalities on properties of subjects, and use those tables to simplify the consistency rules. Use the [Cut] constraint to avoid generating certain redundant compiled rules (see Entailment rules ). For example, to construct a table of subjects belonging to classes that have owl:maxCardinality 1 on some property p , we use the following custom inference rule: Id: maxCardinality_1_table i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p ------------------------------------ i p r [Context <onto:_maxCardinality_1_table>] The constraint [Context <onto:_maxCardinality_1_table>] means that the inferred triples are added to the context (i.e. the named graph) http://www.ontotext.com/_maxCardinality_1_table . (Note that we have defined the prefix onto as http://www.ontotext.com/ in the Prefices section of the rules file.) As the GraphDB documentation on Rules explains: If the context is provided, the statements produced as rule consequences are not \u2018visible\u2019 during normal query answering. Instead, they can only be used as input to this or other rules and only when the rule premise explicitly uses the given context. Now, to find out whether a subject belongs to a class with that cardinality on a given property, we only need to match one triple. The revised implementation of the rule max_cardinality_1_with_deletion_flag is as follows: Consistency: max_cardinality_1_with_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ The constraint [Constraint j != k] means that the premises will be satisfied only if the variables j and k do not refer to the same thing. With these optimisations, the rule is faster by several orders of magnitude. Since properties whose objects can be marked as deleted must be handled differently to properties whose objects cannot be marked as deleted, the knora-base ontology provides a property called objectCannotBeMarkedAsDeleted . All properties in knora-base whose objects cannot take the isDeleted flag (including datatype properties) should be derived from this property. This is how it is used to check owl:maxCardinality 1 for objects that cannot be marked as deleted: Consistency: max_cardinality_1_without_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] p <rdfs:subPropertyOf> <knora-base:objectCannotBeMarkedAsDeleted> i p j [Constraint j != k] i p k [Cut] ------------------------------------ To check owl:minCardinality 1 , we do not care whether the object can be marked as deleted, so we can use this simple rule: Consistency: min_cardinality_1_any_object i p r [Context <onto:_minCardinality_1_table>] ------------------------------------ i p j This means: if a subject i belongs to a class that has owl:minCardinality 1 on property p , and i has no object for p , the rule is violated. To check owl:cardinality 1 , we need two rules: one that checks whether there are too few objects, and one that checks whether there are too many. To check whether there are too few objects, we don't care whether the objects can be marked as deleted, so the rule is the same as min_cardinality_1_any_object , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j To check whether there are too many objects, we need to know whether the objects can be marked as deleted or not. In the case where the objects can be marked as deleted, the rule is the same as max_cardinality_1_with_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_greater_with_deletion_flag i p r [Context <onto:_cardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ In the case where the objects cannot be marked as deleted, the rule is the same as max_cardinality_1_without_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j Knora allows a subproperty of knora-base:hasValue or knora-base:hasLinkTo to be a predicate of a resource only if the resource's class has some cardinality for the property. For convenience, knora-base:hasValue and knora-base:hasLinkTo are subproperties of knora-base:resourceProperty , which is used to check this constraint in the following rule: Consistency: resource_prop_cardinality_any i <knora-base:resourceProperty> j ------------------------------------ i p j i <rdf:type> r r <owl:onProperty> p If resource i has a subproperty of knora-base:resourceProperty , and i is not a member of a subclass of an owl:Restriction r with a cardinality on that property (or on one of its base properties), the rule is violated. A similar rule, value_prop_cardinality_any , ensures that if a value has a subproperty of knora-base:valueHas , the value's class has some cardinality for that property.","title":"Cardinality constraints"},{"location":"DSP-API/05-internals/design/principles/design-overview/","text":"DSP-API Server Design Overview Introduction Knora's responsibilities include: Receiving, validating, authenticating, and authorising HTTP requests from clients (which may be web browsers or other software) to query or update data in a Knora repository. Querying and updating the repository on behalf of clients. Filtering query results according to the user's permissions. Transforming query results into DSP-API responses. Ensuring that ontologies and data in the triplestore are consistent and conform to the requirements of the knora-base ontology. Managing the versioning of data in the triplestore. Working with Sipi to store files that cannot be stored as RDF data. Knora is written in Scala , using the Akka framework for message-based concurrency. It is designed to work with any standards-compliant triplestore via the SPARQL 1.1 Protocol , but is currently tested only with Ontotext GraphDB (with support for other triplestores coming soon). Knora APIs Knora supports different versions of its API for working with humanities data: DSP-API v2 , a standards-based API currently under development. DSP-API v1 , a stable, legacy API that focuses on maintaining compatibility with applications that used Knora's prototype software. There is also a Knora admin API for administering Knora repositories. The Knora code base includes some functionality that is shared by these different APIs, as well as separate packages for each API. Internally, Knora APIs v1 and v2 both use functionality in the admin API. DSP-API v1 uses some functionality from API v2, but API v2 does not depend on API v1. Design Diagram Modules HTTP Module org.knora.webapi.routing : Knora's Akka HTTP routes. Each routing class matches URL patterns for requests involving some particular type of data in the repository. Routes are API-specific. For example, ResourcesRouteV2 matches URL paths starting with /v2/resources , which represent requests involving Knora resources. org.knora.webapi.http : a few HTTP-related constants and utilities. Responders Module org.knora.webapi.responders : Each responder is an actor that is responsible for managing some particular type of data in the repository. A responder receives messages from a route, does some work (e.g. querying the triplestore), and returns a reply message. Responders are API-specific and can communicate with other responders via messages. For example, in API v2, ResourcesResponderV2 handles requests involving resources, and delegates some of its tasks to ValuesResponderV2 , which is responsible for requests involving values. Store Module org.knora.webapi.store : Contains actors that connect to triplestores. The most important one is HttpTriplestoreConnector , which communicates with triplestores via the SPARQL 1.1 Protocol . Shared Between Modules org.knora.webapi : Contains core classes such as Main , which starts the Knora server, and SettingsImpl , which represents the application settings that are loaded using the Typesafe Config library. org.knora.webapi.util : Utilities needed by different parts of the application, such as parsing and formatting tools. org.knora.webapi.messages : The Akka messages used by each responder. org.knora.webapi.messages.twirl : Text-generation templates for use with the Twirl template engine . Knora uses Twirl to generate SPARQL requests and other types of text documents. Actor Supervision and Creation At system start, the main application supervisor actor is created in LiveCore.scala : /** * The main application supervisor actor which is at the top of the actor * hierarchy. All other actors are instantiated as child actors. Further, * this actor is responsible for the execution of the startup and shutdown * sequences. */ lazy val appActor: ActorRef = system.actorOf( Props(new ApplicationActor with LiveManagers) .withDispatcher(KnoraDispatchers.KnoraActorDispatcher), name = APPLICATION_MANAGER_ACTOR_NAME ) and through mixin also the store and responder manager actors: /** * The actor that forwards messages to actors that deal with persistent storage. */ lazy val storeManager: ActorRef = context.actorOf( Props(new StoreManager(self) with LiveActorMaker) .withDispatcher(KnoraDispatchers.KnoraActorDispatcher), name = StoreManagerActorName ) /** * The actor that forwards messages to responder actors to handle API requests. */ lazy val responderManager: ActorRef = context.actorOf( Props(new ResponderManager(self) with LiveActorMaker) .withDispatcher(KnoraDispatchers.KnoraActorDispatcher), name = RESPONDER_MANAGER_ACTOR_NAME ) The ApplicationActor is the first actor in the application. All other actors are children of this actor and thus it takes also the role of the supervisor actor. It accepts messages for starting and stopping the Knora-API, holds the current state of the application, and is responsible for coordination of the startup and shutdown sequence. Further, it forwards any messages meant for responders or the store to the respective actor. In most cases, there is only one instance of each supervised actor; such actors do their work asynchronously in futures, so there would be no advantage in using an actor pool. A few actors do have pools of instances, because they do their work synchronously; this allows concurrency to be controlled by setting the size of each pool. These pools are configured in application.conf under akka.actor.deployment . The ApplicationActor also starts the HTTP service as part of the startup sequence: /** * Starts the Knora-API server. * * @param ignoreRepository if `true`, don't read anything from the repository on startup. * @param requiresIIIFService if `true`, ensure that the IIIF service is started. * @param retryCnt how many times was this command tried */ def appStart(ignoreRepository: Boolean, requiresIIIFService: Boolean, retryCnt: Int): Unit = { val bindingFuture: Future[Http.ServerBinding] = Http() .bindAndHandle( Route.handlerFlow(apiRoutes), knoraSettings.internalKnoraApiHost, knoraSettings.internalKnoraApiPort ) bindingFuture onComplete { case Success(_) => // Transition to ready state self ! AppReady() if (knoraSettings.prometheusEndpoint) { // Load Kamon monitoring Kamon.loadModules() } // Kick of startup procedure. self ! InitStartUp(ignoreRepository, requiresIIIFService) case Failure(ex) => if (retryCnt < 5) { logger.error( \"Failed to bind to {}:{}! - {} - retryCnt: {}\", knoraSettings.internalKnoraApiHost, knoraSettings.internalKnoraApiPort, ex.getMessage, retryCnt ) self ! AppStart(ignoreRepository, requiresIIIFService, retryCnt + 1) } else { logger.error( \"Failed to bind to {}:{}! - {}\", knoraSettings.internalKnoraApiHost, knoraSettings.internalKnoraApiPort, ex.getMessage ) self ! AppStop() } } } Coordinated Application Startup To coordinate necessary startup tasks, the application goes through a few states at startup: Stopped: Application starting. Http layer is still not started. StartingUp: Http layer is started. Only '/health' and monitoring routes are working. WaitingForRepository: Repository check is initiated but not yet finished. RepositoryReady: Repository check has finished and repository is available. CreatingCaches: Creating caches is initiated but not yet finished. CachesReady: Caches are created and ready for use. LoadingOntologies: Loading of ontologies is initiated but not yet finished. OntologiesReady: Ontologies are loaded. MaintenanceMode: During backup or other maintenance tasks, so that access to the API is closed Running: Running state. All APIs are open. During the WaitingForRepository state, if the repository is not configured or available, the system will indefinitely retry to access it. This allows for prolonged startup times of the repository. Also, if checking the repository returns an error, e.g., because the repository data needs to be migrated first, the application will shutdown. Concurrency In general, Knora is written in a functional style, avoiding shared mutable state. This makes it easier to reason about concurrency, and eliminates an important potential source of bugs (see Out of the Tar Pit ). The routes and actors in Knora use Akka's ask pattern, rather than the tell pattern, to send messages and receive responses, because this simplifies the code considerably (using tell would require actors to maintain complex mutable state), with no apparent reduction in performance. To manage asynchronous communication between actors, the DSP-API server uses Scala's Future monad extensively. See Futures with Akka for details. We use Akka's asynchronous logging interface (see Akka Logging ). What the Responders Do In Knora, a responder is an actor that receives a request message (a Scala case class) in the ask pattern, does some work (e.g. getting data from the triplestore), and returns a reply message (another case class). These reply messages are are defined in org.knora.webapi.messages . A responder can produce a reply representing a complete API response, or part of a response that will be used by another responder. If it's a complete API response, there is an API-specific mechanism for converting it into the response format that the client expects. Store Module (org.knora.webapi.store package) The store module is used for accessing the triplestore and other external storage providers. All access to the Store module goes through the StoreManager supervisor actor. The StoreManager creates pools of actors, such as HttpTriplestoreActor , that interface with the storage providers. The contents of the store package are not used directly by other packages, which interact with the store package only by sending messages to StoreManager . Parsing of SPARQL query results is handled by this module. See Store Module for a more detailed discussion. Triplestore Access SPARQL queries are generated from templates, using the Twirl template engine. For example, if we're querying a resource, the template will contain a placeholder for the resource's IRI. The templates can be found under src/main/twirl/queries/sparql . In many cases, different SPARQL must be generated for different triplestores; the Twirl template function then takes the name of the triplestore as a parameter, and may delegate to triplestore-specific templates. Responders are not expected to know which triplestore is being used or how it is accessed. To perform a SPARQL SELECT query, a responder sends a SparqlSelectRequest message to the storeManager actor, like this: for { isEntityUsedSparql <- Future(queries.sparql.v2.txt.isEntityUsed( triplestore = settings.triplestoreType, entityIri = entityIri, ignoreKnoraConstraints = ignoreKnoraConstraints, ignoreRdfSubjectAndObject = ignoreRdfSubjectAndObject ).toString()) isEntityUsedResponse: SparqlSelectResponse <- (storeManager ? SparqlSelectRequest(isEntityUsedSparql)).mapTo[SparqlSelectResponse] The reply message, SparqlSelectResponse , is a data structure containing the rows that were returned as the query result. To perform a SPARQL CONSTRUCT query, you can use SparqlExtendedConstructRequest , and the response will be a SparqlExtendedConstructResponse . Error Handling The error-handling design has these aims: Simplify the error-handling code in actors as much as possible. Produce error messages that clearly indicate the context in which the error occurred (i.e. what the application was trying to do). Ensure that clients receive an appropriate error message when an error occurs. Ensure that ask requests are properly terminated with an akka.actor.Status.Failure message in the event of an error, without which they will simply time out (see Ask: Send and Receive Future ). When a actor encounters an error that isn't the client's fault (e.g. a triplestore failure), log it, but don't do this with errors caused by bad input. When logging errors, include the full JVM stack trace. The design does not yet include, but could easily accommodate, translations of error messages into different languages. A hierarchy of exception classes is defined in Exceptions.scala , representing different sorts of errors that could occur. The hierarchy has two main branches: RequestRejectedException , an abstract class for errors that are the client's fault. These errors are not logged. InternalServerException , an abstract class for errors that are not the client's fault. These errors are logged. Exception classes in this hierarchy can be defined to include a wrapped cause exception. When an exception is logged, its stack trace will be logged along with the stack trace of its cause . It is therefore recommended that low-level code should catch low-level exceptions, and wrap them in one of our higher-level exceptions, in order to clarify the context in which the error occurred. To simplify error-handling in responders, a utility method called future2Message is provided in ActorUtils . It is intended to be used in an actor's receive method to respond to messages in the ask pattern. If the responder's computation is successful, it is sent to the requesting actor as a response to the ask . If the computation fails, the exception representing the failure is wrapped in a Status.Failure , which is sent as a response to the ask . If the error is a subclass of RequestRejectedException , only the sender is notified of the error; otherwise, the error is also logged and rethrown (so that the KnoraExceptionHandler can handle the exception). In many cases, we transform data from the triplestore into a Map object. To simplify checking for required values in these collections, the class ErrorHandlingMap is provided. You can wrap any Map in an ErrorHandlingMap . You must provide a function that will generate an error message when a required value is missing, and optionally a function that throws a particular exception. Rows of SPARQL query results are already returned in ErrorHandlingMap objects. If you want to add a new exception class, see the comments in Exceptions.scala for instructions. Transformation of Exception to Client Responses The org.knora.webapi.KnoraExceptionHandler is brought implicitly into scope of akka-http , and by doing so registered and used to handle the transformation of all KnoraExceptions into HttpResponses . This handler handles only exceptions thrown inside the route and not the actors. However, the design of reply message passing from actors (by using future2Message ), makes sure that any exceptions thrown inside actors, will reach the route, where they will be handled. See also Fuures with Akka . API Routing The API routes in the routing package are defined using the DSL provided by the akka-http library. A routing function has to do the following: Authenticate the client. Figure out what the client is asking for. Construct an appropriate request message and send it to ResponderManagerV1 , using the ask pattern. Return a result to the client. To simplify the coding of routing functions, they are contained in objects that extend org.knora.webapi.routing.Authenticator . Each routing function performs the following operations: Authenticator.getUserADM is called to authenticate the user. The request parameters are interpreted and validated, and a request message is constructed to send to the responder. If the request is invalid, BadRequestException is thrown. If the request message is requesting an update operation, it must include a UUID generated by UUID.randomUUID , so the responder can obtain a write lock on the resource being updated. The routing function then passes the message to a function in an API-specific routing utility: RouteUtilV1 , RouteUtilV2 , or RouteUtilADM . This utility function sends the message to ResponderManager (which forwards it to the relevant responder), returns a response to the client in the appropriate format, and handles any errors. Logging Logging in Knora is configurable through logback.xml , allowing fine grain configuration of what classes / objects should be logged from which level. The Akka Actors use Akka Logging while logging inside plain Scala Objects and Classes is done through Scala Logging .","title":"Design Overview"},{"location":"DSP-API/05-internals/design/principles/design-overview/#dsp-api-server-design-overview","text":"","title":"DSP-API Server Design Overview"},{"location":"DSP-API/05-internals/design/principles/design-overview/#introduction","text":"Knora's responsibilities include: Receiving, validating, authenticating, and authorising HTTP requests from clients (which may be web browsers or other software) to query or update data in a Knora repository. Querying and updating the repository on behalf of clients. Filtering query results according to the user's permissions. Transforming query results into DSP-API responses. Ensuring that ontologies and data in the triplestore are consistent and conform to the requirements of the knora-base ontology. Managing the versioning of data in the triplestore. Working with Sipi to store files that cannot be stored as RDF data. Knora is written in Scala , using the Akka framework for message-based concurrency. It is designed to work with any standards-compliant triplestore via the SPARQL 1.1 Protocol , but is currently tested only with Ontotext GraphDB (with support for other triplestores coming soon).","title":"Introduction"},{"location":"DSP-API/05-internals/design/principles/design-overview/#knora-apis","text":"Knora supports different versions of its API for working with humanities data: DSP-API v2 , a standards-based API currently under development. DSP-API v1 , a stable, legacy API that focuses on maintaining compatibility with applications that used Knora's prototype software. There is also a Knora admin API for administering Knora repositories. The Knora code base includes some functionality that is shared by these different APIs, as well as separate packages for each API. Internally, Knora APIs v1 and v2 both use functionality in the admin API. DSP-API v1 uses some functionality from API v2, but API v2 does not depend on API v1.","title":"Knora APIs"},{"location":"DSP-API/05-internals/design/principles/design-overview/#design-diagram","text":"","title":"Design Diagram"},{"location":"DSP-API/05-internals/design/principles/design-overview/#modules","text":"","title":"Modules"},{"location":"DSP-API/05-internals/design/principles/design-overview/#http-module","text":"org.knora.webapi.routing : Knora's Akka HTTP routes. Each routing class matches URL patterns for requests involving some particular type of data in the repository. Routes are API-specific. For example, ResourcesRouteV2 matches URL paths starting with /v2/resources , which represent requests involving Knora resources. org.knora.webapi.http : a few HTTP-related constants and utilities.","title":"HTTP Module"},{"location":"DSP-API/05-internals/design/principles/design-overview/#responders-module","text":"org.knora.webapi.responders : Each responder is an actor that is responsible for managing some particular type of data in the repository. A responder receives messages from a route, does some work (e.g. querying the triplestore), and returns a reply message. Responders are API-specific and can communicate with other responders via messages. For example, in API v2, ResourcesResponderV2 handles requests involving resources, and delegates some of its tasks to ValuesResponderV2 , which is responsible for requests involving values.","title":"Responders Module"},{"location":"DSP-API/05-internals/design/principles/design-overview/#store-module","text":"org.knora.webapi.store : Contains actors that connect to triplestores. The most important one is HttpTriplestoreConnector , which communicates with triplestores via the SPARQL 1.1 Protocol .","title":"Store Module"},{"location":"DSP-API/05-internals/design/principles/design-overview/#shared-between-modules","text":"org.knora.webapi : Contains core classes such as Main , which starts the Knora server, and SettingsImpl , which represents the application settings that are loaded using the Typesafe Config library. org.knora.webapi.util : Utilities needed by different parts of the application, such as parsing and formatting tools. org.knora.webapi.messages : The Akka messages used by each responder. org.knora.webapi.messages.twirl : Text-generation templates for use with the Twirl template engine . Knora uses Twirl to generate SPARQL requests and other types of text documents.","title":"Shared Between Modules"},{"location":"DSP-API/05-internals/design/principles/design-overview/#actor-supervision-and-creation","text":"At system start, the main application supervisor actor is created in LiveCore.scala : /** * The main application supervisor actor which is at the top of the actor * hierarchy. All other actors are instantiated as child actors. Further, * this actor is responsible for the execution of the startup and shutdown * sequences. */ lazy val appActor: ActorRef = system.actorOf( Props(new ApplicationActor with LiveManagers) .withDispatcher(KnoraDispatchers.KnoraActorDispatcher), name = APPLICATION_MANAGER_ACTOR_NAME ) and through mixin also the store and responder manager actors: /** * The actor that forwards messages to actors that deal with persistent storage. */ lazy val storeManager: ActorRef = context.actorOf( Props(new StoreManager(self) with LiveActorMaker) .withDispatcher(KnoraDispatchers.KnoraActorDispatcher), name = StoreManagerActorName ) /** * The actor that forwards messages to responder actors to handle API requests. */ lazy val responderManager: ActorRef = context.actorOf( Props(new ResponderManager(self) with LiveActorMaker) .withDispatcher(KnoraDispatchers.KnoraActorDispatcher), name = RESPONDER_MANAGER_ACTOR_NAME ) The ApplicationActor is the first actor in the application. All other actors are children of this actor and thus it takes also the role of the supervisor actor. It accepts messages for starting and stopping the Knora-API, holds the current state of the application, and is responsible for coordination of the startup and shutdown sequence. Further, it forwards any messages meant for responders or the store to the respective actor. In most cases, there is only one instance of each supervised actor; such actors do their work asynchronously in futures, so there would be no advantage in using an actor pool. A few actors do have pools of instances, because they do their work synchronously; this allows concurrency to be controlled by setting the size of each pool. These pools are configured in application.conf under akka.actor.deployment . The ApplicationActor also starts the HTTP service as part of the startup sequence: /** * Starts the Knora-API server. * * @param ignoreRepository if `true`, don't read anything from the repository on startup. * @param requiresIIIFService if `true`, ensure that the IIIF service is started. * @param retryCnt how many times was this command tried */ def appStart(ignoreRepository: Boolean, requiresIIIFService: Boolean, retryCnt: Int): Unit = { val bindingFuture: Future[Http.ServerBinding] = Http() .bindAndHandle( Route.handlerFlow(apiRoutes), knoraSettings.internalKnoraApiHost, knoraSettings.internalKnoraApiPort ) bindingFuture onComplete { case Success(_) => // Transition to ready state self ! AppReady() if (knoraSettings.prometheusEndpoint) { // Load Kamon monitoring Kamon.loadModules() } // Kick of startup procedure. self ! InitStartUp(ignoreRepository, requiresIIIFService) case Failure(ex) => if (retryCnt < 5) { logger.error( \"Failed to bind to {}:{}! - {} - retryCnt: {}\", knoraSettings.internalKnoraApiHost, knoraSettings.internalKnoraApiPort, ex.getMessage, retryCnt ) self ! AppStart(ignoreRepository, requiresIIIFService, retryCnt + 1) } else { logger.error( \"Failed to bind to {}:{}! - {}\", knoraSettings.internalKnoraApiHost, knoraSettings.internalKnoraApiPort, ex.getMessage ) self ! AppStop() } } }","title":"Actor Supervision and Creation"},{"location":"DSP-API/05-internals/design/principles/design-overview/#coordinated-application-startup","text":"To coordinate necessary startup tasks, the application goes through a few states at startup: Stopped: Application starting. Http layer is still not started. StartingUp: Http layer is started. Only '/health' and monitoring routes are working. WaitingForRepository: Repository check is initiated but not yet finished. RepositoryReady: Repository check has finished and repository is available. CreatingCaches: Creating caches is initiated but not yet finished. CachesReady: Caches are created and ready for use. LoadingOntologies: Loading of ontologies is initiated but not yet finished. OntologiesReady: Ontologies are loaded. MaintenanceMode: During backup or other maintenance tasks, so that access to the API is closed Running: Running state. All APIs are open. During the WaitingForRepository state, if the repository is not configured or available, the system will indefinitely retry to access it. This allows for prolonged startup times of the repository. Also, if checking the repository returns an error, e.g., because the repository data needs to be migrated first, the application will shutdown.","title":"Coordinated Application Startup"},{"location":"DSP-API/05-internals/design/principles/design-overview/#concurrency","text":"In general, Knora is written in a functional style, avoiding shared mutable state. This makes it easier to reason about concurrency, and eliminates an important potential source of bugs (see Out of the Tar Pit ). The routes and actors in Knora use Akka's ask pattern, rather than the tell pattern, to send messages and receive responses, because this simplifies the code considerably (using tell would require actors to maintain complex mutable state), with no apparent reduction in performance. To manage asynchronous communication between actors, the DSP-API server uses Scala's Future monad extensively. See Futures with Akka for details. We use Akka's asynchronous logging interface (see Akka Logging ).","title":"Concurrency"},{"location":"DSP-API/05-internals/design/principles/design-overview/#what-the-responders-do","text":"In Knora, a responder is an actor that receives a request message (a Scala case class) in the ask pattern, does some work (e.g. getting data from the triplestore), and returns a reply message (another case class). These reply messages are are defined in org.knora.webapi.messages . A responder can produce a reply representing a complete API response, or part of a response that will be used by another responder. If it's a complete API response, there is an API-specific mechanism for converting it into the response format that the client expects.","title":"What the Responders Do"},{"location":"DSP-API/05-internals/design/principles/design-overview/#store-module-orgknorawebapistore-package","text":"The store module is used for accessing the triplestore and other external storage providers. All access to the Store module goes through the StoreManager supervisor actor. The StoreManager creates pools of actors, such as HttpTriplestoreActor , that interface with the storage providers. The contents of the store package are not used directly by other packages, which interact with the store package only by sending messages to StoreManager . Parsing of SPARQL query results is handled by this module. See Store Module for a more detailed discussion.","title":"Store Module (org.knora.webapi.store package)"},{"location":"DSP-API/05-internals/design/principles/design-overview/#triplestore-access","text":"SPARQL queries are generated from templates, using the Twirl template engine. For example, if we're querying a resource, the template will contain a placeholder for the resource's IRI. The templates can be found under src/main/twirl/queries/sparql . In many cases, different SPARQL must be generated for different triplestores; the Twirl template function then takes the name of the triplestore as a parameter, and may delegate to triplestore-specific templates. Responders are not expected to know which triplestore is being used or how it is accessed. To perform a SPARQL SELECT query, a responder sends a SparqlSelectRequest message to the storeManager actor, like this: for { isEntityUsedSparql <- Future(queries.sparql.v2.txt.isEntityUsed( triplestore = settings.triplestoreType, entityIri = entityIri, ignoreKnoraConstraints = ignoreKnoraConstraints, ignoreRdfSubjectAndObject = ignoreRdfSubjectAndObject ).toString()) isEntityUsedResponse: SparqlSelectResponse <- (storeManager ? SparqlSelectRequest(isEntityUsedSparql)).mapTo[SparqlSelectResponse] The reply message, SparqlSelectResponse , is a data structure containing the rows that were returned as the query result. To perform a SPARQL CONSTRUCT query, you can use SparqlExtendedConstructRequest , and the response will be a SparqlExtendedConstructResponse .","title":"Triplestore Access"},{"location":"DSP-API/05-internals/design/principles/design-overview/#error-handling","text":"The error-handling design has these aims: Simplify the error-handling code in actors as much as possible. Produce error messages that clearly indicate the context in which the error occurred (i.e. what the application was trying to do). Ensure that clients receive an appropriate error message when an error occurs. Ensure that ask requests are properly terminated with an akka.actor.Status.Failure message in the event of an error, without which they will simply time out (see Ask: Send and Receive Future ). When a actor encounters an error that isn't the client's fault (e.g. a triplestore failure), log it, but don't do this with errors caused by bad input. When logging errors, include the full JVM stack trace. The design does not yet include, but could easily accommodate, translations of error messages into different languages. A hierarchy of exception classes is defined in Exceptions.scala , representing different sorts of errors that could occur. The hierarchy has two main branches: RequestRejectedException , an abstract class for errors that are the client's fault. These errors are not logged. InternalServerException , an abstract class for errors that are not the client's fault. These errors are logged. Exception classes in this hierarchy can be defined to include a wrapped cause exception. When an exception is logged, its stack trace will be logged along with the stack trace of its cause . It is therefore recommended that low-level code should catch low-level exceptions, and wrap them in one of our higher-level exceptions, in order to clarify the context in which the error occurred. To simplify error-handling in responders, a utility method called future2Message is provided in ActorUtils . It is intended to be used in an actor's receive method to respond to messages in the ask pattern. If the responder's computation is successful, it is sent to the requesting actor as a response to the ask . If the computation fails, the exception representing the failure is wrapped in a Status.Failure , which is sent as a response to the ask . If the error is a subclass of RequestRejectedException , only the sender is notified of the error; otherwise, the error is also logged and rethrown (so that the KnoraExceptionHandler can handle the exception). In many cases, we transform data from the triplestore into a Map object. To simplify checking for required values in these collections, the class ErrorHandlingMap is provided. You can wrap any Map in an ErrorHandlingMap . You must provide a function that will generate an error message when a required value is missing, and optionally a function that throws a particular exception. Rows of SPARQL query results are already returned in ErrorHandlingMap objects. If you want to add a new exception class, see the comments in Exceptions.scala for instructions.","title":"Error Handling"},{"location":"DSP-API/05-internals/design/principles/design-overview/#transformation-of-exception-to-client-responses","text":"The org.knora.webapi.KnoraExceptionHandler is brought implicitly into scope of akka-http , and by doing so registered and used to handle the transformation of all KnoraExceptions into HttpResponses . This handler handles only exceptions thrown inside the route and not the actors. However, the design of reply message passing from actors (by using future2Message ), makes sure that any exceptions thrown inside actors, will reach the route, where they will be handled. See also Fuures with Akka .","title":"Transformation of Exception to Client Responses"},{"location":"DSP-API/05-internals/design/principles/design-overview/#api-routing","text":"The API routes in the routing package are defined using the DSL provided by the akka-http library. A routing function has to do the following: Authenticate the client. Figure out what the client is asking for. Construct an appropriate request message and send it to ResponderManagerV1 , using the ask pattern. Return a result to the client. To simplify the coding of routing functions, they are contained in objects that extend org.knora.webapi.routing.Authenticator . Each routing function performs the following operations: Authenticator.getUserADM is called to authenticate the user. The request parameters are interpreted and validated, and a request message is constructed to send to the responder. If the request is invalid, BadRequestException is thrown. If the request message is requesting an update operation, it must include a UUID generated by UUID.randomUUID , so the responder can obtain a write lock on the resource being updated. The routing function then passes the message to a function in an API-specific routing utility: RouteUtilV1 , RouteUtilV2 , or RouteUtilADM . This utility function sends the message to ResponderManager (which forwards it to the relevant responder), returns a response to the client in the appropriate format, and handles any errors.","title":"API Routing"},{"location":"DSP-API/05-internals/design/principles/design-overview/#logging","text":"Logging in Knora is configurable through logback.xml , allowing fine grain configuration of what classes / objects should be logged from which level. The Akka Actors use Akka Logging while logging inside plain Scala Objects and Classes is done through Scala Logging .","title":"Logging"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/","text":"Feature Toggles For an overview of feature toggles, see Feature Toggles (aka Feature Flags) . The design presented here is partly inspired by that article. Requirements It should be possible to turn features on and off by: changing a setting in application.conf sending a particular HTTP header value with an API request (in the future) using a web-based user interface to configure a feature toggle service that multiple subsystems can access Feature implementations should be produced by factory classes, so that the code using a feature does not need to know about the toggling decision. Feature factories should use toggle configuration taken from different sources, without knowing where the configuration came from. An HTTP response should indicate which features are turned on. A feature toggle should have metadata such as a description, an expiration date, developer contact information, etc. A feature toggle should have a version number, so you can get different versions of the same feature. It should be possible to configure a toggle in application.conf so that its setting cannot be overridden per request. The design of feature toggles should avoid ambiguity and try to prevent situations where clients might be surprised by unexpected functionality. It should be clear what will change when a client requests a particular toggle setting. Therefore, per-request settings should require the client to be explicit about what is being requested. Design Configuration Base Configuration The base configuration of feature toggles is in application.conf under app.feature-toggles . Example: app { feature-toggles { new-foo { description = \"Replace the old foo routes with new ones.\" available-versions = [ 1, 2 ] default-version = 1 enabled-by-default = yes override-allowed = yes expiration-date = \"2021-12-01T00:00:00Z\" developer-emails = [ \"A developer <a.developer@example.org>\" ] } new-bar { description = \"Replace the old bar routes with new ones.\" available-versions = [ 1, 2, 3 ] default-version = 3 enabled-by-default = yes override-allowed = yes expiration-date = \"2021-12-01T00:00:00Z\" developer-emails = [ \"A developer <a.developer@example.org>\" ] } fast-baz { description = \"Replace the slower, more accurate baz route with a faster, less accurate one.\" available-versions = [ 1 ] default-version = 1 enabled-by-default = no override-allowed = yes developer-emails = [ \"A developer <a.developer@example.org>\" ] } } } All fields are required except expiration-date . Since it may not be possible to predict which toggles will need versions, all toggles must have at least one version. (If a toggle could be created without versions, and then get versions later, it would not be obvious what should happen if a client then requested the toggle without specifying a version number.) Version numbers must be an ascending sequence of consecutive integers starting from 1. If expiration-date is provided, it must be an xsd:dateTimeStamp . All feature toggles should have expiration dates except for long-lived ops toggles like fast-baz above. KnoraSettingsFeatureFactoryConfig reads this base configuration on startup. If a feature toggle has an expiration date in the past, a warning is logged on startup. Per-Request Configuration A client can override the base configuration by submitting the HTTP header X-Knora-Feature-Toggles . Its value is a comma-separated list of toggles. Each toggle consists of: its name a colon the version number an equals sign a boolean value, which can be on / off , yes / no , or true / false Using on / off is recommended for clarity. For example: X-Knora-Feature-Toggles: new-foo:2=on,new-bar=off,fast-baz:1=on A version number must be given when enabling a toggle. Only one version of each toggle can be enabled at a time. If a toggle is enabled by default, and you want a version other than the default version, simply enable the toggle, specifying the desired version number. The version number you specify overrides the default. Disabling a toggle means disabling all its versions. When a toggle is disabled, you will get the functionality that you would have got before the toggle existed. A version number cannot be given when disabling a toggle, because it would not be obvious what this would mean (disable all versions or only the specified version). Response Header DSP-API v2 and admin API responses contain the header X-Knora-Feature-Toggles . It lists all configured toggles, in the same format as the corresponding request header. Implementation Framework A FeatureFactoryConfig reads feature toggles from some configuration source, and optionally delegates to a parent FeatureFactoryConfig . KnoraRoute constructs a KnoraSettingsFeatureFactoryConfig to read the base configuration. For each request, it constructs a RequestContextFeatureFactoryConfig , which reads the per-request configuration and has the KnoraSettingsFeatureFactoryConfig as its parent. It then passes the per-request configuration object to the makeRoute method, which can in turn pass it to a feature factory, or send it in a request message to allow a responder to use it. Feature Factories The traits FeatureFactory and Feature are just tagging traits, to make code clearer. The factory methods in a feature factory will depend on the feature, and need only be known by the code that uses the feature. The only requirement is that each factory method must take a FeatureFactoryConfig parameter. To get a FeatureToggle , a feature factory calls featureFactoryConfig.getToggle , passing the name of the toggle. If a feature toggle has only one version, it is enough to test whether test if the toggle is enabled, by calling isEnabled on the toggle. If the feature toggle has more than one version, call its getMatchableState method. To allow the compiler to check that matches on version numbers are exhaustive, this method is designed to be used with a sealed trait (extending Version ) that is implemented by case objects representing the feature's version numbers. The method returns an instance of MatchableState , which is analogous to Option : it is either Off or On , and an instance of On contains one of the version objects. For example: // A trait for version numbers of the new 'foo' feature. sealed trait NewFooVersion extends Version // Represents version 1 of the new 'foo' feature. case object NEW_FOO_1 extends NewFooVersion // Represents version 2 of the new 'foo' feature. case object NEW_FOO_2 extends NewFooVersion // The old 'foo' feature implementation. private val oldFoo = new OldFooFeature // The new 'foo' feature implementation, version 1. private val newFoo1 = new NewFooVersion1Feature // The new 'foo' feature implementation, version 2. private val newFoo2 = new NewFooVersion2Feature def makeFoo(featureFactoryConfig: FeatureFactoryConfig): Foo = { // Get the 'new-foo' feature toggle. val fooToggle: FeatureToggle = featureFactoryConfig.getToggle(\"new-foo\") // Choose an implementation according to the toggle state. fooToggle.getMatchableState(NEW_FOO_1, NEW_FOO_2) match { case Off => oldFoo case On(NEW_FOO_1) => newFoo1 case On(NEW_FOO_2) => newFoo2 } } Routes as Features To select different routes according to a feature toggle: Make a feature factory that extends KnoraRouteFactory and FeatureFactory , and has a makeRoute method that returns different implementations, each of which extends KnoraRoute and Feature . Make a fa\u00e7ade route that extends KnoraRoute , is used in ApplicationActor.apiRoutes , and has a makeRoute method that delegates to the feature factory. To avoid constructing redundant route instances, each fa\u00e7ade route needs its own feature factory class. Documenting a Feature Toggle The behaviour of each possible setting of each feature toggle should be documented. Feature toggles that are configurable per request should be described in the release notes. Removing a Feature Toggle To facilitate removing a feature toggle, each implementation should have: a separate file for its source code a separate file for its documentation When the toggle is removed, the files that are no longer needed can be deleted.","title":"Feature Toggles"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#feature-toggles","text":"For an overview of feature toggles, see Feature Toggles (aka Feature Flags) . The design presented here is partly inspired by that article.","title":"Feature Toggles"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#requirements","text":"It should be possible to turn features on and off by: changing a setting in application.conf sending a particular HTTP header value with an API request (in the future) using a web-based user interface to configure a feature toggle service that multiple subsystems can access Feature implementations should be produced by factory classes, so that the code using a feature does not need to know about the toggling decision. Feature factories should use toggle configuration taken from different sources, without knowing where the configuration came from. An HTTP response should indicate which features are turned on. A feature toggle should have metadata such as a description, an expiration date, developer contact information, etc. A feature toggle should have a version number, so you can get different versions of the same feature. It should be possible to configure a toggle in application.conf so that its setting cannot be overridden per request. The design of feature toggles should avoid ambiguity and try to prevent situations where clients might be surprised by unexpected functionality. It should be clear what will change when a client requests a particular toggle setting. Therefore, per-request settings should require the client to be explicit about what is being requested.","title":"Requirements"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#design","text":"","title":"Design"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#configuration","text":"","title":"Configuration"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#base-configuration","text":"The base configuration of feature toggles is in application.conf under app.feature-toggles . Example: app { feature-toggles { new-foo { description = \"Replace the old foo routes with new ones.\" available-versions = [ 1, 2 ] default-version = 1 enabled-by-default = yes override-allowed = yes expiration-date = \"2021-12-01T00:00:00Z\" developer-emails = [ \"A developer <a.developer@example.org>\" ] } new-bar { description = \"Replace the old bar routes with new ones.\" available-versions = [ 1, 2, 3 ] default-version = 3 enabled-by-default = yes override-allowed = yes expiration-date = \"2021-12-01T00:00:00Z\" developer-emails = [ \"A developer <a.developer@example.org>\" ] } fast-baz { description = \"Replace the slower, more accurate baz route with a faster, less accurate one.\" available-versions = [ 1 ] default-version = 1 enabled-by-default = no override-allowed = yes developer-emails = [ \"A developer <a.developer@example.org>\" ] } } } All fields are required except expiration-date . Since it may not be possible to predict which toggles will need versions, all toggles must have at least one version. (If a toggle could be created without versions, and then get versions later, it would not be obvious what should happen if a client then requested the toggle without specifying a version number.) Version numbers must be an ascending sequence of consecutive integers starting from 1. If expiration-date is provided, it must be an xsd:dateTimeStamp . All feature toggles should have expiration dates except for long-lived ops toggles like fast-baz above. KnoraSettingsFeatureFactoryConfig reads this base configuration on startup. If a feature toggle has an expiration date in the past, a warning is logged on startup.","title":"Base Configuration"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#per-request-configuration","text":"A client can override the base configuration by submitting the HTTP header X-Knora-Feature-Toggles . Its value is a comma-separated list of toggles. Each toggle consists of: its name a colon the version number an equals sign a boolean value, which can be on / off , yes / no , or true / false Using on / off is recommended for clarity. For example: X-Knora-Feature-Toggles: new-foo:2=on,new-bar=off,fast-baz:1=on A version number must be given when enabling a toggle. Only one version of each toggle can be enabled at a time. If a toggle is enabled by default, and you want a version other than the default version, simply enable the toggle, specifying the desired version number. The version number you specify overrides the default. Disabling a toggle means disabling all its versions. When a toggle is disabled, you will get the functionality that you would have got before the toggle existed. A version number cannot be given when disabling a toggle, because it would not be obvious what this would mean (disable all versions or only the specified version).","title":"Per-Request Configuration"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#response-header","text":"DSP-API v2 and admin API responses contain the header X-Knora-Feature-Toggles . It lists all configured toggles, in the same format as the corresponding request header.","title":"Response Header"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#implementation-framework","text":"A FeatureFactoryConfig reads feature toggles from some configuration source, and optionally delegates to a parent FeatureFactoryConfig . KnoraRoute constructs a KnoraSettingsFeatureFactoryConfig to read the base configuration. For each request, it constructs a RequestContextFeatureFactoryConfig , which reads the per-request configuration and has the KnoraSettingsFeatureFactoryConfig as its parent. It then passes the per-request configuration object to the makeRoute method, which can in turn pass it to a feature factory, or send it in a request message to allow a responder to use it.","title":"Implementation Framework"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#feature-factories","text":"The traits FeatureFactory and Feature are just tagging traits, to make code clearer. The factory methods in a feature factory will depend on the feature, and need only be known by the code that uses the feature. The only requirement is that each factory method must take a FeatureFactoryConfig parameter. To get a FeatureToggle , a feature factory calls featureFactoryConfig.getToggle , passing the name of the toggle. If a feature toggle has only one version, it is enough to test whether test if the toggle is enabled, by calling isEnabled on the toggle. If the feature toggle has more than one version, call its getMatchableState method. To allow the compiler to check that matches on version numbers are exhaustive, this method is designed to be used with a sealed trait (extending Version ) that is implemented by case objects representing the feature's version numbers. The method returns an instance of MatchableState , which is analogous to Option : it is either Off or On , and an instance of On contains one of the version objects. For example: // A trait for version numbers of the new 'foo' feature. sealed trait NewFooVersion extends Version // Represents version 1 of the new 'foo' feature. case object NEW_FOO_1 extends NewFooVersion // Represents version 2 of the new 'foo' feature. case object NEW_FOO_2 extends NewFooVersion // The old 'foo' feature implementation. private val oldFoo = new OldFooFeature // The new 'foo' feature implementation, version 1. private val newFoo1 = new NewFooVersion1Feature // The new 'foo' feature implementation, version 2. private val newFoo2 = new NewFooVersion2Feature def makeFoo(featureFactoryConfig: FeatureFactoryConfig): Foo = { // Get the 'new-foo' feature toggle. val fooToggle: FeatureToggle = featureFactoryConfig.getToggle(\"new-foo\") // Choose an implementation according to the toggle state. fooToggle.getMatchableState(NEW_FOO_1, NEW_FOO_2) match { case Off => oldFoo case On(NEW_FOO_1) => newFoo1 case On(NEW_FOO_2) => newFoo2 } }","title":"Feature Factories"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#routes-as-features","text":"To select different routes according to a feature toggle: Make a feature factory that extends KnoraRouteFactory and FeatureFactory , and has a makeRoute method that returns different implementations, each of which extends KnoraRoute and Feature . Make a fa\u00e7ade route that extends KnoraRoute , is used in ApplicationActor.apiRoutes , and has a makeRoute method that delegates to the feature factory. To avoid constructing redundant route instances, each fa\u00e7ade route needs its own feature factory class.","title":"Routes as Features"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#documenting-a-feature-toggle","text":"The behaviour of each possible setting of each feature toggle should be documented. Feature toggles that are configurable per request should be described in the release notes.","title":"Documenting a Feature Toggle"},{"location":"DSP-API/05-internals/design/principles/feature-toggles/#removing-a-feature-toggle","text":"To facilitate removing a feature toggle, each implementation should have: a separate file for its source code a separate file for its documentation When the toggle is removed, the files that are no longer needed can be deleted.","title":"Removing a Feature Toggle"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/","text":"Futures with Akka Introduction Scala's documentation on futures introduces them in this way: Futures provide a nice way to reason about performing many operations in parallel \u2013 in an efficient and non-blocking way. The idea is simple, a Future is a sort of a placeholder object that you can create for a result that does not yet exist. Generally, the result of the Future is computed concurrently and can be later collected. Composing concurrent tasks in this way tends to result in faster, asynchronous, non-blocking parallel code. The rest of that page is well worth reading to get an overview of how futures work and what you can do with them. In Akka , one of the standard patterns for communication between actors is the ask pattern , in which you send a message to an actor and you expect a reply. When you call the ask function (which can be written as a question mark, ? , which acts as an infix operator), it immediately returns a Future , which will complete when the reply is sent. As the Akka documentation explains in Use with Actors , it is possible to block the calling thread until the future completes, using Await.result . However, they say: 'Blocking is discouraged though as it will cause performance problems.' In particular, by not blocking, you can do several ask requests in parallel. One way to avoid blocking is to register a callback on the future, which will be called when it completes (perhaps by another thread), like this: future.onComplete { case Success(result) => println(result) case Failure(ex) => ex.printStackTrace() } But this won't work if you're writing a method that needs return a value based on the result of a future. In this case, you can register a callback that transforms the result of a future into another future: val newFuture = future.map(x => x + 1) However, registering callbacks explicitly gets cumbersome when you need to work with several futures together. In this case, the most convenient alternative to blocking is to use Future as a monad. The links above explain what this means in detail, but the basic idea is that a special syntax, called a for -comprehension, allows you to write code that uses futures as if they were complete, without blocking. In reality, a for -comprehension is syntactic sugar for calling methods like map , but it's much easier to write and to read. You can do things like this: val fooFuture = (fooActor ? GetFoo(\"foo\")).mapTo[Foo] val barFuture = (barActor ? GetBar(\"bar\")).mapTo[Bar] val totalFuture = for { foo: Foo <- fooFuture bar: Bar <- barFuture total = foo.getCount + bar.getCount } yield total Here the messages to fooActor and barActor are sent and processed in parallel, but you're guaranteed that total won't be calculated until the values it needs are available. Note that if you construct fooFuture and barFuture inside the for comprehension, they won't be run in parallel (see Scala for-comprehension with concurrently running futures ). Handling Errors with Futures The constructors and methods of Future (like those of Try ) catch exceptions, which cause the future to fail. This very useful property of futures means that you usually don't need try - catch blocks when using the Future monad (although it is sometimes helpful to include them, in order to catch low-level exceptions and wrap them in higher-level ones). Any exception thrown in code that's being run asynchronously by Future (including in the yield expression of a for comprehension) will be caught, and the result will be a Future containing a Failure . Also, in the previous example, if fooActor or barActor returns a Status.Failure message, the for -comprehension will also yield a failed future. However, you need to be careful with the first line of the for -comprehension. For example, this code doesn't handle exceptions correctly: private def doFooQuery(iri: IRI): Future[String] = { for { queryResponse <- (storeManager ? SparqlSelectRequest(queries.sparql.v1.txt.getFoo(iri).toString())).mapTo[SparqlSelectResponse] ... } yield ... } The getFoo() method calls a Twirl template function to generate SPARQL. The ? operator returns a Future . However, the template function is not run asynchronously , because it is called before the Future constructor is called. So if the template function throws an exception, it won't be caught here. Instead, you can do this: private def doFooQuery(iri: IRI): Future[String] = { for { queryString <- Future(queries.sparql.v1.txt.getFoo(iri).toString()) queryResponse <- (storeManager ? SparqlSelectRequest(queryString)).mapTo[SparqlSelectResponse] ... } yield ... } Here the Future constructor will call the template function asynchronously, and catch any exceptions it throws. This is only necessary if you need to call the template function at the very beginning of a for -comprehension. In the rest of the for comprehension, you'll already implicitly have a Future object. Using recover on Futures By using recover on a Future , an apt error message can be thrown if the Future fails. This is particularly useful when an an error message should be made more clear depending on the context the Future is used in. For example, we are asking the resources responder to query for a certain resource in order to process it in a special way. However, the client does not know that the resources responder is sent a request and in case the resource cannot be found, the message sent back from the resources responder ( NotFoundException ) would not make sense to it. Instead, we would like to handle the message in a way so that it makes sense for the operation the client actually executed. We can do this by calling recover on a Future . private def mySpecialResourceRequest(iri: IRI, userProfile: UserProfileV1): Future[...] = { val resourceRequestFuture = for { resResponse: ResourceFullResponseV1 <- (responderManager ? ResourceFullGetRequestV1(iri = iri, userProfile = userProfile, getIncoming = false)).mapTo[ResourceFullResponseV1] } yield resResponse val resourceRequestFutureRecovered = resourceRequestFuture.recover { case notFound: NotFoundException => throw BadRequestException(s\"Special resource handling failed because the resource could not be found: ${notFound.message}\") } for { res <- resourceRequestFutureRecovered ... } yield ... } Please note that the content of the Future has to be accessed using <- to make this work correctly. Otherwise the content will never be looked at. Designing with Futures In the current design, Knora almost never blocks to wait for a future to complete. The normal flow of control works like this: Incoming HTTP requests are handled by an actor called KnoraService , which delegates them to routing functions (in the routing package). For each request, a routing function gets an Akka HTTP RequestContext , and calls RouteUtilV1.runJsonRoute (in API v1) or RouteUtilV2.runRdfRouteWithFuture (in API v2) to send a message to a supervisor actor to fulfil the request. This creates a Future that will complete when the relevant responder sends its reply. The routing utility registers a callback on this Future to handle the reply message when it becomes available. The supervisor forwards the message to be handled by the appropriate responder. The responder's receive method receives the message, and calls some private method that produces a reply message inside a Future . This may involve sending messages to other actors using ask , getting futures back, and combining them into a single future containing the reply message. The responder passes that future to ActorUtils.future2Message , which registers a callback on it. When the future completes (perhaps in another thread), the callback sends the reply message. In the meantime, the responder doesn't block, so it can start handling the next request. When the responder's reply becomes available, the routing utility's callback registered in (2) calls complete on the RequestContext , which sends an HTTP response to the client. The basic rule of thumb is this: if you're writing a method in an actor, and anything in the method needs to come from a future (e.g. because you need to use ask to get some information from another actor), have the method return a future. Mixing Futures with non-Futures If you have a match ... case or if expression, and one branch obtains some data in a future, but another branch can produce the data immediately, you can wrap the result of the latter branch in a future, so that both branches have the same type. Here we use an alternative implementation of scala.concurrent.Future , found in akka.http.scaladsl.util.FastFuture , which tries to avoid scheduling to an scala.concurrent.ExecutionContext if possible, i.e. if the given future value is already present: def getTotalOfFooAndBar(howToGetFoo: String): Future[Int] = { for { foo <- howToGetFoo match { case \"askForIt\" => (fooActor ? GetFoo(\"foo\")).mapTo[Foo] case \"createIt\" => FastFuture.successful(new Foo()) } bar <- (barActor ? GetBar(\"bar\")).mapTo[Bar] total = foo.getCount + bar.getCount } yield total } How to Write For-Comprehensions Here are some basic rules for writing for -comprehensions: The first line of a for -comprehension has to be a \"generator\", i.e. it has to use the <- operator. If you want to write an assignment (using = ) as the first line, the workaround is to wrap the right-hand side in a monad (like Future ) and use <- instead. Assignments (using = ) are written without val . You're not allowed to write statements that throw away their return values, so if you want to call something like println that returns Unit , you have to assign its return value to _ . The yield returns an object of the same type as the generators, which all have to produce the same type (e.g. Future ). Execution Contexts Whenever you use a future, there has to be an implicit 'execution context' in scope. Scala's documentation on futures says, 'you can think of execution contexts as thread pools'. If you don't have an execution context in scope, you'll get a compile error asking you to include one, and suggesting that you could use import scala.concurrent.ExecutionContext.Implicits.global . Don't do this, because the global Scala execution context is not the most efficient option. Instead, use Knora's custom execution context like so: implicit val executionContext: ExecutionContext = system.dispatchers.lookup(KnoraDispatchers.KnoraActorDispatcher)","title":"Futures with Akka"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#futures-with-akka","text":"","title":"Futures with Akka"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#introduction","text":"Scala's documentation on futures introduces them in this way: Futures provide a nice way to reason about performing many operations in parallel \u2013 in an efficient and non-blocking way. The idea is simple, a Future is a sort of a placeholder object that you can create for a result that does not yet exist. Generally, the result of the Future is computed concurrently and can be later collected. Composing concurrent tasks in this way tends to result in faster, asynchronous, non-blocking parallel code. The rest of that page is well worth reading to get an overview of how futures work and what you can do with them. In Akka , one of the standard patterns for communication between actors is the ask pattern , in which you send a message to an actor and you expect a reply. When you call the ask function (which can be written as a question mark, ? , which acts as an infix operator), it immediately returns a Future , which will complete when the reply is sent. As the Akka documentation explains in Use with Actors , it is possible to block the calling thread until the future completes, using Await.result . However, they say: 'Blocking is discouraged though as it will cause performance problems.' In particular, by not blocking, you can do several ask requests in parallel. One way to avoid blocking is to register a callback on the future, which will be called when it completes (perhaps by another thread), like this: future.onComplete { case Success(result) => println(result) case Failure(ex) => ex.printStackTrace() } But this won't work if you're writing a method that needs return a value based on the result of a future. In this case, you can register a callback that transforms the result of a future into another future: val newFuture = future.map(x => x + 1) However, registering callbacks explicitly gets cumbersome when you need to work with several futures together. In this case, the most convenient alternative to blocking is to use Future as a monad. The links above explain what this means in detail, but the basic idea is that a special syntax, called a for -comprehension, allows you to write code that uses futures as if they were complete, without blocking. In reality, a for -comprehension is syntactic sugar for calling methods like map , but it's much easier to write and to read. You can do things like this: val fooFuture = (fooActor ? GetFoo(\"foo\")).mapTo[Foo] val barFuture = (barActor ? GetBar(\"bar\")).mapTo[Bar] val totalFuture = for { foo: Foo <- fooFuture bar: Bar <- barFuture total = foo.getCount + bar.getCount } yield total Here the messages to fooActor and barActor are sent and processed in parallel, but you're guaranteed that total won't be calculated until the values it needs are available. Note that if you construct fooFuture and barFuture inside the for comprehension, they won't be run in parallel (see Scala for-comprehension with concurrently running futures ).","title":"Introduction"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#handling-errors-with-futures","text":"The constructors and methods of Future (like those of Try ) catch exceptions, which cause the future to fail. This very useful property of futures means that you usually don't need try - catch blocks when using the Future monad (although it is sometimes helpful to include them, in order to catch low-level exceptions and wrap them in higher-level ones). Any exception thrown in code that's being run asynchronously by Future (including in the yield expression of a for comprehension) will be caught, and the result will be a Future containing a Failure . Also, in the previous example, if fooActor or barActor returns a Status.Failure message, the for -comprehension will also yield a failed future. However, you need to be careful with the first line of the for -comprehension. For example, this code doesn't handle exceptions correctly: private def doFooQuery(iri: IRI): Future[String] = { for { queryResponse <- (storeManager ? SparqlSelectRequest(queries.sparql.v1.txt.getFoo(iri).toString())).mapTo[SparqlSelectResponse] ... } yield ... } The getFoo() method calls a Twirl template function to generate SPARQL. The ? operator returns a Future . However, the template function is not run asynchronously , because it is called before the Future constructor is called. So if the template function throws an exception, it won't be caught here. Instead, you can do this: private def doFooQuery(iri: IRI): Future[String] = { for { queryString <- Future(queries.sparql.v1.txt.getFoo(iri).toString()) queryResponse <- (storeManager ? SparqlSelectRequest(queryString)).mapTo[SparqlSelectResponse] ... } yield ... } Here the Future constructor will call the template function asynchronously, and catch any exceptions it throws. This is only necessary if you need to call the template function at the very beginning of a for -comprehension. In the rest of the for comprehension, you'll already implicitly have a Future object.","title":"Handling Errors with Futures"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#using-recover-on-futures","text":"By using recover on a Future , an apt error message can be thrown if the Future fails. This is particularly useful when an an error message should be made more clear depending on the context the Future is used in. For example, we are asking the resources responder to query for a certain resource in order to process it in a special way. However, the client does not know that the resources responder is sent a request and in case the resource cannot be found, the message sent back from the resources responder ( NotFoundException ) would not make sense to it. Instead, we would like to handle the message in a way so that it makes sense for the operation the client actually executed. We can do this by calling recover on a Future . private def mySpecialResourceRequest(iri: IRI, userProfile: UserProfileV1): Future[...] = { val resourceRequestFuture = for { resResponse: ResourceFullResponseV1 <- (responderManager ? ResourceFullGetRequestV1(iri = iri, userProfile = userProfile, getIncoming = false)).mapTo[ResourceFullResponseV1] } yield resResponse val resourceRequestFutureRecovered = resourceRequestFuture.recover { case notFound: NotFoundException => throw BadRequestException(s\"Special resource handling failed because the resource could not be found: ${notFound.message}\") } for { res <- resourceRequestFutureRecovered ... } yield ... } Please note that the content of the Future has to be accessed using <- to make this work correctly. Otherwise the content will never be looked at.","title":"Using recover on Futures"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#designing-with-futures","text":"In the current design, Knora almost never blocks to wait for a future to complete. The normal flow of control works like this: Incoming HTTP requests are handled by an actor called KnoraService , which delegates them to routing functions (in the routing package). For each request, a routing function gets an Akka HTTP RequestContext , and calls RouteUtilV1.runJsonRoute (in API v1) or RouteUtilV2.runRdfRouteWithFuture (in API v2) to send a message to a supervisor actor to fulfil the request. This creates a Future that will complete when the relevant responder sends its reply. The routing utility registers a callback on this Future to handle the reply message when it becomes available. The supervisor forwards the message to be handled by the appropriate responder. The responder's receive method receives the message, and calls some private method that produces a reply message inside a Future . This may involve sending messages to other actors using ask , getting futures back, and combining them into a single future containing the reply message. The responder passes that future to ActorUtils.future2Message , which registers a callback on it. When the future completes (perhaps in another thread), the callback sends the reply message. In the meantime, the responder doesn't block, so it can start handling the next request. When the responder's reply becomes available, the routing utility's callback registered in (2) calls complete on the RequestContext , which sends an HTTP response to the client. The basic rule of thumb is this: if you're writing a method in an actor, and anything in the method needs to come from a future (e.g. because you need to use ask to get some information from another actor), have the method return a future.","title":"Designing with Futures"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#mixing-futures-with-non-futures","text":"If you have a match ... case or if expression, and one branch obtains some data in a future, but another branch can produce the data immediately, you can wrap the result of the latter branch in a future, so that both branches have the same type. Here we use an alternative implementation of scala.concurrent.Future , found in akka.http.scaladsl.util.FastFuture , which tries to avoid scheduling to an scala.concurrent.ExecutionContext if possible, i.e. if the given future value is already present: def getTotalOfFooAndBar(howToGetFoo: String): Future[Int] = { for { foo <- howToGetFoo match { case \"askForIt\" => (fooActor ? GetFoo(\"foo\")).mapTo[Foo] case \"createIt\" => FastFuture.successful(new Foo()) } bar <- (barActor ? GetBar(\"bar\")).mapTo[Bar] total = foo.getCount + bar.getCount } yield total }","title":"Mixing Futures with non-Futures"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#how-to-write-for-comprehensions","text":"Here are some basic rules for writing for -comprehensions: The first line of a for -comprehension has to be a \"generator\", i.e. it has to use the <- operator. If you want to write an assignment (using = ) as the first line, the workaround is to wrap the right-hand side in a monad (like Future ) and use <- instead. Assignments (using = ) are written without val . You're not allowed to write statements that throw away their return values, so if you want to call something like println that returns Unit , you have to assign its return value to _ . The yield returns an object of the same type as the generators, which all have to produce the same type (e.g. Future ).","title":"How to Write For-Comprehensions"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#execution-contexts","text":"Whenever you use a future, there has to be an implicit 'execution context' in scope. Scala's documentation on futures says, 'you can think of execution contexts as thread pools'. If you don't have an execution context in scope, you'll get a compile error asking you to include one, and suggesting that you could use import scala.concurrent.ExecutionContext.Implicits.global . Don't do this, because the global Scala execution context is not the most efficient option. Instead, use Knora's custom execution context like so: implicit val executionContext: ExecutionContext = system.dispatchers.lookup(KnoraDispatchers.KnoraActorDispatcher)","title":"Execution Contexts"},{"location":"DSP-API/05-internals/design/principles/http-module/","text":"HTTP Module The http module holds only a convenience method for adding CORS support to api routes. The CORS implementation uses the akka-http-cors directives implementation.","title":"HTTP Module"},{"location":"DSP-API/05-internals/design/principles/http-module/#http-module","text":"The http module holds only a convenience method for adding CORS support to api routes. The CORS implementation uses the akka-http-cors directives implementation.","title":"HTTP Module"},{"location":"DSP-API/05-internals/design/principles/rdf-api/","text":"RDF Processing API Knora provides an API for parsing and formatting RDF data and for working with RDF graphs. This allows Knora developers to use a single, idiomatic Scala API as a fa\u00e7ade for a Java RDF library. By using a feature toggle, you can choose either Jena or RDF4J as the underlying implementation. Overview The API is in the package org.knora.webapi.messages.util.rdf . It includes: RdfModel , which represents a set of RDF graphs (a default graph and/or one or more named graphs). A model can be constructed from scratch, modified, and searched. RdfNode and its subclasses, which represent RDF nodes (IRIs, blank nodes, and literals). Statement , which represents a triple or quad. RdfNodeFactory , which creates nodes and statements. RdfModelFactory , which creates empty RDF models. RdfFormatUtil , which parses and formats RDF models. JsonLDUtil , which provides specialised functionality for working with RDF in JSON-LD format, and for converting between RDF models and JSON-LD documents. RdfFormatUtil uses JsonLDUtil when appropriate. ShaclValidator , which validates RDF models using SHACL shapes. To work with RDF models, start with RdfFeatureFactory , which returns instances of RdfNodeFactory , RdfModelFactory , RdfFormatUtil , and ShaclValidator , using feature toggle configuration. JsonLDUtil does not need a feature factory. To iterate efficiently over the statements in an RdfModel , use its iterator method. An RdfModel cannot be modified while you are iterating over it. If you are iterating to look for statements to modify, you can collect a Set of statements to remove and a Set of statements to add, and perform these update operations after you have finished the iteration. RDF stream processing To read or write a large amount of RDF data without generating a large string object, you can use the stream processing methods in RdfFormatUtil . To parse an InputStream to an RdfModel , use inputStreamToRdfModel . To format an RdfModel to an OutputStream , use rdfModelToOutputStream . To parse RDF data from an InputStream and process it one statement at a time, you can write a class that implements the RdfStreamProcessor trait, and use it with the RdfFormatUtil.parseWithStreamProcessor method. Your RdfStreamProcessor can also send one statement at a time to a formatting stream processor, which knows how to write RDF to an OutputStream in a particular format. Use RdfFormatUtil.makeFormattingStreamProcessor to construct one of these. SPARQL queries In tests, it can be useful to run SPARQL queries to check the content of an RdfModel . To do this, use the RdfModel.asRepository method, which returns an RdfRepository that can run SELECT queries. The configuration of the default graph depends on which underlying RDF library is used. If you are querying data in named graphs, use FROM or quad patterns rather than the default graph. SHACL validation On startup, graphs of SHACL shapes are loaded from Turtle files in a directory specified by app.shacl.shapes-dir in application.conf , and in subdirectories of that directory. To validate the default graph of an RdfModel using a graph of SHACL shapes, call ShaclValidator.validate , specifying the relative path of the Turtle file containing the graph of shapes. Implementations The Jena-based implementation, in package org.knora.webapi.messages.util.rdf.jenaimpl . The RDF4J-based implementation, in package org.knora.webapi.messages.util.rdf.rdf4jimpl . Feature toggle For an overview of feature toggles, see Feature Toggles . The RDF API uses the feature toggle jena-rdf-library : on : use the Jena implementation. off (the default): use the RDF4J implementation. The default setting is used on startup, e.g. to read ontologies from the repository. After startup, the per-request setting is used. TODO SHACL validation.","title":"RDF Processing API"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#rdf-processing-api","text":"Knora provides an API for parsing and formatting RDF data and for working with RDF graphs. This allows Knora developers to use a single, idiomatic Scala API as a fa\u00e7ade for a Java RDF library. By using a feature toggle, you can choose either Jena or RDF4J as the underlying implementation.","title":"RDF Processing API"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#overview","text":"The API is in the package org.knora.webapi.messages.util.rdf . It includes: RdfModel , which represents a set of RDF graphs (a default graph and/or one or more named graphs). A model can be constructed from scratch, modified, and searched. RdfNode and its subclasses, which represent RDF nodes (IRIs, blank nodes, and literals). Statement , which represents a triple or quad. RdfNodeFactory , which creates nodes and statements. RdfModelFactory , which creates empty RDF models. RdfFormatUtil , which parses and formats RDF models. JsonLDUtil , which provides specialised functionality for working with RDF in JSON-LD format, and for converting between RDF models and JSON-LD documents. RdfFormatUtil uses JsonLDUtil when appropriate. ShaclValidator , which validates RDF models using SHACL shapes. To work with RDF models, start with RdfFeatureFactory , which returns instances of RdfNodeFactory , RdfModelFactory , RdfFormatUtil , and ShaclValidator , using feature toggle configuration. JsonLDUtil does not need a feature factory. To iterate efficiently over the statements in an RdfModel , use its iterator method. An RdfModel cannot be modified while you are iterating over it. If you are iterating to look for statements to modify, you can collect a Set of statements to remove and a Set of statements to add, and perform these update operations after you have finished the iteration.","title":"Overview"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#rdf-stream-processing","text":"To read or write a large amount of RDF data without generating a large string object, you can use the stream processing methods in RdfFormatUtil . To parse an InputStream to an RdfModel , use inputStreamToRdfModel . To format an RdfModel to an OutputStream , use rdfModelToOutputStream . To parse RDF data from an InputStream and process it one statement at a time, you can write a class that implements the RdfStreamProcessor trait, and use it with the RdfFormatUtil.parseWithStreamProcessor method. Your RdfStreamProcessor can also send one statement at a time to a formatting stream processor, which knows how to write RDF to an OutputStream in a particular format. Use RdfFormatUtil.makeFormattingStreamProcessor to construct one of these.","title":"RDF stream processing"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#sparql-queries","text":"In tests, it can be useful to run SPARQL queries to check the content of an RdfModel . To do this, use the RdfModel.asRepository method, which returns an RdfRepository that can run SELECT queries. The configuration of the default graph depends on which underlying RDF library is used. If you are querying data in named graphs, use FROM or quad patterns rather than the default graph.","title":"SPARQL queries"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#shacl-validation","text":"On startup, graphs of SHACL shapes are loaded from Turtle files in a directory specified by app.shacl.shapes-dir in application.conf , and in subdirectories of that directory. To validate the default graph of an RdfModel using a graph of SHACL shapes, call ShaclValidator.validate , specifying the relative path of the Turtle file containing the graph of shapes.","title":"SHACL validation"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#implementations","text":"The Jena-based implementation, in package org.knora.webapi.messages.util.rdf.jenaimpl . The RDF4J-based implementation, in package org.knora.webapi.messages.util.rdf.rdf4jimpl .","title":"Implementations"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#feature-toggle","text":"For an overview of feature toggles, see Feature Toggles . The RDF API uses the feature toggle jena-rdf-library : on : use the Jena implementation. off (the default): use the RDF4J implementation. The default setting is used on startup, e.g. to read ontologies from the repository. After startup, the per-request setting is used.","title":"Feature toggle"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#todo","text":"SHACL validation.","title":"TODO"},{"location":"DSP-API/05-internals/design/principles/store-module/","text":"Store Module Overview The store module houses the different types of data stores supported by Knora. At the moment, only triplestores and IIIF servers (Sipi) are supported. The triplestore support is implemented in the org.knora.webapi.store.triplestore package and the IIIF server support in org.knora.webapi.store.iiif package. Lifecycle At the top level, the store package houses the StoreManager -Actor which is started when Knora starts. The StoreManager then starts the TriplestoreManager and IIIFManager , which each in turn starts their correct actor implementation. HTTP-based Triplestores HTTP-based triplestore support is implemented in the org.knora.webapi.triplestore.http package. An HTTP-based triplestore is one that is accessed remotely over the HTTP protocol. HttpTriplestoreConnector supports the following triplestores: Ontotext GraphDB Fuseki 2 GraphDB Fuseki 2 Embedded Triplestores Embedded triplestores are implemented in the org.knora.webapi.triplestore.embedded package. An embedded triplestore is one that runs in the same JVM as the Knora API server. Apache Jena TDB The support for embedded Jena TDB is currently dropped. The documentation and the code will remain in the repository. You can use it at your own risk. The support for the embedded Jena-TDB triplestore is implemented in org.knora.webapi.triplestore.embedded.JenaTDBActor . The relevant Jena libraries that are used are the following: Jena API - The library used to work programmatically with RDF data Jena TDB - Their implementation of a triple store Concurrency Jena provides concurrency on different levels. On the Jena TDB level there is the Dataset object, representing the triple store. On every access, a transaction (read or write) can be started. On the Jena API level there is a Model object, which is equivalent to an RDF Graph . Here we can lock the model, so that MRSW (Multiple Reader Single Writer) access is allowed. https://jena.apache.org/documentation/tdb/tdb_transactions.html https://jena.apache.org/documentation/notes/concurrency-howto.html Implementation We employ transactions on the Dataset level. This means that every thread that accesses the triplestore, starts a read or write enabled transaction. The transaction mechanism in TDB is based on write-ahead-logging. All changes made inside a write-transaction are written to journals, then propagated to the main database at a suitable moment. This design allows for read-transactions to proceed without locking or other overhead over the base database. Transactional TDB supports one active write transaction, and multiple read transactions at the same time. Read-transactions started before a write-transaction commits see the database in a state without any changes visible. Any transaction starting after a write-transaction commits sees the database with the changes visible, whether fully propagates back to the database or not. There can be active read transactions seeing the state of the database before the updates, and read transactions seeing the state of the database after the updates running at the same time. Configuration In application.conf set to use the embedded triplestore: triplestore { dbtype = \"embedded-jena-tdb\" embedded-jena-tdb { persisted = true // \"false\" -> memory, \"true\" -> disk loadExistingData = false // \"false\" -> use data if exists, \"false\" -> create a fresh store storage-path = \"_TMP\" // ignored if \"memory\" } reload-on-start = false // ignored if \"memory\" as it will always reload rdf-data = [ { path = \"knora-ontologies/knora-base.ttl\" name = \"http://www.knora.org/ontology/knora-base\" } { path = \"knora-ontologies/salsah-gui.ttl\" name = \"http://www.knora.org/ontology/salsah-gui\" } { path = \"test_data/ontologies/incunabula-onto.ttl\" name = \"http://www.knora.org/ontology/0803/incunabula\" } { path = \"test_data/demo_data/incunabula-demo-data.ttl\" name = \"http://www.knora.org/data/incunabula\" } { path = \"test_data/ontologies/images-onto.ttl\" name = \"http://www.knora.org/ontology/0804/dokubib\" } { path = \"test_data/demo_data/images-demo-data.ttl\" name = \"http://www.knora.org/data/dokubib\" } ] } Here the storage is set to persistent , meaning that a Jena TDB store will be created under the defined tdb-storage-path . The reload-on-start flag, if set to true would reload the triplestore with the data referenced in rdf-data . TDB Disk Persisted Store Make sure to set reload-on-start to true if run for the first time. This will create a TDB store and load the data. If only read access is performed, then Knora can be run once with reloading enabled. After that, reloading can be turned off, and the persisted TDB store can be reused, as any data found under the tdb-storage-path will be reused. If the TDB storage files get corrupted, then just delete the folder and reload the data anew. Actor Messages ResetTripleStoreContent(rdfDataObjects: List[RdfDataObject]) ResetTripleStoreContentACK() The embedded Jena TDB can receive reset messages, and will ACK when reloading of the data is finished. RdfDataObject is a simple case class, containing the path and name (the same as rdf-data in the config file) As an example, to use it inside a test you could write something like: val rdfDataObjects = List ( RdfDataObject(path = \"knora-ontologies/knora-base.ttl\", name = \"http://www.knora.org/ontology/knora-base\"), RdfDataObject(path = \"knora-ontologies/salsah-gui.ttl\", name = \"http://www.knora.org/ontology/salsah-gui\"), RdfDataObject(path = \"test_data/ontologies/incunabula-onto.ttl\", name = \"http://www.knora.org/ontology/0803/incunabula\"), RdfDataObject(path = \"test_data/all_data/incunabula-data.ttl\", name = \"http://www.knora.org/data/incunabula\") ) \"Reload data \" in { storeManager ! ResetTripleStoreContent(rdfDataObjects) expectMsg(300.seconds, ResetTripleStoreContentACK()) } IIIF Servers Currently, only support for SIPI is implemented in org.knora.webapi.store.iiifSipiConnector .","title":"Store Module"},{"location":"DSP-API/05-internals/design/principles/store-module/#store-module","text":"","title":"Store Module"},{"location":"DSP-API/05-internals/design/principles/store-module/#overview","text":"The store module houses the different types of data stores supported by Knora. At the moment, only triplestores and IIIF servers (Sipi) are supported. The triplestore support is implemented in the org.knora.webapi.store.triplestore package and the IIIF server support in org.knora.webapi.store.iiif package.","title":"Overview"},{"location":"DSP-API/05-internals/design/principles/store-module/#lifecycle","text":"At the top level, the store package houses the StoreManager -Actor which is started when Knora starts. The StoreManager then starts the TriplestoreManager and IIIFManager , which each in turn starts their correct actor implementation.","title":"Lifecycle"},{"location":"DSP-API/05-internals/design/principles/store-module/#http-based-triplestores","text":"HTTP-based triplestore support is implemented in the org.knora.webapi.triplestore.http package. An HTTP-based triplestore is one that is accessed remotely over the HTTP protocol. HttpTriplestoreConnector supports the following triplestores: Ontotext GraphDB Fuseki 2","title":"HTTP-based Triplestores"},{"location":"DSP-API/05-internals/design/principles/store-module/#graphdb","text":"","title":"GraphDB"},{"location":"DSP-API/05-internals/design/principles/store-module/#fuseki-2","text":"","title":"Fuseki 2"},{"location":"DSP-API/05-internals/design/principles/store-module/#embedded-triplestores","text":"Embedded triplestores are implemented in the org.knora.webapi.triplestore.embedded package. An embedded triplestore is one that runs in the same JVM as the Knora API server.","title":"Embedded Triplestores"},{"location":"DSP-API/05-internals/design/principles/store-module/#apache-jena-tdb","text":"The support for embedded Jena TDB is currently dropped. The documentation and the code will remain in the repository. You can use it at your own risk. The support for the embedded Jena-TDB triplestore is implemented in org.knora.webapi.triplestore.embedded.JenaTDBActor . The relevant Jena libraries that are used are the following: Jena API - The library used to work programmatically with RDF data Jena TDB - Their implementation of a triple store","title":"Apache Jena TDB"},{"location":"DSP-API/05-internals/design/principles/store-module/#concurrency","text":"Jena provides concurrency on different levels. On the Jena TDB level there is the Dataset object, representing the triple store. On every access, a transaction (read or write) can be started. On the Jena API level there is a Model object, which is equivalent to an RDF Graph . Here we can lock the model, so that MRSW (Multiple Reader Single Writer) access is allowed. https://jena.apache.org/documentation/tdb/tdb_transactions.html https://jena.apache.org/documentation/notes/concurrency-howto.html","title":"Concurrency"},{"location":"DSP-API/05-internals/design/principles/store-module/#implementation","text":"We employ transactions on the Dataset level. This means that every thread that accesses the triplestore, starts a read or write enabled transaction. The transaction mechanism in TDB is based on write-ahead-logging. All changes made inside a write-transaction are written to journals, then propagated to the main database at a suitable moment. This design allows for read-transactions to proceed without locking or other overhead over the base database. Transactional TDB supports one active write transaction, and multiple read transactions at the same time. Read-transactions started before a write-transaction commits see the database in a state without any changes visible. Any transaction starting after a write-transaction commits sees the database with the changes visible, whether fully propagates back to the database or not. There can be active read transactions seeing the state of the database before the updates, and read transactions seeing the state of the database after the updates running at the same time.","title":"Implementation"},{"location":"DSP-API/05-internals/design/principles/store-module/#configuration","text":"In application.conf set to use the embedded triplestore: triplestore { dbtype = \"embedded-jena-tdb\" embedded-jena-tdb { persisted = true // \"false\" -> memory, \"true\" -> disk loadExistingData = false // \"false\" -> use data if exists, \"false\" -> create a fresh store storage-path = \"_TMP\" // ignored if \"memory\" } reload-on-start = false // ignored if \"memory\" as it will always reload rdf-data = [ { path = \"knora-ontologies/knora-base.ttl\" name = \"http://www.knora.org/ontology/knora-base\" } { path = \"knora-ontologies/salsah-gui.ttl\" name = \"http://www.knora.org/ontology/salsah-gui\" } { path = \"test_data/ontologies/incunabula-onto.ttl\" name = \"http://www.knora.org/ontology/0803/incunabula\" } { path = \"test_data/demo_data/incunabula-demo-data.ttl\" name = \"http://www.knora.org/data/incunabula\" } { path = \"test_data/ontologies/images-onto.ttl\" name = \"http://www.knora.org/ontology/0804/dokubib\" } { path = \"test_data/demo_data/images-demo-data.ttl\" name = \"http://www.knora.org/data/dokubib\" } ] } Here the storage is set to persistent , meaning that a Jena TDB store will be created under the defined tdb-storage-path . The reload-on-start flag, if set to true would reload the triplestore with the data referenced in rdf-data .","title":"Configuration"},{"location":"DSP-API/05-internals/design/principles/store-module/#tdb-disk-persisted-store","text":"Make sure to set reload-on-start to true if run for the first time. This will create a TDB store and load the data. If only read access is performed, then Knora can be run once with reloading enabled. After that, reloading can be turned off, and the persisted TDB store can be reused, as any data found under the tdb-storage-path will be reused. If the TDB storage files get corrupted, then just delete the folder and reload the data anew.","title":"TDB Disk Persisted Store"},{"location":"DSP-API/05-internals/design/principles/store-module/#actor-messages","text":"ResetTripleStoreContent(rdfDataObjects: List[RdfDataObject]) ResetTripleStoreContentACK() The embedded Jena TDB can receive reset messages, and will ACK when reloading of the data is finished. RdfDataObject is a simple case class, containing the path and name (the same as rdf-data in the config file) As an example, to use it inside a test you could write something like: val rdfDataObjects = List ( RdfDataObject(path = \"knora-ontologies/knora-base.ttl\", name = \"http://www.knora.org/ontology/knora-base\"), RdfDataObject(path = \"knora-ontologies/salsah-gui.ttl\", name = \"http://www.knora.org/ontology/salsah-gui\"), RdfDataObject(path = \"test_data/ontologies/incunabula-onto.ttl\", name = \"http://www.knora.org/ontology/0803/incunabula\"), RdfDataObject(path = \"test_data/all_data/incunabula-data.ttl\", name = \"http://www.knora.org/data/incunabula\") ) \"Reload data \" in { storeManager ! ResetTripleStoreContent(rdfDataObjects) expectMsg(300.seconds, ResetTripleStoreContentACK()) }","title":"Actor Messages"},{"location":"DSP-API/05-internals/design/principles/store-module/#iiif-servers","text":"Currently, only support for SIPI is implemented in org.knora.webapi.store.iiifSipiConnector .","title":"IIIF Servers"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/","text":"Triplestore Updates Requirements General The supported update operations are: Create a new resource with its initial values. Add a new value. Change a value. Delete a value (i.e. mark it as deleted). Delete a resource (i.e. mark it as deleted). Users must be able to edit the same data concurrently. Each update must be atomic and leave the database in a consistent, meaningful state, respecting ontology constraints and permissions. The application must not use any sort of long-lived locks, because they tend to hinder concurrent edits, and it is difficult to ensure that they are released when they are no longer needed. Instead, if a user requests an update based on outdated information (because another user has just changed something, and the first user has not found out yet), the update must be not performed, and the application must notify the user who requested it, suggesting that the user should check the relevant data and try again if necessary. (We may eventually provide functionality to help users merge edits in such a situation. The application can also encourage users to coordinate with one another when they are working on the same data, and may eventually provide functionality to facilitate this coordination.) We can assume that each SPARQL update operation will run in its own database transaction with an isolation level of 'read committed'. This is what GraphDB does when it receives a SPARQL update over HTTP (see GraphDB SE Transactions ). We cannot assume that it is possible to run more than one SPARQL update in a single database transaction. (The SPARQL 1.1 Protocol does not provide a way to do this, and currently it can be done only by embedding the triplestore in the application and using a vendor-specific API, but we cannot require this in Knora.) Permissions To create a new value (as opposed to a new version of an existing value), the user must have permission to modify the containing resource. To create a new version of an existing value, the user needs only to have permission to modify the current version of the value; no permissions on the resource are needed. Since changing a link requires deleting the old link and creating a new one (as described in Linking ), a user wishing to change a link must have modify permission on both the containing resource and the knora-base:LinkValue for the existing link. When a new resource or value is created, it can be given default permissions specified the project's admin data, or (only in API v2) custom permissions can be specified. Ontology Constraints Knora must not allow an update that would violate an ontology constraint. When creating a new value (as opposed to adding a new version of an existing value), Knora must not allow the update if the containing resource's OWL class does not contain a cardinality restriction for the submitted property, or if the new value would violate the cardinality restriction. It must also not allow the update if the type of the submitted value does not match the knora-base:objectClassConstraint of the property, or if the property has no knora-base:objectClassConstraint . In the case of a property that points to a resource, Knora must ensure that the target resource belongs to the OWL class specified in the property's knora-base:objectClassConstraint , or to a subclass of that class. Duplicate and Redundant Values When creating a new value, or changing an existing value, Knora checks whether the submitted value would duplicate an existing value for the same property in the resource. The definition of 'duplicate' depends on the type of value; it does not necessarily mean that the two values are strictly equal. For example, if two text values contain the same Unicode string, they are considered duplicates, even if they have different Standoff markup. If resource R has property P with value V1 , and V1 is a duplicate of V2 , the API server must not add another instance of property P with value V2 . However, if the requesting user does not have permission to see V2 , the duplicate is allowed, because forbidding it would reveal the contents of V2 to the user. When creating a new version of a value, Knora also checks whether the new version is redundant, given the existing value. It is possible for the definition of 'redundant' can depend on the type of value, but in practice, it means that the values are strictly equal: any change, however trivial, is allowed. Versioning Each Knora value (i.e. something belonging to an OWL class derived from knora-base:Value ) is versioned. This means that once created, a value is never modified. Instead, 'changing' a value means creating a new version of the value --- actually a new value --- that points to the previous version using knora-base:previousValue . The versions of a value are a singly-linked list, pointing backwards into the past. When a new version of a value is made, the triple that points from the resource to the old version (using a subproperty of knora-base:hasValue ) is removed, and a triple is added to point from the resource to the new version. Thus the resource always points only to the current version of the value, and the older versions are available only via the current version's knora-base:previousValue predicate. Unlike values, resources (members of OWL classes derived from knora-base:Resource ) are not versioned. The data that is attached to a resource, other than its values, can be modified. Deleting Knora does not actually delete resources or values; it only marks them as deleted. Deleted data is normally hidden. All resources and values must have the predicate knora- base:isDeleted , whose object is a boolean. If a resource or value has been marked as deleted, it has knora-base:isDeleted true and has a knora-base:deleteDate . An optional knora-base:deleteComment may be added to explain why the resource or value has been marked as deleted. Normally, a value is marked as deleted without creating a new version of it. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. Since it is necessary to be able to find out when a resource was deleted, it is not possible to undelete a resource. Moreover, to simplify the checking of cardinality constraints, and for consistency with resources, it is not possible to undelete a value, and no new versions of a deleted value can be made. Instead, if desired, a new resource or value can be created by copying data from a deleted resource or value. Linking Links must be treated differently to other types of values. Knora needs to maintain information about the link, including permissions and a version history. Since the link does not have a unique IRI of its own, Knora uses RDF reifications for this purpose. Each link between two resources has exactly one (non-deleted) knora-base:LinkValue . The resource itself has a predicate that points to the LinkValue , using a naming convention in which the word Value is appended to the name of the link predicate to produce the link value predicate. For example, if a resource representing a book has a predicate called hasAuthor that points to another resource, it must also have a predicate called hasAuthorValue that points to the LinkValue in which information about the link is stored. To find a particular LinkValue , one can query it either by using its IRI (if known), or by using its rdf:subject , rdf:predicate , and rdf:object (and excluding link values that are marked as deleted). Like other values, link values are versioned. The link value predicate always points from the resource to the current version of the link value, and previous versions are available only via the current version's knora-base:previousValue predicate. Deleting a link means deleting the triple that links the two resources, and making a new version of the link value, marked with knora-base:isDeleted . A triple then points from the resource to this new, deleted version (using the link value property). The API allows a link to be 'changed' so that it points to a different target resource. This is implemented as follows: the existing triple connecting the two resources is removed, and a new triple is added using the same link property and pointing to the new target resource. A new version of the old link's LinkValue is made, marked with knora-base:isDeleted . A new LinkValue is made for the new link. The new LinkValue has no connection to the old one. When a resource contains knora-base:TextValue with Standoff markup that includes a reference to another resource, this reference is materialised as a direct link between the two resources, to make it easier to query. A special link property, knora-base:hasStandoffLinkTo , is used for this purpose. The corresponding link value property, knora-base:hasStandoffLinkToValue , points to a LinkValue . This LinkValue contains a reference count, indicated by knora-base:valueHasRefCount , that represents the number of text values in the containing resource that include one or more Standoff references to the specified target resource. Each time this number changes, a new version of this LinkValue is made. When the reference count reaches zero, the triple with knora-base:hasStandoffLinkTo is removed, and a new version of the LinkValue is made and marked with knora-base:isDeleted . If the same resource reference later appears again in a text value, a new triple is added using knora-base:hasStandoffLinkTo , and a new LinkValue is made, with no connection to the old one. For consistency, every LinkValue contains a reference count. If the link property is not knora-base:hasStandoffLinkTo , the reference count will always be either 1 (if the link exists) or 0 (if it has been deleted, in which case the link value will also be marked with knora-base:isDeleted ). When a LinkValue is created for a standoff resource reference, it is given the same permissions as the text value containing the reference. Design Responsibilities of Responders The resources responder ( ResourcesResponderV1 in API v1, ResourcesResponderV2 in API v2) has sole responsibility for generating SPARQL to create and updating resources, and the values responder ( ValuesResponderV1 or ValuesResponderV2 ) has sole responsibility for generating SPARQL to create and update values. When a new resource is created with its values, the values responder generates SPARQL statements that can be included in the INSERT clause of a SPARQL update to create the values, and the resources responder adds these statements to the SPARQL update that creates the resource. This ensures that the resource and its values are created in a single SPARQL update operation, and hence in a single triplestore transaction. Application-level Locking The 'read committed' isolation level cannot prevent a scenario where two users want to add the same data at the same time. It is possible that both requests would do pre-update checks and simultaneously find that it is OK to add the data, and that both updates would then succeed, inserting redundant data and possibly violating ontology constraints. Therefore, Knora uses short-lived, application-level write locks on resources, to ensure that only one request at a time can update a given resource. Before each update, the application acquires a lock on a resource. To prevent deadlocks, Knora locks only one resource per API operation. It then does the pre-update checks and the update, then releases the lock. The lock implementation (in IriLocker ) requires each API request message to include a random UUID, which is generated in the API Routing package. Using application-level locks allows us to do pre-update checks in their own transactions, and finally to do the SPARQL update in its own transaction. Ensuring Data Consistency Knora enforces consistency constraints using three redundant mechanisms: By doing pre-update checks using SPARQL SELECT queries and cached ontology data. By doing checks in the WHERE clauses of SPARQL updates. By using GraphDB's built-in consistency checker (see Consistency Checking ). We take the view that redundant consistency checks are a good thing. Pre-update checks are SPARQL SELECT queries that are executed while holding an application-level lock on the resource to be updated. These checks should work with any triplestore, and can return helpful, Knora-specific error messages to the client if the request would violate a consistency constraint. However, the SPARQL update itself is our only chance to do pre-update checks in the same transaction that will perform the update. The design of the SPARQL 1.1 Update standard makes it possible to ensure that if certain conditions are not met, the update will not be performed. In our SPARQL update code, each update contains a WHERE clause, possibly a DELETE clause, and an INSERT clause. The WHERE clause is executed first. It performs consistency checks and provides values for variables that are used in the DELETE and/or INSERT clauses. In our updates, if the expectations of the WHERE clause are not met (e.g. because the data to be updated does not exist), the WHERE clause should return no results; as a result, the update will not be performed. Regardless of whether the update changes the contents of the triplestore, it returns nothing. If the update did nothing because the conditions of the WHERE clause were not met, the only way to find out is to do a SELECT afterwards. Moreover, in this case, there is no straightforward way to find out which conditions was not met. This is one reason why Knora does pre-update checks using separate SELECT queries and/or cached ontology data, before performing the update. This makes it possible to return specific error messages to the user to indicate why an update cannot be performed. Moreover, while some checks are easy to do in a SPARQL update, others are difficult, impractical, or impossible. Easy checks include checking whether a resource or value exists or is deleted, and checking that the knora-base:objectClassConstraint of a predicate matches the rdf:type of its intended object. Cardinality checks are not very difficult, but they perform poorly on Jena. Knora does not do permission checks in SPARQL, because its permission-checking algorithm is too complex to be implemented in SPARQL. For this reason, Knora's check for duplicate values cannot be done in SPARQL update code, because it relies on permission checks. In a bulk import operation, which can create a large number of resources in a single SPARQL update, a WHERE clause can become very expensive for the triplestore, in terms of memory as well as execution time. Moreover, RDF4J (and hence GraphDB) uses a recursive algorithm to parse SPARQL queries with WHERE clauses, so the size of a WHERE clause is limited by the stack space available to the Java Virtual Machine. Therefore, in bulk import operations, Knora uses INSERT DATA , which does not involve a WHERE clause. Bulk imports thus rely on checks (1) and (3) above. SPARQL Update Examples The following sample SPARQL update code is simpler than what Knora actually does. It is included here to illustrate the way Knora's SPARQL updates are structured and how concurrent updates are handled. Finding a value IRI in a value's version history We will need this query below. If a value is present in a resource property's version history, the query returns everything known about the value, or nothing otherwise: prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?p ?o WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") as ?searchValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?searchValue . ?searchValue ?p ?o . } Creating the initial version of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 1\"\"\" ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) # Do nothing if the resource doesn't exist. ?resource rdf:type ?resourceClass . # Do nothing if the submitted value has the wrong type. ?property knora-base:objectClassConstraint ?valueType . } To find out whether the insert succeeded, the application can use the query in Finding a value IRI in a value's version history to look for the new IRI in the property's version history. Adding a new version of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> DELETE { ?resource ?property ?currentValue . } INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 2\"\"\" ; knora-base:previousValue ?currentValue ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?currentValue) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) ?resource ?property ?currentValue . ?property knora-base:objectClassConstraint ?valueType . } The update request must contain the IRI of the most recent version of the value ( http://rdfh.ch/c5058f3a/values/c3295339 ). If this is not in fact the most recent version (because someone else has done an update), this operation will do nothing (because the WHERE clause will return no rows). To find out whether the update succeeded, the application will then need to do a SELECT query using the query in Finding a value IRI in a value's version history . In the case of concurrent updates, there are two possibilities: Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2, which user A verifies using a SELECT. User B then submits an update to version 1 but it fails, because version 1 is no longer the latest version. User B's SELECT will find that user B's new value IRI is absent from the value's version history. Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2. Before User A has time to do a SELECT, user B reads the new value and updates it again. Both users then do a SELECT, and find that both their new value IRIs are present in the value's version history. Getting all versions of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?value ?valueTimestamp ?previousValue WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?currentValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?value . OPTIONAL { ?value knora-base:valueTimestamp ?valueTimestamp . } OPTIONAL { ?value knora-base:previousValue ?previousValue . } } This assumes that we know the current version of the value. If the version we have is not actually the current version, this query will return no rows.","title":"Triplestore Updates"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#triplestore-updates","text":"","title":"Triplestore Updates"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#requirements","text":"","title":"Requirements"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#general","text":"The supported update operations are: Create a new resource with its initial values. Add a new value. Change a value. Delete a value (i.e. mark it as deleted). Delete a resource (i.e. mark it as deleted). Users must be able to edit the same data concurrently. Each update must be atomic and leave the database in a consistent, meaningful state, respecting ontology constraints and permissions. The application must not use any sort of long-lived locks, because they tend to hinder concurrent edits, and it is difficult to ensure that they are released when they are no longer needed. Instead, if a user requests an update based on outdated information (because another user has just changed something, and the first user has not found out yet), the update must be not performed, and the application must notify the user who requested it, suggesting that the user should check the relevant data and try again if necessary. (We may eventually provide functionality to help users merge edits in such a situation. The application can also encourage users to coordinate with one another when they are working on the same data, and may eventually provide functionality to facilitate this coordination.) We can assume that each SPARQL update operation will run in its own database transaction with an isolation level of 'read committed'. This is what GraphDB does when it receives a SPARQL update over HTTP (see GraphDB SE Transactions ). We cannot assume that it is possible to run more than one SPARQL update in a single database transaction. (The SPARQL 1.1 Protocol does not provide a way to do this, and currently it can be done only by embedding the triplestore in the application and using a vendor-specific API, but we cannot require this in Knora.)","title":"General"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#permissions","text":"To create a new value (as opposed to a new version of an existing value), the user must have permission to modify the containing resource. To create a new version of an existing value, the user needs only to have permission to modify the current version of the value; no permissions on the resource are needed. Since changing a link requires deleting the old link and creating a new one (as described in Linking ), a user wishing to change a link must have modify permission on both the containing resource and the knora-base:LinkValue for the existing link. When a new resource or value is created, it can be given default permissions specified the project's admin data, or (only in API v2) custom permissions can be specified.","title":"Permissions"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#ontology-constraints","text":"Knora must not allow an update that would violate an ontology constraint. When creating a new value (as opposed to adding a new version of an existing value), Knora must not allow the update if the containing resource's OWL class does not contain a cardinality restriction for the submitted property, or if the new value would violate the cardinality restriction. It must also not allow the update if the type of the submitted value does not match the knora-base:objectClassConstraint of the property, or if the property has no knora-base:objectClassConstraint . In the case of a property that points to a resource, Knora must ensure that the target resource belongs to the OWL class specified in the property's knora-base:objectClassConstraint , or to a subclass of that class.","title":"Ontology Constraints"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#duplicate-and-redundant-values","text":"When creating a new value, or changing an existing value, Knora checks whether the submitted value would duplicate an existing value for the same property in the resource. The definition of 'duplicate' depends on the type of value; it does not necessarily mean that the two values are strictly equal. For example, if two text values contain the same Unicode string, they are considered duplicates, even if they have different Standoff markup. If resource R has property P with value V1 , and V1 is a duplicate of V2 , the API server must not add another instance of property P with value V2 . However, if the requesting user does not have permission to see V2 , the duplicate is allowed, because forbidding it would reveal the contents of V2 to the user. When creating a new version of a value, Knora also checks whether the new version is redundant, given the existing value. It is possible for the definition of 'redundant' can depend on the type of value, but in practice, it means that the values are strictly equal: any change, however trivial, is allowed.","title":"Duplicate and Redundant Values"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#versioning","text":"Each Knora value (i.e. something belonging to an OWL class derived from knora-base:Value ) is versioned. This means that once created, a value is never modified. Instead, 'changing' a value means creating a new version of the value --- actually a new value --- that points to the previous version using knora-base:previousValue . The versions of a value are a singly-linked list, pointing backwards into the past. When a new version of a value is made, the triple that points from the resource to the old version (using a subproperty of knora-base:hasValue ) is removed, and a triple is added to point from the resource to the new version. Thus the resource always points only to the current version of the value, and the older versions are available only via the current version's knora-base:previousValue predicate. Unlike values, resources (members of OWL classes derived from knora-base:Resource ) are not versioned. The data that is attached to a resource, other than its values, can be modified.","title":"Versioning"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#deleting","text":"Knora does not actually delete resources or values; it only marks them as deleted. Deleted data is normally hidden. All resources and values must have the predicate knora- base:isDeleted , whose object is a boolean. If a resource or value has been marked as deleted, it has knora-base:isDeleted true and has a knora-base:deleteDate . An optional knora-base:deleteComment may be added to explain why the resource or value has been marked as deleted. Normally, a value is marked as deleted without creating a new version of it. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. Since it is necessary to be able to find out when a resource was deleted, it is not possible to undelete a resource. Moreover, to simplify the checking of cardinality constraints, and for consistency with resources, it is not possible to undelete a value, and no new versions of a deleted value can be made. Instead, if desired, a new resource or value can be created by copying data from a deleted resource or value.","title":"Deleting"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#linking","text":"Links must be treated differently to other types of values. Knora needs to maintain information about the link, including permissions and a version history. Since the link does not have a unique IRI of its own, Knora uses RDF reifications for this purpose. Each link between two resources has exactly one (non-deleted) knora-base:LinkValue . The resource itself has a predicate that points to the LinkValue , using a naming convention in which the word Value is appended to the name of the link predicate to produce the link value predicate. For example, if a resource representing a book has a predicate called hasAuthor that points to another resource, it must also have a predicate called hasAuthorValue that points to the LinkValue in which information about the link is stored. To find a particular LinkValue , one can query it either by using its IRI (if known), or by using its rdf:subject , rdf:predicate , and rdf:object (and excluding link values that are marked as deleted). Like other values, link values are versioned. The link value predicate always points from the resource to the current version of the link value, and previous versions are available only via the current version's knora-base:previousValue predicate. Deleting a link means deleting the triple that links the two resources, and making a new version of the link value, marked with knora-base:isDeleted . A triple then points from the resource to this new, deleted version (using the link value property). The API allows a link to be 'changed' so that it points to a different target resource. This is implemented as follows: the existing triple connecting the two resources is removed, and a new triple is added using the same link property and pointing to the new target resource. A new version of the old link's LinkValue is made, marked with knora-base:isDeleted . A new LinkValue is made for the new link. The new LinkValue has no connection to the old one. When a resource contains knora-base:TextValue with Standoff markup that includes a reference to another resource, this reference is materialised as a direct link between the two resources, to make it easier to query. A special link property, knora-base:hasStandoffLinkTo , is used for this purpose. The corresponding link value property, knora-base:hasStandoffLinkToValue , points to a LinkValue . This LinkValue contains a reference count, indicated by knora-base:valueHasRefCount , that represents the number of text values in the containing resource that include one or more Standoff references to the specified target resource. Each time this number changes, a new version of this LinkValue is made. When the reference count reaches zero, the triple with knora-base:hasStandoffLinkTo is removed, and a new version of the LinkValue is made and marked with knora-base:isDeleted . If the same resource reference later appears again in a text value, a new triple is added using knora-base:hasStandoffLinkTo , and a new LinkValue is made, with no connection to the old one. For consistency, every LinkValue contains a reference count. If the link property is not knora-base:hasStandoffLinkTo , the reference count will always be either 1 (if the link exists) or 0 (if it has been deleted, in which case the link value will also be marked with knora-base:isDeleted ). When a LinkValue is created for a standoff resource reference, it is given the same permissions as the text value containing the reference.","title":"Linking"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#design","text":"","title":"Design"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#responsibilities-of-responders","text":"The resources responder ( ResourcesResponderV1 in API v1, ResourcesResponderV2 in API v2) has sole responsibility for generating SPARQL to create and updating resources, and the values responder ( ValuesResponderV1 or ValuesResponderV2 ) has sole responsibility for generating SPARQL to create and update values. When a new resource is created with its values, the values responder generates SPARQL statements that can be included in the INSERT clause of a SPARQL update to create the values, and the resources responder adds these statements to the SPARQL update that creates the resource. This ensures that the resource and its values are created in a single SPARQL update operation, and hence in a single triplestore transaction.","title":"Responsibilities of Responders"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#application-level-locking","text":"The 'read committed' isolation level cannot prevent a scenario where two users want to add the same data at the same time. It is possible that both requests would do pre-update checks and simultaneously find that it is OK to add the data, and that both updates would then succeed, inserting redundant data and possibly violating ontology constraints. Therefore, Knora uses short-lived, application-level write locks on resources, to ensure that only one request at a time can update a given resource. Before each update, the application acquires a lock on a resource. To prevent deadlocks, Knora locks only one resource per API operation. It then does the pre-update checks and the update, then releases the lock. The lock implementation (in IriLocker ) requires each API request message to include a random UUID, which is generated in the API Routing package. Using application-level locks allows us to do pre-update checks in their own transactions, and finally to do the SPARQL update in its own transaction.","title":"Application-level Locking"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#ensuring-data-consistency","text":"Knora enforces consistency constraints using three redundant mechanisms: By doing pre-update checks using SPARQL SELECT queries and cached ontology data. By doing checks in the WHERE clauses of SPARQL updates. By using GraphDB's built-in consistency checker (see Consistency Checking ). We take the view that redundant consistency checks are a good thing. Pre-update checks are SPARQL SELECT queries that are executed while holding an application-level lock on the resource to be updated. These checks should work with any triplestore, and can return helpful, Knora-specific error messages to the client if the request would violate a consistency constraint. However, the SPARQL update itself is our only chance to do pre-update checks in the same transaction that will perform the update. The design of the SPARQL 1.1 Update standard makes it possible to ensure that if certain conditions are not met, the update will not be performed. In our SPARQL update code, each update contains a WHERE clause, possibly a DELETE clause, and an INSERT clause. The WHERE clause is executed first. It performs consistency checks and provides values for variables that are used in the DELETE and/or INSERT clauses. In our updates, if the expectations of the WHERE clause are not met (e.g. because the data to be updated does not exist), the WHERE clause should return no results; as a result, the update will not be performed. Regardless of whether the update changes the contents of the triplestore, it returns nothing. If the update did nothing because the conditions of the WHERE clause were not met, the only way to find out is to do a SELECT afterwards. Moreover, in this case, there is no straightforward way to find out which conditions was not met. This is one reason why Knora does pre-update checks using separate SELECT queries and/or cached ontology data, before performing the update. This makes it possible to return specific error messages to the user to indicate why an update cannot be performed. Moreover, while some checks are easy to do in a SPARQL update, others are difficult, impractical, or impossible. Easy checks include checking whether a resource or value exists or is deleted, and checking that the knora-base:objectClassConstraint of a predicate matches the rdf:type of its intended object. Cardinality checks are not very difficult, but they perform poorly on Jena. Knora does not do permission checks in SPARQL, because its permission-checking algorithm is too complex to be implemented in SPARQL. For this reason, Knora's check for duplicate values cannot be done in SPARQL update code, because it relies on permission checks. In a bulk import operation, which can create a large number of resources in a single SPARQL update, a WHERE clause can become very expensive for the triplestore, in terms of memory as well as execution time. Moreover, RDF4J (and hence GraphDB) uses a recursive algorithm to parse SPARQL queries with WHERE clauses, so the size of a WHERE clause is limited by the stack space available to the Java Virtual Machine. Therefore, in bulk import operations, Knora uses INSERT DATA , which does not involve a WHERE clause. Bulk imports thus rely on checks (1) and (3) above.","title":"Ensuring Data Consistency"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#sparql-update-examples","text":"The following sample SPARQL update code is simpler than what Knora actually does. It is included here to illustrate the way Knora's SPARQL updates are structured and how concurrent updates are handled.","title":"SPARQL Update Examples"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#finding-a-value-iri-in-a-values-version-history","text":"We will need this query below. If a value is present in a resource property's version history, the query returns everything known about the value, or nothing otherwise: prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?p ?o WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") as ?searchValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?searchValue . ?searchValue ?p ?o . }","title":"Finding a value IRI in a value's version history"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#creating-the-initial-version-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 1\"\"\" ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) # Do nothing if the resource doesn't exist. ?resource rdf:type ?resourceClass . # Do nothing if the submitted value has the wrong type. ?property knora-base:objectClassConstraint ?valueType . } To find out whether the insert succeeded, the application can use the query in Finding a value IRI in a value's version history to look for the new IRI in the property's version history.","title":"Creating the initial version of a value"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#adding-a-new-version-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> DELETE { ?resource ?property ?currentValue . } INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 2\"\"\" ; knora-base:previousValue ?currentValue ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?currentValue) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) ?resource ?property ?currentValue . ?property knora-base:objectClassConstraint ?valueType . } The update request must contain the IRI of the most recent version of the value ( http://rdfh.ch/c5058f3a/values/c3295339 ). If this is not in fact the most recent version (because someone else has done an update), this operation will do nothing (because the WHERE clause will return no rows). To find out whether the update succeeded, the application will then need to do a SELECT query using the query in Finding a value IRI in a value's version history . In the case of concurrent updates, there are two possibilities: Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2, which user A verifies using a SELECT. User B then submits an update to version 1 but it fails, because version 1 is no longer the latest version. User B's SELECT will find that user B's new value IRI is absent from the value's version history. Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2. Before User A has time to do a SELECT, user B reads the new value and updates it again. Both users then do a SELECT, and find that both their new value IRIs are present in the value's version history.","title":"Adding a new version of a value"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#getting-all-versions-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?value ?valueTimestamp ?previousValue WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?currentValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?value . OPTIONAL { ?value knora-base:valueTimestamp ?valueTimestamp . } OPTIONAL { ?value knora-base:previousValue ?previousValue . } } This assumes that we know the current version of the value. If the version we have is not actually the current version, this query will return no rows.","title":"Getting all versions of a value"},{"location":"DSP-API/05-internals/development/","text":"Development Overview Starting GraphDB Build and Running Setup IntelliJ for development of Knora Testing Docker Cheat Sheet Monitoring Knora Profiling Knora Starting the Knora Stack inside Docker Container Updating Repositories Generating Client Test Data","title":"Index"},{"location":"DSP-API/05-internals/development/#development","text":"Overview Starting GraphDB Build and Running Setup IntelliJ for development of Knora Testing Docker Cheat Sheet Monitoring Knora Profiling Knora Starting the Knora Stack inside Docker Container Updating Repositories Generating Client Test Data","title":"Development"},{"location":"DSP-API/05-internals/development/bazel/","text":"Bazel The following section discusses on how to build and run tests for Knora-API with Bazel . Prerequisites To install the Bazel build tool, follow these steps: $ npm install -g @bazel/bazelisk This will install bazelisk which is a wrapper to the bazel binary. It will, when the bazel command ir run, automatically install the supported Bazel version, defined in the .bazelversion file in the root of the knora-api repository. Commands Build webapi : # build webapi $ bazel build //webapi/... # run all webapi tests $ bazel test //webapi//... Build Structure The Bazel build is defined in a number of files: - WORKSPACE - here are external dependencies defined - BUILD - there are a number of BUILD files throughout the directory structure where each represents a separate package responsible for everything underneath. - *.bzl - custom extensions loaded and used in BUILD files For a more detailed discussion, please see the Concepts and Terminology section in the Bazel documentation. Some Notes Override some .bazelrc settings in your own copy created at ~/.bazelrc : build --action_env=PATH=\"/usr/local/bin:/opt/local/bin:/usr/bin:/bin\" build --strategy=Scalac=worker build --worker_sandboxing query --package_path %workspace%:/usr/local/bin/bazel/base_workspace startup --host_jvm_args=-Djavax.net.ssl.trustStore=/Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home/lib/security/cacerts \\ --host_jvm_args=-Djavax.net.ssl.trustStorePassword=changeit Add Bazel Plugin and Project to IntelliJ The latest version of the Bazel plugin supports only IntelliJ upto version 2019.03.05 . After you make sure to run this version of IntelliJ, install the plugin from inside IntelliJ. Click on File -> Import Bazel Project and select twice next . Uncomment the Scala language and click Finish . Run single spec: bash $ bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec Run single spec and only tests containing gaga in the description bash $ bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec --test_arg=-z --test_arg=\"gaga\" Start Scala REPL bash $ bazel run //webapi:main_library_repl Build stamping By default, Bazel tries not to include anything about the system state in build outputs. However, released binaries and libraries often want to include something like the version they were built at or the branch or tag they came from. To reconcile this, Bazel has an option called the workspace status command . This command is run outside of any sandboxes on the local machine, so it can access anything about your source control, OS, or anything else you might want to include. It then dumps its output into bazel-out/volatile-status.txt , which you can use (and certain language rulesets provide support for accessing from code). Our workspace status command is defined in //tools/buildstamp/get_workspace_status . To use it on every bazel command, we need to supply it to each Bazel invocation, which is done by the following line found in .bazelrc : build --workspace_status_command=tools/buildstamp/get_workspace_status --stamp=yes Any line added to .bazelrc is invoked on each corresponding command. The //tools/buildstamp/get_workspace_status emits additional values to bazel-out/volatile-status.txt whereas BUILD_TIMESTAMP is emitted by Bazel itself: BUILD_SCM_REVISION 2d6df6c8fe2d56e3712eb26763f9727916a60164 BUILD_SCM_STATUS Modified BUILD_SCM_TAG v13.0.0-rc.21-17-g2d6df6c-dirty BUILD_TIMESTAMP 1604401028 The value of BUILD_SCM_TAG is used in //webapi/src/main/scala/org/knora/webapi/http/version/versioninfo , which emits a JAR containing VersionInfo.scala . This file is generated based on VersionInfoTemplate.scala found in the same Bazel package. In short, the versioninfo target producing the JAR library depends on the version_info_with_build_tag target which emits the VersionInfo.scala file which has the {BUILD_TAG} variable replaced by the current value of BUILD_SCM_TAG . In an intermediary step, the version_info_without_build_tag target, replaces variables coming from //third_party:versions.bzl .","title":"Bazel Notes"},{"location":"DSP-API/05-internals/development/bazel/#bazel","text":"The following section discusses on how to build and run tests for Knora-API with Bazel .","title":"Bazel"},{"location":"DSP-API/05-internals/development/bazel/#prerequisites","text":"To install the Bazel build tool, follow these steps: $ npm install -g @bazel/bazelisk This will install bazelisk which is a wrapper to the bazel binary. It will, when the bazel command ir run, automatically install the supported Bazel version, defined in the .bazelversion file in the root of the knora-api repository.","title":"Prerequisites"},{"location":"DSP-API/05-internals/development/bazel/#commands","text":"Build webapi : # build webapi $ bazel build //webapi/... # run all webapi tests $ bazel test //webapi//...","title":"Commands"},{"location":"DSP-API/05-internals/development/bazel/#build-structure","text":"The Bazel build is defined in a number of files: - WORKSPACE - here are external dependencies defined - BUILD - there are a number of BUILD files throughout the directory structure where each represents a separate package responsible for everything underneath. - *.bzl - custom extensions loaded and used in BUILD files For a more detailed discussion, please see the Concepts and Terminology section in the Bazel documentation.","title":"Build Structure"},{"location":"DSP-API/05-internals/development/bazel/#some-notes","text":"Override some .bazelrc settings in your own copy created at ~/.bazelrc : build --action_env=PATH=\"/usr/local/bin:/opt/local/bin:/usr/bin:/bin\" build --strategy=Scalac=worker build --worker_sandboxing query --package_path %workspace%:/usr/local/bin/bazel/base_workspace startup --host_jvm_args=-Djavax.net.ssl.trustStore=/Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home/lib/security/cacerts \\ --host_jvm_args=-Djavax.net.ssl.trustStorePassword=changeit Add Bazel Plugin and Project to IntelliJ The latest version of the Bazel plugin supports only IntelliJ upto version 2019.03.05 . After you make sure to run this version of IntelliJ, install the plugin from inside IntelliJ. Click on File -> Import Bazel Project and select twice next . Uncomment the Scala language and click Finish . Run single spec: bash $ bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec Run single spec and only tests containing gaga in the description bash $ bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec --test_arg=-z --test_arg=\"gaga\" Start Scala REPL bash $ bazel run //webapi:main_library_repl","title":"Some Notes"},{"location":"DSP-API/05-internals/development/bazel/#build-stamping","text":"By default, Bazel tries not to include anything about the system state in build outputs. However, released binaries and libraries often want to include something like the version they were built at or the branch or tag they came from. To reconcile this, Bazel has an option called the workspace status command . This command is run outside of any sandboxes on the local machine, so it can access anything about your source control, OS, or anything else you might want to include. It then dumps its output into bazel-out/volatile-status.txt , which you can use (and certain language rulesets provide support for accessing from code). Our workspace status command is defined in //tools/buildstamp/get_workspace_status . To use it on every bazel command, we need to supply it to each Bazel invocation, which is done by the following line found in .bazelrc : build --workspace_status_command=tools/buildstamp/get_workspace_status --stamp=yes Any line added to .bazelrc is invoked on each corresponding command. The //tools/buildstamp/get_workspace_status emits additional values to bazel-out/volatile-status.txt whereas BUILD_TIMESTAMP is emitted by Bazel itself: BUILD_SCM_REVISION 2d6df6c8fe2d56e3712eb26763f9727916a60164 BUILD_SCM_STATUS Modified BUILD_SCM_TAG v13.0.0-rc.21-17-g2d6df6c-dirty BUILD_TIMESTAMP 1604401028 The value of BUILD_SCM_TAG is used in //webapi/src/main/scala/org/knora/webapi/http/version/versioninfo , which emits a JAR containing VersionInfo.scala . This file is generated based on VersionInfoTemplate.scala found in the same Bazel package. In short, the versioninfo target producing the JAR library depends on the version_info_with_build_tag target which emits the VersionInfo.scala file which has the {BUILD_TAG} variable replaced by the current value of BUILD_SCM_TAG . In an intermediary step, the version_info_without_build_tag target, replaces variables coming from //third_party:versions.bzl .","title":"Build stamping"},{"location":"DSP-API/05-internals/development/building-and-running/","text":"Building and Running Running the stack With Docker installed, Run the following: $ make init-db-test to create the knora-test repository and initialize it with loading some test data into the triplestore (Fuseki). Start the entire knora-stack (fuseki (db), sipi, redis, api, salsah1) with the following command: $ make stack-up Then try opening http://localhost:3333/v1/resources/http%3A%2F%2Frdfh.ch%2F0803%2Fc5058f3a in a web browser. You should see a response in JSON describing a book. Note : To delete the existing containers and for a clean start, before creating the knora-test repository explained in the first step above, run the following: $ make stack-down-delete-volumes This stops the knora-stack and deletes any created volumes (deletes the database!). To only shut down the Knora-Stack without deleting the containers: $ make stack-down To restart the knora-api use the following command: $ make stack-restart-api If a change is made to knora-api code, only its image needs to be rebuilt. In that case, use $ make stack-up-fast which starts the knora-stack by skipping rebuilding most of the images (only api image is rebuilt). To work on Metadata, use $ make stack-up-with-metadata which will put three example metadata sets to the projects anything , images and dokubib . This data can then be consumed from localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 , localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F00FF and localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0804 . Managing Containers in Docker Dashboard The Docker Desktop is installed on your computer during the installation of docker, it enables easy management of docker containers and access to Docker Hub. To manage your docker containers, docker desktop provides a dashbord. In docker dashboard, you can see all the running containers, stop, start, restart, or completely delete them. For example, when you start the knora-stack as explained above, in the docker dashboard you will see following: Access the logs To read information logged out of any container (db, api, etc.), click on the container in the dashboard and choose logs . The example, below shows the logs of the database (db) container that includes the last SPARQL query sent to the triplestore. Note that, you can also print out the log information directly from the command line. For example, the same logs of the database container can be printed out using the following command: $ make stack-logs-db Similarly, the logs of the other containers can be printed out by running make with stack-logs-api , stack-logs-sipi , or stack-logs-redis . These commands print out and follow the logs, to only print the logs out without following, use -no-follow version of the commands for example: $ make stack-logs-db-no-follow Lastly, to print out the entire logs of the running knora-stack, use $ make stack-logs Running the automated tests To run all test targets, use the following in the command line: $ make test To run only the dsp-api integration tests, use $ make test-it To run only the dsp-api unit tests, use $ make test-unit Lastly, to run all dsp-api test, use $ make test-webapi As explained in the bazel document , to run a single test from the command line, for example SearchV1R2RSpec , run the following: bash $ bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec Note: to run tests, the api container must be stopped first! Build and Publish Documentation First, you need to install the requirements through: $ make docs-install-requirements Then, to build docs into the local site folder, run the following command: $ make docs-build At this point, you can serve the docs to view them locally using $ make docs-serve Lastly, to build and publish docs to Github Pages, use $ make docs-publish Build and Publish Docker Images To build and publish all Docker images locally $ make docker-build To publish all Docker images to Dockerhub $ make docker-publish Load Testing on Mac OS X To test Knora with many concurrent connections on Mac OS X, you will need to adjust some kernel parameters to allow more open connections, to recycle ephemeral ports more quickly, and to use a wider range of ephemeral port numbers. The script webapi/scripts/macOS-kernel-test-config.sh will do this. Continuous Integration For continuous integration testing, we use Github CI Actions. Every commit pushed to the git repository or every pull request, triggers the build. Additionally, in Github there is a small checkmark beside every commit, signaling the status of the build (successful, unsuccessful, ongoing). The build that is executed on Github CI Actions is defined in .github/workflows/main.yml . Webapi Server Startup-Flags The Webapi-Server can be started with a number of flags. loadDemoData - Flag When the webapi-server is started with the loadDemoData flag, then at startup, the data which is configured in application.conf under the app.triplestore.rdf-data key is loaded into the triplestore, and any data in the triplestore is removed beforehand. allowReloadOverHTTP - Flag When the webapi.server is started with the allowReloadOverHTTP flag ( reStart -r ), then the v1/store/ResetTriplestoreContent route is activated. This route accepts a POST request, with a JSON payload consisting of the following example content: [ { \"path\": \"knora-ontologies/knora-base.ttl\", \"name\": \"http://www.knora.org/ontology/knora-base\" }, { \"path\": \"knora-ontologies/salsah-gui.ttl\", \"name\": \"http://www.knora.org/ontology/salsah-gui\" }, { \"path\": \"test_data/ontologies/incunabula-onto.ttl\", \"name\": \"http://www.knora.org/ontology/0803/incunabula\" }, { \"path\": \"test_data/all_data/incunabula-data.ttl\", \"name\": \"http://www.knora.org/data/incunabula\" } ] This content corresponds to the payload sent with the ResetTriplestoreContent message, defined inside the org.knora.webapi.messages.v1.store.triplestoremessages package. The path being the relative path to the ttl file which will be loaded into a named graph by the name of name .","title":"Build and Running"},{"location":"DSP-API/05-internals/development/building-and-running/#building-and-running","text":"","title":"Building and Running"},{"location":"DSP-API/05-internals/development/building-and-running/#running-the-stack","text":"With Docker installed, Run the following: $ make init-db-test to create the knora-test repository and initialize it with loading some test data into the triplestore (Fuseki). Start the entire knora-stack (fuseki (db), sipi, redis, api, salsah1) with the following command: $ make stack-up Then try opening http://localhost:3333/v1/resources/http%3A%2F%2Frdfh.ch%2F0803%2Fc5058f3a in a web browser. You should see a response in JSON describing a book. Note : To delete the existing containers and for a clean start, before creating the knora-test repository explained in the first step above, run the following: $ make stack-down-delete-volumes This stops the knora-stack and deletes any created volumes (deletes the database!). To only shut down the Knora-Stack without deleting the containers: $ make stack-down To restart the knora-api use the following command: $ make stack-restart-api If a change is made to knora-api code, only its image needs to be rebuilt. In that case, use $ make stack-up-fast which starts the knora-stack by skipping rebuilding most of the images (only api image is rebuilt). To work on Metadata, use $ make stack-up-with-metadata which will put three example metadata sets to the projects anything , images and dokubib . This data can then be consumed from localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 , localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F00FF and localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0804 .","title":"Running the stack"},{"location":"DSP-API/05-internals/development/building-and-running/#managing-containers-in-docker-dashboard","text":"The Docker Desktop is installed on your computer during the installation of docker, it enables easy management of docker containers and access to Docker Hub. To manage your docker containers, docker desktop provides a dashbord. In docker dashboard, you can see all the running containers, stop, start, restart, or completely delete them. For example, when you start the knora-stack as explained above, in the docker dashboard you will see following:","title":"Managing Containers in Docker Dashboard"},{"location":"DSP-API/05-internals/development/building-and-running/#access-the-logs","text":"To read information logged out of any container (db, api, etc.), click on the container in the dashboard and choose logs . The example, below shows the logs of the database (db) container that includes the last SPARQL query sent to the triplestore. Note that, you can also print out the log information directly from the command line. For example, the same logs of the database container can be printed out using the following command: $ make stack-logs-db Similarly, the logs of the other containers can be printed out by running make with stack-logs-api , stack-logs-sipi , or stack-logs-redis . These commands print out and follow the logs, to only print the logs out without following, use -no-follow version of the commands for example: $ make stack-logs-db-no-follow Lastly, to print out the entire logs of the running knora-stack, use $ make stack-logs","title":"Access the logs"},{"location":"DSP-API/05-internals/development/building-and-running/#running-the-automated-tests","text":"To run all test targets, use the following in the command line: $ make test To run only the dsp-api integration tests, use $ make test-it To run only the dsp-api unit tests, use $ make test-unit Lastly, to run all dsp-api test, use $ make test-webapi As explained in the bazel document , to run a single test from the command line, for example SearchV1R2RSpec , run the following: bash $ bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec Note: to run tests, the api container must be stopped first!","title":"Running the automated tests"},{"location":"DSP-API/05-internals/development/building-and-running/#build-and-publish-documentation","text":"First, you need to install the requirements through: $ make docs-install-requirements Then, to build docs into the local site folder, run the following command: $ make docs-build At this point, you can serve the docs to view them locally using $ make docs-serve Lastly, to build and publish docs to Github Pages, use $ make docs-publish","title":"Build and Publish Documentation"},{"location":"DSP-API/05-internals/development/building-and-running/#build-and-publish-docker-images","text":"To build and publish all Docker images locally $ make docker-build To publish all Docker images to Dockerhub $ make docker-publish","title":"Build and Publish Docker Images"},{"location":"DSP-API/05-internals/development/building-and-running/#load-testing-on-mac-os-x","text":"To test Knora with many concurrent connections on Mac OS X, you will need to adjust some kernel parameters to allow more open connections, to recycle ephemeral ports more quickly, and to use a wider range of ephemeral port numbers. The script webapi/scripts/macOS-kernel-test-config.sh will do this.","title":"Load Testing on Mac OS X"},{"location":"DSP-API/05-internals/development/building-and-running/#continuous-integration","text":"For continuous integration testing, we use Github CI Actions. Every commit pushed to the git repository or every pull request, triggers the build. Additionally, in Github there is a small checkmark beside every commit, signaling the status of the build (successful, unsuccessful, ongoing). The build that is executed on Github CI Actions is defined in .github/workflows/main.yml .","title":"Continuous Integration"},{"location":"DSP-API/05-internals/development/building-and-running/#webapi-server-startup-flags","text":"The Webapi-Server can be started with a number of flags.","title":"Webapi Server Startup-Flags"},{"location":"DSP-API/05-internals/development/building-and-running/#loaddemodata-flag","text":"When the webapi-server is started with the loadDemoData flag, then at startup, the data which is configured in application.conf under the app.triplestore.rdf-data key is loaded into the triplestore, and any data in the triplestore is removed beforehand.","title":"loadDemoData - Flag"},{"location":"DSP-API/05-internals/development/building-and-running/#allowreloadoverhttp-flag","text":"When the webapi.server is started with the allowReloadOverHTTP flag ( reStart -r ), then the v1/store/ResetTriplestoreContent route is activated. This route accepts a POST request, with a JSON payload consisting of the following example content: [ { \"path\": \"knora-ontologies/knora-base.ttl\", \"name\": \"http://www.knora.org/ontology/knora-base\" }, { \"path\": \"knora-ontologies/salsah-gui.ttl\", \"name\": \"http://www.knora.org/ontology/salsah-gui\" }, { \"path\": \"test_data/ontologies/incunabula-onto.ttl\", \"name\": \"http://www.knora.org/ontology/0803/incunabula\" }, { \"path\": \"test_data/all_data/incunabula-data.ttl\", \"name\": \"http://www.knora.org/data/incunabula\" } ] This content corresponds to the payload sent with the ResetTriplestoreContent message, defined inside the org.knora.webapi.messages.v1.store.triplestoremessages package. The path being the relative path to the ttl file which will be loaded into a named graph by the name of name .","title":"allowReloadOverHTTP - Flag"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/","text":"Docker Cheat Sheet A complete cheat sheet can be found here Lifecycle docker create creates a container but does not start it. docker run creates and starts a container in one operation. docker rename allows the container to be renamed. docker rm deletes a container. docker update updates a container's resource limits. If you want a transient container, docker run --rm will remove the container after it stops. If you want to map a directory on the host to a docker container, docker run -v $HOSTDIR:$DOCKERDIR . Starting and Stopping docker start starts a container so it is running. docker stop stops a running container. docker restart stops and starts a container. docker pause pauses a running container, \"freezing\" it in place. docker attach will connect to a running container. Info docker ps shows running containers. docker logs gets logs from container. (You can use a custom log driver, but logs is only available for json-file and journald in 1.10) docker inspect looks at all the info on a container (including IP address). docker events gets events from container. docker port shows public facing port of container. docker top shows running processes in container. docker stats shows containers' resource usage statistics. docker diff shows changed files in the container's FS. docker ps -a shows running and stopped containers. docker stats --all shows a running list of containers. Executing Commands docker exec to execute a command in container. To enter a running container, attach a new shell process to a running container called foo, use: docker exec -it foo /bin/bash . Images docker images shows all images. docker build creates image from Dockerfile.","title":"Docker Cheat Sheet"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#docker-cheat-sheet","text":"A complete cheat sheet can be found here","title":"Docker Cheat Sheet"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#lifecycle","text":"docker create creates a container but does not start it. docker run creates and starts a container in one operation. docker rename allows the container to be renamed. docker rm deletes a container. docker update updates a container's resource limits. If you want a transient container, docker run --rm will remove the container after it stops. If you want to map a directory on the host to a docker container, docker run -v $HOSTDIR:$DOCKERDIR .","title":"Lifecycle"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#starting-and-stopping","text":"docker start starts a container so it is running. docker stop stops a running container. docker restart stops and starts a container. docker pause pauses a running container, \"freezing\" it in place. docker attach will connect to a running container.","title":"Starting and Stopping"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#info","text":"docker ps shows running containers. docker logs gets logs from container. (You can use a custom log driver, but logs is only available for json-file and journald in 1.10) docker inspect looks at all the info on a container (including IP address). docker events gets events from container. docker port shows public facing port of container. docker top shows running processes in container. docker stats shows containers' resource usage statistics. docker diff shows changed files in the container's FS. docker ps -a shows running and stopped containers. docker stats --all shows a running list of containers.","title":"Info"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#executing-commands","text":"docker exec to execute a command in container. To enter a running container, attach a new shell process to a running container called foo, use: docker exec -it foo /bin/bash .","title":"Executing Commands"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#images","text":"docker images shows all images. docker build creates image from Dockerfile.","title":"Images"},{"location":"DSP-API/05-internals/development/docker-compose/","text":"Starting the Knora Stack inside Docker Container To run Knora locally, we provide docker-compose.yml which can be used to start GraphDB, Sipi, Webapi running each in its own Docker container. For GraphDB it is additionally necessary to define two environment variables: $ export KNORA_GDB_LICENSE # full path to the GraphDB-SE license file, e.g., /Users/name/GDB/GDB.license $ export KNORA_GDB_HOME # full path to a local folder where GraphDB should store it's data, e.g., /users/name/GDB/home Per default, GraphDB-SE is started. If GraphDB-Free is needed, because there is no awailable license, then a third environment variable can be set to something like: $ export KNORA_GDB_IMAGE=daschswiss/graphdb-free:8.3.1 To run the whole stack: $ docker-compose up For additional information please see the Docker Compose documentation","title":"Starting the DSP-Stack inside Docker Container"},{"location":"DSP-API/05-internals/development/docker-compose/#starting-the-knora-stack-inside-docker-container","text":"To run Knora locally, we provide docker-compose.yml which can be used to start GraphDB, Sipi, Webapi running each in its own Docker container. For GraphDB it is additionally necessary to define two environment variables: $ export KNORA_GDB_LICENSE # full path to the GraphDB-SE license file, e.g., /Users/name/GDB/GDB.license $ export KNORA_GDB_HOME # full path to a local folder where GraphDB should store it's data, e.g., /users/name/GDB/home Per default, GraphDB-SE is started. If GraphDB-Free is needed, because there is no awailable license, then a third environment variable can be set to something like: $ export KNORA_GDB_IMAGE=daschswiss/graphdb-free:8.3.1 To run the whole stack: $ docker-compose up For additional information please see the Docker Compose documentation","title":"Starting the Knora Stack inside Docker Container"},{"location":"DSP-API/05-internals/development/generating-client-test-data/","text":"Generating Client Test Data Requirements Generate test requests and responses for Knora's routes, to be used in testing client code without the need for a running Knora instance. Implementation Client test data is generated as a side effect of running Knora's E2E tests. E2E tests use ClientTestDataCollector to collect test API requests and responses. The implementation of ClientTestDataCollector collects these in a Redis hash. When the E2E tests have completed, the script webapi/scripts/dump-client-test-data.sh saves the collected test data in a Zip file. It then checks the filenames in the Zip file by comparing them with the list in webapi/scripts/expected-client-test-data.txt . Usage On macOS, you will need to install Redis in order to have the redis-cli command-line tool: brew install redis To generate client test data, type: make client-test-data When the tests have finished running, you will find the file client-test-data.zip in the current directory. If generated client test data changes, run make client-test-data , then run this script to update the list of expected test data files: webapi/scripts/update-expected-client-test-data.sh client-test-data.zip","title":"Generating Client Test Data"},{"location":"DSP-API/05-internals/development/generating-client-test-data/#generating-client-test-data","text":"","title":"Generating Client Test Data"},{"location":"DSP-API/05-internals/development/generating-client-test-data/#requirements","text":"Generate test requests and responses for Knora's routes, to be used in testing client code without the need for a running Knora instance.","title":"Requirements"},{"location":"DSP-API/05-internals/development/generating-client-test-data/#implementation","text":"Client test data is generated as a side effect of running Knora's E2E tests. E2E tests use ClientTestDataCollector to collect test API requests and responses. The implementation of ClientTestDataCollector collects these in a Redis hash. When the E2E tests have completed, the script webapi/scripts/dump-client-test-data.sh saves the collected test data in a Zip file. It then checks the filenames in the Zip file by comparing them with the list in webapi/scripts/expected-client-test-data.txt .","title":"Implementation"},{"location":"DSP-API/05-internals/development/generating-client-test-data/#usage","text":"On macOS, you will need to install Redis in order to have the redis-cli command-line tool: brew install redis To generate client test data, type: make client-test-data When the tests have finished running, you will find the file client-test-data.zip in the current directory. If generated client test data changes, run make client-test-data , then run this script to update the list of expected test data files: webapi/scripts/update-expected-client-test-data.sh client-test-data.zip","title":"Usage"},{"location":"DSP-API/05-internals/development/graphdb/","text":"Starting GraphDB Attention! The information on this page is left inside the documentation for historic reasons. GraphDB is not used for active development anymore. GraphDB SE Inside the Knora git repository, there is a folder called /triplestores/graphdb-se containing the latest supported version of the GraphDB-SE distribution archive. Running Locally Unzip graphdb-se-x.x.x-dist.zip to a place of your choosing and run the following: $ cd /to/unziped/location $ ./bin/graphdb -Dgraphdb.license.file=/path/to/GRAPHDB_SE.license Running inside Docker Important Steps To be able to successfully run GraphDB inside docker two important steps need to be done beforhand: Install Docker from http://docker.com . Copy the GraphDB-SE license file into a folder of you choosing and name it GRAPHDB_SE.license . We will mount this folder into the docker container, so that the license can be used by GraphDB running inside the container. Usage $ docker run --rm -it -v /path/to/license/folder:/external -p 7200:7200 daschswiss/graphdb --rm removes the container as soon as you stop it -p forwards the exposed port to your host (or if you use boot2docker to this IP) -it allows interactive mode, so you see if something gets deployed After the GraphDB inside the docker container has started, you can find the GraphDB workbench here: http://localhost:7200 Above, we create and start a transient container ( --rm flag). To create a container that we can stop and start again at a later time, follow the following steps: $ docker run --name graphdb -d -t -v /path/to/license/folder:/external -p 7200:7200 daschswiss/graphdb (to see the console output, attach to the container; to detach press Ctrl-c) $ docker attach graphdb (to stop the container) $ docker stop graphdb (to start the container again) $ docker start graphdb (to remove the container; needs to be stopped) $ docker rm graphdb --name give the container a name -d run container in background and print container ID -t allocate a pseudo TTY, so you see the console output -p forwards the exposed port to your host GraphDB Free You can run GraphDB Free locally as described for GraphDB SE above, or you can use Knora's pre-built GraphDB Free Docker image: $ docker run --rm -p 7200:7200 daschswiss/graphdb-free","title":"Starting GraphDB"},{"location":"DSP-API/05-internals/development/graphdb/#starting-graphdb","text":"Attention! The information on this page is left inside the documentation for historic reasons. GraphDB is not used for active development anymore.","title":"Starting GraphDB"},{"location":"DSP-API/05-internals/development/graphdb/#graphdb-se","text":"Inside the Knora git repository, there is a folder called /triplestores/graphdb-se containing the latest supported version of the GraphDB-SE distribution archive.","title":"GraphDB SE"},{"location":"DSP-API/05-internals/development/graphdb/#running-locally","text":"Unzip graphdb-se-x.x.x-dist.zip to a place of your choosing and run the following: $ cd /to/unziped/location $ ./bin/graphdb -Dgraphdb.license.file=/path/to/GRAPHDB_SE.license","title":"Running Locally"},{"location":"DSP-API/05-internals/development/graphdb/#running-inside-docker","text":"","title":"Running inside Docker"},{"location":"DSP-API/05-internals/development/graphdb/#important-steps","text":"To be able to successfully run GraphDB inside docker two important steps need to be done beforhand: Install Docker from http://docker.com . Copy the GraphDB-SE license file into a folder of you choosing and name it GRAPHDB_SE.license . We will mount this folder into the docker container, so that the license can be used by GraphDB running inside the container.","title":"Important Steps"},{"location":"DSP-API/05-internals/development/graphdb/#usage","text":"$ docker run --rm -it -v /path/to/license/folder:/external -p 7200:7200 daschswiss/graphdb --rm removes the container as soon as you stop it -p forwards the exposed port to your host (or if you use boot2docker to this IP) -it allows interactive mode, so you see if something gets deployed After the GraphDB inside the docker container has started, you can find the GraphDB workbench here: http://localhost:7200 Above, we create and start a transient container ( --rm flag). To create a container that we can stop and start again at a later time, follow the following steps: $ docker run --name graphdb -d -t -v /path/to/license/folder:/external -p 7200:7200 daschswiss/graphdb (to see the console output, attach to the container; to detach press Ctrl-c) $ docker attach graphdb (to stop the container) $ docker stop graphdb (to start the container again) $ docker start graphdb (to remove the container; needs to be stopped) $ docker rm graphdb --name give the container a name -d run container in background and print container ID -t allocate a pseudo TTY, so you see the console output -p forwards the exposed port to your host","title":"Usage"},{"location":"DSP-API/05-internals/development/graphdb/#graphdb-free","text":"You can run GraphDB Free locally as described for GraphDB SE above, or you can use Knora's pre-built GraphDB Free Docker image: $ docker run --rm -p 7200:7200 daschswiss/graphdb-free","title":"GraphDB Free"},{"location":"DSP-API/05-internals/development/intellij-config/","text":"Setup IntelliJ for development of Knora Create an IntelliJ Project for Knora Download and install a version of IntelliJ IDEA that supports Bazel , eg. version 2019.03.05 . Follow the installation procedure and install the Scala plugin Add Bazel Plugin: run InteliJ and install the plugin from inside IntelliJ. Create a project for Knora: restart InteliJ and create a project for Knora using Import Bazel Project option. Make sure that the Bazel Workspace points to the path of Knora and click next . Select the Generate from BUILD file option and give the path to the main BUILD.bazel file of Knora, click next . Uncomment the Scala language and click Finish . At this point a .ijwb file is created for Knora project and added to the welcome screen of InteiJ. You can open the project by clicking on it. Once the project is built and opened in InteliJ, make sure that project in synced with Bazel build files by clicking on Bazel logo Sync Project with Build Files . This needs to be repeated every time there is a change in a BUILD.bazel file. Setup IntelliJ Code Formatter Use Scalafmt in IntelliJ IDEA to format Scala code. In IntelliJ editor setting ( Preferences -> Editor -> Code Style -> Scala ), choose Scalafmt as formatter and check the box for Reformat on file save as shown below: Use IntelliJ IDEA's Run/Debugger Configuration with Knora First, you need to create an application configuration to run or debug a code. Here the configuration is explained using a test as an example, but similarly the application configuration of InteliJ can be used for building the webapi. To run a specific test in a command line using Bazel, you would need to give the path of the test relative to its package as defined in the BUILD.bazel of the package. For example, to run the test GravsearchTypeInspectorSpec in the command line, you would need to enter bazel test //webapi/src/test/scala/org/knora/webapi/messages/util/search:GravsearchTypeInspectorSpec . Now to run or debug the same test and its underlying code in InteliJ, a new configuration should be set up: Click on the 'Add Configuration' to create a new application configuration. Click on the + and choose Bazel Command Give the type of the command, i.e. test and the path parameter, as shown below. Then press Apply , and finish the configuration by pressing OK . After the configuration is completed, it will appear in a drop-down menu that shows all available configurations. To run a configured command, eg. to run the test GravsearchTypeInspectorSpec , choose its configuration from the drop-down menu click on the Run symbol, the results will appear in the a Run window. Note that, before running the test, the docker container of api should be stopped. To debug the code for example by executing a test: Click on a line-number to add a breakpoint. Choose the respective configuration from the drop-down menu. Click on the debugging symbol to start the application with a debugger attached, as shown below: Profile Knora Using VisualVM in IntelliJ First, download and install VisualVM . Then, in IntelliJ, under Preferences -> Plugins, search for the VisualVM Launcher , click on \"Search in repositories\", install the plugin, and restart IntelliJ. IntelliJ's toolbar should now contain a button with a green triangle on an orange circle, with the tooltip \"Run with VisualVM\": You can use this button to run the class org.knora.webapi.app.Main and profile it in VisualVM. The first time you do this, IntelliJ will ask you for the path to the VisualVM executable. On macOS this is /Applications/VisualVM.app/Contents/MacOS/visualvm . When VisualVM starts, it will open a window like this: To use the profiler, click on the \"Sampler\" tab, then on the \"CPU\" button: Now run some DSP-API operations that you're interested in profiling, preferably several times to allow the sampler to collect enough data. Then click on the \"Snapshot\" button: In the snapshot, you'll see a list of threads that were profiled: You can then browse the call tree for each thread, looking for Knora method calls, to see the total time spent in each method:","title":"Setup IntelliJ for development of DSP-API"},{"location":"DSP-API/05-internals/development/intellij-config/#setup-intellij-for-development-of-knora","text":"","title":"Setup IntelliJ for development of Knora"},{"location":"DSP-API/05-internals/development/intellij-config/#create-an-intellij-project-for-knora","text":"Download and install a version of IntelliJ IDEA that supports Bazel , eg. version 2019.03.05 . Follow the installation procedure and install the Scala plugin Add Bazel Plugin: run InteliJ and install the plugin from inside IntelliJ. Create a project for Knora: restart InteliJ and create a project for Knora using Import Bazel Project option. Make sure that the Bazel Workspace points to the path of Knora and click next . Select the Generate from BUILD file option and give the path to the main BUILD.bazel file of Knora, click next . Uncomment the Scala language and click Finish . At this point a .ijwb file is created for Knora project and added to the welcome screen of InteiJ. You can open the project by clicking on it. Once the project is built and opened in InteliJ, make sure that project in synced with Bazel build files by clicking on Bazel logo Sync Project with Build Files . This needs to be repeated every time there is a change in a BUILD.bazel file.","title":"Create an IntelliJ Project for Knora"},{"location":"DSP-API/05-internals/development/intellij-config/#setup-intellij-code-formatter","text":"Use Scalafmt in IntelliJ IDEA to format Scala code. In IntelliJ editor setting ( Preferences -> Editor -> Code Style -> Scala ), choose Scalafmt as formatter and check the box for Reformat on file save as shown below:","title":"Setup IntelliJ Code Formatter"},{"location":"DSP-API/05-internals/development/intellij-config/#use-intellij-ideas-rundebugger-configuration-with-knora","text":"First, you need to create an application configuration to run or debug a code. Here the configuration is explained using a test as an example, but similarly the application configuration of InteliJ can be used for building the webapi. To run a specific test in a command line using Bazel, you would need to give the path of the test relative to its package as defined in the BUILD.bazel of the package. For example, to run the test GravsearchTypeInspectorSpec in the command line, you would need to enter bazel test //webapi/src/test/scala/org/knora/webapi/messages/util/search:GravsearchTypeInspectorSpec . Now to run or debug the same test and its underlying code in InteliJ, a new configuration should be set up: Click on the 'Add Configuration' to create a new application configuration. Click on the + and choose Bazel Command Give the type of the command, i.e. test and the path parameter, as shown below. Then press Apply , and finish the configuration by pressing OK . After the configuration is completed, it will appear in a drop-down menu that shows all available configurations. To run a configured command, eg. to run the test GravsearchTypeInspectorSpec , choose its configuration from the drop-down menu click on the Run symbol, the results will appear in the a Run window. Note that, before running the test, the docker container of api should be stopped. To debug the code for example by executing a test: Click on a line-number to add a breakpoint. Choose the respective configuration from the drop-down menu. Click on the debugging symbol to start the application with a debugger attached, as shown below:","title":"Use IntelliJ IDEA's Run/Debugger Configuration with Knora"},{"location":"DSP-API/05-internals/development/intellij-config/#profile-knora-using-visualvm-in-intellij","text":"First, download and install VisualVM . Then, in IntelliJ, under Preferences -> Plugins, search for the VisualVM Launcher , click on \"Search in repositories\", install the plugin, and restart IntelliJ. IntelliJ's toolbar should now contain a button with a green triangle on an orange circle, with the tooltip \"Run with VisualVM\": You can use this button to run the class org.knora.webapi.app.Main and profile it in VisualVM. The first time you do this, IntelliJ will ask you for the path to the VisualVM executable. On macOS this is /Applications/VisualVM.app/Contents/MacOS/visualvm . When VisualVM starts, it will open a window like this: To use the profiler, click on the \"Sampler\" tab, then on the \"CPU\" button: Now run some DSP-API operations that you're interested in profiling, preferably several times to allow the sampler to collect enough data. Then click on the \"Snapshot\" button: In the snapshot, you'll see a list of threads that were profiled: You can then browse the call tree for each thread, looking for Knora method calls, to see the total time spent in each method:","title":"Profile Knora Using VisualVM in IntelliJ"},{"location":"DSP-API/05-internals/development/migrationNotes/","text":"Breaking Changes and Migration Notes dsp-api V14 We are slowly moving towards unifying the form of all entity IRIs (project, user, resource, value, etc.). All these entities should end with a unique base64Encoded-UUID without padding as 22-characters string. Following breaking changes are implemented: - Enforce all custom IRIs given to entities during creation to end with a valid base64Encoded UUID ( PR #1884 ).","title":"migrationNotes"},{"location":"DSP-API/05-internals/development/migrationNotes/#breaking-changes-and-migration-notes","text":"","title":"Breaking Changes and Migration Notes"},{"location":"DSP-API/05-internals/development/migrationNotes/#dsp-api-v14","text":"We are slowly moving towards unifying the form of all entity IRIs (project, user, resource, value, etc.). All these entities should end with a unique base64Encoded-UUID without padding as 22-characters string. Following breaking changes are implemented: - Enforce all custom IRIs given to entities during creation to end with a valid base64Encoded UUID ( PR #1884 ).","title":"dsp-api V14"},{"location":"DSP-API/05-internals/development/monitoring/","text":"Monitoring Knora Monitoring is implemented by using the Prometheus / Grafana stack. Usage: 1) Start webapi with the necessary -p option (e.g., from inside sbt: run -p or reStart -p 2) Start the monitoring stack by executing the following line inside the monitoring folder: $ WEBAPIHOST=<YourLocalIP> ADMIN_USER=admin ADMIN_PASSWORD=admin docker-compose up -d 3) Head over to localhost:3000, log in using the admin username and password, and open the \"Webapi Akka Actor System\" dashboard. 4) To shut down the monitoring stack, run the following line inside the monitoring folder: $ docker-compose down","title":"Monitoring DSP-API"},{"location":"DSP-API/05-internals/development/monitoring/#monitoring-knora","text":"Monitoring is implemented by using the Prometheus / Grafana stack.","title":"Monitoring Knora"},{"location":"DSP-API/05-internals/development/monitoring/#usage","text":"1) Start webapi with the necessary -p option (e.g., from inside sbt: run -p or reStart -p 2) Start the monitoring stack by executing the following line inside the monitoring folder: $ WEBAPIHOST=<YourLocalIP> ADMIN_USER=admin ADMIN_PASSWORD=admin docker-compose up -d 3) Head over to localhost:3000, log in using the admin username and password, and open the \"Webapi Akka Actor System\" dashboard. 4) To shut down the monitoring stack, run the following line inside the monitoring folder: $ docker-compose down","title":"Usage:"},{"location":"DSP-API/05-internals/development/overview/","text":"Overview Developing for DSP-API requires a complete local installation of Knora. The different parts are: The cloned DSP-API Github repository One of the supplied triplestores in the DSP-API Github repository (GraphDB-SE 8 or Fuseki 3). Sipi by building from source or using the docker image Knora Github Repository $ git clone https://github.com/dasch-swiss/dsp-api Triplestore A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Ontotext GraphDB , a high-performance, proprietary triplestore. We recommend GraphDB Standard Edition, but GraphDB Free (which is proprietary but available free of charge) also works. DSP-API includes support for Apache Jena , which is free software , but use of Jena is deprecated, and support for it will probably be removed in the future. Built-in support and configuration for other triplestores is planned. See the chapter on Starting GraphDB for more details. Sipi Build Sipi Docker Image The Sipi docker image needs to be build by hand, as it requires the Kakadu distribution. To build the image, and push it to the docker hub, follow the following steps: $ git clone https://github.com/dhlab-basel/docker-sipi (copy the Kakadu distribution ``v7_8-01382N.zip`` to the ``docker-sipi`` directory) $ docker build -t daschswiss/sipi $ docker run --name sipi --rm -it -p 1024:1024 daschswiss/sipi (Ctrl-c out of terminal will stop and delete container) $ docker push daschswiss/sipi Pushing the image to the docker hub requires prior authentication with $ docker login . The user needs to be registered on hub.docker.com . Also, the user needs to be allowed to push to the dblabbasel organisation. Running Sipi To use the docker image stored locally or on the docker hub repository type: $ docker run --name sipi -d -p 1024:1024 daschswiss/sipi This will create and start a docker container with the daschswiss/sipi image in the background. The default behaviour is to start Sipi by calling the following command: $ /sipi/local/bin/sipi -config /sipi/config/sipi.knora-test-config.lua To override this default behaviour, start the container by supplying another config file: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /sipi/config/sipi.config.lua You can also mount a directory (the local directory in this example), and use a config file that is outside of the docker container: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ -v $PWD:/localdir \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /localdir/sipi.knora-test-config.lua Redis Server The DSP-API server uses Redis for caching. On macOS you can install Redis through Homebrew : $ brew install redis If you don't want to use Redis, you can disable caching in application.conf via the app.use-redis-cache key, by setting it to false .","title":"Overview"},{"location":"DSP-API/05-internals/development/overview/#overview","text":"Developing for DSP-API requires a complete local installation of Knora. The different parts are: The cloned DSP-API Github repository One of the supplied triplestores in the DSP-API Github repository (GraphDB-SE 8 or Fuseki 3). Sipi by building from source or using the docker image","title":"Overview"},{"location":"DSP-API/05-internals/development/overview/#knora-github-repository","text":"$ git clone https://github.com/dasch-swiss/dsp-api","title":"Knora Github Repository"},{"location":"DSP-API/05-internals/development/overview/#triplestore","text":"A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Ontotext GraphDB , a high-performance, proprietary triplestore. We recommend GraphDB Standard Edition, but GraphDB Free (which is proprietary but available free of charge) also works. DSP-API includes support for Apache Jena , which is free software , but use of Jena is deprecated, and support for it will probably be removed in the future. Built-in support and configuration for other triplestores is planned. See the chapter on Starting GraphDB for more details.","title":"Triplestore"},{"location":"DSP-API/05-internals/development/overview/#sipi","text":"","title":"Sipi"},{"location":"DSP-API/05-internals/development/overview/#build-sipi-docker-image","text":"The Sipi docker image needs to be build by hand, as it requires the Kakadu distribution. To build the image, and push it to the docker hub, follow the following steps: $ git clone https://github.com/dhlab-basel/docker-sipi (copy the Kakadu distribution ``v7_8-01382N.zip`` to the ``docker-sipi`` directory) $ docker build -t daschswiss/sipi $ docker run --name sipi --rm -it -p 1024:1024 daschswiss/sipi (Ctrl-c out of terminal will stop and delete container) $ docker push daschswiss/sipi Pushing the image to the docker hub requires prior authentication with $ docker login . The user needs to be registered on hub.docker.com . Also, the user needs to be allowed to push to the dblabbasel organisation.","title":"Build Sipi Docker Image"},{"location":"DSP-API/05-internals/development/overview/#running-sipi","text":"To use the docker image stored locally or on the docker hub repository type: $ docker run --name sipi -d -p 1024:1024 daschswiss/sipi This will create and start a docker container with the daschswiss/sipi image in the background. The default behaviour is to start Sipi by calling the following command: $ /sipi/local/bin/sipi -config /sipi/config/sipi.knora-test-config.lua To override this default behaviour, start the container by supplying another config file: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /sipi/config/sipi.config.lua You can also mount a directory (the local directory in this example), and use a config file that is outside of the docker container: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ -v $PWD:/localdir \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /localdir/sipi.knora-test-config.lua","title":"Running Sipi"},{"location":"DSP-API/05-internals/development/overview/#redis-server","text":"The DSP-API server uses Redis for caching. On macOS you can install Redis through Homebrew : $ brew install redis If you don't want to use Redis, you can disable caching in application.conf via the app.use-redis-cache key, by setting it to false .","title":"Redis Server"},{"location":"DSP-API/05-internals/development/profiling/","text":"Profiling Knora To run Knora with profiling, we first need to build the application. Please run the following from the top knora folder: $ sbt webapi/stage Profiling with YourKit : Start webapi from the knora/webapi/target/universal/stage directory with the following command: $ ./bin/webapi -J-agentpath:/Applications/YourKit-Java-Profiler-2018.04.app/Contents/Resources/bin/mac/libyjpagent.jnilib -J-Xms1G -J-Xmx1G Now start the YourKit Profiler and connect to the Main process.","title":"Profiling DSP-API"},{"location":"DSP-API/05-internals/development/profiling/#profiling-knora","text":"To run Knora with profiling, we first need to build the application. Please run the following from the top knora folder: $ sbt webapi/stage","title":"Profiling Knora"},{"location":"DSP-API/05-internals/development/profiling/#profiling-with-yourkit","text":"Start webapi from the knora/webapi/target/universal/stage directory with the following command: $ ./bin/webapi -J-agentpath:/Applications/YourKit-Java-Profiler-2018.04.app/Contents/Resources/bin/mac/libyjpagent.jnilib -J-Xms1G -J-Xmx1G Now start the YourKit Profiler and connect to the Main process.","title":"Profiling with YourKit:"},{"location":"DSP-API/05-internals/development/testing/","text":"Testing Prerequisite: Before running any tests, a supported triplestore needs to be started and initialized through a script inside the \"scripts\" folder. For example, when using \"GraphDB Free\", the nedded script is \"graphdb-free-init-knora-test-unit.sh\". Please note the occurrence of \"test-unit\" in the name of the script. How to Write Unit Tests 1) Inside a test, at the beginning, add the following (change the paths to the test data as needed): val rdfDataObjects = List ( RdfDataObject(path = \"test_data/responders.v1.ValuesResponderV1Spec/incunabula-data.ttl\", name = \"http://www.knora.org/data/incunabula\") ) The data will be automatically loaded before any tests are executed. These tests should be stored inside the src/test folder hierarchy. 2) Call the test from terminal: $ make test-unit $ make test-e2e How to Write Integration Tests The only difference between Integration and Unit tests is the location where they are stored and the way how they are called: 1) Store tests inside the src/it folder hierarchy. 2) Call the tests from the terminal: make test-it","title":"Testing"},{"location":"DSP-API/05-internals/development/testing/#testing","text":"Prerequisite: Before running any tests, a supported triplestore needs to be started and initialized through a script inside the \"scripts\" folder. For example, when using \"GraphDB Free\", the nedded script is \"graphdb-free-init-knora-test-unit.sh\". Please note the occurrence of \"test-unit\" in the name of the script.","title":"Testing"},{"location":"DSP-API/05-internals/development/testing/#how-to-write-unit-tests","text":"1) Inside a test, at the beginning, add the following (change the paths to the test data as needed): val rdfDataObjects = List ( RdfDataObject(path = \"test_data/responders.v1.ValuesResponderV1Spec/incunabula-data.ttl\", name = \"http://www.knora.org/data/incunabula\") ) The data will be automatically loaded before any tests are executed. These tests should be stored inside the src/test folder hierarchy. 2) Call the test from terminal: $ make test-unit $ make test-e2e","title":"How to Write Unit Tests"},{"location":"DSP-API/05-internals/development/testing/#how-to-write-integration-tests","text":"The only difference between Integration and Unit tests is the location where they are stored and the way how they are called: 1) Store tests inside the src/it folder hierarchy. 2) Call the tests from the terminal: make test-it","title":"How to Write Integration Tests"},{"location":"DSP-API/05-internals/development/third-party/","text":"Third-Party Dependencies The following section discusses on how third-party dependencies should be defined. Third-party dependencies are defined in the third_party folder. There are two main types of dependencies: (1) Maven library dependencies and (2) Docker image versions. Maven Library Dependencies The Maven library dependencies are defined in the third_party/dependencies.bzl file. To use the external libraries, add the \"flattened\" Bazel version of it to the Bazel rule used to compile the code. Example of a \"flattened\" Bazel version looks as follows: defined: com.typesafe.akka:akka-actor_2.12:2.6.5 flattened: @maven//:com_typesafe_akka_akka_actor_2_12 To query Bazel for all defined Maven dependencies: bazel query @maven//:all | sort Manually Fetching Dependencies The Maven dependencies can be manually fetched with: $ bazel fetch @maven//... If there are any problems downloading the Maven dependencies, set the RJE_VERBOSE environment variable to true to print coursier 's verbose output: $ RJE_VERBOSE=true bazel fetch @maven//... Note: If you are on macOS Big Sur and have the Cisco VPN client installed, make sure that the packet filters are not active, or they may be a problem downloading the dependencies. Docker Image Versions The required Docker image versions of Sipi and Fuseki are defined in the third_party/versions.bzl file. For the Docker images, the supplied digest hashes are relevant for getting the image. These digest hashes can be found on Docker-Hub when inspecting the tag of the Docker image in question.","title":"Third-Party Dependencies"},{"location":"DSP-API/05-internals/development/third-party/#third-party-dependencies","text":"The following section discusses on how third-party dependencies should be defined. Third-party dependencies are defined in the third_party folder. There are two main types of dependencies: (1) Maven library dependencies and (2) Docker image versions.","title":"Third-Party Dependencies"},{"location":"DSP-API/05-internals/development/third-party/#maven-library-dependencies","text":"The Maven library dependencies are defined in the third_party/dependencies.bzl file. To use the external libraries, add the \"flattened\" Bazel version of it to the Bazel rule used to compile the code. Example of a \"flattened\" Bazel version looks as follows: defined: com.typesafe.akka:akka-actor_2.12:2.6.5 flattened: @maven//:com_typesafe_akka_akka_actor_2_12 To query Bazel for all defined Maven dependencies: bazel query @maven//:all | sort","title":"Maven Library Dependencies"},{"location":"DSP-API/05-internals/development/third-party/#manually-fetching-dependencies","text":"The Maven dependencies can be manually fetched with: $ bazel fetch @maven//... If there are any problems downloading the Maven dependencies, set the RJE_VERBOSE environment variable to true to print coursier 's verbose output: $ RJE_VERBOSE=true bazel fetch @maven//... Note: If you are on macOS Big Sur and have the Cisco VPN client installed, make sure that the packet filters are not active, or they may be a problem downloading the dependencies.","title":"Manually Fetching Dependencies"},{"location":"DSP-API/05-internals/development/third-party/#docker-image-versions","text":"The required Docker image versions of Sipi and Fuseki are defined in the third_party/versions.bzl file. For the Docker images, the supplied digest hashes are relevant for getting the image. These digest hashes can be found on Docker-Hub when inspecting the tag of the Docker image in question.","title":"Docker Image Versions"},{"location":"DSP-API/05-internals/development/updating-repositories/","text":"Updating Repositories Requirements When a new version of Knora requires an existing repository to be updated, do this automatically when Knora starts, if possible. Make the update process as fast as possible, with some indication of progress as it runs. Design As explained in Knora Ontology Versions , the knora-base ontology contains a version string to ensure compatibility between a repository and a given version of Knora. The same version string is therefore hard-coded in the Knora source code, in the string constant org.knora.webapi.KnoraBaseVersion . For new pull requests, the format of this string is knora-base vN , where N is an integer that is incremented for each version. During Knora's startup process, ApplicationActor sends an UpdateRepositoryRequest message to the StoreManager , which forwards it to TriplestoreManager , which delegates it to org.knora.webapi.store.triplestore.upgrade.RepositoryUpdater . RepositoryUpdater does the following procedure: Check the knora-base version string in the repository. Consult org.knora.webapi.store.triplestore.upgrade.RepositoryUpdatePlan to see which transformations are needed. Download the entire repository from the triplestore into an N-Quads file. Read the N-Quads file into an RdfModel . Update the RdfModel by running the necessary transformations, and replacing the built-in DSP ontologies with the current ones. Save the RdfModel to a new N-Quads file. Empty the repository in the triplestore. Upload the transformed repository file to the triplestore. To update the RdfModel , RepositoryUpdater runs a sequence of upgrade plugins, each of which is a class in org.knora.webapi.store.triplestore.upgrade.plugins and is registered in RepositoryUpdatePlan . Design Rationale We tried and rejected several other designs: Running SPARQL updates in the triplestore: too slow, and no way to report progress during the update. Downloading the repository and transforming it in Python using rdflib : too slow. Downloading the repository and transforming it in C++ using Redland : also too slow. The Scala implementation is the fastest by far. The whole repository is uploaded in a single transaction, rather than uploading one named graph at a time, because GraphDB's consistency checker can enforce dependencies between named graphs. Adding an Upgrade Plugin Each time a pull request introduces changes that are not compatible with existing data, the following must happen: The knora-base version number must be incremented in knora-base.ttl and in the string constant org.knora.webapi.KnoraBaseVersion . A plugin must be added in the package org.knora.webapi.store.triplestore.upgrade.plugins , to transform existing repositories so that they are compatible with the code changes introduced in the pull request. Each new plugin must be registered by adding it to the sequence returned by RepositoryUpdatePlan.makePluginsForVersions . The order of version numbers (and the plugins) must correspond to the order in which the pull requests are merged. An upgrade plugin is a Scala class that extends UpgradePlugin . The name of the plugin class should refer to the pull request that made the transformation necessary, using the format UpgradePluginPRNNNN , where NNNN is the number of the pull request. A plugin's transform method takes an RdfModel (a mutable object representing the repository) and modifies it as needed. Before transforming the data, a plugin can check whether a required manual transformation has been carried out. If the requirement is not met, the plugin can throw InconsistentRepositoryDataException to abort the upgrade process. Testing Update Plugins Each plugin should have a unit test that extends UpgradePluginSpec . A typical test loads a file containing RDF test data into a RdfModel , runs the plugin, makes an RdfRepository containing the transformed RdfModel , and uses SPARQL to check the result.","title":"Updating Repositories"},{"location":"DSP-API/05-internals/development/updating-repositories/#updating-repositories","text":"","title":"Updating Repositories"},{"location":"DSP-API/05-internals/development/updating-repositories/#requirements","text":"When a new version of Knora requires an existing repository to be updated, do this automatically when Knora starts, if possible. Make the update process as fast as possible, with some indication of progress as it runs.","title":"Requirements"},{"location":"DSP-API/05-internals/development/updating-repositories/#design","text":"As explained in Knora Ontology Versions , the knora-base ontology contains a version string to ensure compatibility between a repository and a given version of Knora. The same version string is therefore hard-coded in the Knora source code, in the string constant org.knora.webapi.KnoraBaseVersion . For new pull requests, the format of this string is knora-base vN , where N is an integer that is incremented for each version. During Knora's startup process, ApplicationActor sends an UpdateRepositoryRequest message to the StoreManager , which forwards it to TriplestoreManager , which delegates it to org.knora.webapi.store.triplestore.upgrade.RepositoryUpdater . RepositoryUpdater does the following procedure: Check the knora-base version string in the repository. Consult org.knora.webapi.store.triplestore.upgrade.RepositoryUpdatePlan to see which transformations are needed. Download the entire repository from the triplestore into an N-Quads file. Read the N-Quads file into an RdfModel . Update the RdfModel by running the necessary transformations, and replacing the built-in DSP ontologies with the current ones. Save the RdfModel to a new N-Quads file. Empty the repository in the triplestore. Upload the transformed repository file to the triplestore. To update the RdfModel , RepositoryUpdater runs a sequence of upgrade plugins, each of which is a class in org.knora.webapi.store.triplestore.upgrade.plugins and is registered in RepositoryUpdatePlan .","title":"Design"},{"location":"DSP-API/05-internals/development/updating-repositories/#design-rationale","text":"We tried and rejected several other designs: Running SPARQL updates in the triplestore: too slow, and no way to report progress during the update. Downloading the repository and transforming it in Python using rdflib : too slow. Downloading the repository and transforming it in C++ using Redland : also too slow. The Scala implementation is the fastest by far. The whole repository is uploaded in a single transaction, rather than uploading one named graph at a time, because GraphDB's consistency checker can enforce dependencies between named graphs.","title":"Design Rationale"},{"location":"DSP-API/05-internals/development/updating-repositories/#adding-an-upgrade-plugin","text":"Each time a pull request introduces changes that are not compatible with existing data, the following must happen: The knora-base version number must be incremented in knora-base.ttl and in the string constant org.knora.webapi.KnoraBaseVersion . A plugin must be added in the package org.knora.webapi.store.triplestore.upgrade.plugins , to transform existing repositories so that they are compatible with the code changes introduced in the pull request. Each new plugin must be registered by adding it to the sequence returned by RepositoryUpdatePlan.makePluginsForVersions . The order of version numbers (and the plugins) must correspond to the order in which the pull requests are merged. An upgrade plugin is a Scala class that extends UpgradePlugin . The name of the plugin class should refer to the pull request that made the transformation necessary, using the format UpgradePluginPRNNNN , where NNNN is the number of the pull request. A plugin's transform method takes an RdfModel (a mutable object representing the repository) and modifies it as needed. Before transforming the data, a plugin can check whether a required manual transformation has been carried out. If the requirement is not met, the plugin can throw InconsistentRepositoryDataException to abort the upgrade process.","title":"Adding an Upgrade Plugin"},{"location":"DSP-API/05-internals/development/updating-repositories/#testing-update-plugins","text":"Each plugin should have a unit test that extends UpgradePluginSpec . A typical test loads a file containing RDF test data into a RdfModel , runs the plugin, makes an RdfRepository containing the transformed RdfModel , and uses SPARQL to check the result.","title":"Testing Update Plugins"},{"location":"DSP-API/07-sipi/","text":"The Sipi Media Server Sipi is a high-performance media server written in C++, for serving and converting binary media files such as images and video. Sipi can efficiently convert between many different formats on demand, preserving embedded metadata, and implements the International Image Interoperability Framework (IIIF) . Knora is designed to use Sipi for converting and serving media files. Setting Up Sipi for Knora Interaction Between Sipi and Knora","title":"Index"},{"location":"DSP-API/07-sipi/#the-sipi-media-server","text":"Sipi is a high-performance media server written in C++, for serving and converting binary media files such as images and video. Sipi can efficiently convert between many different formats on demand, preserving embedded metadata, and implements the International Image Interoperability Framework (IIIF) . Knora is designed to use Sipi for converting and serving media files. Setting Up Sipi for Knora Interaction Between Sipi and Knora","title":"The Sipi Media Server"},{"location":"DSP-API/07-sipi/setup-sipi-for-knora/","text":"Setting Up Sipi for Knora Setup and Execution In order to serve files to the client application like the Salsah GUI, Sipi must be set up and running. Sipi can be downloaded from its own GitHub repository: https://github.com/dhlab-basel/Sipi (which requires building from source), or the published docker image . can be used. To start Sipi, run the following command from inside the sipi/ folder: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.knora-docker-config.lua where LOCAL_IP_ADDRESS is the IP of the host running the Knora . --config=/sipi/config/sipi.knora-docker-config.lua (or --config=/sipi/config/sipi.knora-docker-it-config.lua for using sipi for integration testing). Please see sipi.knora-docker-config.lua for the settings like URL, port number etc. These settings need to be set accordingly in Knora's application.conf . If you use the default settings both in Sipi and Knora, there is no need to change these settings. Whenever a file is requested from Sipi (e.g. a browser trying to dereference an image link served by Knora), a preflight function is called. This function is defined in sipi.init-knora.lua present in the Sipi root directory. It takes three parameters: prefix , identifier (the name of the requested file), and cookie . The prefix is the shortcode of the project that the resource containing the file value belongs to. Given this information, Sipi asks Knora about the current's users permissions on the given file. The cookie contains the current user's Knora session id, so Knora can match Sipi's request with a given user profile and determine the permissions this user has on the file. If the Knora response grants sufficient permissions, the file is served in the requested quality. If the suer has preview rights, Sipi serves a reduced quality or integrates a watermark. If the user has no permissions, Sipi refuses to serve the file. However, all of this behaviour is defined in the preflight function in Sipi and not controlled by Knora. Knora only provides the permission code. See Authentication of Users with Sipi for more information about sharing the session ID. Using Sipi in Test Mode If you just want to test Sipi with Knora without serving the actual files (e.g. when executing browser tests), you can simply start Sipi like this: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.knora-docker-test-config.lua Then always the same test file will be served which is included in Sipi. In test mode, Sipi will not ask Knora about the user's permission on the requested file. Additional Sipi Environment Variables Additionally, these environment variables can be used to further configure Sipi: SIPI_WEBAPI_HOSTNAME=localhost : overrides knora_path in Sipi's config SIPI_WEBAPI_PORT=3333 : overrides knora_port in Sipi's config These variables need to be explicitly used like in sipi.ini-knora.lua : -- -- Allows to set SIPI_WEBAPI_HOSTNAME environment variable and use its value. -- local webapi_hostname = os.getenv(\"SIPI_WEBAPI_HOSTNAME\") if webapi_hostname == nil then webapi_hostname = config.knora_path end server.log(\"webapi_hostname: \" .. webapi_hostname, server.loglevel.LOG_DEBUG) -- -- Allows to set SIPI_WEBAPI_PORT environment variable and use its value. -- local webapi_port = os.getenv(\"SIPI_WEBAPI_PORT\") if webapi_port == nil then webapi_port = config.knora_port end server.log(\"webapi_port: \" .. webapi_port, server.loglevel.LOG_DEBUG) knora_url = 'http://' .. webapi_hostname .. ':' .. webapi_port .. '/admin/files/' .. prefix .. '/' .. identifier","title":"Setting Up Sipi for DSP-API"},{"location":"DSP-API/07-sipi/setup-sipi-for-knora/#setting-up-sipi-for-knora","text":"","title":"Setting Up Sipi for Knora"},{"location":"DSP-API/07-sipi/setup-sipi-for-knora/#setup-and-execution","text":"In order to serve files to the client application like the Salsah GUI, Sipi must be set up and running. Sipi can be downloaded from its own GitHub repository: https://github.com/dhlab-basel/Sipi (which requires building from source), or the published docker image . can be used. To start Sipi, run the following command from inside the sipi/ folder: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.knora-docker-config.lua where LOCAL_IP_ADDRESS is the IP of the host running the Knora . --config=/sipi/config/sipi.knora-docker-config.lua (or --config=/sipi/config/sipi.knora-docker-it-config.lua for using sipi for integration testing). Please see sipi.knora-docker-config.lua for the settings like URL, port number etc. These settings need to be set accordingly in Knora's application.conf . If you use the default settings both in Sipi and Knora, there is no need to change these settings. Whenever a file is requested from Sipi (e.g. a browser trying to dereference an image link served by Knora), a preflight function is called. This function is defined in sipi.init-knora.lua present in the Sipi root directory. It takes three parameters: prefix , identifier (the name of the requested file), and cookie . The prefix is the shortcode of the project that the resource containing the file value belongs to. Given this information, Sipi asks Knora about the current's users permissions on the given file. The cookie contains the current user's Knora session id, so Knora can match Sipi's request with a given user profile and determine the permissions this user has on the file. If the Knora response grants sufficient permissions, the file is served in the requested quality. If the suer has preview rights, Sipi serves a reduced quality or integrates a watermark. If the user has no permissions, Sipi refuses to serve the file. However, all of this behaviour is defined in the preflight function in Sipi and not controlled by Knora. Knora only provides the permission code. See Authentication of Users with Sipi for more information about sharing the session ID.","title":"Setup and Execution"},{"location":"DSP-API/07-sipi/setup-sipi-for-knora/#using-sipi-in-test-mode","text":"If you just want to test Sipi with Knora without serving the actual files (e.g. when executing browser tests), you can simply start Sipi like this: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.knora-docker-test-config.lua Then always the same test file will be served which is included in Sipi. In test mode, Sipi will not ask Knora about the user's permission on the requested file.","title":"Using Sipi in Test Mode"},{"location":"DSP-API/07-sipi/setup-sipi-for-knora/#additional-sipi-environment-variables","text":"Additionally, these environment variables can be used to further configure Sipi: SIPI_WEBAPI_HOSTNAME=localhost : overrides knora_path in Sipi's config SIPI_WEBAPI_PORT=3333 : overrides knora_port in Sipi's config These variables need to be explicitly used like in sipi.ini-knora.lua : -- -- Allows to set SIPI_WEBAPI_HOSTNAME environment variable and use its value. -- local webapi_hostname = os.getenv(\"SIPI_WEBAPI_HOSTNAME\") if webapi_hostname == nil then webapi_hostname = config.knora_path end server.log(\"webapi_hostname: \" .. webapi_hostname, server.loglevel.LOG_DEBUG) -- -- Allows to set SIPI_WEBAPI_PORT environment variable and use its value. -- local webapi_port = os.getenv(\"SIPI_WEBAPI_PORT\") if webapi_port == nil then webapi_port = config.knora_port end server.log(\"webapi_port: \" .. webapi_port, server.loglevel.LOG_DEBUG) knora_url = 'http://' .. webapi_hostname .. ':' .. webapi_port .. '/admin/files/' .. prefix .. '/' .. identifier","title":"Additional Sipi Environment Variables"},{"location":"DSP-API/07-sipi/sipi-and-knora/","text":"Interaction Between Sipi and Knora General Remarks Knora and Sipi (Simple Image Presentation Interface) are two complementary software projects. Whereas Knora deals with data that is written to and read from a triplestore (metadata and annotations), Sipi takes care of storing, converting and serving image files as well as other types of files such as audio, video, or documents (binary files it just stores and serves). Knora and Sipi stick to a clear division of responsibility regarding files: Knora knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from Sipi, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by Sipi. Adding Files to Knora A file is first uploaded to Sipi, then its metadata is submitted to Knora. The implementation of this procedure is described in Knora and Sipi . Instructions for the client are given in Creating File Values (for DSP-API v2) and in Adding Resources with Image Files (for API v1). Retrieving Files from Sipi File URLs in API v2 In DSP-API v2, image file URLs are provided in IIIF format. In the simple ontology schema , a file value is simply a IIIF URL that can be used to retrieve the file from Sipi. In the complex schema, it is a StillImageFileValue with additional properties that the client can use to construct different IIIF URLs, e.g. at different resolutions. See the knora-api ontology for details. File URLs in API v1 In API v1, for each file value, Knora creates several Sipi URLs for accessing the file at different resolutions: \"resinfo\": { \"locations\": [ { \"duration\": \u200b0, \"nx\": \u200b95, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jpg/full/max/0/default.jpg\", \"ny\": \u200b128, \"fps\": \u200b0, \"format_name\": \"JPEG\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b82, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/82,110/0/default.jpg\", \"ny\": \u200b110, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b163, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/163,219/0/default.jpg\", \"ny\": \u200b219, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" } ... ], \"restype_label\": \"Seite\", \"resclass_has_location\": true, Each of these paths has to be handled by the browser by making a call to Sipi, obtaining the binary representation in the desired quality. Authentication of Users with Sipi Whenever a file is requested, Sipi asks Knora about the current user's permissions on the given file. This is achieved by sharing the Knora session cookie with Sipi. When the user logs in to Knora using his browser (using either V1 or V2 authentication route), a session cookie containing a JWT token representing the user is stored in the user's client. This session cookie is then read by Sipi and used to ask Knora for the user's image permissions. For the session cookie to be sent to Sipi, both the DSP-API and Sipi endpoints need to be under the same domain, e.g., api.example.com and iiif.example.com .","title":"Interaction between Sipi and DSP-API"},{"location":"DSP-API/07-sipi/sipi-and-knora/#interaction-between-sipi-and-knora","text":"","title":"Interaction Between Sipi and Knora"},{"location":"DSP-API/07-sipi/sipi-and-knora/#general-remarks","text":"Knora and Sipi (Simple Image Presentation Interface) are two complementary software projects. Whereas Knora deals with data that is written to and read from a triplestore (metadata and annotations), Sipi takes care of storing, converting and serving image files as well as other types of files such as audio, video, or documents (binary files it just stores and serves). Knora and Sipi stick to a clear division of responsibility regarding files: Knora knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from Sipi, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by Sipi.","title":"General Remarks"},{"location":"DSP-API/07-sipi/sipi-and-knora/#adding-files-to-knora","text":"A file is first uploaded to Sipi, then its metadata is submitted to Knora. The implementation of this procedure is described in Knora and Sipi . Instructions for the client are given in Creating File Values (for DSP-API v2) and in Adding Resources with Image Files (for API v1).","title":"Adding Files to Knora"},{"location":"DSP-API/07-sipi/sipi-and-knora/#retrieving-files-from-sipi","text":"","title":"Retrieving Files from Sipi"},{"location":"DSP-API/07-sipi/sipi-and-knora/#file-urls-in-api-v2","text":"In DSP-API v2, image file URLs are provided in IIIF format. In the simple ontology schema , a file value is simply a IIIF URL that can be used to retrieve the file from Sipi. In the complex schema, it is a StillImageFileValue with additional properties that the client can use to construct different IIIF URLs, e.g. at different resolutions. See the knora-api ontology for details.","title":"File URLs in API v2"},{"location":"DSP-API/07-sipi/sipi-and-knora/#file-urls-in-api-v1","text":"In API v1, for each file value, Knora creates several Sipi URLs for accessing the file at different resolutions: \"resinfo\": { \"locations\": [ { \"duration\": \u200b0, \"nx\": \u200b95, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jpg/full/max/0/default.jpg\", \"ny\": \u200b128, \"fps\": \u200b0, \"format_name\": \"JPEG\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b82, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/82,110/0/default.jpg\", \"ny\": \u200b110, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b163, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/163,219/0/default.jpg\", \"ny\": \u200b219, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" } ... ], \"restype_label\": \"Seite\", \"resclass_has_location\": true, Each of these paths has to be handled by the browser by making a call to Sipi, obtaining the binary representation in the desired quality.","title":"File URLs in API v1"},{"location":"DSP-API/07-sipi/sipi-and-knora/#authentication-of-users-with-sipi","text":"Whenever a file is requested, Sipi asks Knora about the current user's permissions on the given file. This is achieved by sharing the Knora session cookie with Sipi. When the user logs in to Knora using his browser (using either V1 or V2 authentication route), a session cookie containing a JWT token representing the user is stored in the user's client. This session cookie is then read by Sipi and used to ask Knora for the user's image permissions. For the session cookie to be sent to Sipi, both the DSP-API and Sipi endpoints need to be under the same domain, e.g., api.example.com and iiif.example.com .","title":"Authentication of Users with Sipi"},{"location":"DSP-API/08-lucene/","text":"Lucene The Lucene full-text index provided by the triplestore is used to perform full-text searches in Knora. The exact behavior can be different depending on the triplestore, e.g., GraphDB or Fuseki. Lucene Query Parser Syntax","title":"Overview"},{"location":"DSP-API/08-lucene/#lucene","text":"The Lucene full-text index provided by the triplestore is used to perform full-text searches in Knora. The exact behavior can be different depending on the triplestore, e.g., GraphDB or Fuseki. Lucene Query Parser Syntax","title":"Lucene"},{"location":"DSP-API/08-lucene/lucene-query-parser-syntax/","text":"Lucene Query Parser Syntax Full-text searches in Knora are based on Lucene. Therefore, full-text searches support the Lucene Query Parser Syntax . A full-text search consists of a single word in the simplest case, but could also be composed of several words combined with Boolean operators . By default, Lucene combines two or more terms separated by space with a logical OR. For examples, see Lucene Query Parser Syntax .","title":"Lucene Query Parser Syntax"},{"location":"DSP-API/08-lucene/lucene-query-parser-syntax/#lucene-query-parser-syntax","text":"Full-text searches in Knora are based on Lucene. Therefore, full-text searches support the Lucene Query Parser Syntax . A full-text search consists of a single word in the simplest case, but could also be composed of several words combined with Boolean operators . By default, Lucene combines two or more terms separated by space with a logical OR. For examples, see Lucene Query Parser Syntax .","title":"Lucene Query Parser Syntax"},{"location":"DSP-API/faq/","text":"Frequently Asked Questions Data Formats What data formats does Knora store? See Data Formats in Knora . Does Knora store XML files? XML files do not lend themselves to searching and linking. Knora's RDF storage is better suited to its goal of facilitating data reuse. If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF . This will allow both text and markup to be searched using Gravsearch . Knora can also regenerate, at any time, an XML document that is equivalent to the original one. If you have XML that simply represents structured data (rather than text documents), we recommend converting it to Knora resources, which are stored as RDF. Triplestores Which triplestores can be used with Knora? Knora is tested with Ontotext GraphDB SE . Our goal is to support several triplestores, including open-source options. Integration with Apache Jena Fuseki has been partly implemented, but is not currently supported. Knora Ontologies Can a project use classes or properties defined in another project's ontology? Knora does not allow this to be done with project-specific ontologies. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators promise not to change it in ways that could affect other ontologies or data that are based on it. See Shared Ontologies for details. There will be a standardisation process for shared ontologies (issue #523 ). Why doesn't Knora use rdfs:domain and rdfs:range for consistency checking? Knora's consistency checking uses Knora-specific properties, which are called knora-base:subjectClassConstraint and knora-base:objectClassConstraint in the knora-base ontology, and knora-api:subjectType and knora-api:objectType in the knora-api ontologies. These properties express restrictions on the possible subjects and objects of a property. If a property's subject or object does not conform to the specified restrictions, Knora considers it an error. In contrast, the RDF Schema specification says that rdfs:domain and rdfs:range can be used to \"infer additional information\" about the subjects and objects of properties, rather than to enforce restrictions. This is, in fact, what RDFS reasoners do in practice. For example, consider these statements: example:hasAuthor rdfs:range example:Person . data:book1 example:hasAuthor data:oxygen . To an RDFS reasoner, the first statement means: if something is used as the object of example:hasAuthor , we can infer that it's an example:Person . The second statement is a mistake; oxygen is not a person. But an RDFS reasoner would infer that data:oxygen is actually an example:Person , since it is used as the object of example:hasAuthor . Queries looking for persons would then get data:oxygen in their results, which would be incorrect. Therefore, rdfs:domain and rdfs:range are not suitable for consistency checking. Knora therefore uses its own properties, along with OWL cardinalities, which it interprets according to a \"closed world\" assumption. Knora performs its own consistency checks to enforce these restrictions. Knora repositories can also take advantage of triplestore-specific consistency checking mechanisms. The constraint language SHACL may someday provide a standard, triplestore-independent way to implement consistency checks, if the obstacles to its adoption can be overcome (see Diverging views of SHACL ). For further discussion of these issues, see SHACL and OWL Compared . Can a user-created property be an owl:TransitiveProperty ? No, because in Knora, a resource controls its properties. This basic assumption is what allows Knora to enforce permissions and transaction integrity. The concept of a transitive property would break this assumption. Consider a link property hasLinkToFoo that is defined as an owl:TransitiveProperty , and is used to link resource Foo1 to resource Foo2 : Suppose that Foo1 and Foo2 are owned by different users, and that the owner of Foo2 does not have permission to change Foo1 . Now suppose that the owner of Foo2 adds a link from Foo2 to Foo3 , using the transitive property: Since the property is transitive, a link from Foo1 to Foo3 is now inferred. But this should not be allowed, because the owner of Foo2 does not have permission to add a link to Foo1 . Moreover, even if the owner of Foo2 did have that permission, the inferred link would not have a knora-base:LinkValue (a reification), which every Knora link must have. The LinkValue is what stores metadata about the creator of the link, its creation date, its permissions, and so on (see LinkValue ). Finally, if an update to one resource could modify another resource, this would violate Knora's model of transaction integrity, in which each transaction can modify only one resource (see Application-level Locking ). Knora would then be unable to ensure that concurrent transactions do not interfere with each other. Should 0.0.0.0 or localhost be used to access Knora locally When running locally with the default configuration, if you want authorization cookies to be shared between webapi and sipi , then both webapi and sipi must be accessed over 0.0.0.0 , or otherwise, the cookie will not be sent to sipi . If no authorization cookie sharing is necessary, then both 0.0.0.0 and localhost will work.","title":"Frequently Asked Questions"},{"location":"DSP-API/faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"DSP-API/faq/#data-formats","text":"","title":"Data Formats"},{"location":"DSP-API/faq/#what-data-formats-does-knora-store","text":"See Data Formats in Knora .","title":"What data formats does Knora store?"},{"location":"DSP-API/faq/#does-knora-store-xml-files","text":"XML files do not lend themselves to searching and linking. Knora's RDF storage is better suited to its goal of facilitating data reuse. If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF . This will allow both text and markup to be searched using Gravsearch . Knora can also regenerate, at any time, an XML document that is equivalent to the original one. If you have XML that simply represents structured data (rather than text documents), we recommend converting it to Knora resources, which are stored as RDF.","title":"Does Knora store XML files?"},{"location":"DSP-API/faq/#triplestores","text":"","title":"Triplestores"},{"location":"DSP-API/faq/#which-triplestores-can-be-used-with-knora","text":"Knora is tested with Ontotext GraphDB SE . Our goal is to support several triplestores, including open-source options. Integration with Apache Jena Fuseki has been partly implemented, but is not currently supported.","title":"Which triplestores can be used with Knora?"},{"location":"DSP-API/faq/#knora-ontologies","text":"","title":"Knora Ontologies"},{"location":"DSP-API/faq/#can-a-project-use-classes-or-properties-defined-in-another-projects-ontology","text":"Knora does not allow this to be done with project-specific ontologies. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators promise not to change it in ways that could affect other ontologies or data that are based on it. See Shared Ontologies for details. There will be a standardisation process for shared ontologies (issue #523 ).","title":"Can a project use classes or properties defined in another project's ontology?"},{"location":"DSP-API/faq/#why-doesnt-knora-use-rdfsdomain-and-rdfsrange-for-consistency-checking","text":"Knora's consistency checking uses Knora-specific properties, which are called knora-base:subjectClassConstraint and knora-base:objectClassConstraint in the knora-base ontology, and knora-api:subjectType and knora-api:objectType in the knora-api ontologies. These properties express restrictions on the possible subjects and objects of a property. If a property's subject or object does not conform to the specified restrictions, Knora considers it an error. In contrast, the RDF Schema specification says that rdfs:domain and rdfs:range can be used to \"infer additional information\" about the subjects and objects of properties, rather than to enforce restrictions. This is, in fact, what RDFS reasoners do in practice. For example, consider these statements: example:hasAuthor rdfs:range example:Person . data:book1 example:hasAuthor data:oxygen . To an RDFS reasoner, the first statement means: if something is used as the object of example:hasAuthor , we can infer that it's an example:Person . The second statement is a mistake; oxygen is not a person. But an RDFS reasoner would infer that data:oxygen is actually an example:Person , since it is used as the object of example:hasAuthor . Queries looking for persons would then get data:oxygen in their results, which would be incorrect. Therefore, rdfs:domain and rdfs:range are not suitable for consistency checking. Knora therefore uses its own properties, along with OWL cardinalities, which it interprets according to a \"closed world\" assumption. Knora performs its own consistency checks to enforce these restrictions. Knora repositories can also take advantage of triplestore-specific consistency checking mechanisms. The constraint language SHACL may someday provide a standard, triplestore-independent way to implement consistency checks, if the obstacles to its adoption can be overcome (see Diverging views of SHACL ). For further discussion of these issues, see SHACL and OWL Compared .","title":"Why doesn't Knora use rdfs:domain and rdfs:range for consistency checking?"},{"location":"DSP-API/faq/#can-a-user-created-property-be-an-owltransitiveproperty","text":"No, because in Knora, a resource controls its properties. This basic assumption is what allows Knora to enforce permissions and transaction integrity. The concept of a transitive property would break this assumption. Consider a link property hasLinkToFoo that is defined as an owl:TransitiveProperty , and is used to link resource Foo1 to resource Foo2 : Suppose that Foo1 and Foo2 are owned by different users, and that the owner of Foo2 does not have permission to change Foo1 . Now suppose that the owner of Foo2 adds a link from Foo2 to Foo3 , using the transitive property: Since the property is transitive, a link from Foo1 to Foo3 is now inferred. But this should not be allowed, because the owner of Foo2 does not have permission to add a link to Foo1 . Moreover, even if the owner of Foo2 did have that permission, the inferred link would not have a knora-base:LinkValue (a reification), which every Knora link must have. The LinkValue is what stores metadata about the creator of the link, its creation date, its permissions, and so on (see LinkValue ). Finally, if an update to one resource could modify another resource, this would violate Knora's model of transaction integrity, in which each transaction can modify only one resource (see Application-level Locking ). Knora would then be unable to ensure that concurrent transactions do not interfere with each other.","title":"Can a user-created property be an owl:TransitiveProperty?"},{"location":"DSP-API/faq/#should-0000-or-localhost-be-used-to-access-knora-locally","text":"When running locally with the default configuration, if you want authorization cookies to be shared between webapi and sipi , then both webapi and sipi must be accessed over 0.0.0.0 , or otherwise, the cookie will not be sent to sipi . If no authorization cookie sharing is necessary, then both 0.0.0.0 and localhost will work.","title":"Should 0.0.0.0 or localhost be used to access Knora locally"},{"location":"DSP-APP/","text":"DSP-APP \u2014 Generic user interface of DaSCH Service Platform NOTE: The current DSP-APP version presents the admin view only. This app is a simple user interface for the Data and Service Center for the Humanities DaSCH, which uses the DSP-API server application in the backend. It's a system for annotation and linkage of resources in arts and humanities. DSP-APP implements DSP-JS-LIB to connect with DSP-API . DSP (DaSCH Service Platform) is a software framework for storing, sharing, and working with primary resources and data in the humanities. DSP-APP is free software , released under GNU Affero General Public license. Documentation User guide \u27a1 for latest released version Developer docs \u27a1 for developers Contribution If you would like to contribute to the development of the DSP-APP alongside us, please consult the general DSP contribution guidelines . Documentation / User guidelines We built the user guidelines and developer documentation with MkDocs . Get more information in the appropriate README .","title":"Introduction"},{"location":"DSP-APP/#dsp-app-generic-user-interface-of-dasch-service-platform","text":"NOTE: The current DSP-APP version presents the admin view only. This app is a simple user interface for the Data and Service Center for the Humanities DaSCH, which uses the DSP-API server application in the backend. It's a system for annotation and linkage of resources in arts and humanities. DSP-APP implements DSP-JS-LIB to connect with DSP-API . DSP (DaSCH Service Platform) is a software framework for storing, sharing, and working with primary resources and data in the humanities. DSP-APP is free software , released under GNU Affero General Public license.","title":"DSP-APP &mdash; Generic user interface of DaSCH Service Platform"},{"location":"DSP-APP/#documentation","text":"","title":"Documentation"},{"location":"DSP-APP/#user-guide","text":"\u27a1 for latest released version","title":"User guide"},{"location":"DSP-APP/#developer-docs","text":"\u27a1 for developers","title":"Developer docs"},{"location":"DSP-APP/#contribution","text":"If you would like to contribute to the development of the DSP-APP alongside us, please consult the general DSP contribution guidelines .","title":"Contribution"},{"location":"DSP-APP/#documentation-user-guidelines","text":"We built the user guidelines and developer documentation with MkDocs . Get more information in the appropriate README .","title":"Documentation / User guidelines"},{"location":"DSP-APP/contribution/","text":"How to Contribute to this Project Development server DSP-APP is built with Angular and uses NPM . You have to install the corresponding packages with npm i . Now you have to possibilites to run the application in developer mode: With a local installed DSP-API environment run ng serve or npm run start . If you want to connect to the DSP-API on our test server run ng serve --configuration=test-server or npm run start-with-test-server . Please consider which version of DSP-API is currently running on the test server (see webapi: https://api.test.dasch.swiss/version ). With this solution you will also have access to all the representation files. In both case navigate to http://0.0.0.0:4200/ . The app will automatically reload if you change any of the resource files. Code scaffolding Run ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module . Build Run npm run build to build the app. The build artifacts will be stored in the dist/ directory. Run the command npm run build-prod for a production build. Test The following tests (unit, e2e and lint) are part of the Github Actions (CI) workflow and has to be run successfully before the code can be merged into the main branch. Running unit tests Run npm run test-local to execute the unit tests via Karma on your local computer. Run npm run test-ci to execute the unit tests via Karma without a browser. It is used in the Github Actions (CI) workflow. Running end-to-end tests Run npm run test-e2e-protractor to execute the end-to-end tests via Protractor . Running code linter Run npm run lint-local to execute the lint service via ESLint . This command uses the --fix flag which fixes simple errors like redundant type if you have default value assigned. In the Github Actions (CI) workflow the linter runs as npm run lint-ci . To integrate ESLint with Visual Studio Code, do the following: Install the ESLint extension. Create a task via the Tasks: Configure Task command and select npm: lint-local . In the resulting tasks.json file, configure the problem matcher to be $eslint-stylish . Further help To get more help on the Angular CLI use ng help or go check out the Angular CLI README .","title":"How to contribute"},{"location":"DSP-APP/contribution/#how-to-contribute-to-this-project","text":"","title":"How to Contribute to this Project"},{"location":"DSP-APP/contribution/#development-server","text":"DSP-APP is built with Angular and uses NPM . You have to install the corresponding packages with npm i . Now you have to possibilites to run the application in developer mode: With a local installed DSP-API environment run ng serve or npm run start . If you want to connect to the DSP-API on our test server run ng serve --configuration=test-server or npm run start-with-test-server . Please consider which version of DSP-API is currently running on the test server (see webapi: https://api.test.dasch.swiss/version ). With this solution you will also have access to all the representation files. In both case navigate to http://0.0.0.0:4200/ . The app will automatically reload if you change any of the resource files.","title":"Development server"},{"location":"DSP-APP/contribution/#code-scaffolding","text":"Run ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module .","title":"Code scaffolding"},{"location":"DSP-APP/contribution/#build","text":"Run npm run build to build the app. The build artifacts will be stored in the dist/ directory. Run the command npm run build-prod for a production build.","title":"Build"},{"location":"DSP-APP/contribution/#test","text":"The following tests (unit, e2e and lint) are part of the Github Actions (CI) workflow and has to be run successfully before the code can be merged into the main branch.","title":"Test"},{"location":"DSP-APP/contribution/#running-unit-tests","text":"Run npm run test-local to execute the unit tests via Karma on your local computer. Run npm run test-ci to execute the unit tests via Karma without a browser. It is used in the Github Actions (CI) workflow.","title":"Running unit tests"},{"location":"DSP-APP/contribution/#running-end-to-end-tests","text":"Run npm run test-e2e-protractor to execute the end-to-end tests via Protractor .","title":"Running end-to-end tests"},{"location":"DSP-APP/contribution/#running-code-linter","text":"Run npm run lint-local to execute the lint service via ESLint . This command uses the --fix flag which fixes simple errors like redundant type if you have default value assigned. In the Github Actions (CI) workflow the linter runs as npm run lint-ci . To integrate ESLint with Visual Studio Code, do the following: Install the ESLint extension. Create a task via the Tasks: Configure Task command and select npm: lint-local . In the resulting tasks.json file, configure the problem matcher to be $eslint-stylish .","title":"Running code linter"},{"location":"DSP-APP/contribution/#further-help","text":"To get more help on the Angular CLI use ng help or go check out the Angular CLI README .","title":"Further help"},{"location":"DSP-APP/contribution/docs-documentation/","text":"DSP-APP Documentation This is the DSP-APP documentation, based on MkDocs and published under http://dasch-swiss.github.io/dsp-app . Contribute If you would like to add your own contributions to the docs, please read the following information regarding the file structure to ensure you follow the same structure. File structure The documentation consists of three main topics with subordinate themes: index contains all information about the DSP-APP user-guide contains the DSP-APP user guide Index = Introduction: All about login, registration and DSP APP information in general. Project = All about project administration; part of DSP-ADMIN User = All about user administration; part of DSP-ADMIN System = All about system administration; part of DSP-ADMIN Data = All about data management; part of VRE. In the current DSP-APP ADMIN version it's commented out contribution contains all information for people who wants to contribute to DSP-APP Index = How to contribute incl. link to the general DSP contribution guidelines ( https://docs.dasch.swiss/developers/dsp/contribution/ ) Release Notes = Contains the CHANGELOG file of DSP-APP Images like screenshots and so on have to be stored in assets/images . The mkdocs.yml file is present in the top-level directory of the repo and the source files are in the docs/ folder. Plugins have to be defined in requirements.txt and in the github actions workflow deploy-docs step under EXTRA_PACKAGES . Getting Started To run the documentation locally you'll need Python installed, as well as the Python package manager pip . You can check if you already have these installed by running the following commands from the command line: $ python --version Python 3.8.2 $ pip --version pip 20.0.2 from /usr/local/lib/python3.8/site-packages/pip (python 3.8) MkDocs supports Python versions 3.5, 3.6, 3.7, 3.8, and pypy3. Installing dependencies Install the required packages by running the following command: make docs-install-requirements Running the documentation locally MkDocs comes with a built-in dev-server that lets you preview your documentation as you work on it. Make sure you're in the same directory as the mkdocs.yml (repository's root folder) configuration file, and then start the server by running the following command: $ make docs-serve INFO - Building documentation... INFO - Cleaning site directory [I 160402 15:50:43 server:271] Serving on http://127.0.0.1:8000 [I 160402 15:50:43 handlers:58] Start watching changes [I 160402 15:50:43 handlers:60] Start detecting changes Open up http://127.0.0.1:8000/ in your browser, and you'll see the documentation start page being. In case you need to clean the project directory, run: make docs-clean To get some help about the make commands, run: make help Building the documentation To build the documentation, run: make docs-build Deploying github page On each release of DSP-APP, a github action script will build and deploy the documentation on dasch-swiss.github.io/dsp-app . Behind the scenes, MkDocs builds the documentation and uses the mkdocs-deploy-gh-pages actions script to deploy them to the gh-pages. That's it!","title":"Docs Documentation"},{"location":"DSP-APP/contribution/docs-documentation/#dsp-app-documentation","text":"This is the DSP-APP documentation, based on MkDocs and published under http://dasch-swiss.github.io/dsp-app .","title":"DSP-APP Documentation"},{"location":"DSP-APP/contribution/docs-documentation/#contribute","text":"If you would like to add your own contributions to the docs, please read the following information regarding the file structure to ensure you follow the same structure.","title":"Contribute"},{"location":"DSP-APP/contribution/docs-documentation/#file-structure","text":"The documentation consists of three main topics with subordinate themes: index contains all information about the DSP-APP user-guide contains the DSP-APP user guide Index = Introduction: All about login, registration and DSP APP information in general. Project = All about project administration; part of DSP-ADMIN User = All about user administration; part of DSP-ADMIN System = All about system administration; part of DSP-ADMIN Data = All about data management; part of VRE. In the current DSP-APP ADMIN version it's commented out contribution contains all information for people who wants to contribute to DSP-APP Index = How to contribute incl. link to the general DSP contribution guidelines ( https://docs.dasch.swiss/developers/dsp/contribution/ ) Release Notes = Contains the CHANGELOG file of DSP-APP Images like screenshots and so on have to be stored in assets/images . The mkdocs.yml file is present in the top-level directory of the repo and the source files are in the docs/ folder. Plugins have to be defined in requirements.txt and in the github actions workflow deploy-docs step under EXTRA_PACKAGES .","title":"File structure"},{"location":"DSP-APP/contribution/docs-documentation/#getting-started","text":"To run the documentation locally you'll need Python installed, as well as the Python package manager pip . You can check if you already have these installed by running the following commands from the command line: $ python --version Python 3.8.2 $ pip --version pip 20.0.2 from /usr/local/lib/python3.8/site-packages/pip (python 3.8) MkDocs supports Python versions 3.5, 3.6, 3.7, 3.8, and pypy3.","title":"Getting Started"},{"location":"DSP-APP/contribution/docs-documentation/#installing-dependencies","text":"Install the required packages by running the following command: make docs-install-requirements","title":"Installing dependencies"},{"location":"DSP-APP/contribution/docs-documentation/#running-the-documentation-locally","text":"MkDocs comes with a built-in dev-server that lets you preview your documentation as you work on it. Make sure you're in the same directory as the mkdocs.yml (repository's root folder) configuration file, and then start the server by running the following command: $ make docs-serve INFO - Building documentation... INFO - Cleaning site directory [I 160402 15:50:43 server:271] Serving on http://127.0.0.1:8000 [I 160402 15:50:43 handlers:58] Start watching changes [I 160402 15:50:43 handlers:60] Start detecting changes Open up http://127.0.0.1:8000/ in your browser, and you'll see the documentation start page being. In case you need to clean the project directory, run: make docs-clean To get some help about the make commands, run: make help","title":"Running the documentation locally"},{"location":"DSP-APP/contribution/docs-documentation/#building-the-documentation","text":"To build the documentation, run: make docs-build","title":"Building the documentation"},{"location":"DSP-APP/contribution/docs-documentation/#deploying-github-page","text":"On each release of DSP-APP, a github action script will build and deploy the documentation on dasch-swiss.github.io/dsp-app . Behind the scenes, MkDocs builds the documentation and uses the mkdocs-deploy-gh-pages actions script to deploy them to the gh-pages. That's it!","title":"Deploying github page"},{"location":"DSP-APP/contribution/release-notes/","text":"Changelog 9.2.1 (2022-02-21) Bug Fixes permission-info: better permission string handling (DEV-537) ( #667 ) ( 8be1efe ) resource: resource viewer is broken if fileRepresentation has restricted view (DEV-455) ( #666 ) ( 6a360ac ) still-image: fix image displayed as black square (DEV-525) ( #668 ) ( 33833f6 ) Maintenance deps: bump url-parse from 1.5.4 to 1.5.7 ( #664 ) ( 54a348f ) rollbar: add environment to the config ( #669 ) ( 8a587b9 ) 9.2.0 (2022-02-17) Bug Fixes ontology-editor: display sub-properties the correct way (DEV-530) ( #661 ) ( a2cf6e0 ) Enhancements resource: display permissions (DEV-454) ( #660 ) ( 13a3a49 ) 9.1.0 (2022-02-15) Enhancements add-link-resource-button: Add Link Resource Button (DEV-404) ( #645 ) ( f762c3c ) Maintenance deps-dev: bump karma from 6.3.13 to 6.3.14 ( #653 ) ( 1794e47 ) deps: bump follow-redirects from 1.14.7 to 1.14.8 ( #656 ) ( 8554764 ) google fonts: switches back to self hosting google fonts ( #654 ) ( 938721b ) open-sea-dragon: updates package to v3.0.0 ( #658 ) ( 42bffa6 ) 9.0.1 (2022-02-09) Bug Fixes main: bug fix in configuration file in case of prod mode (DEV-491) ( #651 ) ( a6c9e87 ) 9.0.0 (2022-02-02) \u26a0 BREAKING CHANGES display dsp release number (DEV-420) (#644) Bug Fixes ontology: support subproperty in ontology editor (DEV-332) ( #643 ) ( c838043 ) Enhancements display dsp release number (DEV-420) ( #644 ) ( b6c9f1c ) Maintenance deps: bump log4js from 6.3.0 to 6.4.1 ( #648 ) ( dd2eebe ) deps: bump nanoid from 3.1.30 to 3.2.0 ( #647 ) ( 13c6f2a ) deps: update packages ( #650 ) ( cc60b0b ) 8.5.0 (2022-01-19) Bug Fixes project: better project form validation (DEV-336) ( #641 ) ( a7563a3 ) Maintenance angular: optimize ng s in dev mode ( #640 ) ( 9812b9c ) deps: fix security vulnerability ( #638 ) ( f19434e ) Enhancements ontology: support partOf value to create book res class (DEV-180) ( #634 ) ( 3051a67 ) 8.4.0 (2022-01-17) Bug Fixes advanced search: update comparison operators in case of rich text (DEV-326) ( #633 ) ( cd01d87 ) archive representation: a resource with an archive representation now loads correctly again ( #630 ) ( 299ecf9 ) date-value: do not submit in case of period button (DEV-373) ( #635 ) ( d7ac1b6 ) Maintenance clean up after bump dsp-js ( #628 ) ( 374fc78 ) ontology: clean up unused code (DEV-304) ( #629 ) ( 3d029a1 ) Enhancements resource: display deleted resource (DEV-299) ( #632 ) ( 2c5fd80 ) 8.3.3 (2022-01-04) Bug Fixes resource: bug fix in pdf viewer (DEV-338) ( #626 ) ( 4b5d5d5 ) 8.3.2 (2021-12-16) Bug Fixes authentication: set active datadog rum user (DEV-325) ( #624 ) ( 69308e0 ) 8.3.1 (2021-12-15) Bug Fixes upload: fix thumbnail preview (DEV-268) ( #619 ) ( 7cb8505 ) Maintenance authentication: new login / logout structure (DEV-325) ( #622 ) ( e8bec98 ) fonts: delete fonts and icons (DEV-327) ( #623 ) ( 08e088b ) google fonts: switch to using fonts hosted by google ( #620 ) ( daa4167 ) 8.3.0 (2021-12-09) Bug Fixes resource: update lastModificationDate after editing label (DEV-315) ( #616 ) ( 3b9d93b ) Enhancements still-image: display iiif url under the image caption (DEV-243) ( #613 ) ( 109978f ) Maintenance metadata: remove \"old\" implementation of the project metadata (DEV-282) ( #615 ) ( 29acf3a ) 8.2.0 (2021-12-08) Bug Fixes ontology: bug fix in ontology form (DEV-280) ( #603 ) ( 4c1bc24 ) resource: create resource iri from route only in certain cases (DEV-306) ( #605 ) ( a38abd0 ) value: fix linkify pipe (DEV-270) ( #602 ) ( f2c8d7a ) Enhancements representation: add support for uploading and viewing archive files (DEV-18) ( #600 ) ( 9bb63d7 ) Maintenance deps: update outdated angular packages ( #604 ) ( 80b3f93 ) deps: use correct nginx-server (DEV-263) ( #610 ) ( ccae958 ) angular: fix budget in prod mode ( #606 ) ( 5072948 ) 8.1.2 (2021-12-01) Maintenance lists: adds changes required for lists to work due to the change in js-lib ( #599 ) ( ca83584 ) projects: don't use the cache when refreshing the projects list. Also renames some labels and methods to clarify that these things are for deactivating a project as opposed to deleting a project. ( #597 ) ( faebe3e ) 8.1.1 (2021-11-19) Bug Fixes results: display xml a better way (DEV-96) ( #593 ) ( d968f2f ) value: bug fix in text-value-as-string (DEV-242) ( #595 ) ( 0fb95ee ) 8.1.0 (2021-11-18) Bug Fixes fulltext-search: updates the projects list when a new project is created (DEV-212) ( #586 ) ( 43fcbfa ) ontology: resolve gui order issue (DEV-222) ( #590 ) ( 4ddbf7c ) ontology: send modified label (DEV-221) ( #589 ) ( 9d7ffea ) text-value: resource-instance-form and display-edit components now correctly display a paragraph text with line breaks (DEV-211) ( #584 ) ( be9d6f4 ) Maintenance deps: update angular to v12 ( #588 ) ( 37e65a8 ) Enhancements properties: ckEditor Internal Links (DEV-118) ( #591 ) ( cac988b ) update UI on region color change (DEV-215) ( #583 ) ( b497d0e ) 8.0.0 (2021-11-10) \u26a0 BREAKING CHANGES resource: new resource route (DEV-196) (#581) Maintenance small code improvements ( #579 ) ( d19e353 ) Enhancements resource: add additional routing for an ark url of a value (DEV-196) ( #575 ) ( c1b0b94 ) resource: new resource route (DEV-196) ( #581 ) ( 3fbd94c ) still-image: uses the color of the color property for the line color if a color property for the region exists ( #580 ) ( 7680353 ) 7.0.1 (2021-11-05) Bug Fixes error: resolve error handler in case of server error (DEV-205) ( #576 ) ( ff9d097 ) ontology: class and property name has to be unique (DEV-183) ( #569 ) ( 059dd2a ) value: display ckEditor in case of rich-text property (DEV-182) ( #571 ) ( 6bfe254 ) Maintenance annotations will now only be drawn when the user is on the annotations tab ( #574 ) ( bddc2f1 ) deps: use release of ckeditor custom build (DEV-189) ( #570 ) ( fb55fd7 ) main: use version route (DEV-124) ( #565 ) ( 16f26ce ) move datadog rum methods to service (DEV-190) ( #572 ) ( 77191cb ) refactors upload-file service to use the string generated in the iiif-config file and changes the public class members in app-init service to private with getters. ( #573 ) ( c39ca5b ) 7.0.0 (2021-10-28) \u26a0 BREAKING CHANGES error logging: rollbar implementation (DEV-20) (#543) Bug Fixes ontology: use correct label (DEV-168) ( #564 ) ( 70cc7d8 ) Maintenance gh: update issue templates ( #562 ) ( 6d510c7 ) Enhancements error logging: rollbar implementation (DEV-20) ( #543 ) ( d0a9e3f ) 6.5.0 (2021-10-21) Enhancements ontology: bring back the name input field (DEV-157) ( #559 ) ( 51e539d ) 6.4.1 (2021-10-20) Bug Fixes value: fix boolean value issue ( #557 ) ( 4d35cd2 ) Maintenance deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #556 ) ( 5f8213c ) 6.4.0 (2021-10-20) Enhancements ontology: delete property from resource class (DSP-1854 / DEV-28) ( #499 ) ( 436c270 ) value: refactor boolean value (DEV-98) ( #554 ) ( 7affa5e ) 6.3.0 (2021-10-15) Bug Fixes disable edit/delete action in deactivated projects (DEV-52) ( #550 ) ( d7bec78 ) properties: do not submit res instance form by adding new value (DEV-150) ( #553 ) ( 99a3022 ) value: fix broken time value component (DEV-147) ( #552 ) ( fb846f9 ) Enhancements datadog RUM implementation (DEV-50) ( #546 ) ( ec59ee5 ) resource: new date picker (DEV-112) ( #532 ) ( 04e4b32 ) 6.2.0 (2021-10-08) Bug Fixes error: improve the current error handler in DSP-APP (DSP-1911) ( #540 ) ( 0eb621b ) gravsearch results now appear after page refresh ( #542 ) ( a88dd79 ) resource-instance-form: reloads cached resource to show changes made to the data model ( #547 ) ( 37bb2a7 ) Enhancements ontology: display id / name in property and class (DEV-37) ( #544 ) ( 0a2bcfb ) search: add missing search resource component (DEV-95) ( #548 ) ( 79abd10 ) Maintenance fulltext-search: persist fulltext search term in input field (DSP-1674) ( #539 ) ( 67a52a3 ) resource: improve still image annotation form (DEV-53) ( #549 ) ( 38bbe41 ) 6.1.0 (2021-09-20) Bug Fixes annotations: empty annotations on upload of new region ( #536 ) ( 075e6b1 ) links: trust the external links (DSP-1904) ( #537 ) ( 303ac3d ) resource-instance-form: resource class name now updates correctly in the event that the name was changed and the page was not refreshed ( #531 ) ( 5783d27 ) resource: increase width of space between entries of incoming links (DSP-1908) ( #538 ) ( 79b4d29 ) still-image-viewer: fix zoom buttons (DSP-1798) ( #533 ) ( b07ec63 ) Enhancements resource: draw regions (DSP-1845) ( #524 ) ( f08706b ) textarea is now provided is the gui-element is a textarea ( #529 ) ( e80a4d2 ) Maintenance modules: clean up imports and npm packages ( #535 ) ( 4310ff7 ) openseadragon prod build fix (DSP-1779) ( #534 ) ( 0a34eaa ) 6.0.0 (2021-09-08) \u26a0 BREAKING CHANGES config: update config file for better iiif support (DSP-1880) (#511) Bug Fixes audio: sanitize audio url (DSP-1819) ( #513 ) ( 35871cd ) deps: fix security vulnerability ( #514 ) ( d793fb8 ) Enhancements config: update config file for better iiif support (DSP-1880) ( #511 ) ( b799600 ) resource: display incoming links (DSP-1846) ( #507 ) ( 9c3abce ) resource: optimize resource instance form (DSP-1256) ( #518 ) ( 5151677 ) Maintenance action: migrate action module (DSP-1852) ( #509 ) ( 725c45e ) core: migrate core module from UI-lib (DSP-1853) ( #505 ) ( ea1cd55 ) deps: bump dsp-js to latest version (DSP-1883) ( #521 ) ( c956d4b ) deps: bump dsp-ui to latest ( #502 ) ( 5d79065 ) fix style in resource, search-panel and progress-indicator (DSP-1887) ( #520 ) ( 854aff2 ) gh-ci: split workflow tasks ( #515 ) ( 83d5874 ) login: add autocomplete to login form (DSP-1892) ( #527 ) ( dd6be15 ) project: handle mandatory keyword field (DSP-1829) ( #503 ) ( 35f6e7b ) remove CoreModule dependency (DSP-1884) ( #519 ) ( 8549104 ) remove ViewerModule dependency (DSP-1890) ( #525 ) ( a99546e ) removes ActionModule dependency ( #523 ) ( bd60f00 ) removes SearchModule dependency ( #522 ) ( 269be23 ) resource: migrate viewer from UI-lib (DSP-1850) ( #504 ) ( b742a98 ) search: migrate search module (DSP-1851) ( #510 ) ( fc7ea5c ) update imports step 1 (DSP-1882) ( #516 ) ( e7a2c4f ) update remaining dsp-ui imports (DSP-1891) ( #526 ) ( 43888a6 ) 5.3.0 (2021-08-12) Maintenance header: clean up code and use notification service after login ( #498 ) ( fb6c368 ) ontology: update create ontology tooltip for unique name (DSP-1139) ( #500 ) ( 946d00f ) Enhancements resource: create link / collection resource (DSP-1835) ( #501 ) ( 8060756 ) workspace: add intermediate view (DSP-1834) ( #494 ) ( d0e475a ) 5.2.1 (2021-08-03) Maintenance deps: bump dsp-ui to latest version (DSP-1838) ( #495 ) ( 4adc49a ) 5.2.0 (2021-08-02) Enhancements resource: add comparison view (DSP-1796) ( #490 ) ( 731ea04 ) resource: update resource's label (DSP-1801) ( #492 ) ( e2c9867 ) improve error handler and fix search results issue (DSP-1826 / DSP-1831) ( #493 ) ( fa2f4b0 ) 5.1.0 (2021-07-26) Bug Fixes ontology: fix regex pattern in ontology form (DSP-1139) ( #483 ) ( 4d0703f ) Documentation user-guide: update user-guide about ontology (DSP-976) ( #480 ) ( e12f196 ) Maintenance ontology: better regex for onto name (DSP-1139) ( #488 ) ( ec881ef ) resource: hide file value in properties (DSP-1261) ( #484 ) ( 4ade17f ) Enhancements resource: add document viewer with download (DSP-1791) ( #485 ) ( ce51bce ) resource: audio player (DSP-1805) ( #487 ) ( bf372dc ) resource: delete and erase resource (DSP-1228) ( #489 ) ( 8b1fdba ) resource: upload audio (DSP-1799) ( #486 ) ( d865df5 ) resource: upload pdf document (DSP-1776) ( #481 ) ( d916b4b ) 5.0.0 (2021-07-05) \u26a0 BREAKING CHANGES upload: add upload form for still images (DSP-1761) (#472) config: add geoname config (DSP-1672) (#473) Documentation ontology: update docs and show hint in ontology-form (DSP-1139) ( #476 ) ( 927237d ) Enhancements config: add geoname config (DSP-1672) ( #473 ) ( d4222ba ) ontology: add property to res class that is in use (DSP-1631) ( #477 ) ( b18e6ec ) ontology: change gui element for text value properties ( #478 ) ( 6af1f7e ) ontology: display description for default and existing props (DSP-1154) ( #475 ) ( 8be7e55 ) upload: add upload form for still images (DSP-1761) ( #472 ) ( 2f314a2 ) Maintenance deps: bump jdnconvertiblecalendar to v0.0.7 (DSP-1770) ( #479 ) ( b2ec64a ) 4.11.1 (2021-06-23) Documentation search: add advanced search user guide (DSP-1662) ( #470 ) ( 30edc96 ) user-guide: fix navigation links ( #468 ) ( 49c68f8 ) Maintenance fix dead links to the documentation ( #471 ) ( d7ae022 ) 4.11.0 (2021-06-22) Enhancements ontology: check if an ontology, a class or a property can be deleted (DSP-1750) ( #457 ) ( fb0c275 ) Maintenance empty landing page instead login (DSP-1756) ( #466 ) ( 32cd462 ) gh-ci: update docs deployment (DSP-1741) ( #463 ) ( 6415152 ) Documentation refactor documentation and set correct links ( #467 ) ( cbeb274 ) 4.10.1 (2021-06-15) Documentation fix dead links and replace screenshots in project ( #460 ) ( a13b8ba ) prepare documentation for docs.dasch.swiss (DSP-1721) ( #458 ) ( 09259f1 ) Maintenance analytics: add fathom ( #462 ) ( f1e0244 ) cookie-policy: reactivate the cookie policy banner (DSP-1727) ( #461 ) ( ac99fbc ) 4.10.0 (2021-06-07) Enhancements ontology: new cardinality workflow (DSP-1652) ( #455 ) ( f1d049c ) 4.9.1 (2021-05-26) Maintenance resource: improve list of properties in resource viewer ( #453 ) ( 49d9b7f ) 4.9.0 (2021-05-26) Bug Fixes disable progress bar if search results are empty (DSP-1575) ( #442 ) ( 8c67d60 ) resource: add if condition (DSP-1655) ( #448 ) ( 656da04 ) Documentation update documentation about contribution (DSP-1657) ( #449 ) ( c25280d ) Enhancements resource: display region annotations in still images (DSP-1585) ( #445 ) ( 86e75b9 ) search: specify linked resource in advanced search (DSP-1661) ( #451 ) ( 3f0d6d9 ) Maintenance deps: update packages to resolve security issues ( #450 ) ( 8e927f7 ) project: resolve regex term (DSP-1654) ( #444 ) ( 739beba ) 4.8.0 (2021-05-21) Maintenance CD/CI: automatically detect common vulnerabilities and coding errors ( #438 ) ( af02332 ) compiler: enable strict template (DSP-1403) ( #432 ) ( 583a338 ) environment: add test-server config (DSP-1650) ( #443 ) ( a56a45b ) Replace favicon and term Knora by DSP (DSP-1181 / DSP-1342) ( #441 ) ( 3b038b6 ) Enhancements ontology: new method to change gui order (DSP-1567/DSP-1646) ( #440 ) ( dfd0ce0 ) 4.7.0 (2021-05-07) Maintenance search results: disable grid view (DSP-1597) ( #435 ) ( c4726fe ) Enhancements DMP: own resource viewer (DSP-1586) ( #434 ) ( 35bd7b3 ) 4.6.0 (2021-04-27) Enhancements DMP: bring back the workspace ( #431 ) ( e8b1c8e ) 4.5.2 (2021-04-22) Bug Fixes list: list no longer displays after deletion if it was the only list among lists ( #429 ) ( b05484e ) project: bug fix in project member management (DSP-1563) ( #425 ) ( ac820dd ) Maintenance ontology: disable ontology graph view (DSP-1560) ( #427 ) ( 0a567d2 ) ontology: disable rti image class (DSP-1559) ( #430 ) ( 48c3c76 ) ontology: rename boolean prop type (DSP-1561) ( #426 ) ( 4dd23d3 ) 4.5.1 (2021-04-20) Bug Fixes ontology: bug fix in create ontology process (DSP-1558) ( #423 ) ( bbd825b ) 4.5.0 (2021-04-20) Bug Fixes users: update session the correct way (DSP-690) ( #419 ) ( 3ec049e ) Enhancements project: better error handler in case a project does not exist (DSP-1401) ( #421 ) ( d7470a0 ) 4.4.3 (2021-04-14) Bug Fixes ontology: Bug fix in ontology form ( #417 ) ( 96dc804 ) 4.4.2 (2021-04-12) Maintenance migrate to angular11: changes (DSP-1471) ( #415 ) ( 3271ece ) 4.4.1 (2021-04-08) Maintenance migrate to angular10: changes (DSP-1415) ( #412 ) ( cec564d ) 4.4.0 (2021-03-23) Bug Fixes deps: package dependency build errors (DSP-1400) ( #410 ) ( 17e0e1a ) Maintenance list-editor: new list form refactor (DSP-1392) ( #403 ) ( 8824682 ) ontology: improve ontology editor design (DSP-1376) ( #401 ) ( 6de83b8 ) project landing page: update metadata typings (DSP-1393) ( #407 ) ( b4f101b ) project metadata page: enable error handler ( #411 ) ( a4004ed ) Enhancements eslint: migrate tslint to eslint (DSP-1372) ( #394 ) ( 6ffc3b6 ) ontology: edit data model info (DSP-1208) ( #385 ) ( 86a5fb8 ) ontology: form to create and edit property (DSP-1210) ( #406 ) ( 91ebb68 ) 4.3.1 (2021-03-03) Bug Fixes project: disable error handler in metadata request (DSP-1395) ( #404 ) ( 86ebfcf ) 4.3.0 (2021-03-02) Bug Fixes ontology: set the cache earlier in case of only one ontology (DSP-1374) ( #397 ) ( c23ae61 ) Enhancements list-editor: insert a child node at a specific position (DSP-1301) ( #395 ) ( 5107200 ) ontology: separate list of ontology properties (DSP-1364) ( #391 ) ( 0f94df6 ) Maintenance deps: bump three from 0.118.3 to 0.125.0 ( #402 ) ( 5ab9c49 ) gh-ci: update release please configuration (DSP-1381) ( #399 ) ( 040df19 ) project landing page: use metadata endpoint to get data from backend (DSP-1199) ( #400 ) ( 5dde42f ) tests: script to find ignored tests ( #396 ) ( 9ca249d ) 4.2.1 (2021-02-24) Bug Fixes ontology: bug fix in list property (DSP-1368) ( #390 ) ( 2fb448e ) 4.2.0 (2021-02-22) Enhancements list-editor: add deletion functionality (DSP-1334) ( #378 ) ( 34c74a6 ) list-editor: delete list root node (DSP-1356) ( #386 ) ( 5d5eabf ) list-editor: reposition a child node amongst its siblings (DSP-1340) ( #388 ) ( 0a9be0e ) ontology: default language for property label ( #382 ) ( 97230d1 ) ontology: edit res class info (DSP-1209) ( #380 ) ( 2debd03 ) ontology: refactor list of properties in resource class (DSP-1360) ( #389 ) ( aa565b3 ) 4.1.0 (2021-02-12) Documentation init mkdocs and move documentation from DSP-DOCS into DSP-APP repo (DSP-380) ( #379 ) ( 07f5067 ) Maintenance bumps DSP-JS to 1.3.0 and DSP-UI to 1.2.1 ( #374 ) ( 7b795ee ) deps: bump socket.io from 2.3.0 to 2.4.1 ( #367 ) ( 8133d87 ) Enhancements list editor: Adds support for editing lists (DSP-741) ( #365 ) ( 5b6ee4b ) ontology: update cardinality in resource class (DSP-1266) ( #377 ) ( 5a766c1 ) 4.0.0 (2021-01-28) \u26a0 BREAKING CHANGES set up the login page as a starting page (DSP-1292) (#370) app+main: comment out the search and everything related to resources (DSP-1291) (#371) Bug Fixes dialog: Diaolog box height issue fixed ( #358 ) ( 15d1182 ) routing: bring back the route handler in main component (DSP-1303) ( #373 ) ( 8492c1a ) Maintenance update pr template (DSP-1189) ( #353 ) ( f348e70 ) update the dsp-ui and dsp-js versions to the latest ( #364 ) ( 66931f0 ) Enhancements display metadata on project landing page (DSP-1065) ( #348 ) ( 3012ef5 ) error: Server error handler (DSP-710) ( #355 ) ( d5b77bf ) new-resource-form: make visible the required prop fields (DSP-1115) ( #342 ) ( 5885b04 ) project landing page: add copy to clipboard functionality (DSP-1248) ( #368 ) ( 17bf71c ) select-resource-class: allow accented character (DSP-1241) ( #363 ) ( 8a2654b ) refactor app+main: comment out the search and everything related to resources (DSP-1291) ( #371 ) ( 50b1309 ) set up the login page as a starting page (DSP-1292) ( #370 ) ( 46dfdbb ) 3.0.0 (2020-12-18) \u26a0 BREAKING CHANGES Prepare next big release (#350) Bug Fixes header: Replace search-panel with fulltext-search ( #313 ) ( d234fa7 ) node_modules: Update dependencies ( #318 ) ( f85e4a2 ) project: Bug fix in project view when not logged-in ( #339 ) ( ce5acf1 ) workspace: Fix broken link ( #306 ) ( 52b324d ) Open external link in new tab ( #297 ) ( 99f188e ) Replaced reset buttons with cancel button ( #284 ) ( 1481018 ) Update docker environment ( #294 ) ( db6d277 ) Documentation Update README ( #292 ) ( fa72ee1 ) Enhancements Prepare next big release ( #350 ) ( 6a39180 ) header: display form link when the session is active ( #332 ) ( d609bd5 ) header+dialog: create button in the header + dialog box ( #320 ) ( 5e4890d ) PR: Add template for PRs ( #305 ) ( 1468ee1 ) Maintenance ci: Update package-name in gh actions workflow ( #352 ) ( 3d9bb13 ) Update js- and ui-lib version ( #293 ) ( 5409d9b )","title":"Release Notes"},{"location":"DSP-APP/contribution/release-notes/#changelog","text":"","title":"Changelog"},{"location":"DSP-APP/contribution/release-notes/#921-2022-02-21","text":"","title":"9.2.1 (2022-02-21)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes","text":"permission-info: better permission string handling (DEV-537) ( #667 ) ( 8be1efe ) resource: resource viewer is broken if fileRepresentation has restricted view (DEV-455) ( #666 ) ( 6a360ac ) still-image: fix image displayed as black square (DEV-525) ( #668 ) ( 33833f6 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance","text":"deps: bump url-parse from 1.5.4 to 1.5.7 ( #664 ) ( 54a348f ) rollbar: add environment to the config ( #669 ) ( 8a587b9 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#920-2022-02-17","text":"","title":"9.2.0 (2022-02-17)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_1","text":"ontology-editor: display sub-properties the correct way (DEV-530) ( #661 ) ( a2cf6e0 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements","text":"resource: display permissions (DEV-454) ( #660 ) ( 13a3a49 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#910-2022-02-15","text":"","title":"9.1.0 (2022-02-15)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_1","text":"add-link-resource-button: Add Link Resource Button (DEV-404) ( #645 ) ( f762c3c )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_1","text":"deps-dev: bump karma from 6.3.13 to 6.3.14 ( #653 ) ( 1794e47 ) deps: bump follow-redirects from 1.14.7 to 1.14.8 ( #656 ) ( 8554764 ) google fonts: switches back to self hosting google fonts ( #654 ) ( 938721b ) open-sea-dragon: updates package to v3.0.0 ( #658 ) ( 42bffa6 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#901-2022-02-09","text":"","title":"9.0.1 (2022-02-09)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_2","text":"main: bug fix in configuration file in case of prod mode (DEV-491) ( #651 ) ( a6c9e87 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#900-2022-02-02","text":"","title":"9.0.0 (2022-02-02)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes","text":"display dsp release number (DEV-420) (#644)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_3","text":"ontology: support subproperty in ontology editor (DEV-332) ( #643 ) ( c838043 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_2","text":"display dsp release number (DEV-420) ( #644 ) ( b6c9f1c )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_2","text":"deps: bump log4js from 6.3.0 to 6.4.1 ( #648 ) ( dd2eebe ) deps: bump nanoid from 3.1.30 to 3.2.0 ( #647 ) ( 13c6f2a ) deps: update packages ( #650 ) ( cc60b0b )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#850-2022-01-19","text":"","title":"8.5.0 (2022-01-19)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_4","text":"project: better project form validation (DEV-336) ( #641 ) ( a7563a3 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_3","text":"angular: optimize ng s in dev mode ( #640 ) ( 9812b9c ) deps: fix security vulnerability ( #638 ) ( f19434e )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_3","text":"ontology: support partOf value to create book res class (DEV-180) ( #634 ) ( 3051a67 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#840-2022-01-17","text":"","title":"8.4.0 (2022-01-17)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_5","text":"advanced search: update comparison operators in case of rich text (DEV-326) ( #633 ) ( cd01d87 ) archive representation: a resource with an archive representation now loads correctly again ( #630 ) ( 299ecf9 ) date-value: do not submit in case of period button (DEV-373) ( #635 ) ( d7ac1b6 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_4","text":"clean up after bump dsp-js ( #628 ) ( 374fc78 ) ontology: clean up unused code (DEV-304) ( #629 ) ( 3d029a1 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_4","text":"resource: display deleted resource (DEV-299) ( #632 ) ( 2c5fd80 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#833-2022-01-04","text":"","title":"8.3.3 (2022-01-04)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_6","text":"resource: bug fix in pdf viewer (DEV-338) ( #626 ) ( 4b5d5d5 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#832-2021-12-16","text":"","title":"8.3.2 (2021-12-16)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_7","text":"authentication: set active datadog rum user (DEV-325) ( #624 ) ( 69308e0 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#831-2021-12-15","text":"","title":"8.3.1 (2021-12-15)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_8","text":"upload: fix thumbnail preview (DEV-268) ( #619 ) ( 7cb8505 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_5","text":"authentication: new login / logout structure (DEV-325) ( #622 ) ( e8bec98 ) fonts: delete fonts and icons (DEV-327) ( #623 ) ( 08e088b ) google fonts: switch to using fonts hosted by google ( #620 ) ( daa4167 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#830-2021-12-09","text":"","title":"8.3.0 (2021-12-09)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_9","text":"resource: update lastModificationDate after editing label (DEV-315) ( #616 ) ( 3b9d93b )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_5","text":"still-image: display iiif url under the image caption (DEV-243) ( #613 ) ( 109978f )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_6","text":"metadata: remove \"old\" implementation of the project metadata (DEV-282) ( #615 ) ( 29acf3a )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#820-2021-12-08","text":"","title":"8.2.0 (2021-12-08)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_10","text":"ontology: bug fix in ontology form (DEV-280) ( #603 ) ( 4c1bc24 ) resource: create resource iri from route only in certain cases (DEV-306) ( #605 ) ( a38abd0 ) value: fix linkify pipe (DEV-270) ( #602 ) ( f2c8d7a )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_6","text":"representation: add support for uploading and viewing archive files (DEV-18) ( #600 ) ( 9bb63d7 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_7","text":"deps: update outdated angular packages ( #604 ) ( 80b3f93 ) deps: use correct nginx-server (DEV-263) ( #610 ) ( ccae958 ) angular: fix budget in prod mode ( #606 ) ( 5072948 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#812-2021-12-01","text":"","title":"8.1.2 (2021-12-01)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_8","text":"lists: adds changes required for lists to work due to the change in js-lib ( #599 ) ( ca83584 ) projects: don't use the cache when refreshing the projects list. Also renames some labels and methods to clarify that these things are for deactivating a project as opposed to deleting a project. ( #597 ) ( faebe3e )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#811-2021-11-19","text":"","title":"8.1.1 (2021-11-19)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_11","text":"results: display xml a better way (DEV-96) ( #593 ) ( d968f2f ) value: bug fix in text-value-as-string (DEV-242) ( #595 ) ( 0fb95ee )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#810-2021-11-18","text":"","title":"8.1.0 (2021-11-18)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_12","text":"fulltext-search: updates the projects list when a new project is created (DEV-212) ( #586 ) ( 43fcbfa ) ontology: resolve gui order issue (DEV-222) ( #590 ) ( 4ddbf7c ) ontology: send modified label (DEV-221) ( #589 ) ( 9d7ffea ) text-value: resource-instance-form and display-edit components now correctly display a paragraph text with line breaks (DEV-211) ( #584 ) ( be9d6f4 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_9","text":"deps: update angular to v12 ( #588 ) ( 37e65a8 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_7","text":"properties: ckEditor Internal Links (DEV-118) ( #591 ) ( cac988b ) update UI on region color change (DEV-215) ( #583 ) ( b497d0e )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#800-2021-11-10","text":"","title":"8.0.0 (2021-11-10)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_1","text":"resource: new resource route (DEV-196) (#581)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#maintenance_10","text":"small code improvements ( #579 ) ( d19e353 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_8","text":"resource: add additional routing for an ark url of a value (DEV-196) ( #575 ) ( c1b0b94 ) resource: new resource route (DEV-196) ( #581 ) ( 3fbd94c ) still-image: uses the color of the color property for the line color if a color property for the region exists ( #580 ) ( 7680353 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#701-2021-11-05","text":"","title":"7.0.1 (2021-11-05)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_13","text":"error: resolve error handler in case of server error (DEV-205) ( #576 ) ( ff9d097 ) ontology: class and property name has to be unique (DEV-183) ( #569 ) ( 059dd2a ) value: display ckEditor in case of rich-text property (DEV-182) ( #571 ) ( 6bfe254 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_11","text":"annotations will now only be drawn when the user is on the annotations tab ( #574 ) ( bddc2f1 ) deps: use release of ckeditor custom build (DEV-189) ( #570 ) ( fb55fd7 ) main: use version route (DEV-124) ( #565 ) ( 16f26ce ) move datadog rum methods to service (DEV-190) ( #572 ) ( 77191cb ) refactors upload-file service to use the string generated in the iiif-config file and changes the public class members in app-init service to private with getters. ( #573 ) ( c39ca5b )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#700-2021-10-28","text":"","title":"7.0.0 (2021-10-28)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_2","text":"error logging: rollbar implementation (DEV-20) (#543)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_14","text":"ontology: use correct label (DEV-168) ( #564 ) ( 70cc7d8 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_12","text":"gh: update issue templates ( #562 ) ( 6d510c7 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_9","text":"error logging: rollbar implementation (DEV-20) ( #543 ) ( d0a9e3f )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#650-2021-10-21","text":"","title":"6.5.0 (2021-10-21)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_10","text":"ontology: bring back the name input field (DEV-157) ( #559 ) ( 51e539d )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#641-2021-10-20","text":"","title":"6.4.1 (2021-10-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_15","text":"value: fix boolean value issue ( #557 ) ( 4d35cd2 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_13","text":"deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #556 ) ( 5f8213c )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#640-2021-10-20","text":"","title":"6.4.0 (2021-10-20)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_11","text":"ontology: delete property from resource class (DSP-1854 / DEV-28) ( #499 ) ( 436c270 ) value: refactor boolean value (DEV-98) ( #554 ) ( 7affa5e )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#630-2021-10-15","text":"","title":"6.3.0 (2021-10-15)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_16","text":"disable edit/delete action in deactivated projects (DEV-52) ( #550 ) ( d7bec78 ) properties: do not submit res instance form by adding new value (DEV-150) ( #553 ) ( 99a3022 ) value: fix broken time value component (DEV-147) ( #552 ) ( fb846f9 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_12","text":"datadog RUM implementation (DEV-50) ( #546 ) ( ec59ee5 ) resource: new date picker (DEV-112) ( #532 ) ( 04e4b32 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#620-2021-10-08","text":"","title":"6.2.0 (2021-10-08)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_17","text":"error: improve the current error handler in DSP-APP (DSP-1911) ( #540 ) ( 0eb621b ) gravsearch results now appear after page refresh ( #542 ) ( a88dd79 ) resource-instance-form: reloads cached resource to show changes made to the data model ( #547 ) ( 37bb2a7 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_13","text":"ontology: display id / name in property and class (DEV-37) ( #544 ) ( 0a2bcfb ) search: add missing search resource component (DEV-95) ( #548 ) ( 79abd10 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_14","text":"fulltext-search: persist fulltext search term in input field (DSP-1674) ( #539 ) ( 67a52a3 ) resource: improve still image annotation form (DEV-53) ( #549 ) ( 38bbe41 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#610-2021-09-20","text":"","title":"6.1.0 (2021-09-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_18","text":"annotations: empty annotations on upload of new region ( #536 ) ( 075e6b1 ) links: trust the external links (DSP-1904) ( #537 ) ( 303ac3d ) resource-instance-form: resource class name now updates correctly in the event that the name was changed and the page was not refreshed ( #531 ) ( 5783d27 ) resource: increase width of space between entries of incoming links (DSP-1908) ( #538 ) ( 79b4d29 ) still-image-viewer: fix zoom buttons (DSP-1798) ( #533 ) ( b07ec63 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_14","text":"resource: draw regions (DSP-1845) ( #524 ) ( f08706b ) textarea is now provided is the gui-element is a textarea ( #529 ) ( e80a4d2 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_15","text":"modules: clean up imports and npm packages ( #535 ) ( 4310ff7 ) openseadragon prod build fix (DSP-1779) ( #534 ) ( 0a34eaa )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#600-2021-09-08","text":"","title":"6.0.0 (2021-09-08)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_3","text":"config: update config file for better iiif support (DSP-1880) (#511)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_19","text":"audio: sanitize audio url (DSP-1819) ( #513 ) ( 35871cd ) deps: fix security vulnerability ( #514 ) ( d793fb8 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_15","text":"config: update config file for better iiif support (DSP-1880) ( #511 ) ( b799600 ) resource: display incoming links (DSP-1846) ( #507 ) ( 9c3abce ) resource: optimize resource instance form (DSP-1256) ( #518 ) ( 5151677 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_16","text":"action: migrate action module (DSP-1852) ( #509 ) ( 725c45e ) core: migrate core module from UI-lib (DSP-1853) ( #505 ) ( ea1cd55 ) deps: bump dsp-js to latest version (DSP-1883) ( #521 ) ( c956d4b ) deps: bump dsp-ui to latest ( #502 ) ( 5d79065 ) fix style in resource, search-panel and progress-indicator (DSP-1887) ( #520 ) ( 854aff2 ) gh-ci: split workflow tasks ( #515 ) ( 83d5874 ) login: add autocomplete to login form (DSP-1892) ( #527 ) ( dd6be15 ) project: handle mandatory keyword field (DSP-1829) ( #503 ) ( 35f6e7b ) remove CoreModule dependency (DSP-1884) ( #519 ) ( 8549104 ) remove ViewerModule dependency (DSP-1890) ( #525 ) ( a99546e ) removes ActionModule dependency ( #523 ) ( bd60f00 ) removes SearchModule dependency ( #522 ) ( 269be23 ) resource: migrate viewer from UI-lib (DSP-1850) ( #504 ) ( b742a98 ) search: migrate search module (DSP-1851) ( #510 ) ( fc7ea5c ) update imports step 1 (DSP-1882) ( #516 ) ( e7a2c4f ) update remaining dsp-ui imports (DSP-1891) ( #526 ) ( 43888a6 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#530-2021-08-12","text":"","title":"5.3.0 (2021-08-12)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_17","text":"header: clean up code and use notification service after login ( #498 ) ( fb6c368 ) ontology: update create ontology tooltip for unique name (DSP-1139) ( #500 ) ( 946d00f )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_16","text":"resource: create link / collection resource (DSP-1835) ( #501 ) ( 8060756 ) workspace: add intermediate view (DSP-1834) ( #494 ) ( d0e475a )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#521-2021-08-03","text":"","title":"5.2.1 (2021-08-03)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_18","text":"deps: bump dsp-ui to latest version (DSP-1838) ( #495 ) ( 4adc49a )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#520-2021-08-02","text":"","title":"5.2.0 (2021-08-02)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_17","text":"resource: add comparison view (DSP-1796) ( #490 ) ( 731ea04 ) resource: update resource's label (DSP-1801) ( #492 ) ( e2c9867 ) improve error handler and fix search results issue (DSP-1826 / DSP-1831) ( #493 ) ( fa2f4b0 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#510-2021-07-26","text":"","title":"5.1.0 (2021-07-26)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_20","text":"ontology: fix regex pattern in ontology form (DSP-1139) ( #483 ) ( 4d0703f )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#documentation","text":"user-guide: update user-guide about ontology (DSP-976) ( #480 ) ( e12f196 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance_19","text":"ontology: better regex for onto name (DSP-1139) ( #488 ) ( ec881ef ) resource: hide file value in properties (DSP-1261) ( #484 ) ( 4ade17f )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_18","text":"resource: add document viewer with download (DSP-1791) ( #485 ) ( ce51bce ) resource: audio player (DSP-1805) ( #487 ) ( bf372dc ) resource: delete and erase resource (DSP-1228) ( #489 ) ( 8b1fdba ) resource: upload audio (DSP-1799) ( #486 ) ( d865df5 ) resource: upload pdf document (DSP-1776) ( #481 ) ( d916b4b )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#500-2021-07-05","text":"","title":"5.0.0 (2021-07-05)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_4","text":"upload: add upload form for still images (DSP-1761) (#472) config: add geoname config (DSP-1672) (#473)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#documentation_1","text":"ontology: update docs and show hint in ontology-form (DSP-1139) ( #476 ) ( 927237d )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#enhancements_19","text":"config: add geoname config (DSP-1672) ( #473 ) ( d4222ba ) ontology: add property to res class that is in use (DSP-1631) ( #477 ) ( b18e6ec ) ontology: change gui element for text value properties ( #478 ) ( 6af1f7e ) ontology: display description for default and existing props (DSP-1154) ( #475 ) ( 8be7e55 ) upload: add upload form for still images (DSP-1761) ( #472 ) ( 2f314a2 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_20","text":"deps: bump jdnconvertiblecalendar to v0.0.7 (DSP-1770) ( #479 ) ( b2ec64a )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#4111-2021-06-23","text":"","title":"4.11.1 (2021-06-23)"},{"location":"DSP-APP/contribution/release-notes/#documentation_2","text":"search: add advanced search user guide (DSP-1662) ( #470 ) ( 30edc96 ) user-guide: fix navigation links ( #468 ) ( 49c68f8 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance_21","text":"fix dead links to the documentation ( #471 ) ( d7ae022 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#4110-2021-06-22","text":"","title":"4.11.0 (2021-06-22)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_20","text":"ontology: check if an ontology, a class or a property can be deleted (DSP-1750) ( #457 ) ( fb0c275 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_22","text":"empty landing page instead login (DSP-1756) ( #466 ) ( 32cd462 ) gh-ci: update docs deployment (DSP-1741) ( #463 ) ( 6415152 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#documentation_3","text":"refactor documentation and set correct links ( #467 ) ( cbeb274 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#4101-2021-06-15","text":"","title":"4.10.1 (2021-06-15)"},{"location":"DSP-APP/contribution/release-notes/#documentation_4","text":"fix dead links and replace screenshots in project ( #460 ) ( a13b8ba ) prepare documentation for docs.dasch.swiss (DSP-1721) ( #458 ) ( 09259f1 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance_23","text":"analytics: add fathom ( #462 ) ( f1e0244 ) cookie-policy: reactivate the cookie policy banner (DSP-1727) ( #461 ) ( ac99fbc )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#4100-2021-06-07","text":"","title":"4.10.0 (2021-06-07)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_21","text":"ontology: new cardinality workflow (DSP-1652) ( #455 ) ( f1d049c )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#491-2021-05-26","text":"","title":"4.9.1 (2021-05-26)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_24","text":"resource: improve list of properties in resource viewer ( #453 ) ( 49d9b7f )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#490-2021-05-26","text":"","title":"4.9.0 (2021-05-26)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_21","text":"disable progress bar if search results are empty (DSP-1575) ( #442 ) ( 8c67d60 ) resource: add if condition (DSP-1655) ( #448 ) ( 656da04 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#documentation_5","text":"update documentation about contribution (DSP-1657) ( #449 ) ( c25280d )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#enhancements_22","text":"resource: display region annotations in still images (DSP-1585) ( #445 ) ( 86e75b9 ) search: specify linked resource in advanced search (DSP-1661) ( #451 ) ( 3f0d6d9 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_25","text":"deps: update packages to resolve security issues ( #450 ) ( 8e927f7 ) project: resolve regex term (DSP-1654) ( #444 ) ( 739beba )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#480-2021-05-21","text":"","title":"4.8.0 (2021-05-21)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_26","text":"CD/CI: automatically detect common vulnerabilities and coding errors ( #438 ) ( af02332 ) compiler: enable strict template (DSP-1403) ( #432 ) ( 583a338 ) environment: add test-server config (DSP-1650) ( #443 ) ( a56a45b ) Replace favicon and term Knora by DSP (DSP-1181 / DSP-1342) ( #441 ) ( 3b038b6 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_23","text":"ontology: new method to change gui order (DSP-1567/DSP-1646) ( #440 ) ( dfd0ce0 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#470-2021-05-07","text":"","title":"4.7.0 (2021-05-07)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_27","text":"search results: disable grid view (DSP-1597) ( #435 ) ( c4726fe )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_24","text":"DMP: own resource viewer (DSP-1586) ( #434 ) ( 35bd7b3 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#460-2021-04-27","text":"","title":"4.6.0 (2021-04-27)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_25","text":"DMP: bring back the workspace ( #431 ) ( e8b1c8e )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#452-2021-04-22","text":"","title":"4.5.2 (2021-04-22)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_22","text":"list: list no longer displays after deletion if it was the only list among lists ( #429 ) ( b05484e ) project: bug fix in project member management (DSP-1563) ( #425 ) ( ac820dd )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_28","text":"ontology: disable ontology graph view (DSP-1560) ( #427 ) ( 0a567d2 ) ontology: disable rti image class (DSP-1559) ( #430 ) ( 48c3c76 ) ontology: rename boolean prop type (DSP-1561) ( #426 ) ( 4dd23d3 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#451-2021-04-20","text":"","title":"4.5.1 (2021-04-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_23","text":"ontology: bug fix in create ontology process (DSP-1558) ( #423 ) ( bbd825b )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#450-2021-04-20","text":"","title":"4.5.0 (2021-04-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_24","text":"users: update session the correct way (DSP-690) ( #419 ) ( 3ec049e )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_26","text":"project: better error handler in case a project does not exist (DSP-1401) ( #421 ) ( d7470a0 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#443-2021-04-14","text":"","title":"4.4.3 (2021-04-14)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_25","text":"ontology: Bug fix in ontology form ( #417 ) ( 96dc804 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#442-2021-04-12","text":"","title":"4.4.2 (2021-04-12)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_29","text":"migrate to angular11: changes (DSP-1471) ( #415 ) ( 3271ece )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#441-2021-04-08","text":"","title":"4.4.1 (2021-04-08)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_30","text":"migrate to angular10: changes (DSP-1415) ( #412 ) ( cec564d )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#440-2021-03-23","text":"","title":"4.4.0 (2021-03-23)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_26","text":"deps: package dependency build errors (DSP-1400) ( #410 ) ( 17e0e1a )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_31","text":"list-editor: new list form refactor (DSP-1392) ( #403 ) ( 8824682 ) ontology: improve ontology editor design (DSP-1376) ( #401 ) ( 6de83b8 ) project landing page: update metadata typings (DSP-1393) ( #407 ) ( b4f101b ) project metadata page: enable error handler ( #411 ) ( a4004ed )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_27","text":"eslint: migrate tslint to eslint (DSP-1372) ( #394 ) ( 6ffc3b6 ) ontology: edit data model info (DSP-1208) ( #385 ) ( 86a5fb8 ) ontology: form to create and edit property (DSP-1210) ( #406 ) ( 91ebb68 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#431-2021-03-03","text":"","title":"4.3.1 (2021-03-03)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_27","text":"project: disable error handler in metadata request (DSP-1395) ( #404 ) ( 86ebfcf )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#430-2021-03-02","text":"","title":"4.3.0 (2021-03-02)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_28","text":"ontology: set the cache earlier in case of only one ontology (DSP-1374) ( #397 ) ( c23ae61 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_28","text":"list-editor: insert a child node at a specific position (DSP-1301) ( #395 ) ( 5107200 ) ontology: separate list of ontology properties (DSP-1364) ( #391 ) ( 0f94df6 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_32","text":"deps: bump three from 0.118.3 to 0.125.0 ( #402 ) ( 5ab9c49 ) gh-ci: update release please configuration (DSP-1381) ( #399 ) ( 040df19 ) project landing page: use metadata endpoint to get data from backend (DSP-1199) ( #400 ) ( 5dde42f ) tests: script to find ignored tests ( #396 ) ( 9ca249d )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#421-2021-02-24","text":"","title":"4.2.1 (2021-02-24)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_29","text":"ontology: bug fix in list property (DSP-1368) ( #390 ) ( 2fb448e )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#420-2021-02-22","text":"","title":"4.2.0 (2021-02-22)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_29","text":"list-editor: add deletion functionality (DSP-1334) ( #378 ) ( 34c74a6 ) list-editor: delete list root node (DSP-1356) ( #386 ) ( 5d5eabf ) list-editor: reposition a child node amongst its siblings (DSP-1340) ( #388 ) ( 0a9be0e ) ontology: default language for property label ( #382 ) ( 97230d1 ) ontology: edit res class info (DSP-1209) ( #380 ) ( 2debd03 ) ontology: refactor list of properties in resource class (DSP-1360) ( #389 ) ( aa565b3 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#410-2021-02-12","text":"","title":"4.1.0 (2021-02-12)"},{"location":"DSP-APP/contribution/release-notes/#documentation_6","text":"init mkdocs and move documentation from DSP-DOCS into DSP-APP repo (DSP-380) ( #379 ) ( 07f5067 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance_33","text":"bumps DSP-JS to 1.3.0 and DSP-UI to 1.2.1 ( #374 ) ( 7b795ee ) deps: bump socket.io from 2.3.0 to 2.4.1 ( #367 ) ( 8133d87 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_30","text":"list editor: Adds support for editing lists (DSP-741) ( #365 ) ( 5b6ee4b ) ontology: update cardinality in resource class (DSP-1266) ( #377 ) ( 5a766c1 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#400-2021-01-28","text":"","title":"4.0.0 (2021-01-28)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_5","text":"set up the login page as a starting page (DSP-1292) (#370) app+main: comment out the search and everything related to resources (DSP-1291) (#371)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_30","text":"dialog: Diaolog box height issue fixed ( #358 ) ( 15d1182 ) routing: bring back the route handler in main component (DSP-1303) ( #373 ) ( 8492c1a )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_34","text":"update pr template (DSP-1189) ( #353 ) ( f348e70 ) update the dsp-ui and dsp-js versions to the latest ( #364 ) ( 66931f0 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_31","text":"display metadata on project landing page (DSP-1065) ( #348 ) ( 3012ef5 ) error: Server error handler (DSP-710) ( #355 ) ( d5b77bf ) new-resource-form: make visible the required prop fields (DSP-1115) ( #342 ) ( 5885b04 ) project landing page: add copy to clipboard functionality (DSP-1248) ( #368 ) ( 17bf71c ) select-resource-class: allow accented character (DSP-1241) ( #363 ) ( 8a2654b )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#refactor","text":"app+main: comment out the search and everything related to resources (DSP-1291) ( #371 ) ( 50b1309 ) set up the login page as a starting page (DSP-1292) ( #370 ) ( 46dfdbb )","title":"refactor"},{"location":"DSP-APP/contribution/release-notes/#300-2020-12-18","text":"","title":"3.0.0 (2020-12-18)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_6","text":"Prepare next big release (#350)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_31","text":"header: Replace search-panel with fulltext-search ( #313 ) ( d234fa7 ) node_modules: Update dependencies ( #318 ) ( f85e4a2 ) project: Bug fix in project view when not logged-in ( #339 ) ( ce5acf1 ) workspace: Fix broken link ( #306 ) ( 52b324d ) Open external link in new tab ( #297 ) ( 99f188e ) Replaced reset buttons with cancel button ( #284 ) ( 1481018 ) Update docker environment ( #294 ) ( db6d277 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#documentation_7","text":"Update README ( #292 ) ( fa72ee1 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#enhancements_32","text":"Prepare next big release ( #350 ) ( 6a39180 ) header: display form link when the session is active ( #332 ) ( d609bd5 ) header+dialog: create button in the header + dialog box ( #320 ) ( 5e4890d ) PR: Add template for PRs ( #305 ) ( 1468ee1 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_35","text":"ci: Update package-name in gh actions workflow ( #352 ) ( 3d9bb13 ) Update js- and ui-lib version ( #293 ) ( 5409d9b )","title":"Maintenance"},{"location":"DSP-APP/user-guide/","text":"User Guide This is the documentation for the generic DSP Web Application of the Data and Service Center for the Humanities DaSCH. You can reach the app on admin.dasch.swiss . Getting started DSP-APP is an intuitive, easy to use web-based application placed on top of DSP-API to directly use its powerful data management functionalities. With this modern web application, the researchers can create their data models, search, browse, and work with their qualitative data as easily as they could with a desktop data management tool. In addition, data models and data will automatically follow accepted standards, be interoperable, findable, and re-usable. Researchers and scholars with small to medium data sets (e.g. PhD research, pilot project, or proof of concept) have access to long-term accessibility to keep their research data alive, guaranteeing longevity of the data. Login To login, click on the LOGIN button of the header (right side), a login form will appear. Fill in the form with your credentials (user name or email and password). In case of a forgotten password, please contact the DaSCH Team . Registration You can use the DSP-APP with restricted access as guest. Otherwise, you'll need a login. At the moment, you have to contact the DaSCH Team to get your login credentials. In the future (end of 2020), we will support the SWITCH edu-ID . Help For any questions or help wanted, you can go to the help page, accessible from the Help button at the top right of the page (see login screen shot ). Here, you can find links to the user guide, get more information about the DaSCH softwares, and get more support through different platform according to your requests.","title":"Introduction"},{"location":"DSP-APP/user-guide/#user-guide","text":"This is the documentation for the generic DSP Web Application of the Data and Service Center for the Humanities DaSCH. You can reach the app on admin.dasch.swiss .","title":"User Guide"},{"location":"DSP-APP/user-guide/#getting-started","text":"DSP-APP is an intuitive, easy to use web-based application placed on top of DSP-API to directly use its powerful data management functionalities. With this modern web application, the researchers can create their data models, search, browse, and work with their qualitative data as easily as they could with a desktop data management tool. In addition, data models and data will automatically follow accepted standards, be interoperable, findable, and re-usable. Researchers and scholars with small to medium data sets (e.g. PhD research, pilot project, or proof of concept) have access to long-term accessibility to keep their research data alive, guaranteeing longevity of the data.","title":"Getting started"},{"location":"DSP-APP/user-guide/#login","text":"To login, click on the LOGIN button of the header (right side), a login form will appear. Fill in the form with your credentials (user name or email and password). In case of a forgotten password, please contact the DaSCH Team .","title":"Login"},{"location":"DSP-APP/user-guide/#registration","text":"You can use the DSP-APP with restricted access as guest. Otherwise, you'll need a login. At the moment, you have to contact the DaSCH Team to get your login credentials. In the future (end of 2020), we will support the SWITCH edu-ID .","title":"Registration"},{"location":"DSP-APP/user-guide/#help","text":"For any questions or help wanted, you can go to the help page, accessible from the Help button at the top right of the page (see login screen shot ). Here, you can find links to the user guide, get more information about the DaSCH softwares, and get more support through different platform according to your requests.","title":"Help"},{"location":"DSP-APP/user-guide/data/","text":"Data management Once your data model is ready, you're able to add data. The DSP-APP offers several possibilities to add data, whether you are starting from scratch or importing data from another program. Start from scratch \u26a0 NOT YET IMPLEMENTED (only mockups are presented) When a project starts from scratch, you will enter and generate new data directly in the DSP-APP itself. Generating new data can be done one by one with a form or with a table-based (Excel like) tool. Upload the files, e.g., the actual audio file of an interview or images of the photographs discussed in the interview Augment the metadata In case of interview transcriptions from audio or video files, DSP-APP will offer a simple transcription tool Create new source; e.g. upload audio file of an interview. Organize data and create additional sources \u26a0 NOT YET IMPLEMENTED The workspace of the DSP-APP includes tools to connect different sources, even if they're not in the same project (linkage), to comment on a source and on their metadata fields (annotate), and to transcribe audio-visual material. These actions will generate more data and will help to find specific sources and their relations easily. It's possible to collect different sources and to store them in an individual collection. You can define more than one collection. You can share collections and invite other users to collaborate. Search and browse DSP-APP offers the possibility to the user to search in 3 different ways: full text search, advanced search and expert search (Gravsearch query). The search bar is always available in the header of each page, whether logged in or out. Full text search Full text search performs queries including one or more terms or phrases, and returns data that matches search conditions. By default, the search is performed in all projects stored in DSP. However, it is possible to filter by project using the menu \"Filter by project\" on the left side of the search bar. https://admin.dasch.swiss - Search 1: Full text search When clicking on the search bar, the search history panel is displayed. The 10 last searches are registered. It is also possible to clear the search history list ( Clear list button at the bottom of the panel). Search history list is accessible for the full text search from any webpage. Special syntax: asterisk* can be used as a wildcard symbol \"quotation marks\" searches for the whole pattern Advanced search The advanced search allows for the creation of complex queries using a graphical widget. The widget's contents are then turned into a string representing a Gravsearch (SPARQL) query to be sent to DSP-API. A query consists of the following elements: - data model selection - selection of a resource class belonging to the selected data model (optional) - specification of properties, comparison operators, and values (optional). Although selection of a resource or a property or both are optional, either a resource class has to be selected or at least one property has to be specified, otherwise the query is not considered valid and cannot be submitted. https://admin.dasch.swiss/search/advanced - Search 2: Advanced search offers many filter combinations and is a powerful search tool. Comparison Operators Depending on the value type of the chosen property, one or more of the following comparison operators can be selected: is equal to : value equality: same number, exact same string, overlap of date periods, same target resource. is not equal to : value inequality: not same number, not exact same string, no overlap of date periods, not same target resource. is greater than : value comparison: number is greater than search value, date period begins after search value. is greater than or equal to value equality / value comparison: number is equal to or greater than search value, overlap of date periods or date period begins after search value. is less than : value comparison: number is less than search value, date period ends before search value. is less than or equal to : value equality / value comparison: number is equal to or less than search value, overlap of date periods or date period ends before search value. exists : value for the given property exists. is like : search value is contained in a text using the SPARQL REGEX function (supports regular expressions). matches : text property: search value matches the text ( Lucene Query Parser Syntax ). linking property: matches the specified linked resource. Search Examples Regular Expressions (is like) The is like operator lets the user search for texts that are like the search value via the support of regular expressions In this example, all books are found whose title contains \"Narrenschiff\" followed by a space and some other characters like \"(lat.)\" or \"(dt.)\". For general information about regular expressions see this interactive tutorial . Lucene Parser Syntax (matches) Used with a text property, the matches operator lets the user search for texts that match the search value, supporting Lucene Query Parser Syntax . In this example, all persons are found whose names contain \"Ja\" and \"ob\" with a character in between (represented by the wildcard \"?\"). This search finds \"Jacob\" as well as \"Jakob\". Note the difference between regular expressions and Lucene parser syntax! Specifying a Linked Resource (matches) Used with a linking property, the matches operator lets the user search for a linked resource that matches the specified properties. In this example, the user writes a query looking for all letters that have an author that: 1. was born after January 1st 1650 2. whose family name is \"Bernoulli\" This is different from the \"is equal to\" operator that lets the user specify a certain person (selected from a list). Expert search The expert search can be more powerful than the advanced search, but requires knowing how to use the query language Gravsearch (based on SparQL and developed by the DaSCH team). With Gravsearch, expert users can build searches by combining text-related criteria with any other criteria. For example : you could search for a page in a manuscript that contains a certain element and also mentions a person, who lived in the same country as another person, who is the author of another author. https://admin.dasch.swiss/search/expert - Search 3: Expert search is a text area in which you can create Gravsearch queries. Here is the default example you can find in the app. To learn Gravsearch, go to the DSP-API documentation \u2192 Gravsearch Search results Simple list The results of the search are displayed in an organised list with a small preview. You can select one result at a time to get more information. Search result 1: Simple list of results, similar to Google's list of results. \u26a0 NOT YET IMPLEMENTED It is not possible yet to sort or order by criteria when searching with the full text search, use the advanced search or the expert search instead to get back sorted results. Grid list: Lighttable \u26a0 NOT YET IMPLEMENTED The results of the search are displayed in a grid list with a big preview. You can select one result at a time to get more information. Search result 2: A preview list where the results are presented in tiles. Table: Excel-like view \u26a0 NOT YET IMPLEMENTED The search results are displayed in a table with the option to sort them. This layout is enabled when the search has been performed with only one source type . Each column of the table corresponds to one metadata. Search result 3: An Excel-like table view to edit multiple sources at once. Do research and work on your data Once you have found the desired sources, you can (re)view them and annotate the source itself, the media file, or single metadata values. If you select more than one source, you can compare them in a side-by-side view, link them, edit them all at once, or save them in a collection. A collection is similar to a playlist in a music app or shopping basket in an online store. Display a source \u26a0 WORK IN PROGRESS The DSP-APP offers different source views for different media types. There's a viewer for still images, moving images, audio and document files. You can open them from the list of search results. Depending on the media type, DSP-APP offers different tools to work on the source. In a still image source, you're able to draw regions on the image and to annotate or transcribe this region. Usually, a still image source is used for book pages, photographs, postcards, letters etc. In time-based sources like moving image or audio document, you can mark sequences on the timeline. A transcription tool helps to annotate and to transcribe the sequence. Single source view. The source type in this example is \"Page\". DSP-APP will offer a graph view to visualize the connection of a selected source. The graph view is a powerful tool because you will find more information about the source by clicking through the nodes. Graph view of a single source. Additionally, you can work on the source directly, e.g, transcribe a moving image or a taped interview or mark regions of interest on still images and on documents. Single source fullframe view with the transcription tool at the bottom. The source type in this example is \"Video\" with a table-based sequence protocol on the right hand-side. Select more than one source \u26a0 NOT YET IMPLEMENTED Three sources are selected; what do you want to do with them? By selecting more than one source, you will be able to edit them all at once, add them to a collection, share or connect them. Or you could compare the sources (see Compare the sources ). Compare the sources \u26a0 NOT YET IMPLEMENTED You will be able to compare from two to six source objects at the same time side by side. Compare 2 to 6 sources with each other, similar to the Mirador web app. Annotate and connect your data (sources and/or metadata) \u26a0 NOT YET IMPLEMENTED A main feature of the flexible data storage that DSP-APP uses is the possibility to annotate and link sources and their metadata. An annotation can be a small note about a date like \"Not sure about the birthdate of this person. There's another date mentioned in the source XYZ\". Inside the note, it will be possible to link to another source. Links in DSP-APP are always bi-directional. If you link source A with source B, then source B knows about this connection. If you find source B, you have the connection to source A as well. Export, save or share the data \u26a0 NOT YET IMPLEMENTED Data sets and metadata extracted through a search can be exported as CSV, XML, or other predefined file formats. It will be also possible to store full text, advanced, and expert search queries to reuse them later, collect source objects in a collection similar to a playlist of a music app or a shopping basket. The share menu offers many tools to export the data, to send it to someone or to store it in an individual source collection.","title":"Data Management"},{"location":"DSP-APP/user-guide/data/#data-management","text":"Once your data model is ready, you're able to add data. The DSP-APP offers several possibilities to add data, whether you are starting from scratch or importing data from another program.","title":"Data management"},{"location":"DSP-APP/user-guide/data/#start-from-scratch","text":"\u26a0 NOT YET IMPLEMENTED (only mockups are presented) When a project starts from scratch, you will enter and generate new data directly in the DSP-APP itself. Generating new data can be done one by one with a form or with a table-based (Excel like) tool. Upload the files, e.g., the actual audio file of an interview or images of the photographs discussed in the interview Augment the metadata In case of interview transcriptions from audio or video files, DSP-APP will offer a simple transcription tool Create new source; e.g. upload audio file of an interview.","title":"Start from scratch"},{"location":"DSP-APP/user-guide/data/#organize-data-and-create-additional-sources","text":"\u26a0 NOT YET IMPLEMENTED The workspace of the DSP-APP includes tools to connect different sources, even if they're not in the same project (linkage), to comment on a source and on their metadata fields (annotate), and to transcribe audio-visual material. These actions will generate more data and will help to find specific sources and their relations easily. It's possible to collect different sources and to store them in an individual collection. You can define more than one collection. You can share collections and invite other users to collaborate.","title":"Organize data and create additional sources"},{"location":"DSP-APP/user-guide/data/#search-and-browse","text":"DSP-APP offers the possibility to the user to search in 3 different ways: full text search, advanced search and expert search (Gravsearch query). The search bar is always available in the header of each page, whether logged in or out.","title":"Search and browse"},{"location":"DSP-APP/user-guide/data/#full-text-search","text":"Full text search performs queries including one or more terms or phrases, and returns data that matches search conditions. By default, the search is performed in all projects stored in DSP. However, it is possible to filter by project using the menu \"Filter by project\" on the left side of the search bar. https://admin.dasch.swiss - Search 1: Full text search When clicking on the search bar, the search history panel is displayed. The 10 last searches are registered. It is also possible to clear the search history list ( Clear list button at the bottom of the panel). Search history list is accessible for the full text search from any webpage. Special syntax: asterisk* can be used as a wildcard symbol \"quotation marks\" searches for the whole pattern","title":"Full text search"},{"location":"DSP-APP/user-guide/data/#advanced-search","text":"The advanced search allows for the creation of complex queries using a graphical widget. The widget's contents are then turned into a string representing a Gravsearch (SPARQL) query to be sent to DSP-API. A query consists of the following elements: - data model selection - selection of a resource class belonging to the selected data model (optional) - specification of properties, comparison operators, and values (optional). Although selection of a resource or a property or both are optional, either a resource class has to be selected or at least one property has to be specified, otherwise the query is not considered valid and cannot be submitted. https://admin.dasch.swiss/search/advanced - Search 2: Advanced search offers many filter combinations and is a powerful search tool.","title":"Advanced search"},{"location":"DSP-APP/user-guide/data/#comparison-operators","text":"Depending on the value type of the chosen property, one or more of the following comparison operators can be selected: is equal to : value equality: same number, exact same string, overlap of date periods, same target resource. is not equal to : value inequality: not same number, not exact same string, no overlap of date periods, not same target resource. is greater than : value comparison: number is greater than search value, date period begins after search value. is greater than or equal to value equality / value comparison: number is equal to or greater than search value, overlap of date periods or date period begins after search value. is less than : value comparison: number is less than search value, date period ends before search value. is less than or equal to : value equality / value comparison: number is equal to or less than search value, overlap of date periods or date period ends before search value. exists : value for the given property exists. is like : search value is contained in a text using the SPARQL REGEX function (supports regular expressions). matches : text property: search value matches the text ( Lucene Query Parser Syntax ). linking property: matches the specified linked resource.","title":"Comparison Operators"},{"location":"DSP-APP/user-guide/data/#search-examples","text":"","title":"Search Examples"},{"location":"DSP-APP/user-guide/data/#regular-expressions-is-like","text":"The is like operator lets the user search for texts that are like the search value via the support of regular expressions In this example, all books are found whose title contains \"Narrenschiff\" followed by a space and some other characters like \"(lat.)\" or \"(dt.)\". For general information about regular expressions see this interactive tutorial .","title":"Regular Expressions (is like)"},{"location":"DSP-APP/user-guide/data/#lucene-parser-syntax-matches","text":"Used with a text property, the matches operator lets the user search for texts that match the search value, supporting Lucene Query Parser Syntax . In this example, all persons are found whose names contain \"Ja\" and \"ob\" with a character in between (represented by the wildcard \"?\"). This search finds \"Jacob\" as well as \"Jakob\". Note the difference between regular expressions and Lucene parser syntax!","title":"Lucene Parser Syntax (matches)"},{"location":"DSP-APP/user-guide/data/#specifying-a-linked-resource-matches","text":"Used with a linking property, the matches operator lets the user search for a linked resource that matches the specified properties. In this example, the user writes a query looking for all letters that have an author that: 1. was born after January 1st 1650 2. whose family name is \"Bernoulli\" This is different from the \"is equal to\" operator that lets the user specify a certain person (selected from a list).","title":"Specifying a Linked Resource (matches)"},{"location":"DSP-APP/user-guide/data/#expert-search","text":"The expert search can be more powerful than the advanced search, but requires knowing how to use the query language Gravsearch (based on SparQL and developed by the DaSCH team). With Gravsearch, expert users can build searches by combining text-related criteria with any other criteria. For example : you could search for a page in a manuscript that contains a certain element and also mentions a person, who lived in the same country as another person, who is the author of another author. https://admin.dasch.swiss/search/expert - Search 3: Expert search is a text area in which you can create Gravsearch queries. Here is the default example you can find in the app. To learn Gravsearch, go to the DSP-API documentation \u2192 Gravsearch","title":"Expert search"},{"location":"DSP-APP/user-guide/data/#search-results","text":"","title":"Search results"},{"location":"DSP-APP/user-guide/data/#simple-list","text":"The results of the search are displayed in an organised list with a small preview. You can select one result at a time to get more information. Search result 1: Simple list of results, similar to Google's list of results. \u26a0 NOT YET IMPLEMENTED It is not possible yet to sort or order by criteria when searching with the full text search, use the advanced search or the expert search instead to get back sorted results.","title":"Simple list"},{"location":"DSP-APP/user-guide/data/#grid-list-lighttable","text":"\u26a0 NOT YET IMPLEMENTED The results of the search are displayed in a grid list with a big preview. You can select one result at a time to get more information. Search result 2: A preview list where the results are presented in tiles.","title":"Grid list: Lighttable"},{"location":"DSP-APP/user-guide/data/#table-excel-like-view","text":"\u26a0 NOT YET IMPLEMENTED The search results are displayed in a table with the option to sort them. This layout is enabled when the search has been performed with only one source type . Each column of the table corresponds to one metadata. Search result 3: An Excel-like table view to edit multiple sources at once.","title":"Table: Excel-like view"},{"location":"DSP-APP/user-guide/data/#do-research-and-work-on-your-data","text":"Once you have found the desired sources, you can (re)view them and annotate the source itself, the media file, or single metadata values. If you select more than one source, you can compare them in a side-by-side view, link them, edit them all at once, or save them in a collection. A collection is similar to a playlist in a music app or shopping basket in an online store.","title":"Do research and work on your data"},{"location":"DSP-APP/user-guide/data/#display-a-source","text":"\u26a0 WORK IN PROGRESS The DSP-APP offers different source views for different media types. There's a viewer for still images, moving images, audio and document files. You can open them from the list of search results. Depending on the media type, DSP-APP offers different tools to work on the source. In a still image source, you're able to draw regions on the image and to annotate or transcribe this region. Usually, a still image source is used for book pages, photographs, postcards, letters etc. In time-based sources like moving image or audio document, you can mark sequences on the timeline. A transcription tool helps to annotate and to transcribe the sequence. Single source view. The source type in this example is \"Page\". DSP-APP will offer a graph view to visualize the connection of a selected source. The graph view is a powerful tool because you will find more information about the source by clicking through the nodes. Graph view of a single source. Additionally, you can work on the source directly, e.g, transcribe a moving image or a taped interview or mark regions of interest on still images and on documents. Single source fullframe view with the transcription tool at the bottom. The source type in this example is \"Video\" with a table-based sequence protocol on the right hand-side.","title":"Display a source"},{"location":"DSP-APP/user-guide/data/#select-more-than-one-source","text":"\u26a0 NOT YET IMPLEMENTED Three sources are selected; what do you want to do with them? By selecting more than one source, you will be able to edit them all at once, add them to a collection, share or connect them. Or you could compare the sources (see Compare the sources ).","title":"Select more than one source"},{"location":"DSP-APP/user-guide/data/#compare-the-sources","text":"\u26a0 NOT YET IMPLEMENTED You will be able to compare from two to six source objects at the same time side by side. Compare 2 to 6 sources with each other, similar to the Mirador web app.","title":"Compare the sources"},{"location":"DSP-APP/user-guide/data/#annotate-and-connect-your-data-sources-andor-metadata","text":"\u26a0 NOT YET IMPLEMENTED A main feature of the flexible data storage that DSP-APP uses is the possibility to annotate and link sources and their metadata. An annotation can be a small note about a date like \"Not sure about the birthdate of this person. There's another date mentioned in the source XYZ\". Inside the note, it will be possible to link to another source. Links in DSP-APP are always bi-directional. If you link source A with source B, then source B knows about this connection. If you find source B, you have the connection to source A as well.","title":"Annotate and connect your data (sources and/or metadata)"},{"location":"DSP-APP/user-guide/data/#export-save-or-share-the-data","text":"\u26a0 NOT YET IMPLEMENTED Data sets and metadata extracted through a search can be exported as CSV, XML, or other predefined file formats. It will be also possible to store full text, advanced, and expert search queries to reuse them later, collect source objects in a collection similar to a playlist of a music app or a shopping basket. The share menu offers many tools to export the data, to send it to someone or to store it in an individual source collection.","title":"Export, save or share the data"},{"location":"DSP-APP/user-guide/project/","text":"Project Administration Project Once you are logged in , the dashboard displays the list of your project(s). If you are a project administrator or a system administrator, you can edit the project information or archive your project from the project menu. Archived projects are stored in a list on your dashboard and they can be \"reactivated\" at any time. https://admin.dasch.swiss/dashboard - By clicking on the project name, you get access to the full project information. A system administrator can create a new research project. This currently requires essential information such as the project name, a shortcode and a shortname (both provided by DaSCH). A short project description is optional, but highly recommended. Form to create a new project. As project administrator or system administrator, you can define your project, add your team members, create permission groups and - most important - define your data model (ontology) and the lists of your project. https://admin.dasch.swiss/project/0803/info - Project management functionalities; e.g. Incunabula project. Project information page is displayed without restricted content, the other functionalities are reserved for project admin and system admin. Collaboration As a system administrator, you can add users as project members and define their permissions roles: Who is able to edit or to see your project data? Data includes the research sources and their metadata. Permissions can be set for the entire project or for single metadata fields. A user menu with different actions is accessible for each member of the project (link to the right side of the user line). The admin can appoint another user as project admin (or remove this permission), edit user's information, change user's password if forgotten, and remove a user. https://admin.dasch.swiss/project/0803/collaboration - Collaboration page where project admin and system admin can add new user to the team. NOTE: Permissions for project admins to add new users as project member will be implemented soon. Data model The definition of the data model ( ontology ) is the most important step. The data model is indispensable for structuring your data. Our platform provides a tool for an easy creation of one or more project data models. First, you have to know which data and sources you want to work with. The data model can be flexible and customizable. The question which you have to answer before you create your data model is according to which criteria do you organize your data ? In this respect it may be useful to ask yourself: How are your data organized? What are the goals you want to achieve, which research questions do you want to answer? As soon as you have come to a conclusion concerning the structure of your data, you're all set to create your data model. Create your data model Go to Data model and click New data model Go to your project, select the tab Data model (step 1) and click the button New data model (step 2) as shown below: By clicking New data model , a dialog box opens: Create data model Now you have to set a unique name ( please consider the NOTE ) and you can add a comment. Push the button Create to create your data model. NOTE: There are some rules for the unique name: must be at least 3 characters long shouldn't start with a number shouldn't start with the letter v and a number spaces or special characters are not allowed may not contain these reserved terms: knora ontology salsah shared simple standoff the unique name can't be changed afterwards! The label is a combination of the project's shortname and the unique name. You can replace it with any other string. After the creation of your data model, your page should look like this: Create resource CLASSES You can then create a resource class by clicking the button + Create new class : By clicking + Create new class , a small window pops up with six basic types to choose from: Which type you choose depends on the data type which you need to describe. Let's assume you have pdf-documents of books and they have a number of pages. To describe this in an ontology, you create a class as Document by clicking on Document . A dialog box pops up which looks like this: For the label you could write Book , and you should add a preferably meaningful comment in at least one of the predefined languages English (en), German (de), French (fr) or Italian (it). Then click the Submit button: Now you have created your first class Book , as seen below: Add PROPERTIES to a resource class Now you can add properties to your class. Your pdf of a book has a number of pages. Hence, it may be useful to define the number of pages as one of the properties of your class Book . Click on + Add Property in the Book box: Theoretically, you have two options now. If you defined properties before, you may simply add them here (second option in the following image). If you just start adding properties, you have to choose Create new from type . By hovering over Create new from type , a new menu box appears: You can choose from a selection of the following basic types with various subtypes: Text ( Short , Paragraph , Rich Text ) List ( Dropdown ) Boolean ( Yes/No selection; checkbox) Date / Time ( Date , Timestamp , Time sequence ) Number ( Integer , Decimal , Page number ) Link / Relation ( Link to Class , Part of Class , External URL ) Location ( Place ; a geonames-identifier ) Shape ( color ) Since in our example you want to add a property for the number of pages of your book, you choose Number . Now you will see that you can either choose the type Decimal , Integer or Page number for your property. Page numbers have no decimal places, thus you will selecet Integer (or Page number which is a special case (s. next section )) as the type for your property. The following window pops up: In the field Property label add for example Number of pages , in the comment section you should add a meaningful explanation. It might also make sense to toggle Required field? since every PDF Document consists of a number of pages. If you toggle it, the number of pages MUST be given if you add data to the class Book - it would then be a required field, not an optional one and data could only be saved if you add the number of pages. If you want to define a property which can have more than one value, you should tick Multiple values? . For the number of pages of a book this does not make sense, but in the case you want to define a property describing which people are mentioned in your Book , the option multiple values is likely to be needed. Now you should see the new property in the box as seen below: Correct property selection in case of special classes Book class with pages as individual classes If you have single digitized pages of a book in your project, they can be defined as its own individual Still image class type. In this case the \u2014 let's call it Page \u2014 class needs two specific properties to work the correct way. One is the part of -property which can be found in the list of properties in the section \"Link / Relation\". This property points to the main class called Book (which should be defined first and is type of Object without representation ). The second property is for the page number definition and is also necessary. This default property can be found in the list of properties in the section called \"Number\". This is how a book and the page class could look like: Define Lists One of the possible property types to choose from is List . Lists are very useful if you want to use controlled vocabulary to describe something. Typical examples are keywords. In your book example it may be useful to define a property which describes to which category of literature your pdf of a book belongs. Before you can add a property of type List to your data model, you have to define this list. For the definiton of a list you have to change to the Lists tab: Click Create your first list . If there is already a list defined, click New list . A new window pops up where you have to enter a name for your list ( List label ) and a short description, then click Create . As soon as the list is created you can continue with the definition of your data model. You can define the individual list items later. How to do this will be explained below. We first focus on the definition of a list property in the data model. Currently there is only one option for displaying a property of type List , namely Dropdown . It is capable of displaying flat as well as hierarchical lists. A new window opens up and as in the case of other properties you have to add a label, a desciption and to choose whether multiple values are allowed and/or whether this property is a required field. But in addition you have to select the list which contains your controlled vocabulary. How to define items in a list In our example we have created a list named Category . Now it is time to define the list items. We will list some main literature genres as the first hierarchy in our list. Enter the name of the list node and click the + as shown below: By clicking on the small arrow on the left a second hierarchical level becomes accessible where you can add items in the same was as for the main hierarchy. It is possible to add list items at any time. You may rearrange the order of your list items and add a new list item at a specific position in the list. Remove PROPERTIES from a resource class To remove a property, hover over the property which you want to remove. By doing so you see a white x with a black background (remove button) appearing, it is highlighted in yellow in the image below: Be aware, that you can only remove a property if there are no data yet! If you click the remove button, the property is removed and a green box pops up for a short time: Delete a property In order to really delete a property you have to go to the Properties section as shown below. Click on Properties , and afterwards click on the waste basket sign of the property which you intend to delete. Be aware, you can only delete properties which are NOT used in a resource class! Delete a CLASS To delete a resource class, click on the three dots in the box of the class which you want to delete. The following box appears and you then have to click Delete resource class . In the alert window popping up, you click the red button Delete . Afterwards, the resource class is deleted. Delete a data model To delete a whole data model, you have to click the button Delete on the right-hand side in the section Data model configuration . In the alert window appearing, you click the red button Delete . The data model is now deleted. An example In the following example we focus on how we can reflect about our data before building our model and how a data model can relate classes to each other. Preparing a data model You have interviewed 20 people and recorded the interviews. During these interviews you talked about photographs. Among all the data collected during the project, the most important are: o audio-files of the interview o transcribed text of conversations (or transcribe the files within the web application) o photographs o data about the person you interviewed o location where the photograph was taken The following Diagram 1 shows the initial situation: Diagram 1: the initial situation. The second step will be to consider the hierarchy of the data. How your hierarchy looks like depends on which criteria your data were organized and what your purposes are. It might even be possible that you don\u2019t need a hierarchy as shown in Diagram 1. In our case, we know that the transcripts are linked to the audio-interviews, persons are linked to interviews and audio-interviews, photographs are linked to audio-interviews and transcripts plus locations are linked to the photographs. How the practical arrangement finally looks like depends on your purposes and preferences. For example we could choose to arrange the data with regards to their audio source as seen in Diagram 2: Diagram 2: Focus on the audio-interview. However, we can also prefer another visualization which focuses on the transcript (Diagram 3): Diagram 3: Focus on the transcript. We could think of many different hierarchies, lastly it depends on what serves your purposes best. Our next step will be to implement the hierarchy in Diagram 3 in our data model. Creating the data model 1. Create resource classes First, we create the resource classes that constitute the basic containers of our data model as depicted in Diagram 1: 2. Relate resource classes According to our Diagram 3, we determined the transcript to be the centre of the hierarchy. In the transcript, the photographs are mentioned, the interviewed person is linked to the transcript and the audio-interview as the raw source is linked to the transcript too. Thus, we have to add photograph, audio-interview and person as properties to the transcript. In the box of Transcript click on + Add property : In the window that appears we hover over Create new from type , in the appearing box we hover over Link and in the next appearing box we click on Resource class . By clicking on Resource class , the following window pops up: We can now fill in Property label Audio , and in Select resource class we choose from the list Audio-Interview . We should add a comment in at least one language to describe the property. It might also make sense to toggle Required field? since a transcript has to be extracted from the audio-interview: Finally, we click the Add to class button as seen below: We should then see the new property, which is a class added to the Transcript properties: After the definition of the whole hierarchy as seen in Diagram 3, the data model looks like this: The resource class Transcript has the resource classes Audio-Interview , Photograph and Person as linked properties. Furthermore, the resource class Photograph has the class Location as linked property. In such a way we reflect the central position of Transcript in our data model.","title":"Project Administration"},{"location":"DSP-APP/user-guide/project/#project-administration","text":"","title":"Project Administration"},{"location":"DSP-APP/user-guide/project/#project","text":"Once you are logged in , the dashboard displays the list of your project(s). If you are a project administrator or a system administrator, you can edit the project information or archive your project from the project menu. Archived projects are stored in a list on your dashboard and they can be \"reactivated\" at any time. https://admin.dasch.swiss/dashboard - By clicking on the project name, you get access to the full project information. A system administrator can create a new research project. This currently requires essential information such as the project name, a shortcode and a shortname (both provided by DaSCH). A short project description is optional, but highly recommended. Form to create a new project. As project administrator or system administrator, you can define your project, add your team members, create permission groups and - most important - define your data model (ontology) and the lists of your project. https://admin.dasch.swiss/project/0803/info - Project management functionalities; e.g. Incunabula project. Project information page is displayed without restricted content, the other functionalities are reserved for project admin and system admin.","title":"Project"},{"location":"DSP-APP/user-guide/project/#collaboration","text":"As a system administrator, you can add users as project members and define their permissions roles: Who is able to edit or to see your project data? Data includes the research sources and their metadata. Permissions can be set for the entire project or for single metadata fields. A user menu with different actions is accessible for each member of the project (link to the right side of the user line). The admin can appoint another user as project admin (or remove this permission), edit user's information, change user's password if forgotten, and remove a user. https://admin.dasch.swiss/project/0803/collaboration - Collaboration page where project admin and system admin can add new user to the team. NOTE: Permissions for project admins to add new users as project member will be implemented soon.","title":"Collaboration"},{"location":"DSP-APP/user-guide/project/#data-model","text":"The definition of the data model ( ontology ) is the most important step. The data model is indispensable for structuring your data. Our platform provides a tool for an easy creation of one or more project data models. First, you have to know which data and sources you want to work with. The data model can be flexible and customizable. The question which you have to answer before you create your data model is according to which criteria do you organize your data ? In this respect it may be useful to ask yourself: How are your data organized? What are the goals you want to achieve, which research questions do you want to answer? As soon as you have come to a conclusion concerning the structure of your data, you're all set to create your data model.","title":"Data model"},{"location":"DSP-APP/user-guide/project/#create-your-data-model","text":"Go to Data model and click New data model Go to your project, select the tab Data model (step 1) and click the button New data model (step 2) as shown below: By clicking New data model , a dialog box opens: Create data model Now you have to set a unique name ( please consider the NOTE ) and you can add a comment. Push the button Create to create your data model. NOTE: There are some rules for the unique name: must be at least 3 characters long shouldn't start with a number shouldn't start with the letter v and a number spaces or special characters are not allowed may not contain these reserved terms: knora ontology salsah shared simple standoff the unique name can't be changed afterwards! The label is a combination of the project's shortname and the unique name. You can replace it with any other string. After the creation of your data model, your page should look like this:","title":"Create your data model"},{"location":"DSP-APP/user-guide/project/#create-resource-classes","text":"You can then create a resource class by clicking the button + Create new class : By clicking + Create new class , a small window pops up with six basic types to choose from: Which type you choose depends on the data type which you need to describe. Let's assume you have pdf-documents of books and they have a number of pages. To describe this in an ontology, you create a class as Document by clicking on Document . A dialog box pops up which looks like this: For the label you could write Book , and you should add a preferably meaningful comment in at least one of the predefined languages English (en), German (de), French (fr) or Italian (it). Then click the Submit button: Now you have created your first class Book , as seen below:","title":"Create resource CLASSES"},{"location":"DSP-APP/user-guide/project/#add-properties-to-a-resource-class","text":"Now you can add properties to your class. Your pdf of a book has a number of pages. Hence, it may be useful to define the number of pages as one of the properties of your class Book . Click on + Add Property in the Book box: Theoretically, you have two options now. If you defined properties before, you may simply add them here (second option in the following image). If you just start adding properties, you have to choose Create new from type . By hovering over Create new from type , a new menu box appears: You can choose from a selection of the following basic types with various subtypes: Text ( Short , Paragraph , Rich Text ) List ( Dropdown ) Boolean ( Yes/No selection; checkbox) Date / Time ( Date , Timestamp , Time sequence ) Number ( Integer , Decimal , Page number ) Link / Relation ( Link to Class , Part of Class , External URL ) Location ( Place ; a geonames-identifier ) Shape ( color ) Since in our example you want to add a property for the number of pages of your book, you choose Number . Now you will see that you can either choose the type Decimal , Integer or Page number for your property. Page numbers have no decimal places, thus you will selecet Integer (or Page number which is a special case (s. next section )) as the type for your property. The following window pops up: In the field Property label add for example Number of pages , in the comment section you should add a meaningful explanation. It might also make sense to toggle Required field? since every PDF Document consists of a number of pages. If you toggle it, the number of pages MUST be given if you add data to the class Book - it would then be a required field, not an optional one and data could only be saved if you add the number of pages. If you want to define a property which can have more than one value, you should tick Multiple values? . For the number of pages of a book this does not make sense, but in the case you want to define a property describing which people are mentioned in your Book , the option multiple values is likely to be needed. Now you should see the new property in the box as seen below:","title":"Add PROPERTIES to a resource class"},{"location":"DSP-APP/user-guide/project/#correct-property-selection-in-case-of-special-classes","text":"","title":"Correct property selection in case of special classes"},{"location":"DSP-APP/user-guide/project/#book-class-with-pages-as-individual-classes","text":"If you have single digitized pages of a book in your project, they can be defined as its own individual Still image class type. In this case the \u2014 let's call it Page \u2014 class needs two specific properties to work the correct way. One is the part of -property which can be found in the list of properties in the section \"Link / Relation\". This property points to the main class called Book (which should be defined first and is type of Object without representation ). The second property is for the page number definition and is also necessary. This default property can be found in the list of properties in the section called \"Number\". This is how a book and the page class could look like:","title":"Book class with pages as individual classes"},{"location":"DSP-APP/user-guide/project/#define-lists","text":"One of the possible property types to choose from is List . Lists are very useful if you want to use controlled vocabulary to describe something. Typical examples are keywords. In your book example it may be useful to define a property which describes to which category of literature your pdf of a book belongs. Before you can add a property of type List to your data model, you have to define this list. For the definiton of a list you have to change to the Lists tab: Click Create your first list . If there is already a list defined, click New list . A new window pops up where you have to enter a name for your list ( List label ) and a short description, then click Create . As soon as the list is created you can continue with the definition of your data model. You can define the individual list items later. How to do this will be explained below. We first focus on the definition of a list property in the data model. Currently there is only one option for displaying a property of type List , namely Dropdown . It is capable of displaying flat as well as hierarchical lists. A new window opens up and as in the case of other properties you have to add a label, a desciption and to choose whether multiple values are allowed and/or whether this property is a required field. But in addition you have to select the list which contains your controlled vocabulary.","title":"Define Lists"},{"location":"DSP-APP/user-guide/project/#how-to-define-items-in-a-list","text":"In our example we have created a list named Category . Now it is time to define the list items. We will list some main literature genres as the first hierarchy in our list. Enter the name of the list node and click the + as shown below: By clicking on the small arrow on the left a second hierarchical level becomes accessible where you can add items in the same was as for the main hierarchy. It is possible to add list items at any time. You may rearrange the order of your list items and add a new list item at a specific position in the list.","title":"How to define items in a list"},{"location":"DSP-APP/user-guide/project/#remove-properties-from-a-resource-class","text":"To remove a property, hover over the property which you want to remove. By doing so you see a white x with a black background (remove button) appearing, it is highlighted in yellow in the image below: Be aware, that you can only remove a property if there are no data yet! If you click the remove button, the property is removed and a green box pops up for a short time:","title":"Remove PROPERTIES from a resource class"},{"location":"DSP-APP/user-guide/project/#delete-a-property","text":"In order to really delete a property you have to go to the Properties section as shown below. Click on Properties , and afterwards click on the waste basket sign of the property which you intend to delete. Be aware, you can only delete properties which are NOT used in a resource class!","title":"Delete a property"},{"location":"DSP-APP/user-guide/project/#delete-a-class","text":"To delete a resource class, click on the three dots in the box of the class which you want to delete. The following box appears and you then have to click Delete resource class . In the alert window popping up, you click the red button Delete . Afterwards, the resource class is deleted.","title":"Delete a CLASS"},{"location":"DSP-APP/user-guide/project/#delete-a-data-model","text":"To delete a whole data model, you have to click the button Delete on the right-hand side in the section Data model configuration . In the alert window appearing, you click the red button Delete . The data model is now deleted.","title":"Delete a data model"},{"location":"DSP-APP/user-guide/project/#an-example","text":"In the following example we focus on how we can reflect about our data before building our model and how a data model can relate classes to each other.","title":"An example"},{"location":"DSP-APP/user-guide/project/#preparing-a-data-model","text":"You have interviewed 20 people and recorded the interviews. During these interviews you talked about photographs. Among all the data collected during the project, the most important are: o audio-files of the interview o transcribed text of conversations (or transcribe the files within the web application) o photographs o data about the person you interviewed o location where the photograph was taken The following Diagram 1 shows the initial situation: Diagram 1: the initial situation. The second step will be to consider the hierarchy of the data. How your hierarchy looks like depends on which criteria your data were organized and what your purposes are. It might even be possible that you don\u2019t need a hierarchy as shown in Diagram 1. In our case, we know that the transcripts are linked to the audio-interviews, persons are linked to interviews and audio-interviews, photographs are linked to audio-interviews and transcripts plus locations are linked to the photographs. How the practical arrangement finally looks like depends on your purposes and preferences. For example we could choose to arrange the data with regards to their audio source as seen in Diagram 2: Diagram 2: Focus on the audio-interview. However, we can also prefer another visualization which focuses on the transcript (Diagram 3): Diagram 3: Focus on the transcript. We could think of many different hierarchies, lastly it depends on what serves your purposes best. Our next step will be to implement the hierarchy in Diagram 3 in our data model.","title":"Preparing a data model"},{"location":"DSP-APP/user-guide/project/#creating-the-data-model","text":"1. Create resource classes First, we create the resource classes that constitute the basic containers of our data model as depicted in Diagram 1: 2. Relate resource classes According to our Diagram 3, we determined the transcript to be the centre of the hierarchy. In the transcript, the photographs are mentioned, the interviewed person is linked to the transcript and the audio-interview as the raw source is linked to the transcript too. Thus, we have to add photograph, audio-interview and person as properties to the transcript. In the box of Transcript click on + Add property : In the window that appears we hover over Create new from type , in the appearing box we hover over Link and in the next appearing box we click on Resource class . By clicking on Resource class , the following window pops up: We can now fill in Property label Audio , and in Select resource class we choose from the list Audio-Interview . We should add a comment in at least one language to describe the property. It might also make sense to toggle Required field? since a transcript has to be extracted from the audio-interview: Finally, we click the Add to class button as seen below: We should then see the new property, which is a class added to the Transcript properties: After the definition of the whole hierarchy as seen in Diagram 3, the data model looks like this: The resource class Transcript has the resource classes Audio-Interview , Photograph and Person as linked properties. Furthermore, the resource class Photograph has the class Location as linked property. In such a way we reflect the central position of Transcript in our data model.","title":"Creating the data model"},{"location":"DSP-APP/user-guide/publication/","text":"Publication \u26a0 NOT YET IMPLEMENTED","title":"Publication"},{"location":"DSP-APP/user-guide/publication/#publication","text":"\u26a0 NOT YET IMPLEMENTED","title":"Publication"},{"location":"DSP-APP/user-guide/system/","text":"System Administration \u26a0 Only for System administrator System administrators can get an overview of all projects and all users stored in DSP. System administration part is accessible from the user menu in the header. All projects System admin gets the list of all activated projects as well as archived projects. It is possible to create a new research project, the required information must be filled in. For each project, the system admin has the possibility to edit the project information and archive the project. Overview of all activated projects, the list of archived projects is displayed below. All users System admin gets the list of all activated and suspended users registered in DSP. New users can be created from this page only (button \"Create new\"). Overview of all users where the system admin has access to several actions. For each user, the system admin has access to several actions: Add as system admin or Remove as system admin : add or remove the user role of system admin Edit user : edit the user information (e.g. first name, last name, default language) Change user's password : the system admin can update the user's password if the user has forgotten it, the system admin must enter his password first (\u26a0 a reset password functionality will be implemented in a later version on the login page) Manage project membership : the system admin can assign the selected user to one or several project, or remove the user from a specific project Suspend user : the user is deactivated and has no more access to DSP-APP. The system admin can reactivate it at any time.","title":"System Administration"},{"location":"DSP-APP/user-guide/system/#system-administration","text":"\u26a0 Only for System administrator System administrators can get an overview of all projects and all users stored in DSP. System administration part is accessible from the user menu in the header.","title":"System Administration"},{"location":"DSP-APP/user-guide/system/#all-projects","text":"System admin gets the list of all activated projects as well as archived projects. It is possible to create a new research project, the required information must be filled in. For each project, the system admin has the possibility to edit the project information and archive the project. Overview of all activated projects, the list of archived projects is displayed below.","title":"All projects"},{"location":"DSP-APP/user-guide/system/#all-users","text":"System admin gets the list of all activated and suspended users registered in DSP. New users can be created from this page only (button \"Create new\"). Overview of all users where the system admin has access to several actions. For each user, the system admin has access to several actions: Add as system admin or Remove as system admin : add or remove the user role of system admin Edit user : edit the user information (e.g. first name, last name, default language) Change user's password : the system admin can update the user's password if the user has forgotten it, the system admin must enter his password first (\u26a0 a reset password functionality will be implemented in a later version on the login page) Manage project membership : the system admin can assign the selected user to one or several project, or remove the user from a specific project Suspend user : the user is deactivated and has no more access to DSP-APP. The system admin can reactivate it at any time.","title":"All users"},{"location":"DSP-APP/user-guide/user/","text":"User Profile https://admin.dasch.swiss/dashboard - Get access to your user profile, collections and account from the main user menu. Your user profile and projects To change your personal information as well as your default language used by the interface, you can edit your profile clicking Edit . Currently, the avatar image comes from gravatar.com (go on their website to register if you want your customized user photo). https://admin.dasch.swiss/projects - Overview of your user profile and your projects. The list of your projects is accessible, click on one project to get more information about it. As project admin, you can also edit or archive your projects, and as system admin, you can additionally create new project on this page. Edit your user profile. The username, the email address and the admin rules are not editable. Your collections \u26a0 NOT YET IMPLEMENTED You will be able to store collections of sources or specific searches to work with them later or share them with collaborators. Your account As a matter of security, it is strongly recommended to update your password at least once a year. In your account page, you can update your password. https://admin.dasch.swiss/account - Update your password and deactivate your user account. \u26a0 You can delete (deactivate) your own user account. Only a system administrator will be able to reactivate it.","title":"User Profile"},{"location":"DSP-APP/user-guide/user/#user-profile","text":"https://admin.dasch.swiss/dashboard - Get access to your user profile, collections and account from the main user menu.","title":"User Profile"},{"location":"DSP-APP/user-guide/user/#your-user-profile-and-projects","text":"To change your personal information as well as your default language used by the interface, you can edit your profile clicking Edit . Currently, the avatar image comes from gravatar.com (go on their website to register if you want your customized user photo). https://admin.dasch.swiss/projects - Overview of your user profile and your projects. The list of your projects is accessible, click on one project to get more information about it. As project admin, you can also edit or archive your projects, and as system admin, you can additionally create new project on this page. Edit your user profile. The username, the email address and the admin rules are not editable.","title":"Your user profile and projects"},{"location":"DSP-APP/user-guide/user/#your-collections","text":"\u26a0 NOT YET IMPLEMENTED You will be able to store collections of sources or specific searches to work with them later or share them with collaborators.","title":"Your collections"},{"location":"DSP-APP/user-guide/user/#your-account","text":"As a matter of security, it is strongly recommended to update your password at least once a year. In your account page, you can update your password. https://admin.dasch.swiss/account - Update your password and deactivate your user account. \u26a0 You can delete (deactivate) your own user account. Only a system administrator will be able to reactivate it.","title":"Your account"},{"location":"DSP-TOOLS/","text":"DSP-TOOLS documentation dsp-tools is a command line tool that helps you interact with the DaSCH Service Platform server (DSP server). In order to archive your data on the DaSCH Service Platform, you need a data model (ontology) that describes your data. The data model is defined in a JSON file which has to be transmitted to the DSP server. If the DSP server is aware of the data model for your project, conforming data can be uploaded into the DSP repository. Often, data is initially added in large quantities. Therefore, dsp-tools allows you to perform bulk imports of your data. In order to do so, the data has to be described in an XML file. dsp-tools is able to read the XML file and upload all data to the DSP server. dsp-tools helps you with the following tasks: dsp-tools create creates the data model (ontology) on a DSP server from a provided JSON file containing the data model. dsp-tools get reads a data model from a DSP server and writes it into a JSON file. dsp-tools xmlupload uploads data from a provided XML file (bulk data import) and writes the mapping from internal IDs to IRIs into a local file. dsp-tools excel creates a JSON or XML file from one or several Excel files. The created data can either be integrated into an ontology or be uploaded directly to a DSP server with dsp-tools create . dsp-tools excel2resources creates the ontology's resource section from an Excel file. The resulting section can be integrated into an ontology and then be uploaded to a DSP server with dsp-tools create . dsp-tools excel2properties creates the ontology's properties section from an Excel file. The resulting section can be integrated into an ontology and then be uploaded to a DSP server with dsp-tools create . dsp-tools id2iri takes an XML file for bulk data import and replaces referenced internal IDs with IRIs. The mapping has to be provided with a JSON file.","title":"Overview"},{"location":"DSP-TOOLS/#dsp-tools-documentation","text":"dsp-tools is a command line tool that helps you interact with the DaSCH Service Platform server (DSP server). In order to archive your data on the DaSCH Service Platform, you need a data model (ontology) that describes your data. The data model is defined in a JSON file which has to be transmitted to the DSP server. If the DSP server is aware of the data model for your project, conforming data can be uploaded into the DSP repository. Often, data is initially added in large quantities. Therefore, dsp-tools allows you to perform bulk imports of your data. In order to do so, the data has to be described in an XML file. dsp-tools is able to read the XML file and upload all data to the DSP server. dsp-tools helps you with the following tasks: dsp-tools create creates the data model (ontology) on a DSP server from a provided JSON file containing the data model. dsp-tools get reads a data model from a DSP server and writes it into a JSON file. dsp-tools xmlupload uploads data from a provided XML file (bulk data import) and writes the mapping from internal IDs to IRIs into a local file. dsp-tools excel creates a JSON or XML file from one or several Excel files. The created data can either be integrated into an ontology or be uploaded directly to a DSP server with dsp-tools create . dsp-tools excel2resources creates the ontology's resource section from an Excel file. The resulting section can be integrated into an ontology and then be uploaded to a DSP server with dsp-tools create . dsp-tools excel2properties creates the ontology's properties section from an Excel file. The resulting section can be integrated into an ontology and then be uploaded to a DSP server with dsp-tools create . dsp-tools id2iri takes an XML file for bulk data import and replaces referenced internal IDs with IRIs. The mapping has to be provided with a JSON file.","title":"DSP-TOOLS documentation"},{"location":"DSP-TOOLS/changelog/","text":"Changelog 1.11.0 (2022-02-28) Enhancements improve prefix handling in json ontos (DEV-572) ( #164 ) ( 8610885 ) 1.10.1 (2022-02-23) Documentation add explanation how an Excel file for list creation must be structured (DEV-533) ( #159 ) ( 660d57b ) explain the interval-prop more precisely ( #162 ) ( 00c18dc ) 1.10.0 (2022-02-21) Documentation add validate argparse info to xmlupload ( #156 ) ( 08ddebd ) improve docs (DEV-450) ( #152 ) ( be5b69f ) Maintenance excel to json list (DEV-431) ( #155 ) ( 8a8c9d0 ) xml-upload: print XML validation errors when xmlupload fails due to validation (DEV-387) ( #149 ) ( 03554c2 ) Enhancements improve json schema validation error output (DEV-456) ( #153 ) ( 9f92b66 ) make comments optional for new properties and resources (DEV-502) ( #158 ) ( 9c30746 ) ontology: add Representation (DEV-551) ( #160 ) ( cba7be0 ) 1.9.0 (2022-01-27) Documentation add isPartOf and seqnum properties to documentation (DEV-216) ( #145 ) ( 09d42a4 ) dsp-tools-excel: mention the GUI order and other small improvements (DEV-99) ( #148 ) ( 853068d ) Enhancements xmlupload: use custom IRIs created from salsah ARKs for XML upload (DEV-179) ( #147 ) ( 873324a ) 1.8.1 (2022-01-11) Bug Fixes problem with reference to list values (DEV-356) ( #143 ) ( 3fce99a ) Maintenance deps: bump nltk from 3.6.5 to 3.6.6 ( #142 ) ( 4f91098 ) 1.8.0 (2022-01-10) Bug Fixes ontology: add default values for missing comments (DEV-337) ( #141 ) ( 6f0094e ) print only unresolvable resptrs ( #139 ) ( cbe1876 ) restrict the creation of classes without cardinalities (DEV-305) ( #136 ) ( 5604a5b ) Enhancements excel-to-json: allow comments in class and property definitions ( #111 ) ( 807959f ) get: extend get command to get more information (DEV-139) ( #137 ) ( 9ce6722 ) Maintenance improve ontology schema and extend tests (DEV-313) ( #140 ) ( 656ccff ) 1.7.1 (2021-12-14) Bug Fixes groups: make groups optional (DEV-138) ( #135 ) ( 6aa1aa7 ) Maintenance deps: bump lxml from 4.6.4 to 4.6.5 ( #133 ) ( 605dc2f ) 1.7.0 (2021-12-07) Bug Fixes boolean-values: allow 0 and 1 as boolean values (DEV-251) ( #131 ) ( fd58ad4 ) create-ontology: within an ontology, references to the ontology itself are not possible (DEV-135) ( #130 ) ( 6a40fc6 ) permissions: use permissions in xml upload (DEV-178) ( #127 ) ( 4dad0ce ) Documentation update out-of-date example in docs (DEV-265) ( #125 ) ( 0dc724c ) Enhancements update DSP-Tools to support ArchiveRepresentation (DEV-259) ( #128 ) ( 85a40c2 ) 1.6.1 (2021-11-25) Bug Fixes inconsistencies in groups and projects (DEV-261) ( #121 ) ( f9a95ed ) schema: list root node needs a comments object (DEV-61) ( #122 ) ( 7bdc589 ) 1.6.0 (2021-11-22) Bug Fixes comments: fix comments in ontology creation (DEV-250) ( #119 ) ( 08effdf ) update dsp-tools to work with API version 16.0.0 ( #117 ) ( af70e9b ) Documentation add time value section ( #116 ) ( 8ef0329 ) typo: correcting typos in documentation ( #112 ) ( 08c1059 ) Enhancements id-to-iri: extend xmlupload to allow references to existing resources (DEV-60) ( #108 ) ( 40b01db ) 1.5.2 (2021-11-16) Maintenance documentation: add missing documentation for excel2resources (DEV-144) ( cde0db5 ) 1.5.1 (2021-10-13) Bug Fixes schema-documentation: update schemas and documentation (DEV-61) ( #105 ) ( 4d9c1e4 ) 1.5.0 (2021-09-24) Enhancements schema: add error codes for validation (DSP-1902) ( #101 ) ( 0bc6149 ) 1.4.2 (2021-09-21) Bug Fixes docs: fix example in documentation (DSP-1740) ( #99 ) ( 11cdd72 ) 1.4.1 (2021-09-20) Maintenance schemas: update schemas (DSP-1902) ( #92 ) ( 16ba335 ) 1.4.0 (2021-09-16) Documentation typo: correct typo in documentation ( #85 ) ( c689d7f ) Enhancements excel-to-properties: create properties from Excel (DSP-1577) ( #89 ) ( 9f48e9a ) excel-to-resources: create resources from excel (DSP-1576) ( #88 ) ( 7b0302f ) 1.3.3 (2021-09-07) Bug Fixes wrong values & property ( #86 ) ( 7cf6405 ) 1.3.2 (2021-08-17) Bug Fixes import: fix import error when starting script directly ( DSP-1869) ( 05b1eb1 ) 1.3.1 (2021-08-11) Bug Fixes manifest: fix documentation and missing files ( DSP-1580) ( #80 ) ( 3345f2a ) 1.3.0 (2021-08-10) Enhancements excel-lists: create multilanguage json lists from excel files ( DSP-1580) ( #75 ) ( 06d071a ) 1.2.1 (2021-07-27) Bug Fixes release: fix skipped release after pull request #74 ( DSP-1797) ( #76 ) ( c8e0a11 ) 1.2.0 (2021-07-26) Enhancements verbose xml upload: use v option to print verbose output in XML upload ( DSP-1797) ( #70 ) ( b1f56a1 ) 1.1.6 (2021-07-22) Documentation add changelog ( #71 ) ( ce1feab ) 1.1.5 (2021-07-14) Documentation dsp-tools-xmlupload: Add Warning section ( #69 ) ( 05baf3d ) dsp-tools-xmlupload: addition to incomplete paragraph ( DSP-1693) ( #67 ) ( 318547f ) 1.1.4 (2021-06-16) Documentation add copyright information to docs ( DSP-1190) ( #65 ) ( 0174c4a ) 1.1.3 (2021-06-08) Documentation update readme after documentation update ( DSP-1693) ( #63 ) ( 7b7dcca ) 1.1.2 (2021-06-07) Maintenance bump Bazel to version with M1 support ( #60 ) ( 69772f4 ) Documentation improve documentation ( DSP-1693) ( #62 ) ( 591b5ad ) 1.1.1 (2021-04-20) Bug Fixes fix import ontology from salsah-export ( DSP-1532) ( #59 ) ( 6e3e7ca ) Maintenance fix doc deployment ( DSP-1492) ( #57 ) ( a55849e ) 1.1.0 (2021-04-09) Bug Fixes add create_ontology command line configuration ( 3ab7e6b ) add folder independence ( 2460937 ) add missing dependencies ( 4d75128 ) add user ( 277121b ) bulk-import of multiple resource link values ( 6ef8908 ), closes #9 cleanup api logging ( DSP-1076) ( #46 ) ( d48e704 ) command line scripts ( 732a0fa ) Correctly set user password ( 9db6445 ) Correctly set user password ( 3583ea2 ) Do not send logout request if token is not set ( 9cfd484 ) removed exception if keywords missing ( 81f7d97 ) requirements ( b5941f1 ) typo ( 3def59d ) Documentation fix twine upload ( bcc87ca ) update publishing description ( 6deb0da ) Enhancements import lists from excel ( DSP-1341) ( #48 ) ( 3628992 ) Maintenance add existing files into new structure ( 84dc1d2 ) add publishing setup ( c18c6b9 ) add pypi badge ( 3fc148c ) add runing tests on travis ( 2eeaeb8 ) add runing tests on travis ( cf4f9e4 ) add runing tests on travis ( b8f3bbc ) add runing tests on travis ( dc4fa02 ) add runing tests on travis ( 16844d8 ) add runing tests on travis ( 593ac85 ) add testing ( ongoing) ( c175a16 ) allow release PRs in PR title check ( #54 ) ( 0414948 ) automate release process ( DSP-1492) ( #52 ) ( 6a96eee ) bump version ( 49bc9d8 ) bump version ( e7364c7 ) bump version to 1.1.0 ( DSP-1492) ( #55 ) ( 3814ed2 ) configure dependencies and command line ( 7f79530 )","title":"Changelog"},{"location":"DSP-TOOLS/changelog/#changelog","text":"","title":"Changelog"},{"location":"DSP-TOOLS/changelog/#1110-2022-02-28","text":"","title":"1.11.0 (2022-02-28)"},{"location":"DSP-TOOLS/changelog/#enhancements","text":"improve prefix handling in json ontos (DEV-572) ( #164 ) ( 8610885 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#1101-2022-02-23","text":"","title":"1.10.1 (2022-02-23)"},{"location":"DSP-TOOLS/changelog/#documentation","text":"add explanation how an Excel file for list creation must be structured (DEV-533) ( #159 ) ( 660d57b ) explain the interval-prop more precisely ( #162 ) ( 00c18dc )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#1100-2022-02-21","text":"","title":"1.10.0 (2022-02-21)"},{"location":"DSP-TOOLS/changelog/#documentation_1","text":"add validate argparse info to xmlupload ( #156 ) ( 08ddebd ) improve docs (DEV-450) ( #152 ) ( be5b69f )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#maintenance","text":"excel to json list (DEV-431) ( #155 ) ( 8a8c9d0 ) xml-upload: print XML validation errors when xmlupload fails due to validation (DEV-387) ( #149 ) ( 03554c2 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#enhancements_1","text":"improve json schema validation error output (DEV-456) ( #153 ) ( 9f92b66 ) make comments optional for new properties and resources (DEV-502) ( #158 ) ( 9c30746 ) ontology: add Representation (DEV-551) ( #160 ) ( cba7be0 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#190-2022-01-27","text":"","title":"1.9.0 (2022-01-27)"},{"location":"DSP-TOOLS/changelog/#documentation_2","text":"add isPartOf and seqnum properties to documentation (DEV-216) ( #145 ) ( 09d42a4 ) dsp-tools-excel: mention the GUI order and other small improvements (DEV-99) ( #148 ) ( 853068d )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_2","text":"xmlupload: use custom IRIs created from salsah ARKs for XML upload (DEV-179) ( #147 ) ( 873324a )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#181-2022-01-11","text":"","title":"1.8.1 (2022-01-11)"},{"location":"DSP-TOOLS/changelog/#bug-fixes","text":"problem with reference to list values (DEV-356) ( #143 ) ( 3fce99a )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#maintenance_1","text":"deps: bump nltk from 3.6.5 to 3.6.6 ( #142 ) ( 4f91098 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#180-2022-01-10","text":"","title":"1.8.0 (2022-01-10)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_1","text":"ontology: add default values for missing comments (DEV-337) ( #141 ) ( 6f0094e ) print only unresolvable resptrs ( #139 ) ( cbe1876 ) restrict the creation of classes without cardinalities (DEV-305) ( #136 ) ( 5604a5b )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#enhancements_3","text":"excel-to-json: allow comments in class and property definitions ( #111 ) ( 807959f ) get: extend get command to get more information (DEV-139) ( #137 ) ( 9ce6722 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#maintenance_2","text":"improve ontology schema and extend tests (DEV-313) ( #140 ) ( 656ccff )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#171-2021-12-14","text":"","title":"1.7.1 (2021-12-14)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_2","text":"groups: make groups optional (DEV-138) ( #135 ) ( 6aa1aa7 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#maintenance_3","text":"deps: bump lxml from 4.6.4 to 4.6.5 ( #133 ) ( 605dc2f )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#170-2021-12-07","text":"","title":"1.7.0 (2021-12-07)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_3","text":"boolean-values: allow 0 and 1 as boolean values (DEV-251) ( #131 ) ( fd58ad4 ) create-ontology: within an ontology, references to the ontology itself are not possible (DEV-135) ( #130 ) ( 6a40fc6 ) permissions: use permissions in xml upload (DEV-178) ( #127 ) ( 4dad0ce )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_3","text":"update out-of-date example in docs (DEV-265) ( #125 ) ( 0dc724c )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_4","text":"update DSP-Tools to support ArchiveRepresentation (DEV-259) ( #128 ) ( 85a40c2 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#161-2021-11-25","text":"","title":"1.6.1 (2021-11-25)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_4","text":"inconsistencies in groups and projects (DEV-261) ( #121 ) ( f9a95ed ) schema: list root node needs a comments object (DEV-61) ( #122 ) ( 7bdc589 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#160-2021-11-22","text":"","title":"1.6.0 (2021-11-22)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_5","text":"comments: fix comments in ontology creation (DEV-250) ( #119 ) ( 08effdf ) update dsp-tools to work with API version 16.0.0 ( #117 ) ( af70e9b )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_4","text":"add time value section ( #116 ) ( 8ef0329 ) typo: correcting typos in documentation ( #112 ) ( 08c1059 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_5","text":"id-to-iri: extend xmlupload to allow references to existing resources (DEV-60) ( #108 ) ( 40b01db )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#152-2021-11-16","text":"","title":"1.5.2 (2021-11-16)"},{"location":"DSP-TOOLS/changelog/#maintenance_4","text":"documentation: add missing documentation for excel2resources (DEV-144) ( cde0db5 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#151-2021-10-13","text":"","title":"1.5.1 (2021-10-13)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_6","text":"schema-documentation: update schemas and documentation (DEV-61) ( #105 ) ( 4d9c1e4 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#150-2021-09-24","text":"","title":"1.5.0 (2021-09-24)"},{"location":"DSP-TOOLS/changelog/#enhancements_6","text":"schema: add error codes for validation (DSP-1902) ( #101 ) ( 0bc6149 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#142-2021-09-21","text":"","title":"1.4.2 (2021-09-21)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_7","text":"docs: fix example in documentation (DSP-1740) ( #99 ) ( 11cdd72 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#141-2021-09-20","text":"","title":"1.4.1 (2021-09-20)"},{"location":"DSP-TOOLS/changelog/#maintenance_5","text":"schemas: update schemas (DSP-1902) ( #92 ) ( 16ba335 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#140-2021-09-16","text":"","title":"1.4.0 (2021-09-16)"},{"location":"DSP-TOOLS/changelog/#documentation_5","text":"typo: correct typo in documentation ( #85 ) ( c689d7f )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_7","text":"excel-to-properties: create properties from Excel (DSP-1577) ( #89 ) ( 9f48e9a ) excel-to-resources: create resources from excel (DSP-1576) ( #88 ) ( 7b0302f )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#133-2021-09-07","text":"","title":"1.3.3 (2021-09-07)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_8","text":"wrong values & property ( #86 ) ( 7cf6405 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#132-2021-08-17","text":"","title":"1.3.2 (2021-08-17)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_9","text":"import: fix import error when starting script directly ( DSP-1869) ( 05b1eb1 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#131-2021-08-11","text":"","title":"1.3.1 (2021-08-11)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_10","text":"manifest: fix documentation and missing files ( DSP-1580) ( #80 ) ( 3345f2a )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#130-2021-08-10","text":"","title":"1.3.0 (2021-08-10)"},{"location":"DSP-TOOLS/changelog/#enhancements_8","text":"excel-lists: create multilanguage json lists from excel files ( DSP-1580) ( #75 ) ( 06d071a )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#121-2021-07-27","text":"","title":"1.2.1 (2021-07-27)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_11","text":"release: fix skipped release after pull request #74 ( DSP-1797) ( #76 ) ( c8e0a11 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#120-2021-07-26","text":"","title":"1.2.0 (2021-07-26)"},{"location":"DSP-TOOLS/changelog/#enhancements_9","text":"verbose xml upload: use v option to print verbose output in XML upload ( DSP-1797) ( #70 ) ( b1f56a1 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#116-2021-07-22","text":"","title":"1.1.6 (2021-07-22)"},{"location":"DSP-TOOLS/changelog/#documentation_6","text":"add changelog ( #71 ) ( ce1feab )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#115-2021-07-14","text":"","title":"1.1.5 (2021-07-14)"},{"location":"DSP-TOOLS/changelog/#documentation_7","text":"dsp-tools-xmlupload: Add Warning section ( #69 ) ( 05baf3d ) dsp-tools-xmlupload: addition to incomplete paragraph ( DSP-1693) ( #67 ) ( 318547f )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#114-2021-06-16","text":"","title":"1.1.4 (2021-06-16)"},{"location":"DSP-TOOLS/changelog/#documentation_8","text":"add copyright information to docs ( DSP-1190) ( #65 ) ( 0174c4a )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#113-2021-06-08","text":"","title":"1.1.3 (2021-06-08)"},{"location":"DSP-TOOLS/changelog/#documentation_9","text":"update readme after documentation update ( DSP-1693) ( #63 ) ( 7b7dcca )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#112-2021-06-07","text":"","title":"1.1.2 (2021-06-07)"},{"location":"DSP-TOOLS/changelog/#maintenance_6","text":"bump Bazel to version with M1 support ( #60 ) ( 69772f4 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#documentation_10","text":"improve documentation ( DSP-1693) ( #62 ) ( 591b5ad )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#111-2021-04-20","text":"","title":"1.1.1 (2021-04-20)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_12","text":"fix import ontology from salsah-export ( DSP-1532) ( #59 ) ( 6e3e7ca )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#maintenance_7","text":"fix doc deployment ( DSP-1492) ( #57 ) ( a55849e )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#110-2021-04-09","text":"","title":"1.1.0 (2021-04-09)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_13","text":"add create_ontology command line configuration ( 3ab7e6b ) add folder independence ( 2460937 ) add missing dependencies ( 4d75128 ) add user ( 277121b ) bulk-import of multiple resource link values ( 6ef8908 ), closes #9 cleanup api logging ( DSP-1076) ( #46 ) ( d48e704 ) command line scripts ( 732a0fa ) Correctly set user password ( 9db6445 ) Correctly set user password ( 3583ea2 ) Do not send logout request if token is not set ( 9cfd484 ) removed exception if keywords missing ( 81f7d97 ) requirements ( b5941f1 ) typo ( 3def59d )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_11","text":"fix twine upload ( bcc87ca ) update publishing description ( 6deb0da )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_10","text":"import lists from excel ( DSP-1341) ( #48 ) ( 3628992 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#maintenance_8","text":"add existing files into new structure ( 84dc1d2 ) add publishing setup ( c18c6b9 ) add pypi badge ( 3fc148c ) add runing tests on travis ( 2eeaeb8 ) add runing tests on travis ( cf4f9e4 ) add runing tests on travis ( b8f3bbc ) add runing tests on travis ( dc4fa02 ) add runing tests on travis ( 16844d8 ) add runing tests on travis ( 593ac85 ) add testing ( ongoing) ( c175a16 ) allow release PRs in PR title check ( #54 ) ( 0414948 ) automate release process ( DSP-1492) ( #52 ) ( 6a96eee ) bump version ( 49bc9d8 ) bump version ( e7364c7 ) bump version to 1.1.0 ( DSP-1492) ( #55 ) ( 3814ed2 ) configure dependencies and command line ( 7f79530 )","title":"Maintenance"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/","text":"Ontologies An ontology is a formal representation of a set of terminologies which finally represent real world objects. Dependencies, attributes and relations of and between the individual components of the set are recorded in a logical, formal language. In contrast to a taxonomy, which defines a mere hierarchical structure within a range of terms, an ontology is much more a network of information of logical dependencies of term elements. Or, in other words, an ontology defines a strict, formal \"data model\" for real world concepts such as \"Person\", \"Work\", \"Artist\" etc. A full-fledged ontology thus has to offer at least two things: a set of concepts or terms (called resources , actually \"resource classes\") that represent concepts of real world objects, as well as attributes or properties describing these resources. These properties are linked either to a final value or may define a relationship to another resource. Let's assume that we define a resource called \"Person\" and two properties called \"hasBirthday\" and \"hasParent\" . For a specific incarnation of a \"Person\" (we call this an instance ), \"hasBirthday\" will have a final value such as \"1960-05-21\", whereas \"hasParent\" will link to another instance of a \"Person\". Within DSP, properties may be re-used for different resources. E.g. a property \"description\" may be used for a resource called \"image\" as well as \"movie\". Therefore, the list of properties is separated from the list of resources. The properties are assigned to the resources by defining \" cardinalities \". A cardinality indicates if a property is mandatory or can be omitted (e.g. if unknown), and if a property may be used several times on the same instance of a resource or not. The cardinality definitions are explained further below . Example of an ontologies object: { \"ontologies\": [ { \"name\": \"seworon\", \"label\": \"Secrets of the World Ontology\", \"properties\": [ ... ], \"resources\": [ ... ] }, { ... }, { ... } ] } Ontologies Object in Detail The following properties can occur within each object in ontologies . Name (required) \"name\": \"<string>\" The ontology's (short) name should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). Label (required) \"label\": \"<string>\" A string that provides the full name of the ontology. Properties (required) \"properties\": [<property-definition>, <property-definition>, ...] A properties array contains all properties used to describe resources in the ontology. A property has to be of a certain data type. It is not possible to create a custom data type. The following fields are mandatory: name labels object gui_element The following fields are optional: comments super (with the exception of LinkValue where super is mandatory) subject gui_attributes A detailed description of properties can be found below . Resources (required) The resource classes are the primary entities of the data model. They are the actual objects inside a terminology space. A resource class can be seen as a template for the representation of a real object that is represented in the DSP. A resource class defines properties ( data fields ). For each of these properties a data type as well as the cardinality has to be provided. \"resources\": [<resource-definition>, <resource-definition>, ...] A resource object needs to have the following fields: name labels super cardinalities The following field is optional: comments A detailed description of resources can be found below . Properties Object in Detail Please note that object is used to define the data type. The gui_element depends on the value of the object . The gui_attributes depends on the value of the gui_element . Name (required) \"name\": \"<string>\" A name for the property, e.g. \"pageOf\", \"hasBirthdate\", \"createdBy\". It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). By convention, property names start with a lower case letter. Labels (required) \"labels\": {\"<language>\": \"<string>\", ...} Collection of labels for the property as strings with language tag (currently \"en\", \"de\", \"fr\" and \"it\" are supported). Comments (optional) \"comments\": { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } Comments with language tags. Currently, \"de\", \"en\", \"fr\" and \"it\" are supported. The comments element is optional. Super (optional) \"super\": [\"<super-property>\", \"<super-property>, ...] A property has to be derived from at least one base property. The most generic base property that the DSP offers is hasValue . In addition, the property may be a sub-property of properties defined in external or other ontologies. External ontologies like dcterms or foaf must be defined in the \"prefix\" section. In this case the qualified name - including the prefix of the external or internal ontology - has to be given. The following base properties are defined by DSP: hasValue : This is the most generic base and taken as default if super is omitted. hasLinkTo : This value represents a link to another resource. You have to indicate the \" object \" as a prefixed name that identifies the resource class this link points to (a \":\" prepended to the name is sufficient if the resource is defined in the current ontology). hasColor : Defines a color value hasComment : Defines a standard comment hasGeometry : Defines a geometry value (a JSON describing a polygon, circle or rectangle) isPartOf : A special variant of hasLinkTo . It says that an instance of the given resource class is an integral part of another resource class. E.g. a \"page\" is part of a \"book\". isRegionOf : A special variant of hasLinkTo . It means that the given resource class is a \"region\" of another resource class. This is typically used to describe regions of interest in images. isAnnotationOf : A special variant of hasLinkTo . It denotes the given resource class as an annotation to another resource class. seqnum : An integer that is used to define a sequence number in an ordered set of instances, e.g. the ordering of the pages in a book (independent of the page naming) in combination with a property derived from isPartOf . Example of a properties object: { \"properties\": [ { \"name\": \"id\", \"subject\": \":School\", \"object\": \"TextValue\", \"super\": [ \"hasValue\" ], \"labels\": { \"en\": \"School ID\", \"de\": \"ID der Schule\", \"fr\": \"ID de l'\u00e9cole\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 32, \"maxlength\": 128 } }, { \"name\": \"name\", \"subject\": \":School\", \"object\": \"TextValue\", \"super\": [ \"hasValue\" ], \"labels\": { \"en\": \"Name of the school\", \"de\": \"Name der Schule\", \"fr\": \"Nom de l'\u00e9cole\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 32, \"maxlength\": 128 } } ] } Subject (optional) \"subject\": \"<resource-class>\" The subject defines the resource class the property can be used on. It has to be provided as prefixed name of the resource class (see below on how prefixed names are used). Object / gui_element / gui_attributes object : required gui_element : required gui_attributes : optional \"object\": \"<data-type>\" The object defines the data type of the value that the property will store. gui_element and gui_attributes depend on the data type. The following data types are allowed: TextValue ColorValue DateValue TimeValue DecimalValue GeomValue GeonameValue IntValue BooleanValue UriValue IntervalValue ListValue Representation any previously defined resource class in case of a link property TextValue \"object\": \"TextValue\" Represents a text that may contain standoff markup. gui_elements / gui_attributes : SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes are: gui_attributes : maxlength=integer (optional): maximal length (number of characters accepted) size=integer (optional): size (width) of widget Textarea : A GUI element for TextValue . Presents a multiline text entry box. The optional attributes are: gui_attributes : cols=integer (optional): number of columns of the textarea rows=integer (optional): number of rows of the textarea width=percent (optional): width of the textarea on screen wrap=soft|hard (optional): wrapping of text Richtext : A GUI element for TextValue . Provides a richtext editor. gui_attributes : No attributes Example: { \"name\": \"hasPictureTitle\", \"super\": [ \"hasValue\" ], \"object\": \"TextValue\", \"labels\": { \"en\": \"Title\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"maxlength\": 255, \"size\": 80 } } IntValue \"object\": \"IntValue\" Represents an integer value. gui-elements / gui_attributes : SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Spinbox : A GUI element for IntegerValue . A text field with and \"up\"- and \"down\"-button for increment/decrement. The attributes \"max=decimal\" and \"min=decimal\" are optional. gui_attributes : max=decimal (optional): Maximal value min=decimal (optional): Minimal value Example: { \"name\": \"hasInteger\", \"super\": [ \"hasValue\" ], \"object\": \"IntValue\", \"labels\": { \"en\": \"Integer\" }, \"gui_element\": \"Spinbox\", \"gui_attributes\": { \"max\": 10.0, \"min\": 0.0 } } DecimalValue \"object\": \"DecimalValue\" A number with decimal point. gui-elements / gui_attributes : Slider : A GUI element for DecimalValue . Provides a slider to select a decimal value. gui_attributes : max=decimal (mandatory): maximal value min=decimal (mandatory): minimal value SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): maximum number of characters accepted size=integer (optional): size of the input field Example: { \"name\": \"hasDecimal\", \"super\": [ \"hasValue\" ], \"object\": \"DecimalValue\", \"labels\": { \"en\": \"Decimal number\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"maxlength\": 255, \"size\": 80 } } DateValue object\": \"DateValue\" Represents a date. It's a string with the format calendar:start:end Please note that the DateValue is an extremely flexible data type. It can represent an exact date or a date with a given uncertainty, and the date can be given in several calendars (currently the Gregorian and the Julian calendars are supported, with the Jewish and Islamic coming soon). Internally, a date is always represented as a start and end date. If start and end date match, it's an exact date. A value like \"1893\" will automatically be expanded to a range from January 1st 1893 to December 31st 1893. calendar is either GREGORIAN or JULIAN start has the form yyyy - mm - dd . If only the year is given, the precision is to the year. If only the year and month is given, the precision is to the month. end is optional if the date represents a clearly defined period or uncertainty. In total, a DateValue has the following form: \"GREGORIAN:1925:1927-03-22\" which means anytime in between 1925 and the 22nd March 1927. gui_elements / gui_attributes : Date : The only GUI element for DateValue . A date picker gui. gui_attributes : No attributes Example: { \"name\": \"hasDate\", \"super\": [ \"hasValue\" ], \"object\": \"DateValue\", \"labels\": { \"en\": \"Date\" }, \"gui_element\": \"Date\" } TimeValue \"object\": \"TimeValue\" A time value represents a precise moment in time in the Gregorian calendar. Since nanosecond precision can be included, it is suitable for use as a timestamp. gui-elements / gui_attributes : TimeStamp : A GUI element for TimeValue which contains a date picker and a time picker. gui_attributes : No attributes Example: { \"name\": \"hasTime\", \"super\": [ \"hasValue\" ], \"object\": \"TimeValue\", \"labels\": { \"en\": \"Time\" }, \"gui_element\": \"TimeStamp\" } IntervalValue \"object\": \"IntervalValue\" Represents a time-interval gui-elements / gui_attributes : SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Interval : Two spin boxes, one for each decimal gui_attributes : No attributes Example: { \"name\": \"hasInterval\", \"super\": [ \"hasValue\" ], \"object\": \"IntervalValue\", \"labels\": { \"en\": \"Time interval\" }, \"gui_element\": \"Interval\" } BooleanValue \"object\": \"BooleanValue\" Represents a Boolean (\"true\" or \"false). gui-elements / gui_attributes : Checkbox : A GUI element for BooleanValue . gui_attributes : No attributes Example: { \"name\": \"hasBoolean\", \"super\": [ \"hasValue\" ], \"object\": \"BooleanValue\", \"labels\": { \"en\": \"Boolean value\" }, \"gui_element\": \"Checkbox\" } UriValue \"object\": \"UriValue\" Represents an URI gui-elements / gui_attributes : SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example: { \"name\": \"hasUri\", \"super\": [ \"hasValue\" ], \"object\": \"UriValue\", \"labels\": { \"en\": \"URI\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"maxlength\": 255, \"size\": 80 } } GeonameValue Represents a location ID in geonames.org. The DSP platform uses identifiers provided by geonames.org to identify geographical locations. gui-elements / gui_attributes : Geonames : The only valid GUI element for GeonameValue . It interfaces are with geonames.org and it allows to select a location. gui_attributes : No attributes Example: { \"name\": \"hasGeoname\", \"super\": [ \"hasValue\" ], \"object\": \"GeonameValue\", \"labels\": { \"en\": \"Geoname\" }, \"gui_element\": \"Geonames\" } ColorValue \"object\": \"ColorValue\" A string representation of the color in the hexadecimal form e.g. \"#ff8000\". gui-elements / gui_attributes : Colorpicker : The only GUI element for ColorValue . It's used to choose a color. gui_attributes : ncolors=integer (optional): Number of colors the color picker should present. Example: { \"name\": \"hasColor\", \"super\": [ \"hasColor\" ], \"object\": \"ColorValue\", \"labels\": { \"en\": \"Color\" }, \"gui_element\": \"Colorpicker\" } GeomValue \"object\": \"GeomValue\" Represents a geometrical shape as JSON. Geometrical shapes are used to define regions of interest (ROI) on still images or moving images. gui-elements / gui_attributes : Geometry : not yet implemented. gui_attributes : No attributes SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example : { \"name\": \"hasGeometry\", \"super\": [ \"hasGeometry\" ], \"object\": \"GeomValue\", \"labels\": \"Geometry\", \"gui_element\": \"SimpleText\" } ListValue \"object\": \"ListValue\" Represents a node of a (possibly hierarchical) list gui-elements / gui_attributes : Radio : A GUI element for ListValue . A set of radio buttons. This works only with flat lists. gui_attributes : hlist=<list-name> (required): The reference of a list root node List : A GUI element for ListValue . A list of values to select one from. This GUI element should be chosen for hierarchical lists or flat lists that could be expanded to hierarchical lists in the future. gui_attributes : hlist=<list-name> (required): The reference of a list root node Example: { \"name\": \"hasListItem\", \"super\": [ \"hasValue\" ], \"object\": \"ListValue\", \"labels\": { \"en\": \"List element\" }, \"gui_element\": \"List\", \"gui_attributes\": { \"hlist\": \"treelistroot\" } } Representation \"object\": \"Representation\" A property pointing to a knora-base:Representation . Has to be used in combination with \"super\": [\"hasRepresentation\"] . A resource having this generic property hasRepresentation can point to any type of Representation, be it a StillImageRepresentation , an AudioRepresentation , etc. gui-elements / gui_attributes : Searchbox : Allows searching resources that have super class Representation by entering at least 3 characters into a searchbox. gui_attributes : numprops=integer (optional): While dynamically displaying the search result, the number of properties that should be displayed. Example: { \"name\": \"hasRep\", \"super\": [ \"hasRepresentation\" ], \"object\": \"Representation\", \"labels\": { \"en\": \"Represented by\" }, \"gui_element\": \"Searchbox\" } hasLinkTo Property \"object\": \":<resource-name>\" Link properties do not follow the pattern of the previous data types, because they do not connect to a final value but to another (existing) resource. Thus, the \"object\" denominates the resource class the link will point to. If the resource is defined in the same ontology, the name has to be prepended by a \":\", if the resource is defined in another (previously defined) ontology, the ontology name has to be prepended separated by a colon \":\", e.g. \"other-onto:MyResource\". When defining a link property, its \"super\" element has to be \"hasLinkTo\" or \"isPartOf\" or derived from \"hasLinkTo\" or \"isPartOf\". \"isPartOf\" is a special type of linked resources, for more information see below . gui-elements/gui_attributes : Searchbox : Has to be used with hasLinkTo property. Allows searching resources by entering the resource name that the given resource should link to. It has one gui_attribute that indicates how many properties of the found resources should be indicated. gui_attributes : numprops=integer (optional): While dynamically displaying the search result, the number of properties that should be displayed. Example: { \"name\": \"hasOtherThing\", \"super\": [ \"hasLinkTo\" ], \"object\": \":Thing\", \"labels\": \"Another thing\", \"gui_element\": \"Searchbox\" } IsPartOf Property A special case of linked resources is resources in a part-of / part-whole relation, i.e. resources that are composed of other resources. A isPartOf property has to be added to the resource that is part of another resource. In case of resources that are of type StillImageRepresentation , an additional property derived from seqnum with object IntValue is required. When defined, a client is able to leaf through the parts of a compound object, p.ex. to leaf through pages of a book. Example: { \"name\": \"partOfBook\", \"super\": [ \"isPartOf\" ], \"object\": \":Book\", \"labels\": { \"en\": \"is part of\" }, \"gui_element\": \"Searchbox\" }, { \"name\": \"hasPageNumber\", \"super\": [ \"seqnum\" ], \"object\": \"IntValue\", \"labels\": { \"en\": \"has page number\" }, \"gui_element\": \"Spinbox\" } Resources Object in Detail Name (required) \"name\": \"<string>\" A name for the resource, e.g. \"Book\", \"Manuscript\", \"Person\". It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). By convention, resource names start with a upper case letter. Labels (required) \"labels\": {\"<language>\": \"<string>\", ...} Collection of labels for the resource as strings with language tag (currently \"en\", \"de\", \"fr\" and \"it\" are supported). Super (required) \"super\": [\"<super-resource>\", \"<super-resource>\", ...] A resource is always derived from at least one other resource. The most generic resource class for DSP is Resource . A resource may be derived from resources defined in external ontologies. The following predefined resources are provided by DSP: Resource : A generic resource representing an item from the real world. This is the most general case, to be used in all cases when your resource is none of the special cases below. StillImageRepresentation : An object representing a still image TextRepresentation : An object representing an (external) text (not yet implemented) AudioRepresentation : An object representing an audio file DDDRepresentation : An object representing a 3-D representation (not yet implemented) DocumentRepresentation : An object representing an opaque document (e.g. a PDF) MovingImageRepresentation : An object representing a moving image (video, film) ArchiveRepresentation : An object representing an archive file (e.g. Zip) Annotation : A predefined annotation object. It has automatically the following predefined properties defined: hasComment (1-n) isAnnotationOf (1) LinkObj : A resource class linking together several other resource classes. The class has the following properties: hasComment (1-n) hasLinkTo (1-n) Region : Represents a region in an image. The class has the following properties: hasColor (1) isRegionOf (1) hasGeometry (1) hasComment (0-n) Additionally, resources can be derived from external ontologies or from resources specified in the present document. Cardinalities (required) \"cardinalities\": [...] An array that contains information about the relation between resources and properties. It tells what properties a resource can have as well as how many times the relation is established. cardinalities : Array of references to the properties that the resource may hold including the cardinality. A cardinality has the following properties: propname (1): The name of the property. If it's used in the form :my_propname , the current ontology is referenced. Otherwise, the prefix of the ontology the property is part of has to be used. gui_order (0-1): An integer number which will help the GUI to display the properties in the desired order (optional) cardinality (1): Indicates how often a given property may occur. The possible values are: \"1\" : exactly once (mandatory one value and only one) \"0-1\" : The value may be omitted, but can occur only once. \"1-n\" : At least one value must be present, but multiple values may be present. \"0-n\" : The value may be omitted, but may also occur multiple times. Comments (optional) \"comments\": { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } Comments with language tags. Currently, \"de\", \"en\", \"fr\" and \"it\" are supported. The comments element is optional. Example for a resource definition: { \"resources\": [ { \"name\": \"Schule\", \"labels\": { \"de\": \"Schule\", \"en\": \"School\", \"fr\": \"Ecole\", \"it\": \"Scuola\" }, \"super\": \"Resource\", \"comments\": { \"de\": \"Ein Kommentar\", \"en\": \"A comment\", \"fr\": \"Une commentaire\", \"it\": \"Un commento\" }, \"cardinalities\": [ { \"propname\": \":schulcode\", \"gui_order\": 1, \"cardinality\": \"1\" }, { \"propname\": \":schulname\", \"gui_order\": 2, \"cardinality\": \"1\" }, { \"propname\": \":bildungsgang\", \"gui_order\": 3, \"cardinality\": \"1\" } ] } ] } Referencing Ontologies For several fields, such as super in both resources and properties or propname in cardinalities , it is necessary to reference entities that are defined elsewhere. The following cases are possible. DSP-API internals: These must be written without leading colon and should not be a fully qualified IRI. E.g. Resource , DocumentRepresentation or hasValue An external ontology: The ontology must be defined in the prefixes This prefix should be used for referencing the ontology. E.g. foaf:familyName or sdo:Organization The current ontology: Within an ontology definition, references can be made by prepending a colon without a prefix. E.g. :hasName Optionally, an explicit prefix can be used, in this case the ontology must be added to the prefixes and the prefix must be identical to the ontology's name . A different ontology defined in the same file: Within one data model file, multiple ontologies can be defined. These will be created in the exact order they appear in the ontologies array. Once an ontology has been created, it can be referenced by the following ontologies via its name: first-onto:hasName . It is not necessary to add first-onto to the prefixes.","title":"Ontologies"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#ontologies","text":"An ontology is a formal representation of a set of terminologies which finally represent real world objects. Dependencies, attributes and relations of and between the individual components of the set are recorded in a logical, formal language. In contrast to a taxonomy, which defines a mere hierarchical structure within a range of terms, an ontology is much more a network of information of logical dependencies of term elements. Or, in other words, an ontology defines a strict, formal \"data model\" for real world concepts such as \"Person\", \"Work\", \"Artist\" etc. A full-fledged ontology thus has to offer at least two things: a set of concepts or terms (called resources , actually \"resource classes\") that represent concepts of real world objects, as well as attributes or properties describing these resources. These properties are linked either to a final value or may define a relationship to another resource. Let's assume that we define a resource called \"Person\" and two properties called \"hasBirthday\" and \"hasParent\" . For a specific incarnation of a \"Person\" (we call this an instance ), \"hasBirthday\" will have a final value such as \"1960-05-21\", whereas \"hasParent\" will link to another instance of a \"Person\". Within DSP, properties may be re-used for different resources. E.g. a property \"description\" may be used for a resource called \"image\" as well as \"movie\". Therefore, the list of properties is separated from the list of resources. The properties are assigned to the resources by defining \" cardinalities \". A cardinality indicates if a property is mandatory or can be omitted (e.g. if unknown), and if a property may be used several times on the same instance of a resource or not. The cardinality definitions are explained further below . Example of an ontologies object: { \"ontologies\": [ { \"name\": \"seworon\", \"label\": \"Secrets of the World Ontology\", \"properties\": [ ... ], \"resources\": [ ... ] }, { ... }, { ... } ] }","title":"Ontologies"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#ontologies-object-in-detail","text":"The following properties can occur within each object in ontologies .","title":"Ontologies Object in Detail"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#name","text":"(required) \"name\": \"<string>\" The ontology's (short) name should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character).","title":"Name"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#label","text":"(required) \"label\": \"<string>\" A string that provides the full name of the ontology.","title":"Label"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#properties","text":"(required) \"properties\": [<property-definition>, <property-definition>, ...] A properties array contains all properties used to describe resources in the ontology. A property has to be of a certain data type. It is not possible to create a custom data type. The following fields are mandatory: name labels object gui_element The following fields are optional: comments super (with the exception of LinkValue where super is mandatory) subject gui_attributes A detailed description of properties can be found below .","title":"Properties"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#resources","text":"(required) The resource classes are the primary entities of the data model. They are the actual objects inside a terminology space. A resource class can be seen as a template for the representation of a real object that is represented in the DSP. A resource class defines properties ( data fields ). For each of these properties a data type as well as the cardinality has to be provided. \"resources\": [<resource-definition>, <resource-definition>, ...] A resource object needs to have the following fields: name labels super cardinalities The following field is optional: comments A detailed description of resources can be found below .","title":"Resources"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#properties-object-in-detail","text":"Please note that object is used to define the data type. The gui_element depends on the value of the object . The gui_attributes depends on the value of the gui_element .","title":"Properties Object in Detail"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#name_1","text":"(required) \"name\": \"<string>\" A name for the property, e.g. \"pageOf\", \"hasBirthdate\", \"createdBy\". It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). By convention, property names start with a lower case letter.","title":"Name"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#labels","text":"(required) \"labels\": {\"<language>\": \"<string>\", ...} Collection of labels for the property as strings with language tag (currently \"en\", \"de\", \"fr\" and \"it\" are supported).","title":"Labels"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#comments","text":"(optional) \"comments\": { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } Comments with language tags. Currently, \"de\", \"en\", \"fr\" and \"it\" are supported. The comments element is optional.","title":"Comments"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#super","text":"(optional) \"super\": [\"<super-property>\", \"<super-property>, ...] A property has to be derived from at least one base property. The most generic base property that the DSP offers is hasValue . In addition, the property may be a sub-property of properties defined in external or other ontologies. External ontologies like dcterms or foaf must be defined in the \"prefix\" section. In this case the qualified name - including the prefix of the external or internal ontology - has to be given. The following base properties are defined by DSP: hasValue : This is the most generic base and taken as default if super is omitted. hasLinkTo : This value represents a link to another resource. You have to indicate the \" object \" as a prefixed name that identifies the resource class this link points to (a \":\" prepended to the name is sufficient if the resource is defined in the current ontology). hasColor : Defines a color value hasComment : Defines a standard comment hasGeometry : Defines a geometry value (a JSON describing a polygon, circle or rectangle) isPartOf : A special variant of hasLinkTo . It says that an instance of the given resource class is an integral part of another resource class. E.g. a \"page\" is part of a \"book\". isRegionOf : A special variant of hasLinkTo . It means that the given resource class is a \"region\" of another resource class. This is typically used to describe regions of interest in images. isAnnotationOf : A special variant of hasLinkTo . It denotes the given resource class as an annotation to another resource class. seqnum : An integer that is used to define a sequence number in an ordered set of instances, e.g. the ordering of the pages in a book (independent of the page naming) in combination with a property derived from isPartOf . Example of a properties object: { \"properties\": [ { \"name\": \"id\", \"subject\": \":School\", \"object\": \"TextValue\", \"super\": [ \"hasValue\" ], \"labels\": { \"en\": \"School ID\", \"de\": \"ID der Schule\", \"fr\": \"ID de l'\u00e9cole\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 32, \"maxlength\": 128 } }, { \"name\": \"name\", \"subject\": \":School\", \"object\": \"TextValue\", \"super\": [ \"hasValue\" ], \"labels\": { \"en\": \"Name of the school\", \"de\": \"Name der Schule\", \"fr\": \"Nom de l'\u00e9cole\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 32, \"maxlength\": 128 } } ] }","title":"Super"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#subject","text":"(optional) \"subject\": \"<resource-class>\" The subject defines the resource class the property can be used on. It has to be provided as prefixed name of the resource class (see below on how prefixed names are used).","title":"Subject"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#object-gui_element-gui_attributes","text":"object : required gui_element : required gui_attributes : optional \"object\": \"<data-type>\" The object defines the data type of the value that the property will store. gui_element and gui_attributes depend on the data type. The following data types are allowed: TextValue ColorValue DateValue TimeValue DecimalValue GeomValue GeonameValue IntValue BooleanValue UriValue IntervalValue ListValue Representation any previously defined resource class in case of a link property","title":"Object / gui_element / gui_attributes"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#textvalue","text":"\"object\": \"TextValue\" Represents a text that may contain standoff markup. gui_elements / gui_attributes : SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes are: gui_attributes : maxlength=integer (optional): maximal length (number of characters accepted) size=integer (optional): size (width) of widget Textarea : A GUI element for TextValue . Presents a multiline text entry box. The optional attributes are: gui_attributes : cols=integer (optional): number of columns of the textarea rows=integer (optional): number of rows of the textarea width=percent (optional): width of the textarea on screen wrap=soft|hard (optional): wrapping of text Richtext : A GUI element for TextValue . Provides a richtext editor. gui_attributes : No attributes Example: { \"name\": \"hasPictureTitle\", \"super\": [ \"hasValue\" ], \"object\": \"TextValue\", \"labels\": { \"en\": \"Title\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"maxlength\": 255, \"size\": 80 } }","title":"TextValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#intvalue","text":"\"object\": \"IntValue\" Represents an integer value. gui-elements / gui_attributes : SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Spinbox : A GUI element for IntegerValue . A text field with and \"up\"- and \"down\"-button for increment/decrement. The attributes \"max=decimal\" and \"min=decimal\" are optional. gui_attributes : max=decimal (optional): Maximal value min=decimal (optional): Minimal value Example: { \"name\": \"hasInteger\", \"super\": [ \"hasValue\" ], \"object\": \"IntValue\", \"labels\": { \"en\": \"Integer\" }, \"gui_element\": \"Spinbox\", \"gui_attributes\": { \"max\": 10.0, \"min\": 0.0 } }","title":"IntValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#decimalvalue","text":"\"object\": \"DecimalValue\" A number with decimal point. gui-elements / gui_attributes : Slider : A GUI element for DecimalValue . Provides a slider to select a decimal value. gui_attributes : max=decimal (mandatory): maximal value min=decimal (mandatory): minimal value SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): maximum number of characters accepted size=integer (optional): size of the input field Example: { \"name\": \"hasDecimal\", \"super\": [ \"hasValue\" ], \"object\": \"DecimalValue\", \"labels\": { \"en\": \"Decimal number\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"maxlength\": 255, \"size\": 80 } }","title":"DecimalValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#datevalue","text":"object\": \"DateValue\" Represents a date. It's a string with the format calendar:start:end Please note that the DateValue is an extremely flexible data type. It can represent an exact date or a date with a given uncertainty, and the date can be given in several calendars (currently the Gregorian and the Julian calendars are supported, with the Jewish and Islamic coming soon). Internally, a date is always represented as a start and end date. If start and end date match, it's an exact date. A value like \"1893\" will automatically be expanded to a range from January 1st 1893 to December 31st 1893. calendar is either GREGORIAN or JULIAN start has the form yyyy - mm - dd . If only the year is given, the precision is to the year. If only the year and month is given, the precision is to the month. end is optional if the date represents a clearly defined period or uncertainty. In total, a DateValue has the following form: \"GREGORIAN:1925:1927-03-22\" which means anytime in between 1925 and the 22nd March 1927. gui_elements / gui_attributes : Date : The only GUI element for DateValue . A date picker gui. gui_attributes : No attributes Example: { \"name\": \"hasDate\", \"super\": [ \"hasValue\" ], \"object\": \"DateValue\", \"labels\": { \"en\": \"Date\" }, \"gui_element\": \"Date\" }","title":"DateValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#timevalue","text":"\"object\": \"TimeValue\" A time value represents a precise moment in time in the Gregorian calendar. Since nanosecond precision can be included, it is suitable for use as a timestamp. gui-elements / gui_attributes : TimeStamp : A GUI element for TimeValue which contains a date picker and a time picker. gui_attributes : No attributes Example: { \"name\": \"hasTime\", \"super\": [ \"hasValue\" ], \"object\": \"TimeValue\", \"labels\": { \"en\": \"Time\" }, \"gui_element\": \"TimeStamp\" }","title":"TimeValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#intervalvalue","text":"\"object\": \"IntervalValue\" Represents a time-interval gui-elements / gui_attributes : SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Interval : Two spin boxes, one for each decimal gui_attributes : No attributes Example: { \"name\": \"hasInterval\", \"super\": [ \"hasValue\" ], \"object\": \"IntervalValue\", \"labels\": { \"en\": \"Time interval\" }, \"gui_element\": \"Interval\" }","title":"IntervalValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#booleanvalue","text":"\"object\": \"BooleanValue\" Represents a Boolean (\"true\" or \"false). gui-elements / gui_attributes : Checkbox : A GUI element for BooleanValue . gui_attributes : No attributes Example: { \"name\": \"hasBoolean\", \"super\": [ \"hasValue\" ], \"object\": \"BooleanValue\", \"labels\": { \"en\": \"Boolean value\" }, \"gui_element\": \"Checkbox\" }","title":"BooleanValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#urivalue","text":"\"object\": \"UriValue\" Represents an URI gui-elements / gui_attributes : SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example: { \"name\": \"hasUri\", \"super\": [ \"hasValue\" ], \"object\": \"UriValue\", \"labels\": { \"en\": \"URI\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"maxlength\": 255, \"size\": 80 } }","title":"UriValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#geonamevalue","text":"Represents a location ID in geonames.org. The DSP platform uses identifiers provided by geonames.org to identify geographical locations. gui-elements / gui_attributes : Geonames : The only valid GUI element for GeonameValue . It interfaces are with geonames.org and it allows to select a location. gui_attributes : No attributes Example: { \"name\": \"hasGeoname\", \"super\": [ \"hasValue\" ], \"object\": \"GeonameValue\", \"labels\": { \"en\": \"Geoname\" }, \"gui_element\": \"Geonames\" }","title":"GeonameValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#colorvalue","text":"\"object\": \"ColorValue\" A string representation of the color in the hexadecimal form e.g. \"#ff8000\". gui-elements / gui_attributes : Colorpicker : The only GUI element for ColorValue . It's used to choose a color. gui_attributes : ncolors=integer (optional): Number of colors the color picker should present. Example: { \"name\": \"hasColor\", \"super\": [ \"hasColor\" ], \"object\": \"ColorValue\", \"labels\": { \"en\": \"Color\" }, \"gui_element\": \"Colorpicker\" }","title":"ColorValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#geomvalue","text":"\"object\": \"GeomValue\" Represents a geometrical shape as JSON. Geometrical shapes are used to define regions of interest (ROI) on still images or moving images. gui-elements / gui_attributes : Geometry : not yet implemented. gui_attributes : No attributes SimpleText : A GUI element for TextValue . A simple text entry box (one line only). The attributes \"maxlength=integer\" and \"size=integer\" are optional. gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example : { \"name\": \"hasGeometry\", \"super\": [ \"hasGeometry\" ], \"object\": \"GeomValue\", \"labels\": \"Geometry\", \"gui_element\": \"SimpleText\" }","title":"GeomValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#listvalue","text":"\"object\": \"ListValue\" Represents a node of a (possibly hierarchical) list gui-elements / gui_attributes : Radio : A GUI element for ListValue . A set of radio buttons. This works only with flat lists. gui_attributes : hlist=<list-name> (required): The reference of a list root node List : A GUI element for ListValue . A list of values to select one from. This GUI element should be chosen for hierarchical lists or flat lists that could be expanded to hierarchical lists in the future. gui_attributes : hlist=<list-name> (required): The reference of a list root node Example: { \"name\": \"hasListItem\", \"super\": [ \"hasValue\" ], \"object\": \"ListValue\", \"labels\": { \"en\": \"List element\" }, \"gui_element\": \"List\", \"gui_attributes\": { \"hlist\": \"treelistroot\" } }","title":"ListValue"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#representation","text":"\"object\": \"Representation\" A property pointing to a knora-base:Representation . Has to be used in combination with \"super\": [\"hasRepresentation\"] . A resource having this generic property hasRepresentation can point to any type of Representation, be it a StillImageRepresentation , an AudioRepresentation , etc. gui-elements / gui_attributes : Searchbox : Allows searching resources that have super class Representation by entering at least 3 characters into a searchbox. gui_attributes : numprops=integer (optional): While dynamically displaying the search result, the number of properties that should be displayed. Example: { \"name\": \"hasRep\", \"super\": [ \"hasRepresentation\" ], \"object\": \"Representation\", \"labels\": { \"en\": \"Represented by\" }, \"gui_element\": \"Searchbox\" }","title":"Representation"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#haslinkto-property","text":"\"object\": \":<resource-name>\" Link properties do not follow the pattern of the previous data types, because they do not connect to a final value but to another (existing) resource. Thus, the \"object\" denominates the resource class the link will point to. If the resource is defined in the same ontology, the name has to be prepended by a \":\", if the resource is defined in another (previously defined) ontology, the ontology name has to be prepended separated by a colon \":\", e.g. \"other-onto:MyResource\". When defining a link property, its \"super\" element has to be \"hasLinkTo\" or \"isPartOf\" or derived from \"hasLinkTo\" or \"isPartOf\". \"isPartOf\" is a special type of linked resources, for more information see below . gui-elements/gui_attributes : Searchbox : Has to be used with hasLinkTo property. Allows searching resources by entering the resource name that the given resource should link to. It has one gui_attribute that indicates how many properties of the found resources should be indicated. gui_attributes : numprops=integer (optional): While dynamically displaying the search result, the number of properties that should be displayed. Example: { \"name\": \"hasOtherThing\", \"super\": [ \"hasLinkTo\" ], \"object\": \":Thing\", \"labels\": \"Another thing\", \"gui_element\": \"Searchbox\" }","title":"hasLinkTo Property"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#ispartof-property","text":"A special case of linked resources is resources in a part-of / part-whole relation, i.e. resources that are composed of other resources. A isPartOf property has to be added to the resource that is part of another resource. In case of resources that are of type StillImageRepresentation , an additional property derived from seqnum with object IntValue is required. When defined, a client is able to leaf through the parts of a compound object, p.ex. to leaf through pages of a book. Example: { \"name\": \"partOfBook\", \"super\": [ \"isPartOf\" ], \"object\": \":Book\", \"labels\": { \"en\": \"is part of\" }, \"gui_element\": \"Searchbox\" }, { \"name\": \"hasPageNumber\", \"super\": [ \"seqnum\" ], \"object\": \"IntValue\", \"labels\": { \"en\": \"has page number\" }, \"gui_element\": \"Spinbox\" }","title":"IsPartOf Property"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#resources-object-in-detail","text":"","title":"Resources Object in Detail"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#name_2","text":"(required) \"name\": \"<string>\" A name for the resource, e.g. \"Book\", \"Manuscript\", \"Person\". It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). By convention, resource names start with a upper case letter.","title":"Name"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#labels_1","text":"(required) \"labels\": {\"<language>\": \"<string>\", ...} Collection of labels for the resource as strings with language tag (currently \"en\", \"de\", \"fr\" and \"it\" are supported).","title":"Labels"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#super_1","text":"(required) \"super\": [\"<super-resource>\", \"<super-resource>\", ...] A resource is always derived from at least one other resource. The most generic resource class for DSP is Resource . A resource may be derived from resources defined in external ontologies. The following predefined resources are provided by DSP: Resource : A generic resource representing an item from the real world. This is the most general case, to be used in all cases when your resource is none of the special cases below. StillImageRepresentation : An object representing a still image TextRepresentation : An object representing an (external) text (not yet implemented) AudioRepresentation : An object representing an audio file DDDRepresentation : An object representing a 3-D representation (not yet implemented) DocumentRepresentation : An object representing an opaque document (e.g. a PDF) MovingImageRepresentation : An object representing a moving image (video, film) ArchiveRepresentation : An object representing an archive file (e.g. Zip) Annotation : A predefined annotation object. It has automatically the following predefined properties defined: hasComment (1-n) isAnnotationOf (1) LinkObj : A resource class linking together several other resource classes. The class has the following properties: hasComment (1-n) hasLinkTo (1-n) Region : Represents a region in an image. The class has the following properties: hasColor (1) isRegionOf (1) hasGeometry (1) hasComment (0-n) Additionally, resources can be derived from external ontologies or from resources specified in the present document.","title":"Super"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#cardinalities","text":"(required) \"cardinalities\": [...] An array that contains information about the relation between resources and properties. It tells what properties a resource can have as well as how many times the relation is established. cardinalities : Array of references to the properties that the resource may hold including the cardinality. A cardinality has the following properties: propname (1): The name of the property. If it's used in the form :my_propname , the current ontology is referenced. Otherwise, the prefix of the ontology the property is part of has to be used. gui_order (0-1): An integer number which will help the GUI to display the properties in the desired order (optional) cardinality (1): Indicates how often a given property may occur. The possible values are: \"1\" : exactly once (mandatory one value and only one) \"0-1\" : The value may be omitted, but can occur only once. \"1-n\" : At least one value must be present, but multiple values may be present. \"0-n\" : The value may be omitted, but may also occur multiple times.","title":"Cardinalities"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#comments_1","text":"(optional) \"comments\": { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } Comments with language tags. Currently, \"de\", \"en\", \"fr\" and \"it\" are supported. The comments element is optional. Example for a resource definition: { \"resources\": [ { \"name\": \"Schule\", \"labels\": { \"de\": \"Schule\", \"en\": \"School\", \"fr\": \"Ecole\", \"it\": \"Scuola\" }, \"super\": \"Resource\", \"comments\": { \"de\": \"Ein Kommentar\", \"en\": \"A comment\", \"fr\": \"Une commentaire\", \"it\": \"Un commento\" }, \"cardinalities\": [ { \"propname\": \":schulcode\", \"gui_order\": 1, \"cardinality\": \"1\" }, { \"propname\": \":schulname\", \"gui_order\": 2, \"cardinality\": \"1\" }, { \"propname\": \":bildungsgang\", \"gui_order\": 3, \"cardinality\": \"1\" } ] } ] }","title":"Comments"},{"location":"DSP-TOOLS/dsp-tools-create-ontologies/#referencing-ontologies","text":"For several fields, such as super in both resources and properties or propname in cardinalities , it is necessary to reference entities that are defined elsewhere. The following cases are possible. DSP-API internals: These must be written without leading colon and should not be a fully qualified IRI. E.g. Resource , DocumentRepresentation or hasValue An external ontology: The ontology must be defined in the prefixes This prefix should be used for referencing the ontology. E.g. foaf:familyName or sdo:Organization The current ontology: Within an ontology definition, references can be made by prepending a colon without a prefix. E.g. :hasName Optionally, an explicit prefix can be used, in this case the ontology must be added to the prefixes and the prefix must be identical to the ontology's name . A different ontology defined in the same file: Within one data model file, multiple ontologies can be defined. These will be created in the exact order they appear in the ontologies array. Once an ontology has been created, it can be referenced by the following ontologies via its name: first-onto:hasName . It is not necessary to add first-onto to the prefixes.","title":"Referencing Ontologies"},{"location":"DSP-TOOLS/dsp-tools-create/","text":"JSON data model definition format This document describes the structure of a data model (ontology) used by DSP. According to Wikipedia, the data model is \"an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities. [...] A data model explicitly determines the structure of data. Data models are typically specified by a data specialist, data librarian, or a digital humanities scholar in a data modeling notation\". The following sections describe the notation for ontologies in the context of DSP. A short overview A complete data model definition for DSP looks like this: { \"prefixes\": { \"foaf\": \"http://xmlns.com/foaf/0.1/\", \"dcterms\": \"http://purl.org/dc/terms/\" }, \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/ontology.json\", \"project\": { \"shortcode\": \"0123\", \"shortname\": \"BiZ\", \"longname\": \"Bildung in Zahlen\", \"descriptions\": { ... }, \"keywords\": [ ... ], \"lists\": [ ... ], \"groups\": [ ... ], \"users\": [ ... ], \"ontologies\": [ ... ] } } \"prefixes\" object (optional) \"prefixes\": { \"prefix\": \"<iri>\", ...} The prefixes object contains the prefixes of external ontologies that are used in the current project. All prefixes are composed of the actual prefix and an IRI. The prefix is used as an abbreviation so one does not have to write the full qualified IRI each time it is used. So, instead of writing a property called \"familyname\" as http://xmlns.com/foaf/0.1/familyName one can simply use foaf:familyName . { \"prefixes\": { \"foaf\": \"http://xmlns.com/foaf/0.1/\", \"dcterms\": \"http://purl.org/dc/terms/\" } } It is not necessary to define prefixes for the ontologies that are defined in this file. Ontologies in the same file can refer to each other via their name. See also here . \"$schema\" object (required) The $schema object refers to the JSON schema for DSP data model definitions and is mandatory. \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/ontology.json\" \"project\" object (required) \"project\": {\"key\": \"<value>\", ...} The project object contains all resources and properties of the ontology as well as some information about the project. It requires all the following data fields: shortcode shortname longname keywords ontologies The following fields are optional (if one or more of these fields are not used, they should be omitted): descriptions lists groups users A simple example definition of the project object looks like this: { \"project\": { \"shortcode\": \"0809\", \"shortname\": \"test\", \"longname\": \"Test Example\", \"descriptions\": { \"en\": \"This is a simple example project\", \"de\": \"Dies ist ein einfaches Beispielprojekt\" }, \"keywords\": [ \"example\", \"simple\" ], \"lists\": [ ... ], \"groups\": [ ... ], \"users\": [ ... ], \"ontologies\": [ ... ] } } \"project\" object in detail In the following section all fields of the project object are explained in detail. Shortcode (required) \"shortcode\": \"<4-hex-characters>\" The shortcode has to be unique and is represented by a 4 digit hexadecimal string. The shortcode has to be provided by the DaSCH. Shortname (required) \"shortname\": \"<string>\" The shortname has to be unique. It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). Longname (required) \"longname\": \"<string>\" The longname is a string that provides the full name of the project. Descriptions (required) \"descriptions\": {\"<lang>\": \"<string>\", ...} The description is represented as a collection of strings with language tags (currently \"en\", \"de\", \"fr\" and \"it\" are supported). It is the description of the project. Keywords (required) \"keywords\": [\"<string>\", \"<string>\", ...] Keywords are represented as an array of strings and are used to describe and/or tag the project. Lists (optional) \"lists\": [<list-definition>,<list-definition>,...] Lists can be used to provide controlled vocabularies and can be \"flat\" or \"hierarchical\". One advantage of the use of hierarchical lists is that it allows a user to sub-categorize objects. This helps in the formulation of specific search requests. If there is a list node \"Vocal music\" and sub-nodes \"Song\" and \"Opera\", a search for \"Vocal Music\" would return objects classified as \"Song\" and \"Opera\". But a search for \"Song\" would only return objects classified as \"Song\". In dsp-tools the structure of a list is mapped using JSON. Only a single root node is allowed which also contains the name of the list. Inside the root node any number of child nodes and sub-nodes of child nodes are allowed. A resource can be assigned to a list node within its properties. For example, a resource of type \"Musical work\" with the title \"La Traviata\" would have a property like \"hasMusicGenre\" with the value \"Grand opera\". Within DSP, each property has a cardinality. Sometimes, a taxonomy allows an object to belong to multiple categories. In these cases, a cardinality greater than 1 has to be used. A node of a list may have the following elements: name : Name of the node as string. It is mandatory and has to be unique within the list. labels : Label with language tags in the form { \"<lang>\": \"<label>\", \"<lang>\": \"<label>\", ... } . The labels element is mandatory. It needs to specify at least one language. Currently, \"de\", \"en\", \"fr\" and \"it\" are supported. comments : Comment with language tags in the form { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } . Currently, \"de\", \"en\", \"fr\" and \"it\" are supported. The comments element is mandatory for the root node of the list. For all other nodes, it is optional. If not used, the element should be omitted. nodes : Array of sub-nodes. The nodes element is optional and can be omitted in case of a flat list. Example of a list: { \"lists\": [ { \"name\": \"my_list\", \"labels\": { \"en\": \"Disciplines of the Humanities\" }, \"comments\": { \"en\": \"This is just an example.\", \"fr\": \"C'est un example.\" }, \"nodes\": [ { \"name\": \"node_1_1\", \"labels\": { \"en\": \"Performing arts\" }, \"comments\": { \"en\": \"Arts that are events\", \"de\": \"K\u00fcnste mit performativem Character\" }, \"nodes\": [ { \"name\": \"node_2_2\", \"labels\": { \"en\": \"Music\" }, \"nodes\": [ { \"name\": \"node_3_3\", \"labels\": { \"en\": \"Chamber music\" } }, { \"name\": \"node_4_3\", \"labels\": { \"en\": \"Church music\" } }, { \"name\": \"node_5_3\", \"labels\": { \"en\": \"Conducting\" }, \"nodes\": [ { \"name\": \"node_6_4\", \"labels\": { \"en\": \"Choirs\" } }, { \"name\": \"node_7_4\", \"labels\": { \"en\": \"Orchestras\" } } ] }, { \"name\": \"node_8_3\", \"labels\": { \"en\": \"Music history\" } }, { \"name\": \"node_9_3\", \"labels\": { \"en\": \"Musictheory\" } }, { \"name\": \"node_10_3\", \"labels\": { \"en\": \"Musicology\" } }, { \"name\": \"node_11_3\", \"labels\": { \"en\": \"Jazz\" } }, { \"name\": \"node_12_3\", \"labels\": { \"en\": \"Pop/Rock/Blues\" } } ] } ] }, { ... }, { ... } ] } ] } Lists from Excel A list can be directly imported from one or several Excel files. The folder with the Excel file(s) can then directly be referenced inside the list definition by defining it as new list node: { \"name\": \"List-from-excel\", \"labels\": { \"en\": \"List from an Excel file\", \"de\": \"Liste von einer Excel-Datei\" }, \"comments\": { \"en\": \"This is just an example.\", \"fr\": \"C'est un example.\" }, \"nodes\": { \"folder\": \"excel-lists\" } } The nodes section has to contain the field: folder : Path to the folder containing the Excel files Further information about the expected format of the Excel lists and details to this functionality can be found here . The lists element is optional. If not used, it should be omitted. Groups (optional) \"groups\": [<group-definition>, <group-definition>,...] The groups object contains groups definitions. This is used to specify the permissions a user gets. A project may define several groups such as \"project-admins\", \"editors\" etc. in order to provide their members specific permissions. A group definition has the following elements: name : name of the group, mandatory descriptions : description of the group with language tags in the form \"descriptions\": {\"<lang>\": \"<string>\", ...} ( currently \"en\", \"de\", \"fr\" and \"it\" are supported), mandatory selfjoin : true if users are allowed to join the group themselves, false if an administrator has to add the users, optional status : true if the group is active, false if the group is inactive, optional Example: { \"groups\": [ { \"name\": \"biz-editors\", \"descriptions\": {\"en\" : \"Editors for the BiZ project\"}, \"selfjoin\": false, \"status\": true } ] } Users (optional) \"users\": [<user-definition>, <user-definition>,...] This object contains user definitions. A user has the following elements: username : username used for login email : email that identifies the user, has to be unique within DSP givenName : firstname of the user familyName : surname of the user password : password of the user lang : the default language of the user: \"en\", \"de\", \"fr\", \"it\" (optional, default: \"en\") groups : List of groups the user belongs to. The name of the group has to be provided with the ontology's namespace, p.ex. \"onto:editors\". The given ontology defined in the same ontology file has no name, so only \":editors\" is required if the user belongs to the group \"editors\". (optional) projects : List of projects the user belongs to. The project name has to be followed by a \":\" and either \"member\" or \"admin\". This indicates if the new user has admin rights in the given project or is an ordinary user. myproject:admin would add the user as admin to the project \"myproject\". The given project defined in the same ontology file has no name, so only \":admin\"or \":member\" is required. (optional) Example: { \"users\": [ { \"username\": \"bizedit\", \"email\": \"bizedit@test.org\", \"givenName\": \"biz-given\", \"familyName\": \"biz-family\", \"password\": \"biz1234\", \"lang\": \"en\", \"groups\": [ \":biz-editors\" ], \"projects\": [ \":admin\", \"otherProject:member\" ] } ] } The users element is optional. If not used, it should be omitted. Ontologies (required) \"ontologies\": [<ontology-definition>, <ontology-definition>, ...] Inside the ontologies section all resources and properties are described. A project may have multiple ontologies. It requires the following data fields: name label properties resources A detailed description of ontologies can be found here Fully fleshed out example ontology Finally, here is a complete example of an ontology definition: { \"prefixes\": { \"foaf\": \"http://xmlns.com/foaf/0.1/\", \"dcterms\": \"http://purl.org/dc/terms/\" }, \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/ontology.json\", \"project\": { \"shortcode\": \"0170\", \"shortname\": \"teimp\", \"longname\": \"Test Import\", \"descriptions\": { \"en\": \"This is a project for testing the creation of ontologies and data\", \"de\": \"Dies ist ein Projekt, um die Erstellung von Ontologien und Datenimport zu testen\" }, \"keywords\": [ \"test\", \"import\" ], \"lists\": [ { \"name\": \"orgtype\", \"labels\": { \"en\": \"Organization Type\", \"de\": \"Organisationsart\" }, \"comments\": { \"en\": \"List of different organization types\", \"de\": \"Liste unterschiedlicher Organisationstypen\" }, \"nodes\": [ { \"name\": \"business\", \"labels\": { \"en\": \"Commerce\", \"de\": \"Handel\" }, \"nodes\": [ { \"name\": \"transport\", \"labels\": { \"en\": \"Transportation\", \"de\": \"Transport\" } }, { \"name\": \"finances\", \"labels\": { \"en\": \"Finances\", \"de\": \"Finanzen\" } } ] }, { \"name\": \"society\", \"labels\": { \"en\": \"Society\", \"de\": \"Gesellschaft\" } } ] } ], \"ontologies\": [ { \"name\": \"teimp\", \"label\": \"Test import ontology\", \"properties\": [ { \"name\": \"firstname\", \"super\": [ \"hasValue\", \"foaf:givenName\" ], \"object\": \"TextValue\", \"labels\": { \"en\": \"Firstname\", \"de\": \"Vorname\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 24, \"maxlength\": 32 } }, { \"name\": \"lastname\", \"super\": [ \"hasValue\", \"foaf:familyName\" ], \"object\": \"TextValue\", \"labels\": { \"en\": \"Lastname\", \"de\": \"Nachname\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 24, \"maxlength\": 64 } }, { \"name\": \"member\", \"super\": [ \"hasLinkTo\" ], \"object\": \"teimp:organization\", \"labels\": { \"en\": \"member of\", \"de\": \"Mitglied von\" }, \"gui_element\": \"Searchbox\" }, { \"name\": \"name\", \"super\": [ \"hasValue\" ], \"object\": \"TextValue\", \"labels\": { \"en\": \"Name\", \"de\": \"Name\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 64, \"maxlength\": 64 } }, { \"name\": \"orgtype\", \"super\": [ \"hasValue\" ], \"object\": \"ListValue\", \"labels\": { \"en\": \"Organizationtype\", \"de\": \"Organisationstyp\" }, \"comments\": { \"en\": \"Type of organization\", \"de\": \"Art der Organisation\" }, \"gui_element\": \"List\", \"gui_attributes\": { \"hlist\": \"orgtype\" } } ], \"resources\": [ { \"name\": \"person\", \"super\": \"Resource\", \"labels\": { \"en\": \"Person\", \"de\": \"Person\" }, \"comments\": { \"en\": \"Represents a human being\", \"de\": \"Repr\u00e4sentiert eine Person/Menschen\" }, \"cardinalities\": [ { \"propname\": \":firstname\", \"gui_order\": 1, \"cardinality\": \"1\" }, { \"propname\": \":lastname\", \"gui_order\": 2, \"cardinality\": \"1\" }, { \"propname\": \":member\", \"gui_order\": 3, \"cardinality\": \"0-n\" } ] }, { \"name\": \"organization\", \"super\": \"Resource\", \"labels\": { \"en\": \"Organization\", \"de\": \"Organisation\" }, \"comments\": { \"en\": \"Denotes an organizational unit\", \"de\": \"Eine Institution oder Tr\u00e4gerschaft\" }, \"cardinalities\": [ { \"propname\": \":name\", \"gui_order\": 1, \"cardinality\": \"1-n\" }, { \"propname\": \":orgtype\", \"gui_order\": 2, \"cardinality\": \"1-n\" } ] } ] } ] } }","title":"Overview"},{"location":"DSP-TOOLS/dsp-tools-create/#json-data-model-definition-format","text":"This document describes the structure of a data model (ontology) used by DSP. According to Wikipedia, the data model is \"an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities. [...] A data model explicitly determines the structure of data. Data models are typically specified by a data specialist, data librarian, or a digital humanities scholar in a data modeling notation\". The following sections describe the notation for ontologies in the context of DSP.","title":"JSON data model definition format"},{"location":"DSP-TOOLS/dsp-tools-create/#a-short-overview","text":"A complete data model definition for DSP looks like this: { \"prefixes\": { \"foaf\": \"http://xmlns.com/foaf/0.1/\", \"dcterms\": \"http://purl.org/dc/terms/\" }, \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/ontology.json\", \"project\": { \"shortcode\": \"0123\", \"shortname\": \"BiZ\", \"longname\": \"Bildung in Zahlen\", \"descriptions\": { ... }, \"keywords\": [ ... ], \"lists\": [ ... ], \"groups\": [ ... ], \"users\": [ ... ], \"ontologies\": [ ... ] } }","title":"A short overview"},{"location":"DSP-TOOLS/dsp-tools-create/#prefixes-object","text":"(optional) \"prefixes\": { \"prefix\": \"<iri>\", ...} The prefixes object contains the prefixes of external ontologies that are used in the current project. All prefixes are composed of the actual prefix and an IRI. The prefix is used as an abbreviation so one does not have to write the full qualified IRI each time it is used. So, instead of writing a property called \"familyname\" as http://xmlns.com/foaf/0.1/familyName one can simply use foaf:familyName . { \"prefixes\": { \"foaf\": \"http://xmlns.com/foaf/0.1/\", \"dcterms\": \"http://purl.org/dc/terms/\" } } It is not necessary to define prefixes for the ontologies that are defined in this file. Ontologies in the same file can refer to each other via their name. See also here .","title":"\"prefixes\" object"},{"location":"DSP-TOOLS/dsp-tools-create/#schema-object","text":"(required) The $schema object refers to the JSON schema for DSP data model definitions and is mandatory. \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/ontology.json\"","title":"\"$schema\" object"},{"location":"DSP-TOOLS/dsp-tools-create/#project-object","text":"(required) \"project\": {\"key\": \"<value>\", ...} The project object contains all resources and properties of the ontology as well as some information about the project. It requires all the following data fields: shortcode shortname longname keywords ontologies The following fields are optional (if one or more of these fields are not used, they should be omitted): descriptions lists groups users A simple example definition of the project object looks like this: { \"project\": { \"shortcode\": \"0809\", \"shortname\": \"test\", \"longname\": \"Test Example\", \"descriptions\": { \"en\": \"This is a simple example project\", \"de\": \"Dies ist ein einfaches Beispielprojekt\" }, \"keywords\": [ \"example\", \"simple\" ], \"lists\": [ ... ], \"groups\": [ ... ], \"users\": [ ... ], \"ontologies\": [ ... ] } }","title":"\"project\" object"},{"location":"DSP-TOOLS/dsp-tools-create/#project-object-in-detail","text":"In the following section all fields of the project object are explained in detail.","title":"\"project\" object in detail"},{"location":"DSP-TOOLS/dsp-tools-create/#shortcode","text":"(required) \"shortcode\": \"<4-hex-characters>\" The shortcode has to be unique and is represented by a 4 digit hexadecimal string. The shortcode has to be provided by the DaSCH.","title":"Shortcode"},{"location":"DSP-TOOLS/dsp-tools-create/#shortname","text":"(required) \"shortname\": \"<string>\" The shortname has to be unique. It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character).","title":"Shortname"},{"location":"DSP-TOOLS/dsp-tools-create/#longname","text":"(required) \"longname\": \"<string>\" The longname is a string that provides the full name of the project.","title":"Longname"},{"location":"DSP-TOOLS/dsp-tools-create/#descriptions","text":"(required) \"descriptions\": {\"<lang>\": \"<string>\", ...} The description is represented as a collection of strings with language tags (currently \"en\", \"de\", \"fr\" and \"it\" are supported). It is the description of the project.","title":"Descriptions"},{"location":"DSP-TOOLS/dsp-tools-create/#keywords","text":"(required) \"keywords\": [\"<string>\", \"<string>\", ...] Keywords are represented as an array of strings and are used to describe and/or tag the project.","title":"Keywords"},{"location":"DSP-TOOLS/dsp-tools-create/#lists","text":"(optional) \"lists\": [<list-definition>,<list-definition>,...] Lists can be used to provide controlled vocabularies and can be \"flat\" or \"hierarchical\". One advantage of the use of hierarchical lists is that it allows a user to sub-categorize objects. This helps in the formulation of specific search requests. If there is a list node \"Vocal music\" and sub-nodes \"Song\" and \"Opera\", a search for \"Vocal Music\" would return objects classified as \"Song\" and \"Opera\". But a search for \"Song\" would only return objects classified as \"Song\". In dsp-tools the structure of a list is mapped using JSON. Only a single root node is allowed which also contains the name of the list. Inside the root node any number of child nodes and sub-nodes of child nodes are allowed. A resource can be assigned to a list node within its properties. For example, a resource of type \"Musical work\" with the title \"La Traviata\" would have a property like \"hasMusicGenre\" with the value \"Grand opera\". Within DSP, each property has a cardinality. Sometimes, a taxonomy allows an object to belong to multiple categories. In these cases, a cardinality greater than 1 has to be used. A node of a list may have the following elements: name : Name of the node as string. It is mandatory and has to be unique within the list. labels : Label with language tags in the form { \"<lang>\": \"<label>\", \"<lang>\": \"<label>\", ... } . The labels element is mandatory. It needs to specify at least one language. Currently, \"de\", \"en\", \"fr\" and \"it\" are supported. comments : Comment with language tags in the form { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } . Currently, \"de\", \"en\", \"fr\" and \"it\" are supported. The comments element is mandatory for the root node of the list. For all other nodes, it is optional. If not used, the element should be omitted. nodes : Array of sub-nodes. The nodes element is optional and can be omitted in case of a flat list. Example of a list: { \"lists\": [ { \"name\": \"my_list\", \"labels\": { \"en\": \"Disciplines of the Humanities\" }, \"comments\": { \"en\": \"This is just an example.\", \"fr\": \"C'est un example.\" }, \"nodes\": [ { \"name\": \"node_1_1\", \"labels\": { \"en\": \"Performing arts\" }, \"comments\": { \"en\": \"Arts that are events\", \"de\": \"K\u00fcnste mit performativem Character\" }, \"nodes\": [ { \"name\": \"node_2_2\", \"labels\": { \"en\": \"Music\" }, \"nodes\": [ { \"name\": \"node_3_3\", \"labels\": { \"en\": \"Chamber music\" } }, { \"name\": \"node_4_3\", \"labels\": { \"en\": \"Church music\" } }, { \"name\": \"node_5_3\", \"labels\": { \"en\": \"Conducting\" }, \"nodes\": [ { \"name\": \"node_6_4\", \"labels\": { \"en\": \"Choirs\" } }, { \"name\": \"node_7_4\", \"labels\": { \"en\": \"Orchestras\" } } ] }, { \"name\": \"node_8_3\", \"labels\": { \"en\": \"Music history\" } }, { \"name\": \"node_9_3\", \"labels\": { \"en\": \"Musictheory\" } }, { \"name\": \"node_10_3\", \"labels\": { \"en\": \"Musicology\" } }, { \"name\": \"node_11_3\", \"labels\": { \"en\": \"Jazz\" } }, { \"name\": \"node_12_3\", \"labels\": { \"en\": \"Pop/Rock/Blues\" } } ] } ] }, { ... }, { ... } ] } ] }","title":"Lists"},{"location":"DSP-TOOLS/dsp-tools-create/#lists-from-excel","text":"A list can be directly imported from one or several Excel files. The folder with the Excel file(s) can then directly be referenced inside the list definition by defining it as new list node: { \"name\": \"List-from-excel\", \"labels\": { \"en\": \"List from an Excel file\", \"de\": \"Liste von einer Excel-Datei\" }, \"comments\": { \"en\": \"This is just an example.\", \"fr\": \"C'est un example.\" }, \"nodes\": { \"folder\": \"excel-lists\" } } The nodes section has to contain the field: folder : Path to the folder containing the Excel files Further information about the expected format of the Excel lists and details to this functionality can be found here . The lists element is optional. If not used, it should be omitted.","title":"Lists from Excel"},{"location":"DSP-TOOLS/dsp-tools-create/#groups","text":"(optional) \"groups\": [<group-definition>, <group-definition>,...] The groups object contains groups definitions. This is used to specify the permissions a user gets. A project may define several groups such as \"project-admins\", \"editors\" etc. in order to provide their members specific permissions. A group definition has the following elements: name : name of the group, mandatory descriptions : description of the group with language tags in the form \"descriptions\": {\"<lang>\": \"<string>\", ...} ( currently \"en\", \"de\", \"fr\" and \"it\" are supported), mandatory selfjoin : true if users are allowed to join the group themselves, false if an administrator has to add the users, optional status : true if the group is active, false if the group is inactive, optional Example: { \"groups\": [ { \"name\": \"biz-editors\", \"descriptions\": {\"en\" : \"Editors for the BiZ project\"}, \"selfjoin\": false, \"status\": true } ] }","title":"Groups"},{"location":"DSP-TOOLS/dsp-tools-create/#users","text":"(optional) \"users\": [<user-definition>, <user-definition>,...] This object contains user definitions. A user has the following elements: username : username used for login email : email that identifies the user, has to be unique within DSP givenName : firstname of the user familyName : surname of the user password : password of the user lang : the default language of the user: \"en\", \"de\", \"fr\", \"it\" (optional, default: \"en\") groups : List of groups the user belongs to. The name of the group has to be provided with the ontology's namespace, p.ex. \"onto:editors\". The given ontology defined in the same ontology file has no name, so only \":editors\" is required if the user belongs to the group \"editors\". (optional) projects : List of projects the user belongs to. The project name has to be followed by a \":\" and either \"member\" or \"admin\". This indicates if the new user has admin rights in the given project or is an ordinary user. myproject:admin would add the user as admin to the project \"myproject\". The given project defined in the same ontology file has no name, so only \":admin\"or \":member\" is required. (optional) Example: { \"users\": [ { \"username\": \"bizedit\", \"email\": \"bizedit@test.org\", \"givenName\": \"biz-given\", \"familyName\": \"biz-family\", \"password\": \"biz1234\", \"lang\": \"en\", \"groups\": [ \":biz-editors\" ], \"projects\": [ \":admin\", \"otherProject:member\" ] } ] } The users element is optional. If not used, it should be omitted.","title":"Users"},{"location":"DSP-TOOLS/dsp-tools-create/#ontologies","text":"(required) \"ontologies\": [<ontology-definition>, <ontology-definition>, ...] Inside the ontologies section all resources and properties are described. A project may have multiple ontologies. It requires the following data fields: name label properties resources A detailed description of ontologies can be found here","title":"Ontologies"},{"location":"DSP-TOOLS/dsp-tools-create/#fully-fleshed-out-example-ontology","text":"Finally, here is a complete example of an ontology definition: { \"prefixes\": { \"foaf\": \"http://xmlns.com/foaf/0.1/\", \"dcterms\": \"http://purl.org/dc/terms/\" }, \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/ontology.json\", \"project\": { \"shortcode\": \"0170\", \"shortname\": \"teimp\", \"longname\": \"Test Import\", \"descriptions\": { \"en\": \"This is a project for testing the creation of ontologies and data\", \"de\": \"Dies ist ein Projekt, um die Erstellung von Ontologien und Datenimport zu testen\" }, \"keywords\": [ \"test\", \"import\" ], \"lists\": [ { \"name\": \"orgtype\", \"labels\": { \"en\": \"Organization Type\", \"de\": \"Organisationsart\" }, \"comments\": { \"en\": \"List of different organization types\", \"de\": \"Liste unterschiedlicher Organisationstypen\" }, \"nodes\": [ { \"name\": \"business\", \"labels\": { \"en\": \"Commerce\", \"de\": \"Handel\" }, \"nodes\": [ { \"name\": \"transport\", \"labels\": { \"en\": \"Transportation\", \"de\": \"Transport\" } }, { \"name\": \"finances\", \"labels\": { \"en\": \"Finances\", \"de\": \"Finanzen\" } } ] }, { \"name\": \"society\", \"labels\": { \"en\": \"Society\", \"de\": \"Gesellschaft\" } } ] } ], \"ontologies\": [ { \"name\": \"teimp\", \"label\": \"Test import ontology\", \"properties\": [ { \"name\": \"firstname\", \"super\": [ \"hasValue\", \"foaf:givenName\" ], \"object\": \"TextValue\", \"labels\": { \"en\": \"Firstname\", \"de\": \"Vorname\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 24, \"maxlength\": 32 } }, { \"name\": \"lastname\", \"super\": [ \"hasValue\", \"foaf:familyName\" ], \"object\": \"TextValue\", \"labels\": { \"en\": \"Lastname\", \"de\": \"Nachname\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 24, \"maxlength\": 64 } }, { \"name\": \"member\", \"super\": [ \"hasLinkTo\" ], \"object\": \"teimp:organization\", \"labels\": { \"en\": \"member of\", \"de\": \"Mitglied von\" }, \"gui_element\": \"Searchbox\" }, { \"name\": \"name\", \"super\": [ \"hasValue\" ], \"object\": \"TextValue\", \"labels\": { \"en\": \"Name\", \"de\": \"Name\" }, \"gui_element\": \"SimpleText\", \"gui_attributes\": { \"size\": 64, \"maxlength\": 64 } }, { \"name\": \"orgtype\", \"super\": [ \"hasValue\" ], \"object\": \"ListValue\", \"labels\": { \"en\": \"Organizationtype\", \"de\": \"Organisationstyp\" }, \"comments\": { \"en\": \"Type of organization\", \"de\": \"Art der Organisation\" }, \"gui_element\": \"List\", \"gui_attributes\": { \"hlist\": \"orgtype\" } } ], \"resources\": [ { \"name\": \"person\", \"super\": \"Resource\", \"labels\": { \"en\": \"Person\", \"de\": \"Person\" }, \"comments\": { \"en\": \"Represents a human being\", \"de\": \"Repr\u00e4sentiert eine Person/Menschen\" }, \"cardinalities\": [ { \"propname\": \":firstname\", \"gui_order\": 1, \"cardinality\": \"1\" }, { \"propname\": \":lastname\", \"gui_order\": 2, \"cardinality\": \"1\" }, { \"propname\": \":member\", \"gui_order\": 3, \"cardinality\": \"0-n\" } ] }, { \"name\": \"organization\", \"super\": \"Resource\", \"labels\": { \"en\": \"Organization\", \"de\": \"Organisation\" }, \"comments\": { \"en\": \"Denotes an organizational unit\", \"de\": \"Eine Institution oder Tr\u00e4gerschaft\" }, \"cardinalities\": [ { \"propname\": \":name\", \"gui_order\": 1, \"cardinality\": \"1-n\" }, { \"propname\": \":orgtype\", \"gui_order\": 2, \"cardinality\": \"1-n\" } ] } ] } ] } }","title":"Fully fleshed out example ontology"},{"location":"DSP-TOOLS/dsp-tools-excel/","text":"Excel files for data modelling and data import dsp-tools is able to process Excel files and output the appropriate JSON or XML file. The JSON/XML file can then be used to create the ontology on the DSP server or import data to the DSP repository. dsp-tools can also be used to create a list from an Excel file. Create the resources for a data model from an Excel file With dsp-tools, the resources section used in a data model (JSON) can be created from an Excel file. Only XLSX files are allowed. The resources section can be inserted into the ontology file and then be uploaded onto a DSP server. An Excel file template can be found here . It is recommended to work from the template. The expected worksheets of the Excel file are: classes : a table with all resource classes intended to be used in the resulting JSON class1 , class2 ,...: a table for each resource class named after its name The Excel sheet must have the following structure. The worksheet called classes has the following structure: The expected columns are: name : The name of the resource en , de , fr , it : The labels of the resource in different languages, at least one language has to be provided comment_en , comment_de , comment_fr , comment_it : optional comments in the respective language super : The base class of the resource All other worksheets, one for each resource class, have the following structure: { width=50% } The expected columns are: Property : The name of the property Cardinality : The cardinality, one of: 1 , 0-1 , 1-n , 0-n The GUI order is given by the order in which the properties are listed in the Excel sheet. For further information about resources, see here . Create the properties for a data model from an Excel file With dsp-tools, the properties section used in a data model (JSON) can be created from an Excel file. Only the first worksheet of the Excel file is considered and only XLSX files are allowed. The properties section can be inserted into the ontology file and then be uploaded onto a DSP server. An Excel file template can be found here . It is recommended to work from the template. The Excel sheet must have the following structure: The expected columns are: name : The name of the property super : The base property of the property object : If the property is derived from hasValue , the type of the property must be further specified by the object it takes, e.g. TextValue , ListValue , or IntValue . If the property is derived from hasLinkTo , the object specifies the resource class that this property refers to. en , de , fr , it : The labels of the property in different languages, at least one language has to be provided comment_en , comment_de , comment_fr , comment_it : optional comments in the respective language gui_element : The GUI element for the property hlist : In case of list values: the name of the list For further information about properties, see here . Create a DSP-conform XML file from an Excel file [not yet implemented] Create a list from one or several Excel files With dsp-tools, a JSON list can be created from one or several Excel files. The list can then be inserted into a JSON ontology and uploaded to a DSP server. It is possible to create multilingual lists. In this case, a separate Excel file has to be created for each language. The data must be in the first worksheet of each Excel file. It is important that all the Excel lists have the same structure. So, the translation of a label in one Excel sheet has to be in the exact same cell than the original was in the other Excel sheet (i.e. same cell index). It is recommended to work from the following templates: description_en.xlsx : The English list \"description\" Beschreibung_de.xlsx : Its German counterpart \"Beschreibung\" The Excel sheets must have the following structure: Only Excel files with file extension .xlsx are considered. All Excel files have to be located in the same directory. When calling the excel command, this folder is provided as an argument to the call. The language of the labels has to be provided in the Excel file's file name after an underline and before the file extension, e.g. Beschreibung_de.xlsx would be considered a list with German ( de ) labels, description_en.xlsx a list with English ( en ) labels. The language has to be one of {de, en, fr, it}. The following example shows how to create a JSON list from two Excel files which are in a directory called listfolder . The output is written to the file list.json . dsp-tools excel listfolder list.json The two Excel files Beschreibung_de.xlsx and description_en.xlsx are located in a folder called listfolder . listfolder |__ Beschreibung_de.xlsx |__ description_en.xlsx For each list node, the labels are read from the Excel files. The language code, provided in the file name, is then used for the labels. As node name, a simplified version of the English label is taken if English is one of the available languages. If English is not available, one of the other languages is chosen (which one depends on the representation of the file order). If there are two node names with the same name, an incrementing number is appended to the name . { \"name\": \"description\", \"labels\": { \"de\": \"Beschreibung\", \"en\": \"description\" }, \"nodes\": [ { \"name\": \"first-sublist\", \"labels\": { \"de\": \"erste Unterliste\", \"en\": \"first sublist\" }, \"nodes\": [ { \"name\": \"first-subnode\", \"labels\": { \"de\": \"erster Listenknoten\", \"en\": \"first subnode\" }, \"nodes\": [ { ... } ] }, ... ] } ] } After the creation of the list, a validation against the JSON schema for lists is performed. An error message is printed out if the list is not valid. Furthermore, it is checked that no two nodes are the same.","title":"Excel file processing"},{"location":"DSP-TOOLS/dsp-tools-excel/#excel-files-for-data-modelling-and-data-import","text":"dsp-tools is able to process Excel files and output the appropriate JSON or XML file. The JSON/XML file can then be used to create the ontology on the DSP server or import data to the DSP repository. dsp-tools can also be used to create a list from an Excel file.","title":"Excel files for data modelling and data import"},{"location":"DSP-TOOLS/dsp-tools-excel/#create-the-resources-for-a-data-model-from-an-excel-file","text":"With dsp-tools, the resources section used in a data model (JSON) can be created from an Excel file. Only XLSX files are allowed. The resources section can be inserted into the ontology file and then be uploaded onto a DSP server. An Excel file template can be found here . It is recommended to work from the template. The expected worksheets of the Excel file are: classes : a table with all resource classes intended to be used in the resulting JSON class1 , class2 ,...: a table for each resource class named after its name The Excel sheet must have the following structure. The worksheet called classes has the following structure: The expected columns are: name : The name of the resource en , de , fr , it : The labels of the resource in different languages, at least one language has to be provided comment_en , comment_de , comment_fr , comment_it : optional comments in the respective language super : The base class of the resource All other worksheets, one for each resource class, have the following structure: { width=50% } The expected columns are: Property : The name of the property Cardinality : The cardinality, one of: 1 , 0-1 , 1-n , 0-n The GUI order is given by the order in which the properties are listed in the Excel sheet. For further information about resources, see here .","title":"Create the resources for a data model from an Excel file"},{"location":"DSP-TOOLS/dsp-tools-excel/#create-the-properties-for-a-data-model-from-an-excel-file","text":"With dsp-tools, the properties section used in a data model (JSON) can be created from an Excel file. Only the first worksheet of the Excel file is considered and only XLSX files are allowed. The properties section can be inserted into the ontology file and then be uploaded onto a DSP server. An Excel file template can be found here . It is recommended to work from the template. The Excel sheet must have the following structure: The expected columns are: name : The name of the property super : The base property of the property object : If the property is derived from hasValue , the type of the property must be further specified by the object it takes, e.g. TextValue , ListValue , or IntValue . If the property is derived from hasLinkTo , the object specifies the resource class that this property refers to. en , de , fr , it : The labels of the property in different languages, at least one language has to be provided comment_en , comment_de , comment_fr , comment_it : optional comments in the respective language gui_element : The GUI element for the property hlist : In case of list values: the name of the list For further information about properties, see here .","title":"Create the properties for a data model from an Excel file"},{"location":"DSP-TOOLS/dsp-tools-excel/#create-a-dsp-conform-xml-file-from-an-excel-file","text":"[not yet implemented]","title":"Create a DSP-conform XML file from an Excel file"},{"location":"DSP-TOOLS/dsp-tools-excel/#create-a-list-from-one-or-several-excel-files","text":"With dsp-tools, a JSON list can be created from one or several Excel files. The list can then be inserted into a JSON ontology and uploaded to a DSP server. It is possible to create multilingual lists. In this case, a separate Excel file has to be created for each language. The data must be in the first worksheet of each Excel file. It is important that all the Excel lists have the same structure. So, the translation of a label in one Excel sheet has to be in the exact same cell than the original was in the other Excel sheet (i.e. same cell index). It is recommended to work from the following templates: description_en.xlsx : The English list \"description\" Beschreibung_de.xlsx : Its German counterpart \"Beschreibung\" The Excel sheets must have the following structure: Only Excel files with file extension .xlsx are considered. All Excel files have to be located in the same directory. When calling the excel command, this folder is provided as an argument to the call. The language of the labels has to be provided in the Excel file's file name after an underline and before the file extension, e.g. Beschreibung_de.xlsx would be considered a list with German ( de ) labels, description_en.xlsx a list with English ( en ) labels. The language has to be one of {de, en, fr, it}. The following example shows how to create a JSON list from two Excel files which are in a directory called listfolder . The output is written to the file list.json . dsp-tools excel listfolder list.json The two Excel files Beschreibung_de.xlsx and description_en.xlsx are located in a folder called listfolder . listfolder |__ Beschreibung_de.xlsx |__ description_en.xlsx For each list node, the labels are read from the Excel files. The language code, provided in the file name, is then used for the labels. As node name, a simplified version of the English label is taken if English is one of the available languages. If English is not available, one of the other languages is chosen (which one depends on the representation of the file order). If there are two node names with the same name, an incrementing number is appended to the name . { \"name\": \"description\", \"labels\": { \"de\": \"Beschreibung\", \"en\": \"description\" }, \"nodes\": [ { \"name\": \"first-sublist\", \"labels\": { \"de\": \"erste Unterliste\", \"en\": \"first sublist\" }, \"nodes\": [ { \"name\": \"first-subnode\", \"labels\": { \"de\": \"erster Listenknoten\", \"en\": \"first subnode\" }, \"nodes\": [ { ... } ] }, ... ] } ] } After the creation of the list, a validation against the JSON schema for lists is performed. An error message is printed out if the list is not valid. Furthermore, it is checked that no two nodes are the same.","title":"Create a list from one or several Excel files"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/","text":"Information for developers There is a Makefile for all the following tasks (and more). Type make to print the available targets. Install from source To install from source run: python3 setup.py install Install the requirements To install the requirements run: pip3 install -r requirements.txt To generate a requirements file (usually requirements.txt), that you commit with your project, run: pip3 freeze > requirements.txt Testing Please note that testing requires launching the complete DSP API stack which is based on docker images. Therefore, we recommend installing the docker desktop client . To run the complete test suite: make test Code style When contributing to the project please make sure you use the same code style rules as we do. We use autopep8 and mypy . The configuration is defined in pyproject.toml in the root directory of the project. [tool.autopep8] max_line_length = 180 experimental = true [tool.mypy] ignore_missing_imports = true follow_imports = \"silent\" show_column_numbers = true strict = true You can use the configuration with autopep8 --global-config pyproject.toml --in-place $FilePath$ and mypy --config-file pyproject.toml [file path] . If you are using PyCharm we recommend installing autopep8 as external tool. You can then use it with right-click on the file > External Tools > autopep8 to reformat files in-place. mypy is available as plugin . For formatting Markdown files (*.md) we use the default styling configuration provided by PyCharm. Publishing Publishing is automated with GitHub Actions and should not be done manually. Please follow the Pull Request Guidelines . If done correctly, when merging a pull request into main , the release-please action will create or update a pull request for a release. This pull request will follow semantic versioning and update the change log. Once all desired features are merged, the release can be executed by merging this release pull request into main . This will trigger actions that create a release on GitHub, on PyPI and the docs. Please ensure you have only one pull request per feature. Publishing manually Publishing is automated with GitHub Actions and should not be done manually. If you still need to do it, follow the steps below. Generate the distribution package. Make sure you have the latest versions of setuptools and wheel installed: python3 -m pip install --upgrade pip setuptools wheel python3 setup.py sdist bdist_wheel You can install the package locally from the dist: python3 -m pip ./dist/some_name.whl Upload package works also with make : make dist make upload For local development: python3 setup.py develop Contributing to the documentation The documentation is a collection of markdown files in the docs folder. After updates of the files, build and check the result with the following commands: make docs-build make docs-serve To update the changes to the official documentation pages run: make docs-publish","title":"Information for developers"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/#information-for-developers","text":"There is a Makefile for all the following tasks (and more). Type make to print the available targets.","title":"Information for developers"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/#install-from-source","text":"To install from source run: python3 setup.py install","title":"Install from source"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/#install-the-requirements","text":"To install the requirements run: pip3 install -r requirements.txt To generate a requirements file (usually requirements.txt), that you commit with your project, run: pip3 freeze > requirements.txt","title":"Install the requirements"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/#testing","text":"Please note that testing requires launching the complete DSP API stack which is based on docker images. Therefore, we recommend installing the docker desktop client . To run the complete test suite: make test","title":"Testing"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/#code-style","text":"When contributing to the project please make sure you use the same code style rules as we do. We use autopep8 and mypy . The configuration is defined in pyproject.toml in the root directory of the project. [tool.autopep8] max_line_length = 180 experimental = true [tool.mypy] ignore_missing_imports = true follow_imports = \"silent\" show_column_numbers = true strict = true You can use the configuration with autopep8 --global-config pyproject.toml --in-place $FilePath$ and mypy --config-file pyproject.toml [file path] . If you are using PyCharm we recommend installing autopep8 as external tool. You can then use it with right-click on the file > External Tools > autopep8 to reformat files in-place. mypy is available as plugin . For formatting Markdown files (*.md) we use the default styling configuration provided by PyCharm.","title":"Code style"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/#publishing","text":"Publishing is automated with GitHub Actions and should not be done manually. Please follow the Pull Request Guidelines . If done correctly, when merging a pull request into main , the release-please action will create or update a pull request for a release. This pull request will follow semantic versioning and update the change log. Once all desired features are merged, the release can be executed by merging this release pull request into main . This will trigger actions that create a release on GitHub, on PyPI and the docs. Please ensure you have only one pull request per feature.","title":"Publishing"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/#publishing-manually","text":"Publishing is automated with GitHub Actions and should not be done manually. If you still need to do it, follow the steps below. Generate the distribution package. Make sure you have the latest versions of setuptools and wheel installed: python3 -m pip install --upgrade pip setuptools wheel python3 setup.py sdist bdist_wheel You can install the package locally from the dist: python3 -m pip ./dist/some_name.whl Upload package works also with make : make dist make upload For local development: python3 setup.py develop","title":"Publishing manually"},{"location":"DSP-TOOLS/dsp-tools-information-for-developers/#contributing-to-the-documentation","text":"The documentation is a collection of markdown files in the docs folder. After updates of the files, build and check the result with the following commands: make docs-build make docs-serve To update the changes to the official documentation pages run: make docs-publish","title":"Contributing to the documentation"},{"location":"DSP-TOOLS/dsp-tools-usage/","text":"Installation and usage The following paragraphs gives you an overview of how to install and use dsp-tools. Installation To install the latest version run: pip3 install dsp-tools To update to the latest version run: pip3 install --upgrade dsp-tools Create a data model on a DSP server dsp-tools create [options] data_model_definition.json The following options are available: -s | --server server : URL of the DSP server (default: 0.0.0.0:3333) -u | --user username : username used for authentication with the DSP API (default: root@example.com) -p | --password password : password used for authentication with the DSP API (default: test) -V | --validate : If set, only the validation of the JSON file is performed. -l | --lists : If set, only the lists are created using a simplified schema . Please note that in this case the project must already exist. -v | --verbose : If set, some information about the progress is printed to the console. The command is used to read the definition of a data model (provided in a JSON file) and create it on the DSP server. The following example shows how to load the ontology defined in data_model_definition.json onto the DSP server https://api.dsl.server.org provided with the -s option. The username root@example.com and the password test are used. dsp-tools create -s https://api.dsl.server.org -u root@example.com -p test data_model_definition.json The description of the expected JSON format can be found here . Get a data model from a DSP server dsp-tools get [options] output_file.json The following options are available: -s | --server server : URL of the DSP server (default: 0.0.0.0:3333) -u | --user username : username used for authentication with the DSP API (default: root@example.com) -p | --password password : password used for authentication with the DSP API (default: test) -P | --project shortcode | shortname | iri : shortcode, shortname or (mandatory) IRI of the project -v | --verbose : If set, some information about the progress is printed to the console. The command is used to get the definition of a data model from a DSP server and write it into a JSON file. This JSON file could then be used to upload the data model to another DSP server. The following example shows how to get the data model from a DSP server https://api.dsl.server.org provided with the -s option. The username root@example.com and the password test are used. The data model is saved into the output file output_file.json . dsp-tools get -s https://api.dsl.server.org -u root@example.com -p test -P my_project output_file.json Upload data to a DSP server dsp-tools xmlupload [options] xml_data_file.xml The following options are available: -s | --server server : URL of the DSP server (default: 0.0.0.0:3333) -u | --user username : username used for authentication with the DSP API (default: root@example.com) -p | --password password : password used for authentication with the DSP API (default: test) -V | --validate : If set, only the validation of the XML file is performed. -i | --imgdir dirpath : path to the directory where the bitstream objects are stored (default: .) -S | --sipi SIPIserver : URL of the SIPI IIIF server (default: http://0.0.0.0:1024) -I | --incremental : If set, IRIs instead of internal IDs are expected as reference to already existing resources on DSP -v | --verbose : If set, more information about the uploaded resources is printed to the console. The command is used to upload data defined in an XML file onto a DSP server. The following example shows how to upload data from an XML file xml_data_file.xml onto the DSP server https://api.dsl.server.org provided with the -s option. The username root@example.com and the password test are used. The interface for the SIPI IIIF server is provided with the -S option ( https://iiif.dsl.server.org ). dsp-tools xmlupload -s https://api.dsl.server.org -u root@example.com -p test -S https://iiif.dsl.server.org xml_data_file.xml The description of the expected XML format can be found here . An internal ID is used in the <resptr> tag of an XML file used for xmlupload to reference resources inside the same XML file. Once data is uploaded to DSP it cannot be referenced by this internal ID anymore. Instead, the resource's IRI has to be used. The mapping of internal IDs to their respective IRIs is written to a file called id2iri_mapping_[timstamp].json after a successful xmlupload . See dsp-tools id2iri for more information about how to use this file to replace internal IDs in an existing XML file to reference existing resources. Create a JSON list file from one or several Excel files dsp-tools excel [option] folder_with_excel_files output_file.json The following option is available: -l | --listname listname : name to be used for the list (filename before last occurrence of _ is used if omitted) The command is used to create a JSON list file from one or several Excel files. It is possible to create multilingual lists. Therefore, an Excel file for each language has to be provided. The data has to be in the first worksheet of the Excel file and all Excel files have to be in the same directory. When calling the excel command, this directory has to be provided as an argument to the call. The following example shows how to create a JSON list from Excel files in a directory called lists . dsp-tools excel lists list.json The description of the expected Excel format can be found here . More information about the usage of this command can be found here . Create resources from an Excel file dsp-tools excel2resources excel_file.xlsx output_file.json The command is used to create the resources section of an ontology from an Excel file. Therefore, an Excel file has to be provided with the data in the first worksheet of the Excel file. The following example shows how to create the resources section from an Excel file called Resources.xlsx . The output is written to a file called resources.json . dsp-tools excel2resources Resources.xlsx resources.json More information about the usage of this command can be found here . Create properties from an Excel file dsp-tools excel2properties excel_file.xlsx output_file.json The command is used to create the properties section of an ontology from an Excel file. Therefore, an Excel file has to be provided with the data in the first worksheet of the Excel file. The following example shows how to create the properties section from an Excel file called Properties.xlsx . The output is written to a file called properties.json . dsp-tools excel2properties Properties.xlsx properties.json More information about the usage of this command can be found here . Replace internal IDs with IRIs in XML file dsp-tools id2iri xml_file.xml mapping_file.json --outfile xml_out_file.xml When uploading data with dsp-tools xmlupload an internal ID is used in the <resptr> tag of the XML file to reference resources inside the same XML file. Once data is uploaded to DSP it cannot be referenced by this internal ID anymore. Instead, the resource's IRI has to be used. With dsp-tools id2iri internal IDs can be replaced with their corresponding IRIs within a provided XML. The output is written to a new XML file called id2iri_replaced_[timestamp].xml (the file path and name can be overwritten with option --outfile ). If all internal IDs were replaced, the newly created XML can be used with dsp-tools xmlupload --incremental id2iri_replaced_20211026_120247263754.xml to upload the data. Note that internal IDs and IRIs cannot be mixed. The input XML file has to be provided as well as the JSON file which contains the mapping from internal IDs to IRIs. This JSON file is generated after each successful xmlupload . In order to upload data incrementally the procedure described here is recommended.","title":"Installation and usage"},{"location":"DSP-TOOLS/dsp-tools-usage/#installation-and-usage","text":"The following paragraphs gives you an overview of how to install and use dsp-tools.","title":"Installation and usage"},{"location":"DSP-TOOLS/dsp-tools-usage/#installation","text":"To install the latest version run: pip3 install dsp-tools To update to the latest version run: pip3 install --upgrade dsp-tools","title":"Installation"},{"location":"DSP-TOOLS/dsp-tools-usage/#create-a-data-model-on-a-dsp-server","text":"dsp-tools create [options] data_model_definition.json The following options are available: -s | --server server : URL of the DSP server (default: 0.0.0.0:3333) -u | --user username : username used for authentication with the DSP API (default: root@example.com) -p | --password password : password used for authentication with the DSP API (default: test) -V | --validate : If set, only the validation of the JSON file is performed. -l | --lists : If set, only the lists are created using a simplified schema . Please note that in this case the project must already exist. -v | --verbose : If set, some information about the progress is printed to the console. The command is used to read the definition of a data model (provided in a JSON file) and create it on the DSP server. The following example shows how to load the ontology defined in data_model_definition.json onto the DSP server https://api.dsl.server.org provided with the -s option. The username root@example.com and the password test are used. dsp-tools create -s https://api.dsl.server.org -u root@example.com -p test data_model_definition.json The description of the expected JSON format can be found here .","title":"Create a data model on a DSP server"},{"location":"DSP-TOOLS/dsp-tools-usage/#get-a-data-model-from-a-dsp-server","text":"dsp-tools get [options] output_file.json The following options are available: -s | --server server : URL of the DSP server (default: 0.0.0.0:3333) -u | --user username : username used for authentication with the DSP API (default: root@example.com) -p | --password password : password used for authentication with the DSP API (default: test) -P | --project shortcode | shortname | iri : shortcode, shortname or (mandatory) IRI of the project -v | --verbose : If set, some information about the progress is printed to the console. The command is used to get the definition of a data model from a DSP server and write it into a JSON file. This JSON file could then be used to upload the data model to another DSP server. The following example shows how to get the data model from a DSP server https://api.dsl.server.org provided with the -s option. The username root@example.com and the password test are used. The data model is saved into the output file output_file.json . dsp-tools get -s https://api.dsl.server.org -u root@example.com -p test -P my_project output_file.json","title":"Get a data model from a DSP server"},{"location":"DSP-TOOLS/dsp-tools-usage/#upload-data-to-a-dsp-server","text":"dsp-tools xmlupload [options] xml_data_file.xml The following options are available: -s | --server server : URL of the DSP server (default: 0.0.0.0:3333) -u | --user username : username used for authentication with the DSP API (default: root@example.com) -p | --password password : password used for authentication with the DSP API (default: test) -V | --validate : If set, only the validation of the XML file is performed. -i | --imgdir dirpath : path to the directory where the bitstream objects are stored (default: .) -S | --sipi SIPIserver : URL of the SIPI IIIF server (default: http://0.0.0.0:1024) -I | --incremental : If set, IRIs instead of internal IDs are expected as reference to already existing resources on DSP -v | --verbose : If set, more information about the uploaded resources is printed to the console. The command is used to upload data defined in an XML file onto a DSP server. The following example shows how to upload data from an XML file xml_data_file.xml onto the DSP server https://api.dsl.server.org provided with the -s option. The username root@example.com and the password test are used. The interface for the SIPI IIIF server is provided with the -S option ( https://iiif.dsl.server.org ). dsp-tools xmlupload -s https://api.dsl.server.org -u root@example.com -p test -S https://iiif.dsl.server.org xml_data_file.xml The description of the expected XML format can be found here . An internal ID is used in the <resptr> tag of an XML file used for xmlupload to reference resources inside the same XML file. Once data is uploaded to DSP it cannot be referenced by this internal ID anymore. Instead, the resource's IRI has to be used. The mapping of internal IDs to their respective IRIs is written to a file called id2iri_mapping_[timstamp].json after a successful xmlupload . See dsp-tools id2iri for more information about how to use this file to replace internal IDs in an existing XML file to reference existing resources.","title":"Upload data to a DSP server"},{"location":"DSP-TOOLS/dsp-tools-usage/#create-a-json-list-file-from-one-or-several-excel-files","text":"dsp-tools excel [option] folder_with_excel_files output_file.json The following option is available: -l | --listname listname : name to be used for the list (filename before last occurrence of _ is used if omitted) The command is used to create a JSON list file from one or several Excel files. It is possible to create multilingual lists. Therefore, an Excel file for each language has to be provided. The data has to be in the first worksheet of the Excel file and all Excel files have to be in the same directory. When calling the excel command, this directory has to be provided as an argument to the call. The following example shows how to create a JSON list from Excel files in a directory called lists . dsp-tools excel lists list.json The description of the expected Excel format can be found here . More information about the usage of this command can be found here .","title":"Create a JSON list file from one or several Excel files"},{"location":"DSP-TOOLS/dsp-tools-usage/#create-resources-from-an-excel-file","text":"dsp-tools excel2resources excel_file.xlsx output_file.json The command is used to create the resources section of an ontology from an Excel file. Therefore, an Excel file has to be provided with the data in the first worksheet of the Excel file. The following example shows how to create the resources section from an Excel file called Resources.xlsx . The output is written to a file called resources.json . dsp-tools excel2resources Resources.xlsx resources.json More information about the usage of this command can be found here .","title":"Create resources from an Excel file"},{"location":"DSP-TOOLS/dsp-tools-usage/#create-properties-from-an-excel-file","text":"dsp-tools excel2properties excel_file.xlsx output_file.json The command is used to create the properties section of an ontology from an Excel file. Therefore, an Excel file has to be provided with the data in the first worksheet of the Excel file. The following example shows how to create the properties section from an Excel file called Properties.xlsx . The output is written to a file called properties.json . dsp-tools excel2properties Properties.xlsx properties.json More information about the usage of this command can be found here .","title":"Create properties from an Excel file"},{"location":"DSP-TOOLS/dsp-tools-usage/#replace-internal-ids-with-iris-in-xml-file","text":"dsp-tools id2iri xml_file.xml mapping_file.json --outfile xml_out_file.xml When uploading data with dsp-tools xmlupload an internal ID is used in the <resptr> tag of the XML file to reference resources inside the same XML file. Once data is uploaded to DSP it cannot be referenced by this internal ID anymore. Instead, the resource's IRI has to be used. With dsp-tools id2iri internal IDs can be replaced with their corresponding IRIs within a provided XML. The output is written to a new XML file called id2iri_replaced_[timestamp].xml (the file path and name can be overwritten with option --outfile ). If all internal IDs were replaced, the newly created XML can be used with dsp-tools xmlupload --incremental id2iri_replaced_20211026_120247263754.xml to upload the data. Note that internal IDs and IRIs cannot be mixed. The input XML file has to be provided as well as the JSON file which contains the mapping from internal IDs to IRIs. This JSON file is generated after each successful xmlupload . In order to upload data incrementally the procedure described here is recommended.","title":"Replace internal IDs with IRIs in XML file"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/","text":"DSP XML file format for importing data With dsp-tools, data can be imported into a DSP repository (on a DSP server) from an XML file. The import file is a standard XML file as described on this page. After a successful upload of the data, an output file is written (called id2iri_mapping_[timstamp].json ) with the mapping from the internal IDs used inside the XML to their corresponding IRIs which uniquely identify them inside DSP. This file should be kept if data is later added with the --incremental option . The import file must start with the standard XML header: <?xml version='1.0' encoding='utf-8'?> The root element <knora> The <knora> element describes all resources that should be imported. It has the following attributes: xmlns : \"https://dasch.swiss/schema\" (required) xmlns:xsi : \"http://www.w3.org/2001/XMLSchema-instance\" (required) xsi:schemaLocation : \"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/data.xsd\" ( required) shortcode : project shortcode, e.g. \"0801\" (required) default-ontology : name of the ontology (required) The <knora> element may look as follows: <knora xmlns=\"https://dasch.swiss/schema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/data.xsd\" shortcode=\"0806\" default-ontology=\"webern\"> ... </knora> The <knora> element can only contain the following sub-elements: <permissions> (optional) <resource> Describing permissions with <permissions> elements The DSP server provides access control for each resource and each field of a resource through permissions. For a thorough explanation of the permission and access system of the DSP platform, see DSP platform permissions . It is optional to define permissions in the XML. If not defined, default permissions are applied (only project and system administrators can view and edit resources). The following access rights are defined by the DSP platform which apply to either a resource or a field: RV restricted view permission : The user gets only a restricted view of the element. E.g. in case of a still image resource, the image is displayed at reduced resolution or with a watermark overlay. V view permission : The user has read access to the element. M modifiy permission : The user may modify the element, but may not delete it. D delete permission : The user is allowed to delete the element. CR change right permission : The user may change the permission of the element. The user does not hold the permissions directly, but may belong to an arbitrary number of groups which hold the permissions. By default, the following groups always exist, and each user belongs to at least one of them: UnknownUser : The user is not known to the DSP platform (not logged in). KnownUser : The user is known (performed login), but is not a member of the project the data element belongs to. ProjectMember : The user belongs to the same project as the data element. ProjectAdmin : The user is project administrator in the project the data element belongs to. Creator : The user is the owner of the element (created the element). SystemAdmin : The user is a system administrator. In addition, more groups with arbitrary names can be created by a project admin. For referencing a group, the project name has to be prepended before the group name, separated by a colon, e.g. dsp-test:MlsEditors . A <permissions> element contains the permissions given to the selected groups and is called a permission set . It has a mandatory attribute id and must contain at least one <allow> element per group indicating the group's permission. The permission is referenced inside the resource or property tag by its id . It is of the following form: <permissions id=\"res-default\"> <allow group=\"UnknownUser\">RV</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"ProjectAdmin\">CR</allow> <allow group=\"Creator\">CR</allow> <allow group=\"dsp-test:MlsEditors\">D</allow> </permissions> If you don't want a group to have access at all, leave it out. In the following example, only ProjectAdmin s will see the resource or property with permission special-permission : <permissions id=\"special-permission\"> <allow group=\"ProjectAdmin\">CR</allow> </permissions> Note: The permissions defined in the XML are applied to resources that are created. But only project or system administrators do have the permission to create resources via the XML upload. The <allow> sub-element The <allow> element is used to define the permission for a specific group. It is of the following form: <allow group=\"ProjectAdmin\">CR</allow> The allowed values are: RV restricted view : Same as V but if it is applied to an image, the image is shown blurred. V view : The user can view a resource or a value, but can not modify it. M modify : The user can modify a resource or value, but can not delete it. The original resource or value will be preserved. D delete : The user can mark a resource or value as deleted. The original resource or value will be preserved. CR change right : The user can change the permission of a resource or value. The user is also allowed to permanently delete (erase) a resource. The group attribute is mandatory. It defines the group which the permission is applied to. DSP system groups as well as project specific groups are supported. A project specific group name has the form project-shortname:groupname . The available system groups are: UnknownUser (not logged in user) KnownUser (logged in user) ProjectMember (user with project membership) Creator (creator of the resource or value) ProjectAdmin (user with project admin membership) SystemAdmin (system administrator) There are no sub-elements allowed for the <allow> element. Example for a permissions section A complete <permissions> section may look as follows: <knora xmlns=\"https://dasch.swiss/schema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/data.xsd\" shortcode=\"0806\" default-ontology=\"webern\"> <permissions id=\"res-default\"> <allow group=\"UnknownUser\">RV</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> </permissions> <permissions id=\"res-restricted\"> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> </permissions> <permissions id=\"prop-default\"> <allow group=\"UnknownUser\">V</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> </permissions> <permissions id=\"prop-restricted\"> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> </permissions> ... </knora> Describing resources with the <resource> element A <resource> element contains all necessary information to create a resource. It has the following attributes: label : a human-readable, preferably meaningful short name of the resource (required) restype : the resource type as defined within the ontology (required) id : a unique, arbitrary string providing a unique ID to the resource in order to be referencable by other resources; the ID is only used during the import process and later replaced by the IRI used internally by DSP (required) permissions : a reference to a permission set; the permissions will be applied to the created resource (optional) iri : a custom IRI used when migrating existing resources (optional) ark : a version 0 ARK used when migrating existing resources from salsah.org to DSP (optional), it is not possible to use iri and ark in the same resource. When ark is used, it overrides iri . A complete <resource> element may look as follows: <resource label=\"EURUS015a\" restype=\":Postcard\" id=\"238807\" permissions=\"res-def-perm\"> ... </resource> The <resource> element contains a property element (e.g. <text-prop> ) for each property class (i.e. data field) describing the resource. The property element itself contains one or several value elements (e.g. <text> ) and must have an attribute name with the name of the property as defined in the project specific ontology. Example for a property element of type text ( <text-prop> ) with two value elements <text> : <text-prop name=\":hasTranslation\"> <text encoding=\"utf8\">Dies ist eine \u00dcbersetzung.</text> <text encoding=\"utf8\">Dies ist eine weitere \u00dcbersetzung.</text> </text-prop> \u26a0 Look out In case of a cardinality 1-n, multiple <text> tags have to be created inside the <text-prop> tag (do not use multiple <text-prop> tags). The following property elements exist: <bitstream> : contains a path to a file (if the resource is a multimedia resource) <boolean-prop> : contains a boolean value <color-prop> : contains color values <date-prop> : contains date values <decimal-prop> : contains decimal values <geometry-prop> : contains JSON geometry definitions for a region <geoname-prop> : contains geonames.org location codes <list-prop> : contains list element labels <iconclass-prop> : contains iconclass.org codes (not yet implemented) <integer-prop> : contains integer values <interval-prop> : contains interval values <period-prop> : contains time period values (not yet implemented) <resptr-prop> : contains links to other resources <text-prop> : contains text values <time-prop> : contains time values <uri-prop> : contains URI values <bitstream> The <bitstream> element is used for bitstream data. It contains the path to a bitstream object like an image file, a ZIP container, an audio file etc. It must only be used if the resource is a StillImageRepresentation , an AudioRepresentation , a DocumentRepresentation etc. Note: There is only one <bitstream> element allowed per representation! The <bitstream> element must be the first element! Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) Example: <bitstream permissions=\"prop-restricted\">postcards/images/EURUS015a.jpg</bitstream> <boolean-prop> The <boolean-prop> element is used for boolean values. It must contain exactly one <boolean> element. Attributes: name : name of the property as defined in the ontology (required) <boolean> The <boolean> element must contain the string \"true\" or \"false\", or the numeral 1 (true) or 0 (false). Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <boolean-prop name=\":hasBoolean\"> <boolean>true</boolean> </boolean-prop> <boolean-prop name=\":hasBoolean\"> <boolean>0</boolean> </boolean-prop> <color-prop> The <color-prop> element is used for color values. It must contain at least one <color> element. Attributes: name : name of the property as defined in the ontology (required) <color> The <color> element is used to indicate a color value. The color has to be given in web-notation, that is a # followed by 3 or 6 hex numerals. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) A property with two color values would be defined as follows: <color-prop name=\":hasColor\"> <color>#00ff66</color> <color>#ff00ff</color> </color-prop> <date-prop> The <date-prop> element is used for date values. It must contain at least one <date> element. Attributes: name : name of the property as defined in the ontology (required) <date> the <date> element contains a DSP-specific date value. It has the following format: calendar:epoch:yyyy-mm-dd:epoch:yyyy-mm-dd calendar : either \"JULIAN\" or \"GREGORIAN\" (optional, default: GREGORIAN) epoch : either \"BCE\" or \"CE\" (optional, default CE) yyyy : year with four digits (required) mm : month with two digits (optional, e.g. 01, 02, ..., 12) dd : day with two digits (optional, e.g. 01, 02, ..., 31) If two dates are provided, the date is defined as range between the two dates. If the day is omitted, then the precision it month , if also the month is omitted, the precision is year . Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <date-prop name=\":hasDate\"> <date>GREGORIAN:CE:2014-01-31</date> </date-prop> <date-prop name=\":hasDate\"> <date>GREGORIAN:CE:1930-09-02:CE:1930-09-03</date> </date-prop> <decimal-prop> The <decimal-prop> element is used for decimal values. It must contain at least one <decimal> element. Attributes: name : name of the property as defined in the ontology (required) <decimal> The <decimal> element contains a decimal number. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <decimal-prop name=\":hasDecimal\"> <decimal>3.14159</decimal> </decimal-prop> <geometry-prop> The <geometry-prop> element is used for a geometric definition of a 2-D region (e.g. a region on an image). It must contain at least one <geometry> element. Note: Usually these are not created by an import and should be used with caution! Attributes: name : name of the property as defined in the ontology (required) <geometry> A geometry value is defined as a JSON object. It contains the following data: status : \"active\" or \"deleted\" type : \"circle\", \"rectangle\" or \"polygon\" lineColor : web-color lineWidth : integer number (in pixels) points : array of coordinate objects of the form {\"x\": decimal, \"y\": decimal} radius : coordinate object of the form {\"x\": decimal, \"y\": decimal} Please note that all coordinates are normalized coordinates (relative to the image size) between 0.0 and 1.0! The following example defines a polygon: { \"status\": \"active\", \"type\": \"polygon\", \"lineColor\": \"#ff3333\", \"lineWidth\": 2, \"points\": [{\"x\": 0.17252396166134185, \"y\": 0.1597222222222222}, {\"x\": 0.8242811501597445, \"y\": 0.14583333333333334}, {\"x\": 0.8242811501597445, \"y\": 0.8310185185185185}, {\"x\": 0.1757188498402556, \"y\": 0.8240740740740741}, {\"x\": 0.1757188498402556, \"y\": 0.1597222222222222}, {\"x\": 0.16932907348242812, \"y\": 0.16435185185185186}], \"original_index\": 0 } Example of a <geometry> element: <geometry-prop name=\":hasPolygon\"> <geometry>{\"status\":\"active\",\"type\"=\"circle\",\"lineColor\"=\"#ff0000\",\"lineWidth\"=2,\"points\":[{\"x\":0.5,\"y\":0.5}],\"radius\":{\"x\":0.1,\"y\":0.0}}</geometry> </geometry-prop> Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) <geoname-prop> The <geoname-prop> element is used for values that contain a geonames.org ID. It must contain at least one <geoname> element. Attributes: name : name of the property as defined in the ontology (required) <geoname> Contains a valid geonames.org ID. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example (city of Vienna): <geoname-prop name=\":hasLocation\"> <geoname>2761369</geoname> </geoname-prop> <list-prop> The <list-prop> element is used as entry point into a list (list node). List nodes are identified by their name attribute that was given when creating the list nodes (which must be unique within each list!). It must contain at least one <list> element. Attributes: name : name of the property as defined in the ontology (required) list : name of the list as defined in the ontology (required) <list> The <list> element references a node in a (pull-down or hierarchical) list. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <list-prop list=\"category\" name=\":hasCategory\"> <list>physics</list> </list-prop> <iconclass-prop> ( not yet implemented ) The <iconclass-prop> element is used for iconclass.org ID. It must contain at least one <iconclass> element. For example: 92E112 stands for (story of) Aurora (Eos); 'Aurora' (Ripa) - infancy, upbringing Aurora \u00b7 Ripa \u00b7 air \u00b7 ancient history \u00b7 child \u00b7 classical antiquity \u00b7 goddess \u00b7 gods \u00b7 heaven \u00b7 history \u00b7 infancy \u00b7 mythology \u00b7 sky \u00b7 upbringing \u00b7 youth Attributes: name : name of the property as defined in the ontology (required) <iconclass> ( not yet implemented ) References an iconclass.org ID. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Usage: <iconclass-prop name=\":hasIcon\"> <iconclass>92E112</iconclass> </iconclass-prop> <integer-prop> The <integer-prop> element is used for integer values. It must contain at least one <integer> element. Attributes: name : name of the property as defined in the ontology (required) <integer> The <integer> element contains an integer value. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <integer-prop name=\":hasInteger\"> <integer>4711</integer> </integer-prop> <interval-prop> The <interval-prop> element is used for intervals with a start and an end point on a timeline, e.g. relative to the beginning of an audio or video file. An <interval-prop> must contain at least one <interval> element. Attributes: name : name of the property as defined in the ontology (required) <interval> A time interval is represented by plain decimal numbers (=seconds), without a special notation for minutes and hours. The <interval> element contains two decimals separated by a colon ( : ). The places before the decimal point are seconds, and the places after the decimal points are fractions of a second. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <interval-prop name=\":hasInterval\"> <interval>60.5:120.5</interval> <!-- 0:01:00.5 - 0:02:00.5 --> <interval>61:3600</interval> <!-- 0:01:01 - 1:00:00 --> </interval-prop> <resptr-prop> The <resptr-prop> element is used to link other resources within DSP. It must contain at least one <resptr> element. Attributes: name : name of the property as defined in the ontology (required) <resptr> The <resptr> element contains either the internal ID of another resource inside the XML or the IRI of an already existing resource on DSP. Inside the same XML file, a mixture of the two is not possible. If referencing existing resources, xmlupload --incremental has to be used. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: If there is a resource defined as <resource label=\"EURUS015a\" restype=\":Postcard\" id=\"238807\">...</resource> , it can be referenced as: <resptr-prop name=\":hasReferenceTo\"> <resptr>238807</resptr> </resptr-prop> <text-prop> The <text-prop> element is used for text values. It must contain at least one <text> element. Attributes: name : name of the property as defined in the ontology (required) <text> The <text> element has the following attributes: encoding : either \"utf8\" or \"xml\" (required) utf8 : The element describes a simple text without markup. The text is a simple UTF-8 string. xml : The element describes a complex text containing markup. It must follow the XML format as defined by the DSP standard mapping . permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) There are two variants of text: Simple (UTF8) and complex (XML). Within a text property, multiple simple and complex text values may be mixed. Both simple and complex text values can be used inside all gui_elements that are defined in an ontology (SimpleText, Richtext, Textarea, see here ). But typically, you would use UTF8 in a SimpleText, and XML in Richtext or Textarea. Simple text (UTF-8) An example for simple text: <text-prop name=\":hasComment\"> <text encoding=\"utf8\">Probe bei \"Wimberger\". Lokal in Wien?</text> </text-prop> If your text is very long, it is not advised to add XML-\"pretty-print\" whitespaces after line breaks. These whitespaces will be taken into the text field as they are. Text with markup (XML) dsp-tools assumes that for markup (standoff markup), the DSP standard mapping is used (custom mapping is not yet implemented). Example of a text containing a link to another resource: <text-prop name=\":hasComment\"> <text encoding=\"xml\" >The <strong>third</strong> object and a <a class=\"salsah-link\" href=\"IRI:obj_0003:IRI\">link</a>.</text> </text-prop> Please note that the href option within the anchor tag ( <a> ) points to an internal resource of the DSP and has to conform to the special format IRI:[res-id]:IRI where [res-id] is the resource id defined within the XML import file. <time-prop> The <time-prop> element is used for time values. It must contain at least one <time> element. Attributes: name : name of the property as defined in the ontology (required) <time> The <time> element represents an exact datetime value in the form of yyyy-mm-ddThh:mm:ss.sssssssssssszzzzzz . The following abbreviations describe this form: yyyy : a four-digit numeral that represents the year. The value cannot start with a minus (-) or a plus (+) sign. 0001 is the lexical representation of the year 1 of the Common Era (also known as 1 AD). The value cannot be 0000. mm : a two-digit numeral that represents the month dd : a two-digit numeral that represents the day hh : a two-digit numeral representing the hours. Must be between 0 and 23 mm : a two-digit numeral that represents the minutes ss : a two-digit numeral that represents the seconds ssssssssssss : If present, a 1-to-12-digit numeral that represents the fractional seconds (optional) zzzzzz : represents the time zone (required). Each part of the datetime value that is expressed as a numeric value is constrained to the maximum value within the interval that is determined by the next higher part of the datetime value. For example, the day value can never be 32 and cannot be 29 for month 02 and year 2002 (February 2002). The timezone is defined as follows: A plus (+) or minus (-) sign that is followed by hh:mm: + : Indicates that the specified time instant is in a time zone that is ahead of the UTC time by hh hours and mm minutes. - : Indicates that the specified time instant is in a time zone that is behind UTC time by hh hours and mm minutes. hh : a two-digit numeral (with leading zeros as required) that represents the hours. The value must be between -14 and +14, inclusive. mm : a two-digit numeral that represents the minutes. The value must be zero when hh is equal to 14. Z: The literal Z, which represents the time in UTC (Z represents Zulu time, which is equivalent to UTC). Specifying Z for the time zone is equivalent to specifying +00:00 or -00:00. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <time-prop name=\":hasTime\"> <time>2019-10-23T13:45:12Z</time> </time-prop> The following value indicates noon on October 10, 2009, Eastern Standard Time in the United States: <time-prop name=\":hasTime\"> <time>2009-10-10T12:00:00-05:00</time> </time-prop> <uri-prop> The <uri-prop> element is used for referencing resources with a URI. It must contain at least one <uri> element. Attributes: name : name of the property as defined in the ontology (required) <uri> The <uri> element contains a syntactically valid URI. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <uri-prop name=\":hasURI\"> <uri>http://www.groove-t-gang.ch</uri> </uri-prop> Incremental XML Upload After a successful upload of the data, an output file is written (called id2iri_mapping_[timstamp].json ) with the mapping of internal IDs used inside the XML and their corresponding IRIs which uniquely identify them inside DSP. This file should be kept if data is later added with the --incremental option. To do an incremental XML upload, one of the following procedures is recommended. Incremental XML upload with use of internal IDs: Initial XML upload with internal IDs. The file id2iri_mapping_[timestamp].json is created. Create new XML file(s) with resources referencing other resources by their internal IDs in <resptr> (using the same IDs as in the initial XML upload). Run dsp-tools id2iri new_data.xml id2iri_mapping_[timestamp].json to replace the internal IDs in new_data.xml with IRIs. Only internal IDs inside the <resptr> tag are replaced. Run dsp-tools xmlupload --incremental new_data.xml to upload the data to DSP. Incremental XML Upload with the use of IRIs: Use IRIs in the XML to reference existing data on the DSP server. Complete example <?xml version='1.0' encoding='utf-8'?> <knora xmlns=\"https://dasch.swiss/schema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/data.xsd\" shortcode=\"0001\" default-ontology=\"anything\"> <!-- permissions: see https://docs.dasch.swiss/DSP-API/05-internals/design/api-admin/administration/#permissions --> <permissions id=\"res-default\"> <allow group=\"UnknownUser\">RV</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> <allow group=\"anything:Thing searcher\">D</allow> </permissions> <permissions id=\"res-restricted\"> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow>> <allow group=\"ProjectAdmin\">CR</allow>> <allow group=\"anything:Thing searcher\">M</allow>> </permissions> <permissions id=\"prop-default\"> <allow group=\"UnknownUser\">V</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow>> <allow group=\"anything:Thing searcher\">D</allow>> </permissions> <permissions id=\"prop-restricted\"> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> <allow group=\"anything:Thing searcher\">M</allow> </permissions> <resource label=\"obj_inst1\" restype=\":BlueThing\" id=\"obj_0001\" permissions=\"res-default\"> <list-prop list=\"treelistroot\" name=\":hasListItem\"> <list permissions=\"prop-default\">Tree list node 02</list> </list-prop> <list-prop list=\"treelistroot\" name=\":hasOtherListItem\"> <list permissions=\"prop-default\">Tree list node 03</list> </list-prop> <text-prop name=\":hasRichtext\"> <text permissions=\"prop-default\" encoding=\"xml\" >The <strong>third</strong> object and a <a class=\"salsah-link\" href=\"IRI:obj_0003:IRI\">link</a> to.</text> </text-prop> <text-prop name=\":hasRichtext\"> <text permissions=\"prop-default\" encoding=\"xml\" >The <strong>third</strong> object and a <a class=\"salsah-link\" href=\"IRI:obj_0003:IRI\">link</a> to.</text> </text-prop> <text-prop name=\":hasText\"> <text permissions=\"prop-default\" encoding=\"utf8\">Dies ist ein einfacher Text ohne Markup</text> <text permissions=\"prop-restricted\" encoding=\"utf8\">Nochmals ein einfacher Text</text> </text-prop> <date-prop name=\":hasDate\"> <date permissions=\"prop-default\">JULIAN:CE:1401-05-17:CE:1402-01</date> </date-prop> <integer-prop name=\":hasInteger\"> <integer permissions=\"prop-default\">4711</integer> </integer-prop> <decimal-prop name=\":hasDecimal\"> <decimal permissions=\"prop-default\" comment=\"Eulersche Zahl\">2.718281828459</decimal> </decimal-prop> <boolean-prop name=\":hasBoolean\"> <boolean permissions=\"prop-default\">true</boolean> </boolean-prop> <uri-prop name=\":hasUri\"> <uri permissions=\"prop-default\">http://dasch.swiss/gaga</uri> </uri-prop> <interval-prop name=\":hasInterval\"> <interval permissions=\"prop-default\">12.5:14.2</interval> </interval-prop> <color-prop name=\":hasColor\"> <color permissions=\"prop-default\">#00ff00</color> </color-prop> <geometry-prop name=\":hasGeometry\"> <geometry permissions=\"prop-default\"> { \"status\":\"active\", \"lineColor\":\"#ff3333\", \"lineWidth\":2, \"points\":[ {\"x\":0.08098591549295775,\"y\":0.16741071428571427}, {\"x\":0.7394366197183099,\"y\":0.7299107142857143}], \"type\":\"rectangle\", \"original_index\":0 } </geometry> </geometry-prop> <geoname-prop name=\":hasGeoname\"> <geoname permissions=\"prop-default\" comment=\"A sacred place for railroad fans\">5416656</geoname> </geoname-prop> <resptr-prop name=\":hasBlueThing\"> <resptr permissions=\"prop-default\">obj_0002</resptr> </resptr-prop> </resource> <resource label=\"obj_inst2\" restype=\":BlueThing\" id=\"obj_0002\" permissions=\"res-default\"> <list-prop list=\"treelistroot\" name=\":hasListItem\"> <list permissions=\"prop-default\">Tree list node 10</list> </list-prop> <list-prop list=\"treelistroot\" name=\":hasOtherListItem\"> <list permissions=\"prop-default\">Tree list node 11</list> </list-prop> <text-prop name=\":hasRichtext\"> <text permissions=\"prop-default\" encoding=\"xml\">What is this <em>bold</em> thing?</text> </text-prop> <text-prop name=\":hasText\"> <text permissions=\"prop-default\" encoding=\"utf8\">aa bbb cccc ddddd</text> </text-prop> <date-prop name=\":hasDate\"> <date permissions=\"prop-default\">1888</date> </date-prop> <integer-prop name=\":hasInteger\"> <integer permissions=\"prop-default\">42</integer> </integer-prop> <decimal-prop name=\":hasDecimal\"> <decimal permissions=\"prop-default\" comment=\"Die Zahl PI\">3.14159</decimal> </decimal-prop> <boolean-prop name=\":hasBoolean\"> <boolean permissions=\"prop-default\">false</boolean> </boolean-prop> <uri-prop name=\":hasUri\"> <uri permissions=\"prop-default\">http://unibas.ch/gugus</uri> </uri-prop> <interval-prop name=\":hasInterval\"> <interval permissions=\"prop-default\">24:100.075</interval> </interval-prop> <color-prop name=\":hasColor\"> <color permissions=\"prop-default\">#33ff77</color> </color-prop> <geometry-prop name=\":hasGeometry\"> <geometry permissions=\"prop-default\"> { \"status\":\"active\", \"lineColor\":\"#ff3333\", \"lineWidth\":2, \"points\":[ {\"x\":0.08098591549295775,\"y\":0.16741071428571427}, {\"x\":0.7394366197183099,\"y\":0.7299107142857143}], \"type\":\"rectangle\", \"original_index\":0 } </geometry> </geometry-prop> <geoname-prop name=\":hasGeoname\"> <geoname permissions=\"prop-default\" comment=\"A sacred place for railroad fans\">5416656</geoname> </geoname-prop> <resptr-prop name=\":hasBlueThing\"> <resptr permissions=\"prop-default\">obj_0003</resptr> </resptr-prop> </resource> <resource label=\"obj_inst3\" restype=\":BlueThing\" id=\"obj_0003\" permissions=\"res-default\"> <list-prop list=\"treelistroot\" name=\":hasListItem\"> <list permissions=\"prop-default\">Tree list node 01</list> </list-prop> <list-prop list=\"treelistroot\" name=\":hasOtherListItem\"> <list permissions=\"prop-default\">Tree list node 02</list> </list-prop> <text-prop name=\":hasRichtext\"> <text permissions=\"prop-default\" encoding=\"xml\">This is <em>bold and <strong>string</strong></em> text!</text> </text-prop> <text-prop name=\":hasText\"> <text permissions=\"prop-default\" encoding=\"utf8\">aa bbb cccc ddddd</text> </text-prop> <date-prop name=\":hasDate\"> <date permissions=\"prop-default\">1888</date> </date-prop> <integer-prop name=\":hasInteger\"> <integer permissions=\"prop-default\">42</integer> </integer-prop> <decimal-prop name=\":hasDecimal\"> <decimal permissions=\"prop-default\" comment=\"Die Zahl PI\">3.14159</decimal> </decimal-prop> <boolean-prop name=\":hasBoolean\"> <boolean permissions=\"prop-default\">false</boolean> </boolean-prop> <uri-prop name=\":hasUri\"> <uri permissions=\"prop-default\">http://unibas.ch/gugus</uri> </uri-prop> <interval-prop name=\":hasInterval\"> <interval permissions=\"prop-default\">24:100.075</interval> </interval-prop> <color-prop name=\":hasColor\"> <color permissions=\"prop-default\">#33ff77</color> </color-prop> <geometry-prop name=\":hasGeometry\"> <geometry permissions=\"prop-default\"> { \"status\":\"active\", \"lineColor\":\"#ff3333\", \"lineWidth\":2, \"points\":[ {\"x\":0.08098591549295775,\"y\":0.16741071428571427}, {\"x\":0.7394366197183099,\"y\":0.7299107142857143}], \"type\":\"rectangle\", \"original_index\":0 } </geometry> </geometry-prop> <geoname-prop name=\":hasGeoname\"> <geoname permissions=\"prop-default\" comment=\"A sacred place for railroad fans\">5416656</geoname> </geoname-prop> </resource> <resource label=\"obj_inst4\" restype=\":ThingPicture\" id=\"obj_0004\" permissions=\"res-default\"> <bitstream>gaga.tif</bitstream> <text-prop name=\":hasPictureTitle\"> <text permissions=\"prop-default\" encoding=\"utf8\">This is the famous Lena</text> </text-prop> </resource> </knora>","title":"Bulk data import"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#dsp-xml-file-format-for-importing-data","text":"With dsp-tools, data can be imported into a DSP repository (on a DSP server) from an XML file. The import file is a standard XML file as described on this page. After a successful upload of the data, an output file is written (called id2iri_mapping_[timstamp].json ) with the mapping from the internal IDs used inside the XML to their corresponding IRIs which uniquely identify them inside DSP. This file should be kept if data is later added with the --incremental option . The import file must start with the standard XML header: <?xml version='1.0' encoding='utf-8'?>","title":"DSP XML file format for importing data"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#the-root-element-knora","text":"The <knora> element describes all resources that should be imported. It has the following attributes: xmlns : \"https://dasch.swiss/schema\" (required) xmlns:xsi : \"http://www.w3.org/2001/XMLSchema-instance\" (required) xsi:schemaLocation : \"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/data.xsd\" ( required) shortcode : project shortcode, e.g. \"0801\" (required) default-ontology : name of the ontology (required) The <knora> element may look as follows: <knora xmlns=\"https://dasch.swiss/schema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/data.xsd\" shortcode=\"0806\" default-ontology=\"webern\"> ... </knora> The <knora> element can only contain the following sub-elements: <permissions> (optional) <resource>","title":"The root element &lt;knora&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#describing-permissions-with-permissions-elements","text":"The DSP server provides access control for each resource and each field of a resource through permissions. For a thorough explanation of the permission and access system of the DSP platform, see DSP platform permissions . It is optional to define permissions in the XML. If not defined, default permissions are applied (only project and system administrators can view and edit resources). The following access rights are defined by the DSP platform which apply to either a resource or a field: RV restricted view permission : The user gets only a restricted view of the element. E.g. in case of a still image resource, the image is displayed at reduced resolution or with a watermark overlay. V view permission : The user has read access to the element. M modifiy permission : The user may modify the element, but may not delete it. D delete permission : The user is allowed to delete the element. CR change right permission : The user may change the permission of the element. The user does not hold the permissions directly, but may belong to an arbitrary number of groups which hold the permissions. By default, the following groups always exist, and each user belongs to at least one of them: UnknownUser : The user is not known to the DSP platform (not logged in). KnownUser : The user is known (performed login), but is not a member of the project the data element belongs to. ProjectMember : The user belongs to the same project as the data element. ProjectAdmin : The user is project administrator in the project the data element belongs to. Creator : The user is the owner of the element (created the element). SystemAdmin : The user is a system administrator. In addition, more groups with arbitrary names can be created by a project admin. For referencing a group, the project name has to be prepended before the group name, separated by a colon, e.g. dsp-test:MlsEditors . A <permissions> element contains the permissions given to the selected groups and is called a permission set . It has a mandatory attribute id and must contain at least one <allow> element per group indicating the group's permission. The permission is referenced inside the resource or property tag by its id . It is of the following form: <permissions id=\"res-default\"> <allow group=\"UnknownUser\">RV</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"ProjectAdmin\">CR</allow> <allow group=\"Creator\">CR</allow> <allow group=\"dsp-test:MlsEditors\">D</allow> </permissions> If you don't want a group to have access at all, leave it out. In the following example, only ProjectAdmin s will see the resource or property with permission special-permission : <permissions id=\"special-permission\"> <allow group=\"ProjectAdmin\">CR</allow> </permissions> Note: The permissions defined in the XML are applied to resources that are created. But only project or system administrators do have the permission to create resources via the XML upload.","title":"Describing permissions with &lt;permissions&gt; elements"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#the-allow-sub-element","text":"The <allow> element is used to define the permission for a specific group. It is of the following form: <allow group=\"ProjectAdmin\">CR</allow> The allowed values are: RV restricted view : Same as V but if it is applied to an image, the image is shown blurred. V view : The user can view a resource or a value, but can not modify it. M modify : The user can modify a resource or value, but can not delete it. The original resource or value will be preserved. D delete : The user can mark a resource or value as deleted. The original resource or value will be preserved. CR change right : The user can change the permission of a resource or value. The user is also allowed to permanently delete (erase) a resource. The group attribute is mandatory. It defines the group which the permission is applied to. DSP system groups as well as project specific groups are supported. A project specific group name has the form project-shortname:groupname . The available system groups are: UnknownUser (not logged in user) KnownUser (logged in user) ProjectMember (user with project membership) Creator (creator of the resource or value) ProjectAdmin (user with project admin membership) SystemAdmin (system administrator) There are no sub-elements allowed for the <allow> element.","title":"The &lt;allow&gt; sub-element"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#example-for-a-permissions-section","text":"A complete <permissions> section may look as follows: <knora xmlns=\"https://dasch.swiss/schema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/data.xsd\" shortcode=\"0806\" default-ontology=\"webern\"> <permissions id=\"res-default\"> <allow group=\"UnknownUser\">RV</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> </permissions> <permissions id=\"res-restricted\"> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> </permissions> <permissions id=\"prop-default\"> <allow group=\"UnknownUser\">V</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> </permissions> <permissions id=\"prop-restricted\"> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> </permissions> ... </knora>","title":"Example for a permissions section"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#describing-resources-with-the-resource-element","text":"A <resource> element contains all necessary information to create a resource. It has the following attributes: label : a human-readable, preferably meaningful short name of the resource (required) restype : the resource type as defined within the ontology (required) id : a unique, arbitrary string providing a unique ID to the resource in order to be referencable by other resources; the ID is only used during the import process and later replaced by the IRI used internally by DSP (required) permissions : a reference to a permission set; the permissions will be applied to the created resource (optional) iri : a custom IRI used when migrating existing resources (optional) ark : a version 0 ARK used when migrating existing resources from salsah.org to DSP (optional), it is not possible to use iri and ark in the same resource. When ark is used, it overrides iri . A complete <resource> element may look as follows: <resource label=\"EURUS015a\" restype=\":Postcard\" id=\"238807\" permissions=\"res-def-perm\"> ... </resource> The <resource> element contains a property element (e.g. <text-prop> ) for each property class (i.e. data field) describing the resource. The property element itself contains one or several value elements (e.g. <text> ) and must have an attribute name with the name of the property as defined in the project specific ontology. Example for a property element of type text ( <text-prop> ) with two value elements <text> : <text-prop name=\":hasTranslation\"> <text encoding=\"utf8\">Dies ist eine \u00dcbersetzung.</text> <text encoding=\"utf8\">Dies ist eine weitere \u00dcbersetzung.</text> </text-prop> \u26a0 Look out In case of a cardinality 1-n, multiple <text> tags have to be created inside the <text-prop> tag (do not use multiple <text-prop> tags). The following property elements exist: <bitstream> : contains a path to a file (if the resource is a multimedia resource) <boolean-prop> : contains a boolean value <color-prop> : contains color values <date-prop> : contains date values <decimal-prop> : contains decimal values <geometry-prop> : contains JSON geometry definitions for a region <geoname-prop> : contains geonames.org location codes <list-prop> : contains list element labels <iconclass-prop> : contains iconclass.org codes (not yet implemented) <integer-prop> : contains integer values <interval-prop> : contains interval values <period-prop> : contains time period values (not yet implemented) <resptr-prop> : contains links to other resources <text-prop> : contains text values <time-prop> : contains time values <uri-prop> : contains URI values","title":"Describing resources with the &lt;resource&gt; element"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#bitstream","text":"The <bitstream> element is used for bitstream data. It contains the path to a bitstream object like an image file, a ZIP container, an audio file etc. It must only be used if the resource is a StillImageRepresentation , an AudioRepresentation , a DocumentRepresentation etc. Note: There is only one <bitstream> element allowed per representation! The <bitstream> element must be the first element! Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) Example: <bitstream permissions=\"prop-restricted\">postcards/images/EURUS015a.jpg</bitstream>","title":"&lt;bitstream&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#boolean-prop","text":"The <boolean-prop> element is used for boolean values. It must contain exactly one <boolean> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;boolean-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#boolean","text":"The <boolean> element must contain the string \"true\" or \"false\", or the numeral 1 (true) or 0 (false). Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <boolean-prop name=\":hasBoolean\"> <boolean>true</boolean> </boolean-prop> <boolean-prop name=\":hasBoolean\"> <boolean>0</boolean> </boolean-prop>","title":"&lt;boolean&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#color-prop","text":"The <color-prop> element is used for color values. It must contain at least one <color> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;color-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#color","text":"The <color> element is used to indicate a color value. The color has to be given in web-notation, that is a # followed by 3 or 6 hex numerals. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) A property with two color values would be defined as follows: <color-prop name=\":hasColor\"> <color>#00ff66</color> <color>#ff00ff</color> </color-prop>","title":"&lt;color&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#date-prop","text":"The <date-prop> element is used for date values. It must contain at least one <date> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;date-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#date","text":"the <date> element contains a DSP-specific date value. It has the following format: calendar:epoch:yyyy-mm-dd:epoch:yyyy-mm-dd calendar : either \"JULIAN\" or \"GREGORIAN\" (optional, default: GREGORIAN) epoch : either \"BCE\" or \"CE\" (optional, default CE) yyyy : year with four digits (required) mm : month with two digits (optional, e.g. 01, 02, ..., 12) dd : day with two digits (optional, e.g. 01, 02, ..., 31) If two dates are provided, the date is defined as range between the two dates. If the day is omitted, then the precision it month , if also the month is omitted, the precision is year . Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <date-prop name=\":hasDate\"> <date>GREGORIAN:CE:2014-01-31</date> </date-prop> <date-prop name=\":hasDate\"> <date>GREGORIAN:CE:1930-09-02:CE:1930-09-03</date> </date-prop>","title":"&lt;date&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#decimal-prop","text":"The <decimal-prop> element is used for decimal values. It must contain at least one <decimal> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;decimal-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#decimal","text":"The <decimal> element contains a decimal number. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <decimal-prop name=\":hasDecimal\"> <decimal>3.14159</decimal> </decimal-prop>","title":"&lt;decimal&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#geometry-prop","text":"The <geometry-prop> element is used for a geometric definition of a 2-D region (e.g. a region on an image). It must contain at least one <geometry> element. Note: Usually these are not created by an import and should be used with caution! Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;geometry-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#geometry","text":"A geometry value is defined as a JSON object. It contains the following data: status : \"active\" or \"deleted\" type : \"circle\", \"rectangle\" or \"polygon\" lineColor : web-color lineWidth : integer number (in pixels) points : array of coordinate objects of the form {\"x\": decimal, \"y\": decimal} radius : coordinate object of the form {\"x\": decimal, \"y\": decimal} Please note that all coordinates are normalized coordinates (relative to the image size) between 0.0 and 1.0! The following example defines a polygon: { \"status\": \"active\", \"type\": \"polygon\", \"lineColor\": \"#ff3333\", \"lineWidth\": 2, \"points\": [{\"x\": 0.17252396166134185, \"y\": 0.1597222222222222}, {\"x\": 0.8242811501597445, \"y\": 0.14583333333333334}, {\"x\": 0.8242811501597445, \"y\": 0.8310185185185185}, {\"x\": 0.1757188498402556, \"y\": 0.8240740740740741}, {\"x\": 0.1757188498402556, \"y\": 0.1597222222222222}, {\"x\": 0.16932907348242812, \"y\": 0.16435185185185186}], \"original_index\": 0 } Example of a <geometry> element: <geometry-prop name=\":hasPolygon\"> <geometry>{\"status\":\"active\",\"type\"=\"circle\",\"lineColor\"=\"#ff0000\",\"lineWidth\"=2,\"points\":[{\"x\":0.5,\"y\":0.5}],\"radius\":{\"x\":0.1,\"y\":0.0}}</geometry> </geometry-prop> Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional)","title":"&lt;geometry&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#geoname-prop","text":"The <geoname-prop> element is used for values that contain a geonames.org ID. It must contain at least one <geoname> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;geoname-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#geoname","text":"Contains a valid geonames.org ID. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example (city of Vienna): <geoname-prop name=\":hasLocation\"> <geoname>2761369</geoname> </geoname-prop>","title":"&lt;geoname&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#list-prop","text":"The <list-prop> element is used as entry point into a list (list node). List nodes are identified by their name attribute that was given when creating the list nodes (which must be unique within each list!). It must contain at least one <list> element. Attributes: name : name of the property as defined in the ontology (required) list : name of the list as defined in the ontology (required)","title":"&lt;list-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#list","text":"The <list> element references a node in a (pull-down or hierarchical) list. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <list-prop list=\"category\" name=\":hasCategory\"> <list>physics</list> </list-prop>","title":"&lt;list&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#iconclass-prop-not-yet-implemented","text":"The <iconclass-prop> element is used for iconclass.org ID. It must contain at least one <iconclass> element. For example: 92E112 stands for (story of) Aurora (Eos); 'Aurora' (Ripa) - infancy, upbringing Aurora \u00b7 Ripa \u00b7 air \u00b7 ancient history \u00b7 child \u00b7 classical antiquity \u00b7 goddess \u00b7 gods \u00b7 heaven \u00b7 history \u00b7 infancy \u00b7 mythology \u00b7 sky \u00b7 upbringing \u00b7 youth Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;iconclass-prop&gt; (not yet implemented)"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#iconclass-not-yet-implemented","text":"References an iconclass.org ID. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Usage: <iconclass-prop name=\":hasIcon\"> <iconclass>92E112</iconclass> </iconclass-prop>","title":"&lt;iconclass&gt; (not yet implemented)"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#integer-prop","text":"The <integer-prop> element is used for integer values. It must contain at least one <integer> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;integer-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#integer","text":"The <integer> element contains an integer value. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <integer-prop name=\":hasInteger\"> <integer>4711</integer> </integer-prop>","title":"&lt;integer&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#interval-prop","text":"The <interval-prop> element is used for intervals with a start and an end point on a timeline, e.g. relative to the beginning of an audio or video file. An <interval-prop> must contain at least one <interval> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;interval-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#interval","text":"A time interval is represented by plain decimal numbers (=seconds), without a special notation for minutes and hours. The <interval> element contains two decimals separated by a colon ( : ). The places before the decimal point are seconds, and the places after the decimal points are fractions of a second. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <interval-prop name=\":hasInterval\"> <interval>60.5:120.5</interval> <!-- 0:01:00.5 - 0:02:00.5 --> <interval>61:3600</interval> <!-- 0:01:01 - 1:00:00 --> </interval-prop>","title":"&lt;interval&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#resptr-prop","text":"The <resptr-prop> element is used to link other resources within DSP. It must contain at least one <resptr> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;resptr-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#resptr","text":"The <resptr> element contains either the internal ID of another resource inside the XML or the IRI of an already existing resource on DSP. Inside the same XML file, a mixture of the two is not possible. If referencing existing resources, xmlupload --incremental has to be used. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: If there is a resource defined as <resource label=\"EURUS015a\" restype=\":Postcard\" id=\"238807\">...</resource> , it can be referenced as: <resptr-prop name=\":hasReferenceTo\"> <resptr>238807</resptr> </resptr-prop>","title":"&lt;resptr&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#text-prop","text":"The <text-prop> element is used for text values. It must contain at least one <text> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;text-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#text","text":"The <text> element has the following attributes: encoding : either \"utf8\" or \"xml\" (required) utf8 : The element describes a simple text without markup. The text is a simple UTF-8 string. xml : The element describes a complex text containing markup. It must follow the XML format as defined by the DSP standard mapping . permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) There are two variants of text: Simple (UTF8) and complex (XML). Within a text property, multiple simple and complex text values may be mixed. Both simple and complex text values can be used inside all gui_elements that are defined in an ontology (SimpleText, Richtext, Textarea, see here ). But typically, you would use UTF8 in a SimpleText, and XML in Richtext or Textarea.","title":"&lt;text&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#simple-text-utf-8","text":"An example for simple text: <text-prop name=\":hasComment\"> <text encoding=\"utf8\">Probe bei \"Wimberger\". Lokal in Wien?</text> </text-prop> If your text is very long, it is not advised to add XML-\"pretty-print\" whitespaces after line breaks. These whitespaces will be taken into the text field as they are.","title":"Simple text (UTF-8)"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#text-with-markup-xml","text":"dsp-tools assumes that for markup (standoff markup), the DSP standard mapping is used (custom mapping is not yet implemented). Example of a text containing a link to another resource: <text-prop name=\":hasComment\"> <text encoding=\"xml\" >The <strong>third</strong> object and a <a class=\"salsah-link\" href=\"IRI:obj_0003:IRI\">link</a>.</text> </text-prop> Please note that the href option within the anchor tag ( <a> ) points to an internal resource of the DSP and has to conform to the special format IRI:[res-id]:IRI where [res-id] is the resource id defined within the XML import file.","title":"Text with markup (XML)"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#time-prop","text":"The <time-prop> element is used for time values. It must contain at least one <time> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;time-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#time","text":"The <time> element represents an exact datetime value in the form of yyyy-mm-ddThh:mm:ss.sssssssssssszzzzzz . The following abbreviations describe this form: yyyy : a four-digit numeral that represents the year. The value cannot start with a minus (-) or a plus (+) sign. 0001 is the lexical representation of the year 1 of the Common Era (also known as 1 AD). The value cannot be 0000. mm : a two-digit numeral that represents the month dd : a two-digit numeral that represents the day hh : a two-digit numeral representing the hours. Must be between 0 and 23 mm : a two-digit numeral that represents the minutes ss : a two-digit numeral that represents the seconds ssssssssssss : If present, a 1-to-12-digit numeral that represents the fractional seconds (optional) zzzzzz : represents the time zone (required). Each part of the datetime value that is expressed as a numeric value is constrained to the maximum value within the interval that is determined by the next higher part of the datetime value. For example, the day value can never be 32 and cannot be 29 for month 02 and year 2002 (February 2002). The timezone is defined as follows: A plus (+) or minus (-) sign that is followed by hh:mm: + : Indicates that the specified time instant is in a time zone that is ahead of the UTC time by hh hours and mm minutes. - : Indicates that the specified time instant is in a time zone that is behind UTC time by hh hours and mm minutes. hh : a two-digit numeral (with leading zeros as required) that represents the hours. The value must be between -14 and +14, inclusive. mm : a two-digit numeral that represents the minutes. The value must be zero when hh is equal to 14. Z: The literal Z, which represents the time in UTC (Z represents Zulu time, which is equivalent to UTC). Specifying Z for the time zone is equivalent to specifying +00:00 or -00:00. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <time-prop name=\":hasTime\"> <time>2019-10-23T13:45:12Z</time> </time-prop> The following value indicates noon on October 10, 2009, Eastern Standard Time in the United States: <time-prop name=\":hasTime\"> <time>2009-10-10T12:00:00-05:00</time> </time-prop>","title":"&lt;time&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#uri-prop","text":"The <uri-prop> element is used for referencing resources with a URI. It must contain at least one <uri> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;uri-prop&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#uri","text":"The <uri> element contains a syntactically valid URI. Attributes: permissions : ID or a permission set (optional, but if omitted, very restricted default permissions apply) comment : a comment for this specific value (optional) Example: <uri-prop name=\":hasURI\"> <uri>http://www.groove-t-gang.ch</uri> </uri-prop>","title":"&lt;uri&gt;"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#incremental-xml-upload","text":"After a successful upload of the data, an output file is written (called id2iri_mapping_[timstamp].json ) with the mapping of internal IDs used inside the XML and their corresponding IRIs which uniquely identify them inside DSP. This file should be kept if data is later added with the --incremental option. To do an incremental XML upload, one of the following procedures is recommended. Incremental XML upload with use of internal IDs: Initial XML upload with internal IDs. The file id2iri_mapping_[timestamp].json is created. Create new XML file(s) with resources referencing other resources by their internal IDs in <resptr> (using the same IDs as in the initial XML upload). Run dsp-tools id2iri new_data.xml id2iri_mapping_[timestamp].json to replace the internal IDs in new_data.xml with IRIs. Only internal IDs inside the <resptr> tag are replaced. Run dsp-tools xmlupload --incremental new_data.xml to upload the data to DSP. Incremental XML Upload with the use of IRIs: Use IRIs in the XML to reference existing data on the DSP server.","title":"Incremental XML Upload"},{"location":"DSP-TOOLS/dsp-tools-xmlupload/#complete-example","text":"<?xml version='1.0' encoding='utf-8'?> <knora xmlns=\"https://dasch.swiss/schema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/knora/dsplib/schemas/data.xsd\" shortcode=\"0001\" default-ontology=\"anything\"> <!-- permissions: see https://docs.dasch.swiss/DSP-API/05-internals/design/api-admin/administration/#permissions --> <permissions id=\"res-default\"> <allow group=\"UnknownUser\">RV</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> <allow group=\"anything:Thing searcher\">D</allow> </permissions> <permissions id=\"res-restricted\"> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow>> <allow group=\"ProjectAdmin\">CR</allow>> <allow group=\"anything:Thing searcher\">M</allow>> </permissions> <permissions id=\"prop-default\"> <allow group=\"UnknownUser\">V</allow> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow>> <allow group=\"anything:Thing searcher\">D</allow>> </permissions> <permissions id=\"prop-restricted\"> <allow group=\"KnownUser\">V</allow> <allow group=\"Creator\">CR</allow> <allow group=\"ProjectAdmin\">CR</allow> <allow group=\"anything:Thing searcher\">M</allow> </permissions> <resource label=\"obj_inst1\" restype=\":BlueThing\" id=\"obj_0001\" permissions=\"res-default\"> <list-prop list=\"treelistroot\" name=\":hasListItem\"> <list permissions=\"prop-default\">Tree list node 02</list> </list-prop> <list-prop list=\"treelistroot\" name=\":hasOtherListItem\"> <list permissions=\"prop-default\">Tree list node 03</list> </list-prop> <text-prop name=\":hasRichtext\"> <text permissions=\"prop-default\" encoding=\"xml\" >The <strong>third</strong> object and a <a class=\"salsah-link\" href=\"IRI:obj_0003:IRI\">link</a> to.</text> </text-prop> <text-prop name=\":hasRichtext\"> <text permissions=\"prop-default\" encoding=\"xml\" >The <strong>third</strong> object and a <a class=\"salsah-link\" href=\"IRI:obj_0003:IRI\">link</a> to.</text> </text-prop> <text-prop name=\":hasText\"> <text permissions=\"prop-default\" encoding=\"utf8\">Dies ist ein einfacher Text ohne Markup</text> <text permissions=\"prop-restricted\" encoding=\"utf8\">Nochmals ein einfacher Text</text> </text-prop> <date-prop name=\":hasDate\"> <date permissions=\"prop-default\">JULIAN:CE:1401-05-17:CE:1402-01</date> </date-prop> <integer-prop name=\":hasInteger\"> <integer permissions=\"prop-default\">4711</integer> </integer-prop> <decimal-prop name=\":hasDecimal\"> <decimal permissions=\"prop-default\" comment=\"Eulersche Zahl\">2.718281828459</decimal> </decimal-prop> <boolean-prop name=\":hasBoolean\"> <boolean permissions=\"prop-default\">true</boolean> </boolean-prop> <uri-prop name=\":hasUri\"> <uri permissions=\"prop-default\">http://dasch.swiss/gaga</uri> </uri-prop> <interval-prop name=\":hasInterval\"> <interval permissions=\"prop-default\">12.5:14.2</interval> </interval-prop> <color-prop name=\":hasColor\"> <color permissions=\"prop-default\">#00ff00</color> </color-prop> <geometry-prop name=\":hasGeometry\"> <geometry permissions=\"prop-default\"> { \"status\":\"active\", \"lineColor\":\"#ff3333\", \"lineWidth\":2, \"points\":[ {\"x\":0.08098591549295775,\"y\":0.16741071428571427}, {\"x\":0.7394366197183099,\"y\":0.7299107142857143}], \"type\":\"rectangle\", \"original_index\":0 } </geometry> </geometry-prop> <geoname-prop name=\":hasGeoname\"> <geoname permissions=\"prop-default\" comment=\"A sacred place for railroad fans\">5416656</geoname> </geoname-prop> <resptr-prop name=\":hasBlueThing\"> <resptr permissions=\"prop-default\">obj_0002</resptr> </resptr-prop> </resource> <resource label=\"obj_inst2\" restype=\":BlueThing\" id=\"obj_0002\" permissions=\"res-default\"> <list-prop list=\"treelistroot\" name=\":hasListItem\"> <list permissions=\"prop-default\">Tree list node 10</list> </list-prop> <list-prop list=\"treelistroot\" name=\":hasOtherListItem\"> <list permissions=\"prop-default\">Tree list node 11</list> </list-prop> <text-prop name=\":hasRichtext\"> <text permissions=\"prop-default\" encoding=\"xml\">What is this <em>bold</em> thing?</text> </text-prop> <text-prop name=\":hasText\"> <text permissions=\"prop-default\" encoding=\"utf8\">aa bbb cccc ddddd</text> </text-prop> <date-prop name=\":hasDate\"> <date permissions=\"prop-default\">1888</date> </date-prop> <integer-prop name=\":hasInteger\"> <integer permissions=\"prop-default\">42</integer> </integer-prop> <decimal-prop name=\":hasDecimal\"> <decimal permissions=\"prop-default\" comment=\"Die Zahl PI\">3.14159</decimal> </decimal-prop> <boolean-prop name=\":hasBoolean\"> <boolean permissions=\"prop-default\">false</boolean> </boolean-prop> <uri-prop name=\":hasUri\"> <uri permissions=\"prop-default\">http://unibas.ch/gugus</uri> </uri-prop> <interval-prop name=\":hasInterval\"> <interval permissions=\"prop-default\">24:100.075</interval> </interval-prop> <color-prop name=\":hasColor\"> <color permissions=\"prop-default\">#33ff77</color> </color-prop> <geometry-prop name=\":hasGeometry\"> <geometry permissions=\"prop-default\"> { \"status\":\"active\", \"lineColor\":\"#ff3333\", \"lineWidth\":2, \"points\":[ {\"x\":0.08098591549295775,\"y\":0.16741071428571427}, {\"x\":0.7394366197183099,\"y\":0.7299107142857143}], \"type\":\"rectangle\", \"original_index\":0 } </geometry> </geometry-prop> <geoname-prop name=\":hasGeoname\"> <geoname permissions=\"prop-default\" comment=\"A sacred place for railroad fans\">5416656</geoname> </geoname-prop> <resptr-prop name=\":hasBlueThing\"> <resptr permissions=\"prop-default\">obj_0003</resptr> </resptr-prop> </resource> <resource label=\"obj_inst3\" restype=\":BlueThing\" id=\"obj_0003\" permissions=\"res-default\"> <list-prop list=\"treelistroot\" name=\":hasListItem\"> <list permissions=\"prop-default\">Tree list node 01</list> </list-prop> <list-prop list=\"treelistroot\" name=\":hasOtherListItem\"> <list permissions=\"prop-default\">Tree list node 02</list> </list-prop> <text-prop name=\":hasRichtext\"> <text permissions=\"prop-default\" encoding=\"xml\">This is <em>bold and <strong>string</strong></em> text!</text> </text-prop> <text-prop name=\":hasText\"> <text permissions=\"prop-default\" encoding=\"utf8\">aa bbb cccc ddddd</text> </text-prop> <date-prop name=\":hasDate\"> <date permissions=\"prop-default\">1888</date> </date-prop> <integer-prop name=\":hasInteger\"> <integer permissions=\"prop-default\">42</integer> </integer-prop> <decimal-prop name=\":hasDecimal\"> <decimal permissions=\"prop-default\" comment=\"Die Zahl PI\">3.14159</decimal> </decimal-prop> <boolean-prop name=\":hasBoolean\"> <boolean permissions=\"prop-default\">false</boolean> </boolean-prop> <uri-prop name=\":hasUri\"> <uri permissions=\"prop-default\">http://unibas.ch/gugus</uri> </uri-prop> <interval-prop name=\":hasInterval\"> <interval permissions=\"prop-default\">24:100.075</interval> </interval-prop> <color-prop name=\":hasColor\"> <color permissions=\"prop-default\">#33ff77</color> </color-prop> <geometry-prop name=\":hasGeometry\"> <geometry permissions=\"prop-default\"> { \"status\":\"active\", \"lineColor\":\"#ff3333\", \"lineWidth\":2, \"points\":[ {\"x\":0.08098591549295775,\"y\":0.16741071428571427}, {\"x\":0.7394366197183099,\"y\":0.7299107142857143}], \"type\":\"rectangle\", \"original_index\":0 } </geometry> </geometry-prop> <geoname-prop name=\":hasGeoname\"> <geoname permissions=\"prop-default\" comment=\"A sacred place for railroad fans\">5416656</geoname> </geoname-prop> </resource> <resource label=\"obj_inst4\" restype=\":ThingPicture\" id=\"obj_0004\" permissions=\"res-default\"> <bitstream>gaga.tif</bitstream> <text-prop name=\":hasPictureTitle\"> <text permissions=\"prop-default\" encoding=\"utf8\">This is the famous Lena</text> </text-prop> </resource> </knora>","title":"Complete example"},{"location":"community/about-us/","text":"About us Since 2017, the Data and Service Center for the Humanities (DaSCH) has been a member of the Swiss Academy of Humanities and Social Sciences. The main task of the institution is to operate a platform for humanities research data that ensures access to this data. In addition, the networking of data with other databases is to be promoted (linked open data), thus creating added value for research and the interested public. Get more information on our website: https://dasch.swiss Follow us on Github Twitter Facebook","title":"About us"},{"location":"community/about-us/#about-us","text":"Since 2017, the Data and Service Center for the Humanities (DaSCH) has been a member of the Swiss Academy of Humanities and Social Sciences. The main task of the institution is to operate a platform for humanities research data that ensures access to this data. In addition, the networking of data with other databases is to be promoted (linked open data), thus creating added value for research and the interested public. Get more information on our website: https://dasch.swiss Follow us on Github Twitter Facebook","title":"About us"},{"location":"community/product-updates/","text":"Product Updates You'll find the general list of features, updates and bug fixes of the DaSCH Service Platform (DSP) on our confluence DSP Changelog page . Each DSP repository has also it's own release notes: DSP API release notes DSP JS Lib release notes DSP APP release notes DSP Tools release notes SIPI release notes","title":"Product Updates"},{"location":"community/product-updates/#product-updates","text":"You'll find the general list of features, updates and bug fixes of the DaSCH Service Platform (DSP) on our confluence DSP Changelog page . Each DSP repository has also it's own release notes: DSP API release notes DSP JS Lib release notes DSP APP release notes DSP Tools release notes SIPI release notes","title":"Product Updates"},{"location":"developers/getting-started/","text":"Developer Overview Getting started with the DaSCH Service Platform (DSP) Local Development Environment At the DaSCH, the principal development environment is Apple macOS . Each developer machine should have the following prerequisites installed: Docker Desktop: https://www.docker.com/products/docker-desktop Homebrew: https://brew.sh , which can be used to install: git expect sbt python (Python 3) node Java AdoptOpenJDK 11 To install, follow these steps: brew tap AdoptOpenJDK/openjdk brew cask install AdoptOpenJDK/openjdk/adoptopenjdk11 To pin the version of Java, you can add this environment variable to your startup script (bashrc, etc.): export JAVA_HOME=`/usr/libexec/java_home -v 11` You can also use jEnv to use different versions of Java for different things. Bazel build tools To install, follow these steps: npm install -g @bazel/bazelisk npm install -g @bazel/buildozer This will install bazelisk which is a wrapper to the bazel binary. It will, when the bazel command ir run, automatically install the supported Bazel version, defined in the .bazelversion file in the root of the knora-api repository. Clone DSP-API from GitHub To clone DSP-API from Github open a terminal window and change to the directory where you intend to install DSP-API. Then type git clone https://github.com/dasch-swiss/dsp-api.git This will install the directory dsp-api with subdirectories in the chosen directory. Bazel Commands Build webapi : # build webapi bazel build //webapi/... # run all webapi tests bazel test //webapi/... Build the docker image From inside the cloned dsp-api repository folder, create a test repository: make init-db-test Then start the DSP stack: make stack-up This should start the complete Knora stack consisting of Fuseki, DSP-API, Redis, and Sipi. If everything worked properly, the Dashboard in Docker Desktop should show those containers running. To stop everything again, type make stack-down Please see the Makefile for other useful make targets. Build Structure The Bazel build is defined in a number of files: WORKSPACE - here are external dependencies defined BUILD - there are a number of BUILD files throughout the directory structure where each represents a separate package responsible for everything underneath. *.bzl - custom extensions loaded and used in BUILD files For a more detailed discussion, please see the Concepts and Terminology section in the Bazel documentation. Some Notes Override some .bazelrc settings in your own copy created at ~/.bazelrc : bash build --action_env=PATH=\"/usr/local/bin:/opt/local/bin:/usr/bin:/bin\" build --strategy=Scalac=worker build --worker_sandboxing query --package_path %workspace%:/usr/local/bin/bazel/base_workspace startup --host_jvm_args=-Djavax.net.ssl.trustStore=/Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home/lib/security/cacerts \\ --host_jvm_args=-Djavax.net.ssl.trustStorePassword=changeit Add Bazel Plugin and Project to IntelliJ The latest version of the Bazel plugin supports only IntelliJ upto version 2020.01.04 . After you make sure to run this version of IntelliJ, install the plugin from inside IntelliJ. Click on File -> Import Bazel Project and select twice next . Uncomment the Scala language and click Finish . Run single spec: bash bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec Run single spec and only tests containing gaga in the description bash bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec --test_arg=-z --test_arg=\"gaga\" Start Scala REPL bash bazel run //webapi:main_library_repl Build stamping By default, Bazel tries not to include anything about the system state in build outputs. However, released binaries and libraries often want to include something like the version they were built at or the branch or tag they came from. To reconcile this, Bazel has an option called the workspace status command . This command is run outside of any sandboxes on the local machine, so it can access anything about your source control, OS, or anything else you might want to include. It then dumps its output into bazel-out/volatile-status.txt , which you can use (and certain language rulesets provide support for accessing from code). Our workspace status command is defined in //tools/buildstamp/get_workspace_status . To use it on every bazel command, we need to supply it to each Bazel invocation, which is done by the following line found in .bazelrc : build --workspace_status_command=tools/buildstamp/get_workspace_status --stamp=yes Any line added to .bazelrc is invoked on each corresponding command. The //tools/buildstamp/get_workspace_status emits additional values to bazel-out/volatile-status.txt whereas BUILD_TIMESTAMP is emitted by Bazel itself: BUILD_SCM_REVISION 2d6df6c8fe2d56e3712eb26763f9727916a60164 BUILD_SCM_STATUS Modified BUILD_SCM_TAG v13.0.0-rc.21-17-g2d6df6c-dirty BUILD_TIMESTAMP 1604401028 The value of BUILD_SCM_TAG is used in //webapi/src/main/scala/org/knora/webapi/http/version/versioninfo , which emits a JAR containing VersionInfo.scala . This file is generated based on VersionInfoTemplate.scala found in the same Bazel package. In short, the versioninfo target producing the JAR library depends on the version_info_with_build_tag target which emits the VersionInfo.scala file which has the {BUILD_TAG} variable replaced by the current value of BUILD_SCM_TAG . In an intermediary step, the version_info_without_build_tag target, replaces variables coming from //third_party:versions.bzl . Visualize your Build Add the following line to your ~/.bazelrc: query --package_path %workspace%:[PATH TO BAZEL]/base_workspace # set the path to the bazel binary Run bazel query inside your project directory, asking it to search for all dependencies of //:main (or however the label is to your target of interest): bazel query 'deps(//:main)' --output graph > graph.in This creates a file called graph.in , which is a text representation of the build graph. You can use dot (install with brew install graphviz ) to create a png: dot -Tpng < graph.in > graph.png","title":"Getting Started"},{"location":"developers/getting-started/#developer-overview","text":"","title":"Developer Overview"},{"location":"developers/getting-started/#getting-started-with-the-dasch-service-platform-dsp","text":"","title":"Getting started with the DaSCH Service Platform (DSP)"},{"location":"developers/getting-started/#local-development-environment","text":"At the DaSCH, the principal development environment is Apple macOS . Each developer machine should have the following prerequisites installed: Docker Desktop: https://www.docker.com/products/docker-desktop Homebrew: https://brew.sh , which can be used to install: git expect sbt python (Python 3) node","title":"Local Development Environment"},{"location":"developers/getting-started/#java-adoptopenjdk-11","text":"To install, follow these steps: brew tap AdoptOpenJDK/openjdk brew cask install AdoptOpenJDK/openjdk/adoptopenjdk11 To pin the version of Java, you can add this environment variable to your startup script (bashrc, etc.): export JAVA_HOME=`/usr/libexec/java_home -v 11` You can also use jEnv to use different versions of Java for different things.","title":"Java AdoptOpenJDK 11"},{"location":"developers/getting-started/#bazel-build-tools","text":"To install, follow these steps: npm install -g @bazel/bazelisk npm install -g @bazel/buildozer This will install bazelisk which is a wrapper to the bazel binary. It will, when the bazel command ir run, automatically install the supported Bazel version, defined in the .bazelversion file in the root of the knora-api repository.","title":"Bazel build tools"},{"location":"developers/getting-started/#clone-dsp-api-from-github","text":"To clone DSP-API from Github open a terminal window and change to the directory where you intend to install DSP-API. Then type git clone https://github.com/dasch-swiss/dsp-api.git This will install the directory dsp-api with subdirectories in the chosen directory.","title":"Clone DSP-API from GitHub"},{"location":"developers/getting-started/#bazel-commands","text":"Build webapi : # build webapi bazel build //webapi/... # run all webapi tests bazel test //webapi/...","title":"Bazel Commands"},{"location":"developers/getting-started/#build-the-docker-image","text":"From inside the cloned dsp-api repository folder, create a test repository: make init-db-test Then start the DSP stack: make stack-up This should start the complete Knora stack consisting of Fuseki, DSP-API, Redis, and Sipi. If everything worked properly, the Dashboard in Docker Desktop should show those containers running. To stop everything again, type make stack-down Please see the Makefile for other useful make targets.","title":"Build the docker image"},{"location":"developers/getting-started/#build-structure","text":"The Bazel build is defined in a number of files: WORKSPACE - here are external dependencies defined BUILD - there are a number of BUILD files throughout the directory structure where each represents a separate package responsible for everything underneath. *.bzl - custom extensions loaded and used in BUILD files For a more detailed discussion, please see the Concepts and Terminology section in the Bazel documentation.","title":"Build Structure"},{"location":"developers/getting-started/#some-notes","text":"Override some .bazelrc settings in your own copy created at ~/.bazelrc : bash build --action_env=PATH=\"/usr/local/bin:/opt/local/bin:/usr/bin:/bin\" build --strategy=Scalac=worker build --worker_sandboxing query --package_path %workspace%:/usr/local/bin/bazel/base_workspace startup --host_jvm_args=-Djavax.net.ssl.trustStore=/Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home/lib/security/cacerts \\ --host_jvm_args=-Djavax.net.ssl.trustStorePassword=changeit Add Bazel Plugin and Project to IntelliJ The latest version of the Bazel plugin supports only IntelliJ upto version 2020.01.04 . After you make sure to run this version of IntelliJ, install the plugin from inside IntelliJ. Click on File -> Import Bazel Project and select twice next . Uncomment the Scala language and click Finish . Run single spec: bash bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec Run single spec and only tests containing gaga in the description bash bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec --test_arg=-z --test_arg=\"gaga\" Start Scala REPL bash bazel run //webapi:main_library_repl","title":"Some Notes"},{"location":"developers/getting-started/#build-stamping","text":"By default, Bazel tries not to include anything about the system state in build outputs. However, released binaries and libraries often want to include something like the version they were built at or the branch or tag they came from. To reconcile this, Bazel has an option called the workspace status command . This command is run outside of any sandboxes on the local machine, so it can access anything about your source control, OS, or anything else you might want to include. It then dumps its output into bazel-out/volatile-status.txt , which you can use (and certain language rulesets provide support for accessing from code). Our workspace status command is defined in //tools/buildstamp/get_workspace_status . To use it on every bazel command, we need to supply it to each Bazel invocation, which is done by the following line found in .bazelrc : build --workspace_status_command=tools/buildstamp/get_workspace_status --stamp=yes Any line added to .bazelrc is invoked on each corresponding command. The //tools/buildstamp/get_workspace_status emits additional values to bazel-out/volatile-status.txt whereas BUILD_TIMESTAMP is emitted by Bazel itself: BUILD_SCM_REVISION 2d6df6c8fe2d56e3712eb26763f9727916a60164 BUILD_SCM_STATUS Modified BUILD_SCM_TAG v13.0.0-rc.21-17-g2d6df6c-dirty BUILD_TIMESTAMP 1604401028 The value of BUILD_SCM_TAG is used in //webapi/src/main/scala/org/knora/webapi/http/version/versioninfo , which emits a JAR containing VersionInfo.scala . This file is generated based on VersionInfoTemplate.scala found in the same Bazel package. In short, the versioninfo target producing the JAR library depends on the version_info_with_build_tag target which emits the VersionInfo.scala file which has the {BUILD_TAG} variable replaced by the current value of BUILD_SCM_TAG . In an intermediary step, the version_info_without_build_tag target, replaces variables coming from //third_party:versions.bzl .","title":"Build stamping"},{"location":"developers/getting-started/#visualize-your-build","text":"Add the following line to your ~/.bazelrc: query --package_path %workspace%:[PATH TO BAZEL]/base_workspace # set the path to the bazel binary Run bazel query inside your project directory, asking it to search for all dependencies of //:main (or however the label is to your target of interest): bazel query 'deps(//:main)' --output graph > graph.in This creates a file called graph.in , which is a text representation of the build graph. You can use dot (install with brew install graphviz ) to create a png: dot -Tpng < graph.in > graph.png","title":"Visualize your Build"},{"location":"developers/introduction/","text":"Introduction to DSP-API The main software framework in the back-end of the DaSCH Service Platform is called DSP-API (previously Knora). DSP-API is a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP-API aims to solve key problems in the long-term preservation and reuse of humanities data: Traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. Downloading the data to check whether the data are interesting or not is time-consuming and makes it impractical to reuse data from many different sources. DSP-API solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP-API, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different data formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old data files, or even all the operating systems that these programs ran on. Instead of preserving all these data formats, DSP-API supports the conversion of all sorts of data to a small number of formats that are suitable for long-term preservation, and that maintain the data\u2019s meaning and structure: Non-binary data is stored as R esource D escription F ramework ( RDF ), in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. For a concise information about RDF basics see here . Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by the media server SIPI , with metadata stored in the triplestore. For a concise information about SIPI see here . Moreover, DSP-API has built-in support for special data structures that occur on a regular basis in humanities data: persistent links, calender-independent dates and flexible searchable text markup. Persistent links are a very important feature. If a resource is changed, a new resource will be created in DSP-API. The older version remains available and citable, there will be no dead links. This means that if in a publication an older version is referenced, the cited version still can be displayed, but there will be a notice that a newer version exists with the corresponding link attached to it. A date could be given in any kind of calendar - e.g. the Julian, Gregorian, Jewish or Islamic - just to name the most frequent ones. DSP-API stores dates using the Julian day count that was established by astronomers. Use of the Julian day count easily allows for conversion from one calendar into another and to calculate distances between two dates. It is possible to search for a date in one calendar and to convert it into another one. Commonly used text markup systems have troubles to cope with overlapping markup. DSP-API solves this problem by using Standoff/RDF markup where the markup is stored as RDF data, separately from the text. This enables overlapping markup. DSP-API\u2019s RDF-based standoff is designed to support the needs of complex digital critical editions. DSP-API can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time. The following table contains a non-exhaustive list of data formats and the information on how these formats are stored and managed by DSP-API (and SIPI): Original format Format in DSP-API Text (XML, LaTEX, Word, etc.) DSP resources (RDF) containing Standoff/RDF Tabular data, including relational databases DSP resources Data in tree or graph structures DSP resources Images (jpg, png, tiff, etc.) JPEG 2000 files stored by SIPI Audio and video files format not decided yet, stored by SIPI pdf stored by SIPI, but data reuse is improved by extracting the text for storage as Standoff/RDF DSP-API makes data available for reuse via its generic, standards-based A pplication P rogramming I nterfaces (APIs). A V irtual R esearch E nvironment (VRE) can then use these APIs to search, link together, and add to data from different research projects in a unified way. The full DSP-API documentation can be found here . Layout of DaSCH Service Platform The DaSCH Service Platform is a platform that includes five layers (see Figure 1). The bottom layer consists of an RDF triplestore, the IIIF-based media server SIPI , the knora-base ontology and any project specific ontologies that extend the base ontology. The second layer is occupied by the DSP-API which is a RESTful API, i.e. an application program interface that uses HTTP requests to GET, PUT, POST and DELETE data. The DSP API has an implemented access control. It returns information in JSON-LD format. In order to make the data accessible in an easy way, three more layers are built on top of the DSP API. The DSP-JS library comprises the third layer, it contains a reusable Node.js module for HTTP requests written in TypeScript. Layer four is occupied by DSP UI modules . These modules help to create a graphical user interface. They are developed with Angular and TypeScript and designed in such a way that they can be integrated to an Angular project. The top layer is made up of the generic DSP-APP and the more specific project Apps. From the top layer Gravsearch queries are sent to the DSP API, where permissions are checked and the queries translated into SPARQL queries, which are sent further down to the triplestore. The results are returned to the DSP-APP if the user has the sufficient permissions. In such a way, copyrighted material can be protected. Figure 1: DaSCH Service Platform architecture. The generic web app DSP-APP itself consists of three different parts (see Figure 2). First, there is the project administration part where you can manage your project - build your data model, set permissions, add users, etc. Then, there is a cross-project research platform where you search (full text, advanced or expert search), add or modify your data - this is your working environment. The third component is the Manifest+ viewer wich is designed for project presentation. Alternatively, it is possible to build more elaborate project-specific Apps based on the provided DSP-API modules in the different layers. However, it's up to you to keep such project-specific Apps compatible with the latest DSP API version. Figure 2: Details of DSP-APP. Currently, the following programming languages, software and formats are used for the various components: Component Software and formats RDF triplestore Apache Jena Fuseki Ontologies knora-base ontology and derived project ontologies SIPI C++, Lua, API-format: JSON DSP API Scala, API-formats: JSON-LD, RDF/XML or Turtle DSP-JS TypeScript, communication with DSP-API DSP-UI modules Angular modules, TypeScript, uses DSP-JS DSP-APP Angular, TypeScript, uses DSP-UI modules and DSP-JS The knora-base ontology DSP-API has a base ontology , i.e. a data model, with pre-defined basic data types. In addition to this base ontology, each project can create its own data model which is capable to describe the types of items it wishes to store. Project specific ontologies must be extensions of the knora-base ontology. The knora-base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In our documents it will be identified by the prefix knora-base or simply kb . TODO: add link to knora-base doc. Standoff/RDF Text Markup Standoff markup is text markup that is stored separately from the content it describes. DSP-API\u2019s Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. By storing markup as RDF, DSP-API can search for markup structures in the same way as for any RDF data structure. This enables searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as DSP resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. One could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain period of time. In DSP-API\u2019s Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, but has its own semantic properties. It is possible to define own tag classes in the ontology by creating subclasses of the already defined kb:StandoffTag , and to attach own properties to them. ### http://www.knora.org/ontology/knora-base#StandoffLinkTag kb:StandoffLinkTag rdf:type owl:Class ; rdfs:subClassOf kb:StandoffTag , [ rdf:type owl:Restriction ; owl:onProperty kb:standoffTagHasLink ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"Represents a reference to a Knora resource in a TextValue\"@en . DSP-API supports automatic conversion between XML and Standoff/RDF. This can be achieved by Standoff/RDF storing the order of tags and their hierarchical relationships. Then, an XML-to-Standoff Mapping for the standoff tag classes and properties has to be defined. The mapping is written in XML. Afterwards, an XML document can be imported into DSP-API, which will store it in Standoff/RDF format. The following example shows a possible mapping for a knoraDate: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>text</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>mydate</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/0001/anything#StandoffEventTag</classIri> <attributes> <attribute> <attributeName>description</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription</propertyIri> </attribute> </attributes> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffDateTag</type> <attributeName>knoraDate</attributeName> </datatype> </standoffClass> </mappingElement> </mapping> Once the mapping has been created, an XML like the following could be sent to DSP-API and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description=\"new year\" knoraDate=\"GREGORIAN:2016-12-31\">New Year's Eve</mydate>. It was a lot of fun. </text> The text and markup can then be searched using the search language Gravsearch (TODO: add link). When the document is retrieved, DSP-API converts it back to the original XML. Using Gravsearch for searches DSP-API provides a search language called Gravsearch that is based on the SPARQL language. Gravsearch supports DSP\u2019s humanites-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows for combining text-related criteria with any other criteria in searches. TODO: add link to Gravsearch doc.","title":"Introduction"},{"location":"developers/introduction/#introduction-to-dsp-api","text":"The main software framework in the back-end of the DaSCH Service Platform is called DSP-API (previously Knora). DSP-API is a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP-API aims to solve key problems in the long-term preservation and reuse of humanities data: Traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. Downloading the data to check whether the data are interesting or not is time-consuming and makes it impractical to reuse data from many different sources. DSP-API solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP-API, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different data formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old data files, or even all the operating systems that these programs ran on. Instead of preserving all these data formats, DSP-API supports the conversion of all sorts of data to a small number of formats that are suitable for long-term preservation, and that maintain the data\u2019s meaning and structure: Non-binary data is stored as R esource D escription F ramework ( RDF ), in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. For a concise information about RDF basics see here . Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by the media server SIPI , with metadata stored in the triplestore. For a concise information about SIPI see here . Moreover, DSP-API has built-in support for special data structures that occur on a regular basis in humanities data: persistent links, calender-independent dates and flexible searchable text markup. Persistent links are a very important feature. If a resource is changed, a new resource will be created in DSP-API. The older version remains available and citable, there will be no dead links. This means that if in a publication an older version is referenced, the cited version still can be displayed, but there will be a notice that a newer version exists with the corresponding link attached to it. A date could be given in any kind of calendar - e.g. the Julian, Gregorian, Jewish or Islamic - just to name the most frequent ones. DSP-API stores dates using the Julian day count that was established by astronomers. Use of the Julian day count easily allows for conversion from one calendar into another and to calculate distances between two dates. It is possible to search for a date in one calendar and to convert it into another one. Commonly used text markup systems have troubles to cope with overlapping markup. DSP-API solves this problem by using Standoff/RDF markup where the markup is stored as RDF data, separately from the text. This enables overlapping markup. DSP-API\u2019s RDF-based standoff is designed to support the needs of complex digital critical editions. DSP-API can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time. The following table contains a non-exhaustive list of data formats and the information on how these formats are stored and managed by DSP-API (and SIPI): Original format Format in DSP-API Text (XML, LaTEX, Word, etc.) DSP resources (RDF) containing Standoff/RDF Tabular data, including relational databases DSP resources Data in tree or graph structures DSP resources Images (jpg, png, tiff, etc.) JPEG 2000 files stored by SIPI Audio and video files format not decided yet, stored by SIPI pdf stored by SIPI, but data reuse is improved by extracting the text for storage as Standoff/RDF DSP-API makes data available for reuse via its generic, standards-based A pplication P rogramming I nterfaces (APIs). A V irtual R esearch E nvironment (VRE) can then use these APIs to search, link together, and add to data from different research projects in a unified way. The full DSP-API documentation can be found here .","title":"Introduction to DSP-API"},{"location":"developers/introduction/#layout-of-dasch-service-platform","text":"The DaSCH Service Platform is a platform that includes five layers (see Figure 1). The bottom layer consists of an RDF triplestore, the IIIF-based media server SIPI , the knora-base ontology and any project specific ontologies that extend the base ontology. The second layer is occupied by the DSP-API which is a RESTful API, i.e. an application program interface that uses HTTP requests to GET, PUT, POST and DELETE data. The DSP API has an implemented access control. It returns information in JSON-LD format. In order to make the data accessible in an easy way, three more layers are built on top of the DSP API. The DSP-JS library comprises the third layer, it contains a reusable Node.js module for HTTP requests written in TypeScript. Layer four is occupied by DSP UI modules . These modules help to create a graphical user interface. They are developed with Angular and TypeScript and designed in such a way that they can be integrated to an Angular project. The top layer is made up of the generic DSP-APP and the more specific project Apps. From the top layer Gravsearch queries are sent to the DSP API, where permissions are checked and the queries translated into SPARQL queries, which are sent further down to the triplestore. The results are returned to the DSP-APP if the user has the sufficient permissions. In such a way, copyrighted material can be protected. Figure 1: DaSCH Service Platform architecture. The generic web app DSP-APP itself consists of three different parts (see Figure 2). First, there is the project administration part where you can manage your project - build your data model, set permissions, add users, etc. Then, there is a cross-project research platform where you search (full text, advanced or expert search), add or modify your data - this is your working environment. The third component is the Manifest+ viewer wich is designed for project presentation. Alternatively, it is possible to build more elaborate project-specific Apps based on the provided DSP-API modules in the different layers. However, it's up to you to keep such project-specific Apps compatible with the latest DSP API version. Figure 2: Details of DSP-APP. Currently, the following programming languages, software and formats are used for the various components: Component Software and formats RDF triplestore Apache Jena Fuseki Ontologies knora-base ontology and derived project ontologies SIPI C++, Lua, API-format: JSON DSP API Scala, API-formats: JSON-LD, RDF/XML or Turtle DSP-JS TypeScript, communication with DSP-API DSP-UI modules Angular modules, TypeScript, uses DSP-JS DSP-APP Angular, TypeScript, uses DSP-UI modules and DSP-JS","title":"Layout of DaSCH Service Platform"},{"location":"developers/introduction/#the-knora-base-ontology","text":"DSP-API has a base ontology , i.e. a data model, with pre-defined basic data types. In addition to this base ontology, each project can create its own data model which is capable to describe the types of items it wishes to store. Project specific ontologies must be extensions of the knora-base ontology. The knora-base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In our documents it will be identified by the prefix knora-base or simply kb . TODO: add link to knora-base doc.","title":"The knora-base ontology"},{"location":"developers/introduction/#standoffrdf-text-markup","text":"Standoff markup is text markup that is stored separately from the content it describes. DSP-API\u2019s Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. By storing markup as RDF, DSP-API can search for markup structures in the same way as for any RDF data structure. This enables searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as DSP resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. One could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain period of time. In DSP-API\u2019s Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, but has its own semantic properties. It is possible to define own tag classes in the ontology by creating subclasses of the already defined kb:StandoffTag , and to attach own properties to them. ### http://www.knora.org/ontology/knora-base#StandoffLinkTag kb:StandoffLinkTag rdf:type owl:Class ; rdfs:subClassOf kb:StandoffTag , [ rdf:type owl:Restriction ; owl:onProperty kb:standoffTagHasLink ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"Represents a reference to a Knora resource in a TextValue\"@en . DSP-API supports automatic conversion between XML and Standoff/RDF. This can be achieved by Standoff/RDF storing the order of tags and their hierarchical relationships. Then, an XML-to-Standoff Mapping for the standoff tag classes and properties has to be defined. The mapping is written in XML. Afterwards, an XML document can be imported into DSP-API, which will store it in Standoff/RDF format. The following example shows a possible mapping for a knoraDate: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>text</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>mydate</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/0001/anything#StandoffEventTag</classIri> <attributes> <attribute> <attributeName>description</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription</propertyIri> </attribute> </attributes> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffDateTag</type> <attributeName>knoraDate</attributeName> </datatype> </standoffClass> </mappingElement> </mapping> Once the mapping has been created, an XML like the following could be sent to DSP-API and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description=\"new year\" knoraDate=\"GREGORIAN:2016-12-31\">New Year's Eve</mydate>. It was a lot of fun. </text> The text and markup can then be searched using the search language Gravsearch (TODO: add link). When the document is retrieved, DSP-API converts it back to the original XML.","title":"Standoff/RDF Text Markup"},{"location":"developers/introduction/#using-gravsearch-for-searches","text":"DSP-API provides a search language called Gravsearch that is based on the SPARQL language. Gravsearch supports DSP\u2019s humanites-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows for combining text-related criteria with any other criteria in searches. TODO: add link to Gravsearch doc.","title":"Using Gravsearch for searches"},{"location":"developers/rdf/","text":"Resource Description Framework (RDF) basics The Resource Description Framework (RDF) is the basic representation language and foundation of the Semantic Web. It addresses the fundamental issue of managing distributed data. All things in the world are referred to as resources . Resources can be anything: documents, people, physical objects as well as abstract concepts. The Resource Description Framework (RDF) is the framework for expressing information about such resources. It is useful if information on the Web is not only displayed, but needs to be processed by applications. The following introduction to RDF draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 27\u201350 which we warmly recommend for reading. Further information can be found in the RDF 1.1 Primer . A note about the examples in this document It was aimed for to explain all following language features by using only one exemplary project. The setting of the chosen project is the following: It is about archaeological objects stemming from different findspots - known and unknown - and kept in different institutions around the world today. These objects show depictions of mythological scenes that illustrate episodes known from ancient literature, e.g. the Iliad or the Odyssey of Homer, or reflect thoughts of various ancient philosophers about the nature of our world and all creatures living therein. For some of these objects other data and documents exist on the Web, e.g. entries in museum databases, and we may possess low or high resolution images of them. Furthermore, the findspots - if known - can be identified unambigously by reference to geographical databases, e.g. GeoNames. If data are available in tabular form, the rows represent the items we intend to describe and each column represents some property of these items. The cells in the table then denote particular values for these properties. Table 1 shows a small excerpt of such a table from our exemplary project. ID Category City Institution InventoryNr. 1 Ceramics Boston Museum of Fine Arts 28.46 2 Glyptics London British Museum 2717 3 Relief New York Metropolitan Museum 24.97.11 In RDF, each of these cells has to be represented with three values which are called triples : a global reference for the row, a global reference for the column, and the value in the cell itself. The identifier for the row is the subject of the triple, the identifier for the column the predicate of the triple, and the value in the cell the object of the triple. There are three types of RDF data that can occur in triples: I nternational R esource I dentifiers ( IRI s) / U niversal R esource I dentifiers ( URI s), literals and blank nodes . A triple now describes the relationship between two resources which are the subject and the object of the triple. The predicate represents the nature of the relationship between subject and object. The relationship is directional - the predicate always points from the subject to the object - and is called a property . Table 2 shows all the triples of the data in Table 1. |Subject|Predicate|Object| |-----|:----:|---| |ID 1|belongsToCategory|Ceramics| |ID 1|todayIn|Boston| |ID 1|isKeptIn|Museum of Fine Arts| |ID 1|hasInventory|28.46| |ID 2|belongsToCategory|Glyptics| |ID 2|todayIn|London| |ID 2|isKeptIn|British Museum| |ID 2|hasInventory|2717| |ID 3|belongsToCategory|Relief| |ID 3|todayIn|New York| |ID 3|isKeptIn|Metropolitan Museum| |ID 3|hasInventory|24.97.11| Often, the same resource, e.g. a person, is referenced in multiple triples. When more than one triple refers to the same thing, it is more useful to view the triples in a directed graph where each triple is depicted by nodes and arcs: the subjects and objects of the triples are the nodes while the predicates denote the arcs with the predicate as label on the arc: Furthermore, if the subject or object is a URI/IRI or a blank node, it is depicted within an ellipse, if it is a literal value, however, within a rectangle. The graph display of the triples in Table 2 then looks as follows: Let's assume we possess the information in Table 3 from another source which we intend to merge with our data presented in Table 1. |Work|Author|Depiction| |-----|:----:|---| |Iliad|Homer|24.97.11| |Odyssey|Homer|24.97.11| This provides us with the following triples in Table 4: |Subject|Predicate|Object| |-----|:----:|---| |Iliad|hasAuthor|Homer| |Odyssey|hasAuthor|Homer| |Iliad|hasDepictionOn|24.97.11| |Odyssey|hasDepictionOn|24.97.11| The graph display of the triples in Table 2 concerning ID 3 and of the triples in Table 4 looks as follows: Since we now look at one specific example, namely \"ID 3\", all the values are literals and hence depicted in yellow rectangles. Namespaces, Uniform Resource Identifiers (URIs) and International Resource Identifiers (IRIs) If we intend to merge information from different sources, an essential question is whether a node in one graph is the same node as a node in another graph. RDF solves this issue through use of U niform R esource I dentifiers (URIs) or I nternational R esource I dentifiers (IRIs). Our well known web addresses, the URLs, are just a special case of URIs and IRIs. An International Resource Identifier is the internationalised form of a URI. IRIs extend the allowed characters in URIs from a subset of the ASCII character set to almost all characters of the Universal Code Character Set (Unicode / ISO 10646). The syntax of the URI/IRI allows to deference it, i.e. to use all the information in the URI/IRI such as server name, protocol, port number, file name etc. to locate a file or a location on the Web. The possibility of dereferencing enables participation in a global Web infrastructure. URIs and IRIs are painful to write out in detail when expressing models. Hence, it is common to use an abbreviation scheme. Then a URI/IRI has two parts: a namespace and an identifier with a colon in between. The representation for the identifier United Kingdom in the namespace geonames is geonames:UnitedKingdom . URIs/IRIs may not contain embedded spaces. Hence, the so-called InterCap convention is followed: names that consist of multiple words are transformed to identifiers without spaces by capitalizing each word: \"part of\" becomes partOf , \"Measure for Measure\" MeasureForMeasure , and so on. The selection of namespaces is unrestricted. However, it is common practice to refer to related identifiers in a single namespace. Following the above example all geographical information would be placed into the suggestive namespace geonames . These names correspond to fully qualified URIs - geonames stands for material in the geographical database GeoNames . Using URIs/IRIs as standard for global identifiers enables for a worldwide reference and thus, two peolpe anywhere in the world to refer to the same thing unequivocally. This property allows for specifying certain terms by a standard organization such as W3C. W3C standards provide definitions for terms such as e.g. type , Class , subClassOf which are intended to apply globally across the Semantic Web. W3C has defined a number of standard namespaces for use with Web technologies. The most important are: * xsd: Indicates identifiers for XML schema definition. The global IRI for the xsd namespace is http://www.w3.org/2001/XMLSchema# . * xslns: Indicates identifiers for XML namespaces. The global IRI for the xslns namespace is https://www.w3.org/XML/1998/namespace . * rdf: Indicates identifiers used in RDF. The global IRI for the rdf namespace is http://www.w3.org/1999/02/22-rdf-syntax-ns# . * rdfs: Indicates identifiers used for the RDF Schema language (RDFS). The global IRI for the rdfs namespace is http://www.w3.org/2000/01/rdf-schema# . * owl: Indicates identifiers used for the Web Ontology Language (OWL). The global IRI for the owl namespace is http://www.w3.org/2002/07/owl# . Any URI in one of these namespaces - e.g. rdfs:subClassOf which is short for http://www.w3.org/2000/01/rdf-schema#subClassOf - refers to a particular term defined in the RDFS standard by the W3C. The term can also be dereferenced: at the server www.w3.org there is a page at the location 2000/01/rdf-schema with an entry about rdfs:subClassOf which gives additional information about this resource. Literals Literals are values that are not URIs/IRIs. They may be simple strings such as \"Homer\", dates such as \"April 30th, 700 BCE\", numbers such as \"2.71828\". They are often associated with one of the following datatypes (list non-exhaustive): * boolean with value true or false * string with value character string * decimal with an arbitrary-precision decimal number as value * integer with an arbitrary-precision integer number as value * date with value in format yyyy-mm-dd Literals may only appear as object of a triple. Identifiers in the RDF namespace The RDF data model specifies the notion of triples and the merging of sets of triples. With the introduction of namespaces RDF provides agreements on how to refer to a particular entity. The RDF standard defines a small number of standard identifiers in the namespace rdf . rdf:type is a property that provides an elementary system in RDF to define types. rdf:type can be the predicate of a triple, the subject of the triple can be any identifier and the object of the triple is understood to be a type. rdf:type can be used to e.g. state, that Homers works belong to a group of literary works we call Poetry: Subject Predicate Object Iliad rdf:type Poetry Odyssey rdf:type Poetry rdf:Property is an identifier to indicate when another identifier is to be used as a predicate rather than as subject or object. Some triples from our examples in Table 2 and Table 4 can be expressed with rdf:Property in the following way: Subject Predicate Object wrote rdf:type rdf:Property isKeptIn rdf:type rdf:Property hasDepictionOn rdf:type rdf:Property Reification The strict subject - predicate - object form of RDF triples is limiting if one wants to qualify a statement further, if a statement about another statement seems desireable. We may wish to express that our object with ID 3 in Table 1 was bought by the Metropolitan Museum in 1924. Such a process of a statement about a statement is called reification . Reification can be achieved by different approaches. The easiest approach is to add just further triples expressing the desired relationship. myonto:ID3 myonto:todayIn \"New York\" . myonto:ID3 myonto:keptIn \"Metropolitan Museum\" . myonto:ID3 myonto:hasAccessionDate 1924 . The namespace myonto is used in the above example to express that the statements concern resources and properties which are defined in our own namespace. In contrast, otheronto will be used in following examples to express that an external not further defined namespace is referred to. The simple approach shown above works well if more information about some event or statement needs to be specified. However, it doesn't work well in cases when information about the statement itself shall be expressed: We may wish to express that the information that on our object with ID 3 in Table 1 scenes from the Iliad are depicted (information contained in Table 3) stems from the catalogue entry of this object in the online collection of the Metropolitan Museum. Such metadata about statements are often related with provenance indications, likelihood expressions, context information or time spans. In such cases it is necessary to explicitly make a statement about a statement. This process, called explicit reification is supported by the RDF standard with three resources called rdf:subject , rdf:predicate and rdf:object . With the following set of triples we can express that in the online collection of the Metropolitan Museum is written that ID 3 contains a depiction of scenes from the Iliad: myonto:n1 rdf:subject myonto:Iliad ; rdf:predicate myonto:hasDepictionOn ; rdf:object myonto:ID 3 . web:MetropolitanMuseum myonto:says myonto:n1 . Expressing RDF in textual form: Turtle When data are published in RDF on the Web the issue of representing RDF in text arises. There are multiple ways of achieving this. We are using a compact serialization of RDF which is called Turtle . It uses pre-defined shortcuts or namespaces. Since a binding between the local used namespaces and the global URIs/IRIs have to be achieved, Turtle begins with a preamble in which these bindings are defined: @prefix myonto: http://www.myontology @prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# With these abbreviations the triples can be expressed in subject/predicate/object order followed by a period. myonto:HomerWorks rdf:type myonto:Poetry . This statement expresses that Homer's literary works belong to the category of poetry. If several triples share a common subject it need not be repeated each time. Instead of terminating the first triple with a period, a semicolon (;) is used to indicate that another triple with the same subject follows. myonto:Homer rdf:type myonto:Author ; myonto:wrote \"Iliad\" . This statement expresses that in my ontology named myonto Homer is part of my class Author and that he wrote the Iliad. If there are several triples that share both subject and predicate, a comma (,) is used to separate the objects. E.g. to express, that Homer wrote both the Iliad and the Odyssey, I can use the following statement: myonto:Homer myonto:wrote myonto:Iliad, myonto:Odyssey . To improve terseness and readability Turtle provides some abbreviations. The most widley used abbreviation is the word a to mean rdf:type . Thus, the following two triples are equivalent, both telling that the class Ceramics in my ontology is part of a larger class called Category: myonto:Ceramics rdf:type myonto:Category . myonto:Ceramics a myonto:Category . Blank nodes Sometimes we are aware of that something exists, that we know some things about it, but its identity is unknown. We want to express what we know about this resource without bothering to use a global identifier. Such a resource without a global identifier can be represented by a blank node. Blank nodes are comparable to the unknown variables x or y in an equation - they represent something without saying what their value is. Blank nodes can be the subject and/or the object of a triple. Within the framework of our example of archaeological objects showing depictions of Homeric poetry which are held by different institutions, the exact provenience of some objects may be unknown since they stem from illicit excavations and were bought on the antiquities market many years ago. Nevertheless, we know that each object possesses a provenience. A blank node is indicated by square brackets ([]). All triples of which it is a subject are placed within these brackets. The information that if an object was bought on the antiquities market no detail information about its find context is available can be put inside a blank node: [ rdf:type myonto:Market ; myonto:noInfo myonto:FindContext ] Such a blank node can then be referred to in other triples by including the entire bracketed sequence in place of the blank node. The following example expresses that all my objects which belong to the class UnprovenancedObj in my ontology myonto were bought on the antiquities market and for them I have no detail information about their find contexts available: myonto:UnprovenancedObj myonto:isPartOf [ rdf:type myonto:Market ; myonto:noInfo myonto:FindContext ] Ordered information in RDF Ordering of RDF triples has to be specified explicitly: elements can be ordered in a list format. In Turtle an ordered list can be expressed by putting a sequence of objects within brackets (()). If we want to express that the king of Mykene, Agamemnon, was the father of four children, Iphigeneia being the oldest and Orestes being the youngest, we can express that in the following way: Agamemnon myonto:isFatherOf (Iphigeneia, Elektra, Chrysothemis, Orestes) . RDF Schema (RDFS) RDF simply creates a graph structure to represent data. The RDF S chema (RDFS) is a semantic extension of RDF wich provides some guidelines about how to use this graph structure, i.e. it imposes special syntactic conditions or restrictions upon RDF graphs. The schema is informaton about the data. It should help to provide meaning to the data. Thus, it is a layer on top of the RDF layer to describe consistency constraints in the data. The key to these levels is inferencing . The statements of meaning are given in the form of an inference pattern: \"Given some initial information, the following new information can be derived.\" That's the way the RDF Schema language (RDFS) and also the Web Ontology Language (OWL) work. All schema information in RDFS is expressed by RDF triples. The meaning of asserted triples is defined with new inferred triples. The structures that describe the meaning of the data are also in triples. The following introduction to RDF Schema draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 113\u2013152 which we warmly recommend for reading. Further information can be found in the Recommendations of RDF Schema 1.1 . Asserted triples and inferred triples Asserted triples are triple data that were explicitly added in the original RDF store. Inferred triples are additional triples that are inferred by one of the inference rules. There is no logical distinction between inferred and asserted triples. Hence, one should be careful concerning inference rules and how to implement them. The RDFS and OWL standards define for certain patterns of triples which inferences are valid. The simplest approach is to store all triples in a single store and to ignore whether they are asserted or inferred. This approach is called cached inferencing since all inferences are stored with the data. It is simple, but the number of triples in the triple store increases and some inferred triples may later turn out to be incorrect und unwarranted. The other extreme is to never actually store any inferred triples in any persistent store. Then, inferencing is done in response to queries only. This approach can be called just in time inferencing , since the inferences are made just in time. The query responses are produced such that they respect all the appropriate inferences, but no inferred triple is retained. Both approaches have an important impact if data sources change, i.e. if a triple is deleted or a new triple added. If cached inferencing was chosen, originally inferred triples which are no longer valid must be identified and removed or new ones added. An important variant of just in time inferencing is where explicit inferencing is undesired. What kind of inferencing is needed depends on the required level of expressivity for a certain task. There are different inferencing levels. RDFS operates on a small number of inference rules that deal mostly with relating classes to subclasses and properties to classes. OWL includes constraints on properties and notions of equality and includes rules for describing classes based on allowed values for properties. All these standards use inferencing, but they differ in the inferencing that they support. Classes Resources can be grouped in classes which are themselves resources. The members of such a class are known as instances of the class. Classes are often identified by URIs/IRIs. All RDF datatypes are classes. The instances of a class that is a datatype are the members of the value space of the datatype. Thus, \"3.14\" is an instance of the class decimal, \"4\" is an instance of the class integer, \"2000-01-01\" is an instance of the class date, etc. The basic construct for specifying a group of related resources in RDFS is called an rdfs:Class . The way to express that something is a class is with a triple in which the predicate is rdf:type and the object is rdfs:Class as in the following examples: myonto:Ceramics rdf:type rdfs:Class . myonto:BlackFigured rdf:type rdfs:Class . These triples express that our resources Ceramics and BlackFigured are classes. One of the basic terms is rdfs:subClassOf . The meaning of \" B is a subClassOf C \" is \"every member of class B is also a member of class C\", expressed in the form of an inference. From a further information \" x is a member of B \" one can derive the new information \" x is a member of C \". Speaking more generally, if a class A is a subclass of another class B, then anything of type A is also of type B. This is called the type propagation rule . This feature of inference systems is particulary useful in a Semantic Web context in which new combinations of relationships likely occur as data from multiple sources are merged. In the framework of our example the class BlackFigured is a subclass of the class Ceramics . For any member of the class BlackFigured we can then derive that it is also a member of the class Ceramics due to the following statement : myonto:BlackFigured rdfs:subClassOf myonto:Ceramics . A class may be a member of its own class extension and an instance of itself, this applies e.g. for rdfs:Class . Properties An RDF property describes the relationship between a subject resource and an object resource. Properties with inferences One of the most fundemantal terms in RDFS is rdfs:subPropertyOf . It is a transitive property and allows a modeler to describe a hierarchy of related properties. If we want to express that some of the people who work for a museum are permanently employed while others possess only loose contracts we could express this fact with the following triples: myonto:isEmployedBy rdfs:subPropertyOf myonto:worksFor . myonto:contractsTo rdfs:subPropertyOf myonto:worksFor . Regardless whether a person is employed by the museum or is a contractor, the person works for the museum. Other basic properties are rdfs:range and rdfs:domain . They have meanings inspired by the mathematical use of the words range and domain : the domain of a function is the set of values for which it is defined, its range is the set of values it can take. Both give informaton about how a property P is to be used: domain refers to the subject of any triple that uses P as its predicate, range refers to the object of any such triple. rdfs:domain P rdfs:domain D . means that property P has domain D . From this we can infer that the subject of that triple is a member of the class D . rdfs:domain can be used to specify with which class the defined property can be used with. It is possible to specify multiple rdfs:domain properties when defining a property. We pick just two classes from our example - Ceramics and BlackFigured - which show a subclass relation: myonto:BlackFigured rdfs:subClassOf myonto:Ceramics . We now have a property called incised whose domain is BlackFigured . myonto:incised rdfs:domain myonto:BlackFigured . This means that all my objects with incised decoration belong to the class BlackFigured . rdfs:range P rdfs:range R . means that the property P has range R . From this we can infer that the object (the value of P ) of that triple is a member of class R . If the predicate of a triple has more than one rdfs:range property, the resources denoted by the objects of triples are instances of all the classes stated by the rdfs:range properties. If we want to specify that queens who gave birth to a son could theoretically become queen mothers, we could do that with the following combination of rdfs:domain and rdfs:range : myonto:hasSon rdfs:domain myonto:Queen . myonto:hasSon rdfs:range myonto:QueenMother . It is important to know that if P is used in an inconsistent way with this declaration, RDFS does not signal an error, but rather infers the necessary type information to bring P into accordance with its domain and range declarations! In RDFS, there is no notion of an incorrect or inconsistent inference, i.e. it will never proclaim an input as invalid but simply infer appropriate type information. Domains and ranges are not used to validate information, but to determine new information based on old information. In practice, there are often better and more appropriate options to use instead of rdfs:domain and rdfs:range alone. Properties without inferences RDFS provides some properties from which no inferences can be drawn, i.e. no inference semantics is defined for them. They are useful and important for documentation purposes. These are rdfs:label , rdfs:comment , rdfs:seeAlso and rdfs:isDefinedBy . Resources on the Semantic Web are specified by IRIs/URIs which are not meaningful to people. Thus, RDFS provides the property rdfs:label whose intended use is to provide a human-readable version for any resource's name. Multilingual labels are possible if the language tagging facility of RDF literals is used. myonto:BlackFigured rdfs:label \"black-figured vessels\"@en, \"schwarzfigurige Gef\u00e4sse\"@de . Frequently it is useful to add comments about a model, i.e. to document it properly. In RDFS, rdfs:comment is an instance of rdf:Property that can be used to provide a human-readable description of a resource. Multilingual documentation is possible if the language tagging facility of RDF literals is used. To make a comment a triple using the property rdfs:comment as a predicate has to be asserted. myonto:BlackFigured rdfs:comment \"The class BlackFigured contains ceramic vessels where the decoration is painted with black paint.\" . In the case where a resource is an URL, supplementary information about this resource may be useful. This additional information is often included in documents. rdfs:seeAlso provides a way to specify the web location of such supplementary information. The web location has to be given in the form of an IRI/URI! The precise behaviour of a processor is not specified, but most tools that encounter rdfs:seeAlso link them to those links in a browser or application interface. In our example we could link findspots of archaeological objects to a web resource with geodata, e.g. GeoNames, in the following way: myonto:latitude rdfs:seeAlso geonames:lat . rdfs:isDefinedby provides a link to the primary resource of information about a resource. Thus, the definitional description of a resource can be found, e.g. rdfs:isDefinedBy is defined in RDF to be a rdfs:subPropertyOf of rdfs:seeAlso . Combinations and patterns Intersection RDFS inference rules are few and rather simple. More specific patterns can be obtained by combining basic RDFS features. One such case is set intersection. If we intend to draw the inference that if a resource x is an instance of class C , then it should also be an instance of classes A and B , expressing the formal relationship C \u2286 A \u2229 B . Such an inference can be obtained by making C a subclass of A and B : :C rdfs:subClassOf :A . :C rdfs:subClassOf :B . Due to the inference rule defined for rdfs:subClassOf we can infer from the triple x rdf:type :C . the desired triples x rdf:type :A . x rdf:type :B . Thus, from a membership in C membership in A and B can be inferred. But from membership in A and B membership in C cannot be inferred! Inferences can only be drawn in one direction. In an analogous way to the treatment of classes, set intersection can be defined for properties using the construct rdfs:subPropertyOf . Union The union of two sets ( A \u222a B \u2286 C ) can be obtained by making C a superclass of A and B . :A rdfs:subClassOf :C . :B rdfs:subClassOf :C . Then, for any instance x that is either a member of class A or of B it will be inferred that it is also a member of class C . In an analogous way to the treatment of classes, set union can be defined for properties using rdfs:subPropertyOf . Collections A collection is represented as a list of items. rdf:List is an instance of rdfs:Class that can be used to build descriptions of lists and other list-like structures. Summary The following Figure 4 illustrates the concepts of resource, class, and sub-class based on our example project. Figure 5 shows the same in a more general way: resources are denoted by a large black dot and arrows are drawn from a resource to the class it defines. A sub-class is shown by a rectangle (the sub-class) completely enclosed by another (the super-class), i.e. class ConstraintProperty is a subclass of class Property. The notion rdf:type specifies that something is a member of a group, i.e. an instance of a class. By using rdfs:Class instead of rdf:type a description of the meaning of a membership in a group is gained. Meaning is expressed through the mechanisms of inference in RDFS that can be drawn when a resource is used in a certain way. The following Figure 6 expresses the same information about the class hierarchy, but does so using a graphic representation of the RDF data model. If a class is a subset of another, there is an arc labelled \"s\" from the node representing the first class to the node representing the second one (\"s\" stands for rdfs:subClassOf ). If a resource was an instance of a class, then there is an arc labelled \"t\" from the resource to the node representing the class (\"t\" stands for rdf:type ). Not all arcs are drawn, e.g. rdfs:ConstraintProperty is a subclass of rdfs:Resource because it is a subclass of rdf:Property which is a subclass of rdfs:Resource . Examples: - The class rdfs:Literal is an instance of rdfs:Class and an instance of rdfs:Resource . - The class rdf:Property is the class of RDF properties and an instance of rdfs:Class . Web Ontology Language (OWL) OWL is intended to be used when information contained in documents needs to be processed by applications, it explicitly represents the meaning of terms in vocabularies and the relationship between those terms. The representation of terms and their interrelationships are called an ontology . A concrete syntax is needed in order to store ontologies and to exchange them among tools and applications. The primary exchange syntax for OWL is the XML syntax for RDF (RDF/XML), but other syntaxes such as e.g. Turtle are also frequently used. The data described by an OWL ontology is interpreted as a set of \"individuals\" and a set of \"property assertions\" which relate these individuals to each other. An ontology consists of a set of axioms which place constraints on sets of individuals called \"classes\" and the types of relationships permitted between them. OWL ontologies can import other ontologies, adding information from the imported ontology to the current ontology. The main building blocks of the OWL language are an RDF graph and at least one concrete syntax - there may be more than one - that can be used to serialize and exchange ontologies. OWL has been designed to meet the needs for a Web Ontology Language. It is part of the W3C recommendations related to the Semantic Web: - XML provides a surface syntax for structured documents, but imposes no semantic constraints. - XML Schema is a language for restricting the structure of XML documents and extends XML with datatypes. - RDF is a datamodel for objects and relations between them. Furthermore, it provides a simple semantics for this datamodel and these datamodels can be represented in an XML syntax. - RDF Schema is a vocabulary for describing properties and classes of RDF resources, with a semantics for generalization-hierarchies of such properties and classes. - OWL then adds more vocabulary to RDF for describing properties and classes: e.g. relations between classes, cardinality, equality, characteristics of properties and enumerated classes. The following introduction to OWL draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 153\u2013305 which we warmly recommend for reading. Further information can be found in the Recommendations of the OWL 2 Web Ontology Language Document Overview (Second Edition) and the Wikipedia entry of OWL . owl:Class In OWL, a Class defines a group of individuals that belong together because they share some properties. An owl:Class differs from an rdfs:Class - an owl:Class is a special case of an rdfs:Class . Classes can be organised in a hierarchy using rdfs:subClassOf . Thus, owl:Class is defined as a subclass of rdfs:Class : owl:Class rdfs:subClassOf rdfs:Class . This means that every member of an owl:Class is also a member of rdfs:Class . There is a built-in most general class named owl:Thing which is the class of all individuals. It is a superclass of all OWL classes. There is also a built-in class named owl:Nothing which is the class that has no instances. It is a subclass of all OWL classes. owl:inverseOf Extra language features that are not directly provided by OWL, but that one may desire, such as e.g. superClassOf , are often supported by OWL as a combination of other features. The construct owl:inverseOf inverses a property, i.e. the direction of the property is reversed. This property can be used to define e.g. the superClassOf of a resource by combining it with rdfs:subClassOf in the following way: myonto:superClassOf owl:inverseOf rdfs:subClassOf . owl:SymmetricProperty For a symmetric property holds that if a pair (x,y) is an instance of the property P, then also the pair (y,x) is an instance of this property P. Such a property is provided by owl:SymmetricProperty and expressed in OWL as a Class. An example for such a property is to be married - if Agamemnon is married to Klytaimnestra, Klytaimnestra is also married to Agamemnon. Thus we can define a property married in our ontology with the following triples: myonto:married rdf:type owl:SymmetricProperty . Agamemnon myonto:married Klytaimnestra . Be aware - to make sure that owl:inverseOf works in both directions, one has to assert that owl:inverseOf rdf:type owl:SymmetricProperty . owl:TransitiveProperty Another important property is transitivity. Transitivity is a relation between three elements such that if it holds between the first and second and it also holds between the second and third, it must necessarily hold between the first and the third. In OWL, transitivity is provided by the construct owl:TransitiveProperty which is a class of properties. To model the property isLocatedIn in our ontology as a member of the transitive class we can state myonto:isLocatedIn rdf:type owl:TransitiveProperty . Together with the triples Rome myonto:isLocatedIn Italy . Italy myonto:isLocatedIn Europe . we can infer that Rome is located in Europe. owl:equivalentClass A frequent situation is that if information about the same entity from different sources is merged then the two providers of this information will not have used the same URI/IRI for refering to the same entity. When combining these data it may be useful to state that two URIs/IRIs actually refer to the same entity. When two classes are known to always have the same members, they are said to be equivalent . Such a situation can be expressed with one simple statement using owl:equivalentClass : owl:equivalentClass rdf:type owl:SymmetricProperty . myonto:GreekGods owl:equivalentClass otheronto:Deities . The second triple expresses that the class GreekGods in our ontology is equivalent to the class Deities in some other ontology we refer to. Note that when two classes are equivalent, it only means that they have the same members. But other properties of these classes aren't shared! owl:equivalentProperty If one intends to state that two properties are equivalent, owl:equivalentProperty can be used: myonto:isInvisible owl:equivalentClass otheronto:notSeen . This statement expresses that the property which is called isInvisible in our ontology, is named notSeen in some other ontology. owl:sameAs If it turns out that two individuals are actually one and the same, owl:sameAs can be used to state this fact: myonto:Puteoli owl:sameAs otheronto:Puzzeoli . This statement expresses that the site which is called Puteoli in our ontology, is the same as a site named Puzzeoli in some other ontology. owl:FunctionalProperty A functional property owl:FunctionalProperty is a property which can only have one single value. An everyday example for such a property is e.g. hasBirthplace since each person has only one birth place. Functional properties can be useful to infer sameness, e.g. if names with foreign characters are transliterated differently in two sources - a Greek \"B\" may be transliterated either as \"B\" or as \"V\", we can state: myonto:GreekB owl:FunctionalProperty otheronto:GreekV . owl:InverseFunctionalProperty However, it is more common to use the related notion of owl:InverseFunctionalProperty . One can think of this construct to be the inverse of owl:FunctionalProperty as its name suggests. Especially identifying numbers are inverse functional properties. myonto:hasInventoryNumber rdf:type owl:InverseFunctionalProperty . myonto:ID3 myonto:hasInventoryNumber \"24.97.11\" . otheronto:ID2435 myonto:hasInventoryNumber \"24.97.11\" . From the above example follows that ID 3 in my data set is the same object as ID 2435 in another data set. It is sometimes useful for a single property to be an owl:FunctionalProperty and an owl:InverseFunctionalProperty . This means that it is a one-to-one property: for each individual there is exactly one value for the property and the other way round. This feature is intended in the case of unique identifiers as in the following example: myonto:hasID rdfs:domain myonto:Monument . myonto:hasID rdfs:range xsd:Integer . myonto:hasID rfd:type owl:FunctionalProperty . myonto:hasID rfd:type owl:InverseFunctionalProperty . This means that each member of class Monument possesses a unique identifier that is an integer number. Any two monuments that share an ID must be the same (due to inverse functionality) and in addition, each monument can have at most one ID (due to functionality). owl:ObjectProperty and owl:DatatypeProperty The constructs owl:sameAs , owl:FunctionalProperty and owl:InverseFunctionalProperty especially help to describe how information from multiple sources can be merged. OWL can also provide useful information for editing tools if a value of some property may be either a link to another object or a widget for a particular data type. For this purpose OWL distinguishes between owl:DatatypeProperty and owl:ObjectProperty . owl:DatatypeProperty can have a data value as object, owl:ObjectProperty can have a resource as object. myonto:inSameMuseum rdf:type owl:ObjectProperty. myonto:shipVoyage rdf:type owl:DatatypeProperty. The first example may be used to express that one archaeological object is kept in the same museum as another archaeological object while the second example may select those individuals who participated in a ship voyage such as e.g. the Argonauts. Restrictions The construct owl:Restriction allows to describe individuals of classes in terms of existing properties and classes that have already been modeled. The class of all things in OWL called owl:Thing is unrestricted. A restriction provides some description that limits the kinds of things that can be said about a member of the class. A restriction class in OWL is defined by the keyword owl:onProperty . A description of how the new class is constrained can be provided e.g. by owl:allValuesFrom , owl:someValuesFrom and owl:hasValue . The membership in a restriction class must satisfy the specified conditions as well as the owl:onProperty specification. Property constraints owl:someValuesFrom selects all individuals from a class for which at least one value of the property P comes from class C . In our example we can formulate such a restriction as: [a owl:Restriction; owl:onProperty myonto:isLocatedIn; owl:someValuesFrom myonto:Museum] All archaeological objects kept in a museum today thus have been defined as all archaeological objects for which at least one value of the property isLocatedIn comes from the class Museum . The [ ] notation refers to a blank node which is described by the properties listed here. This restriction class has no specific name associated with it - it is defined by the properties of the restriction and is hence called an unnamed class . owl:allValuesFrom selects all individuals from a class for which all values of the property P come from class C . In our example we can formulate such a restriction as: [a owl:Restriction; owl:onProperty myonto:hasProvenience; owl:allValuesFrom myonto:Findspot] This restriction selects all our archaeological objects for which the findspot is known. A noteworthy difference between owl:someValuesFrom and owl:allValuesFrom is that the former implies that there must be such a member, while the latter technically means if there are any members, then they all must have this property which doesn't imply that there are any members. owl:hasValue is used to produce a restriction of the form \"all individuals that have the value A for the property P \". We can formulate such a restriction as: [ a owl:Restriction ; owl:onProperty myonto:P ; owl:hasValue myonto:A ] . Let's assume we defined a property myonto:hasImage which helps to select archaeological objects for which we possess images. We can now state a restriction for those with high resolution images: myonto:HighResolutionObject owl:equivalentClass [ a owl:Restriction ; owl:onProperty myonto:hasImage; owl:hasValue myonto:hasHighresImage ] . That we have such a high resolution image of a certain object we can formulate with the following triple: myonto:ID3 myonto:hasImage myonto:hasHighresImage . Then it is possible to deduce myonto:ID3 a myonto:HighResolutionObject . owl:hasValue is just a special case of the owl:someValuesFrom restriction. Nevertheless, it is very useful because it effectively turns specific instance descriptions into class descriptions. OWL provides a facility for defining new classes as unions ( owl:unionOf ) and intersections ( owl:intersectionOf ) of previously defined classes. The union of two or more classes includes the members of all those classes while the intersection includes only those that belong to every one of the classes. OWL allows to enumerate the members of a class using the construct owl:oneOf . If I have a class myonto:ObjectsSomeSmallMuseum with the members \"vase1\", \"vase2\" and \"relief1\", then: myonto:ObjectsSomeSmallMuseum rdf:type owl:Class; owl:oneOf (myonto:vase1 myonto:vase2 myonto:relief1). My class myonto:ObjectsSomeSmallMuseum is related via the property owl:oneOf to a list of the members of the class. However, owl:oneOf should be used only in situations in which the definition of the class is not likely to change at all or at least not frequently. One such case would e.g. be the number of planets in the solar system. In contrast, the above example may be appropriate for our own immediate needs, but not for a more general approach: although we include only three objects of this small museum in our data, the museum itself for sure owns many more. Sometimes it may be useful to state that one thing is different from another thing. OWL provides owl:differentFrom for this. An example is the following: myonto:Zenon owl:differentFrom otheronto:Zenon. Two different ancient Greek philosophers with the name Zenon are known. The above triple states that the Zenon in our ontology (e.g. Zenon of Elea) is not the same Zenon as in another ontology (e.g. Zenon of Kition). Cardinalities OWL also includes restrictions that refer to cardinalities , i.e. the number of values for a specific property. Cardinality restrictions can be used to define sets of particular interest. Cardinality refers to the number of distinct values a property has. The fact that we only know about two works attributed to Homer - the Iliad and the Odyssey - we may state by using owl:cardinality : [a owl:Restriction; owl:onProperty myonto:HomerWorks; owl:cardinality 2] Cardinality restrictions can also be used to specify upper and lower boundaries, the respective constructs are named owl:maxCardinality and owl:minCardinality . The restriction to cardinalities of 0 and 1 have special modeling utility: minCardinality 0 indicates a set of individuals for which some value for a specified property is optional minCardinality 1 indicates a set of individuals for which some value for a specified property is required maxCardinality 0 specifies that no value for the specified property is allowed maxCardinality 1 specifies that a value is unique (but need not exist) Reasoning with individuals and classes From an RDF perspective inferences about individuals and inferences about classes are very similar: in both cases new triples are added to the model based on the asserted triples. However, from a modeling perspective, these two kinds of reasoning are very different. The former draws specific conclusions about individuals while the latter draws general conclusions about classes of individuals. In the case of reasoning about individuals the information specified in one source is transformed according to a model for use in another context with the help of constructs such as rdfs:subClassOf , rdfs:subPropertyOf and various owl:Restriction . Class reasoning determines how data are related in general with constructs such as rdfs:subClassOf , rdfs:subPropertyOf , rdfs:domain or rdfs:range . Once these more general relationships have been inferred, the processing of the data can be done much easier. Composing files OWL provides a built-in class owl:Ontology . The URI/IRI of an ontology usually corresponds to the URL of the file on the Web where the ontology is stored. The corresponding URI/IRI can be eclosed in angle brackets as follows: <http://www.knora.org/ontology/knora-base> rdf:type owl:Ontology. This can be useful when modularity of semantic models is specified. The most frequent way to specify modularity is with the property owl:imports . This property connects two instances of the class owl:Ontology . Summary of constructs rdfs:subClassOf - the members of a subclass are also a member of a superclass rdfs:subPropertyOf - relations described by a subproperty also hold for the superproperty rdfs:domain - the subject of a triple is classified into the domain of the predicate rdfs:range - the object of a triple is classified into the range of the predicate rdfs:label - human-readable name of a resource, no semantics inferable rdfs:comment - human-readable information of the model, no semantics inferable owl:equivalentClass - the members of each class are also members of the other class owl:equivalentProperty - relations that hold for each property also hold for the other property owl:sameAs - all statements about one instance hold for the other instance owl:inverseOf - exchanges subject and object owl:TransitiveProperty - the chains of a relationship collapse into a single relationship owl:SymmetricProperty - the property is its own inverse owl:FunctionalProperty - only one value as object allowed owl:InverseFunctionalProperty - only one value as subject allowed owl:ObjectProperty - the property can have a resource as object owl:DatatypeProperty - the property can have a data value as object owl:Restriction - a building block in OWL that describes classes by restricting the values that are allowed for certain properties owl:hasValue - a type of restriction that refers to a single value for a property owl:someValuesFrom - a type of restriction that refers to a set from which some value for a property must come owl:allValuesFrom - a type of restriction that refers to a set from which all values for a property must come owl:onProperty - a link from a restriction to the property it restricts. owl:unionOf - unites classes and creates a new class owl:intersectionOf - determines the intersection of classes and creates a new class owl:complementOf - determines the compliment of a class and creates a new class owl:oneOf - specifies that a class consists just of the listed members owl:differentFrom - specifies that one individual is not identical to another one owl:disjointWith - specifies that two classes cannot share a member owl:cardinality - specifies information about the number of distict values for some property owl:minCardinality - specifies information about the minimum number of distinct values for a property owl:maxCardinality - specifies information about the maximum number of distinct values for a property owl:imports - allows one ontology to refer explicitly to another ontology.","title":"RDF"},{"location":"developers/rdf/#resource-description-framework-rdf-basics","text":"The Resource Description Framework (RDF) is the basic representation language and foundation of the Semantic Web. It addresses the fundamental issue of managing distributed data. All things in the world are referred to as resources . Resources can be anything: documents, people, physical objects as well as abstract concepts. The Resource Description Framework (RDF) is the framework for expressing information about such resources. It is useful if information on the Web is not only displayed, but needs to be processed by applications. The following introduction to RDF draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 27\u201350 which we warmly recommend for reading. Further information can be found in the RDF 1.1 Primer .","title":"Resource Description Framework (RDF) basics"},{"location":"developers/rdf/#a-note-about-the-examples-in-this-document","text":"It was aimed for to explain all following language features by using only one exemplary project. The setting of the chosen project is the following: It is about archaeological objects stemming from different findspots - known and unknown - and kept in different institutions around the world today. These objects show depictions of mythological scenes that illustrate episodes known from ancient literature, e.g. the Iliad or the Odyssey of Homer, or reflect thoughts of various ancient philosophers about the nature of our world and all creatures living therein. For some of these objects other data and documents exist on the Web, e.g. entries in museum databases, and we may possess low or high resolution images of them. Furthermore, the findspots - if known - can be identified unambigously by reference to geographical databases, e.g. GeoNames. If data are available in tabular form, the rows represent the items we intend to describe and each column represents some property of these items. The cells in the table then denote particular values for these properties. Table 1 shows a small excerpt of such a table from our exemplary project. ID Category City Institution InventoryNr. 1 Ceramics Boston Museum of Fine Arts 28.46 2 Glyptics London British Museum 2717 3 Relief New York Metropolitan Museum 24.97.11 In RDF, each of these cells has to be represented with three values which are called triples : a global reference for the row, a global reference for the column, and the value in the cell itself. The identifier for the row is the subject of the triple, the identifier for the column the predicate of the triple, and the value in the cell the object of the triple. There are three types of RDF data that can occur in triples: I nternational R esource I dentifiers ( IRI s) / U niversal R esource I dentifiers ( URI s), literals and blank nodes . A triple now describes the relationship between two resources which are the subject and the object of the triple. The predicate represents the nature of the relationship between subject and object. The relationship is directional - the predicate always points from the subject to the object - and is called a property . Table 2 shows all the triples of the data in Table 1. |Subject|Predicate|Object| |-----|:----:|---| |ID 1|belongsToCategory|Ceramics| |ID 1|todayIn|Boston| |ID 1|isKeptIn|Museum of Fine Arts| |ID 1|hasInventory|28.46| |ID 2|belongsToCategory|Glyptics| |ID 2|todayIn|London| |ID 2|isKeptIn|British Museum| |ID 2|hasInventory|2717| |ID 3|belongsToCategory|Relief| |ID 3|todayIn|New York| |ID 3|isKeptIn|Metropolitan Museum| |ID 3|hasInventory|24.97.11| Often, the same resource, e.g. a person, is referenced in multiple triples. When more than one triple refers to the same thing, it is more useful to view the triples in a directed graph where each triple is depicted by nodes and arcs: the subjects and objects of the triples are the nodes while the predicates denote the arcs with the predicate as label on the arc: Furthermore, if the subject or object is a URI/IRI or a blank node, it is depicted within an ellipse, if it is a literal value, however, within a rectangle. The graph display of the triples in Table 2 then looks as follows: Let's assume we possess the information in Table 3 from another source which we intend to merge with our data presented in Table 1. |Work|Author|Depiction| |-----|:----:|---| |Iliad|Homer|24.97.11| |Odyssey|Homer|24.97.11| This provides us with the following triples in Table 4: |Subject|Predicate|Object| |-----|:----:|---| |Iliad|hasAuthor|Homer| |Odyssey|hasAuthor|Homer| |Iliad|hasDepictionOn|24.97.11| |Odyssey|hasDepictionOn|24.97.11| The graph display of the triples in Table 2 concerning ID 3 and of the triples in Table 4 looks as follows: Since we now look at one specific example, namely \"ID 3\", all the values are literals and hence depicted in yellow rectangles.","title":"A note about the examples in this document"},{"location":"developers/rdf/#namespaces-uniform-resource-identifiers-uris-and-international-resource-identifiers-iris","text":"If we intend to merge information from different sources, an essential question is whether a node in one graph is the same node as a node in another graph. RDF solves this issue through use of U niform R esource I dentifiers (URIs) or I nternational R esource I dentifiers (IRIs). Our well known web addresses, the URLs, are just a special case of URIs and IRIs. An International Resource Identifier is the internationalised form of a URI. IRIs extend the allowed characters in URIs from a subset of the ASCII character set to almost all characters of the Universal Code Character Set (Unicode / ISO 10646). The syntax of the URI/IRI allows to deference it, i.e. to use all the information in the URI/IRI such as server name, protocol, port number, file name etc. to locate a file or a location on the Web. The possibility of dereferencing enables participation in a global Web infrastructure. URIs and IRIs are painful to write out in detail when expressing models. Hence, it is common to use an abbreviation scheme. Then a URI/IRI has two parts: a namespace and an identifier with a colon in between. The representation for the identifier United Kingdom in the namespace geonames is geonames:UnitedKingdom . URIs/IRIs may not contain embedded spaces. Hence, the so-called InterCap convention is followed: names that consist of multiple words are transformed to identifiers without spaces by capitalizing each word: \"part of\" becomes partOf , \"Measure for Measure\" MeasureForMeasure , and so on. The selection of namespaces is unrestricted. However, it is common practice to refer to related identifiers in a single namespace. Following the above example all geographical information would be placed into the suggestive namespace geonames . These names correspond to fully qualified URIs - geonames stands for material in the geographical database GeoNames . Using URIs/IRIs as standard for global identifiers enables for a worldwide reference and thus, two peolpe anywhere in the world to refer to the same thing unequivocally. This property allows for specifying certain terms by a standard organization such as W3C. W3C standards provide definitions for terms such as e.g. type , Class , subClassOf which are intended to apply globally across the Semantic Web. W3C has defined a number of standard namespaces for use with Web technologies. The most important are: * xsd: Indicates identifiers for XML schema definition. The global IRI for the xsd namespace is http://www.w3.org/2001/XMLSchema# . * xslns: Indicates identifiers for XML namespaces. The global IRI for the xslns namespace is https://www.w3.org/XML/1998/namespace . * rdf: Indicates identifiers used in RDF. The global IRI for the rdf namespace is http://www.w3.org/1999/02/22-rdf-syntax-ns# . * rdfs: Indicates identifiers used for the RDF Schema language (RDFS). The global IRI for the rdfs namespace is http://www.w3.org/2000/01/rdf-schema# . * owl: Indicates identifiers used for the Web Ontology Language (OWL). The global IRI for the owl namespace is http://www.w3.org/2002/07/owl# . Any URI in one of these namespaces - e.g. rdfs:subClassOf which is short for http://www.w3.org/2000/01/rdf-schema#subClassOf - refers to a particular term defined in the RDFS standard by the W3C. The term can also be dereferenced: at the server www.w3.org there is a page at the location 2000/01/rdf-schema with an entry about rdfs:subClassOf which gives additional information about this resource.","title":"Namespaces, Uniform Resource Identifiers (URIs) and International Resource Identifiers (IRIs)"},{"location":"developers/rdf/#literals","text":"Literals are values that are not URIs/IRIs. They may be simple strings such as \"Homer\", dates such as \"April 30th, 700 BCE\", numbers such as \"2.71828\". They are often associated with one of the following datatypes (list non-exhaustive): * boolean with value true or false * string with value character string * decimal with an arbitrary-precision decimal number as value * integer with an arbitrary-precision integer number as value * date with value in format yyyy-mm-dd Literals may only appear as object of a triple.","title":"Literals"},{"location":"developers/rdf/#identifiers-in-the-rdf-namespace","text":"The RDF data model specifies the notion of triples and the merging of sets of triples. With the introduction of namespaces RDF provides agreements on how to refer to a particular entity. The RDF standard defines a small number of standard identifiers in the namespace rdf . rdf:type is a property that provides an elementary system in RDF to define types. rdf:type can be the predicate of a triple, the subject of the triple can be any identifier and the object of the triple is understood to be a type. rdf:type can be used to e.g. state, that Homers works belong to a group of literary works we call Poetry: Subject Predicate Object Iliad rdf:type Poetry Odyssey rdf:type Poetry rdf:Property is an identifier to indicate when another identifier is to be used as a predicate rather than as subject or object. Some triples from our examples in Table 2 and Table 4 can be expressed with rdf:Property in the following way: Subject Predicate Object wrote rdf:type rdf:Property isKeptIn rdf:type rdf:Property hasDepictionOn rdf:type rdf:Property","title":"Identifiers in the RDF namespace"},{"location":"developers/rdf/#reification","text":"The strict subject - predicate - object form of RDF triples is limiting if one wants to qualify a statement further, if a statement about another statement seems desireable. We may wish to express that our object with ID 3 in Table 1 was bought by the Metropolitan Museum in 1924. Such a process of a statement about a statement is called reification . Reification can be achieved by different approaches. The easiest approach is to add just further triples expressing the desired relationship. myonto:ID3 myonto:todayIn \"New York\" . myonto:ID3 myonto:keptIn \"Metropolitan Museum\" . myonto:ID3 myonto:hasAccessionDate 1924 . The namespace myonto is used in the above example to express that the statements concern resources and properties which are defined in our own namespace. In contrast, otheronto will be used in following examples to express that an external not further defined namespace is referred to. The simple approach shown above works well if more information about some event or statement needs to be specified. However, it doesn't work well in cases when information about the statement itself shall be expressed: We may wish to express that the information that on our object with ID 3 in Table 1 scenes from the Iliad are depicted (information contained in Table 3) stems from the catalogue entry of this object in the online collection of the Metropolitan Museum. Such metadata about statements are often related with provenance indications, likelihood expressions, context information or time spans. In such cases it is necessary to explicitly make a statement about a statement. This process, called explicit reification is supported by the RDF standard with three resources called rdf:subject , rdf:predicate and rdf:object . With the following set of triples we can express that in the online collection of the Metropolitan Museum is written that ID 3 contains a depiction of scenes from the Iliad: myonto:n1 rdf:subject myonto:Iliad ; rdf:predicate myonto:hasDepictionOn ; rdf:object myonto:ID 3 . web:MetropolitanMuseum myonto:says myonto:n1 .","title":"Reification"},{"location":"developers/rdf/#expressing-rdf-in-textual-form-turtle","text":"When data are published in RDF on the Web the issue of representing RDF in text arises. There are multiple ways of achieving this. We are using a compact serialization of RDF which is called Turtle . It uses pre-defined shortcuts or namespaces. Since a binding between the local used namespaces and the global URIs/IRIs have to be achieved, Turtle begins with a preamble in which these bindings are defined: @prefix myonto: http://www.myontology @prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# With these abbreviations the triples can be expressed in subject/predicate/object order followed by a period. myonto:HomerWorks rdf:type myonto:Poetry . This statement expresses that Homer's literary works belong to the category of poetry. If several triples share a common subject it need not be repeated each time. Instead of terminating the first triple with a period, a semicolon (;) is used to indicate that another triple with the same subject follows. myonto:Homer rdf:type myonto:Author ; myonto:wrote \"Iliad\" . This statement expresses that in my ontology named myonto Homer is part of my class Author and that he wrote the Iliad. If there are several triples that share both subject and predicate, a comma (,) is used to separate the objects. E.g. to express, that Homer wrote both the Iliad and the Odyssey, I can use the following statement: myonto:Homer myonto:wrote myonto:Iliad, myonto:Odyssey . To improve terseness and readability Turtle provides some abbreviations. The most widley used abbreviation is the word a to mean rdf:type . Thus, the following two triples are equivalent, both telling that the class Ceramics in my ontology is part of a larger class called Category: myonto:Ceramics rdf:type myonto:Category . myonto:Ceramics a myonto:Category .","title":"Expressing RDF in textual form: Turtle"},{"location":"developers/rdf/#blank-nodes","text":"Sometimes we are aware of that something exists, that we know some things about it, but its identity is unknown. We want to express what we know about this resource without bothering to use a global identifier. Such a resource without a global identifier can be represented by a blank node. Blank nodes are comparable to the unknown variables x or y in an equation - they represent something without saying what their value is. Blank nodes can be the subject and/or the object of a triple. Within the framework of our example of archaeological objects showing depictions of Homeric poetry which are held by different institutions, the exact provenience of some objects may be unknown since they stem from illicit excavations and were bought on the antiquities market many years ago. Nevertheless, we know that each object possesses a provenience. A blank node is indicated by square brackets ([]). All triples of which it is a subject are placed within these brackets. The information that if an object was bought on the antiquities market no detail information about its find context is available can be put inside a blank node: [ rdf:type myonto:Market ; myonto:noInfo myonto:FindContext ] Such a blank node can then be referred to in other triples by including the entire bracketed sequence in place of the blank node. The following example expresses that all my objects which belong to the class UnprovenancedObj in my ontology myonto were bought on the antiquities market and for them I have no detail information about their find contexts available: myonto:UnprovenancedObj myonto:isPartOf [ rdf:type myonto:Market ; myonto:noInfo myonto:FindContext ]","title":"Blank nodes"},{"location":"developers/rdf/#ordered-information-in-rdf","text":"Ordering of RDF triples has to be specified explicitly: elements can be ordered in a list format. In Turtle an ordered list can be expressed by putting a sequence of objects within brackets (()). If we want to express that the king of Mykene, Agamemnon, was the father of four children, Iphigeneia being the oldest and Orestes being the youngest, we can express that in the following way: Agamemnon myonto:isFatherOf (Iphigeneia, Elektra, Chrysothemis, Orestes) .","title":"Ordered information in RDF"},{"location":"developers/rdf/#rdf-schema-rdfs","text":"RDF simply creates a graph structure to represent data. The RDF S chema (RDFS) is a semantic extension of RDF wich provides some guidelines about how to use this graph structure, i.e. it imposes special syntactic conditions or restrictions upon RDF graphs. The schema is informaton about the data. It should help to provide meaning to the data. Thus, it is a layer on top of the RDF layer to describe consistency constraints in the data. The key to these levels is inferencing . The statements of meaning are given in the form of an inference pattern: \"Given some initial information, the following new information can be derived.\" That's the way the RDF Schema language (RDFS) and also the Web Ontology Language (OWL) work. All schema information in RDFS is expressed by RDF triples. The meaning of asserted triples is defined with new inferred triples. The structures that describe the meaning of the data are also in triples. The following introduction to RDF Schema draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 113\u2013152 which we warmly recommend for reading. Further information can be found in the Recommendations of RDF Schema 1.1 .","title":"RDF Schema (RDFS)"},{"location":"developers/rdf/#asserted-triples-and-inferred-triples","text":"Asserted triples are triple data that were explicitly added in the original RDF store. Inferred triples are additional triples that are inferred by one of the inference rules. There is no logical distinction between inferred and asserted triples. Hence, one should be careful concerning inference rules and how to implement them. The RDFS and OWL standards define for certain patterns of triples which inferences are valid. The simplest approach is to store all triples in a single store and to ignore whether they are asserted or inferred. This approach is called cached inferencing since all inferences are stored with the data. It is simple, but the number of triples in the triple store increases and some inferred triples may later turn out to be incorrect und unwarranted. The other extreme is to never actually store any inferred triples in any persistent store. Then, inferencing is done in response to queries only. This approach can be called just in time inferencing , since the inferences are made just in time. The query responses are produced such that they respect all the appropriate inferences, but no inferred triple is retained. Both approaches have an important impact if data sources change, i.e. if a triple is deleted or a new triple added. If cached inferencing was chosen, originally inferred triples which are no longer valid must be identified and removed or new ones added. An important variant of just in time inferencing is where explicit inferencing is undesired. What kind of inferencing is needed depends on the required level of expressivity for a certain task. There are different inferencing levels. RDFS operates on a small number of inference rules that deal mostly with relating classes to subclasses and properties to classes. OWL includes constraints on properties and notions of equality and includes rules for describing classes based on allowed values for properties. All these standards use inferencing, but they differ in the inferencing that they support.","title":"Asserted triples and inferred triples"},{"location":"developers/rdf/#classes","text":"Resources can be grouped in classes which are themselves resources. The members of such a class are known as instances of the class. Classes are often identified by URIs/IRIs. All RDF datatypes are classes. The instances of a class that is a datatype are the members of the value space of the datatype. Thus, \"3.14\" is an instance of the class decimal, \"4\" is an instance of the class integer, \"2000-01-01\" is an instance of the class date, etc. The basic construct for specifying a group of related resources in RDFS is called an rdfs:Class . The way to express that something is a class is with a triple in which the predicate is rdf:type and the object is rdfs:Class as in the following examples: myonto:Ceramics rdf:type rdfs:Class . myonto:BlackFigured rdf:type rdfs:Class . These triples express that our resources Ceramics and BlackFigured are classes. One of the basic terms is rdfs:subClassOf . The meaning of \" B is a subClassOf C \" is \"every member of class B is also a member of class C\", expressed in the form of an inference. From a further information \" x is a member of B \" one can derive the new information \" x is a member of C \". Speaking more generally, if a class A is a subclass of another class B, then anything of type A is also of type B. This is called the type propagation rule . This feature of inference systems is particulary useful in a Semantic Web context in which new combinations of relationships likely occur as data from multiple sources are merged. In the framework of our example the class BlackFigured is a subclass of the class Ceramics . For any member of the class BlackFigured we can then derive that it is also a member of the class Ceramics due to the following statement : myonto:BlackFigured rdfs:subClassOf myonto:Ceramics . A class may be a member of its own class extension and an instance of itself, this applies e.g. for rdfs:Class .","title":"Classes"},{"location":"developers/rdf/#properties","text":"An RDF property describes the relationship between a subject resource and an object resource.","title":"Properties"},{"location":"developers/rdf/#properties-with-inferences","text":"One of the most fundemantal terms in RDFS is rdfs:subPropertyOf . It is a transitive property and allows a modeler to describe a hierarchy of related properties. If we want to express that some of the people who work for a museum are permanently employed while others possess only loose contracts we could express this fact with the following triples: myonto:isEmployedBy rdfs:subPropertyOf myonto:worksFor . myonto:contractsTo rdfs:subPropertyOf myonto:worksFor . Regardless whether a person is employed by the museum or is a contractor, the person works for the museum. Other basic properties are rdfs:range and rdfs:domain . They have meanings inspired by the mathematical use of the words range and domain : the domain of a function is the set of values for which it is defined, its range is the set of values it can take. Both give informaton about how a property P is to be used: domain refers to the subject of any triple that uses P as its predicate, range refers to the object of any such triple.","title":"Properties with inferences"},{"location":"developers/rdf/#rdfsdomain","text":"P rdfs:domain D . means that property P has domain D . From this we can infer that the subject of that triple is a member of the class D . rdfs:domain can be used to specify with which class the defined property can be used with. It is possible to specify multiple rdfs:domain properties when defining a property. We pick just two classes from our example - Ceramics and BlackFigured - which show a subclass relation: myonto:BlackFigured rdfs:subClassOf myonto:Ceramics . We now have a property called incised whose domain is BlackFigured . myonto:incised rdfs:domain myonto:BlackFigured . This means that all my objects with incised decoration belong to the class BlackFigured .","title":"rdfs:domain"},{"location":"developers/rdf/#rdfsrange","text":"P rdfs:range R . means that the property P has range R . From this we can infer that the object (the value of P ) of that triple is a member of class R . If the predicate of a triple has more than one rdfs:range property, the resources denoted by the objects of triples are instances of all the classes stated by the rdfs:range properties. If we want to specify that queens who gave birth to a son could theoretically become queen mothers, we could do that with the following combination of rdfs:domain and rdfs:range : myonto:hasSon rdfs:domain myonto:Queen . myonto:hasSon rdfs:range myonto:QueenMother . It is important to know that if P is used in an inconsistent way with this declaration, RDFS does not signal an error, but rather infers the necessary type information to bring P into accordance with its domain and range declarations! In RDFS, there is no notion of an incorrect or inconsistent inference, i.e. it will never proclaim an input as invalid but simply infer appropriate type information. Domains and ranges are not used to validate information, but to determine new information based on old information. In practice, there are often better and more appropriate options to use instead of rdfs:domain and rdfs:range alone.","title":"rdfs:range"},{"location":"developers/rdf/#properties-without-inferences","text":"RDFS provides some properties from which no inferences can be drawn, i.e. no inference semantics is defined for them. They are useful and important for documentation purposes. These are rdfs:label , rdfs:comment , rdfs:seeAlso and rdfs:isDefinedBy . Resources on the Semantic Web are specified by IRIs/URIs which are not meaningful to people. Thus, RDFS provides the property rdfs:label whose intended use is to provide a human-readable version for any resource's name. Multilingual labels are possible if the language tagging facility of RDF literals is used. myonto:BlackFigured rdfs:label \"black-figured vessels\"@en, \"schwarzfigurige Gef\u00e4sse\"@de . Frequently it is useful to add comments about a model, i.e. to document it properly. In RDFS, rdfs:comment is an instance of rdf:Property that can be used to provide a human-readable description of a resource. Multilingual documentation is possible if the language tagging facility of RDF literals is used. To make a comment a triple using the property rdfs:comment as a predicate has to be asserted. myonto:BlackFigured rdfs:comment \"The class BlackFigured contains ceramic vessels where the decoration is painted with black paint.\" . In the case where a resource is an URL, supplementary information about this resource may be useful. This additional information is often included in documents. rdfs:seeAlso provides a way to specify the web location of such supplementary information. The web location has to be given in the form of an IRI/URI! The precise behaviour of a processor is not specified, but most tools that encounter rdfs:seeAlso link them to those links in a browser or application interface. In our example we could link findspots of archaeological objects to a web resource with geodata, e.g. GeoNames, in the following way: myonto:latitude rdfs:seeAlso geonames:lat . rdfs:isDefinedby provides a link to the primary resource of information about a resource. Thus, the definitional description of a resource can be found, e.g. rdfs:isDefinedBy is defined in RDF to be a rdfs:subPropertyOf of rdfs:seeAlso .","title":"Properties without inferences"},{"location":"developers/rdf/#combinations-and-patterns","text":"","title":"Combinations and patterns"},{"location":"developers/rdf/#intersection","text":"RDFS inference rules are few and rather simple. More specific patterns can be obtained by combining basic RDFS features. One such case is set intersection. If we intend to draw the inference that if a resource x is an instance of class C , then it should also be an instance of classes A and B , expressing the formal relationship C \u2286 A \u2229 B . Such an inference can be obtained by making C a subclass of A and B : :C rdfs:subClassOf :A . :C rdfs:subClassOf :B . Due to the inference rule defined for rdfs:subClassOf we can infer from the triple x rdf:type :C . the desired triples x rdf:type :A . x rdf:type :B . Thus, from a membership in C membership in A and B can be inferred. But from membership in A and B membership in C cannot be inferred! Inferences can only be drawn in one direction. In an analogous way to the treatment of classes, set intersection can be defined for properties using the construct rdfs:subPropertyOf .","title":"Intersection"},{"location":"developers/rdf/#union","text":"The union of two sets ( A \u222a B \u2286 C ) can be obtained by making C a superclass of A and B . :A rdfs:subClassOf :C . :B rdfs:subClassOf :C . Then, for any instance x that is either a member of class A or of B it will be inferred that it is also a member of class C . In an analogous way to the treatment of classes, set union can be defined for properties using rdfs:subPropertyOf .","title":"Union"},{"location":"developers/rdf/#collections","text":"A collection is represented as a list of items. rdf:List is an instance of rdfs:Class that can be used to build descriptions of lists and other list-like structures.","title":"Collections"},{"location":"developers/rdf/#summary","text":"The following Figure 4 illustrates the concepts of resource, class, and sub-class based on our example project. Figure 5 shows the same in a more general way: resources are denoted by a large black dot and arrows are drawn from a resource to the class it defines. A sub-class is shown by a rectangle (the sub-class) completely enclosed by another (the super-class), i.e. class ConstraintProperty is a subclass of class Property. The notion rdf:type specifies that something is a member of a group, i.e. an instance of a class. By using rdfs:Class instead of rdf:type a description of the meaning of a membership in a group is gained. Meaning is expressed through the mechanisms of inference in RDFS that can be drawn when a resource is used in a certain way. The following Figure 6 expresses the same information about the class hierarchy, but does so using a graphic representation of the RDF data model. If a class is a subset of another, there is an arc labelled \"s\" from the node representing the first class to the node representing the second one (\"s\" stands for rdfs:subClassOf ). If a resource was an instance of a class, then there is an arc labelled \"t\" from the resource to the node representing the class (\"t\" stands for rdf:type ). Not all arcs are drawn, e.g. rdfs:ConstraintProperty is a subclass of rdfs:Resource because it is a subclass of rdf:Property which is a subclass of rdfs:Resource . Examples: - The class rdfs:Literal is an instance of rdfs:Class and an instance of rdfs:Resource . - The class rdf:Property is the class of RDF properties and an instance of rdfs:Class .","title":"Summary"},{"location":"developers/rdf/#web-ontology-language-owl","text":"OWL is intended to be used when information contained in documents needs to be processed by applications, it explicitly represents the meaning of terms in vocabularies and the relationship between those terms. The representation of terms and their interrelationships are called an ontology . A concrete syntax is needed in order to store ontologies and to exchange them among tools and applications. The primary exchange syntax for OWL is the XML syntax for RDF (RDF/XML), but other syntaxes such as e.g. Turtle are also frequently used. The data described by an OWL ontology is interpreted as a set of \"individuals\" and a set of \"property assertions\" which relate these individuals to each other. An ontology consists of a set of axioms which place constraints on sets of individuals called \"classes\" and the types of relationships permitted between them. OWL ontologies can import other ontologies, adding information from the imported ontology to the current ontology. The main building blocks of the OWL language are an RDF graph and at least one concrete syntax - there may be more than one - that can be used to serialize and exchange ontologies. OWL has been designed to meet the needs for a Web Ontology Language. It is part of the W3C recommendations related to the Semantic Web: - XML provides a surface syntax for structured documents, but imposes no semantic constraints. - XML Schema is a language for restricting the structure of XML documents and extends XML with datatypes. - RDF is a datamodel for objects and relations between them. Furthermore, it provides a simple semantics for this datamodel and these datamodels can be represented in an XML syntax. - RDF Schema is a vocabulary for describing properties and classes of RDF resources, with a semantics for generalization-hierarchies of such properties and classes. - OWL then adds more vocabulary to RDF for describing properties and classes: e.g. relations between classes, cardinality, equality, characteristics of properties and enumerated classes. The following introduction to OWL draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 153\u2013305 which we warmly recommend for reading. Further information can be found in the Recommendations of the OWL 2 Web Ontology Language Document Overview (Second Edition) and the Wikipedia entry of OWL .","title":"Web Ontology Language (OWL)"},{"location":"developers/rdf/#owlclass","text":"In OWL, a Class defines a group of individuals that belong together because they share some properties. An owl:Class differs from an rdfs:Class - an owl:Class is a special case of an rdfs:Class . Classes can be organised in a hierarchy using rdfs:subClassOf . Thus, owl:Class is defined as a subclass of rdfs:Class : owl:Class rdfs:subClassOf rdfs:Class . This means that every member of an owl:Class is also a member of rdfs:Class . There is a built-in most general class named owl:Thing which is the class of all individuals. It is a superclass of all OWL classes. There is also a built-in class named owl:Nothing which is the class that has no instances. It is a subclass of all OWL classes.","title":"owl:Class"},{"location":"developers/rdf/#owlinverseof","text":"Extra language features that are not directly provided by OWL, but that one may desire, such as e.g. superClassOf , are often supported by OWL as a combination of other features. The construct owl:inverseOf inverses a property, i.e. the direction of the property is reversed. This property can be used to define e.g. the superClassOf of a resource by combining it with rdfs:subClassOf in the following way: myonto:superClassOf owl:inverseOf rdfs:subClassOf .","title":"owl:inverseOf"},{"location":"developers/rdf/#owlsymmetricproperty","text":"For a symmetric property holds that if a pair (x,y) is an instance of the property P, then also the pair (y,x) is an instance of this property P. Such a property is provided by owl:SymmetricProperty and expressed in OWL as a Class. An example for such a property is to be married - if Agamemnon is married to Klytaimnestra, Klytaimnestra is also married to Agamemnon. Thus we can define a property married in our ontology with the following triples: myonto:married rdf:type owl:SymmetricProperty . Agamemnon myonto:married Klytaimnestra . Be aware - to make sure that owl:inverseOf works in both directions, one has to assert that owl:inverseOf rdf:type owl:SymmetricProperty .","title":"owl:SymmetricProperty"},{"location":"developers/rdf/#owltransitiveproperty","text":"Another important property is transitivity. Transitivity is a relation between three elements such that if it holds between the first and second and it also holds between the second and third, it must necessarily hold between the first and the third. In OWL, transitivity is provided by the construct owl:TransitiveProperty which is a class of properties. To model the property isLocatedIn in our ontology as a member of the transitive class we can state myonto:isLocatedIn rdf:type owl:TransitiveProperty . Together with the triples Rome myonto:isLocatedIn Italy . Italy myonto:isLocatedIn Europe . we can infer that Rome is located in Europe.","title":"owl:TransitiveProperty"},{"location":"developers/rdf/#owlequivalentclass","text":"A frequent situation is that if information about the same entity from different sources is merged then the two providers of this information will not have used the same URI/IRI for refering to the same entity. When combining these data it may be useful to state that two URIs/IRIs actually refer to the same entity. When two classes are known to always have the same members, they are said to be equivalent . Such a situation can be expressed with one simple statement using owl:equivalentClass : owl:equivalentClass rdf:type owl:SymmetricProperty . myonto:GreekGods owl:equivalentClass otheronto:Deities . The second triple expresses that the class GreekGods in our ontology is equivalent to the class Deities in some other ontology we refer to. Note that when two classes are equivalent, it only means that they have the same members. But other properties of these classes aren't shared!","title":"owl:equivalentClass"},{"location":"developers/rdf/#owlequivalentproperty","text":"If one intends to state that two properties are equivalent, owl:equivalentProperty can be used: myonto:isInvisible owl:equivalentClass otheronto:notSeen . This statement expresses that the property which is called isInvisible in our ontology, is named notSeen in some other ontology.","title":"owl:equivalentProperty"},{"location":"developers/rdf/#owlsameas","text":"If it turns out that two individuals are actually one and the same, owl:sameAs can be used to state this fact: myonto:Puteoli owl:sameAs otheronto:Puzzeoli . This statement expresses that the site which is called Puteoli in our ontology, is the same as a site named Puzzeoli in some other ontology.","title":"owl:sameAs"},{"location":"developers/rdf/#owlfunctionalproperty","text":"A functional property owl:FunctionalProperty is a property which can only have one single value. An everyday example for such a property is e.g. hasBirthplace since each person has only one birth place. Functional properties can be useful to infer sameness, e.g. if names with foreign characters are transliterated differently in two sources - a Greek \"B\" may be transliterated either as \"B\" or as \"V\", we can state: myonto:GreekB owl:FunctionalProperty otheronto:GreekV .","title":"owl:FunctionalProperty"},{"location":"developers/rdf/#owlinversefunctionalproperty","text":"However, it is more common to use the related notion of owl:InverseFunctionalProperty . One can think of this construct to be the inverse of owl:FunctionalProperty as its name suggests. Especially identifying numbers are inverse functional properties. myonto:hasInventoryNumber rdf:type owl:InverseFunctionalProperty . myonto:ID3 myonto:hasInventoryNumber \"24.97.11\" . otheronto:ID2435 myonto:hasInventoryNumber \"24.97.11\" . From the above example follows that ID 3 in my data set is the same object as ID 2435 in another data set. It is sometimes useful for a single property to be an owl:FunctionalProperty and an owl:InverseFunctionalProperty . This means that it is a one-to-one property: for each individual there is exactly one value for the property and the other way round. This feature is intended in the case of unique identifiers as in the following example: myonto:hasID rdfs:domain myonto:Monument . myonto:hasID rdfs:range xsd:Integer . myonto:hasID rfd:type owl:FunctionalProperty . myonto:hasID rfd:type owl:InverseFunctionalProperty . This means that each member of class Monument possesses a unique identifier that is an integer number. Any two monuments that share an ID must be the same (due to inverse functionality) and in addition, each monument can have at most one ID (due to functionality).","title":"owl:InverseFunctionalProperty"},{"location":"developers/rdf/#owlobjectproperty-and-owldatatypeproperty","text":"The constructs owl:sameAs , owl:FunctionalProperty and owl:InverseFunctionalProperty especially help to describe how information from multiple sources can be merged. OWL can also provide useful information for editing tools if a value of some property may be either a link to another object or a widget for a particular data type. For this purpose OWL distinguishes between owl:DatatypeProperty and owl:ObjectProperty . owl:DatatypeProperty can have a data value as object, owl:ObjectProperty can have a resource as object. myonto:inSameMuseum rdf:type owl:ObjectProperty. myonto:shipVoyage rdf:type owl:DatatypeProperty. The first example may be used to express that one archaeological object is kept in the same museum as another archaeological object while the second example may select those individuals who participated in a ship voyage such as e.g. the Argonauts.","title":"owl:ObjectProperty and owl:DatatypeProperty"},{"location":"developers/rdf/#restrictions","text":"The construct owl:Restriction allows to describe individuals of classes in terms of existing properties and classes that have already been modeled. The class of all things in OWL called owl:Thing is unrestricted. A restriction provides some description that limits the kinds of things that can be said about a member of the class. A restriction class in OWL is defined by the keyword owl:onProperty . A description of how the new class is constrained can be provided e.g. by owl:allValuesFrom , owl:someValuesFrom and owl:hasValue . The membership in a restriction class must satisfy the specified conditions as well as the owl:onProperty specification.","title":"Restrictions"},{"location":"developers/rdf/#property-constraints","text":"owl:someValuesFrom selects all individuals from a class for which at least one value of the property P comes from class C . In our example we can formulate such a restriction as: [a owl:Restriction; owl:onProperty myonto:isLocatedIn; owl:someValuesFrom myonto:Museum] All archaeological objects kept in a museum today thus have been defined as all archaeological objects for which at least one value of the property isLocatedIn comes from the class Museum . The [ ] notation refers to a blank node which is described by the properties listed here. This restriction class has no specific name associated with it - it is defined by the properties of the restriction and is hence called an unnamed class . owl:allValuesFrom selects all individuals from a class for which all values of the property P come from class C . In our example we can formulate such a restriction as: [a owl:Restriction; owl:onProperty myonto:hasProvenience; owl:allValuesFrom myonto:Findspot] This restriction selects all our archaeological objects for which the findspot is known. A noteworthy difference between owl:someValuesFrom and owl:allValuesFrom is that the former implies that there must be such a member, while the latter technically means if there are any members, then they all must have this property which doesn't imply that there are any members. owl:hasValue is used to produce a restriction of the form \"all individuals that have the value A for the property P \". We can formulate such a restriction as: [ a owl:Restriction ; owl:onProperty myonto:P ; owl:hasValue myonto:A ] . Let's assume we defined a property myonto:hasImage which helps to select archaeological objects for which we possess images. We can now state a restriction for those with high resolution images: myonto:HighResolutionObject owl:equivalentClass [ a owl:Restriction ; owl:onProperty myonto:hasImage; owl:hasValue myonto:hasHighresImage ] . That we have such a high resolution image of a certain object we can formulate with the following triple: myonto:ID3 myonto:hasImage myonto:hasHighresImage . Then it is possible to deduce myonto:ID3 a myonto:HighResolutionObject . owl:hasValue is just a special case of the owl:someValuesFrom restriction. Nevertheless, it is very useful because it effectively turns specific instance descriptions into class descriptions. OWL provides a facility for defining new classes as unions ( owl:unionOf ) and intersections ( owl:intersectionOf ) of previously defined classes. The union of two or more classes includes the members of all those classes while the intersection includes only those that belong to every one of the classes. OWL allows to enumerate the members of a class using the construct owl:oneOf . If I have a class myonto:ObjectsSomeSmallMuseum with the members \"vase1\", \"vase2\" and \"relief1\", then: myonto:ObjectsSomeSmallMuseum rdf:type owl:Class; owl:oneOf (myonto:vase1 myonto:vase2 myonto:relief1). My class myonto:ObjectsSomeSmallMuseum is related via the property owl:oneOf to a list of the members of the class. However, owl:oneOf should be used only in situations in which the definition of the class is not likely to change at all or at least not frequently. One such case would e.g. be the number of planets in the solar system. In contrast, the above example may be appropriate for our own immediate needs, but not for a more general approach: although we include only three objects of this small museum in our data, the museum itself for sure owns many more. Sometimes it may be useful to state that one thing is different from another thing. OWL provides owl:differentFrom for this. An example is the following: myonto:Zenon owl:differentFrom otheronto:Zenon. Two different ancient Greek philosophers with the name Zenon are known. The above triple states that the Zenon in our ontology (e.g. Zenon of Elea) is not the same Zenon as in another ontology (e.g. Zenon of Kition).","title":"Property constraints"},{"location":"developers/rdf/#cardinalities","text":"OWL also includes restrictions that refer to cardinalities , i.e. the number of values for a specific property. Cardinality restrictions can be used to define sets of particular interest. Cardinality refers to the number of distinct values a property has. The fact that we only know about two works attributed to Homer - the Iliad and the Odyssey - we may state by using owl:cardinality : [a owl:Restriction; owl:onProperty myonto:HomerWorks; owl:cardinality 2] Cardinality restrictions can also be used to specify upper and lower boundaries, the respective constructs are named owl:maxCardinality and owl:minCardinality . The restriction to cardinalities of 0 and 1 have special modeling utility: minCardinality 0 indicates a set of individuals for which some value for a specified property is optional minCardinality 1 indicates a set of individuals for which some value for a specified property is required maxCardinality 0 specifies that no value for the specified property is allowed maxCardinality 1 specifies that a value is unique (but need not exist)","title":"Cardinalities"},{"location":"developers/rdf/#reasoning-with-individuals-and-classes","text":"From an RDF perspective inferences about individuals and inferences about classes are very similar: in both cases new triples are added to the model based on the asserted triples. However, from a modeling perspective, these two kinds of reasoning are very different. The former draws specific conclusions about individuals while the latter draws general conclusions about classes of individuals. In the case of reasoning about individuals the information specified in one source is transformed according to a model for use in another context with the help of constructs such as rdfs:subClassOf , rdfs:subPropertyOf and various owl:Restriction . Class reasoning determines how data are related in general with constructs such as rdfs:subClassOf , rdfs:subPropertyOf , rdfs:domain or rdfs:range . Once these more general relationships have been inferred, the processing of the data can be done much easier.","title":"Reasoning with individuals and classes"},{"location":"developers/rdf/#composing-files","text":"OWL provides a built-in class owl:Ontology . The URI/IRI of an ontology usually corresponds to the URL of the file on the Web where the ontology is stored. The corresponding URI/IRI can be eclosed in angle brackets as follows: <http://www.knora.org/ontology/knora-base> rdf:type owl:Ontology. This can be useful when modularity of semantic models is specified. The most frequent way to specify modularity is with the property owl:imports . This property connects two instances of the class owl:Ontology .","title":"Composing files"},{"location":"developers/rdf/#summary-of-constructs","text":"rdfs:subClassOf - the members of a subclass are also a member of a superclass rdfs:subPropertyOf - relations described by a subproperty also hold for the superproperty rdfs:domain - the subject of a triple is classified into the domain of the predicate rdfs:range - the object of a triple is classified into the range of the predicate rdfs:label - human-readable name of a resource, no semantics inferable rdfs:comment - human-readable information of the model, no semantics inferable owl:equivalentClass - the members of each class are also members of the other class owl:equivalentProperty - relations that hold for each property also hold for the other property owl:sameAs - all statements about one instance hold for the other instance owl:inverseOf - exchanges subject and object owl:TransitiveProperty - the chains of a relationship collapse into a single relationship owl:SymmetricProperty - the property is its own inverse owl:FunctionalProperty - only one value as object allowed owl:InverseFunctionalProperty - only one value as subject allowed owl:ObjectProperty - the property can have a resource as object owl:DatatypeProperty - the property can have a data value as object owl:Restriction - a building block in OWL that describes classes by restricting the values that are allowed for certain properties owl:hasValue - a type of restriction that refers to a single value for a property owl:someValuesFrom - a type of restriction that refers to a set from which some value for a property must come owl:allValuesFrom - a type of restriction that refers to a set from which all values for a property must come owl:onProperty - a link from a restriction to the property it restricts. owl:unionOf - unites classes and creates a new class owl:intersectionOf - determines the intersection of classes and creates a new class owl:complementOf - determines the compliment of a class and creates a new class owl:oneOf - specifies that a class consists just of the listed members owl:differentFrom - specifies that one individual is not identical to another one owl:disjointWith - specifies that two classes cannot share a member owl:cardinality - specifies information about the number of distict values for some property owl:minCardinality - specifies information about the minimum number of distinct values for a property owl:maxCardinality - specifies information about the maximum number of distinct values for a property owl:imports - allows one ontology to refer explicitly to another ontology.","title":"Summary of constructs"},{"location":"developers/dsp/contribution/","text":"How to contribute to the development of the DSP The DSP software is developed under git version control using GitHub . It includes the following main repositories: In all these repositories, we follow the GitHub flow recommondations: Create a branch from main . Add commits . Open a pull request . Discuss and review your code . Merge into main branch. Create Branch Guidelines You will work on an own branch to resolve one issue or user story defined on Youtrack . Each of those issues has a DEV-number which has to be used in the branch name: wip/<DEV-nr>-<subject> The prefix wip stands for \"work in progress\" followed by a \"/\" (slash). The second part starts with the DEV-number followed by a short subject which contains succinct description of the issue/user story. DEV-number and subject have to be written in kebab-case with \"-\" (hyphens). Git Commit Guidelines We follow strict rules how a commit message has to look like. This leads to more readable messages that are easy to follow when looking through the project history and release notes. Since release notes are automatically generated from commits, it is important to follow the Conventional Commit messages . Commit Message Format <type>(<scope>): <subject> Type Must be one of the following: fix : represents bug fixes, and correlates to a SemVer patch . refactor : represents production code refactoring, and correlates to a patch . feat : represents a new feature, and correlates to a SemVer minor . feat! , fix! , refactor! , etc.: represents a breaking change (indicated by the ! ) and will result in a SemVer major .\\ \u26a0 It is important that the exclamation mark is placed before the colon. For example feat!: <subject> or feat(api-v2)!: <subject> docs : documentation changes (no production code change). chore : maintenance tasks (no production code change). style : styles update (no production code change). test : all about tests: adding, refactoring tests (no production code change). The first four items on this list are taken into account for the release notes and have an effect on the version number. Scope (optional) The scope could be anything specifying place of the commit change. Subject The subject contains succinct description of the change: use the imperative, present tense: \"change\" not \"changed\" nor \"changes\" don't capitalize first letter no dot (.) at the end Pull Request Guidelines Set title and add description A pull request usually resolves one issue or user story defined on Youtrack . Since we started to use the release-please-action it's very important to set the PR title in the correct way, especially because all commits added within the pull request are squashed. Otherwise PR's with bad titles won't be added to the automatically generated CHANGELOG and release notes. Thus PR title has to follow the commit message convention mentioned above , with small modifications. PR Title Format <type>(<scope>): <subject> (<DEV-no.>) It's crucial to start the PR title with the <type> ( allowed types ), followed by optional <scope> (in brackets and without space between type and scope). <subject> should be YouTrack task title or its short version. At the end of the PR title add inside the brackets <DEV-no.> , which represents the number of the task(s) related to the PR. Here is an example: docs(contribution): example pull request title (DEV-001) The PR description should contains important informations for its reviewers. Don't copy/paste YouTrack task description here. Instead of that start the description by adding the following: Resolves <DEV-no.> Github's Autolink Setting will automatically generate a link to Youtrack's issue. Add a label (optional) This step is optional, since it has no impact on the release process anymore. However adding at least one of the corresponding label to your PR will help quickly realize its purpose: breaking : breaking changes. enhancement : new feature. bug : a bug fix. styling update style (no production code change). documentation : changes to the documentation. testing : all about tests: adding, refactoring tests (no production code change). refactor : refactoring production code. chore : maintenance tasks (no production code change). dependencies : update a dependency package version. Make a draft Please convert the pull request to draft as long it isn't ready for reviewing. As soon as the PR is ready for review , click on the corresponding button \"Ready for review\". Branch protection rules The main branch of each repo (it's usually the main branch) is protected by the following rules: Require pull request reviews before merging At least from one reviewer Require status checks to pass before merging Require branches to be up-to-date before merging Status checks e.g. tests defined in each repository's CI When the PR is merged, the branch will be deleted automatically. Code Review Guidelines Rewievers should pay attention to proper PR title setting . General GitHub actions workflows (CI) We use GitHub actions to automate some processes. Run tests With each push to GitHub, the tests of the repository are executed. Successfull tests are needed to merge code into repository's main branch (s. Branch protection rules ). Prepare release We use release-please-action to prepare the next release. This action script automates the CHANGELOG generation, the creation of GitHub releases, and version bumps. In doing so, it creates a release PR which updates itself with each push into main branch following the commit messages. It's important to use the defined rules from above in all commits and in PR titles . Create release When we are ready to tag a release, simply merge the release PR. This will create a release on Github, builds the npm package or the docker image and publishes on the corresponding platform.","title":"Contribution"},{"location":"developers/dsp/contribution/#how-to-contribute-to-the-development-of-the-dsp","text":"The DSP software is developed under git version control using GitHub . It includes the following main repositories: In all these repositories, we follow the GitHub flow recommondations: Create a branch from main . Add commits . Open a pull request . Discuss and review your code . Merge into main branch.","title":"How to contribute to the development of the DSP"},{"location":"developers/dsp/contribution/#create-branch-guidelines","text":"You will work on an own branch to resolve one issue or user story defined on Youtrack . Each of those issues has a DEV-number which has to be used in the branch name: wip/<DEV-nr>-<subject> The prefix wip stands for \"work in progress\" followed by a \"/\" (slash). The second part starts with the DEV-number followed by a short subject which contains succinct description of the issue/user story. DEV-number and subject have to be written in kebab-case with \"-\" (hyphens).","title":"Create Branch Guidelines"},{"location":"developers/dsp/contribution/#git-commit-guidelines","text":"We follow strict rules how a commit message has to look like. This leads to more readable messages that are easy to follow when looking through the project history and release notes. Since release notes are automatically generated from commits, it is important to follow the Conventional Commit messages .","title":"Git Commit Guidelines"},{"location":"developers/dsp/contribution/#commit-message-format","text":"<type>(<scope>): <subject>","title":"Commit Message Format"},{"location":"developers/dsp/contribution/#type","text":"Must be one of the following: fix : represents bug fixes, and correlates to a SemVer patch . refactor : represents production code refactoring, and correlates to a patch . feat : represents a new feature, and correlates to a SemVer minor . feat! , fix! , refactor! , etc.: represents a breaking change (indicated by the ! ) and will result in a SemVer major .\\ \u26a0 It is important that the exclamation mark is placed before the colon. For example feat!: <subject> or feat(api-v2)!: <subject> docs : documentation changes (no production code change). chore : maintenance tasks (no production code change). style : styles update (no production code change). test : all about tests: adding, refactoring tests (no production code change). The first four items on this list are taken into account for the release notes and have an effect on the version number.","title":"Type"},{"location":"developers/dsp/contribution/#scope-optional","text":"The scope could be anything specifying place of the commit change.","title":"Scope (optional)"},{"location":"developers/dsp/contribution/#subject","text":"The subject contains succinct description of the change: use the imperative, present tense: \"change\" not \"changed\" nor \"changes\" don't capitalize first letter no dot (.) at the end","title":"Subject"},{"location":"developers/dsp/contribution/#pull-request-guidelines","text":"","title":"Pull Request Guidelines"},{"location":"developers/dsp/contribution/#set-title-and-add-description","text":"A pull request usually resolves one issue or user story defined on Youtrack . Since we started to use the release-please-action it's very important to set the PR title in the correct way, especially because all commits added within the pull request are squashed. Otherwise PR's with bad titles won't be added to the automatically generated CHANGELOG and release notes. Thus PR title has to follow the commit message convention mentioned above , with small modifications.","title":"Set title and add description"},{"location":"developers/dsp/contribution/#pr-title-format","text":"<type>(<scope>): <subject> (<DEV-no.>) It's crucial to start the PR title with the <type> ( allowed types ), followed by optional <scope> (in brackets and without space between type and scope). <subject> should be YouTrack task title or its short version. At the end of the PR title add inside the brackets <DEV-no.> , which represents the number of the task(s) related to the PR. Here is an example: docs(contribution): example pull request title (DEV-001) The PR description should contains important informations for its reviewers. Don't copy/paste YouTrack task description here. Instead of that start the description by adding the following: Resolves <DEV-no.> Github's Autolink Setting will automatically generate a link to Youtrack's issue.","title":"PR Title Format"},{"location":"developers/dsp/contribution/#add-a-label-optional","text":"This step is optional, since it has no impact on the release process anymore. However adding at least one of the corresponding label to your PR will help quickly realize its purpose: breaking : breaking changes. enhancement : new feature. bug : a bug fix. styling update style (no production code change). documentation : changes to the documentation. testing : all about tests: adding, refactoring tests (no production code change). refactor : refactoring production code. chore : maintenance tasks (no production code change). dependencies : update a dependency package version.","title":"Add a label (optional)"},{"location":"developers/dsp/contribution/#make-a-draft","text":"Please convert the pull request to draft as long it isn't ready for reviewing. As soon as the PR is ready for review , click on the corresponding button \"Ready for review\".","title":"Make a draft"},{"location":"developers/dsp/contribution/#branch-protection-rules","text":"The main branch of each repo (it's usually the main branch) is protected by the following rules: Require pull request reviews before merging At least from one reviewer Require status checks to pass before merging Require branches to be up-to-date before merging Status checks e.g. tests defined in each repository's CI When the PR is merged, the branch will be deleted automatically.","title":"Branch protection rules"},{"location":"developers/dsp/contribution/#code-review-guidelines","text":"Rewievers should pay attention to proper PR title setting .","title":"Code Review Guidelines"},{"location":"developers/dsp/contribution/#general-github-actions-workflows-ci","text":"We use GitHub actions to automate some processes.","title":"General GitHub actions workflows (CI)"},{"location":"developers/dsp/contribution/#run-tests","text":"With each push to GitHub, the tests of the repository are executed. Successfull tests are needed to merge code into repository's main branch (s. Branch protection rules ).","title":"Run tests"},{"location":"developers/dsp/contribution/#prepare-release","text":"We use release-please-action to prepare the next release. This action script automates the CHANGELOG generation, the creation of GitHub releases, and version bumps. In doing so, it creates a release PR which updates itself with each push into main branch following the commit messages. It's important to use the defined rules from above in all commits and in PR titles .","title":"Prepare release"},{"location":"developers/dsp/contribution/#create-release","text":"When we are ready to tag a release, simply merge the release PR. This will create a release on Github, builds the npm package or the docker image and publishes on the corresponding platform.","title":"Create release"},{"location":"developers/libraries/","text":"Libraries DSP-JS DSP-JS is a library to facilitate the communication with DSP-API in web clients developed with TypeScript/JavaScript. It depends on RxJS and is web framework agnostic (it can be used with Angular, React, Vue.js etc.). \u2192 Go to the DSP-JS documentation","title":"Libraries"},{"location":"developers/libraries/#libraries","text":"","title":"Libraries"},{"location":"developers/libraries/#dsp-js","text":"DSP-JS is a library to facilitate the communication with DSP-API in web clients developed with TypeScript/JavaScript. It depends on RxJS and is web framework agnostic (it can be used with Angular, React, Vue.js etc.). \u2192 Go to the DSP-JS documentation","title":"DSP-JS"},{"location":"developers/sipi/","text":"SIPI basics The media server SIPI The S imple I mage P resentation I nterface (Sipi) takes care of storing, converting and serving image, audio and video files as well as other documents such as pdf files. It is designed to be used by all institutions that need to preserve high-quality images and to make them available online. SIPI implements the I nternational I mage I nteroperability F ramework ( IIIF ), which aims at supporting interoperability between different image repositories. SIPI efficiently converts lossless between image formats while preserving the metadata contained in the image files. If images are stored in JPEG 2000 format, SIPI can convert them on the fly to formats that are commonly used on the Internet. SIPI is written in C++ and runs on Linux and Mac OS X. It offers a flexible framework for specifying authentication and authorization logic which is obtained by scripts written in the scripting language Lua . SIPI supports restricted access to images, either by reducing the image dimensions or by adding watermarks to the images. Interaction of DSP-API and SIPI If a file is requested from SIPI by e.g. an image link served by DSP-API, a preflight function is called. This function needs three parameters: a prefix, the identifier (the name of the requested file) and a cookie. All file links created by DSP-API use the project number as prefix. An example link from our incunabula project may look as follows: 0.0.0.0:1024/0803/incunabula_0000003328.jp2/full/2613,3505/0/default.jpg . Based on the provided information, SIPI asks DSP-API about the permissions on the file in question of the current user. Therefore, the cookie is needed: it contains the current user's DSP-API session ID. Hence, DSP-API can match SIPI's request with a given user profile and tell SIPI the permissions this user has on the requested file. If the user has sufficient permissions, the file is served in full quality. If the user has only preview rights, SIPI serves a reduced quality of the file or integrates a watermark. If the user has no permissions, SIPI refuses to serve the file. However, all of this behaviour is defined in the preflight function in SIPI and not controlled by DSP-API. DSP-API only provides the permission code. Thus, DSP-API and SIPI stick to a clear division of responsibility regarding files: DSP-API knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from SIPI, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by SIPI. When a user creates a resource with a digital representation attached to it in DSP-API either via the G raphical U ser I nterface (GUI) or directly via the A pplication P rogramming I nterface (API), the file is directly sent to SIPI to calculate a thumbnail hosted by SIPI which then gets displayed to the user in the browser. SIPI copies the original file into a temporary directory and keeps it there for later processing in another request. In its answer in JSON format, SIPI returns the path to the thumbnail, the name of the temporarily stored original file managed by SIPI, the mime type of the original file and the original name of the file submitted by the client. At the moment when the user wants to attach the file to a resource, the request is sent to DSP-API's API providing all the required parameters to create the resource along with additional information about the file to be attached. The file itself is not submitted to the DSP-API's API, but its filename returned by SIPI.","title":"Sipi"},{"location":"developers/sipi/#sipi-basics","text":"","title":"SIPI basics"},{"location":"developers/sipi/#the-media-server-sipi","text":"The S imple I mage P resentation I nterface (Sipi) takes care of storing, converting and serving image, audio and video files as well as other documents such as pdf files. It is designed to be used by all institutions that need to preserve high-quality images and to make them available online. SIPI implements the I nternational I mage I nteroperability F ramework ( IIIF ), which aims at supporting interoperability between different image repositories. SIPI efficiently converts lossless between image formats while preserving the metadata contained in the image files. If images are stored in JPEG 2000 format, SIPI can convert them on the fly to formats that are commonly used on the Internet. SIPI is written in C++ and runs on Linux and Mac OS X. It offers a flexible framework for specifying authentication and authorization logic which is obtained by scripts written in the scripting language Lua . SIPI supports restricted access to images, either by reducing the image dimensions or by adding watermarks to the images.","title":"The media server SIPI"},{"location":"developers/sipi/#interaction-of-dsp-api-and-sipi","text":"If a file is requested from SIPI by e.g. an image link served by DSP-API, a preflight function is called. This function needs three parameters: a prefix, the identifier (the name of the requested file) and a cookie. All file links created by DSP-API use the project number as prefix. An example link from our incunabula project may look as follows: 0.0.0.0:1024/0803/incunabula_0000003328.jp2/full/2613,3505/0/default.jpg . Based on the provided information, SIPI asks DSP-API about the permissions on the file in question of the current user. Therefore, the cookie is needed: it contains the current user's DSP-API session ID. Hence, DSP-API can match SIPI's request with a given user profile and tell SIPI the permissions this user has on the requested file. If the user has sufficient permissions, the file is served in full quality. If the user has only preview rights, SIPI serves a reduced quality of the file or integrates a watermark. If the user has no permissions, SIPI refuses to serve the file. However, all of this behaviour is defined in the preflight function in SIPI and not controlled by DSP-API. DSP-API only provides the permission code. Thus, DSP-API and SIPI stick to a clear division of responsibility regarding files: DSP-API knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from SIPI, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by SIPI. When a user creates a resource with a digital representation attached to it in DSP-API either via the G raphical U ser I nterface (GUI) or directly via the A pplication P rogramming I nterface (API), the file is directly sent to SIPI to calculate a thumbnail hosted by SIPI which then gets displayed to the user in the browser. SIPI copies the original file into a temporary directory and keeps it there for later processing in another request. In its answer in JSON format, SIPI returns the path to the thumbnail, the name of the temporarily stored original file managed by SIPI, the mime type of the original file and the original name of the file submitted by the client. At the moment when the user wants to attach the file to a resource, the request is sent to DSP-API's API providing all the required parameters to create the resource along with additional information about the file to be attached. The file itself is not submitted to the DSP-API's API, but its filename returned by SIPI.","title":"Interaction of DSP-API and SIPI"}]}