{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DaSCH Service Platform Documentation Since 2017, the Data and Service Center for the Humanities (DaSCH) has been a member of the Swiss Academy of Humanities and Social Sciences. Our mission is to operate a platform for Humanities research data that ensures access to this data. In addition, the networking of data with other databases is to be promoted (linked open data), thus creating added value for research and the interested public. Services The task of the DaSCH is to promote and support the generation, use and long-term availability of research data in the Humanities in Switzerland. The focus is on making research data in the Humanities available online over the long term in the most direct and easy-to-use way possible and supporting researchers in using them for further research projects (\"re-use of research data\"). The DaSCH operates the necessary infrastructures (a so called \"keep-alive\" archive) and supports researchers in using this infrastructure. In order to reach this goal, the DaSCH offers the following services: Long term hosting of research data The infrastructure of the DaSCH is designed to host and keep accessible complex qualitative research data (e.g. any kind of databases and associated digital objects such as digital texts, images, movies, audio). The data has to be migrated to the infrastructure (both hardware and software) maintained by the DaSCH. All data will be held with a minimal redundancy of 6 identical copies at two geographically different locations in Switzerland (based on switchEngines) for an indefinite amount of time. Access to the data is provided by an API based on widely adopted standards (e.g. RESTful based on JSON-LD, IIIF, RDF, TEI/XML etc.) and through a generic web interface. In order to fulfill these requirements, DaSCH develops and maintains various software tools which are described and documented here. Documentation For researchers If you are a researcher, you're probably most interested in the usage of the generic web application. In this case please have a look at our DSP-APP documentation . For developers The documentation for developers is split into different groups depending on the software repository. Overview DSP-API is the main software framework in the back-end. DSP-APP DSP-TOOLS is a python library to enable researchers and data stewards to work with DSP-API (e.g. creating data models, uploading data, etc.). DSP Libraries SIPI For the community In case of further questions, bug reports or if you want to get in contact with us have a look at our community page .","title":"Overview"},{"location":"#dasch-service-platform-documentation","text":"Since 2017, the Data and Service Center for the Humanities (DaSCH) has been a member of the Swiss Academy of Humanities and Social Sciences. Our mission is to operate a platform for Humanities research data that ensures access to this data. In addition, the networking of data with other databases is to be promoted (linked open data), thus creating added value for research and the interested public.","title":"DaSCH Service Platform Documentation"},{"location":"#services","text":"The task of the DaSCH is to promote and support the generation, use and long-term availability of research data in the Humanities in Switzerland. The focus is on making research data in the Humanities available online over the long term in the most direct and easy-to-use way possible and supporting researchers in using them for further research projects (\"re-use of research data\"). The DaSCH operates the necessary infrastructures (a so called \"keep-alive\" archive) and supports researchers in using this infrastructure. In order to reach this goal, the DaSCH offers the following services:","title":"Services"},{"location":"#long-term-hosting-of-research-data","text":"The infrastructure of the DaSCH is designed to host and keep accessible complex qualitative research data (e.g. any kind of databases and associated digital objects such as digital texts, images, movies, audio). The data has to be migrated to the infrastructure (both hardware and software) maintained by the DaSCH. All data will be held with a minimal redundancy of 6 identical copies at two geographically different locations in Switzerland (based on switchEngines) for an indefinite amount of time. Access to the data is provided by an API based on widely adopted standards (e.g. RESTful based on JSON-LD, IIIF, RDF, TEI/XML etc.) and through a generic web interface. In order to fulfill these requirements, DaSCH develops and maintains various software tools which are described and documented here.","title":"Long term hosting of research data"},{"location":"#documentation","text":"","title":"Documentation"},{"location":"#for-researchers","text":"If you are a researcher, you're probably most interested in the usage of the generic web application. In this case please have a look at our DSP-APP documentation .","title":"For researchers"},{"location":"#for-developers","text":"The documentation for developers is split into different groups depending on the software repository. Overview DSP-API is the main software framework in the back-end. DSP-APP DSP-TOOLS is a python library to enable researchers and data stewards to work with DSP-API (e.g. creating data models, uploading data, etc.). DSP Libraries SIPI","title":"For developers"},{"location":"#for-the-community","text":"In case of further questions, bug reports or if you want to get in contact with us have a look at our community page .","title":"For the community"},{"location":"DSP-API/Readme/","text":"DSP-API Documentation This folder contains the sources to the DSP-API part of documentation published under https://docs.dasch.swiss/ and managed by DSP-DOCS repository. Build and serve the docs locally Documentation can be build by invoking the following make commands from the project root directory: make docs-install-requirements: ## install requirements make docs-build # build the documentation make docs-serve # serve it locally Prerequisites You will need Graphviz . On macOS: ```shell brew install graphviz ``` On Linux, use your distribution's package manager.","title":"DSP-API Documentation"},{"location":"DSP-API/Readme/#dsp-api-documentation","text":"This folder contains the sources to the DSP-API part of documentation published under https://docs.dasch.swiss/ and managed by DSP-DOCS repository.","title":"DSP-API Documentation"},{"location":"DSP-API/Readme/#build-and-serve-the-docs-locally","text":"Documentation can be build by invoking the following make commands from the project root directory: make docs-install-requirements: ## install requirements make docs-build # build the documentation make docs-serve # serve it locally","title":"Build and serve the docs locally"},{"location":"DSP-API/Readme/#prerequisites","text":"You will need Graphviz . On macOS: ```shell brew install graphviz ``` On Linux, use your distribution's package manager.","title":"Prerequisites"},{"location":"DSP-API/01-introduction/example-project/","text":"An Example Project This section introduces some of the basic concepts involved in creating ontologies for DSP projects, by means of a relatively simple example project. Before reading this document, it will be helpful to have some familiarity with the basic concepts explained in knora-base. DSP-API comes with two example projects, called incunabula and images-demo . Here we will consider the incunabula example, which is a reduced version of a real research project on early printed books. It is designed to store an image of each page of each book, as well as RDF data about books, pages, their contents, and relationships between them. At the moment, only the RDF data is provided in the example project, not the images. The incunabula ontology is in the file incunabula-onto.ttl , and its data is in the file incunabula-demo-data.ttl . Both these files are in a standard RDF file format called Turtle . The DSP-API distribution includes sample scripts (in the webapi/scripts directory) for importing these files directly into different triplestores. If you are starting a new project from scratch, you can adapt these scripts to import your ontology (and any existing RDF data) into your triplestore for use with DSP-API. The syntax of Turtle is fairly simple: it is basically a sequence of triples. We will consider some details of Turtle syntax as we go along. The Incunabula Ontology Here we will just focus on some of the main aspects of the ontology. An ontology file typically begins by defining prefixes for the IRIs of other ontologies that will be referred to. First there are some prefixes for ontologies that are very commonly used in RDF: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix dcterms: <http://purl.org/dc/terms/> . The rdf , rdfs , and owl ontologies contain basic properties that are used to define ontology entities. The xsd ontology contains definitions of literal data types such as string and integer . (For more information about these ontologies, see the references in knora-base.) The foaf ontology contains classes and properties for representing people. The dcterms ontology represents Dublin Core metadata. Then we define prefixes for DSP ontologies: @prefix knora-base: <http://www.knora.org/ontology/knora-base#> . @prefix salsah-gui: <http://www.knora.org/ontology/salsah-gui#> . The knora-base ontology contains DSP-API's core abstractions, and is described in knora-base. The salsah-gui ontology includes properties that DSP projects must use to enable SALSAH, DSP-API's generic virtual research environment. For convenience, we can use the empty prefix to refer to the incunabula ontology itself: @prefix : <http://www.knora.org/ontology/0803/incunabula#> . However, outside the ontology file, it would make more sense to define an incunabula prefix to refer to the incunabula ontology. Properties All the content produced by a DSP project must be stored in Knora resources (see incunabula-resource-classes ). Resources have properties that point to different parts of their contents; for example, the incunabula project contains books, which have properties like title . Every property that poitns to a DSP value must be a subproperty of knora-base:hasValue , and every property that points to another Knora resource must be a subproperty of knora-base:hasLinkTo . Here is the definition of the incunabula:title property: :title rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:hasValue, dcterms:title ; rdfs:label \"Titel\"@de , \"Titre\"@fr , \"Titolo\"@it , \"Title\"@en ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue ; salsah-gui:guiElement salsah-gui:SimpleText ; salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" . The definition of incunabula:title consists of a list of triples, all of which have :title as their subject. To avoid repeating :title for each triple, Turtle syntax allows us to use a semicolon ( ; ) to separate triples that have the same subject. Moreover, some triples also have the same predicate; a comma ( , ) is used to avoid repeating the predicate. The definition of :title says: rdf:type owl:ObjectProperty : It is an owl:ObjectProperty . There are two kinds of OWL properties: object properties and datatype properties. Object properties point to objects, which have IRIs and can have their own properties. Datatype properties point to literal values, such as strings and integers. rdfs:subPropertyOf knora-base:hasValue, dcterms:title : It is a subproperty of knora-base:hasValue and dcterms:title . Since the objects of this property will be Knora values, it must be a subproperty of knora-base:hasValue . To facilitate searches, we have also chosen to make it a subproperty of dcterms:title . In the DSP-API v2, if you do a search for resources that have a certain dcterms:title , and there is a resource with a matching incunabula:title , the search results could include that resource. rdfs:label \"Titel\"@de , etc.: It has the specified labels in various languages. These are needed, for example, by user interfaces, to prompt the user to enter a value. knora-base:subjectClassConstraint :book : The subject of the property must be an incunabula:book . knora-base:objectClassConstraint knora-base:TextValue : The object of this property must be a knora-base:TextValue (which is a subclass of knora-base:Value ). salsah-gui:guiElement salsah-gui:SimpleText : When SALSAH asks a user to enter a value for this property, it should use a simple text field. salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" : The SALSAH text field for entering a value for this property should be 80 characters wide, and should accept at most 255 characters. The incunabula ontology contains several other property definitions that are basically similar. Note that different subclasses of Value are used. For example, incunabula:pubdate , which represents the publication date of a book, points to a knora-base:DateValue . The DateValue class stores a date range, with a specified degree of precision and a preferred calendar system for display. A property can point to a Knora resource instead of to a Knora value. For example, in the incunabula ontology, there are resources representing pages and books, and each page is part of some book. This relationship is expressed using the property incunabula:partOf : :partOf rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOf ; rdfs:label \"ist ein Teil von\"@de , \"est un part de\"@fr , \"e una parte di\"@it , \"is a part of\"@en ; rdfs:comment \"\"\"Diese Property bezeichnet eine Verbindung zu einer anderen Resource, in dem ausgesagt wird, dass die vorliegende Resource ein integraler Teil der anderen Resource ist. Zum Beispiel ist eine Buchseite ein integraler Bestandteil genau eines Buches.\"\"\"@de ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint :book ; salsah-gui:guiElement salsah-gui:Searchbox . The key things to notice here are: rdfs:subPropertyOf knora-base:isPartOf : The knora-base ontology provides a generic isPartOf property to express part-whole relationships. A project may use knora-base:isPartOf directly, however creating a subproperty such as incunabula:partOf will allow to customize the property further, e.g. by giving it a more descriptive label. It is important to note that knora-base:isPartOf is a subproperty of knora-base:hasLinkTo . Any property that points to a knora-base:Resource must be a subproperty of knora-base:hasLinkTo . Such a property is called a link property . knora-base:objectClassConstraint :book : The object of this property must be a member of the class incunabula:book , which, as we will see below, is a subclass of knora-base:Resource . salsah-gui:guiElement salsah-gui:Searchbox : When SALSAH prompts a user to select the book that a page is part of, it should provide a search box enabling the user to find the desired book. Because incunabula:partOf is a link property, it must always accompanied by a link value property , which enables Knora to store metadata about each link that is created with the link property. This metadata includes the date and time when the link was created, its owner, the permissions it grants, and whether it has been deleted. Storing this metadata allows Knora to authorise users to see or modify the link, as well as to query a previous state of a repository in which a deleted link had not yet been deleted. (The ability to query previous states of a repository is planned for DSP-API version 2.) The name of a link property and its link value property must be related by the following naming convention: to determine the name of the link value property, add the word Value to the name of the link property. Hence, the incunabula ontology defines the property partOfValue : :partOfValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOfValue ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint knora-base:LinkValue . As a link value property, incunabula:partOfValue must point to a knora-base:LinkValue . The LinkValue class is an RDF reification of a triple (in this case, the triple that links a page to a book). For more details about this, see knora-base-linkvalue. Note that the property incunabula:hasAuthor points to a knora-base:TextValue , because the incunabula project represents authors simply by their names. A more complex project could represent each author as a resource, in which case incunabula:hasAuthor would need to be a subproperty of knora-base:hasLinkTo . Resource Classes The two main resource classes in the incunabula ontology are book and page . Here is incunabula:book : :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :title ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publisher ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publoc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"4\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :pubdate ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :location ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :url ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :physical_desc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"9\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :note ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :book_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"book.gif\" ; rdfs:label \"Buch\"@de , \"Livre\"@fr , \"Libro\"@it , \"Book\"@en ; rdfs:comment \"\"\"Diese Resource-Klasse beschreibt ein Buch\"\"\"@de . Like every Knora resource class, incunabula:book is a subclass of knora-base:Resource . It is also a subclass of a number of other classes of type owl:Restriction , which are defined in square brackets, using Turtle's syntax for anonymous blank nodes. Each owl:Restriction specifies a cardinality for a property that is allowed in resources of type incunabula:book . A cardinality is indeed a kind of restriction: it means that a resource of this type may have, or must have, a certain number of instances of the specified property. For example, incunabula:book has cardinalities saying that a book must have at least one title and at most one publication date. In the DSP-API version 1, the word 'occurrence' is used instead of 'cardinality'. The OWL cardinalities supported by Knora are described in OWL Cardinalities . Note that incunabula:book specifies a cardinality of owl:minCardinality 0 on the property incunabula:hasAuthor . At first glance, this might seem as if it serves no purpose, since it says that the property is optional and can have any number of instances. You may be wondering whether this cardinality could simply be omitted from the definition of incunabula:book . However, Knora requires every property of a resource to have some cardinality in the resource's class. This is because Knora uses the cardinalities to determine which properties are possible for instances of the class, and the DSP-API relies on this information. If there was no cardinality for incunabula:hasAuthor , Knora would not allow a book to have an author. Each owl:Restriction specifying a cardinality can include the predicate salsah-gui:guiOrder , which tells the SALSAH GUI the order the properties should be displayed in. Here is the definition of incunabula:page : :page rdf:type owl:Class ; rdfs:subClassOf knora-base:StillImageRepresentation , [ rdf:type owl:Restriction ; owl:onProperty :pagenum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOfValue ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOf ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :seqnum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :page_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :origname ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :transcription ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"page.gif\" ; rdfs:label \"Seite\"@de , \"Page\"@fr , \"Page\"@en ; rdfs:comment \"\"\"Eine Seite ist ein Teil eines Buchs\"\"\"@de , \"\"\"Une page est une partie d'un livre\"\"\"@fr , \"\"\"A page is a part of a book\"\"\"@en . The incunabula:page class is a subclass of knora-base:StillImageRepresentation , which is a subclass of knora-base:Representation , which is a subclass of knora-base:Resource . The class knora-base:Representation is used for resources that contain metadata about files stored by Knora. Each It has different subclasses that can hold different types of files, including still images, audio, and video files. A given Representation can store metadata about several different files, as long as they are of the same type and are semantically equivalent, e.g. are different versions of the same image with different colorspaces, so that coordinates in one file will work in the other files. In Knora, a subclass inherits the cardinalities defined in its superclasses. Let's look at the class hierarchy of incunabula:page , starting with knora-base:Representation : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can store one or more FileValues\"@en . This says that a Representation must have at least one instance of the property hasFileValue , which is defined like this: :hasFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasValue ; :subjectClassConstraint :Representation ; :objectClassConstraint :FileValue . The subject of hasFileValue must be a Representation , and its object must be a FileValue . There are different subclasses of FileValue for different kinds of files, but we'll skip the details here. This is the definition of knora-base:StillImageRepresentation : :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can contain two-dimensional still image files\"@en . It must have at least one instance of the property hasStillImageFileValue , which is defined as follows: :hasStillImageFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasFileValue ; :subjectClassConstraint :StillImageRepresentation ; :objectClassConstraint :StillImageFileValue . Because hasStillImageFileValue is a subproperty of hasFileValue , the cardinality on hasStillImageFileValue , defined in the subclass StillImageRepresentation , overrides the cardinality on hasFileValue , defined in the superclass Representation . In other words, the more general cardinality in the superclass is replaced by a more specific cardinality in the base class. Since incunabula:page is a subclass of StillImageRepresentation , it inherits the cardinality on hasStillImageFileValue . As a result, a page must have at least one image file attached to it. Here's another example of cardinality inheritance. The class knora-base:Resource has a cardinality for knora-base:seqnum . The idea is that resources of any type could be arranged in some sort of sequence. As we saw above, incunabula:page is a subclass of knora-base:Resource . But incunabula:page has its own cardinality for incunabula:seqnum , which is a subproperty of knora-base:seqnum . Once again, the subclass's cardinality on the subproperty replaces the superclass's cardinality on the superproperty: a page is allowed to have an incunabula:seqnum , but it is not allowed to have a knora-base:seqnum .","title":"An Example Project"},{"location":"DSP-API/01-introduction/example-project/#an-example-project","text":"This section introduces some of the basic concepts involved in creating ontologies for DSP projects, by means of a relatively simple example project. Before reading this document, it will be helpful to have some familiarity with the basic concepts explained in knora-base. DSP-API comes with two example projects, called incunabula and images-demo . Here we will consider the incunabula example, which is a reduced version of a real research project on early printed books. It is designed to store an image of each page of each book, as well as RDF data about books, pages, their contents, and relationships between them. At the moment, only the RDF data is provided in the example project, not the images. The incunabula ontology is in the file incunabula-onto.ttl , and its data is in the file incunabula-demo-data.ttl . Both these files are in a standard RDF file format called Turtle . The DSP-API distribution includes sample scripts (in the webapi/scripts directory) for importing these files directly into different triplestores. If you are starting a new project from scratch, you can adapt these scripts to import your ontology (and any existing RDF data) into your triplestore for use with DSP-API. The syntax of Turtle is fairly simple: it is basically a sequence of triples. We will consider some details of Turtle syntax as we go along.","title":"An Example Project"},{"location":"DSP-API/01-introduction/example-project/#the-incunabula-ontology","text":"Here we will just focus on some of the main aspects of the ontology. An ontology file typically begins by defining prefixes for the IRIs of other ontologies that will be referred to. First there are some prefixes for ontologies that are very commonly used in RDF: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix dcterms: <http://purl.org/dc/terms/> . The rdf , rdfs , and owl ontologies contain basic properties that are used to define ontology entities. The xsd ontology contains definitions of literal data types such as string and integer . (For more information about these ontologies, see the references in knora-base.) The foaf ontology contains classes and properties for representing people. The dcterms ontology represents Dublin Core metadata. Then we define prefixes for DSP ontologies: @prefix knora-base: <http://www.knora.org/ontology/knora-base#> . @prefix salsah-gui: <http://www.knora.org/ontology/salsah-gui#> . The knora-base ontology contains DSP-API's core abstractions, and is described in knora-base. The salsah-gui ontology includes properties that DSP projects must use to enable SALSAH, DSP-API's generic virtual research environment. For convenience, we can use the empty prefix to refer to the incunabula ontology itself: @prefix : <http://www.knora.org/ontology/0803/incunabula#> . However, outside the ontology file, it would make more sense to define an incunabula prefix to refer to the incunabula ontology.","title":"The Incunabula Ontology"},{"location":"DSP-API/01-introduction/example-project/#properties","text":"All the content produced by a DSP project must be stored in Knora resources (see incunabula-resource-classes ). Resources have properties that point to different parts of their contents; for example, the incunabula project contains books, which have properties like title . Every property that poitns to a DSP value must be a subproperty of knora-base:hasValue , and every property that points to another Knora resource must be a subproperty of knora-base:hasLinkTo . Here is the definition of the incunabula:title property: :title rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:hasValue, dcterms:title ; rdfs:label \"Titel\"@de , \"Titre\"@fr , \"Titolo\"@it , \"Title\"@en ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue ; salsah-gui:guiElement salsah-gui:SimpleText ; salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" . The definition of incunabula:title consists of a list of triples, all of which have :title as their subject. To avoid repeating :title for each triple, Turtle syntax allows us to use a semicolon ( ; ) to separate triples that have the same subject. Moreover, some triples also have the same predicate; a comma ( , ) is used to avoid repeating the predicate. The definition of :title says: rdf:type owl:ObjectProperty : It is an owl:ObjectProperty . There are two kinds of OWL properties: object properties and datatype properties. Object properties point to objects, which have IRIs and can have their own properties. Datatype properties point to literal values, such as strings and integers. rdfs:subPropertyOf knora-base:hasValue, dcterms:title : It is a subproperty of knora-base:hasValue and dcterms:title . Since the objects of this property will be Knora values, it must be a subproperty of knora-base:hasValue . To facilitate searches, we have also chosen to make it a subproperty of dcterms:title . In the DSP-API v2, if you do a search for resources that have a certain dcterms:title , and there is a resource with a matching incunabula:title , the search results could include that resource. rdfs:label \"Titel\"@de , etc.: It has the specified labels in various languages. These are needed, for example, by user interfaces, to prompt the user to enter a value. knora-base:subjectClassConstraint :book : The subject of the property must be an incunabula:book . knora-base:objectClassConstraint knora-base:TextValue : The object of this property must be a knora-base:TextValue (which is a subclass of knora-base:Value ). salsah-gui:guiElement salsah-gui:SimpleText : When SALSAH asks a user to enter a value for this property, it should use a simple text field. salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" : The SALSAH text field for entering a value for this property should be 80 characters wide, and should accept at most 255 characters. The incunabula ontology contains several other property definitions that are basically similar. Note that different subclasses of Value are used. For example, incunabula:pubdate , which represents the publication date of a book, points to a knora-base:DateValue . The DateValue class stores a date range, with a specified degree of precision and a preferred calendar system for display. A property can point to a Knora resource instead of to a Knora value. For example, in the incunabula ontology, there are resources representing pages and books, and each page is part of some book. This relationship is expressed using the property incunabula:partOf : :partOf rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOf ; rdfs:label \"ist ein Teil von\"@de , \"est un part de\"@fr , \"e una parte di\"@it , \"is a part of\"@en ; rdfs:comment \"\"\"Diese Property bezeichnet eine Verbindung zu einer anderen Resource, in dem ausgesagt wird, dass die vorliegende Resource ein integraler Teil der anderen Resource ist. Zum Beispiel ist eine Buchseite ein integraler Bestandteil genau eines Buches.\"\"\"@de ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint :book ; salsah-gui:guiElement salsah-gui:Searchbox . The key things to notice here are: rdfs:subPropertyOf knora-base:isPartOf : The knora-base ontology provides a generic isPartOf property to express part-whole relationships. A project may use knora-base:isPartOf directly, however creating a subproperty such as incunabula:partOf will allow to customize the property further, e.g. by giving it a more descriptive label. It is important to note that knora-base:isPartOf is a subproperty of knora-base:hasLinkTo . Any property that points to a knora-base:Resource must be a subproperty of knora-base:hasLinkTo . Such a property is called a link property . knora-base:objectClassConstraint :book : The object of this property must be a member of the class incunabula:book , which, as we will see below, is a subclass of knora-base:Resource . salsah-gui:guiElement salsah-gui:Searchbox : When SALSAH prompts a user to select the book that a page is part of, it should provide a search box enabling the user to find the desired book. Because incunabula:partOf is a link property, it must always accompanied by a link value property , which enables Knora to store metadata about each link that is created with the link property. This metadata includes the date and time when the link was created, its owner, the permissions it grants, and whether it has been deleted. Storing this metadata allows Knora to authorise users to see or modify the link, as well as to query a previous state of a repository in which a deleted link had not yet been deleted. (The ability to query previous states of a repository is planned for DSP-API version 2.) The name of a link property and its link value property must be related by the following naming convention: to determine the name of the link value property, add the word Value to the name of the link property. Hence, the incunabula ontology defines the property partOfValue : :partOfValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOfValue ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint knora-base:LinkValue . As a link value property, incunabula:partOfValue must point to a knora-base:LinkValue . The LinkValue class is an RDF reification of a triple (in this case, the triple that links a page to a book). For more details about this, see knora-base-linkvalue. Note that the property incunabula:hasAuthor points to a knora-base:TextValue , because the incunabula project represents authors simply by their names. A more complex project could represent each author as a resource, in which case incunabula:hasAuthor would need to be a subproperty of knora-base:hasLinkTo .","title":"Properties"},{"location":"DSP-API/01-introduction/example-project/#resource-classes","text":"The two main resource classes in the incunabula ontology are book and page . Here is incunabula:book : :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :title ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publisher ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publoc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"4\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :pubdate ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :location ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :url ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :physical_desc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"9\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :note ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :book_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"book.gif\" ; rdfs:label \"Buch\"@de , \"Livre\"@fr , \"Libro\"@it , \"Book\"@en ; rdfs:comment \"\"\"Diese Resource-Klasse beschreibt ein Buch\"\"\"@de . Like every Knora resource class, incunabula:book is a subclass of knora-base:Resource . It is also a subclass of a number of other classes of type owl:Restriction , which are defined in square brackets, using Turtle's syntax for anonymous blank nodes. Each owl:Restriction specifies a cardinality for a property that is allowed in resources of type incunabula:book . A cardinality is indeed a kind of restriction: it means that a resource of this type may have, or must have, a certain number of instances of the specified property. For example, incunabula:book has cardinalities saying that a book must have at least one title and at most one publication date. In the DSP-API version 1, the word 'occurrence' is used instead of 'cardinality'. The OWL cardinalities supported by Knora are described in OWL Cardinalities . Note that incunabula:book specifies a cardinality of owl:minCardinality 0 on the property incunabula:hasAuthor . At first glance, this might seem as if it serves no purpose, since it says that the property is optional and can have any number of instances. You may be wondering whether this cardinality could simply be omitted from the definition of incunabula:book . However, Knora requires every property of a resource to have some cardinality in the resource's class. This is because Knora uses the cardinalities to determine which properties are possible for instances of the class, and the DSP-API relies on this information. If there was no cardinality for incunabula:hasAuthor , Knora would not allow a book to have an author. Each owl:Restriction specifying a cardinality can include the predicate salsah-gui:guiOrder , which tells the SALSAH GUI the order the properties should be displayed in. Here is the definition of incunabula:page : :page rdf:type owl:Class ; rdfs:subClassOf knora-base:StillImageRepresentation , [ rdf:type owl:Restriction ; owl:onProperty :pagenum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOfValue ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOf ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :seqnum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :page_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :origname ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :transcription ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"page.gif\" ; rdfs:label \"Seite\"@de , \"Page\"@fr , \"Page\"@en ; rdfs:comment \"\"\"Eine Seite ist ein Teil eines Buchs\"\"\"@de , \"\"\"Une page est une partie d'un livre\"\"\"@fr , \"\"\"A page is a part of a book\"\"\"@en . The incunabula:page class is a subclass of knora-base:StillImageRepresentation , which is a subclass of knora-base:Representation , which is a subclass of knora-base:Resource . The class knora-base:Representation is used for resources that contain metadata about files stored by Knora. Each It has different subclasses that can hold different types of files, including still images, audio, and video files. A given Representation can store metadata about several different files, as long as they are of the same type and are semantically equivalent, e.g. are different versions of the same image with different colorspaces, so that coordinates in one file will work in the other files. In Knora, a subclass inherits the cardinalities defined in its superclasses. Let's look at the class hierarchy of incunabula:page , starting with knora-base:Representation : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can store one or more FileValues\"@en . This says that a Representation must have at least one instance of the property hasFileValue , which is defined like this: :hasFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasValue ; :subjectClassConstraint :Representation ; :objectClassConstraint :FileValue . The subject of hasFileValue must be a Representation , and its object must be a FileValue . There are different subclasses of FileValue for different kinds of files, but we'll skip the details here. This is the definition of knora-base:StillImageRepresentation : :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can contain two-dimensional still image files\"@en . It must have at least one instance of the property hasStillImageFileValue , which is defined as follows: :hasStillImageFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasFileValue ; :subjectClassConstraint :StillImageRepresentation ; :objectClassConstraint :StillImageFileValue . Because hasStillImageFileValue is a subproperty of hasFileValue , the cardinality on hasStillImageFileValue , defined in the subclass StillImageRepresentation , overrides the cardinality on hasFileValue , defined in the superclass Representation . In other words, the more general cardinality in the superclass is replaced by a more specific cardinality in the base class. Since incunabula:page is a subclass of StillImageRepresentation , it inherits the cardinality on hasStillImageFileValue . As a result, a page must have at least one image file attached to it. Here's another example of cardinality inheritance. The class knora-base:Resource has a cardinality for knora-base:seqnum . The idea is that resources of any type could be arranged in some sort of sequence. As we saw above, incunabula:page is a subclass of knora-base:Resource . But incunabula:page has its own cardinality for incunabula:seqnum , which is a subproperty of knora-base:seqnum . Once again, the subclass's cardinality on the subproperty replaces the superclass's cardinality on the superproperty: a page is allowed to have an incunabula:seqnum , but it is not allowed to have a knora-base:seqnum .","title":"Resource Classes"},{"location":"DSP-API/01-introduction/file-formats/","text":"File Formats in DSP-API Currently, only a limited number of file formats is accepted to be uploaded onto DSP. Some metadata is extracted from the files during the ingest but the file formats are not validated. Only image file formats are currently migrated into another format. Both, the migrated version of the file and the original are kept. The following table shows the accepted file formats: Category Accepted format Converted during ingest? Text, XML 1 TXT, XML, XSL, XSD No Tables CSV, XLS, XLSX No 2D Images JPG, JPEG, JP2, PNG, TIF, TIFF Yes, converted to JPEG 2000 by Sipi Audio MPEG (MP3), WAV No Video MP4 No Office PDF, DOC, DOCX, PPT, PPTX No Archives ZIP, TAR, GZ, Z, TAR.GZ, TGZ, GZIP, 7Z No 1: If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF .","title":"File Formats in DSP-API"},{"location":"DSP-API/01-introduction/file-formats/#file-formats-in-dsp-api","text":"Currently, only a limited number of file formats is accepted to be uploaded onto DSP. Some metadata is extracted from the files during the ingest but the file formats are not validated. Only image file formats are currently migrated into another format. Both, the migrated version of the file and the original are kept. The following table shows the accepted file formats: Category Accepted format Converted during ingest? Text, XML 1 TXT, XML, XSL, XSD No Tables CSV, XLS, XLSX No 2D Images JPG, JPEG, JP2, PNG, TIF, TIFF Yes, converted to JPEG 2000 by Sipi Audio MPEG (MP3), WAV No Video MP4 No Office PDF, DOC, DOCX, PPT, PPTX No Archives ZIP, TAR, GZ, Z, TAR.GZ, TGZ, GZIP, 7Z No 1: If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF .","title":"File Formats in DSP-API"},{"location":"DSP-API/01-introduction/standoff-rdf/","text":"Standoff/RDF Text Markup Standoff markup is text markup that is stored separately from the content it describes. DSP-API's Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. This approach has some advantages over commonly used markup systems such as XML: First, XML and other hierarchical markup systems assume that a document is a hierarchy, and have difficulty representing non-hierarchical structures or multiple overlapping hierarchies. Standoff markup can easily represent these structures. Second, markup languages are typically designed to be used in text files. But there is no standard system for searching and linking together many different text files containing markup. It is possible to do this in a non-standard way by using an XML database such as eXist , but this still does not allow for queries that include text as well as non-textual data not stored in XML. By storing markup as RDF, DSP-API can search for markup structures in the same way as it searches for any RDF data structure. This makes it possible to do searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. You could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. In DSP-API's Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, and has semantic properties of its own. You can define your own tag classes in your ontology by making subclasses of knora-base:StandoffTag , and attach your own properties to them. You can then search for those properties using DSP-API's search language, Gravsearch . The built-in knora-base and standoff ontologies provide some basic tags that can be reused or extended. These include tags that represent DSP-API data types. For example, knora-base:StandoffDateTag represents a date in exactly the same way as a date value , i.e. as a calendar-independent astronomical date. You can use this tag as-is, or extend it by making a subclass, to represent dates in texts. Gravsearch includes built-in functionality for searching for these data type tags. For example, you can search for text containing a date that falls within a certain date range . DSP-API supports automatic conversion between XML and Standoff/RDF. To make this work, Standoff/RDF stores the order of tags and their hierarchical relationships. You must define an XML-to-Standoff Mapping for your standoff tag classes and properties. Then you can import an XML document into DSP-API, which will store it as Standoff/RDF. The text and markup can then be searched using Gravsearch. When you retrieve the document, DSP-API converts it back to the original XML. To represent overlapping or non-hierarchical markup in exported and imported XML, DSP-API supports CLIX tags. As XML-to-Standoff has proved to be complicated and not very well performing, the use of standoff with custom mappings is discouraged. Improved integration of text with XML mark up, particularly TEI-XML, is in planning.","title":"Standoff/RDF Text Markup"},{"location":"DSP-API/01-introduction/standoff-rdf/#standoffrdf-text-markup","text":"Standoff markup is text markup that is stored separately from the content it describes. DSP-API's Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. This approach has some advantages over commonly used markup systems such as XML: First, XML and other hierarchical markup systems assume that a document is a hierarchy, and have difficulty representing non-hierarchical structures or multiple overlapping hierarchies. Standoff markup can easily represent these structures. Second, markup languages are typically designed to be used in text files. But there is no standard system for searching and linking together many different text files containing markup. It is possible to do this in a non-standard way by using an XML database such as eXist , but this still does not allow for queries that include text as well as non-textual data not stored in XML. By storing markup as RDF, DSP-API can search for markup structures in the same way as it searches for any RDF data structure. This makes it possible to do searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. You could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. In DSP-API's Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, and has semantic properties of its own. You can define your own tag classes in your ontology by making subclasses of knora-base:StandoffTag , and attach your own properties to them. You can then search for those properties using DSP-API's search language, Gravsearch . The built-in knora-base and standoff ontologies provide some basic tags that can be reused or extended. These include tags that represent DSP-API data types. For example, knora-base:StandoffDateTag represents a date in exactly the same way as a date value , i.e. as a calendar-independent astronomical date. You can use this tag as-is, or extend it by making a subclass, to represent dates in texts. Gravsearch includes built-in functionality for searching for these data type tags. For example, you can search for text containing a date that falls within a certain date range . DSP-API supports automatic conversion between XML and Standoff/RDF. To make this work, Standoff/RDF stores the order of tags and their hierarchical relationships. You must define an XML-to-Standoff Mapping for your standoff tag classes and properties. Then you can import an XML document into DSP-API, which will store it as Standoff/RDF. The text and markup can then be searched using Gravsearch. When you retrieve the document, DSP-API converts it back to the original XML. To represent overlapping or non-hierarchical markup in exported and imported XML, DSP-API supports CLIX tags. As XML-to-Standoff has proved to be complicated and not very well performing, the use of standoff with custom mappings is discouraged. Improved integration of text with XML mark up, particularly TEI-XML, is in planning.","title":"Standoff/RDF Text Markup"},{"location":"DSP-API/01-introduction/what-is-dsp/","text":"What is DSP and DSP-API? The DaSCH Service Platform (DSP) is a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP aims to solve key problems in the long-term preservation and reuse of humanities data: First, traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. You have to first identify an information package that might be of interest, then download it, and only then can you find out what's really in it. This is time-consuming, and makes it impractical to reuse data from many different sources. DSP solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different file formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old files, or even all the operating systems that these programs ran on. Therefore, DSP only accepts a certain number of file formats . Non-binary data is stored as RDF , in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by Sipi , with metadata stored in the triplestore. DSP makes this data available for reuse via its generic, standards-based application programming interface DSP-API. A virtual research environment (VRE) can use DSP-API to query, link, and add to data from different research projects in a unified way. Humanities-Focused Data Storage Each project creates its own data model (or ontology ), describing the types of items it wishes to store, using basic data types defined in Knora's base ontology . This gives projects the freedom to describe their data in a way that makes sense to them, while allowing DSP to support searching and linking across projects. DSP has built-in support for data structures that are commonly needed in humanities data, and that present unique challenges for any type of database storage. Calendar-Independent Dates In the humanities, a date could be based on any sort of calendar (e.g. Gregorian, Julian, Islamic, or Hebrew). The DSP stores dates using a calendar-independent, astronomical representation, and converts between calendars as needed. This makes it possible to search for a date in one calendar, and get search results in other calendars. Flexible, Searchable Text Markup Commonly used text markup systems, such as TEI/XML , have to represent a text as a hierarchy, and therefore have trouble supporting overlapping markup. DSP supports Standoff/RDF markup : the markup is stored as RDF data, separately from the text, allowing for overlapping markup. DSP's RDF-based standoff is designed to support the needs of complex digital critical editions. The DSP can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time. Powerful Searches DSP-API provides a search language, Gravsearch , that is designed to meet the needs of humanities researchers. Gravsearch supports DSP-API's humanities-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows searches to combine text-related criteria with any other criteria. For example, you could search for a text that contains a certain word and also mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. Access Control The RDF standards do not include any concept of permissions. DSP-API's permission system allows project administrators and users to determine who can see or modify each item of data. DSP-API filters search results according to each user's permissions. Data History RDF does not have a concept of data history. DSP-API maintains all previous versions of each item of data. Ordinary searches return only the latest version, but you can obtain and cite an item as it was at any point in the past. Data Consistency RDF triplestores do not implement a standardised way of ensuring the consistency of data in a repository. DSP-API ensures that all data is consistent, conforms the project-specific data models, and meets DSP-API's minimum requirements for interoperability and reusability of data. Linked Open Data DSP-API supports publishing data online as as Linked Open Data , using open standards to allow interoperability between different repositories on the web.","title":"What is DSP?"},{"location":"DSP-API/01-introduction/what-is-dsp/#what-is-dsp-and-dsp-api","text":"The DaSCH Service Platform (DSP) is a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP aims to solve key problems in the long-term preservation and reuse of humanities data: First, traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. You have to first identify an information package that might be of interest, then download it, and only then can you find out what's really in it. This is time-consuming, and makes it impractical to reuse data from many different sources. DSP solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different file formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old files, or even all the operating systems that these programs ran on. Therefore, DSP only accepts a certain number of file formats . Non-binary data is stored as RDF , in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by Sipi , with metadata stored in the triplestore. DSP makes this data available for reuse via its generic, standards-based application programming interface DSP-API. A virtual research environment (VRE) can use DSP-API to query, link, and add to data from different research projects in a unified way.","title":"What is DSP and DSP-API?"},{"location":"DSP-API/01-introduction/what-is-dsp/#humanities-focused-data-storage","text":"Each project creates its own data model (or ontology ), describing the types of items it wishes to store, using basic data types defined in Knora's base ontology . This gives projects the freedom to describe their data in a way that makes sense to them, while allowing DSP to support searching and linking across projects. DSP has built-in support for data structures that are commonly needed in humanities data, and that present unique challenges for any type of database storage.","title":"Humanities-Focused Data Storage"},{"location":"DSP-API/01-introduction/what-is-dsp/#calendar-independent-dates","text":"In the humanities, a date could be based on any sort of calendar (e.g. Gregorian, Julian, Islamic, or Hebrew). The DSP stores dates using a calendar-independent, astronomical representation, and converts between calendars as needed. This makes it possible to search for a date in one calendar, and get search results in other calendars.","title":"Calendar-Independent Dates"},{"location":"DSP-API/01-introduction/what-is-dsp/#flexible-searchable-text-markup","text":"Commonly used text markup systems, such as TEI/XML , have to represent a text as a hierarchy, and therefore have trouble supporting overlapping markup. DSP supports Standoff/RDF markup : the markup is stored as RDF data, separately from the text, allowing for overlapping markup. DSP's RDF-based standoff is designed to support the needs of complex digital critical editions. The DSP can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time.","title":"Flexible, Searchable Text Markup"},{"location":"DSP-API/01-introduction/what-is-dsp/#powerful-searches","text":"DSP-API provides a search language, Gravsearch , that is designed to meet the needs of humanities researchers. Gravsearch supports DSP-API's humanities-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows searches to combine text-related criteria with any other criteria. For example, you could search for a text that contains a certain word and also mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period.","title":"Powerful Searches"},{"location":"DSP-API/01-introduction/what-is-dsp/#access-control","text":"The RDF standards do not include any concept of permissions. DSP-API's permission system allows project administrators and users to determine who can see or modify each item of data. DSP-API filters search results according to each user's permissions.","title":"Access Control"},{"location":"DSP-API/01-introduction/what-is-dsp/#data-history","text":"RDF does not have a concept of data history. DSP-API maintains all previous versions of each item of data. Ordinary searches return only the latest version, but you can obtain and cite an item as it was at any point in the past.","title":"Data History"},{"location":"DSP-API/01-introduction/what-is-dsp/#data-consistency","text":"RDF triplestores do not implement a standardised way of ensuring the consistency of data in a repository. DSP-API ensures that all data is consistent, conforms the project-specific data models, and meets DSP-API's minimum requirements for interoperability and reusability of data.","title":"Data Consistency"},{"location":"DSP-API/01-introduction/what-is-dsp/#linked-open-data","text":"DSP-API supports publishing data online as as Linked Open Data , using open standards to allow interoperability between different repositories on the web.","title":"Linked Open Data"},{"location":"DSP-API/02-dsp-ontologies/introduction/","text":"Introduction The DSP ontologies provide a generic framework for describing humanities research data, allowing data from different projects to be combined, augmented, and reused. Resource Description Framework (RDF) DSP-API uses a hierarchy of ontologies based on the Resource Description Framework ( RDF ), RDF Schema ( RDFS ), and the Web Ontology Language ( OWL ). Both RDFS and OWL are expressed in RDF. RDF expresses information as a set of statements (called triples ). A triple consists of a subject, a predicate, and an object: The object may be either a literal value (such as a name or number) or another subject. Thus it is possible to create complex graphs that connect many subjects, like this: In RDF, each subject and predicate has a unique, URL-like identifier called an Internationalized Resource Identifier ( IRI ). Within a given project, IRIs typically differ only in their last component (the \"local part\"), which is often the fragment following a # character. Such IRIs share a long \"prefix\". In Turtle and similar formats for writing RDF, a short prefix label can be defined to represent the long prefix. Then an IRI can be written as a prefix label and a local part, separated by a colon ( : ). For example, if the \"example\" project's long prefix is http://www.example.org/rdf# , and it contains subjects with IRIs like http://www.example.org/rdf#book , we can define the prefix label ex to represent the prefix label, and write prefixed names for IRIs: Built-in Ontologies and User-Created Ontologies To ensure the interoperability of data produced by different projects, each project must describe its data model by creating one or more ontologies that extend Knora's built-in ontologies. The main built-in ontology in Knora is knora-base . Shared Ontologies Knora does not normally allow a project to use classes or properties defined in an ontology that belongs to another project. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. Specifically, in a shared ontology, existing classes and properties cannot safely be changed, but new ones can be added. (It is not even safe to add an optional cardinality to an existing class, because this could cause subclasses to violate the rule that a class cannot have a cardinality on property P as well as a cardinality on a subproperty of P; see Restrictions on Classes .) For more details about shared ontologies, see Shared Ontologies .","title":"Introduction"},{"location":"DSP-API/02-dsp-ontologies/introduction/#introduction","text":"The DSP ontologies provide a generic framework for describing humanities research data, allowing data from different projects to be combined, augmented, and reused.","title":"Introduction"},{"location":"DSP-API/02-dsp-ontologies/introduction/#resource-description-framework-rdf","text":"DSP-API uses a hierarchy of ontologies based on the Resource Description Framework ( RDF ), RDF Schema ( RDFS ), and the Web Ontology Language ( OWL ). Both RDFS and OWL are expressed in RDF. RDF expresses information as a set of statements (called triples ). A triple consists of a subject, a predicate, and an object: The object may be either a literal value (such as a name or number) or another subject. Thus it is possible to create complex graphs that connect many subjects, like this: In RDF, each subject and predicate has a unique, URL-like identifier called an Internationalized Resource Identifier ( IRI ). Within a given project, IRIs typically differ only in their last component (the \"local part\"), which is often the fragment following a # character. Such IRIs share a long \"prefix\". In Turtle and similar formats for writing RDF, a short prefix label can be defined to represent the long prefix. Then an IRI can be written as a prefix label and a local part, separated by a colon ( : ). For example, if the \"example\" project's long prefix is http://www.example.org/rdf# , and it contains subjects with IRIs like http://www.example.org/rdf#book , we can define the prefix label ex to represent the prefix label, and write prefixed names for IRIs:","title":"Resource Description Framework (RDF)"},{"location":"DSP-API/02-dsp-ontologies/introduction/#built-in-ontologies-and-user-created-ontologies","text":"To ensure the interoperability of data produced by different projects, each project must describe its data model by creating one or more ontologies that extend Knora's built-in ontologies. The main built-in ontology in Knora is knora-base .","title":"Built-in Ontologies and User-Created Ontologies"},{"location":"DSP-API/02-dsp-ontologies/introduction/#shared-ontologies","text":"Knora does not normally allow a project to use classes or properties defined in an ontology that belongs to another project. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. Specifically, in a shared ontology, existing classes and properties cannot safely be changed, but new ones can be added. (It is not even safe to add an optional cardinality to an existing class, because this could cause subclasses to violate the rule that a class cannot have a cardinality on property P as well as a cardinality on a subproperty of P; see Restrictions on Classes .) For more details about shared ontologies, see Shared Ontologies .","title":"Shared Ontologies"},{"location":"DSP-API/02-dsp-ontologies/knora-base/","text":"The Knora Base Ontology Overview The Knora base ontology is the main built-in Knora ontology. Each project that uses DSP-API must describe its data model by creating ontologies that extend this ontology. The Knora base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In the DSP-API documentation in general, it is identified by the prefix knora-base , but for brevity, in this document, we use kb or omit the prefix entirely. The Knora Data Model The Knora data model is based on the observation that, in the humanities, a value or literal is often itself structured and can be highly complex. Moreover, a value may have its own metadata, such as its creation date, information about permissions, and so on. Therefore, the Knora base ontology describes structured value types that can store this type of metadata. In the diagram below, a book ( ex:book2 ) has a title (identified by the predicate ex:title ) and a publication date ( ex:pubdate ), each of which has some metadata. Projects In Knora, each item of data belongs to some particular project. Each project using Knora must define a kb:knoraProject , which has these properties (cardinalities are indicated in parentheses after each property name): projectShortname (1): A short name that can be used to identify the project in configuration files and the like. projectLongname (0-1): The full name of the project. projectShortcode (1): A hexadecimal code that uniquely identifies the project. These codes are assigned to projects by the DaSCH . projectDescription (1-n): A description of the project. belongsToInstitution (0-1): The kb:Institution that the project belongs to. Ontologies and resources are associated with a project by means of the kb:attachedToProject property, as described in Ontologies and Properties of Resource ). Users are associated with a project by means of the kb:isInProject property, as described in Users and Groups . Ontologies Each user-created ontology must be defined as an owl:Ontology with the properties rdfs:label and kb:attachedToProject . Since DSP-API v20 kb:lastModificationDate property is also required. Resources All the content produced by a project (e.g. digitised primary source materials or research data) must be stored in objects that belong to subclasses of kb:Resource , so that Knora can query and update that content. Each project using the Knora base ontology must define its own OWL classes, derived from kb:Resource , to represent the types of data it deals with. A subclass of kb:Resource may additionally be a subclass of any other class, e.g. an industry-standard class such as foaf:Person ; this can facilitate searches across projects. Resources have properties that point to different parts of the content they contain. For example, a resource representing a book could have a property called hasAuthor , pointing to the author of the book. There are two possible kinds of content in a Knora resource: Knora values (see Values ) or links to other resources (see Links Between Resources ). Properties that point to Knora values must be subproperties of kb:hasValue , and properties that point to other resources must be subproperties of kb:hasLinkTo . Either of these two types of properties may also be a subproperty of any other property, e.g. an industry-standard property such as foaf:name ; this can facilitate searches across projects. Each property definition must specify the types that its subjects and objects must belong to (see Constraints on the Types of Property Subjects and Objects for details). Each user-created resource class definition must use OWL cardinality restrictions to specify the properties that resources of that class can have (see OWL Cardinalities for details). Resources are not versioned; only their values are versioned (see Values ). Every resource is required to have an rdfs:label . The object of this property is an xsd:string , rather than a Knora value; hence it is not versioned. A user who has modify permission on a resource (see Authorisation ) can change its label. A resource can be marked as deleted; Knora does this by adding the predicate kb:isDeleted true to the resource. An optional kb:deleteComment may be added to explain why the resource has been marked as deleted. Deleted resources are normally hidden. They cannot be undeleted, because even though resources are not versioned, it is necessary to be able to find out when a resource was deleted. If desired, a new resource can be created by copying data from a deleted resource. Properties of Resource creationDate (1): The time when the resource was created. attachedToUser (1): The user who owns the resource. attachedToProject (1): The project that the resource is part of. lastModificationDate (0-1): A timestamp indicating when the resource (or one of its values) was last modified. seqnum (0-1): The sequence number of the resource, if it is part of an ordered group of resources, such as the pages in a book. isDeleted (1): Indicates whether the resource has been deleted. deleteDate (0-1): If the resource has been deleted, indicates when it was deleted. deleteComment (0-1): If the resource has been deleted, indicates why it was deleted. Resources can have properties that point to other resources; see Links Between Resources . A resource grants permissions to groups of users; see Authorisation . Representations It is not practical to store all data in RDF. In particular, RDF is not a good storage medium for binary data such as images. Therefore, Knora stores such data outside the triplestore, in ordinary files. A resource can have metadata about a file attached to it. The technical term for such a resource in Knora is a Representation . For each file, there is a kb:FileValue in the triplestore containing metadata about the file (see FileValue ). Knora uses Sipi to store files. The Knora APIs provide ways to create file values using Knora and Sipi. A resource that has a file value must belong to one of the subclasses of kb:Representation . Its subclasses include: StillImageRepresentation : A representation containing a still image file. MovingImageRepresentation : A representation containing a video file. AudioRepresentation : A representation containing an audio file. DDDrepresentation : A representation containing a 3D image file. TextRepresentation : A representation containing a formatted text file, such as an XML file. DocumentRepresentation : A representation containing a document (such as a PDF file) that is not a text file. ArchiveRepresentation : A representation containing an archive file (such as a zip archive). These classes can be used directly in data, but it is often better to make subclasses of them, to include metadata about the files being stored. The base class of all these classes is Representation , which is not intended to be used directly. It has this property, which its subclasses override: hasFileValue (1): Points to a file value. There are two ways for a project to design classes for representations. The simpler way is to create a resource class that represents a thing in the world (such as ex:Painting ) and also belongs to a subclass of Representation . This is adequate if the class can have only one type of file attached to it. For example, if paintings are represented only by still images, ex:Painting could be a subclass of StillImageRepresentation . This is the only approach supported in DSP-API v1. The more flexible approach, which is supported by DSP-API v2, is for each ex:Painting to link (using kb:hasRepresentation or a subproperty) to other resources containing files that represent the painting. Each of these other resources can extend a different subclass of Representation . For example, a painting could have a StillImageRepresentation as well as a DDDrepresentation . Standard Resource Classes In general, each project using Knora must define its own subclasses of kb:Resource . However, the Knora base ontology provides some standard subclasses of kb:Resource , which are intended to be used by any project: Region : Represents a region of a Representation (see Representations ). Annotation : Represents an annotation of a resource. The hasComment property points to the text of the annotation, represented as a kb:TextValue . LinkObj : Represents a link that connects two or more resources. A LinkObj has a hasLinkTo property pointing to each resource that it connects, as well as a hasLinkToValue property pointing to a reification of each of these direct links ( see Links Between Resources ). A LinkObj is more complex (and hence less convenient and readable) than a simple direct link, but it has the advantage that it can be annotated using an Annotation . For improved readability, a project can make its own subclasses of LinkObj with specific meanings. Values The Knora base ontology defines a set of OWL classes that are derived from kb:Value and represent different types of structured values found in humanities data. This set of classes may not be extended by user-created ontologies. A value is always part of one particular resource, which points to it using some property derived from hasValue . For example, a user-created ontology could specify a Book class with a property hasSummary (derived from hasValue ), and that property could have a knora-base:objectClassConstraint of TextValue . This would mean that the summary of each book is represented as a TextValue . Knora values are versioned. Existing values are not modified. Instead, a new version of an existing value is created. The new version is linked to the old version via the previousValue property. Since each value version has a different IRI, there is no IRI that can be used to cite the value, such that it will always refer to the latest version of the value. Therefore, the latest version of each value has a separate UUID, as the object of the property valueHasUUID . When a new version of the value is created, this UUID is moved to the new version. This makes it possible to cite the latest version of a value by searching for the UUID. \"Deleting\" a value means marking it with kb:isDeleted . An optional kb:deleteComment may be added to explain why the value has been marked as deleted. Deleted values are normally hidden. Most types of values are marked as deleted without creating a new version of the value. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. To simplify the enforcement of ontology constraints, and for consistency with resource updates, no new versions of a deleted value can be made; it is not possible to undelete. Instead, if desired, a new value can be created by copying data from a deleted value. Properties of Value valueCreationDate (1): The date and time when the value was created. attachedToUser (1): The user who owns the value. valueHasString (1): A human-readable string representation of the value's contents, which is available to Knora's full-text search index. valueHasOrder (0-1): A resource may have several properties of the same type with different values (which will be of the same class), and it may be necessary to indicate an order in which these values occur. For example, a book may have several authors which should appear in a defined order. Hence, valueHasOrder , when present, points to an integer literal indicating the order of a given value relative to the other values of the same property. These integers will not necessarily start at any particular number, and will not necessarily be consecutive. previousValue (0-1): The previous version of the value. valueHasUUID (0-1): The UUID that refers to all versions of the value. Only the latest version of the value has this property. isDeleted (1): Indicates whether the value has been deleted. deleteDate (0-1): If the value has been deleted, indicates when it was deleted. deleteComment (0-1): If the value has been deleted, indicates why it was deleted. Each Knora value can grant permissions (see Authorisation ). Subclasses of Value TextValue Represents text, possibly including markup. The text is the object of the valueHasString property. A line break is represented as a Unicode line feed character ( U+000A ). The non-printing Unicode character INFORMATION SEPARATOR TWO (U+001E) can be used to separate words that are separated only by standoff markup (see below), so they are recognised as separate in a full-text search index. Markup is stored using this property: valueHasStandoff (0-n): Points to a standoff markup tag. See Text with Standoff Markup . valueHasMapping (0-1): Points to the mapping used to create the standoff markup and to convert it back to the original XML. See Mapping to Create Standoff From XML . A text value can have a specified language: valueHasLanguage (0-1): An ISO 639-1 code as string specifying the language of the text. DateValue Humanities data includes many different types of dates. In Knora, a date has a specified calendar, and is always represented as a period with start and end points (which may be equal), each of which has a precision ( DAY , MONTH , or YEAR ). For GREGORIAN and JULIAN calendars, an optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Internally, the start and end points are stored as two Julian Day Numbers. This calendar-independent representation makes it possible to compare and search for dates regardless of the calendar in which they were entered. Properties: valueHasCalendar (1): The name of the calendar in which the date should be displayed. Currently GREGORIAN , JULIAN , and ISLAMIC civil calendars are supported. valueHasStartJDN (1): The Julian Day Number of the start of the period (an xsd:integer ). valueHasStartPrecision (1): The precision of the start of the period. valueHasEndJDN (1): The Julian Day Number of the end of the period (an xsd:integer ). valueHasEndPrecision (1): The precision of the end of the period. TimeValue A Knora time value represents a precise moment in time in the Gregorian calendar. Since nanosecond precision can be included, it is suitable for use as a timestamp. Properties: valueHasTimeStamp (1): An xsd:dateTimeStamp , stored as an xsd:dateTime (because SPARQL does not support xsd:dateTimeStamp ). IntValue Represents an integer. Property: valueHasInteger (1): An xsd:integer . ColorValue valueHasColor (1): A string representing a color. The string encodes a color as hexadecimal RGB values, e.g. \\#FF0000 . DecimalValue Represents an arbitrary-precision decimal number. Property: valueHasDecimal (1): An xsd:decimal . UriValue Represents a non-Knora URI. Property: valueHasUri (1): An xsd:anyURI . BooleanValue Represents a boolean value. Property: valueHasBoolean (1): An xsd:boolean . GeomValue Represents a geometrical object as a JSON string, using normalized coordinates. Property: valueHasGeometry (1): A JSON string. GeonameValue Represents a geolocation, using the identifiers found at GeoNames . Property: valueHasGeonameCode (1): The identifier of a geographical feature from GeoNames , represented as an xsd:string . IntervalValue Represents a time interval, with precise start and end times on a timeline, e.g. relative to the beginning of an audio or video file. Properties: valueHasIntervalStart (1): An xsd:decimal representing the start of the interval in seconds. valueHasIntervalEnd (1): An xsd:decimal representing the end of the interval in seconds. ListValue Projects often need to define lists or hierarchies of categories that can be assigned to many different resources. Then, for example, a user interface can provide a drop-down menu to allow the user to assign a category to a resource. The ListValue class provides a way to represent these sorts of data structures. It can represent either a flat list or a tree. A ListValue has this property: valueHasListNode (1): Points to a ListNode . Each ListNode can have the following properties: isRootNode (0-1): Set to true if this is the root node. hasSubListNode (0-n): Points to the node's child nodes, if any. hasRootNode (0-1): Points to the root node of the list (absent if isRootNode is true ). listNodePosition (0-1): An integer indicating the node's position in the list of its siblings (absent if isRootNode is true ). listNodeName (0-1): The node's human-readable name (absent if isRootNode is true ). FileValue Knora stores certain kinds of data outside the triplestore, in files (see Representations ). Each digital object that is stored outside the triplestore has associated metadata, which is stored in the triplestore in a kb:FileValue . The base class FileValue , which is not intended to be used directly, has these properties: internalFilename (1): The name of the file as stored by Knora. internalMimeType (1): The MIME type of the file as stored by Knora. originalFilename (0-1): The original name of the file when it was uploaded to the DSP-API server. originalMimeType (0-1): The original MIME type of the file when it was uploaded to the Knora API server. isPreview (0-1): A boolean indicating whether the file is a preview, i.e. a small image representing the contents of the file. A preview is always a StillImageFileValue , regardless of the type of the enclosing Representation . The subclasses of FileValue , which are intended to be used directly in data, include: StillImageFileValue : Contains metadata about a still image file. MovingImageFileValue : Contains metadata about a video file. AudioFileValue : Contains metadata about an audio file. DDDFileValue : Contains metadata about a 3D image file. TextFileValue : Contains metadata about a text file. DocumentFileValue : Contains metadata about a document (such as PDF) that is not a text file. ArchiveFileValue : Contains metadata about an archive (such as zio archive). Each of these classes contains properties that are specific to the type of file it describes. For example, still image files have dimensions, video files have frame rates, and so on. FileValue objects are versioned like other values, and the actual files stored by Knora are also versioned. Version 1 of the DSP-API does not provide a way to retrieve a previous version of a file, but this feature will be added in a subsequent version of the API. LinkValue A LinkValue is an RDF \"reification\" containing metadata about a link between two resources. It is therefore a subclass of rdf:Statement as well as of Value . It has these properties: rdf:subject (1) : The resource that is the source of the link. rdf:predicate (1) : The link property. rdf:object (1) : The resource that is the target of the link. valueHasRefCount (1) : The reference count of the link. This is meaningful when the LinkValue describes resource references in Standoff text markup (see StandoffLinkTag ). Otherwise, the reference count will always be 1 (if the link exists) or 0 (if it has been deleted). For details about how links are created in Knora, see Links Between Resources . ExternalResValue Represents a resource that is not stored in the RDF triplestore managed by Knora, but instead resides in an external repository managed by some other software. The ExternalResValue contains the information that Knora needs in order to access the resource, assuming that a suitable gateway plugin is installed. extResAccessInfo (1) : The location of the repository containing the external resource (e.g. its URL). extResId (1) : The repository-specific ID of the external resource. extResProvider (1) : The name of the external provider of the resource. Links Between Resources A link between two resources is expressed, first of all, as a triple, in which the subject is the resource that is the source of the link, the predicate is a \"link property\" (a subproperty of kb:hasLinkTo ), and the object is the resource that is the target of the link. It is also useful to store metadata about links. For example, Knora needs to know who owns the link, who has permission to modify it, when it was created, and so on. Such metadata cannot simply describe the link property, because then it would refer to that property in general, not to any particular instance in which that property is used to connect two particular resources. To attach metadata to a specific link in RDF, it is necessary to create an RDF \"reification\". A reification makes statements about a particular triple (subject, predicate, object), in this case the triple that expresses the link between the resources. Knora uses reifications of type kb:LinkValue (described in LinkValue to store metadata about links. For example, suppose a project describes paintings that belong to collections. The project can define an ontology as follows (expressed here in Turtle format, and simplified for the purposes of illustration): @prefix kb <http://www.knora.org/ontology/knora-base#> . @prefix : <http://www.knora.org/ontology/paintings#> . :Painting rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasArtist ; owl:cardinality 1 ] , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollection ; owl:minCardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollectionValue ; owl:minCardinality 1 ] . :Collection rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasCollectionName ; owl:cardinality 1 ] . :hasArtist rdf:type owl:ObjectProperty ; rdfs:label \"Name of artist\" ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasTitle rdf:type owl:ObjectProperty ; rdfs:label \"Title of painting\" kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasCollectionName rdf:type owl:ObjectProperty ; rdfs:label \"Name of collection\" ; kb:subjectClassConstraint :Collection ; kb:objectClassConstraint kb:TextValue . To link the paintings to the collection, we must add a \"link property\" to the ontology. In this case, the link property will point from a painting to the collection it belongs to. Every link property must be a subproperty of kb:hasLinkTo . :isInCollection rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkTo ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint :Collection . We must then add a \"link value property\", which will point from a painting to a kb:LinkValue (described in LinkValue ), which will contain metadata about the link between the property and the collection. In particular, the link value specifies the creator of the link, the date when it was created, and the permissions that determine who can view or modify it. The name of the link value property is constructed using a simple naming convention: the word Value is appended to the name of the link property. In this case, since our link property is called :isInCollection , the link value property must be called :isInCollectionValue . Every link value property must be a subproperty of kb:hasLinkToValue . :isInCollectionValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkToValue ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:LinkValue . Given this ontology, we can create some RDF data describing a painting and a collection: @prefix paintings <http://www.knora.org/ontology/paintings#> . @prefix data <http://www.knora.org/ontology/paintings/data#> . data:dali_4587 rdf:type paintings:Painting ; paintings:hasTitle data:value_A ; paintings:hasArtist data:value_B . data:value_A rdf:type kb:TextValue ; kb:valueHasString \"The Persistence of Memory\" . data:value_B rdf:type kb:TextValue ; kb:valueHasString \"Salvador Dali\" . data:pompidou rdf:type paintings:Collection ; paintings:hasCollectionName data:value_C . data:value_C rdf:type kb:TextValue ; kb:valueHasString \"Centre Pompidou, Paris\" . We can then state that the painting is in the collection: data:dali_4587 paintings:isInCollection data:pompidou ; paintings:isinCollectionValue data:value_D . data:value_D rdf:type kb:LinkValue ; rdf:subject data:dali_4587 ; rdf:predicate paintings:isInCollection ; rdf:object data:pompidou ; kb:valueHasRefCount 1 . This creates a link ( paintings:isInCollection ) between the painting and the collection, along with a reification containing metadata about the link. We can visualise the result as the following graph: Knora allows a user to see a link if the requesting user has permission to see the source and target resources as well as the kb:LinkValue . Part-Whole-Relations between Resources isPartOf A special case of linked resources are part-of related resources , i.e. a resource consisting of several other resources. In order to create a part-of relation between two resources, the resource that is part of another resource needs to have a property that is either kb:isPartOf or a subproperty thereof. kb:isPartOf itself is a subproperty of kb:hasLinkTo . Same as described above for link properties, a corresponding part-of value property is created automatically. This value property has the same name as the part-of property with Value appended. For example, if in an ontology data a property data:partOf was defined, the corresponding value property would be named data:partOfValue . This newly created property data:partOfValue is defined as a subproperty of kb:isPartOfValue . Part-of relations are recommended for resources of type kb:StillImageRepresentation . In that case, the resource that is part of another resource needs to have a property kb:seqnum or a subproperty thereof, with an integer as value. A client can then use this information to leaf through the parts of the compound resource (p.ex. to leaf through the pages of a book like in this example). isSequenceOf Similar to kb:isPartOf for kb:StillImageRepresentations , part-whole-relations can be defined for resources that have a time dimension by using kb:isSequenceOf . You can use it for video or audio resources that are subtypes of kb:MovingImageRepresentation and kb:AudioRepresentation . kb:isSequenceOf is intended to be used in combination with the property kb:hasSequenceBounds which points to a kb:IntervalValue . This defines the start and end point of the subseqence in relation to the entire audio/video resource as an interval . When the properties are used in this combination, a dedicated behavior in the frontend allows to display the sequences alongside the main resource. There is an important difference between kb:isSequenceOf and kb:isPartOf : For kb:isPartOf , each part is a kb:StillImageRepresentation and the whole consists of multiple such parts. In kb:isSequenceOf on the other hand, the whole is one kb:MovingImageRepresentation or kb:AudioRepresentation . The parts only define which sub-sequence of this representation they are. Text with Standoff Markup DSP-API is designed to be able to store text with markup, which can indicate formatting and structure, as well as the complex observations involved in transcribing handwritten manuscripts. One popular way of representing text in the humanities is to encode it in XML using the Text Encoding Initiative ( TEI ) guidelines. In DSP-API, a TEI/XML document can be stored as a file with attached metadata, but this is not recommended, because it does not allow to perform searches across multiple documents. The recommended way to store text with markup in DSP-API is to use the built-in support for \"standoff\" markup, which is stored separately from the text. This has some advantages over embedded markup such as XML. While XML requires markup to have a hierarchical structure, and does not allow overlapping tags, standoff nodes do not have these limitations (see Using Standoff Properties for Marking-up Historical Documents in the Humanities ). A standoff tag can be attached to any substring in the text by giving its start and end positions. Unlike in corpus linguistics, we do not use any tokenisation resulting in a form of predefined segmentation, which would limit the user's ability to freely annotate any ranges in the text. For example, suppose we have the following text: This sentence has overlapping visual attributes. This would require just two standoff tags: (italic, start=5, end=29) and (bold, start=14, end=36) . Moreover, standoff makes it possible to mark up the same text in different, possibly incompatible ways, allowing for different interpretations without making redundant copies of the text. In the Knora base ontology, any text value can have standoff tags. By representing standoff as RDF triples, DSP-API makes markup searchable across multiple text documents in a repository. For example, if a repository contains documents in which references to persons are indicated in standoff, it is straightforward to find all the documents mentioning a particular person. DSP-API's standoff support is intended to make it possible to convert documents with embedded, hierarchical markup, such as TEI/XML, into RDF standoff and back again, with no data loss, thus bringing the benefits of RDF to existing TEI-encoded documents. In the Knora base ontology, a TextValue can have one or more standoff tags. Each standoff tag indicates the start and end positions of a substring in the text that has a particular attribute. The OWL class kb:StandoffTag , which is the base class of all standoff node classes, has these properties: standoffTagHasStart (1): The index of the first character in the text that has the attribute. standoffTagHasEnd (1): The index of the last character in the text that has the attribute, plus 1. standoffTagHasUUID (1): A UUID identifying this instance and those corresponding to it in later versions of the TextValue it belongs to. The UUID is a means to maintain a reference to a particular range of a text also when new versions are made and standoff tag IRIs change. standoffTagHasOriginalXMLID (0-1): The original ID of the XML element that the standoff tag represents, if any. standoffTagHasStartIndex (1): The start index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same start position, they can be nested correctly with this information when transforming them to XML. standoffTagHasEndIndex (1): The end index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same end position, they can be nested correctly with this information when transforming them to XML. standoffTagHasStartParent (0-1): Points to the parent standoff tag. This corresponds to the original nesting of tags in XML. If a standoff tag has no parent, it represents the XML root element. If the original XML element is a CLIX tag, it represents the start of a virtual (non syntactical) hierarchy. standoffTagHasEndParent (0-1): Points to the parent standoff tag if the original XML element is a CLIX tag and represents the end of a virtual (non syntactical) hierarchy. The StandoffTag class is not used directly in RDF data; instead, its subclasses are used. A few subclasses are currently provided in standoff-onto.ttl , and more will be added to support TEI semantics. Projects are able to define their own custom standoff tag classes (direct subclasses of StandoffTag or one of the standoff data type classes or subclasses of one of the standoff classes defined in standoff-onto.ttl ). Subclasses of StandoffTag Standoff Data Type Tags Associates data in some Knora value type with a substring in a text. Standoff data type tags are subclasses of ValueBase classes. StandoffLinkTag Indicates that a substring refers to another kb:Resource . See StandoffLinkTag . StandoffInternalReferenceTag Indicates that a substring refers to another standoff tag in the same text value. See Internal Links in a TextValue . StandoffUriTag Indicates that a substring is associated with a URI, which is stored in the same form that is used for kb:UriValue . See UriValue . StandoffDateTag Indicates that a substring represents a date, which is stored in the same form that is used for kb:DateValue . See DateValue . StandoffColorTag Indicates that a substring represents a color, which is stored in the same form that is used for kb:ColorValue . See ColorValue . StandoffIntegerTag Indicates that a substring represents an integer, which is stored in the same form that is used for kb:IntegerValue . See IntValue . StandoffDecimalTag Indicates that a substring represents a number with fractions, which is stored in the same form that is used for kb:DecimalValue . See DecimalValue . StandoffIntervalTag Indicates that a substring represents an interval, which is stored in the same form that is used for kb:IntervalValue . See IntervalValue . StandoffBooleanTag Indicates that a substring represents a Boolean, which is stored in the same form that is used for kb:BooleanValue . See BooleanValue . StandoffTimeTag Indicates that a substring represents a timestamp, which is stored in the same form that is used for kb:TimeValue . See TimeValue . StandoffLinkTag A StandoffLinkTag Indicates that a substring is associated with a Knora resource. For example, if a repository contains resources representing persons, a text could be marked up so that each time a person's name is mentioned, a StandoffLinkTag connects the name to the Knora resource describing that person. It has the following property: standoffTagHasLink (1): The IRI of the resource that is referred to. One of the design goals of the Knora base ontology is to make it easy and efficient to find out which resources contain references to a given resource. Direct links are easier and more efficient to query than indirect links. Therefore, when a text value contains a resource reference in its standoff nodes, Knora automatically creates a direct link between the containing resource and the target resource, along with an RDF reification (a kb:LinkValue ) describing the link, as discussed in Links Between Resources . In this case, the link property is always kb:hasStandoffLinkTo , and the link value property (which points to the LinkValue ) is always kb:hasStandoffLinkToValue . DSP-API automatically updates direct links and reifications for standoff resource references when text values are updated. To do this, it keeps track of the number of text values in each resource that contain at least one standoff reference to a given target resource. It stores this number as the reference count of the LinkValue (see LinkValue ) describing the direct link. Each time this number changes, it makes a new version of the LinkValue , with an updated reference count. When the reference count reaches zero, it removes the direct link and makes a new version of the LinkValue , marked with kb:isDeleted . For example, if data:R1 is a resource with a text value in which the resource data:R2 is referenced, the repository could contain the following triples: data : R1 ex : hasComment data : V1 . data : V1 rdf : type kb : TextValue ; kb : valueHasString \"This link is internal.\" ; kb : valueHasStandoff data : SO1 . data : SO1 rdf : type kb : StandoffLinkTag ; kb : standoffTagHasStart: 5 ; kb : standoffTagHasEnd: 9 ; kb : standoffTagHasLink data : R2 . data : R1 kb : hasStandoffLinkTo data : R2 . data : R1 kb : hasStandoffLinkToValue data : LV1 . data : LV1 rdf : type kb : LinkValue ; rdf : subject data : R1 ; rdf : predicate kb : hasStandoffLinkTo ; rdf : object data : R2 ; kb : valueHasRefCount 1 . The result can be visualized like this: Link values created automatically for resource references in standoff are visible to all users, and the creator of these link values is always kb:SystemUser (see Users and Groups ). The DSP-API server allows a user to see a standoff link if the user has permission to see the source and target resources. Internal Links in a TextValue Internal links in a TextValue can be represented using the data type standoff class StandoffInternalReferenceTag or a subclass of it. It has the following property: standoffTagHasInternalReference (1): Points to a StandoffTag that belongs to the same TextValue . It has an objectClassConstraint of StandoffTag . For links to a kb:Resource , see StandoffLinkTag . Mapping to Create Standoff From XML A mapping allows for the conversion of an XML document to RDF-standoff and back. A mapping defines one-to-one relations between XML elements (with or without a class) and attributes and standoff classes and properties (see XML to Standoff Mapping ). A mapping is represented by a kb:XMLToStandoffMapping which contains one or more kb:MappingElement . A kb:MappingElement maps an XML element (including attributes) to a standoff class and standoff properties. It has the following properties: mappingHasXMLTagname (1): The name of the XML element that is mapped to a standoff class. mappingHasXMLNamespace (1): The XML namespace of the XML element that is mapped to a standoff class. If no namespace is given, noNamespace is used. mappingHasXMLClass (1): The name of the class of the XML element. If it has no class, noClass is used. mappingHasStandoffClass (1): The standoff class the XML element is mapped to. mappingHasXMLAttribute (0-n): Maps XML attributes to standoff properties using MappingXMLAttribute . See below. mappingHasStandoffDataTypeClass (0-1): Indicates the standoff data type class of the standoff class the XML element is mapped to. mappingElementRequiresSeparator (1): Indicates if there should be an invisible word separator inserted after the XML element in the RDF-standoff representation. Once the markup is stripped, text segments that belonged to different elements may be concatenated. A MappingXMLAttribute has the following properties: - mappingHasXMLAttributename : The name of the XML attribute that is mapped to a standoff property. - mappingHasXMLNamespace : The namespace of the XML attribute that is mapped to a standoff property. If no namespace is given, noNamespace is used. - mappingHasStandoffProperty : The standoff property the XML attribute is mapped to. DSP-API includes a standard mapping used by the DSP APP. It has the IRI http://rdfh.ch/standoff/mappings/StandardMapping and defines mappings for a few elements used to write texts with simple markup. Standoff in Digital Editions DSP-API's standoff is designed to make it possible to convert XML documents to standoff and back. One application for this feature is an editing workflow in which an editor works in an XML editor, and the resulting XML documents are converted to standoff and stored in the DSP, where they can be searched and annotated. If an editor wants to correct text that has been imported from XML into standoff, the text can be exported as XML, edited, and imported again. To preserve annotations on standoff tags across edits, each tag can automatically be given a UUID. In a future version of the Knora base ontology, it may be possible to create annotations that point to UUIDs rather than to IRIs. When a text is exported to XML, the UUIDs can be included in the XML. When the edited XML is imported again, it can be converted to new standoff tags with the same UUIDs. Annotations that applied to standoff tags in the previous version of the text will therefore also apply to equivalent tags in the new version. When text is converted from XML into standoff, tags are also given indexes, which are numbered from 0 within the context of a particular text. This makes it possible to order tags that share the same position, and to preserve the hierarchy of the original XML document. An ordinary, hierarchical XML tag is converted to a standoff tag that has one index, as well as the index of its parent tag, if any. The Knora base ontology also supports non-hierarchical markup such as CLIX , which enables overlapping markup to be represented in XML. When non-hierarchical markup is converted to standoff, both the start position and the end position of the standoff tag have indexes and parent indexes. To support these features, a standoff tag can have these additional properties: - standoffTagHasStartIndex (0-1): The index of the start position. - standoffTagHasEndIndex (0-1): The index of the end position, if this is a non-hierarchical tag. - standoffTagHasStartParent (0-1): The IRI of the tag, if any, that contains the start position. - standoffTagHasEndParent (0-1): The IRI of the tag, if any, that contains the end position, if this is a non-hierarchical tag. - standoffTagHasUUID (0-1): A UUID that can be used to annotate a standoff tag that may be present in different versions of a text, or in different layers of a text (such as a diplomatic transcription and an edited critical text). Querying Standoff in SPARQL A future version of DSP-API may provide an API for querying standoff markup. In the meantime, it is possible to query it directly in SPARQL. For example, here is a SPARQL query (using RDFS inference) that finds all the text values that have a standoff date tag referring to Christmas Eve 2016, contained in a StandoffItalicTag : PREFIX knora-base : <http://www.knora.org/ontology/knora-base#> PREFIX standoff : <http://www.knora.org/ontology/standoff#> select * where { ?standoffTag a knora-base : StandoffDateTag . ?standoffTag knora-base : valueHasStartJDN ?dateStart . ?standoffTag knora-base : valueHasEndJDN ?dateEnd . FILTER ( 2457747 <= ?dateEnd && 2457747 >= ?dateStart ) ?standoffTag knora-base : standoffTagHasStartParent ?parent . ?parent a standoff : StandoffItalicTag . ?textValue knora-base : valueHasStandoff ?standoffTag . ?textValue knora-base : valueHasString ?string . ?standoffTag knora-base : standoffTagHasStart ?startPos . ?standoffTag knora-base : standoffTagHasEnd ?endPos . } Authorisation Users and Groups Each Knora user is represented by an object belonging to the class kb:User , which is a subclass of foaf:Person , and has the following properties: userid (1) : A unique identifier that the user must provide when logging in. password (1) : A cryptographic hash of the user's password. email (0-n) : Email addresses belonging to the user. isInProject (0-n) : Projects that the user is a member of. isInGroup (0-n) : user-created groups that the user is a member of. foaf:familyName (1) : The user's family name. foaf:givenName (1) : The user's given name. Knora's concept of access control is that an object (a resource or value) can grant permissions to groups of users (but not to individual users). There are several built-in groups: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:ProjectMember : When checking a user's permissions on an object, the user is automatically assigned to this group if she is a member of the project that the object belongs to. knora-admin:Creator : When checking a user's permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectAdmin : When checking a user's permissions on an object, the user is automatically assigned to this group if she is an administrator of the project that the object belongs to. knora-admin:SystemAdmin : The group of Knora system administrators. A user-created ontology can define additional groups, which must belong to the OWL class knora-admin:UserGroup . There is one built-in knora-admin:SystemUser , which is the creator of link values created automatically for resource references in standoff markup (see StandoffLinkTag ). Permissions Each resource or value can grant certain permissions to specified user groups. These permissions are represented as the object of the predicate kb:hasPermissions , which is required on every kb:Resource and on the current version of every kb:Value . The permissions attached to the current version of a value also apply to previous versions of the value. Value versions other than the current one do not have this predicate. The following permissions can be granted: Restricted view permission (RV) Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) Allows an unrestricted view of the object. Having view permission on a resource only affects the user's ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) Allows the item to be marked as deleted. Change rights permission (CR) Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user's permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. To view a link between resources, a user needs permission to view the source and target resources. He also needs permission to view the LinkValue representing the link, unless the link property is hasStandoffLinkTo (see StandoffLinkTag ). The format of the object of kb:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar ( | ). For example, if an object grants view permission to unknown and known users, and modify permission to project members, the resulting permission literal would be: V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember Consistency Checking Knora tries to enforce repository consistency by checking constraints that are specified in the Knora base ontology and in user-created ontologies. Three types of consistency rules are enforced: Cardinalities in OWL class definitions must be satisfied. Constraints on the types of the subjects and objects of OWL object properties must be satisfied. A datatype property may not have an empty string as an object. OWL Cardinalities As noted in Resources , each subclass of Resource must use OWL cardinality restrictions to specify the properties it can have. More specifically, a resource is allowed to have a property that is a subproperty of kb:hasValue or kb:hasLinkTo only if the resource's class has some cardinality for that property. Similarly, a value is allowed to have a subproperty of kb:valueHas only if the value's class has some cardinality for that property. Knora supports, and attempts to enforce, the following cardinality constraints: owl:cardinality 1 : Exactly One 1 - A resource of this class must have exactly one instance of the specified property. owl:minCardinality 1 : At Least One 1-n - A resource of this class must have at least one instance of the specified property. owl:maxCardinality 1 : Zero Or One 0-1 - A resource of this class must have either zero or one instance of the specified property. owl:minCardinality 0 : Unbounded 0-n - A resource of this class may have zero or more instances of the specified property. Knora requires cardinalities to be defined using blank nodes, as in the following example from knora-base : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . The cardinality of a link property must be the same as the cardinality of the corresponding link value property. Each owl:Restriction may have the predicate salsah-gui:guiOrder to indicate the order in which properties should be displayed in a GUI (see The SALSAH GUI Ontology ). A resource class inherits cardinalities from its superclasses. This follows from the rules of RDFS inference. Also, in Knora, cardinalities in the subclass can override cardinalities that would otherwise be inherited from the superclass. Specifically, if a superclass has a cardinality on a property P, and a subclass has a cardinality on a subproperty of P, the subclass's cardinality overrides the superclass's cardinality. In the example above, hasStillImageFileValue is a subproperty of hasFileValue . Therefore, the cardinality on hasStillImageFileValue overrides (i.e. replaces) the one on hasFileValue . Note that, unlike cardinalities, predicates of properties are not inherited. If :foo rdfs:subPropertyOf :bar , this does not mean that :foo inherits anything from :bar . Any predicates of :foo that are also needed by :bar must be defined explicitly on :bar . This design decision was made because property predicate inheritance is not provided by RDFS inference, and would make it more difficult to check the correctness of ontologies, while providing little practical benefit. For more information about OWL cardinalities, see the OWL 2 Primer . Constraints on the Types of Property Subjects and Objects When a user-created ontology defines a property, it must indicate the types that are allowed as objects (and, if possible, as subjects) of the property. This is done using the following Knora-specific properties: subjectClassConstraint : Specifies the class that subjects of the property must belong to. This constraint is recommended but not required. Knora will attempt to enforce this constraint. objectClassConstraint : If the property is an object property, specifies the class that objects of the property must belong to. Every subproperty of kb:hasValue or a kb:hasLinkTo (i.e. every property of a resource that points to a kb:Value or to another resource) is required to have this constraint, because Knora relies on it to know what type of object to expect for the property. Knora will attempt to enforce this constraint. objectDatatypeConstraint : If the property is a datatype property, specifies the type of literals that can be objects of the property. Knora will not attempt to enforce this constraint, but it is useful for documentation purposes. Note that it is possible for a subproperty to have a more restrictive contraint than its base property, by specifing a subject or object class that is a subclass of the one specified in the base property. However, it is not possible for the subproperty to make the base property's constraint less restrictive. See also Why doesn't DSP-API use rdfs:domain and rdfs:range for consistency checking? Consistency Constraint Example A user-created ontology could define consistency constraints as in this simplified example: :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ] . :hasTitle rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . :hasAuthor rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . Summary of Restrictions on User-Created Ontologies An ontology can refer to a Knora ontology in another project only if the other ontology is built-in or shared (see Shared Ontologies ). Restrictions on Classes Each class must be a subclass of either kb:Resource or kb:StandoffTag , but not both (note that this forbids user-created subclasses of kb:Value ). All the cardinalities that a class defines directly (i.e. does not inherit from kb:Resource ) must be on properties that are defined in the triplestore. Within the cardinalities of a class, there must be a link value property for each link property and vice versa. The cardinality of a link property must be the same as the cardinality of the corresponding link value property. A cardinality on a property with a boolean value must be owl:cardinality 1 or owl:maxCardinality 1 . Each class must be a subclass of all the classes that are subject class constraints of the properties in its cardinalities. If it's a resource class, all its directly defined cardinalities must be on Knora resource properties (subproperties of kb:hasValue or kb:hasLinkTo ), and all its base classes with Knora IRIs must also be resource classes. A cardinality on kb:resourceProperty or kb:hasValue is forbidden. It must also have an rdfs:label . If it's a standoff class, none of its cardinalities may be on Knora resource properties, and all its base classes with Knora IRIs must also be standoff classes. A class cannot have a cardinality on property P as well as a cardinality on a subproperty of P. Restrictions on properties The property's subject class constraint, if provided, must be a subclass of kb:Resource or kb:StandoffTag , and must be a subclass of the subject class constraints of all its base properties. Its object class constraint, if provided, must be a subclass of the object class constraints of all its base properties. If the property is a Knora resource property, it must have an object class constraint and an rdfs:label . It can't be a subproperty of both kb:hasValue and kb:hasLinkTo . It can't be a subproperty of kb:hasFileValue . Each of its base properties that has a Knora IRI must also be a Knora resource property. Standardisation The DaSCH intends to coordinate the standardisation of generally useful entities proposed in user-created ontologies. We envisage a process in which two or more projects would initiate the process by starting a public discussion on proposed entities to be shared. Once a consensus was reached, the DaSCH would publish these entities in a Shared Ontology ). Knora Ontology Versions The Knora base ontology has the property kb:ontologyVersion , whose object is a string that indicates the deployed version of all the Knora built-in ontologies. This allows the repository update program to determine which repository updates are needed when Knora is upgraded.","title":"The Knora Base Ontology"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#the-knora-base-ontology","text":"","title":"The Knora Base Ontology"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#overview","text":"The Knora base ontology is the main built-in Knora ontology. Each project that uses DSP-API must describe its data model by creating ontologies that extend this ontology. The Knora base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In the DSP-API documentation in general, it is identified by the prefix knora-base , but for brevity, in this document, we use kb or omit the prefix entirely.","title":"Overview"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#the-knora-data-model","text":"The Knora data model is based on the observation that, in the humanities, a value or literal is often itself structured and can be highly complex. Moreover, a value may have its own metadata, such as its creation date, information about permissions, and so on. Therefore, the Knora base ontology describes structured value types that can store this type of metadata. In the diagram below, a book ( ex:book2 ) has a title (identified by the predicate ex:title ) and a publication date ( ex:pubdate ), each of which has some metadata.","title":"The Knora Data Model"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#projects","text":"In Knora, each item of data belongs to some particular project. Each project using Knora must define a kb:knoraProject , which has these properties (cardinalities are indicated in parentheses after each property name): projectShortname (1): A short name that can be used to identify the project in configuration files and the like. projectLongname (0-1): The full name of the project. projectShortcode (1): A hexadecimal code that uniquely identifies the project. These codes are assigned to projects by the DaSCH . projectDescription (1-n): A description of the project. belongsToInstitution (0-1): The kb:Institution that the project belongs to. Ontologies and resources are associated with a project by means of the kb:attachedToProject property, as described in Ontologies and Properties of Resource ). Users are associated with a project by means of the kb:isInProject property, as described in Users and Groups .","title":"Projects"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#ontologies","text":"Each user-created ontology must be defined as an owl:Ontology with the properties rdfs:label and kb:attachedToProject . Since DSP-API v20 kb:lastModificationDate property is also required.","title":"Ontologies"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#resources","text":"All the content produced by a project (e.g. digitised primary source materials or research data) must be stored in objects that belong to subclasses of kb:Resource , so that Knora can query and update that content. Each project using the Knora base ontology must define its own OWL classes, derived from kb:Resource , to represent the types of data it deals with. A subclass of kb:Resource may additionally be a subclass of any other class, e.g. an industry-standard class such as foaf:Person ; this can facilitate searches across projects. Resources have properties that point to different parts of the content they contain. For example, a resource representing a book could have a property called hasAuthor , pointing to the author of the book. There are two possible kinds of content in a Knora resource: Knora values (see Values ) or links to other resources (see Links Between Resources ). Properties that point to Knora values must be subproperties of kb:hasValue , and properties that point to other resources must be subproperties of kb:hasLinkTo . Either of these two types of properties may also be a subproperty of any other property, e.g. an industry-standard property such as foaf:name ; this can facilitate searches across projects. Each property definition must specify the types that its subjects and objects must belong to (see Constraints on the Types of Property Subjects and Objects for details). Each user-created resource class definition must use OWL cardinality restrictions to specify the properties that resources of that class can have (see OWL Cardinalities for details). Resources are not versioned; only their values are versioned (see Values ). Every resource is required to have an rdfs:label . The object of this property is an xsd:string , rather than a Knora value; hence it is not versioned. A user who has modify permission on a resource (see Authorisation ) can change its label. A resource can be marked as deleted; Knora does this by adding the predicate kb:isDeleted true to the resource. An optional kb:deleteComment may be added to explain why the resource has been marked as deleted. Deleted resources are normally hidden. They cannot be undeleted, because even though resources are not versioned, it is necessary to be able to find out when a resource was deleted. If desired, a new resource can be created by copying data from a deleted resource.","title":"Resources"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#properties-of-resource","text":"creationDate (1): The time when the resource was created. attachedToUser (1): The user who owns the resource. attachedToProject (1): The project that the resource is part of. lastModificationDate (0-1): A timestamp indicating when the resource (or one of its values) was last modified. seqnum (0-1): The sequence number of the resource, if it is part of an ordered group of resources, such as the pages in a book. isDeleted (1): Indicates whether the resource has been deleted. deleteDate (0-1): If the resource has been deleted, indicates when it was deleted. deleteComment (0-1): If the resource has been deleted, indicates why it was deleted. Resources can have properties that point to other resources; see Links Between Resources . A resource grants permissions to groups of users; see Authorisation .","title":"Properties of Resource"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#representations","text":"It is not practical to store all data in RDF. In particular, RDF is not a good storage medium for binary data such as images. Therefore, Knora stores such data outside the triplestore, in ordinary files. A resource can have metadata about a file attached to it. The technical term for such a resource in Knora is a Representation . For each file, there is a kb:FileValue in the triplestore containing metadata about the file (see FileValue ). Knora uses Sipi to store files. The Knora APIs provide ways to create file values using Knora and Sipi. A resource that has a file value must belong to one of the subclasses of kb:Representation . Its subclasses include: StillImageRepresentation : A representation containing a still image file. MovingImageRepresentation : A representation containing a video file. AudioRepresentation : A representation containing an audio file. DDDrepresentation : A representation containing a 3D image file. TextRepresentation : A representation containing a formatted text file, such as an XML file. DocumentRepresentation : A representation containing a document (such as a PDF file) that is not a text file. ArchiveRepresentation : A representation containing an archive file (such as a zip archive). These classes can be used directly in data, but it is often better to make subclasses of them, to include metadata about the files being stored. The base class of all these classes is Representation , which is not intended to be used directly. It has this property, which its subclasses override: hasFileValue (1): Points to a file value. There are two ways for a project to design classes for representations. The simpler way is to create a resource class that represents a thing in the world (such as ex:Painting ) and also belongs to a subclass of Representation . This is adequate if the class can have only one type of file attached to it. For example, if paintings are represented only by still images, ex:Painting could be a subclass of StillImageRepresentation . This is the only approach supported in DSP-API v1. The more flexible approach, which is supported by DSP-API v2, is for each ex:Painting to link (using kb:hasRepresentation or a subproperty) to other resources containing files that represent the painting. Each of these other resources can extend a different subclass of Representation . For example, a painting could have a StillImageRepresentation as well as a DDDrepresentation .","title":"Representations"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#standard-resource-classes","text":"In general, each project using Knora must define its own subclasses of kb:Resource . However, the Knora base ontology provides some standard subclasses of kb:Resource , which are intended to be used by any project: Region : Represents a region of a Representation (see Representations ). Annotation : Represents an annotation of a resource. The hasComment property points to the text of the annotation, represented as a kb:TextValue . LinkObj : Represents a link that connects two or more resources. A LinkObj has a hasLinkTo property pointing to each resource that it connects, as well as a hasLinkToValue property pointing to a reification of each of these direct links ( see Links Between Resources ). A LinkObj is more complex (and hence less convenient and readable) than a simple direct link, but it has the advantage that it can be annotated using an Annotation . For improved readability, a project can make its own subclasses of LinkObj with specific meanings.","title":"Standard Resource Classes"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#values","text":"The Knora base ontology defines a set of OWL classes that are derived from kb:Value and represent different types of structured values found in humanities data. This set of classes may not be extended by user-created ontologies. A value is always part of one particular resource, which points to it using some property derived from hasValue . For example, a user-created ontology could specify a Book class with a property hasSummary (derived from hasValue ), and that property could have a knora-base:objectClassConstraint of TextValue . This would mean that the summary of each book is represented as a TextValue . Knora values are versioned. Existing values are not modified. Instead, a new version of an existing value is created. The new version is linked to the old version via the previousValue property. Since each value version has a different IRI, there is no IRI that can be used to cite the value, such that it will always refer to the latest version of the value. Therefore, the latest version of each value has a separate UUID, as the object of the property valueHasUUID . When a new version of the value is created, this UUID is moved to the new version. This makes it possible to cite the latest version of a value by searching for the UUID. \"Deleting\" a value means marking it with kb:isDeleted . An optional kb:deleteComment may be added to explain why the value has been marked as deleted. Deleted values are normally hidden. Most types of values are marked as deleted without creating a new version of the value. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. To simplify the enforcement of ontology constraints, and for consistency with resource updates, no new versions of a deleted value can be made; it is not possible to undelete. Instead, if desired, a new value can be created by copying data from a deleted value.","title":"Values"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#properties-of-value","text":"valueCreationDate (1): The date and time when the value was created. attachedToUser (1): The user who owns the value. valueHasString (1): A human-readable string representation of the value's contents, which is available to Knora's full-text search index. valueHasOrder (0-1): A resource may have several properties of the same type with different values (which will be of the same class), and it may be necessary to indicate an order in which these values occur. For example, a book may have several authors which should appear in a defined order. Hence, valueHasOrder , when present, points to an integer literal indicating the order of a given value relative to the other values of the same property. These integers will not necessarily start at any particular number, and will not necessarily be consecutive. previousValue (0-1): The previous version of the value. valueHasUUID (0-1): The UUID that refers to all versions of the value. Only the latest version of the value has this property. isDeleted (1): Indicates whether the value has been deleted. deleteDate (0-1): If the value has been deleted, indicates when it was deleted. deleteComment (0-1): If the value has been deleted, indicates why it was deleted. Each Knora value can grant permissions (see Authorisation ).","title":"Properties of Value"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#subclasses-of-value","text":"","title":"Subclasses of Value"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#textvalue","text":"Represents text, possibly including markup. The text is the object of the valueHasString property. A line break is represented as a Unicode line feed character ( U+000A ). The non-printing Unicode character INFORMATION SEPARATOR TWO (U+001E) can be used to separate words that are separated only by standoff markup (see below), so they are recognised as separate in a full-text search index. Markup is stored using this property: valueHasStandoff (0-n): Points to a standoff markup tag. See Text with Standoff Markup . valueHasMapping (0-1): Points to the mapping used to create the standoff markup and to convert it back to the original XML. See Mapping to Create Standoff From XML . A text value can have a specified language: valueHasLanguage (0-1): An ISO 639-1 code as string specifying the language of the text.","title":"TextValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#datevalue","text":"Humanities data includes many different types of dates. In Knora, a date has a specified calendar, and is always represented as a period with start and end points (which may be equal), each of which has a precision ( DAY , MONTH , or YEAR ). For GREGORIAN and JULIAN calendars, an optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Internally, the start and end points are stored as two Julian Day Numbers. This calendar-independent representation makes it possible to compare and search for dates regardless of the calendar in which they were entered. Properties: valueHasCalendar (1): The name of the calendar in which the date should be displayed. Currently GREGORIAN , JULIAN , and ISLAMIC civil calendars are supported. valueHasStartJDN (1): The Julian Day Number of the start of the period (an xsd:integer ). valueHasStartPrecision (1): The precision of the start of the period. valueHasEndJDN (1): The Julian Day Number of the end of the period (an xsd:integer ). valueHasEndPrecision (1): The precision of the end of the period.","title":"DateValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#timevalue","text":"A Knora time value represents a precise moment in time in the Gregorian calendar. Since nanosecond precision can be included, it is suitable for use as a timestamp. Properties: valueHasTimeStamp (1): An xsd:dateTimeStamp , stored as an xsd:dateTime (because SPARQL does not support xsd:dateTimeStamp ).","title":"TimeValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#intvalue","text":"Represents an integer. Property: valueHasInteger (1): An xsd:integer .","title":"IntValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#colorvalue","text":"valueHasColor (1): A string representing a color. The string encodes a color as hexadecimal RGB values, e.g. \\#FF0000 .","title":"ColorValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#decimalvalue","text":"Represents an arbitrary-precision decimal number. Property: valueHasDecimal (1): An xsd:decimal .","title":"DecimalValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#urivalue","text":"Represents a non-Knora URI. Property: valueHasUri (1): An xsd:anyURI .","title":"UriValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#booleanvalue","text":"Represents a boolean value. Property: valueHasBoolean (1): An xsd:boolean .","title":"BooleanValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#geomvalue","text":"Represents a geometrical object as a JSON string, using normalized coordinates. Property: valueHasGeometry (1): A JSON string.","title":"GeomValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#geonamevalue","text":"Represents a geolocation, using the identifiers found at GeoNames . Property: valueHasGeonameCode (1): The identifier of a geographical feature from GeoNames , represented as an xsd:string .","title":"GeonameValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#intervalvalue","text":"Represents a time interval, with precise start and end times on a timeline, e.g. relative to the beginning of an audio or video file. Properties: valueHasIntervalStart (1): An xsd:decimal representing the start of the interval in seconds. valueHasIntervalEnd (1): An xsd:decimal representing the end of the interval in seconds.","title":"IntervalValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#listvalue","text":"Projects often need to define lists or hierarchies of categories that can be assigned to many different resources. Then, for example, a user interface can provide a drop-down menu to allow the user to assign a category to a resource. The ListValue class provides a way to represent these sorts of data structures. It can represent either a flat list or a tree. A ListValue has this property: valueHasListNode (1): Points to a ListNode . Each ListNode can have the following properties: isRootNode (0-1): Set to true if this is the root node. hasSubListNode (0-n): Points to the node's child nodes, if any. hasRootNode (0-1): Points to the root node of the list (absent if isRootNode is true ). listNodePosition (0-1): An integer indicating the node's position in the list of its siblings (absent if isRootNode is true ). listNodeName (0-1): The node's human-readable name (absent if isRootNode is true ).","title":"ListValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#filevalue","text":"Knora stores certain kinds of data outside the triplestore, in files (see Representations ). Each digital object that is stored outside the triplestore has associated metadata, which is stored in the triplestore in a kb:FileValue . The base class FileValue , which is not intended to be used directly, has these properties: internalFilename (1): The name of the file as stored by Knora. internalMimeType (1): The MIME type of the file as stored by Knora. originalFilename (0-1): The original name of the file when it was uploaded to the DSP-API server. originalMimeType (0-1): The original MIME type of the file when it was uploaded to the Knora API server. isPreview (0-1): A boolean indicating whether the file is a preview, i.e. a small image representing the contents of the file. A preview is always a StillImageFileValue , regardless of the type of the enclosing Representation . The subclasses of FileValue , which are intended to be used directly in data, include: StillImageFileValue : Contains metadata about a still image file. MovingImageFileValue : Contains metadata about a video file. AudioFileValue : Contains metadata about an audio file. DDDFileValue : Contains metadata about a 3D image file. TextFileValue : Contains metadata about a text file. DocumentFileValue : Contains metadata about a document (such as PDF) that is not a text file. ArchiveFileValue : Contains metadata about an archive (such as zio archive). Each of these classes contains properties that are specific to the type of file it describes. For example, still image files have dimensions, video files have frame rates, and so on. FileValue objects are versioned like other values, and the actual files stored by Knora are also versioned. Version 1 of the DSP-API does not provide a way to retrieve a previous version of a file, but this feature will be added in a subsequent version of the API.","title":"FileValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#linkvalue","text":"A LinkValue is an RDF \"reification\" containing metadata about a link between two resources. It is therefore a subclass of rdf:Statement as well as of Value . It has these properties: rdf:subject (1) : The resource that is the source of the link. rdf:predicate (1) : The link property. rdf:object (1) : The resource that is the target of the link. valueHasRefCount (1) : The reference count of the link. This is meaningful when the LinkValue describes resource references in Standoff text markup (see StandoffLinkTag ). Otherwise, the reference count will always be 1 (if the link exists) or 0 (if it has been deleted). For details about how links are created in Knora, see Links Between Resources .","title":"LinkValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#externalresvalue","text":"Represents a resource that is not stored in the RDF triplestore managed by Knora, but instead resides in an external repository managed by some other software. The ExternalResValue contains the information that Knora needs in order to access the resource, assuming that a suitable gateway plugin is installed. extResAccessInfo (1) : The location of the repository containing the external resource (e.g. its URL). extResId (1) : The repository-specific ID of the external resource. extResProvider (1) : The name of the external provider of the resource.","title":"ExternalResValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#links-between-resources","text":"A link between two resources is expressed, first of all, as a triple, in which the subject is the resource that is the source of the link, the predicate is a \"link property\" (a subproperty of kb:hasLinkTo ), and the object is the resource that is the target of the link. It is also useful to store metadata about links. For example, Knora needs to know who owns the link, who has permission to modify it, when it was created, and so on. Such metadata cannot simply describe the link property, because then it would refer to that property in general, not to any particular instance in which that property is used to connect two particular resources. To attach metadata to a specific link in RDF, it is necessary to create an RDF \"reification\". A reification makes statements about a particular triple (subject, predicate, object), in this case the triple that expresses the link between the resources. Knora uses reifications of type kb:LinkValue (described in LinkValue to store metadata about links. For example, suppose a project describes paintings that belong to collections. The project can define an ontology as follows (expressed here in Turtle format, and simplified for the purposes of illustration): @prefix kb <http://www.knora.org/ontology/knora-base#> . @prefix : <http://www.knora.org/ontology/paintings#> . :Painting rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasArtist ; owl:cardinality 1 ] , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollection ; owl:minCardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollectionValue ; owl:minCardinality 1 ] . :Collection rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasCollectionName ; owl:cardinality 1 ] . :hasArtist rdf:type owl:ObjectProperty ; rdfs:label \"Name of artist\" ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasTitle rdf:type owl:ObjectProperty ; rdfs:label \"Title of painting\" kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasCollectionName rdf:type owl:ObjectProperty ; rdfs:label \"Name of collection\" ; kb:subjectClassConstraint :Collection ; kb:objectClassConstraint kb:TextValue . To link the paintings to the collection, we must add a \"link property\" to the ontology. In this case, the link property will point from a painting to the collection it belongs to. Every link property must be a subproperty of kb:hasLinkTo . :isInCollection rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkTo ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint :Collection . We must then add a \"link value property\", which will point from a painting to a kb:LinkValue (described in LinkValue ), which will contain metadata about the link between the property and the collection. In particular, the link value specifies the creator of the link, the date when it was created, and the permissions that determine who can view or modify it. The name of the link value property is constructed using a simple naming convention: the word Value is appended to the name of the link property. In this case, since our link property is called :isInCollection , the link value property must be called :isInCollectionValue . Every link value property must be a subproperty of kb:hasLinkToValue . :isInCollectionValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkToValue ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:LinkValue . Given this ontology, we can create some RDF data describing a painting and a collection: @prefix paintings <http://www.knora.org/ontology/paintings#> . @prefix data <http://www.knora.org/ontology/paintings/data#> . data:dali_4587 rdf:type paintings:Painting ; paintings:hasTitle data:value_A ; paintings:hasArtist data:value_B . data:value_A rdf:type kb:TextValue ; kb:valueHasString \"The Persistence of Memory\" . data:value_B rdf:type kb:TextValue ; kb:valueHasString \"Salvador Dali\" . data:pompidou rdf:type paintings:Collection ; paintings:hasCollectionName data:value_C . data:value_C rdf:type kb:TextValue ; kb:valueHasString \"Centre Pompidou, Paris\" . We can then state that the painting is in the collection: data:dali_4587 paintings:isInCollection data:pompidou ; paintings:isinCollectionValue data:value_D . data:value_D rdf:type kb:LinkValue ; rdf:subject data:dali_4587 ; rdf:predicate paintings:isInCollection ; rdf:object data:pompidou ; kb:valueHasRefCount 1 . This creates a link ( paintings:isInCollection ) between the painting and the collection, along with a reification containing metadata about the link. We can visualise the result as the following graph: Knora allows a user to see a link if the requesting user has permission to see the source and target resources as well as the kb:LinkValue .","title":"Links Between Resources"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#part-whole-relations-between-resources","text":"","title":"Part-Whole-Relations between Resources"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#ispartof","text":"A special case of linked resources are part-of related resources , i.e. a resource consisting of several other resources. In order to create a part-of relation between two resources, the resource that is part of another resource needs to have a property that is either kb:isPartOf or a subproperty thereof. kb:isPartOf itself is a subproperty of kb:hasLinkTo . Same as described above for link properties, a corresponding part-of value property is created automatically. This value property has the same name as the part-of property with Value appended. For example, if in an ontology data a property data:partOf was defined, the corresponding value property would be named data:partOfValue . This newly created property data:partOfValue is defined as a subproperty of kb:isPartOfValue . Part-of relations are recommended for resources of type kb:StillImageRepresentation . In that case, the resource that is part of another resource needs to have a property kb:seqnum or a subproperty thereof, with an integer as value. A client can then use this information to leaf through the parts of the compound resource (p.ex. to leaf through the pages of a book like in this example).","title":"isPartOf"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#issequenceof","text":"Similar to kb:isPartOf for kb:StillImageRepresentations , part-whole-relations can be defined for resources that have a time dimension by using kb:isSequenceOf . You can use it for video or audio resources that are subtypes of kb:MovingImageRepresentation and kb:AudioRepresentation . kb:isSequenceOf is intended to be used in combination with the property kb:hasSequenceBounds which points to a kb:IntervalValue . This defines the start and end point of the subseqence in relation to the entire audio/video resource as an interval . When the properties are used in this combination, a dedicated behavior in the frontend allows to display the sequences alongside the main resource. There is an important difference between kb:isSequenceOf and kb:isPartOf : For kb:isPartOf , each part is a kb:StillImageRepresentation and the whole consists of multiple such parts. In kb:isSequenceOf on the other hand, the whole is one kb:MovingImageRepresentation or kb:AudioRepresentation . The parts only define which sub-sequence of this representation they are.","title":"isSequenceOf"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#text-with-standoff-markup","text":"DSP-API is designed to be able to store text with markup, which can indicate formatting and structure, as well as the complex observations involved in transcribing handwritten manuscripts. One popular way of representing text in the humanities is to encode it in XML using the Text Encoding Initiative ( TEI ) guidelines. In DSP-API, a TEI/XML document can be stored as a file with attached metadata, but this is not recommended, because it does not allow to perform searches across multiple documents. The recommended way to store text with markup in DSP-API is to use the built-in support for \"standoff\" markup, which is stored separately from the text. This has some advantages over embedded markup such as XML. While XML requires markup to have a hierarchical structure, and does not allow overlapping tags, standoff nodes do not have these limitations (see Using Standoff Properties for Marking-up Historical Documents in the Humanities ). A standoff tag can be attached to any substring in the text by giving its start and end positions. Unlike in corpus linguistics, we do not use any tokenisation resulting in a form of predefined segmentation, which would limit the user's ability to freely annotate any ranges in the text. For example, suppose we have the following text: This sentence has overlapping visual attributes. This would require just two standoff tags: (italic, start=5, end=29) and (bold, start=14, end=36) . Moreover, standoff makes it possible to mark up the same text in different, possibly incompatible ways, allowing for different interpretations without making redundant copies of the text. In the Knora base ontology, any text value can have standoff tags. By representing standoff as RDF triples, DSP-API makes markup searchable across multiple text documents in a repository. For example, if a repository contains documents in which references to persons are indicated in standoff, it is straightforward to find all the documents mentioning a particular person. DSP-API's standoff support is intended to make it possible to convert documents with embedded, hierarchical markup, such as TEI/XML, into RDF standoff and back again, with no data loss, thus bringing the benefits of RDF to existing TEI-encoded documents. In the Knora base ontology, a TextValue can have one or more standoff tags. Each standoff tag indicates the start and end positions of a substring in the text that has a particular attribute. The OWL class kb:StandoffTag , which is the base class of all standoff node classes, has these properties: standoffTagHasStart (1): The index of the first character in the text that has the attribute. standoffTagHasEnd (1): The index of the last character in the text that has the attribute, plus 1. standoffTagHasUUID (1): A UUID identifying this instance and those corresponding to it in later versions of the TextValue it belongs to. The UUID is a means to maintain a reference to a particular range of a text also when new versions are made and standoff tag IRIs change. standoffTagHasOriginalXMLID (0-1): The original ID of the XML element that the standoff tag represents, if any. standoffTagHasStartIndex (1): The start index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same start position, they can be nested correctly with this information when transforming them to XML. standoffTagHasEndIndex (1): The end index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same end position, they can be nested correctly with this information when transforming them to XML. standoffTagHasStartParent (0-1): Points to the parent standoff tag. This corresponds to the original nesting of tags in XML. If a standoff tag has no parent, it represents the XML root element. If the original XML element is a CLIX tag, it represents the start of a virtual (non syntactical) hierarchy. standoffTagHasEndParent (0-1): Points to the parent standoff tag if the original XML element is a CLIX tag and represents the end of a virtual (non syntactical) hierarchy. The StandoffTag class is not used directly in RDF data; instead, its subclasses are used. A few subclasses are currently provided in standoff-onto.ttl , and more will be added to support TEI semantics. Projects are able to define their own custom standoff tag classes (direct subclasses of StandoffTag or one of the standoff data type classes or subclasses of one of the standoff classes defined in standoff-onto.ttl ).","title":"Text with Standoff Markup"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#subclasses-of-standofftag","text":"","title":"Subclasses of StandoffTag"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#standoff-data-type-tags","text":"Associates data in some Knora value type with a substring in a text. Standoff data type tags are subclasses of ValueBase classes. StandoffLinkTag Indicates that a substring refers to another kb:Resource . See StandoffLinkTag . StandoffInternalReferenceTag Indicates that a substring refers to another standoff tag in the same text value. See Internal Links in a TextValue . StandoffUriTag Indicates that a substring is associated with a URI, which is stored in the same form that is used for kb:UriValue . See UriValue . StandoffDateTag Indicates that a substring represents a date, which is stored in the same form that is used for kb:DateValue . See DateValue . StandoffColorTag Indicates that a substring represents a color, which is stored in the same form that is used for kb:ColorValue . See ColorValue . StandoffIntegerTag Indicates that a substring represents an integer, which is stored in the same form that is used for kb:IntegerValue . See IntValue . StandoffDecimalTag Indicates that a substring represents a number with fractions, which is stored in the same form that is used for kb:DecimalValue . See DecimalValue . StandoffIntervalTag Indicates that a substring represents an interval, which is stored in the same form that is used for kb:IntervalValue . See IntervalValue . StandoffBooleanTag Indicates that a substring represents a Boolean, which is stored in the same form that is used for kb:BooleanValue . See BooleanValue . StandoffTimeTag Indicates that a substring represents a timestamp, which is stored in the same form that is used for kb:TimeValue . See TimeValue .","title":"Standoff Data Type Tags"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#standofflinktag","text":"A StandoffLinkTag Indicates that a substring is associated with a Knora resource. For example, if a repository contains resources representing persons, a text could be marked up so that each time a person's name is mentioned, a StandoffLinkTag connects the name to the Knora resource describing that person. It has the following property: standoffTagHasLink (1): The IRI of the resource that is referred to. One of the design goals of the Knora base ontology is to make it easy and efficient to find out which resources contain references to a given resource. Direct links are easier and more efficient to query than indirect links. Therefore, when a text value contains a resource reference in its standoff nodes, Knora automatically creates a direct link between the containing resource and the target resource, along with an RDF reification (a kb:LinkValue ) describing the link, as discussed in Links Between Resources . In this case, the link property is always kb:hasStandoffLinkTo , and the link value property (which points to the LinkValue ) is always kb:hasStandoffLinkToValue . DSP-API automatically updates direct links and reifications for standoff resource references when text values are updated. To do this, it keeps track of the number of text values in each resource that contain at least one standoff reference to a given target resource. It stores this number as the reference count of the LinkValue (see LinkValue ) describing the direct link. Each time this number changes, it makes a new version of the LinkValue , with an updated reference count. When the reference count reaches zero, it removes the direct link and makes a new version of the LinkValue , marked with kb:isDeleted . For example, if data:R1 is a resource with a text value in which the resource data:R2 is referenced, the repository could contain the following triples: data : R1 ex : hasComment data : V1 . data : V1 rdf : type kb : TextValue ; kb : valueHasString \"This link is internal.\" ; kb : valueHasStandoff data : SO1 . data : SO1 rdf : type kb : StandoffLinkTag ; kb : standoffTagHasStart: 5 ; kb : standoffTagHasEnd: 9 ; kb : standoffTagHasLink data : R2 . data : R1 kb : hasStandoffLinkTo data : R2 . data : R1 kb : hasStandoffLinkToValue data : LV1 . data : LV1 rdf : type kb : LinkValue ; rdf : subject data : R1 ; rdf : predicate kb : hasStandoffLinkTo ; rdf : object data : R2 ; kb : valueHasRefCount 1 . The result can be visualized like this: Link values created automatically for resource references in standoff are visible to all users, and the creator of these link values is always kb:SystemUser (see Users and Groups ). The DSP-API server allows a user to see a standoff link if the user has permission to see the source and target resources.","title":"StandoffLinkTag"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#internal-links-in-a-textvalue","text":"Internal links in a TextValue can be represented using the data type standoff class StandoffInternalReferenceTag or a subclass of it. It has the following property: standoffTagHasInternalReference (1): Points to a StandoffTag that belongs to the same TextValue . It has an objectClassConstraint of StandoffTag . For links to a kb:Resource , see StandoffLinkTag .","title":"Internal Links in a TextValue"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#mapping-to-create-standoff-from-xml","text":"A mapping allows for the conversion of an XML document to RDF-standoff and back. A mapping defines one-to-one relations between XML elements (with or without a class) and attributes and standoff classes and properties (see XML to Standoff Mapping ). A mapping is represented by a kb:XMLToStandoffMapping which contains one or more kb:MappingElement . A kb:MappingElement maps an XML element (including attributes) to a standoff class and standoff properties. It has the following properties: mappingHasXMLTagname (1): The name of the XML element that is mapped to a standoff class. mappingHasXMLNamespace (1): The XML namespace of the XML element that is mapped to a standoff class. If no namespace is given, noNamespace is used. mappingHasXMLClass (1): The name of the class of the XML element. If it has no class, noClass is used. mappingHasStandoffClass (1): The standoff class the XML element is mapped to. mappingHasXMLAttribute (0-n): Maps XML attributes to standoff properties using MappingXMLAttribute . See below. mappingHasStandoffDataTypeClass (0-1): Indicates the standoff data type class of the standoff class the XML element is mapped to. mappingElementRequiresSeparator (1): Indicates if there should be an invisible word separator inserted after the XML element in the RDF-standoff representation. Once the markup is stripped, text segments that belonged to different elements may be concatenated. A MappingXMLAttribute has the following properties: - mappingHasXMLAttributename : The name of the XML attribute that is mapped to a standoff property. - mappingHasXMLNamespace : The namespace of the XML attribute that is mapped to a standoff property. If no namespace is given, noNamespace is used. - mappingHasStandoffProperty : The standoff property the XML attribute is mapped to. DSP-API includes a standard mapping used by the DSP APP. It has the IRI http://rdfh.ch/standoff/mappings/StandardMapping and defines mappings for a few elements used to write texts with simple markup.","title":"Mapping to Create Standoff From XML"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#standoff-in-digital-editions","text":"DSP-API's standoff is designed to make it possible to convert XML documents to standoff and back. One application for this feature is an editing workflow in which an editor works in an XML editor, and the resulting XML documents are converted to standoff and stored in the DSP, where they can be searched and annotated. If an editor wants to correct text that has been imported from XML into standoff, the text can be exported as XML, edited, and imported again. To preserve annotations on standoff tags across edits, each tag can automatically be given a UUID. In a future version of the Knora base ontology, it may be possible to create annotations that point to UUIDs rather than to IRIs. When a text is exported to XML, the UUIDs can be included in the XML. When the edited XML is imported again, it can be converted to new standoff tags with the same UUIDs. Annotations that applied to standoff tags in the previous version of the text will therefore also apply to equivalent tags in the new version. When text is converted from XML into standoff, tags are also given indexes, which are numbered from 0 within the context of a particular text. This makes it possible to order tags that share the same position, and to preserve the hierarchy of the original XML document. An ordinary, hierarchical XML tag is converted to a standoff tag that has one index, as well as the index of its parent tag, if any. The Knora base ontology also supports non-hierarchical markup such as CLIX , which enables overlapping markup to be represented in XML. When non-hierarchical markup is converted to standoff, both the start position and the end position of the standoff tag have indexes and parent indexes. To support these features, a standoff tag can have these additional properties: - standoffTagHasStartIndex (0-1): The index of the start position. - standoffTagHasEndIndex (0-1): The index of the end position, if this is a non-hierarchical tag. - standoffTagHasStartParent (0-1): The IRI of the tag, if any, that contains the start position. - standoffTagHasEndParent (0-1): The IRI of the tag, if any, that contains the end position, if this is a non-hierarchical tag. - standoffTagHasUUID (0-1): A UUID that can be used to annotate a standoff tag that may be present in different versions of a text, or in different layers of a text (such as a diplomatic transcription and an edited critical text).","title":"Standoff in Digital Editions"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#querying-standoff-in-sparql","text":"A future version of DSP-API may provide an API for querying standoff markup. In the meantime, it is possible to query it directly in SPARQL. For example, here is a SPARQL query (using RDFS inference) that finds all the text values that have a standoff date tag referring to Christmas Eve 2016, contained in a StandoffItalicTag : PREFIX knora-base : <http://www.knora.org/ontology/knora-base#> PREFIX standoff : <http://www.knora.org/ontology/standoff#> select * where { ?standoffTag a knora-base : StandoffDateTag . ?standoffTag knora-base : valueHasStartJDN ?dateStart . ?standoffTag knora-base : valueHasEndJDN ?dateEnd . FILTER ( 2457747 <= ?dateEnd && 2457747 >= ?dateStart ) ?standoffTag knora-base : standoffTagHasStartParent ?parent . ?parent a standoff : StandoffItalicTag . ?textValue knora-base : valueHasStandoff ?standoffTag . ?textValue knora-base : valueHasString ?string . ?standoffTag knora-base : standoffTagHasStart ?startPos . ?standoffTag knora-base : standoffTagHasEnd ?endPos . }","title":"Querying Standoff in SPARQL"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#authorisation","text":"","title":"Authorisation"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#users-and-groups","text":"Each Knora user is represented by an object belonging to the class kb:User , which is a subclass of foaf:Person , and has the following properties: userid (1) : A unique identifier that the user must provide when logging in. password (1) : A cryptographic hash of the user's password. email (0-n) : Email addresses belonging to the user. isInProject (0-n) : Projects that the user is a member of. isInGroup (0-n) : user-created groups that the user is a member of. foaf:familyName (1) : The user's family name. foaf:givenName (1) : The user's given name. Knora's concept of access control is that an object (a resource or value) can grant permissions to groups of users (but not to individual users). There are several built-in groups: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:ProjectMember : When checking a user's permissions on an object, the user is automatically assigned to this group if she is a member of the project that the object belongs to. knora-admin:Creator : When checking a user's permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectAdmin : When checking a user's permissions on an object, the user is automatically assigned to this group if she is an administrator of the project that the object belongs to. knora-admin:SystemAdmin : The group of Knora system administrators. A user-created ontology can define additional groups, which must belong to the OWL class knora-admin:UserGroup . There is one built-in knora-admin:SystemUser , which is the creator of link values created automatically for resource references in standoff markup (see StandoffLinkTag ).","title":"Users and Groups"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#permissions","text":"Each resource or value can grant certain permissions to specified user groups. These permissions are represented as the object of the predicate kb:hasPermissions , which is required on every kb:Resource and on the current version of every kb:Value . The permissions attached to the current version of a value also apply to previous versions of the value. Value versions other than the current one do not have this predicate. The following permissions can be granted: Restricted view permission (RV) Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) Allows an unrestricted view of the object. Having view permission on a resource only affects the user's ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) Allows the item to be marked as deleted. Change rights permission (CR) Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user's permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. To view a link between resources, a user needs permission to view the source and target resources. He also needs permission to view the LinkValue representing the link, unless the link property is hasStandoffLinkTo (see StandoffLinkTag ). The format of the object of kb:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar ( | ). For example, if an object grants view permission to unknown and known users, and modify permission to project members, the resulting permission literal would be: V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember","title":"Permissions"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#consistency-checking","text":"Knora tries to enforce repository consistency by checking constraints that are specified in the Knora base ontology and in user-created ontologies. Three types of consistency rules are enforced: Cardinalities in OWL class definitions must be satisfied. Constraints on the types of the subjects and objects of OWL object properties must be satisfied. A datatype property may not have an empty string as an object.","title":"Consistency Checking"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#owl-cardinalities","text":"As noted in Resources , each subclass of Resource must use OWL cardinality restrictions to specify the properties it can have. More specifically, a resource is allowed to have a property that is a subproperty of kb:hasValue or kb:hasLinkTo only if the resource's class has some cardinality for that property. Similarly, a value is allowed to have a subproperty of kb:valueHas only if the value's class has some cardinality for that property. Knora supports, and attempts to enforce, the following cardinality constraints: owl:cardinality 1 : Exactly One 1 - A resource of this class must have exactly one instance of the specified property. owl:minCardinality 1 : At Least One 1-n - A resource of this class must have at least one instance of the specified property. owl:maxCardinality 1 : Zero Or One 0-1 - A resource of this class must have either zero or one instance of the specified property. owl:minCardinality 0 : Unbounded 0-n - A resource of this class may have zero or more instances of the specified property. Knora requires cardinalities to be defined using blank nodes, as in the following example from knora-base : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . The cardinality of a link property must be the same as the cardinality of the corresponding link value property. Each owl:Restriction may have the predicate salsah-gui:guiOrder to indicate the order in which properties should be displayed in a GUI (see The SALSAH GUI Ontology ). A resource class inherits cardinalities from its superclasses. This follows from the rules of RDFS inference. Also, in Knora, cardinalities in the subclass can override cardinalities that would otherwise be inherited from the superclass. Specifically, if a superclass has a cardinality on a property P, and a subclass has a cardinality on a subproperty of P, the subclass's cardinality overrides the superclass's cardinality. In the example above, hasStillImageFileValue is a subproperty of hasFileValue . Therefore, the cardinality on hasStillImageFileValue overrides (i.e. replaces) the one on hasFileValue . Note that, unlike cardinalities, predicates of properties are not inherited. If :foo rdfs:subPropertyOf :bar , this does not mean that :foo inherits anything from :bar . Any predicates of :foo that are also needed by :bar must be defined explicitly on :bar . This design decision was made because property predicate inheritance is not provided by RDFS inference, and would make it more difficult to check the correctness of ontologies, while providing little practical benefit. For more information about OWL cardinalities, see the OWL 2 Primer .","title":"OWL Cardinalities"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#constraints-on-the-types-of-property-subjects-and-objects","text":"When a user-created ontology defines a property, it must indicate the types that are allowed as objects (and, if possible, as subjects) of the property. This is done using the following Knora-specific properties: subjectClassConstraint : Specifies the class that subjects of the property must belong to. This constraint is recommended but not required. Knora will attempt to enforce this constraint. objectClassConstraint : If the property is an object property, specifies the class that objects of the property must belong to. Every subproperty of kb:hasValue or a kb:hasLinkTo (i.e. every property of a resource that points to a kb:Value or to another resource) is required to have this constraint, because Knora relies on it to know what type of object to expect for the property. Knora will attempt to enforce this constraint. objectDatatypeConstraint : If the property is a datatype property, specifies the type of literals that can be objects of the property. Knora will not attempt to enforce this constraint, but it is useful for documentation purposes. Note that it is possible for a subproperty to have a more restrictive contraint than its base property, by specifing a subject or object class that is a subclass of the one specified in the base property. However, it is not possible for the subproperty to make the base property's constraint less restrictive. See also Why doesn't DSP-API use rdfs:domain and rdfs:range for consistency checking?","title":"Constraints on the Types of Property Subjects and Objects"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#consistency-constraint-example","text":"A user-created ontology could define consistency constraints as in this simplified example: :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ] . :hasTitle rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . :hasAuthor rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue .","title":"Consistency Constraint Example"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#summary-of-restrictions-on-user-created-ontologies","text":"An ontology can refer to a Knora ontology in another project only if the other ontology is built-in or shared (see Shared Ontologies ).","title":"Summary of Restrictions on User-Created Ontologies"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#restrictions-on-classes","text":"Each class must be a subclass of either kb:Resource or kb:StandoffTag , but not both (note that this forbids user-created subclasses of kb:Value ). All the cardinalities that a class defines directly (i.e. does not inherit from kb:Resource ) must be on properties that are defined in the triplestore. Within the cardinalities of a class, there must be a link value property for each link property and vice versa. The cardinality of a link property must be the same as the cardinality of the corresponding link value property. A cardinality on a property with a boolean value must be owl:cardinality 1 or owl:maxCardinality 1 . Each class must be a subclass of all the classes that are subject class constraints of the properties in its cardinalities. If it's a resource class, all its directly defined cardinalities must be on Knora resource properties (subproperties of kb:hasValue or kb:hasLinkTo ), and all its base classes with Knora IRIs must also be resource classes. A cardinality on kb:resourceProperty or kb:hasValue is forbidden. It must also have an rdfs:label . If it's a standoff class, none of its cardinalities may be on Knora resource properties, and all its base classes with Knora IRIs must also be standoff classes. A class cannot have a cardinality on property P as well as a cardinality on a subproperty of P.","title":"Restrictions on Classes"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#restrictions-on-properties","text":"The property's subject class constraint, if provided, must be a subclass of kb:Resource or kb:StandoffTag , and must be a subclass of the subject class constraints of all its base properties. Its object class constraint, if provided, must be a subclass of the object class constraints of all its base properties. If the property is a Knora resource property, it must have an object class constraint and an rdfs:label . It can't be a subproperty of both kb:hasValue and kb:hasLinkTo . It can't be a subproperty of kb:hasFileValue . Each of its base properties that has a Knora IRI must also be a Knora resource property.","title":"Restrictions on properties"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#standardisation","text":"The DaSCH intends to coordinate the standardisation of generally useful entities proposed in user-created ontologies. We envisage a process in which two or more projects would initiate the process by starting a public discussion on proposed entities to be shared. Once a consensus was reached, the DaSCH would publish these entities in a Shared Ontology ).","title":"Standardisation"},{"location":"DSP-API/02-dsp-ontologies/knora-base/#knora-ontology-versions","text":"The Knora base ontology has the property kb:ontologyVersion , whose object is a string that indicates the deployed version of all the Knora built-in ontologies. This allows the repository update program to determine which repository updates are needed when Knora is upgraded.","title":"Knora Ontology Versions"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/","text":"The SALSAH GUI Ontology Overview The SALSAH GUI ontology provides entities that can be used in user-created ontologies to indicate to SALSAH (or to another GUI) how data should be entered and displayed. The SALSAH GUI ontology is identified by the IRI http://www.knora.org/ontology/salsah-gui . In the Knora documentation in general, it is identified by the prefix salsah-gui , but for brevity, we omit the prefix in this document. Properties guiOrder guiOrder can be attached to a cardinality in a resource class, to indicate the order in which properties should be displayed in the GUI. The object is a non-negative integer. For example, a property with guiOrder 0 would be displayed first, followed by a property with guiOrder 1, and so on. guiElement guiElement can be attached to a property definition to indicate which GUI element should be used to enter data for the property. This should be one of the individuals of class Guielement described below. guiAttribute guiAttribute can be attached to a property definition to provide attributes for the GUI element specified in guiElement . The objects of this predicate are written in a DSL with the following syntax: object = attribute name , \"=\" , attribute value ; attribute name = identifier ; identifier = letter , { letter } ; attribute value = integer | decimal | percent | string | iri ; percent = integer , \"%\" ; iri = \"<\" , string , \">\" ; The attributes used with each GUI element are described below under Individuals . guiAttributeDefinition guiAttributeDefinition is used only in the salsah-gui ontology itself, as a predicate attached to instances of Guielement (see Individuals ), to specify the attributes that can be given as objects of guiAttribute when a given Guielement is used. The objects of this predicate are written in a DSL with the following syntax: object = attribute name , [ \"(required)\" ], \":\" , attribute type , [ enumerated values ] ; enumerated values = \"(\" , enumerated value , { \"|\" , enumerated value } \")\" ; attribute name = identifier ; attribute type = \"integer\" | \"decimal\" | \"percent\" | \"string\" | \"iri\" ; enumerated value = identifier ; identifier = letter , { letter } ; Enumerated values are allowed only if attribute type is string . If enumerated values are provided for an attribute, the attribute value given via guiAttribute must be one of the enumerated values. Classes Guielement The instances of class Guielement are individuals representing GUI elements for data entry. Individuals Colorpicker Colorpicker is a GUI element for selecting a color. A property definition that uses this element may also contain a guiAttribute predicate whose object is a string in the form \"ncolors=N\" , where N is an integer specifying the number of colors to display. Date Date is a GUI element for selecting a date. Geometry Geometry is a GUI element for selecting the geometry of a two-dimensional region. Geonames Geonames is a GUI element for selecting a Geonames identifier. Interval Interval is a GUI element for selecting a time interval in an audio or video recording. List List is a GUI element for selecting an item in a hierarchical list (see ListValue ). A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list. Pulldown Pulldown is a GUI element for selecting an item in a flat list (see ListValue ) using a pull-down menu. A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list. Radio Radio is a GUI element for selecting an item in a flat list (see ListValue ) using radio buttons. A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list. Richtext Richtext is a GUI element for editing multi-line formatted text. Searchbox Searchbox is a GUI element for searching for a resource by matching text in its rdfs:label . For DSP-API v1, a property definition that uses this element may also contain this guiAttribute predicate: \"numprops=N\" , where N is an integer specifying the number of describing properties to be returned for each found resource. For DSP-API v2, the guiAttribute has no effect. SimpleText SimpleText is a GUI element for editing a single line of unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: \"size=N\" , where N is an integer specifying the size of the text field. \"maxlength=N\" , where N is an integer specifying the maximum length of the string to be input. Slider Slider is a GUI element for choosing numerical values using a slider. A property definition that uses this element must also contain a guiAttribute predicate with both of the following objects: \"min=N\" , where N is an integer specifying the minimum value of the input. \"max=N\" , where N is an integer specifying the maximum value of the input. Spinbox Spinbox is a GUI element for choosing numerical values using a spinbox. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: \"min=N\" , where N is an integer specifying the minimum value of the input. \"max=N\" , where N is an integer specifying the maximum value of the input. Textarea Textarea is a GUI element for editing multi-line unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or more of the following objects: \"width=N\" , where N is a percentage of the window width (an integer followed by % ). \"cols=N\" , where N is an integer representing the number of colums in the text entry box. \"rows=N\" , where N is an integer specifying the height of the text entry box in rows. \"wrap=W\" , where W is soft or hard (see wrap ). Checkbox Checkbox is a GUI element for choosing a boolean value using a checkbox. Fileupload Fileupload is a GUI element for uploading a file.","title":"The SALSAH GUI Ontology"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#the-salsah-gui-ontology","text":"","title":"The SALSAH GUI Ontology"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#overview","text":"The SALSAH GUI ontology provides entities that can be used in user-created ontologies to indicate to SALSAH (or to another GUI) how data should be entered and displayed. The SALSAH GUI ontology is identified by the IRI http://www.knora.org/ontology/salsah-gui . In the Knora documentation in general, it is identified by the prefix salsah-gui , but for brevity, we omit the prefix in this document.","title":"Overview"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#properties","text":"","title":"Properties"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#guiorder","text":"guiOrder can be attached to a cardinality in a resource class, to indicate the order in which properties should be displayed in the GUI. The object is a non-negative integer. For example, a property with guiOrder 0 would be displayed first, followed by a property with guiOrder 1, and so on.","title":"guiOrder"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#guielement","text":"guiElement can be attached to a property definition to indicate which GUI element should be used to enter data for the property. This should be one of the individuals of class Guielement described below.","title":"guiElement"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#guiattribute","text":"guiAttribute can be attached to a property definition to provide attributes for the GUI element specified in guiElement . The objects of this predicate are written in a DSL with the following syntax: object = attribute name , \"=\" , attribute value ; attribute name = identifier ; identifier = letter , { letter } ; attribute value = integer | decimal | percent | string | iri ; percent = integer , \"%\" ; iri = \"<\" , string , \">\" ; The attributes used with each GUI element are described below under Individuals .","title":"guiAttribute"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#guiattributedefinition","text":"guiAttributeDefinition is used only in the salsah-gui ontology itself, as a predicate attached to instances of Guielement (see Individuals ), to specify the attributes that can be given as objects of guiAttribute when a given Guielement is used. The objects of this predicate are written in a DSL with the following syntax: object = attribute name , [ \"(required)\" ], \":\" , attribute type , [ enumerated values ] ; enumerated values = \"(\" , enumerated value , { \"|\" , enumerated value } \")\" ; attribute name = identifier ; attribute type = \"integer\" | \"decimal\" | \"percent\" | \"string\" | \"iri\" ; enumerated value = identifier ; identifier = letter , { letter } ; Enumerated values are allowed only if attribute type is string . If enumerated values are provided for an attribute, the attribute value given via guiAttribute must be one of the enumerated values.","title":"guiAttributeDefinition"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#classes","text":"","title":"Classes"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#guielement_1","text":"The instances of class Guielement are individuals representing GUI elements for data entry.","title":"Guielement"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#individuals","text":"","title":"Individuals"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#colorpicker","text":"Colorpicker is a GUI element for selecting a color. A property definition that uses this element may also contain a guiAttribute predicate whose object is a string in the form \"ncolors=N\" , where N is an integer specifying the number of colors to display.","title":"Colorpicker"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#date","text":"Date is a GUI element for selecting a date.","title":"Date"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#geometry","text":"Geometry is a GUI element for selecting the geometry of a two-dimensional region.","title":"Geometry"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#geonames","text":"Geonames is a GUI element for selecting a Geonames identifier.","title":"Geonames"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#interval","text":"Interval is a GUI element for selecting a time interval in an audio or video recording.","title":"Interval"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#list","text":"List is a GUI element for selecting an item in a hierarchical list (see ListValue ). A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list.","title":"List"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#pulldown","text":"Pulldown is a GUI element for selecting an item in a flat list (see ListValue ) using a pull-down menu. A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list.","title":"Pulldown"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#radio","text":"Radio is a GUI element for selecting an item in a flat list (see ListValue ) using radio buttons. A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list.","title":"Radio"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#richtext","text":"Richtext is a GUI element for editing multi-line formatted text.","title":"Richtext"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#searchbox","text":"Searchbox is a GUI element for searching for a resource by matching text in its rdfs:label . For DSP-API v1, a property definition that uses this element may also contain this guiAttribute predicate: \"numprops=N\" , where N is an integer specifying the number of describing properties to be returned for each found resource. For DSP-API v2, the guiAttribute has no effect.","title":"Searchbox"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#simpletext","text":"SimpleText is a GUI element for editing a single line of unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: \"size=N\" , where N is an integer specifying the size of the text field. \"maxlength=N\" , where N is an integer specifying the maximum length of the string to be input.","title":"SimpleText"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#slider","text":"Slider is a GUI element for choosing numerical values using a slider. A property definition that uses this element must also contain a guiAttribute predicate with both of the following objects: \"min=N\" , where N is an integer specifying the minimum value of the input. \"max=N\" , where N is an integer specifying the maximum value of the input.","title":"Slider"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#spinbox","text":"Spinbox is a GUI element for choosing numerical values using a spinbox. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: \"min=N\" , where N is an integer specifying the minimum value of the input. \"max=N\" , where N is an integer specifying the maximum value of the input.","title":"Spinbox"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#textarea","text":"Textarea is a GUI element for editing multi-line unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or more of the following objects: \"width=N\" , where N is a percentage of the window width (an integer followed by % ). \"cols=N\" , where N is an integer representing the number of colums in the text entry box. \"rows=N\" , where N is an integer specifying the height of the text entry box in rows. \"wrap=W\" , where W is soft or hard (see wrap ).","title":"Textarea"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#checkbox","text":"Checkbox is a GUI element for choosing a boolean value using a checkbox.","title":"Checkbox"},{"location":"DSP-API/02-dsp-ontologies/salsah-gui/#fileupload","text":"Fileupload is a GUI element for uploading a file.","title":"Fileupload"},{"location":"DSP-API/03-endpoints/api-admin/groups/","text":"Groups Endpoint Endpoint Overview Group Operations: GET: /admin/groups : return all groups GET: /admin/groups/<groupIri> : return single group identified by [IRI] POST: /admin/groups : create a new group PUT: /admin/groups/<groupIri> : update groups's basic information PUT: /admin/groups/<groupIri>/status : update group's status DELETE: /admin/groups/<groupIri> : delete group (set status to false) Member Operations: GET: /admin/groups/<groupIri>/members : return all group members Group Operations Create Group Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission Required information: name (unique inside project), project IRI Optional information: group descriptions Returns information about the newly created group TypeScript Docs: groupFormats - CreateGroupApiRequestV1 POST: /admin/groups BODY: { \"name\" : \"NewGroup\" , \"descriptions\" : [ { \"value\" : \"NewGroupDescription\" , \"language\" : \"en\" }, { \"value\" : \"NeueGruppenBeschreibung\" , \"language\" : \"de\" } ], \"project\" : \"http://rdfh.ch/projects/00FF\" , \"status\" : true , \"selfjoin\" : false } Additionally, each group can have an optional custom IRI (of @ref: Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/groups/00FF/a95UWs71KUklnFOe1rcw1w\" , \"name\" : \"GroupWithCustomIRI\" , \"descriptions\" : [{ \"value\" : \"A new group with a custom IRI\" , \"language\" : \"en\" }], \"project\" : \"http://rdfh.ch/projects/00FF\" , \"status\" : true , \"selfjoin\" : false } Update group information Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) Changeable information: name , descriptions , selfjoin TypeScript Docs: groupFormats - ChangeGroupApiRequestADM PUT: /admin/groups/<groupIri> BODY: { \"name\" : \"UpdatedGroupName\" , \"descriptions\" : [{ \"value\" : \"UpdatedGroupDescription\" , \"language\" : \"en\" }], \"selfjoin\" : false } Change Group Status: Required permission: SystemAdmin / hasProjectAllAdminPermission Changeable information: status Remark: Deleting a group, removes all members from the group. PUT: /admin/groups/<groupIri>/status BODY: { \"status\" : false } Delete Group: Required permission: SystemAdmin / hasProjectAllAdminPermission Remark: The same as changing the groups status to false . To un-delete, set status to true . DELETE: /admin/groups/<groupIri> Example Group Information stored in admin named graph: : <http://rdfh.ch/groups/[shortcode]/[UUID]> rdf:type knora-admin:UserGroup ; knora-admin:groupName \"Name of the group\" ; knora-admin:groupDescriptions \"A description of the group\"@en ; knora-admin:belongsToProject <http://rdfh.ch/projects/[UUID]> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean . Member Operations Get Group Members Returns all group members Required permission: SystemAdmin / ProjectAdmin GET: /admin/groups/<groupIri>/members","title":"Groups Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/groups/#groups-endpoint","text":"","title":"Groups Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/groups/#endpoint-overview","text":"Group Operations: GET: /admin/groups : return all groups GET: /admin/groups/<groupIri> : return single group identified by [IRI] POST: /admin/groups : create a new group PUT: /admin/groups/<groupIri> : update groups's basic information PUT: /admin/groups/<groupIri>/status : update group's status DELETE: /admin/groups/<groupIri> : delete group (set status to false) Member Operations: GET: /admin/groups/<groupIri>/members : return all group members","title":"Endpoint Overview"},{"location":"DSP-API/03-endpoints/api-admin/groups/#group-operations","text":"","title":"Group Operations"},{"location":"DSP-API/03-endpoints/api-admin/groups/#create-group","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission Required information: name (unique inside project), project IRI Optional information: group descriptions Returns information about the newly created group TypeScript Docs: groupFormats - CreateGroupApiRequestV1 POST: /admin/groups BODY: { \"name\" : \"NewGroup\" , \"descriptions\" : [ { \"value\" : \"NewGroupDescription\" , \"language\" : \"en\" }, { \"value\" : \"NeueGruppenBeschreibung\" , \"language\" : \"de\" } ], \"project\" : \"http://rdfh.ch/projects/00FF\" , \"status\" : true , \"selfjoin\" : false } Additionally, each group can have an optional custom IRI (of @ref: Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/groups/00FF/a95UWs71KUklnFOe1rcw1w\" , \"name\" : \"GroupWithCustomIRI\" , \"descriptions\" : [{ \"value\" : \"A new group with a custom IRI\" , \"language\" : \"en\" }], \"project\" : \"http://rdfh.ch/projects/00FF\" , \"status\" : true , \"selfjoin\" : false }","title":"Create Group"},{"location":"DSP-API/03-endpoints/api-admin/groups/#update-group-information","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) Changeable information: name , descriptions , selfjoin TypeScript Docs: groupFormats - ChangeGroupApiRequestADM PUT: /admin/groups/<groupIri> BODY: { \"name\" : \"UpdatedGroupName\" , \"descriptions\" : [{ \"value\" : \"UpdatedGroupDescription\" , \"language\" : \"en\" }], \"selfjoin\" : false }","title":"Update group information"},{"location":"DSP-API/03-endpoints/api-admin/groups/#change-group-status","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission Changeable information: status Remark: Deleting a group, removes all members from the group. PUT: /admin/groups/<groupIri>/status BODY: { \"status\" : false }","title":"Change Group Status:"},{"location":"DSP-API/03-endpoints/api-admin/groups/#delete-group","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission Remark: The same as changing the groups status to false . To un-delete, set status to true . DELETE: /admin/groups/<groupIri> Example Group Information stored in admin named graph: : <http://rdfh.ch/groups/[shortcode]/[UUID]> rdf:type knora-admin:UserGroup ; knora-admin:groupName \"Name of the group\" ; knora-admin:groupDescriptions \"A description of the group\"@en ; knora-admin:belongsToProject <http://rdfh.ch/projects/[UUID]> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean .","title":"Delete Group:"},{"location":"DSP-API/03-endpoints/api-admin/groups/#member-operations","text":"","title":"Member Operations"},{"location":"DSP-API/03-endpoints/api-admin/groups/#get-group-members","text":"Returns all group members Required permission: SystemAdmin / ProjectAdmin GET: /admin/groups/<groupIri>/members","title":"Get Group Members"},{"location":"DSP-API/03-endpoints/api-admin/introduction/","text":"Introduction: Using the Admin API The DSP Admin API makes it possible to administrate projects, users, user groups, permissions, and hierarchical lists. RESTful API The Knora Admin API is a RESTful API that allows for reading and adding of administrative resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The various HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ). Knora IRIs in the Admin API Every resource that is created or hosted by Knora is identified by a unique ID called an Internationalized Resource Identifier ( IRI ). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike the DSP-API v2, the admin API uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ). Admin Path Segment Every request to Admin API includes admin as a path segment, e.g. http://host/admin/users/iri/http%3A%2F%2Frdfh.ch%2Fusers%2Froot . Admin API Response Format If an API request is handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON. Placeholder host in sample URLs Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on. Authentication For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. Credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). Admin API Endpoints An overview over all admin API endpoints can be found here .","title":"Introduction"},{"location":"DSP-API/03-endpoints/api-admin/introduction/#introduction-using-the-admin-api","text":"The DSP Admin API makes it possible to administrate projects, users, user groups, permissions, and hierarchical lists.","title":"Introduction: Using the Admin API"},{"location":"DSP-API/03-endpoints/api-admin/introduction/#restful-api","text":"The Knora Admin API is a RESTful API that allows for reading and adding of administrative resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The various HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ).","title":"RESTful API"},{"location":"DSP-API/03-endpoints/api-admin/introduction/#knora-iris-in-the-admin-api","text":"Every resource that is created or hosted by Knora is identified by a unique ID called an Internationalized Resource Identifier ( IRI ). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike the DSP-API v2, the admin API uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ).","title":"Knora IRIs in the Admin API"},{"location":"DSP-API/03-endpoints/api-admin/introduction/#admin-path-segment","text":"Every request to Admin API includes admin as a path segment, e.g. http://host/admin/users/iri/http%3A%2F%2Frdfh.ch%2Fusers%2Froot .","title":"Admin Path Segment"},{"location":"DSP-API/03-endpoints/api-admin/introduction/#admin-api-response-format","text":"If an API request is handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON.","title":"Admin API Response Format"},{"location":"DSP-API/03-endpoints/api-admin/introduction/#placeholder-host-in-sample-urls","text":"Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on.","title":"Placeholder host in sample URLs"},{"location":"DSP-API/03-endpoints/api-admin/introduction/#authentication","text":"For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. Credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ).","title":"Authentication"},{"location":"DSP-API/03-endpoints/api-admin/introduction/#admin-api-endpoints","text":"An overview over all admin API endpoints can be found here .","title":"Admin API Endpoints"},{"location":"DSP-API/03-endpoints/api-admin/lists/","text":"Lists Endpoint Endpoint Overview List Item Operations: GET: /admin/lists[?projectIri=<projectIri>] : return all lists optionally filtered by project GET: /admin/lists/<listItemIri> : return complete list with all children if IRI of the list (i.e. root node) is given If IRI of the child node is given, return the node with its immediate children GET: /admin/lists/infos/<listIri> : return list information (without children) GET: /admin/lists/nodes/<nodeIri> : return list node information (without children) GET: /admin/lists/<listIri>/info : return list basic information (without children) GET: /admin/lists/candelete/<listItemIri> : check if list or its node is unused and can be deleted POST: /admin/lists : create new list POST: /admin/lists/<parentNodeIri> : create new child node under the supplied parent node IRI PUT: /admin/lists/<listItemIri> : update node information (root or child) PUT: /admin/lists/<listItemIri>/name : update the name of the node (root or child) PUT: /admin/lists/<listItemIri>/labels : update labels of the node (root or child) PUT: /admin/lists/<listItemIri>/comments : update comments of the node (root or child) PUT: /admin/lists/<nodeIri>/position : update position of a child node within its current parent or by changing its parent node DELETE: /admin/lists/<listItemIri> : delete a list (i.e. root node) or a child node and all its children, if not used DELETE: /admin/lists/comments/<nodeIri> : delete comments of a node (child only) List Item Operations Get lists Required permission: none Return all lists optionally filtered by project GET: /admin/lists[?projectIri=<projectIri>] Get list Required permission: none Return complete list (or node ) including basic information of the list (or child node), listinfo (or nodeinfo ), and all its children GET: /admin/lists/<listIri> Get list's information Required permission: none Return list information, listinfo (without children). GET: /admin/lists/infos/<listIri> Get list node Information Required permission: none Return node information, nodeinfo , (without children). GET: /admin/lists/nodes/<nodeIri> Get list's information (merged) Required permission: none Return list (or node) basic information, listinfo (or nodeinfo ), without its children GET: /admin/lists/<listIri>/info Check if list node is unused and can be deleted Required permission: none GET: /admin/lists/candelete/<listItemIri> Return simple JSON that confirms if the list node can be deleted { \"canDeleteList\" : true , \"listIri\" : \"http://rdfh.ch/lists/0801/xxx\" } List (root node or child node with all its children) can be deleted only if it (or one of its children) is not used. Create new list Required permission: SystemAdmin / ProjectAdmin Required fields: projectIri , labels , comments POST: /admin/lists BODY: { \"projectIri\" : \"someprojectiri\" , \"labels\" : [{ \"value\" : \"New list\" , \"language\" : \"en\" }], \"comments\" : [] } Additionally, each list can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"a new list\" , \"labels\" : [{ \"value\" : \"New list with IRI\" , \"language\" : \"en\" }], \"comments\" : [{ \"value\" : \"New comment\" , \"language\" : \"en\" }] } The response will contain the basic information of the list, listinfo and an empty list of its children, as below: { \"list\" : { \"children\" : [], \"listinfo\" : { \"comments\" : [{ \"value\" : \"New comment\" , \"language\" : \"en\" }], \"id\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"isRootNode\" : true , \"labels\" : [ { \"value\" : \"New list with IRI\" , \"language\" : \"en\" } ], \"name\" : \"a new list\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" } } } Create new child node Required permission: SystemAdmin / ProjectAdmin Required fields: parentNodeIri , projectIri , labels , Appends a new child node under the supplied nodeIri. If the supplied nodeIri is the listIri, then a new child node is appended to the top level. If a position is given for the new child node, the node will be created and inserted in the specified position, otherwise the node is appended to the end of parent's children. POST: /admin/lists/<parentNodeIri> BODY: { \"parentNodeIri\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"a child\" , \"labels\" : [{ \"value\" : \"New List Node\" , \"language\" : \"en\" }] } Additionally, each child node can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\" , \"parentNodeIri\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"a child\" , \"labels\" : [{ \"value\" : \"New List Node\" , \"language\" : \"en\" }] } The response will contain the basic information of the node, nodeinfo , as below: { \"nodeinfo\" : { \"comments\" : [], \"hasRootNode\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"id\" : \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\" , \"labels\" : [ { \"value\" : \"New List Node\" , \"language\" : \"en\" } ], \"name\" : \"a new child\" , \"position\" : 1 } } The new node can be created and inserted in a specific position which must be given in the payload as shown below. If necessary, according to the given position, the sibling nodes will be shifted. Note that position cannot have a value higher than the number of existing children. { \"parentNodeIri\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"Inserted new child\" , \"position\" : 0 , \"labels\" : [{ \"value\" : \"New List Node\" , \"language\" : \"en\" }] } In case the new node should be appended to the list of current children, either position: -1 must be given in the payload or the position parameter must be left out of the payload. Update list's or node's information The basic information of a list (or node) such as its labels, comments, name, or all of them can be updated. The parameters that must be updated together with the new value must be given in the JSON body of the request together with the IRI of the list and the IRI of the project it belongs to. Required permission: SystemAdmin / ProjectAdmin Required fields: listIri , projectIri Update list information PUT: /admin/lists/<listIri> BODY: { \"listIri\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"new name for the list\" , \"labels\" : [{ \"value\" : \"a new label for the list\" , \"language\" : \"en\" }], \"comments\" : [{ \"value\" : \"a new comment for the list\" , \"language\" : \"en\" }] } The response will contain the basic information of the list, listinfo (or nodeinfo ), without its children, as below: { \"listinfo\" : { \"comments\" : [ { \"value\" : \"a new comment for the list\" , \"language\" : \"en\" } ], \"id\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"isRootNode\" : true , \"labels\" : [ { \"value\" : \"a new label for the list\" , \"language\" : \"en\" } ], \"name\" : \"new name for the list\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" } } If only name of the list must be updated, it can be given as below in the body of the request: { \"listIri\" : \"listIri\" , \"projectIri\" : \"someprojectiri\" , \"name\" : \"another name\" } Alternatively, basic information name , labels , or comments of the root node (i.e. list) can be updated individually as explained below. Update list or node's name Required permission: SystemAdmin / ProjectAdmin Update name of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/name BODY: The new name of the node must be given in the body of the request as shown below: ``json { \"name\": \"a new name\" } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Update list or node's labels - Required permission: SystemAdmin / ProjectAdmin - Update labels of the list (i.e. root node) or a child node whose IRI is specified by `<listItemIri>`. - PUT: `/admin/lists/<listItemIri>/labels` - BODY: The new set of labels of the node must be given in the body of the request as shown below: ```json { \"labels\": [{\"language\": \"se\", \"value\": \"nya m\u00e4rkningen\"}] } There is no need to specify the project IRI because it is automatically extracted using the given `. Update list or node's comments Required permission: SystemAdmin / ProjectAdmin Update comments of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/labels BODY: The new set of comments of the node must be given in the body of the request as shown below: ```json { \"comments\": [{\"language\": \"se\", \"value\": \"nya kommentarer\"}] } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Repositioning a child node The position of an existing child node can be updated. The child node can be either repositioned within its current parent node, or can be added to another parent node in a specific position. The IRI of the parent node and the new position of the child node must be given in the request body. If a node is supposed to be repositioned to the end of a parent node's children, give `position: -1`. Suppose a parent node `parentNode1` has five children in positions 0-4, to change the position of its child node `childNode4` from its original position 3 to position 1 the request body should specify the IRI of its parent node and the new position as below: ```json { \"parentNodeIri\": \"<parentNode1-IRI>\", \"position\": 1 } Then the node childNode4 will be put in position 1, and its siblings will be shifted accordingly. The new position given in the request body cannot be the same as the child node's original position. If position: -1 is given, the node will be moved to the end of children list, and its siblings will be shifted to left. In case of repositioning the node within its current parent, the maximum permitted position is the length of its children list, i.e. in this example the highest allowed position is 4. To reposition a child node childNode4 to another parent node parentNode2 in a specific position, for example position: 3 , the IRI of the new parent node and the position the node must be placed within children of parentNode2 must be given as: { \"parentNodeIri\" : \"<parentNode2-IRI>\" , \"position\" : 3 } In this case, the childNode4 is removed from the list of children of its old parent parentNode1 and its old siblings are shifted accordingly. Then the node childNode4 is added to the specified new parent, i.e. parentNode2 , in the given position. The new siblings are shifted accordingly. Note that, the furthest the node can be placed is at the end of the list of the children of parentNode2 . That means if parentNode2 had 3 children with positions 0-2, then childNode4 can be placed in position 0-3 within children of its new parent node. If the position: -1 is given, the node will be appended to the end of new parent's children, and new siblings will not be shifted. Values less than -1 are not permitted for parameter position . Required permission: SystemAdmin / ProjectAdmin Response: returns the updated parent node with all its children. Put /admin/lists/<nodeIri>/position Delete a list or a node An entire list or a single node of it can be completely deleted, if not in use. Before deleting an entire list (i.e. root node), the data and ontologies are checked for any usage of the list or its children. If not in use, the list and all its children are deleted. Similarily, before deleting a single node of a list, it is verified that the node itself and none of its children are used. If not in use, the node and all its children are deleted. Once a node is deleted, its parent node is updated by shifting the remaining child nodes with respect to the position of the deleted node. Required permission: SystemAdmin / ProjectAdmin Response: If the IRI of the list (i.e. root node) is given, the iri of the deleted list with a flag deleted: true is returned. If the IRI of a child node is given, the updated parent node is returned. Delete /admin/lists/<listItemIri> Delete child node comments Performing a DELETE request to route /admin/lists/comments/<nodeIri> deletes the comments of that node. As a response sipmle JSON is returned: { \"commentsDeleted\" : true , \"nodeIri\" : \"http://rdfh.ch/lists/0801/xxx\" }","title":"Lists Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/lists/#lists-endpoint","text":"","title":"Lists Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/lists/#endpoint-overview","text":"List Item Operations: GET: /admin/lists[?projectIri=<projectIri>] : return all lists optionally filtered by project GET: /admin/lists/<listItemIri> : return complete list with all children if IRI of the list (i.e. root node) is given If IRI of the child node is given, return the node with its immediate children GET: /admin/lists/infos/<listIri> : return list information (without children) GET: /admin/lists/nodes/<nodeIri> : return list node information (without children) GET: /admin/lists/<listIri>/info : return list basic information (without children) GET: /admin/lists/candelete/<listItemIri> : check if list or its node is unused and can be deleted POST: /admin/lists : create new list POST: /admin/lists/<parentNodeIri> : create new child node under the supplied parent node IRI PUT: /admin/lists/<listItemIri> : update node information (root or child) PUT: /admin/lists/<listItemIri>/name : update the name of the node (root or child) PUT: /admin/lists/<listItemIri>/labels : update labels of the node (root or child) PUT: /admin/lists/<listItemIri>/comments : update comments of the node (root or child) PUT: /admin/lists/<nodeIri>/position : update position of a child node within its current parent or by changing its parent node DELETE: /admin/lists/<listItemIri> : delete a list (i.e. root node) or a child node and all its children, if not used DELETE: /admin/lists/comments/<nodeIri> : delete comments of a node (child only)","title":"Endpoint Overview"},{"location":"DSP-API/03-endpoints/api-admin/lists/#list-item-operations","text":"","title":"List Item Operations"},{"location":"DSP-API/03-endpoints/api-admin/lists/#get-lists","text":"Required permission: none Return all lists optionally filtered by project GET: /admin/lists[?projectIri=<projectIri>]","title":"Get lists"},{"location":"DSP-API/03-endpoints/api-admin/lists/#get-list","text":"Required permission: none Return complete list (or node ) including basic information of the list (or child node), listinfo (or nodeinfo ), and all its children GET: /admin/lists/<listIri>","title":"Get list"},{"location":"DSP-API/03-endpoints/api-admin/lists/#get-lists-information","text":"Required permission: none Return list information, listinfo (without children). GET: /admin/lists/infos/<listIri>","title":"Get list's information"},{"location":"DSP-API/03-endpoints/api-admin/lists/#get-list-node-information","text":"Required permission: none Return node information, nodeinfo , (without children). GET: /admin/lists/nodes/<nodeIri>","title":"Get list node Information"},{"location":"DSP-API/03-endpoints/api-admin/lists/#get-lists-information-merged","text":"Required permission: none Return list (or node) basic information, listinfo (or nodeinfo ), without its children GET: /admin/lists/<listIri>/info","title":"Get list's information (merged)"},{"location":"DSP-API/03-endpoints/api-admin/lists/#check-if-list-node-is-unused-and-can-be-deleted","text":"Required permission: none GET: /admin/lists/candelete/<listItemIri> Return simple JSON that confirms if the list node can be deleted { \"canDeleteList\" : true , \"listIri\" : \"http://rdfh.ch/lists/0801/xxx\" } List (root node or child node with all its children) can be deleted only if it (or one of its children) is not used.","title":"Check if list node is unused and can be deleted"},{"location":"DSP-API/03-endpoints/api-admin/lists/#create-new-list","text":"Required permission: SystemAdmin / ProjectAdmin Required fields: projectIri , labels , comments POST: /admin/lists BODY: { \"projectIri\" : \"someprojectiri\" , \"labels\" : [{ \"value\" : \"New list\" , \"language\" : \"en\" }], \"comments\" : [] } Additionally, each list can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"a new list\" , \"labels\" : [{ \"value\" : \"New list with IRI\" , \"language\" : \"en\" }], \"comments\" : [{ \"value\" : \"New comment\" , \"language\" : \"en\" }] } The response will contain the basic information of the list, listinfo and an empty list of its children, as below: { \"list\" : { \"children\" : [], \"listinfo\" : { \"comments\" : [{ \"value\" : \"New comment\" , \"language\" : \"en\" }], \"id\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"isRootNode\" : true , \"labels\" : [ { \"value\" : \"New list with IRI\" , \"language\" : \"en\" } ], \"name\" : \"a new list\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" } } }","title":"Create new list"},{"location":"DSP-API/03-endpoints/api-admin/lists/#create-new-child-node","text":"Required permission: SystemAdmin / ProjectAdmin Required fields: parentNodeIri , projectIri , labels , Appends a new child node under the supplied nodeIri. If the supplied nodeIri is the listIri, then a new child node is appended to the top level. If a position is given for the new child node, the node will be created and inserted in the specified position, otherwise the node is appended to the end of parent's children. POST: /admin/lists/<parentNodeIri> BODY: { \"parentNodeIri\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"a child\" , \"labels\" : [{ \"value\" : \"New List Node\" , \"language\" : \"en\" }] } Additionally, each child node can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\" , \"parentNodeIri\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"a child\" , \"labels\" : [{ \"value\" : \"New List Node\" , \"language\" : \"en\" }] } The response will contain the basic information of the node, nodeinfo , as below: { \"nodeinfo\" : { \"comments\" : [], \"hasRootNode\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"id\" : \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\" , \"labels\" : [ { \"value\" : \"New List Node\" , \"language\" : \"en\" } ], \"name\" : \"a new child\" , \"position\" : 1 } } The new node can be created and inserted in a specific position which must be given in the payload as shown below. If necessary, according to the given position, the sibling nodes will be shifted. Note that position cannot have a value higher than the number of existing children. { \"parentNodeIri\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"Inserted new child\" , \"position\" : 0 , \"labels\" : [{ \"value\" : \"New List Node\" , \"language\" : \"en\" }] } In case the new node should be appended to the list of current children, either position: -1 must be given in the payload or the position parameter must be left out of the payload.","title":"Create new child node"},{"location":"DSP-API/03-endpoints/api-admin/lists/#update-lists-or-nodes-information","text":"The basic information of a list (or node) such as its labels, comments, name, or all of them can be updated. The parameters that must be updated together with the new value must be given in the JSON body of the request together with the IRI of the list and the IRI of the project it belongs to. Required permission: SystemAdmin / ProjectAdmin Required fields: listIri , projectIri Update list information PUT: /admin/lists/<listIri> BODY: { \"listIri\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" , \"name\" : \"new name for the list\" , \"labels\" : [{ \"value\" : \"a new label for the list\" , \"language\" : \"en\" }], \"comments\" : [{ \"value\" : \"a new comment for the list\" , \"language\" : \"en\" }] } The response will contain the basic information of the list, listinfo (or nodeinfo ), without its children, as below: { \"listinfo\" : { \"comments\" : [ { \"value\" : \"a new comment for the list\" , \"language\" : \"en\" } ], \"id\" : \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\" , \"isRootNode\" : true , \"labels\" : [ { \"value\" : \"a new label for the list\" , \"language\" : \"en\" } ], \"name\" : \"new name for the list\" , \"projectIri\" : \"http://rdfh.ch/projects/0001\" } } If only name of the list must be updated, it can be given as below in the body of the request: { \"listIri\" : \"listIri\" , \"projectIri\" : \"someprojectiri\" , \"name\" : \"another name\" } Alternatively, basic information name , labels , or comments of the root node (i.e. list) can be updated individually as explained below.","title":"Update list's or node's information"},{"location":"DSP-API/03-endpoints/api-admin/lists/#update-list-or-nodes-name","text":"Required permission: SystemAdmin / ProjectAdmin Update name of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/name BODY: The new name of the node must be given in the body of the request as shown below: ``json { \"name\": \"a new name\" } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Update list or node's labels - Required permission: SystemAdmin / ProjectAdmin - Update labels of the list (i.e. root node) or a child node whose IRI is specified by `<listItemIri>`. - PUT: `/admin/lists/<listItemIri>/labels` - BODY: The new set of labels of the node must be given in the body of the request as shown below: ```json { \"labels\": [{\"language\": \"se\", \"value\": \"nya m\u00e4rkningen\"}] } There is no need to specify the project IRI because it is automatically extracted using the given `.","title":"Update list or node's name"},{"location":"DSP-API/03-endpoints/api-admin/lists/#update-list-or-nodes-comments","text":"Required permission: SystemAdmin / ProjectAdmin Update comments of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/labels BODY: The new set of comments of the node must be given in the body of the request as shown below: ```json { \"comments\": [{\"language\": \"se\", \"value\": \"nya kommentarer\"}] } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Repositioning a child node The position of an existing child node can be updated. The child node can be either repositioned within its current parent node, or can be added to another parent node in a specific position. The IRI of the parent node and the new position of the child node must be given in the request body. If a node is supposed to be repositioned to the end of a parent node's children, give `position: -1`. Suppose a parent node `parentNode1` has five children in positions 0-4, to change the position of its child node `childNode4` from its original position 3 to position 1 the request body should specify the IRI of its parent node and the new position as below: ```json { \"parentNodeIri\": \"<parentNode1-IRI>\", \"position\": 1 } Then the node childNode4 will be put in position 1, and its siblings will be shifted accordingly. The new position given in the request body cannot be the same as the child node's original position. If position: -1 is given, the node will be moved to the end of children list, and its siblings will be shifted to left. In case of repositioning the node within its current parent, the maximum permitted position is the length of its children list, i.e. in this example the highest allowed position is 4. To reposition a child node childNode4 to another parent node parentNode2 in a specific position, for example position: 3 , the IRI of the new parent node and the position the node must be placed within children of parentNode2 must be given as: { \"parentNodeIri\" : \"<parentNode2-IRI>\" , \"position\" : 3 } In this case, the childNode4 is removed from the list of children of its old parent parentNode1 and its old siblings are shifted accordingly. Then the node childNode4 is added to the specified new parent, i.e. parentNode2 , in the given position. The new siblings are shifted accordingly. Note that, the furthest the node can be placed is at the end of the list of the children of parentNode2 . That means if parentNode2 had 3 children with positions 0-2, then childNode4 can be placed in position 0-3 within children of its new parent node. If the position: -1 is given, the node will be appended to the end of new parent's children, and new siblings will not be shifted. Values less than -1 are not permitted for parameter position . Required permission: SystemAdmin / ProjectAdmin Response: returns the updated parent node with all its children. Put /admin/lists/<nodeIri>/position","title":"Update list or node's comments"},{"location":"DSP-API/03-endpoints/api-admin/lists/#delete-a-list-or-a-node","text":"An entire list or a single node of it can be completely deleted, if not in use. Before deleting an entire list (i.e. root node), the data and ontologies are checked for any usage of the list or its children. If not in use, the list and all its children are deleted. Similarily, before deleting a single node of a list, it is verified that the node itself and none of its children are used. If not in use, the node and all its children are deleted. Once a node is deleted, its parent node is updated by shifting the remaining child nodes with respect to the position of the deleted node. Required permission: SystemAdmin / ProjectAdmin Response: If the IRI of the list (i.e. root node) is given, the iri of the deleted list with a flag deleted: true is returned. If the IRI of a child node is given, the updated parent node is returned. Delete /admin/lists/<listItemIri>","title":"Delete a list or a node"},{"location":"DSP-API/03-endpoints/api-admin/lists/#delete-child-node-comments","text":"Performing a DELETE request to route /admin/lists/comments/<nodeIri> deletes the comments of that node. As a response sipmle JSON is returned: { \"commentsDeleted\" : true , \"nodeIri\" : \"http://rdfh.ch/lists/0801/xxx\" }","title":"Delete child node comments"},{"location":"DSP-API/03-endpoints/api-admin/overview/","text":"Admin Endpoint For the management of users , projects , groups , lists , and permissions , the DSP-API following a resource centric approach, provides the following endpoints corresponding to the respective classes of objects that they have an effect on, namely: Users endpoint : http://server:port/admin/users - knora-base:User Projects endpoint : http://server:port/admin/projects - knora-base:knoraProject Groups endpoint : http://server:port/admin/groups - knora-base:UserGroup Lists endpoint : http://server:port/admin/lists - knora-base:ListNode Permissions endpoint : http://server:port/admin/permissions - knora-admin:Permission All information regarding users, projects, groups, lists and permissions is stored in the http://www.knora.org/admin named graph. Additionally there is the stores endpoint which allows manipulation of the triplestore content.","title":"Overview"},{"location":"DSP-API/03-endpoints/api-admin/overview/#admin-endpoint","text":"For the management of users , projects , groups , lists , and permissions , the DSP-API following a resource centric approach, provides the following endpoints corresponding to the respective classes of objects that they have an effect on, namely: Users endpoint : http://server:port/admin/users - knora-base:User Projects endpoint : http://server:port/admin/projects - knora-base:knoraProject Groups endpoint : http://server:port/admin/groups - knora-base:UserGroup Lists endpoint : http://server:port/admin/lists - knora-base:ListNode Permissions endpoint : http://server:port/admin/permissions - knora-admin:Permission All information regarding users, projects, groups, lists and permissions is stored in the http://www.knora.org/admin named graph. Additionally there is the stores endpoint which allows manipulation of the triplestore content.","title":"Admin Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/permissions/","text":"Permissions Endpoint For an extensive explanation on how DSP permissions are implemented, see here . Route Operations Explanation /admin/permissions/{projectIri} GET get all permissions of a project /admin/permissions/ap/{projectIri} GET get all administrative permissions of a project /admin/permissions/ap/{projectIri}/{groupIri} GET get all administrative permissions of a group /admin/permissions/doap/{projectIri} GET get all default object access permissions of a project /admin/permissions/ap POST create a new administrative permission /admin/permissions/doap POST create a new default object access permission /admin/permissions/{permissionIri}/group PUT update for which group an administrative or default object access permission is used /admin/permissions/{permissionIri}/hasPermission PUT update the scope of an administrative or default object access permission , i.e. what permissions are granted to which group when this permission applies /admin/permissions/{doap_permissionIri}/resourceClass PUT update for which resource class a default object access permission applies /admin/permissions/{doap_permissionIri}/property PUT update for which property a default object access permission applies /admin/permissions/{permissionIri} DELETE delete an administrative or default object access permission Permission Operations Note: For the following operations, the requesting user must be either a systemAdmin or a projectAdmin . Getting Permissions GET: /admin/permissions/<projectIri> : return all permissions for a project. As a response, the IRI and the type of all permissions of a project are returned. GET: /admin/permissions/ap/<projectIri> : return all administrative permissions for a project. As a response, all administrative_permissions of a project are returned. GET: /admin/permissions/ap/<projectIri>/<groupIri> : return the administrative permissions for a project group. As a response, the administrative_permission defined for the group is returned. GET: /admin/permissions/doap/<projectIri> : return all default object access permissions for a project. As a response, all default_object_acces_permissions of a project are returned. Creating New Administrative Permissions POST: /admin/permissions/ap : create a new administrative permission. The type of permissions, the project and group to which the permission should be added must be included in the request body, for example: { \"forGroup\" : \"http://rdfh.ch/groups/0001/thing-searcher\" , \"forProject\" : \"http://rdfh.ch/projects/0001\" , \"hasPermissions\" :[ { \"additionalInformation\" : null , \"name\" : \"ProjectAdminGroupAllPermission\" , \"permissionCode\" : null } ] } In addition, in the body of the request, it is possible to specify a custom IRI (of DSP IRI form) for a permission through the @id attribute which will then be assigned to the permission; otherwise the permission will get a unique random IRI. A custom permission IRI must be http://rdfh.ch/permissions/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the permission belongs to), plus a custom ID string. For example: \"id\": \"http://rdfh.ch/permissions/0001/jKIYuaEUETBcyxpenUwRzQ\", As a response, the created administrative permission and its IRI are returned as below: { \"administrative_permission\" : { \"forGroup\" : \"http://rdfh.ch/groups/0001/thing-searcher\" , \"forProject\" : \"http://rdfh.ch/projects/0001\" , \"hasPermissions\" : [ { \"additionalInformation\" : null , \"name\" : \"ProjectAdminGroupAllPermission\" , \"permissionCode\" : null } ], \"iri\" : \"http://rdfh.ch/permissions/0001/mFlyBEiMQtGzwy_hK0M-Ow\" } } hasPermissions contains permission types that must be granted. See the complete description of administrative permission types . In summary, each permission should contain followings: additionalInformation : should be left empty, otherwise will be ignored. name : indicates the type of the permission that can be one of the followings: ProjectAdminAllPermission : gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ProjectAdminGroupAllPermission : gives the user the permission to modify group info and group membership on all groups belonging to the project. ProjectAdminGroupRestrictedPermission : gives the user the permission to modify group info and group membership on certain groups belonging to the project. ProjectAdminRightsAllPermission : gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). ProjectResourceCreateAllPermission : gives the permission to create resources inside the project. ProjectResourceCreateRestrictedPermission : gives restricted resource creation permission inside the project. permissionCode : should be left empty, otherwise will be ignored. Note that during the creation of a new project, a default set of administrative permissions are added to its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new administrative permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified (See update permission ). Creating New Default Object Access Permissions POST: /admin/permissions/doap : create a new default object access permission. A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. For example, to create a new default object access permission for a group of a project the request body would be { \"forGroup\" : \"http://rdfh.ch/groups/0001/thing-searcher\" , \"forProject\" : \"http://rdfh.ch/projects/0001\" , \"forProperty\" : null , \"forResourceClass\" : null , \"hasPermissions\" :[ { \"additionalInformation\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" , \"name\" : \"D\" , \"permissionCode\" : 7 } ] } hasPermissions contains permission types that must be granted. See a complete description of object access permission types . In summary, each permission should contain followings: additionalInformation : To whom the permission should be granted: project members, known users, unknown users, etc. name : indicates the type of the permission that can be one of the followings. RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) permissionCode : The code assigned to a permission indicating its hierarchical level. These codes are as below: 1 : for restricted view permission (least privileged) 2 : for view permission 6 : for modify permission 7 : for delete permission 8 : for change rights permission (most privileged) Note that, at least either name or permissionCode must be provided. If one is missing, it will be extrapolated from the other. For example, if permissionCode= 1 is given but name was left empty, its value will be set to name = RV . Similar to the previous case a custom IRI can be assigned to a permission specified by the id in the request body. The example below shows the request body to create a new default object access permission with a custom IRI defined for a resource class of a specific project: { \"id\" : \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\" , \"forGroup\" : null , \"forProject\" : \"http://rdfh.ch/projects/00FF\" , \"forProperty\" : null , \"forResourceClass\" : \"http://www.knora.org/ontology/00FF/images#bild\" , \"hasPermissions\" :[ { \"additionalInformation\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" , \"name\" : \"D\" , \"permissionCode\" : 7 } ] } The response contains the newly created permission and its IRI, as: { \"default_object_access_permission\" : { \"forGroup\" : null , \"forProject\" : \"http://rdfh.ch/projects/00FF\" , \"forProperty\" : null , \"forResourceClass\" : \"http://www.knora.org/ontology/00FF/images#bild\" , \"hasPermissions\" : [ { \"additionalInformation\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" , \"name\" : \"D\" , \"permissionCode\" : 7 } ], \"iri\" : \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\" } } Note that during the creation of a new project, a set of default object access permissions are created for its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new default object access permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified; see below for more information. Updating a Permission's Group PUT: /admin/permissions/<permissionIri>/group to change the group for which an administrative or a default object access permission, identified by its IRI <permissionIri> , is defined. The request body must contain the IRI of the new group as below: { \"forGroup\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" } When updating an administrative permission, its previous forGroup value will be replaced with the new one. When updating a default object access permission, if it originally had a forGroup value defined, it will be replaced with the new group. Otherwise, if the default object access permission was defined for a resource class or a property or the combination of both, the permission will be defined for the newly specified group and its previous forResourceClass and forProperty values will be deleted. Updating a Permission's Scope PUT: /admin/permissions/<permissionIri>/hasPermissions to change the scope of permissions assigned to an administrative or a default object access permission identified by it IRI, <permissionIri> . The request body must contain the new set of permission types as below: { \"hasPermissions\" :[ { \"additionalInformation\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" , \"name\" : \"D\" , \"permissionCode\" : 7 } ] } Each permission item given in hasPermissions , must contain the necessary parameters with respect to the type of the permission. For example, if you wish to change the scope of an administrative permission, follow the guidelines for the content of its hasPermissions property. Similarly, if you wish to change the scope of a default object access permission, follow the guidelines given about the content of its hasPermissions property. Either the name or the permissionCode must be present; it is not necessary to provide both. The previous permission set is replaced by the new permission set. In order to remove a permission for a group entirely, you can provide a new set of permissions, leaving out the permission specification for the group. Updating a Default Object Access Permission's Resource Class PUT: /admin/permissions/<doap_permissionIri>/resourceClass to change the resource class for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object acceess permission. The IRI of the new resource class must be given in the request body as: { \"forResourceClass\" : \"http://www.knora.org/ontology/0803/incunabula#book\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given resource class instead of the group. That means the value of the forGroup will be deleted. Updating a Default Object Access Permission's Property PUT: /admin/permissions/<doap_permissionIri>/property to change the property for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object access permission. The IRI of the new property must be given in the request body as: { \"forProperty\" : \"http://www.knora.org/ontology/00FF/images#titel\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given property instead of the group. That means the value of the forGroup will be deleted. Deleting a Permission DELETE: /admin/permissions/<permissionIri> to delete an administrative, or a default object access permission. The IRI of the permission must be given in encoded form.","title":"Permissions Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#permissions-endpoint","text":"For an extensive explanation on how DSP permissions are implemented, see here . Route Operations Explanation /admin/permissions/{projectIri} GET get all permissions of a project /admin/permissions/ap/{projectIri} GET get all administrative permissions of a project /admin/permissions/ap/{projectIri}/{groupIri} GET get all administrative permissions of a group /admin/permissions/doap/{projectIri} GET get all default object access permissions of a project /admin/permissions/ap POST create a new administrative permission /admin/permissions/doap POST create a new default object access permission /admin/permissions/{permissionIri}/group PUT update for which group an administrative or default object access permission is used /admin/permissions/{permissionIri}/hasPermission PUT update the scope of an administrative or default object access permission , i.e. what permissions are granted to which group when this permission applies /admin/permissions/{doap_permissionIri}/resourceClass PUT update for which resource class a default object access permission applies /admin/permissions/{doap_permissionIri}/property PUT update for which property a default object access permission applies /admin/permissions/{permissionIri} DELETE delete an administrative or default object access permission","title":"Permissions Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#permission-operations","text":"Note: For the following operations, the requesting user must be either a systemAdmin or a projectAdmin .","title":"Permission Operations"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#getting-permissions","text":"GET: /admin/permissions/<projectIri> : return all permissions for a project. As a response, the IRI and the type of all permissions of a project are returned. GET: /admin/permissions/ap/<projectIri> : return all administrative permissions for a project. As a response, all administrative_permissions of a project are returned. GET: /admin/permissions/ap/<projectIri>/<groupIri> : return the administrative permissions for a project group. As a response, the administrative_permission defined for the group is returned. GET: /admin/permissions/doap/<projectIri> : return all default object access permissions for a project. As a response, all default_object_acces_permissions of a project are returned.","title":"Getting Permissions"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#creating-new-administrative-permissions","text":"POST: /admin/permissions/ap : create a new administrative permission. The type of permissions, the project and group to which the permission should be added must be included in the request body, for example: { \"forGroup\" : \"http://rdfh.ch/groups/0001/thing-searcher\" , \"forProject\" : \"http://rdfh.ch/projects/0001\" , \"hasPermissions\" :[ { \"additionalInformation\" : null , \"name\" : \"ProjectAdminGroupAllPermission\" , \"permissionCode\" : null } ] } In addition, in the body of the request, it is possible to specify a custom IRI (of DSP IRI form) for a permission through the @id attribute which will then be assigned to the permission; otherwise the permission will get a unique random IRI. A custom permission IRI must be http://rdfh.ch/permissions/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the permission belongs to), plus a custom ID string. For example: \"id\": \"http://rdfh.ch/permissions/0001/jKIYuaEUETBcyxpenUwRzQ\", As a response, the created administrative permission and its IRI are returned as below: { \"administrative_permission\" : { \"forGroup\" : \"http://rdfh.ch/groups/0001/thing-searcher\" , \"forProject\" : \"http://rdfh.ch/projects/0001\" , \"hasPermissions\" : [ { \"additionalInformation\" : null , \"name\" : \"ProjectAdminGroupAllPermission\" , \"permissionCode\" : null } ], \"iri\" : \"http://rdfh.ch/permissions/0001/mFlyBEiMQtGzwy_hK0M-Ow\" } } hasPermissions contains permission types that must be granted. See the complete description of administrative permission types . In summary, each permission should contain followings: additionalInformation : should be left empty, otherwise will be ignored. name : indicates the type of the permission that can be one of the followings: ProjectAdminAllPermission : gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ProjectAdminGroupAllPermission : gives the user the permission to modify group info and group membership on all groups belonging to the project. ProjectAdminGroupRestrictedPermission : gives the user the permission to modify group info and group membership on certain groups belonging to the project. ProjectAdminRightsAllPermission : gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). ProjectResourceCreateAllPermission : gives the permission to create resources inside the project. ProjectResourceCreateRestrictedPermission : gives restricted resource creation permission inside the project. permissionCode : should be left empty, otherwise will be ignored. Note that during the creation of a new project, a default set of administrative permissions are added to its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new administrative permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified (See update permission ).","title":"Creating New Administrative Permissions"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#creating-new-default-object-access-permissions","text":"POST: /admin/permissions/doap : create a new default object access permission. A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. For example, to create a new default object access permission for a group of a project the request body would be { \"forGroup\" : \"http://rdfh.ch/groups/0001/thing-searcher\" , \"forProject\" : \"http://rdfh.ch/projects/0001\" , \"forProperty\" : null , \"forResourceClass\" : null , \"hasPermissions\" :[ { \"additionalInformation\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" , \"name\" : \"D\" , \"permissionCode\" : 7 } ] } hasPermissions contains permission types that must be granted. See a complete description of object access permission types . In summary, each permission should contain followings: additionalInformation : To whom the permission should be granted: project members, known users, unknown users, etc. name : indicates the type of the permission that can be one of the followings. RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) permissionCode : The code assigned to a permission indicating its hierarchical level. These codes are as below: 1 : for restricted view permission (least privileged) 2 : for view permission 6 : for modify permission 7 : for delete permission 8 : for change rights permission (most privileged) Note that, at least either name or permissionCode must be provided. If one is missing, it will be extrapolated from the other. For example, if permissionCode= 1 is given but name was left empty, its value will be set to name = RV . Similar to the previous case a custom IRI can be assigned to a permission specified by the id in the request body. The example below shows the request body to create a new default object access permission with a custom IRI defined for a resource class of a specific project: { \"id\" : \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\" , \"forGroup\" : null , \"forProject\" : \"http://rdfh.ch/projects/00FF\" , \"forProperty\" : null , \"forResourceClass\" : \"http://www.knora.org/ontology/00FF/images#bild\" , \"hasPermissions\" :[ { \"additionalInformation\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" , \"name\" : \"D\" , \"permissionCode\" : 7 } ] } The response contains the newly created permission and its IRI, as: { \"default_object_access_permission\" : { \"forGroup\" : null , \"forProject\" : \"http://rdfh.ch/projects/00FF\" , \"forProperty\" : null , \"forResourceClass\" : \"http://www.knora.org/ontology/00FF/images#bild\" , \"hasPermissions\" : [ { \"additionalInformation\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" , \"name\" : \"D\" , \"permissionCode\" : 7 } ], \"iri\" : \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\" } } Note that during the creation of a new project, a set of default object access permissions are created for its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new default object access permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified; see below for more information.","title":"Creating New Default Object Access Permissions"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#updating-a-permissions-group","text":"PUT: /admin/permissions/<permissionIri>/group to change the group for which an administrative or a default object access permission, identified by its IRI <permissionIri> , is defined. The request body must contain the IRI of the new group as below: { \"forGroup\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" } When updating an administrative permission, its previous forGroup value will be replaced with the new one. When updating a default object access permission, if it originally had a forGroup value defined, it will be replaced with the new group. Otherwise, if the default object access permission was defined for a resource class or a property or the combination of both, the permission will be defined for the newly specified group and its previous forResourceClass and forProperty values will be deleted.","title":"Updating a Permission's Group"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#updating-a-permissions-scope","text":"PUT: /admin/permissions/<permissionIri>/hasPermissions to change the scope of permissions assigned to an administrative or a default object access permission identified by it IRI, <permissionIri> . The request body must contain the new set of permission types as below: { \"hasPermissions\" :[ { \"additionalInformation\" : \"http://www.knora.org/ontology/knora-admin#ProjectMember\" , \"name\" : \"D\" , \"permissionCode\" : 7 } ] } Each permission item given in hasPermissions , must contain the necessary parameters with respect to the type of the permission. For example, if you wish to change the scope of an administrative permission, follow the guidelines for the content of its hasPermissions property. Similarly, if you wish to change the scope of a default object access permission, follow the guidelines given about the content of its hasPermissions property. Either the name or the permissionCode must be present; it is not necessary to provide both. The previous permission set is replaced by the new permission set. In order to remove a permission for a group entirely, you can provide a new set of permissions, leaving out the permission specification for the group.","title":"Updating a Permission's Scope"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#updating-a-default-object-access-permissions-resource-class","text":"PUT: /admin/permissions/<doap_permissionIri>/resourceClass to change the resource class for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object acceess permission. The IRI of the new resource class must be given in the request body as: { \"forResourceClass\" : \"http://www.knora.org/ontology/0803/incunabula#book\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given resource class instead of the group. That means the value of the forGroup will be deleted.","title":"Updating a Default Object Access Permission's Resource Class"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#updating-a-default-object-access-permissions-property","text":"PUT: /admin/permissions/<doap_permissionIri>/property to change the property for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object access permission. The IRI of the new property must be given in the request body as: { \"forProperty\" : \"http://www.knora.org/ontology/00FF/images#titel\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given property instead of the group. That means the value of the forGroup will be deleted.","title":"Updating a Default Object Access Permission's Property"},{"location":"DSP-API/03-endpoints/api-admin/permissions/#deleting-a-permission","text":"DELETE: /admin/permissions/<permissionIri> to delete an administrative, or a default object access permission. The IRI of the permission must be given in encoded form.","title":"Deleting a Permission"},{"location":"DSP-API/03-endpoints/api-admin/projects/","text":"Projects Endpoint Scope Route Operations Explanation projects /admin/projects GET get all projects projects /admin/projects POST create a project projects /admin/projects/shortname/{shortname} GET get a single project projects /admin/projects/shortcode/{shortcode} GET get a single project projects /admin/projects/iri/{iri} GET get a single project projects /admin/projects/iri/{iri} PUT update a project projects /admin/projects/iri/{iri} DELETE delete a project projects /admin/projects/iri/{iri}/AllData GET get all data of a project project members /admin/projects/shortname/{shortname}/members GET get all project members project members /admin/projects/shortcode/{shortcode}/members GET get all project members project members /admin/projects/iri/{iri}/members GET get all project members project members /admin/projects/shortname/{shortname}/admin-members GET get all project admins project members /admin/projects/shortcode/{shortcode}/admin-members GET get all project admins project members /admin/projects/iri/{iri}/admin-members GET get all project admins keywords /admin/projects/Keywords GET get all project keywords keywords /admin/projects/iri/{iri}/Keywords GET get project keywords of a single project view settings /admin/projects/shortname/{shortname}/RestrictedViewSettings GET get restricted view settings for a project view settings /admin/projects/shortcode/{shortcode}/RestrictedViewSettings GET get restricted view settings for a project view settings /admin/projects/iri/{iri}/RestrictedViewSettings GET get restricted view settings for a project Project Operations Get All Projects Permissions: No permissions required Request definition: GET /admin/projects Description: Returns a list of all projects. Example request: curl --request GET --url http://localhost:3333/admin/projects Example response: { \"projects\": [ { \"description\": [ { \"value\": \"A demo project of a collection of images\", \"language\": \"en\" } ], \"id\": \"http://rdfh.ch/projects/00FF\", \"keywords\": [ \"collection\", \"images\" ], \"logo\": null, \"longname\": \"Image Collection Demo\", \"ontologies\": [ \"http://0.0.0.0:3333/ontology/00FF/images/v2\" ], \"selfjoin\": false, \"shortcode\": \"00FF\", \"shortname\": \"images\", \"status\": true }, { // ... } ] } Create a New Project Permissions: SystemAdmin Request definition: POST /admin/projects Description: Create a new project. Required payload: shortcode (unique, 4-digits) shortname (unique, it should be in the form of a xsd:NCNAME and it should be URL safe) description (collection of descriptions as strings with language tag) keywords (collection of keywords) status (true, if project is active. false, if project is inactive) selfjoin Optional payload: id (unique, custom DSP IRI, e.g. used for migrating a project from one server to another) longname logo Example request: curl --request POST \\ --url http://localhost:3333/admin/projects \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' \\ --header 'Content-Type: application/json' \\ --data '{ \"shortname\": \"newproject\", \"shortcode\": \"3333\", \"longname\": \"project longname\", \"description\": [ { \"value\": \"project description\", \"language\": \"en\" } ], \"keywords\": [ \"test project\" ], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false }' Example response: { \"project\": { \"description\": [ { \"value\": \"project description\", \"language\": \"en\" } ], \"id\": \"http://rdfh.ch/projects/3333\", \"keywords\": [ \"test project\" ], \"logo\": \"/fu/bar/baz.jpg\", \"longname\": \"project longname\", \"ontologies\": [], \"selfjoin\": false, \"shortcode\": \"3333\", \"shortname\": \"newproject\", \"status\": true } } Errors: 400 Bad Request if the project already exists or any of the provided properties is invalid. 401 Unauthorized if authorization failed. Default set of permissions for a new project: When a new project is created, following default permissions are added to its admins and members: ProjectAdmin group receives an administrative permission to do all project level operations and to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForAdmin ProjectAdmin group also gets a default object access permission to change rights (which includes delete, modify, view, and restricted view permissions) of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForAdmin ProjectMember group receives an administrative permission to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForMember ProjectMember group also gets a default object access permission to modify (which includes view and restricted view permissions) of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForMember Get Project by ID The ID can be shortcode, shortname or IRI. Permissions: No permissions required Request definition: GET /admin/projects/shortcode/{shortcode} GET /admin/projects/shortname/{shortname} GET /admin/projects/iri/{iri} Description: Returns a single project identified by shortcode, shortname or IRI. Example request: curl --request GET --url http://localhost:3333/admin/projects/shortcode/0001 curl --request GET --url http://localhost:3333/admin/projects/shortname/anything curl --request GET --url \\ http://localhost:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 Example response: { \"project\": { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"Anything Project\", \"ontologies\": [ \"http://0.0.0.0:3333/ontology/0001/something/v2\", \"http://0.0.0.0:3333/ontology/0001/sequences/v2\", \"http://0.0.0.0:3333/ontology/0001/freetest/v2\", \"http://0.0.0.0:3333/ontology/0001/minimal/v2\", \"http://0.0.0.0:3333/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": true } } Errors: 400 Bad Request if the provided ID is not valid. 404 Not Found if no project with the provided ID is found. NB: IRI must be URL-encoded. Update Project Information Permissions: SystemAdmin / ProjectAdmin Request definition: PUT /admin/projects/iri/{iri} Description: Update a project identified by its IRI. Payload: The following properties can be changed: longname description keywords logo status selfjoin Example request: curl --request PUT \\ --url http://localhost:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' \\ --header 'Content-Type: application/json' \\ --data '{ \"longname\": \"other longname\" }' Example response: { \"project\": { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"other longname\", \"ontologies\": [ \"http://api.knora.org/ontology/0001/something/v2\", \"http://api.knora.org/ontology/0001/sequences/v2\", \"http://api.knora.org/ontology/0001/freetest/v2\", \"http://api.knora.org/ontology/0001/minimal/v2\", \"http://api.knora.org/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": true } } Errors: 400 Bad Request if the provided IRI is not valid. if the provided payload is not valid. 404 Not Found if no project with the provided IRI is found. Delete a Project Permissions: SystemAdmin / ProjectAdmin Request definition: DELETE /admin/projects/iri/{iri} Description: Mark a project as deleted (by setting the status flag to false ). curl --request DELETE \\ --url http://localhost:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' \\ --header 'Content-Type: application/json' Example response: { \"project\": { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"other longname\", \"ontologies\": [ \"http://api.knora.org/ontology/0001/something/v2\", \"http://api.knora.org/ontology/0001/sequences/v2\", \"http://api.knora.org/ontology/0001/freetest/v2\", \"http://api.knora.org/ontology/0001/minimal/v2\", \"http://api.knora.org/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": false } } Errors: 400 Bad Request if the provided IRI is not valid. 404 Not Found if no project with the provided IRI is found. Get all Data of a Project Permissions: ProjectAdmin / SystemAdmin Request definition: POST /admin/projects/iri/{iri}/AllData Description: Gets all data of a project as a TriG file (ontologies, resource data, admin data, and permissions). Example request: curl --request GET \\ --url http://localhost:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F00FF/AllData \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: @prefix images: <http://www.knora.org/ontology/00FF/images#> . @prefix knora-admin: <http://www.knora.org/ontology/knora-admin#> . @prefix knora-base: <http://www.knora.org/ontology/knora-base#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix salsah-gui: <http://www.knora.org/ontology/salsah-gui#> . @prefix standoff: <http://www.knora.org/ontology/standoff#> . @prefix xml: <http://www.w3.org/XML/1998/namespace> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . <http://www.knora.org/ontology/00FF/images> { <http://www.knora.org/ontology/00FF/images> rdf:type owl:Ontology ; rdfs:label \"The images demo ontology\" ; knora-base:attachedToProject <http://rdfh.ch/projects/00FF> ; knora-base:lastModificationDate \"2012-12-12T12:12:12.12Z\"^^xsd:dateTime . images:lastname rdf:type owl:ObjectProperty ; rdfs:comment \"Nachname einer Person\"@de ; rdfs:comment \"Last name of a person\"@en ; rdfs:label \"Name\"@de ; rdfs:subPropertyOf knora-base:hasValue ; knora-base:objectClassConstraint knora-base:TextValue ; knora-base:subjectClassConstraint images:person ; salsah-gui:guiAttribute \"size=32\" ; salsah-gui:guiAttribute \"maxlength=32\" ; salsah-gui:guiElement salsah-gui:SimpleText . # ... } <http://www.knora.org/data/00FF/images> { <http://rdfh.ch/00FF/0cb8286054d5> rdf:type images:bild ; rdfs:label \"1 Alpinismus\" ; images:bearbeiter <http://rdfh.ch/00FF/0cb8286054d5/values/0b80b43aee0f04> ; images:titel <http://rdfh.ch/00FF/0cb8286054d5/values/cea90774ee0f04> ; images:urheber <http://rdfh.ch/00FF/df1260ad43d5> ; images:urheberValue <http://rdfh.ch/00FF/0cb8286054d5/values/e346ff38-6b03-4a27-a11b-b0818a2e5ee3> ; knora-base:attachedToProject <http://rdfh.ch/projects/00FF> ; knora-base:attachedToUser <http://rdfh.ch/users/c266a56709> ; knora-base:creationDate \"2016-03-02T15:05:57Z\"^^xsd:dateTime ; knora-base:hasPermissions \"CR knora-admin:ProjectMember,knora-admin:Creator|V knora-admin:KnownUser|RV knora-admin:UnknownUser\" ; knora-base:hasStillImageFileValue <http://rdfh.ch/00FF/0cb8286054d5/values/c66133bf942f01> ; knora-base:isDeleted false . # ... } <http://www.knora.org/data/admin> { # ... } <http://www.knora.org/data/permissions> { # ... } Project Member Operations Get Project Members by ID Permissions: SystemAdmin / ProjectAdmin Request definition: GET /admin/projects/shortcode/{shortcode}/members GET /admin/projects/shortname/{shortname}/members GET /admin/projects/iri/{iri}/members Description: returns all members part of a project identified through iri, shortname or shortcode Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/shortcode/0001/members' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/shortname/anything/members' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001/members' --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: { \"members\": [ { \"email\": \"anything.user01@example.org\", \"familyName\": \"UserFamilyName\", \"givenName\": \"UserGivenName\", \"groups\": [], \"id\": \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\", \"lang\": \"de\", \"password\": null, \"permissions\": { \"administrativePermissionsPerProject\": { \"http://rdfh.ch/projects/0001\": [ { \"additionalInformation\": null, \"name\": \"ProjectResourceCreateAllPermission\", \"permissionCode\": null } ] }, \"groupsPerProject\": { \"http://rdfh.ch/projects/0001\": [ \"http://www.knora.org/ontology/knora-admin#ProjectMember\" ] } }, \"projects\": [ { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"Anything Project\", \"ontologies\": [ \"http://0.0.0.0:3333/ontology/0001/something/v2\", \"http://0.0.0.0:3333/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": true } ], \"sessionId\": null, \"status\": true, \"token\": null, \"username\": \"anything.user01\" } ] } Errors: 400 Bad Request if the provided ID is not valid. 404 Not Found if no project with the provided ID is found. NB: IRI must be URL-encoded. Get Project Admins by ID Permissions: SystemAdmin / ProjectAdmin Request definition: - GET /admin/projects/shortcode/{shortcode}/admin-members - GET /admin/projects/shortname/{shortname}/admin-members - GET /admin/projects/iri/{iri}/admin-members Description: returns all admin members part of a project identified through iri, shortname or shortcode Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/shortcode/0001/admin-members' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/shortname/anything/admin-members' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001/admin-members' --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: { \"members\": [ { \"email\": \"anything.admin@example.org\", \"familyName\": \"Admin\", \"givenName\": \"Anything\", \"groups\": [], \"id\": \"http://rdfh.ch/users/AnythingAdminUser\", \"lang\": \"de\", \"password\": null, \"permissions\": { \"administrativePermissionsPerProject\": { \"http://rdfh.ch/projects/0001\": [ { \"additionalInformation\": null, \"name\": \"ProjectResourceCreateAllPermission\", \"permissionCode\": null }, { \"additionalInformation\": null, \"name\": \"ProjectAdminAllPermission\", \"permissionCode\": null } ] }, \"groupsPerProject\": { \"http://rdfh.ch/projects/0001\": [ \"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"http://www.knora.org/ontology/knora-admin#ProjectAdmin\" ] } }, \"projects\": [ { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"Anything Project\", \"ontologies\": [ \"http://0.0.0.0:3333/ontology/0001/something/v2\", \"http://0.0.0.0:3333/ontology/0001/sequences/v2\", \"http://0.0.0.0:3333/ontology/0001/freetest/v2\", \"http://0.0.0.0:3333/ontology/0001/minimal/v2\", \"http://0.0.0.0:3333/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": true } ], \"sessionId\": null, \"status\": true, \"token\": null, \"username\": \"anything.admin\" } ] } Errors: 400 Bad Request if the provided ID is not valid. 404 Not Found if no project with the provided ID is found. NB: IRI must be URL-encoded. Other Project Operations Get all Keywords Permissions: Request definition: GET /admin/projects/Keywords Description: returns keywords of all projects as a list Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/Keywords' Example response: { \"keywords\": [ \"Annotation\", \"Arabe\", \"Arabic\", \"Arabisch\", \"Audio\", \"Basel\", \"Basler Fr\u00fchdrucke\", \"Bilder\", \"Bilderfolgen\", \"Contectualisation of images\", \"Cyrillic\", \"Cyrillique\", \"Data and Service Center for the Humanities (DaSCH)\", \"Grec\", \"Greek\", \"Griechisch\", \"Hebrew\", \"Hebr\u00e4isch\", \"Hieroglyphen\", \"H\u00e9breu\", \"Inkunabel\", \"Japanese\", \"Japanisch\", \"Japonais\", \"Keilschrift\", \"Kunsthistorisches Seminar Universit\u00e4t Basel\", \"Kyrillisch\", \"Late Middle Ages\", \"Letterpress Printing\", \"Markup\", \"Narrenschiff\", \"Objekte\", \"Sebastian Brant\", \"Sonderzeichen\", \"Texteigenschaften\", \"Textquellen\", \"Wiegendrucke\", \"XML\", \"arbitrary test data\", \"asdf\", \"audio\", \"caract\u00e8res sp\u00e9ciaux\", \"collection\", \"cuneiform\", \"cun\u00e9iforme\", \"early print\", \"hieroglyphs\", \"hi\u00e9roglyphes\", \"images\", \"incunabula\", \"objects\", \"objets\", \"propri\u00e9t\u00e9s de texte\", \"ship of fools\", \"sources\", \"special characters\", \"textual properties\", \"textual sources\", \"things\" ] } Get Keywords of a Project Permissions: Request definition: - GET /admin/projects/iri/{iri}/Keywords Description: returns the keywords of a single project Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001/Keywords' --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: { \"keywords\": [ \"arbitrary test data\", \"things\" ] } Restricted View Settings Permissions: ProjectAdmin Request definition: - GET /admin/projects/shortcode/{shortcode}/RestrictedViewSettings - GET /admin/projects/shortname/{shortname}/RestrictedViewSettings - GET /admin/projects/iri/{iri}/RestrictedViewSettings Description: returns the project's restricted view settings Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/shortcode/0001/RestrictedViewSettings' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/shortname/anything/RestrictedViewSettings' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001/RestrictedViewSettings' --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: { \"settings\": { \"size\": \"!512,512\", \"watermark\": \"path_to_image\" } } Operates on the following properties: - knora-admin:projectRestrictedViewSize : the IIIF size value - knora-admin:projectRestrictedViewWatermark : the path to the watermark image. Currently not used!","title":"Projects Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/projects/#projects-endpoint","text":"Scope Route Operations Explanation projects /admin/projects GET get all projects projects /admin/projects POST create a project projects /admin/projects/shortname/{shortname} GET get a single project projects /admin/projects/shortcode/{shortcode} GET get a single project projects /admin/projects/iri/{iri} GET get a single project projects /admin/projects/iri/{iri} PUT update a project projects /admin/projects/iri/{iri} DELETE delete a project projects /admin/projects/iri/{iri}/AllData GET get all data of a project project members /admin/projects/shortname/{shortname}/members GET get all project members project members /admin/projects/shortcode/{shortcode}/members GET get all project members project members /admin/projects/iri/{iri}/members GET get all project members project members /admin/projects/shortname/{shortname}/admin-members GET get all project admins project members /admin/projects/shortcode/{shortcode}/admin-members GET get all project admins project members /admin/projects/iri/{iri}/admin-members GET get all project admins keywords /admin/projects/Keywords GET get all project keywords keywords /admin/projects/iri/{iri}/Keywords GET get project keywords of a single project view settings /admin/projects/shortname/{shortname}/RestrictedViewSettings GET get restricted view settings for a project view settings /admin/projects/shortcode/{shortcode}/RestrictedViewSettings GET get restricted view settings for a project view settings /admin/projects/iri/{iri}/RestrictedViewSettings GET get restricted view settings for a project","title":"Projects Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/projects/#project-operations","text":"","title":"Project Operations"},{"location":"DSP-API/03-endpoints/api-admin/projects/#get-all-projects","text":"Permissions: No permissions required Request definition: GET /admin/projects Description: Returns a list of all projects. Example request: curl --request GET --url http://localhost:3333/admin/projects Example response: { \"projects\": [ { \"description\": [ { \"value\": \"A demo project of a collection of images\", \"language\": \"en\" } ], \"id\": \"http://rdfh.ch/projects/00FF\", \"keywords\": [ \"collection\", \"images\" ], \"logo\": null, \"longname\": \"Image Collection Demo\", \"ontologies\": [ \"http://0.0.0.0:3333/ontology/00FF/images/v2\" ], \"selfjoin\": false, \"shortcode\": \"00FF\", \"shortname\": \"images\", \"status\": true }, { // ... } ] }","title":"Get All Projects"},{"location":"DSP-API/03-endpoints/api-admin/projects/#create-a-new-project","text":"Permissions: SystemAdmin Request definition: POST /admin/projects Description: Create a new project. Required payload: shortcode (unique, 4-digits) shortname (unique, it should be in the form of a xsd:NCNAME and it should be URL safe) description (collection of descriptions as strings with language tag) keywords (collection of keywords) status (true, if project is active. false, if project is inactive) selfjoin Optional payload: id (unique, custom DSP IRI, e.g. used for migrating a project from one server to another) longname logo Example request: curl --request POST \\ --url http://localhost:3333/admin/projects \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' \\ --header 'Content-Type: application/json' \\ --data '{ \"shortname\": \"newproject\", \"shortcode\": \"3333\", \"longname\": \"project longname\", \"description\": [ { \"value\": \"project description\", \"language\": \"en\" } ], \"keywords\": [ \"test project\" ], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false }' Example response: { \"project\": { \"description\": [ { \"value\": \"project description\", \"language\": \"en\" } ], \"id\": \"http://rdfh.ch/projects/3333\", \"keywords\": [ \"test project\" ], \"logo\": \"/fu/bar/baz.jpg\", \"longname\": \"project longname\", \"ontologies\": [], \"selfjoin\": false, \"shortcode\": \"3333\", \"shortname\": \"newproject\", \"status\": true } } Errors: 400 Bad Request if the project already exists or any of the provided properties is invalid. 401 Unauthorized if authorization failed.","title":"Create a New Project"},{"location":"DSP-API/03-endpoints/api-admin/projects/#default-set-of-permissions-for-a-new-project","text":"When a new project is created, following default permissions are added to its admins and members: ProjectAdmin group receives an administrative permission to do all project level operations and to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForAdmin ProjectAdmin group also gets a default object access permission to change rights (which includes delete, modify, view, and restricted view permissions) of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForAdmin ProjectMember group receives an administrative permission to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForMember ProjectMember group also gets a default object access permission to modify (which includes view and restricted view permissions) of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForMember","title":"Default set of permissions for a new project:"},{"location":"DSP-API/03-endpoints/api-admin/projects/#get-project-by-id","text":"The ID can be shortcode, shortname or IRI. Permissions: No permissions required Request definition: GET /admin/projects/shortcode/{shortcode} GET /admin/projects/shortname/{shortname} GET /admin/projects/iri/{iri} Description: Returns a single project identified by shortcode, shortname or IRI. Example request: curl --request GET --url http://localhost:3333/admin/projects/shortcode/0001 curl --request GET --url http://localhost:3333/admin/projects/shortname/anything curl --request GET --url \\ http://localhost:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 Example response: { \"project\": { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"Anything Project\", \"ontologies\": [ \"http://0.0.0.0:3333/ontology/0001/something/v2\", \"http://0.0.0.0:3333/ontology/0001/sequences/v2\", \"http://0.0.0.0:3333/ontology/0001/freetest/v2\", \"http://0.0.0.0:3333/ontology/0001/minimal/v2\", \"http://0.0.0.0:3333/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": true } } Errors: 400 Bad Request if the provided ID is not valid. 404 Not Found if no project with the provided ID is found. NB: IRI must be URL-encoded.","title":"Get Project by ID"},{"location":"DSP-API/03-endpoints/api-admin/projects/#update-project-information","text":"Permissions: SystemAdmin / ProjectAdmin Request definition: PUT /admin/projects/iri/{iri} Description: Update a project identified by its IRI. Payload: The following properties can be changed: longname description keywords logo status selfjoin Example request: curl --request PUT \\ --url http://localhost:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' \\ --header 'Content-Type: application/json' \\ --data '{ \"longname\": \"other longname\" }' Example response: { \"project\": { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"other longname\", \"ontologies\": [ \"http://api.knora.org/ontology/0001/something/v2\", \"http://api.knora.org/ontology/0001/sequences/v2\", \"http://api.knora.org/ontology/0001/freetest/v2\", \"http://api.knora.org/ontology/0001/minimal/v2\", \"http://api.knora.org/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": true } } Errors: 400 Bad Request if the provided IRI is not valid. if the provided payload is not valid. 404 Not Found if no project with the provided IRI is found.","title":"Update Project Information"},{"location":"DSP-API/03-endpoints/api-admin/projects/#delete-a-project","text":"Permissions: SystemAdmin / ProjectAdmin Request definition: DELETE /admin/projects/iri/{iri} Description: Mark a project as deleted (by setting the status flag to false ). curl --request DELETE \\ --url http://localhost:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' \\ --header 'Content-Type: application/json' Example response: { \"project\": { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"other longname\", \"ontologies\": [ \"http://api.knora.org/ontology/0001/something/v2\", \"http://api.knora.org/ontology/0001/sequences/v2\", \"http://api.knora.org/ontology/0001/freetest/v2\", \"http://api.knora.org/ontology/0001/minimal/v2\", \"http://api.knora.org/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": false } } Errors: 400 Bad Request if the provided IRI is not valid. 404 Not Found if no project with the provided IRI is found.","title":"Delete a Project"},{"location":"DSP-API/03-endpoints/api-admin/projects/#get-all-data-of-a-project","text":"Permissions: ProjectAdmin / SystemAdmin Request definition: POST /admin/projects/iri/{iri}/AllData Description: Gets all data of a project as a TriG file (ontologies, resource data, admin data, and permissions). Example request: curl --request GET \\ --url http://localhost:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F00FF/AllData \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: @prefix images: <http://www.knora.org/ontology/00FF/images#> . @prefix knora-admin: <http://www.knora.org/ontology/knora-admin#> . @prefix knora-base: <http://www.knora.org/ontology/knora-base#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix salsah-gui: <http://www.knora.org/ontology/salsah-gui#> . @prefix standoff: <http://www.knora.org/ontology/standoff#> . @prefix xml: <http://www.w3.org/XML/1998/namespace> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . <http://www.knora.org/ontology/00FF/images> { <http://www.knora.org/ontology/00FF/images> rdf:type owl:Ontology ; rdfs:label \"The images demo ontology\" ; knora-base:attachedToProject <http://rdfh.ch/projects/00FF> ; knora-base:lastModificationDate \"2012-12-12T12:12:12.12Z\"^^xsd:dateTime . images:lastname rdf:type owl:ObjectProperty ; rdfs:comment \"Nachname einer Person\"@de ; rdfs:comment \"Last name of a person\"@en ; rdfs:label \"Name\"@de ; rdfs:subPropertyOf knora-base:hasValue ; knora-base:objectClassConstraint knora-base:TextValue ; knora-base:subjectClassConstraint images:person ; salsah-gui:guiAttribute \"size=32\" ; salsah-gui:guiAttribute \"maxlength=32\" ; salsah-gui:guiElement salsah-gui:SimpleText . # ... } <http://www.knora.org/data/00FF/images> { <http://rdfh.ch/00FF/0cb8286054d5> rdf:type images:bild ; rdfs:label \"1 Alpinismus\" ; images:bearbeiter <http://rdfh.ch/00FF/0cb8286054d5/values/0b80b43aee0f04> ; images:titel <http://rdfh.ch/00FF/0cb8286054d5/values/cea90774ee0f04> ; images:urheber <http://rdfh.ch/00FF/df1260ad43d5> ; images:urheberValue <http://rdfh.ch/00FF/0cb8286054d5/values/e346ff38-6b03-4a27-a11b-b0818a2e5ee3> ; knora-base:attachedToProject <http://rdfh.ch/projects/00FF> ; knora-base:attachedToUser <http://rdfh.ch/users/c266a56709> ; knora-base:creationDate \"2016-03-02T15:05:57Z\"^^xsd:dateTime ; knora-base:hasPermissions \"CR knora-admin:ProjectMember,knora-admin:Creator|V knora-admin:KnownUser|RV knora-admin:UnknownUser\" ; knora-base:hasStillImageFileValue <http://rdfh.ch/00FF/0cb8286054d5/values/c66133bf942f01> ; knora-base:isDeleted false . # ... } <http://www.knora.org/data/admin> { # ... } <http://www.knora.org/data/permissions> { # ... }","title":"Get all Data of a Project"},{"location":"DSP-API/03-endpoints/api-admin/projects/#project-member-operations","text":"","title":"Project Member Operations"},{"location":"DSP-API/03-endpoints/api-admin/projects/#get-project-members-by-id","text":"Permissions: SystemAdmin / ProjectAdmin Request definition: GET /admin/projects/shortcode/{shortcode}/members GET /admin/projects/shortname/{shortname}/members GET /admin/projects/iri/{iri}/members Description: returns all members part of a project identified through iri, shortname or shortcode Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/shortcode/0001/members' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/shortname/anything/members' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001/members' --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: { \"members\": [ { \"email\": \"anything.user01@example.org\", \"familyName\": \"UserFamilyName\", \"givenName\": \"UserGivenName\", \"groups\": [], \"id\": \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\", \"lang\": \"de\", \"password\": null, \"permissions\": { \"administrativePermissionsPerProject\": { \"http://rdfh.ch/projects/0001\": [ { \"additionalInformation\": null, \"name\": \"ProjectResourceCreateAllPermission\", \"permissionCode\": null } ] }, \"groupsPerProject\": { \"http://rdfh.ch/projects/0001\": [ \"http://www.knora.org/ontology/knora-admin#ProjectMember\" ] } }, \"projects\": [ { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"Anything Project\", \"ontologies\": [ \"http://0.0.0.0:3333/ontology/0001/something/v2\", \"http://0.0.0.0:3333/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": true } ], \"sessionId\": null, \"status\": true, \"token\": null, \"username\": \"anything.user01\" } ] } Errors: 400 Bad Request if the provided ID is not valid. 404 Not Found if no project with the provided ID is found. NB: IRI must be URL-encoded.","title":"Get Project Members by ID"},{"location":"DSP-API/03-endpoints/api-admin/projects/#get-project-admins-by-id","text":"Permissions: SystemAdmin / ProjectAdmin Request definition: - GET /admin/projects/shortcode/{shortcode}/admin-members - GET /admin/projects/shortname/{shortname}/admin-members - GET /admin/projects/iri/{iri}/admin-members Description: returns all admin members part of a project identified through iri, shortname or shortcode Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/shortcode/0001/admin-members' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/shortname/anything/admin-members' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001/admin-members' --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: { \"members\": [ { \"email\": \"anything.admin@example.org\", \"familyName\": \"Admin\", \"givenName\": \"Anything\", \"groups\": [], \"id\": \"http://rdfh.ch/users/AnythingAdminUser\", \"lang\": \"de\", \"password\": null, \"permissions\": { \"administrativePermissionsPerProject\": { \"http://rdfh.ch/projects/0001\": [ { \"additionalInformation\": null, \"name\": \"ProjectResourceCreateAllPermission\", \"permissionCode\": null }, { \"additionalInformation\": null, \"name\": \"ProjectAdminAllPermission\", \"permissionCode\": null } ] }, \"groupsPerProject\": { \"http://rdfh.ch/projects/0001\": [ \"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"http://www.knora.org/ontology/knora-admin#ProjectAdmin\" ] } }, \"projects\": [ { \"description\": [ { \"value\": \"Anything Project\" } ], \"id\": \"http://rdfh.ch/projects/0001\", \"keywords\": [ \"arbitrary test data\", \"things\" ], \"logo\": null, \"longname\": \"Anything Project\", \"ontologies\": [ \"http://0.0.0.0:3333/ontology/0001/something/v2\", \"http://0.0.0.0:3333/ontology/0001/sequences/v2\", \"http://0.0.0.0:3333/ontology/0001/freetest/v2\", \"http://0.0.0.0:3333/ontology/0001/minimal/v2\", \"http://0.0.0.0:3333/ontology/0001/anything/v2\" ], \"selfjoin\": false, \"shortcode\": \"0001\", \"shortname\": \"anything\", \"status\": true } ], \"sessionId\": null, \"status\": true, \"token\": null, \"username\": \"anything.admin\" } ] } Errors: 400 Bad Request if the provided ID is not valid. 404 Not Found if no project with the provided ID is found. NB: IRI must be URL-encoded.","title":"Get Project Admins by ID"},{"location":"DSP-API/03-endpoints/api-admin/projects/#other-project-operations","text":"","title":"Other Project Operations"},{"location":"DSP-API/03-endpoints/api-admin/projects/#get-all-keywords","text":"Permissions: Request definition: GET /admin/projects/Keywords Description: returns keywords of all projects as a list Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/Keywords' Example response: { \"keywords\": [ \"Annotation\", \"Arabe\", \"Arabic\", \"Arabisch\", \"Audio\", \"Basel\", \"Basler Fr\u00fchdrucke\", \"Bilder\", \"Bilderfolgen\", \"Contectualisation of images\", \"Cyrillic\", \"Cyrillique\", \"Data and Service Center for the Humanities (DaSCH)\", \"Grec\", \"Greek\", \"Griechisch\", \"Hebrew\", \"Hebr\u00e4isch\", \"Hieroglyphen\", \"H\u00e9breu\", \"Inkunabel\", \"Japanese\", \"Japanisch\", \"Japonais\", \"Keilschrift\", \"Kunsthistorisches Seminar Universit\u00e4t Basel\", \"Kyrillisch\", \"Late Middle Ages\", \"Letterpress Printing\", \"Markup\", \"Narrenschiff\", \"Objekte\", \"Sebastian Brant\", \"Sonderzeichen\", \"Texteigenschaften\", \"Textquellen\", \"Wiegendrucke\", \"XML\", \"arbitrary test data\", \"asdf\", \"audio\", \"caract\u00e8res sp\u00e9ciaux\", \"collection\", \"cuneiform\", \"cun\u00e9iforme\", \"early print\", \"hieroglyphs\", \"hi\u00e9roglyphes\", \"images\", \"incunabula\", \"objects\", \"objets\", \"propri\u00e9t\u00e9s de texte\", \"ship of fools\", \"sources\", \"special characters\", \"textual properties\", \"textual sources\", \"things\" ] }","title":"Get all Keywords"},{"location":"DSP-API/03-endpoints/api-admin/projects/#get-keywords-of-a-project","text":"Permissions: Request definition: - GET /admin/projects/iri/{iri}/Keywords Description: returns the keywords of a single project Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001/Keywords' --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: { \"keywords\": [ \"arbitrary test data\", \"things\" ] }","title":"Get Keywords of a Project"},{"location":"DSP-API/03-endpoints/api-admin/projects/#restricted-view-settings","text":"Permissions: ProjectAdmin Request definition: - GET /admin/projects/shortcode/{shortcode}/RestrictedViewSettings - GET /admin/projects/shortname/{shortname}/RestrictedViewSettings - GET /admin/projects/iri/{iri}/RestrictedViewSettings Description: returns the project's restricted view settings Example request: curl --request GET 'http://0.0.0.0:3333/admin/projects/shortcode/0001/RestrictedViewSettings' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/shortname/anything/RestrictedViewSettings' \\ --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' curl --request GET 'http://0.0.0.0:3333/admin/projects/iri/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001/RestrictedViewSettings' --header 'Authorization: Basic cm9vdEBleGFtcGxlLmNvbTp0ZXN0' Example response: { \"settings\": { \"size\": \"!512,512\", \"watermark\": \"path_to_image\" } } Operates on the following properties: - knora-admin:projectRestrictedViewSize : the IIIF size value - knora-admin:projectRestrictedViewWatermark : the path to the watermark image. Currently not used!","title":"Restricted View Settings"},{"location":"DSP-API/03-endpoints/api-admin/stores/","text":"Stores Endpoint This endpoint allows manipulation of the triplestore content. POST admin/store/ResetTriplestoreContent resets the triplestore content, given that the allowReloadOverHttp configuration flag is set to true . This route is mostly used in tests.","title":"Stores Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/stores/#stores-endpoint","text":"This endpoint allows manipulation of the triplestore content. POST admin/store/ResetTriplestoreContent resets the triplestore content, given that the allowReloadOverHttp configuration flag is set to true . This route is mostly used in tests.","title":"Stores Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/users/","text":"Users Endpoint Endpoint Overview User Operations: GET: /admin/users : return all users GET: /admin/users/[iri | email | username]/<identifier> : return single user identified by [IRI | email | username] POST: /admin/users/ : create new user PUT: /admin/users/iri/<userIri>/BasicUserInformation : update user's basic user information PUT: /admin/users/iri/<userIri>/Password : update user's password PUT: /admin/users/iri/<userIri>/Status : update user's status DELETE: /admin/users/iri/<userIri> : delete user (set status to false) User's project membership operations GET: /admin/users/iri/<userIri>/project-memberships : get user's project memberships POST: /admin/users/iri/<userIri>/project-memberships/<projectIri> : add user to project (to ProjectMember group) DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> : remove user from project (to ProjectMember group) User's group membership operations GET: /admin/users/iri/<userIri>/project-admin-memberships : get user's ProjectAdmin group memberships POST: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : add user to ProjectAdmin group DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : remove user from ProjectAdmin group GET: /admin/users/iri/<userIri>/group-memberships : get user's normal group memberships POST: /admin/users/iri/<userIri>/group-memberships/<groupIri> : add user to normal group DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> : remove user from normal group PUT: /admin/users/iri/<userIri>/SystemAdmin : Add/remove user to/from SystemAdmin group User Operations Get users Required permission: SystemAdmin GET: /admin/users Get user Required permission: SystemAdmin / self: for getting all properties All other users: for getting only the public properties ( givenName and familyName ) GET: /admin/users/[iri | email | username ]/<identifier> Create user Required permission: none, self-registration is allowed Required information: email (unique), given name, family name, password, status, systemAdmin Username restrictions: 4 - 50 characters long Only contains alphanumeric characters, underscore and dot. Underscore and dot can't be at the end or start of a username Underscore or dot can't be used multiple times in a row Returns information about the newly created user TypeScript Docs: userFormats - CreateUserApiRequestV1 POST: /admin/users BODY: { \"email\" : \"donald.duck@example.org\" , \"givenName\" : \"Donald\" , \"familyName\" : \"Duck\" , \"username\" : \"donald.duck\" , \"password\" : \"test\" , \"status\" : true , \"lang\" : \"en\" , \"systemAdmin\" : false } Additionally, each user can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/users/FnjFfIQFVDvI7ex8zSyUyw\" , \"email\" : \"donald.duck@example.org\" , \"givenName\" : \"Donald\" , \"familyName\" : \"Duck\" , \"username\" : \"donald.duck\" , \"password\" : \"test\" , \"status\" : true , \"lang\" : \"en\" , \"systemAdmin\" : false } Update basic user information** Required permission: SystemAdmin / self Changeable information: username, email, given name, family name, password, status, SystemAdmin membership TypeScript Docs: userFormats - ChangeUserApiRequestADM PUT: /admin/users/iri/<userIri>/BasicUserInformation BODY: { \"username\" : \"donald.big.duck\" , \"email\" : \"donald.big.duck@example.org\" , \"givenName\" : \"Big Donald\" , \"familyName\" : \"Duckmann\" , \"lang\" : \"de\" } Update user's password Required permission: SystemAdmin / self Changeable information: password PUT: /admin/users/iri/<userIri>/Password BODY: { \"requesterPassword\" : \"test\" , \"newPassword\" : \"test1234\" } Delete user Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . PUT: /admin/users/iri/<userIri>/Status BODY: { \"status\": false // true or false } Delete user (-\\update user)** Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . DELETE: /admin/users/iri/<userIri> BODY: empty User's project membership operations Get user's project memberships GET: /admin/users/iri/<userIri>/project-memberships Add/remove user to/from project Required permission: SystemAdmin / ProjectAdmin / self (if project self-assignment is enabled) Required information: project IRI, user IRI Effects: knora-base:isInProject user property POST / DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> BODY: empty Note: When a user is project admin in the same project, his project admin membership will be removed as well. User's group membership operations Get user's project admin memberships GET: /admin/users/iri/<userIri>/project-admin-memberships Add/remove user to/from project admin group Required permission: SystemAdmin / ProjectAdmin Required information: project IRI, user IRI Effects: knora-base:isInProjectAdminGroup user property POST / DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> BODY: empty Note: In order to add a user to a project admin group, the user needs to be member of that project. Get user's group memberships** GET: /admin/users/iri/<userIri>/group-memberships Add/remove user to/from 'normal' group (not SystemAdmin or ProjectAdmin ) Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) / User (if group self-assignment is enabled) Required information: group IRI, user IRI Effects: knora-base:isInGroup POST / DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> BODY: empty Add/remove user to/from system admin group Required permission: SystemAdmin / self Effects property: knora-base:isInSystemAdminGroup with value true or false PUT: /admin/users/iri/<userIri>/SystemAdmin BODY: { \"systemAdmin\": false } Example Data The following is an example for user information stored in the admin named graph: <http://rdfh.ch/users/c266a56709> rdf:type knora-admin:User ; knora-admin:username \"user01.user1\"^^xsd:string ; knora-admin:email \"user01.user1@example.com\"^^xsd:string ; knora-admin:givenName \"User01\"^^xsd:string ; knora-admin:familyName \"User\"^^xsd:string ; knora-admin:password \"$e0801$FGl9FDIWw+D83OeNPGmD9u2VTqIkJopIQECgmb2DSWQLS0TeKSvYoWAkbEv6KxePPlCI3CP9MmVHuvnWv8/kag==$mlegCYdGXt+ghuo8i0rLjgOiNnGDW604Q5g/v7zwBPU=\"^^xsd:string ; knora-admin:preferredLanguage \"de\"^^xsd:string ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:isInProject <http://rdfh.ch/projects/00FF> ; knora-admin:isInSystemAdminGroup \"false\"^^xsd:boolean ; knora-admin:isInProjectAdminGroup <http://rdfh.ch/projects/00FF> .","title":"Users Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/users/#users-endpoint","text":"","title":"Users Endpoint"},{"location":"DSP-API/03-endpoints/api-admin/users/#endpoint-overview","text":"User Operations: GET: /admin/users : return all users GET: /admin/users/[iri | email | username]/<identifier> : return single user identified by [IRI | email | username] POST: /admin/users/ : create new user PUT: /admin/users/iri/<userIri>/BasicUserInformation : update user's basic user information PUT: /admin/users/iri/<userIri>/Password : update user's password PUT: /admin/users/iri/<userIri>/Status : update user's status DELETE: /admin/users/iri/<userIri> : delete user (set status to false) User's project membership operations GET: /admin/users/iri/<userIri>/project-memberships : get user's project memberships POST: /admin/users/iri/<userIri>/project-memberships/<projectIri> : add user to project (to ProjectMember group) DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> : remove user from project (to ProjectMember group) User's group membership operations GET: /admin/users/iri/<userIri>/project-admin-memberships : get user's ProjectAdmin group memberships POST: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : add user to ProjectAdmin group DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : remove user from ProjectAdmin group GET: /admin/users/iri/<userIri>/group-memberships : get user's normal group memberships POST: /admin/users/iri/<userIri>/group-memberships/<groupIri> : add user to normal group DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> : remove user from normal group PUT: /admin/users/iri/<userIri>/SystemAdmin : Add/remove user to/from SystemAdmin group","title":"Endpoint Overview"},{"location":"DSP-API/03-endpoints/api-admin/users/#user-operations","text":"","title":"User Operations"},{"location":"DSP-API/03-endpoints/api-admin/users/#get-users","text":"Required permission: SystemAdmin GET: /admin/users","title":"Get users"},{"location":"DSP-API/03-endpoints/api-admin/users/#get-user","text":"Required permission: SystemAdmin / self: for getting all properties All other users: for getting only the public properties ( givenName and familyName ) GET: /admin/users/[iri | email | username ]/<identifier>","title":"Get user"},{"location":"DSP-API/03-endpoints/api-admin/users/#create-user","text":"Required permission: none, self-registration is allowed Required information: email (unique), given name, family name, password, status, systemAdmin Username restrictions: 4 - 50 characters long Only contains alphanumeric characters, underscore and dot. Underscore and dot can't be at the end or start of a username Underscore or dot can't be used multiple times in a row Returns information about the newly created user TypeScript Docs: userFormats - CreateUserApiRequestV1 POST: /admin/users BODY: { \"email\" : \"donald.duck@example.org\" , \"givenName\" : \"Donald\" , \"familyName\" : \"Duck\" , \"username\" : \"donald.duck\" , \"password\" : \"test\" , \"status\" : true , \"lang\" : \"en\" , \"systemAdmin\" : false } Additionally, each user can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/users/FnjFfIQFVDvI7ex8zSyUyw\" , \"email\" : \"donald.duck@example.org\" , \"givenName\" : \"Donald\" , \"familyName\" : \"Duck\" , \"username\" : \"donald.duck\" , \"password\" : \"test\" , \"status\" : true , \"lang\" : \"en\" , \"systemAdmin\" : false }","title":"Create user"},{"location":"DSP-API/03-endpoints/api-admin/users/#update-basic-user-information","text":"Required permission: SystemAdmin / self Changeable information: username, email, given name, family name, password, status, SystemAdmin membership TypeScript Docs: userFormats - ChangeUserApiRequestADM PUT: /admin/users/iri/<userIri>/BasicUserInformation BODY: { \"username\" : \"donald.big.duck\" , \"email\" : \"donald.big.duck@example.org\" , \"givenName\" : \"Big Donald\" , \"familyName\" : \"Duckmann\" , \"lang\" : \"de\" }","title":"Update basic user information**"},{"location":"DSP-API/03-endpoints/api-admin/users/#update-users-password","text":"Required permission: SystemAdmin / self Changeable information: password PUT: /admin/users/iri/<userIri>/Password BODY: { \"requesterPassword\" : \"test\" , \"newPassword\" : \"test1234\" }","title":"Update user's password"},{"location":"DSP-API/03-endpoints/api-admin/users/#delete-user","text":"Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . PUT: /admin/users/iri/<userIri>/Status BODY: { \"status\": false // true or false }","title":"Delete user"},{"location":"DSP-API/03-endpoints/api-admin/users/#delete-user-update-user","text":"Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . DELETE: /admin/users/iri/<userIri> BODY: empty","title":"Delete user (-\\update user)**"},{"location":"DSP-API/03-endpoints/api-admin/users/#users-project-membership-operations","text":"","title":"User's project membership operations"},{"location":"DSP-API/03-endpoints/api-admin/users/#get-users-project-memberships","text":"GET: /admin/users/iri/<userIri>/project-memberships","title":"Get user's project memberships"},{"location":"DSP-API/03-endpoints/api-admin/users/#addremove-user-tofrom-project","text":"Required permission: SystemAdmin / ProjectAdmin / self (if project self-assignment is enabled) Required information: project IRI, user IRI Effects: knora-base:isInProject user property POST / DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> BODY: empty Note: When a user is project admin in the same project, his project admin membership will be removed as well.","title":"Add/remove user to/from project"},{"location":"DSP-API/03-endpoints/api-admin/users/#users-group-membership-operations","text":"","title":"User's group membership operations"},{"location":"DSP-API/03-endpoints/api-admin/users/#get-users-project-admin-memberships","text":"GET: /admin/users/iri/<userIri>/project-admin-memberships","title":"Get user's project admin memberships"},{"location":"DSP-API/03-endpoints/api-admin/users/#addremove-user-tofrom-project-admin-group","text":"Required permission: SystemAdmin / ProjectAdmin Required information: project IRI, user IRI Effects: knora-base:isInProjectAdminGroup user property POST / DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> BODY: empty Note: In order to add a user to a project admin group, the user needs to be member of that project.","title":"Add/remove user to/from project admin group"},{"location":"DSP-API/03-endpoints/api-admin/users/#get-users-group-memberships","text":"GET: /admin/users/iri/<userIri>/group-memberships","title":"Get user's group memberships**"},{"location":"DSP-API/03-endpoints/api-admin/users/#addremove-user-tofrom-normal-group-not-systemadmin-or-projectadmin","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) / User (if group self-assignment is enabled) Required information: group IRI, user IRI Effects: knora-base:isInGroup POST / DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> BODY: empty","title":"Add/remove user to/from 'normal' group (not SystemAdmin or ProjectAdmin)"},{"location":"DSP-API/03-endpoints/api-admin/users/#addremove-user-tofrom-system-admin-group","text":"Required permission: SystemAdmin / self Effects property: knora-base:isInSystemAdminGroup with value true or false PUT: /admin/users/iri/<userIri>/SystemAdmin BODY: { \"systemAdmin\": false }","title":"Add/remove user to/from system admin group"},{"location":"DSP-API/03-endpoints/api-admin/users/#example-data","text":"The following is an example for user information stored in the admin named graph: <http://rdfh.ch/users/c266a56709> rdf:type knora-admin:User ; knora-admin:username \"user01.user1\"^^xsd:string ; knora-admin:email \"user01.user1@example.com\"^^xsd:string ; knora-admin:givenName \"User01\"^^xsd:string ; knora-admin:familyName \"User\"^^xsd:string ; knora-admin:password \"$e0801$FGl9FDIWw+D83OeNPGmD9u2VTqIkJopIQECgmb2DSWQLS0TeKSvYoWAkbEv6KxePPlCI3CP9MmVHuvnWv8/kag==$mlegCYdGXt+ghuo8i0rLjgOiNnGDW604Q5g/v7zwBPU=\"^^xsd:string ; knora-admin:preferredLanguage \"de\"^^xsd:string ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:isInProject <http://rdfh.ch/projects/00FF> ; knora-admin:isInSystemAdminGroup \"false\"^^xsd:boolean ; knora-admin:isInProjectAdminGroup <http://rdfh.ch/projects/00FF> .","title":"Example Data"},{"location":"DSP-API/03-endpoints/api-util/version/","text":"Version The version endpoint provides the versions of the used components in the Knora-stack. The response has the type application/json and contains the following information: name: has the value \"version\" version numbers for the following components: akkaHttp gdbFree gdbSE sbt scala sipi webapi Example request GET /version Example response { \"akkaHttp\" : \"10.1.7\" , \"gdbFree\" : \"8.10.0-free\" , \"gdbSE\" : \"8.5.0-se\" , \"name\" : \"version\" , \"sbt\" : \"1.2.8\" , \"scala\" : \"2.12.8\" , \"sipi\" : \"v2.0.1\" , \"webapi\" : \"10.0.0-7-gc5a72b3-SNAPSHOT\" }","title":"Version"},{"location":"DSP-API/03-endpoints/api-util/version/#version","text":"The version endpoint provides the versions of the used components in the Knora-stack. The response has the type application/json and contains the following information: name: has the value \"version\" version numbers for the following components: akkaHttp gdbFree gdbSE sbt scala sipi webapi","title":"Version"},{"location":"DSP-API/03-endpoints/api-util/version/#example-request","text":"GET /version","title":"Example request"},{"location":"DSP-API/03-endpoints/api-util/version/#example-response","text":"{ \"akkaHttp\" : \"10.1.7\" , \"gdbFree\" : \"8.10.0-free\" , \"gdbSE\" : \"8.5.0-se\" , \"name\" : \"version\" , \"sbt\" : \"1.2.8\" , \"scala\" : \"2.12.8\" , \"sipi\" : \"v2.0.1\" , \"webapi\" : \"10.0.0-7-gc5a72b3-SNAPSHOT\" }","title":"Example response"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/","text":"Adding Resources To create a resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the resources path segment: HTTP POST to http://host/v1/resources Unlike in the case of GET requests, the request body consists of JSON describing the resource to be created. Creating resources requires authentication since only known users may add resources. Adding Resources Without Image Files The format of the JSON used to create a resource without an image file is described in the TypeScript interface createResourceWithoutRepresentationRequest in module createResourceFormats . It requires the IRI of the resource class the new resource belongs to, a label describing the new resource, the IRI of the project the new resource belongs to, and the properties to be assigned to the new resource. The request header's content type has to be set to application/json . Adding Resources with Image Files The first step is to upload an image file to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The TOKEN is the sid returned by Knora in response to the client's login request (see Authentication ). The request must contain a body part providing the file as well as a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi will then convert the uploaded image file to JPEG 2000 format and store it in a temporary location. If this is successful, it will return a JSON response that looks something like this: { \"uploadedFiles\" : [{ \"originalFilename\" : \"manuscript-1234-page-1.tiff\" , \"internalFilename\" : \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" , \"temporaryBaseIIIFUrl\" : \"http://sipihost/tmp\" }] } This provides: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file The client may now wish to get a thumbnail of the uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding the filename and IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image whose width and height are at most 128 pixels wide, you would request http://sipihost/tmp/3UIsXH9bP0j-BV0D4sN51Xz.jp2/full/!128,128/0/default.jpg . The request to Knora works similarly to Adding Resources Without Image Files , with the addition of file , whose value is the internalFilename that Sipi returned. See the TypeScript interface createResourceWithRepresentationRequest in module createResourceFormats for details. The request header's content type must be set to application/json . Response to a Resource Creation When a resource has been successfully created, Knora sends back a JSON containing the new resource's IRI ( res_id ) and its properties. The resource IRI identifies the resource and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface createResourceResponse in module createResourceFormats . Changing a Resource's Label A resource's label can be changed by making a PUT request to the path segments resources/label . The resource's IRI has to be provided in the URL (as its last segment). The new label has to submitted as JSON in the HTTP request's body. HTTP PUT to http://host/v1/resources/label/resourceIRI The JSON format of the request is described in the TypeScript interface changeResourceLabelRequest in module createResourceFormats . The response is described in the TypeScript interface changeResourceLabelResponse in module createResourceFormats . Bulk Import If you have a large amount of data to import into Knora, it can be more convenient to use the bulk import feature than to create resources one by one. In a bulk import operation, you submit an XML document to Knora, describing multiple resources to be created. This is especially useful if the resources to be created have links to one another. Knora checks the entire request for consistency as as a whole, and performs the update in a single database transaction. Only system or project administrators may use the bulk import. The procedure for using this feature is as follows (see the example below ). Make an HTTP GET request to Knora to get XML schemas describing the XML to be provided for the import. If you are importing image files, upload files to Sipi . Generate an XML import document representing the data to be imported, following the Knora import schemas that were generated in step 1. You will probably want to write a script to do this. Knora is not involved in this step. If you are also importing image files, this XML document needs to contain the filenames that Sipi returned for the files you uploaded in step 2. Validate your XML import document , using an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen . This will help ensure that the data you submit to Knora is correct. Knora is not involved in this step. Submit the XML import document to Knora . In this procedure, the person responsible for generating the XML import data need not be familiar with RDF or with the ontologies involved. When Knora receives an XML import, it validates it first using the relevant XML schemas, and then using the same internal checks that it performs when creating any resource. The details of the XML import format are illustrated in the following examples. Bulk Import Example Suppose we have a project with existing data (but no image files), which we want to import into Knora. We have created an ontology called http://www.knora.org/ontology/0801/biblio for the project, and this ontology also uses definitions from another ontology, called http://www.knora.org/ontology/0801/beol . 1. Get XML Schemas To get XML schemas for an import, we use the following route, specifying the (URL-encoded) IRI of our project's main ontology (in this case http://www.knora.org/ontology/0801/biblio ): HTTP GET to http://host/v1/resources/xmlimportschemas/ontologyIRI In our example, the URL could be: http://localhost:3333/v1/resources/xmlimportschemas/http%3A%2F%2Fwww.knora.org%2Fontology%2F0801%2Fbiblio This returns a Zip archive called p0801-biblio-xml-schemas.zip , containing three files: p0801-biblio.xsd : The schema for our main ontology. p0801-beol.xsd : A schema for another ontology that our main ontology depends on. knoraXmlImport.xsd : The standard Knora XML import schema, used by all XML imports. 2. Upload Files to Sipi See Upload Files to Sipi in the DSP-API v2 documentation. 3. Generate XML Import Document We now convert our existing data to XML, probably by writing a custom script. The resulting XML import document could look like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol= \"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport= \"http://api.knora.org/ontology/knoraXmlImport/v1#\" > <p0801-beol:person id= \"abel\" > <knoraXmlImport:label> Niels Henrik Abel </knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType= \"richtext_value\" > Abel </p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType= \"richtext_value\" > Niels Henrik </p0801-beol:hasGivenName> <p0801-beol:personHasTitle knoraType= \"richtext_value\" lang= \"en\" > Sir </p0801-beol:personHasTitle> </p0801-beol:person> <p0801-beol:person id= \"holmes\" > <knoraXmlImport:label> Sherlock Holmes </knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType= \"richtext_value\" > Holmes </p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType= \"richtext_value\" > Sherlock </p0801-beol:hasGivenName> </p0801-beol:person> <p0801-biblio:Journal id= \"math_intelligencer\" > <knoraXmlImport:label> Math Intelligencer </knoraXmlImport:label> <p0801-biblio:hasName knoraType= \"richtext_value\" > Math Intelligencer </p0801-biblio:hasName> </p0801-biblio:Journal> <p0801-biblio:JournalArticle id= \"strings_in_the_16th_and_17th_centuries\" creationDate= \"2019-01-09T15:45:54Z\" > <knoraXmlImport:label> Strings in the 16th and 17th Centuries </knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType= \"richtext_value\" mapping_id= \"http://rdfh.ch/standoff/mappings/StandardMapping\" > <text xmlns= \"\" > The most <strong> interesting </strong> article in <a class= \"salsah-link\" href= \"ref:math_intelligencer\" > Math Intelligencer </a> . </text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType= \"richtext_value\" > 73 </p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType= \"link_value\" target= \"math_intelligencer\" linkType= \"ref\" /> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType= \"richtext_value\" > 27 </p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType= \"link_value\" linkType= \"ref\" target= \"abel\" /> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType= \"link_value\" linkType= \"ref\" target= \"holmes\" /> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType= \"date_value\" > GREGORIAN:1976 </p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType= \"richtext_value\" lang= \"en\" > Strings in the 16th and 17th Centuries </p0801-biblio:publicationHasTitle> <p0801-biblio:publicationHasTitle knoraType= \"richtext_value\" > An alternate title </p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType= \"richtext_value\" > 48 </p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> This illustrates several aspects of XML imports: The root XML element must be knoraXmlImport:resources . There is an XML namespace corresponding each ontology used in the import. These namespaces can be found in the XML schema files returned by Knora. We have copied and pasted xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" from the main XML schema, p0801-biblio.xsd . This enables the Knora API server to identify the main ontology we are using. We have used xsi:schemaLocation to indicate the main schema's namespace and filename. If we put our XML document in the same directory as the schemas, and we run an XML validator to check the XML, it should load the schemas. The child elements of knoraXmlImport:resources represent resources to be created. The order of these elements is unimportant. Each resource must have an ID, which must be an XML NCName , and must be unique within the file. These IDs are used only during the import, and will not be stored in the triplestore. Each resource can optionally have a creationDate attribute, which can be an xsd:dateTime or an xsd:dateTimeStamp . If creationDate is not supplied, the current time is used. The first child element of each resource must be a knoraXmlImport:label , which will be stored as the resource's rdfs:label . Optionally, the second child element of a resource can provide metadata about a file to be attached to the resource (see bulk-import-with-digital-representations). The remaining child elements of each resource represent its property values. These must be sorted in alphabetical order by property name. If a property has mutliple values, these are represented as multiple adjacent property elements. The type of each value must be specified using the attribute knoraType . A link to another resource described in the XML import is represented as a child element of a property element, with attributes knoraType=\"link_value\" and linkType=\"ref\" , and a target attribute containing the ID of the target resource. There is a specfic syntax for referring to properties from other ontologies. In the example, p0801-beol:comment is defined in the ontology http://www.knora.org/ontology/0001/beol . In the XML, we refer to it as p0801-biblio:p0801-beol__comment . A text value can contain XML markup. If it does: The text value element must have the attribute mapping_id , specifying a mapping from XML to standoff markup (see XML-to-standoff-mapping). It is necessary to specify the appropriate XML namespace (in this case the null namespace, xmlns=\"\" ) for the XML markup in the text value. The XML markup in the text value will not be validated by the schema. In an XML tag that is mapped to a standoff link tag, the link target can refer either to the IRI of a resoruce that already exists in the triplestore, or to the ID of a resource described in the import. If a link points to a resource described in the import, the ID of the target resource must be prefixed with ref: . In the example above, using the standard mapping, the standoff link to math_intelligencer has the target ref:math_intelligencer . A text value can have a lang attribute, whose value is an ISO 639-1 code specifying the language of the text. 4. Validate XML Import Document You can use an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen , to check that your XML import document is valid according to the schemas you got from Knora. For example, using Saxon: java -cp ./saxon9ee.jar com.saxonica.Validate -xsd:p0801-biblio.xsd -s:data.xml 5. Submit XML Import Document to Knora To create these resources in Knora, make an HTTP post request with the XML import document as the request body. The URL must specify the (URL-encoded) IRI of the project in which the resources should be created: HTTP POST to http://host/v1/resources/xmlimport/projectIRI For example, using curl : curl -v -u root@example.com:test --data @data.xml --header \"Content-Type: application/xml\" http://localhost:3333/v1/resources/xmlimport/http%3A%2F%2Frdfh.ch%2Fprojects%2F0801 Bulk Import with Links to Existing Resources Having run the import in the previous example, we can import more data with links to the data that is now in the triplestore: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol= \"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport= \"http://api.knora.org/ontology/knoraXmlImport/v1#\" > <p0801-biblio:JournalArticle id= \"strings_in_the_18th_century\" > <knoraXmlImport:label> Strings in the 18th Century </knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType= \"richtext_value\" mapping_id= \"http://rdfh.ch/standoff/mappings/StandardMapping\" > <text xmlns= \"\" > The most <strong> boring </strong> article in <a class= \"salsah-link\" href= \"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\" > Math Intelligencer </a> . </text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType= \"richtext_value\" > 76 </p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType= \"link_value\" linkType= \"iri\" target= \"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\" /> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType= \"richtext_value\" > 27 </p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType= \"link_value\" linkType= \"iri\" target= \"http://rdfh.ch/biblio/c-xMB3qkRs232pWyjdUUvA\" /> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType= \"date_value\" > GREGORIAN:1977 </p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType= \"richtext_value\" > Strings in the 18th Century </p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType= \"richtext_value\" > 52 </p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> Note that in the link elements referring to existing resources, the linkType attribute has the value iri , and the target attribute contains the IRI of the target resource. Bulk Import with Image Files To attach an image file to a resource, we must provide the element knoraXmlImport:file before the property elements. In this element, we must provide a filename attribute, containing the internalFilename that Sipi returned for the file in 2. Upload Files to Sipi . <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns= \"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://api.knora.org/ontology/incunabula/xml-import/v1# incunabula.xsd\" xmlns:incunabula= \"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:knoraXmlImport= \"http://api.knora.org/ontology/knoraXmlImport/v1#\" > <incunabula:book id= \"test_book\" > <knoraXmlImport:label> a book with one page </knoraXmlImport:label> <incunabula:title knoraType= \"richtext_value\" > the title of a book with one page </incunabula:title> </incunabula:book> <incunabula:page id= \"test_page\" > <knoraXmlImport:label> a page with an image </knoraXmlImport:label> <knoraXmlImport:file filename= \"67SEfNU1wK2-CSf5abe2eh3.jp2\" /> <incunabula:origname knoraType= \"richtext_value\" > Chlaus </incunabula:origname> <incunabula:pagenum knoraType= \"richtext_value\" > 1a </incunabula:pagenum> <incunabula:partOf> <incunabula:book knoraType= \"link_value\" linkType= \"ref\" ref= \"test_book\" /> </incunabula:partOf> <incunabula:seqnum knoraType= \"int_value\" > 1 </incunabula:seqnum> </incunabula:page> </knoraXmlImport:resources> During the processing of the bulk import, Knora will ask Sipi for the rest of the file's metadata, and store that metadata in a file value attached to the resource.","title":"Adding Resources"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#adding-resources","text":"To create a resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the resources path segment: HTTP POST to http://host/v1/resources Unlike in the case of GET requests, the request body consists of JSON describing the resource to be created. Creating resources requires authentication since only known users may add resources.","title":"Adding Resources"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#adding-resources-without-image-files","text":"The format of the JSON used to create a resource without an image file is described in the TypeScript interface createResourceWithoutRepresentationRequest in module createResourceFormats . It requires the IRI of the resource class the new resource belongs to, a label describing the new resource, the IRI of the project the new resource belongs to, and the properties to be assigned to the new resource. The request header's content type has to be set to application/json .","title":"Adding Resources Without Image Files"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#adding-resources-with-image-files","text":"The first step is to upload an image file to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The TOKEN is the sid returned by Knora in response to the client's login request (see Authentication ). The request must contain a body part providing the file as well as a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi will then convert the uploaded image file to JPEG 2000 format and store it in a temporary location. If this is successful, it will return a JSON response that looks something like this: { \"uploadedFiles\" : [{ \"originalFilename\" : \"manuscript-1234-page-1.tiff\" , \"internalFilename\" : \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" , \"temporaryBaseIIIFUrl\" : \"http://sipihost/tmp\" }] } This provides: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file The client may now wish to get a thumbnail of the uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding the filename and IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image whose width and height are at most 128 pixels wide, you would request http://sipihost/tmp/3UIsXH9bP0j-BV0D4sN51Xz.jp2/full/!128,128/0/default.jpg . The request to Knora works similarly to Adding Resources Without Image Files , with the addition of file , whose value is the internalFilename that Sipi returned. See the TypeScript interface createResourceWithRepresentationRequest in module createResourceFormats for details. The request header's content type must be set to application/json .","title":"Adding Resources with Image Files"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#response-to-a-resource-creation","text":"When a resource has been successfully created, Knora sends back a JSON containing the new resource's IRI ( res_id ) and its properties. The resource IRI identifies the resource and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface createResourceResponse in module createResourceFormats .","title":"Response to a Resource Creation"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#changing-a-resources-label","text":"A resource's label can be changed by making a PUT request to the path segments resources/label . The resource's IRI has to be provided in the URL (as its last segment). The new label has to submitted as JSON in the HTTP request's body. HTTP PUT to http://host/v1/resources/label/resourceIRI The JSON format of the request is described in the TypeScript interface changeResourceLabelRequest in module createResourceFormats . The response is described in the TypeScript interface changeResourceLabelResponse in module createResourceFormats .","title":"Changing a Resource's Label"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#bulk-import","text":"If you have a large amount of data to import into Knora, it can be more convenient to use the bulk import feature than to create resources one by one. In a bulk import operation, you submit an XML document to Knora, describing multiple resources to be created. This is especially useful if the resources to be created have links to one another. Knora checks the entire request for consistency as as a whole, and performs the update in a single database transaction. Only system or project administrators may use the bulk import. The procedure for using this feature is as follows (see the example below ). Make an HTTP GET request to Knora to get XML schemas describing the XML to be provided for the import. If you are importing image files, upload files to Sipi . Generate an XML import document representing the data to be imported, following the Knora import schemas that were generated in step 1. You will probably want to write a script to do this. Knora is not involved in this step. If you are also importing image files, this XML document needs to contain the filenames that Sipi returned for the files you uploaded in step 2. Validate your XML import document , using an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen . This will help ensure that the data you submit to Knora is correct. Knora is not involved in this step. Submit the XML import document to Knora . In this procedure, the person responsible for generating the XML import data need not be familiar with RDF or with the ontologies involved. When Knora receives an XML import, it validates it first using the relevant XML schemas, and then using the same internal checks that it performs when creating any resource. The details of the XML import format are illustrated in the following examples.","title":"Bulk Import"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#bulk-import-example","text":"Suppose we have a project with existing data (but no image files), which we want to import into Knora. We have created an ontology called http://www.knora.org/ontology/0801/biblio for the project, and this ontology also uses definitions from another ontology, called http://www.knora.org/ontology/0801/beol .","title":"Bulk Import Example"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#1-get-xml-schemas","text":"To get XML schemas for an import, we use the following route, specifying the (URL-encoded) IRI of our project's main ontology (in this case http://www.knora.org/ontology/0801/biblio ): HTTP GET to http://host/v1/resources/xmlimportschemas/ontologyIRI In our example, the URL could be: http://localhost:3333/v1/resources/xmlimportschemas/http%3A%2F%2Fwww.knora.org%2Fontology%2F0801%2Fbiblio This returns a Zip archive called p0801-biblio-xml-schemas.zip , containing three files: p0801-biblio.xsd : The schema for our main ontology. p0801-beol.xsd : A schema for another ontology that our main ontology depends on. knoraXmlImport.xsd : The standard Knora XML import schema, used by all XML imports.","title":"1. Get XML Schemas"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#2-upload-files-to-sipi","text":"See Upload Files to Sipi in the DSP-API v2 documentation.","title":"2. Upload Files to Sipi"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#3-generate-xml-import-document","text":"We now convert our existing data to XML, probably by writing a custom script. The resulting XML import document could look like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol= \"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport= \"http://api.knora.org/ontology/knoraXmlImport/v1#\" > <p0801-beol:person id= \"abel\" > <knoraXmlImport:label> Niels Henrik Abel </knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType= \"richtext_value\" > Abel </p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType= \"richtext_value\" > Niels Henrik </p0801-beol:hasGivenName> <p0801-beol:personHasTitle knoraType= \"richtext_value\" lang= \"en\" > Sir </p0801-beol:personHasTitle> </p0801-beol:person> <p0801-beol:person id= \"holmes\" > <knoraXmlImport:label> Sherlock Holmes </knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType= \"richtext_value\" > Holmes </p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType= \"richtext_value\" > Sherlock </p0801-beol:hasGivenName> </p0801-beol:person> <p0801-biblio:Journal id= \"math_intelligencer\" > <knoraXmlImport:label> Math Intelligencer </knoraXmlImport:label> <p0801-biblio:hasName knoraType= \"richtext_value\" > Math Intelligencer </p0801-biblio:hasName> </p0801-biblio:Journal> <p0801-biblio:JournalArticle id= \"strings_in_the_16th_and_17th_centuries\" creationDate= \"2019-01-09T15:45:54Z\" > <knoraXmlImport:label> Strings in the 16th and 17th Centuries </knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType= \"richtext_value\" mapping_id= \"http://rdfh.ch/standoff/mappings/StandardMapping\" > <text xmlns= \"\" > The most <strong> interesting </strong> article in <a class= \"salsah-link\" href= \"ref:math_intelligencer\" > Math Intelligencer </a> . </text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType= \"richtext_value\" > 73 </p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType= \"link_value\" target= \"math_intelligencer\" linkType= \"ref\" /> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType= \"richtext_value\" > 27 </p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType= \"link_value\" linkType= \"ref\" target= \"abel\" /> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType= \"link_value\" linkType= \"ref\" target= \"holmes\" /> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType= \"date_value\" > GREGORIAN:1976 </p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType= \"richtext_value\" lang= \"en\" > Strings in the 16th and 17th Centuries </p0801-biblio:publicationHasTitle> <p0801-biblio:publicationHasTitle knoraType= \"richtext_value\" > An alternate title </p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType= \"richtext_value\" > 48 </p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> This illustrates several aspects of XML imports: The root XML element must be knoraXmlImport:resources . There is an XML namespace corresponding each ontology used in the import. These namespaces can be found in the XML schema files returned by Knora. We have copied and pasted xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" from the main XML schema, p0801-biblio.xsd . This enables the Knora API server to identify the main ontology we are using. We have used xsi:schemaLocation to indicate the main schema's namespace and filename. If we put our XML document in the same directory as the schemas, and we run an XML validator to check the XML, it should load the schemas. The child elements of knoraXmlImport:resources represent resources to be created. The order of these elements is unimportant. Each resource must have an ID, which must be an XML NCName , and must be unique within the file. These IDs are used only during the import, and will not be stored in the triplestore. Each resource can optionally have a creationDate attribute, which can be an xsd:dateTime or an xsd:dateTimeStamp . If creationDate is not supplied, the current time is used. The first child element of each resource must be a knoraXmlImport:label , which will be stored as the resource's rdfs:label . Optionally, the second child element of a resource can provide metadata about a file to be attached to the resource (see bulk-import-with-digital-representations). The remaining child elements of each resource represent its property values. These must be sorted in alphabetical order by property name. If a property has mutliple values, these are represented as multiple adjacent property elements. The type of each value must be specified using the attribute knoraType . A link to another resource described in the XML import is represented as a child element of a property element, with attributes knoraType=\"link_value\" and linkType=\"ref\" , and a target attribute containing the ID of the target resource. There is a specfic syntax for referring to properties from other ontologies. In the example, p0801-beol:comment is defined in the ontology http://www.knora.org/ontology/0001/beol . In the XML, we refer to it as p0801-biblio:p0801-beol__comment . A text value can contain XML markup. If it does: The text value element must have the attribute mapping_id , specifying a mapping from XML to standoff markup (see XML-to-standoff-mapping). It is necessary to specify the appropriate XML namespace (in this case the null namespace, xmlns=\"\" ) for the XML markup in the text value. The XML markup in the text value will not be validated by the schema. In an XML tag that is mapped to a standoff link tag, the link target can refer either to the IRI of a resoruce that already exists in the triplestore, or to the ID of a resource described in the import. If a link points to a resource described in the import, the ID of the target resource must be prefixed with ref: . In the example above, using the standard mapping, the standoff link to math_intelligencer has the target ref:math_intelligencer . A text value can have a lang attribute, whose value is an ISO 639-1 code specifying the language of the text.","title":"3. Generate XML Import Document"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#4-validate-xml-import-document","text":"You can use an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen , to check that your XML import document is valid according to the schemas you got from Knora. For example, using Saxon: java -cp ./saxon9ee.jar com.saxonica.Validate -xsd:p0801-biblio.xsd -s:data.xml","title":"4. Validate XML Import Document"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#5-submit-xml-import-document-to-knora","text":"To create these resources in Knora, make an HTTP post request with the XML import document as the request body. The URL must specify the (URL-encoded) IRI of the project in which the resources should be created: HTTP POST to http://host/v1/resources/xmlimport/projectIRI For example, using curl : curl -v -u root@example.com:test --data @data.xml --header \"Content-Type: application/xml\" http://localhost:3333/v1/resources/xmlimport/http%3A%2F%2Frdfh.ch%2Fprojects%2F0801","title":"5. Submit XML Import Document to Knora"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#bulk-import-with-links-to-existing-resources","text":"Having run the import in the previous example, we can import more data with links to the data that is now in the triplestore: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio= \"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol= \"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport= \"http://api.knora.org/ontology/knoraXmlImport/v1#\" > <p0801-biblio:JournalArticle id= \"strings_in_the_18th_century\" > <knoraXmlImport:label> Strings in the 18th Century </knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType= \"richtext_value\" mapping_id= \"http://rdfh.ch/standoff/mappings/StandardMapping\" > <text xmlns= \"\" > The most <strong> boring </strong> article in <a class= \"salsah-link\" href= \"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\" > Math Intelligencer </a> . </text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType= \"richtext_value\" > 76 </p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType= \"link_value\" linkType= \"iri\" target= \"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\" /> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType= \"richtext_value\" > 27 </p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType= \"link_value\" linkType= \"iri\" target= \"http://rdfh.ch/biblio/c-xMB3qkRs232pWyjdUUvA\" /> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType= \"date_value\" > GREGORIAN:1977 </p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType= \"richtext_value\" > Strings in the 18th Century </p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType= \"richtext_value\" > 52 </p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> Note that in the link elements referring to existing resources, the linkType attribute has the value iri , and the target attribute contains the IRI of the target resource.","title":"Bulk Import with Links to Existing Resources"},{"location":"DSP-API/03-endpoints/api-v1/adding-resources/#bulk-import-with-image-files","text":"To attach an image file to a resource, we must provide the element knoraXmlImport:file before the property elements. In this element, we must provide a filename attribute, containing the internalFilename that Sipi returned for the file in 2. Upload Files to Sipi . <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns= \"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://api.knora.org/ontology/incunabula/xml-import/v1# incunabula.xsd\" xmlns:incunabula= \"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:knoraXmlImport= \"http://api.knora.org/ontology/knoraXmlImport/v1#\" > <incunabula:book id= \"test_book\" > <knoraXmlImport:label> a book with one page </knoraXmlImport:label> <incunabula:title knoraType= \"richtext_value\" > the title of a book with one page </incunabula:title> </incunabula:book> <incunabula:page id= \"test_page\" > <knoraXmlImport:label> a page with an image </knoraXmlImport:label> <knoraXmlImport:file filename= \"67SEfNU1wK2-CSf5abe2eh3.jp2\" /> <incunabula:origname knoraType= \"richtext_value\" > Chlaus </incunabula:origname> <incunabula:pagenum knoraType= \"richtext_value\" > 1a </incunabula:pagenum> <incunabula:partOf> <incunabula:book knoraType= \"link_value\" linkType= \"ref\" ref= \"test_book\" /> </incunabula:partOf> <incunabula:seqnum knoraType= \"int_value\" > 1 </incunabula:seqnum> </incunabula:page> </knoraXmlImport:resources> During the processing of the bulk import, Knora will ask Sipi for the rest of the file's metadata, and store that metadata in a file value attached to the resource.","title":"Bulk Import with Image Files"},{"location":"DSP-API/03-endpoints/api-v1/adding-values/","text":"Adding a Value In order to add values to an existing resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the values path segment. Creating values requires authentication since only known users may add values. Adding a Property Value In order to add a value to a resource, its property type, value, and project has to be indicated in the JSON. Also the IRI of the resource the new value belongs has to be provided in the JSON. HTTP POST to http://host/v1/values Depending on the type of the new value, one of the following formats (all TypeScript interfaces defined in module addValueFormats ) has to be used in order to create a new value: addRichtextValueRequest addLinkValueRequest addIntegerValueRequest addDecimalValueRequest addBooleanValueRequest addUriValueRequest addDateValueRequest (see dateString in basicMessageComponents for the date format) addColorValueRequest addGeometryValueRequest addHierarchicalListValueRequest addintervalValueRequest addGeonameValueRequest Response on Value Creation When a value has been successfully created, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface addValueResponse in module addValueFormats .","title":"Adding Values"},{"location":"DSP-API/03-endpoints/api-v1/adding-values/#adding-a-value","text":"In order to add values to an existing resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the values path segment. Creating values requires authentication since only known users may add values.","title":"Adding a Value"},{"location":"DSP-API/03-endpoints/api-v1/adding-values/#adding-a-property-value","text":"In order to add a value to a resource, its property type, value, and project has to be indicated in the JSON. Also the IRI of the resource the new value belongs has to be provided in the JSON. HTTP POST to http://host/v1/values Depending on the type of the new value, one of the following formats (all TypeScript interfaces defined in module addValueFormats ) has to be used in order to create a new value: addRichtextValueRequest addLinkValueRequest addIntegerValueRequest addDecimalValueRequest addBooleanValueRequest addUriValueRequest addDateValueRequest (see dateString in basicMessageComponents for the date format) addColorValueRequest addGeometryValueRequest addHierarchicalListValueRequest addintervalValueRequest addGeonameValueRequest","title":"Adding a Property Value"},{"location":"DSP-API/03-endpoints/api-v1/adding-values/#response-on-value-creation","text":"When a value has been successfully created, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface addValueResponse in module addValueFormats .","title":"Response on Value Creation"},{"location":"DSP-API/03-endpoints/api-v1/authentication/","text":"Authentication Login and Logout When a client accesses the /v1/session?login route successfully, it gets back headers requesting that a cookie is created, which will store the session token. On all subsequent calls to any route, this session token needs to be sent with each request. Normally, a web browser does this automatically, i.e. sends the cookie on every request. The session token is used by the server to retrieve the user profile. If successful, the user is deemed authenticated. To logout the client can call the same route and provide the logout parameter /v1/session?logout . This will invalidate the session token and return headers for removing the cookie on the client. Submitting Credentials For login , credentials in form of email and password need to be sent with the request. There are two possibilities to do so: in the URL submitting the parameters email and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedEmail&password=pw ) in the HTTP authorization header ( HTTP basic authentication ) when doing a HTTP request to the API When using Python's module requests , the credentials (email / password) can simply be submitted as a tuple with each request using the param auth ( python requests ). An alternative way for accessing all routes is to simply supply the email and password credentials on each request either as URL parameters or in the HTTP authorization header. Checking Credentials To check the credentials, there is a special route called /v1/authenticate , which can be used to check if the credentials are valid. Usage Scenarios Create session by logging-in, send session token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Authentication"},{"location":"DSP-API/03-endpoints/api-v1/authentication/#authentication","text":"","title":"Authentication"},{"location":"DSP-API/03-endpoints/api-v1/authentication/#login-and-logout","text":"When a client accesses the /v1/session?login route successfully, it gets back headers requesting that a cookie is created, which will store the session token. On all subsequent calls to any route, this session token needs to be sent with each request. Normally, a web browser does this automatically, i.e. sends the cookie on every request. The session token is used by the server to retrieve the user profile. If successful, the user is deemed authenticated. To logout the client can call the same route and provide the logout parameter /v1/session?logout . This will invalidate the session token and return headers for removing the cookie on the client.","title":"Login and Logout"},{"location":"DSP-API/03-endpoints/api-v1/authentication/#submitting-credentials","text":"For login , credentials in form of email and password need to be sent with the request. There are two possibilities to do so: in the URL submitting the parameters email and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedEmail&password=pw ) in the HTTP authorization header ( HTTP basic authentication ) when doing a HTTP request to the API When using Python's module requests , the credentials (email / password) can simply be submitted as a tuple with each request using the param auth ( python requests ). An alternative way for accessing all routes is to simply supply the email and password credentials on each request either as URL parameters or in the HTTP authorization header.","title":"Submitting Credentials"},{"location":"DSP-API/03-endpoints/api-v1/authentication/#checking-credentials","text":"To check the credentials, there is a special route called /v1/authenticate , which can be used to check if the credentials are valid.","title":"Checking Credentials"},{"location":"DSP-API/03-endpoints/api-v1/authentication/#usage-scenarios","text":"Create session by logging-in, send session token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Usage Scenarios"},{"location":"DSP-API/03-endpoints/api-v1/changing-values/","text":"Changing a Value To add values to an existing resource, the HTTP method PUT has to be used. Changing values requires authentication since only known users may change values. Modifying a Property Value The request has to be sent to the Knora server using the values path segment followed by the value's IRI: HTTP PUT to http://host/values/valueIRI The value IRI has to be URL-encoded. To change an existing value (creating a new version of it), the value's current IRI and its new value have to be submitted as JSON in the HTTP body. Depending on the type of the new value, one of the following formats has to be used in order to create a new value (all these TypeScript interfaces are defined in module changeValueFormats ): changeRichtextValueRequest changeLinkValueRequest changeIntegerValueRequest changeDecimalValueRequest changeBooleanValueRequest changeUriValueRequest changeDateValueRequest changeColorValueRequest changeGeometryValueRequest changeHierarchicalListValueRequest changeIntervalValueRequest changeGeonameValueRequest Modifying a File Value To change a file value, the client first uploads the new file to Sipi, following the procedure described in Adding Resources with Image Files . Then the client sends a request to Knora, using this following route: HTTP PUT to http://host/filevalue/resourceIRI Here, resourceIRI is the URL-encoded IRI of the resource whose file value is to be changed. The body of the request is a JSON object described in the TypeScript interface changeFileValueRequest in module changeValueFormats , and contains file , whose value is the internalFilename that Sipi returned. The request header's content type must be set to application/json . Response on Value Change When a value has been successfully changed, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface changeValueResponse in module changeValueFormats .","title":"Changing Values"},{"location":"DSP-API/03-endpoints/api-v1/changing-values/#changing-a-value","text":"To add values to an existing resource, the HTTP method PUT has to be used. Changing values requires authentication since only known users may change values.","title":"Changing a Value"},{"location":"DSP-API/03-endpoints/api-v1/changing-values/#modifying-a-property-value","text":"The request has to be sent to the Knora server using the values path segment followed by the value's IRI: HTTP PUT to http://host/values/valueIRI The value IRI has to be URL-encoded. To change an existing value (creating a new version of it), the value's current IRI and its new value have to be submitted as JSON in the HTTP body. Depending on the type of the new value, one of the following formats has to be used in order to create a new value (all these TypeScript interfaces are defined in module changeValueFormats ): changeRichtextValueRequest changeLinkValueRequest changeIntegerValueRequest changeDecimalValueRequest changeBooleanValueRequest changeUriValueRequest changeDateValueRequest changeColorValueRequest changeGeometryValueRequest changeHierarchicalListValueRequest changeIntervalValueRequest changeGeonameValueRequest","title":"Modifying a Property Value"},{"location":"DSP-API/03-endpoints/api-v1/changing-values/#modifying-a-file-value","text":"To change a file value, the client first uploads the new file to Sipi, following the procedure described in Adding Resources with Image Files . Then the client sends a request to Knora, using this following route: HTTP PUT to http://host/filevalue/resourceIRI Here, resourceIRI is the URL-encoded IRI of the resource whose file value is to be changed. The body of the request is a JSON object described in the TypeScript interface changeFileValueRequest in module changeValueFormats , and contains file , whose value is the internalFilename that Sipi returned. The request header's content type must be set to application/json .","title":"Modifying a File Value"},{"location":"DSP-API/03-endpoints/api-v1/changing-values/#response-on-value-change","text":"When a value has been successfully changed, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface changeValueResponse in module changeValueFormats .","title":"Response on Value Change"},{"location":"DSP-API/03-endpoints/api-v1/delete-resources-and-values/","text":"Deleting Resources and Values Knora does not actually delete resources or values; it just marks them as deleted. To mark a resource or value as deleted, you must use the HTTP method DELETE has to be used. This requires authentication. Mark a Resource as Deleted The delete request has to be sent to the Knora server using the resources path segment. HTTP DELETE to http://host/resources/resourceIRI?deleteComment=String The resource IRI must be URL-encoded. The deleteComment is an optional comment explaining why the resource is being marked as deleted. Mark a Value as Deleted The delete request has to be sent to the Knora server using the values path segment, providing the valueIRI: HTTP DELETE to http://host/values/valueIRI?deleteComment=String The value IRI must be URL-encoded. The deleteComment is an optional comment explaining why the value is being marked as deleted. Once a value has been marked as deleted, no new versions of it can be made.","title":"Deleting Resources and Values"},{"location":"DSP-API/03-endpoints/api-v1/delete-resources-and-values/#deleting-resources-and-values","text":"Knora does not actually delete resources or values; it just marks them as deleted. To mark a resource or value as deleted, you must use the HTTP method DELETE has to be used. This requires authentication.","title":"Deleting Resources and Values"},{"location":"DSP-API/03-endpoints/api-v1/delete-resources-and-values/#mark-a-resource-as-deleted","text":"The delete request has to be sent to the Knora server using the resources path segment. HTTP DELETE to http://host/resources/resourceIRI?deleteComment=String The resource IRI must be URL-encoded. The deleteComment is an optional comment explaining why the resource is being marked as deleted.","title":"Mark a Resource as Deleted"},{"location":"DSP-API/03-endpoints/api-v1/delete-resources-and-values/#mark-a-value-as-deleted","text":"The delete request has to be sent to the Knora server using the values path segment, providing the valueIRI: HTTP DELETE to http://host/values/valueIRI?deleteComment=String The value IRI must be URL-encoded. The deleteComment is an optional comment explaining why the value is being marked as deleted. Once a value has been marked as deleted, no new versions of it can be made.","title":"Mark a Value as Deleted"},{"location":"DSP-API/03-endpoints/api-v1/introduction/","text":"Introduction: Using API V1 RESTful API DSP-API V1 is a RESTful API that allows for reading and adding of resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The diverse HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ). Knora IRIs Every resource that is created or hosted by Knora is identified by a unique id, a so called Internationalized Resource Identifier (IRI). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike DSP-API v2, DSP-API v1 uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ). V1 Path Segment Every request to API V1 includes v1 as a path segment, e.g. http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests to another version of the API will require another path segment. DSP-API Response Format In case an API request could be handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON (using UTF-8). In this JSON, an API specific status code is sent (member status ). The JSON formats are formally defined as TypeScript interfaces (located in salsah/src/typescript_interfaces ). Build the HTML documentation of these interfaces by executing make jsonformat (see docs/Readme.md for further instructions). Placeholder host in sample URLs Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on. Authentication For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. When using the SALSAH web interface, after logging in a session is established (cookie based). When using the API with another client application, credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). Also when reading resources authentication my be needed as resources and their values may have restricted view permissions.","title":"Introduction"},{"location":"DSP-API/03-endpoints/api-v1/introduction/#introduction-using-api-v1","text":"","title":"Introduction: Using API V1"},{"location":"DSP-API/03-endpoints/api-v1/introduction/#restful-api","text":"DSP-API V1 is a RESTful API that allows for reading and adding of resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The diverse HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ).","title":"RESTful API"},{"location":"DSP-API/03-endpoints/api-v1/introduction/#knora-iris","text":"Every resource that is created or hosted by Knora is identified by a unique id, a so called Internationalized Resource Identifier (IRI). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike DSP-API v2, DSP-API v1 uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ).","title":"Knora IRIs"},{"location":"DSP-API/03-endpoints/api-v1/introduction/#v1-path-segment","text":"Every request to API V1 includes v1 as a path segment, e.g. http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests to another version of the API will require another path segment.","title":"V1 Path Segment"},{"location":"DSP-API/03-endpoints/api-v1/introduction/#dsp-api-response-format","text":"In case an API request could be handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON (using UTF-8). In this JSON, an API specific status code is sent (member status ). The JSON formats are formally defined as TypeScript interfaces (located in salsah/src/typescript_interfaces ). Build the HTML documentation of these interfaces by executing make jsonformat (see docs/Readme.md for further instructions).","title":"DSP-API Response Format"},{"location":"DSP-API/03-endpoints/api-v1/introduction/#placeholder-host-in-sample-urls","text":"Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on.","title":"Placeholder host in sample URLs"},{"location":"DSP-API/03-endpoints/api-v1/introduction/#authentication","text":"For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. When using the SALSAH web interface, after logging in a session is established (cookie based). When using the API with another client application, credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). Also when reading resources authentication my be needed as resources and their values may have restricted view permissions.","title":"Authentication"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/","text":"Reading and Searching Resources In order to get an existing resource, the HTTP method GET has to be used. The request has to be sent to the Knora server using the resources path segment (depending on the type of request, this segment has to be exchanged, see below). Reading resources may require authentication since some resources may have restricted viewing permissions. Get the Representation of a Resource by its IRI Simple Request of a Resource (full Resource Request) A resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL encoded. In order to get the resource with the IRI http://rdfh.ch/c5058f3a (an incunabula book contained in the test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL encoded IRI: HTTP GET to http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a More formalized, the URL looks like this: HTTP GET to http://host/v1/resources/resourceIRI As an answer, the client receives a JSON that represents the requested resource. It has the following members: status : The Knora status code, 0 if everything went well userdata : Data about the user that made the request resinfo : Data describing the requested resource and its class resdata : Short information about the resource and its class (including information about the given user's permissions on the resource) incoming : Resources pointing to the requested resource props : Properties of the requested resource. For a complete and more formalized description of a full resource request, look at the TypeScript interface resourceFullResponse in the module resourceResponseFormats . Provide Request Parameters To make a request more specific, the following parameters can be appended to the URL ( http://www.knora.org/resources/resourceIRI?param1=value1&param2=value2 ): reqtype=info|context|rights : Specifies the type of request. Setting the parameter's to value info returns short information about the requested resource (contains only resinfo and no properties, see TypeScript interface resourceInfoResponse in module resourceResponseFormats ). Setting the parameter's value to context returns context information ( resource_context ) about the requested resource: Either the dependent parts of a compound resource (e.g. pages of a book) or the parent resource of a dependent resource (e.g. the book a pages belongs to). By default, a context query does not return information about the requested resource itself, but only about its context (see TypeScript interface resourceContextResponse in module resourceResponseFormats ). See below how to get additional information about the resource. The parameter rights returns only the given user's permissions on the requested resource (see TypeScript interface resourceRightsResponse in module resourceResponseFormats ). resinfo=true : Can be used in combination with reqtype=context : If set, resinfo is added to the response representing information about the requested resource (complementary to its context), see TypeScript interface resourceContextResponse in module resourceResponseFormats . Obtain an HTML Representation of a Resource In order to get an HTML representation of a resource (not a JSON), the path segment resources.html can be used: HTTP GET to http://host/v1/resources.html/resourceIRI?reqtype=properties The request returns the properties of the requested resource as an HTML document. Get only the Properties belonging to a Resource In order to get only the properties of a resource without any other information, the path segment properties can be used: HTTP GET to http://host/v1/properties/resourceIRI The JSON contains just the member properties representing the requested resource's properties (see TypeScript interface resourcePropertiesResponse in module resourceResponseFormats ). Get Information about a Resource Class Get a Resource Class by its IRI In order to get information about a resource class, the path segment resourcetypes can be used. Append the IRI of the resource class to the URL (e.g. http://www.knora.org/ontology/0803/incunabula#book ). HTTP GET to http://host/v1/resourcetypes/resourceClassIRI In the JSON, the information about the resource class and all the property types that it may have are returned. None of these are actual instances of a property, but only types (see TypeScript interface resourceTypeResponse in module resourceResponseFormats ). Get all the Property Types of a Resource Class or a Vocabulary To get a list of all the available property types, the path segment propertylists can be used. It can be restricted to a certain vocbulary using the parameter vocabulary or to a certain resource class using the parameter restype . # returns all the property types for incunabula:page HTTP GET to http://host/v1/propertylists?restype=resourceClassIRI # returns all the property types for the incunabula vocabulary HTTP GET to http://host/v1/propertylists?vocabulary=vocabularyIRI Both of these queries return a list of property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface propertyTypesInResourceClassResponse in module resourceResponseFormats . Get the Resource Classes of a Vocabulary Resource classes and property types are organized in (project specific) name spaces, so called vocabularies. In order to get all the resource classes defined for a specific vocabulary (e.g. incunabula ), the parameter vocabulary has to be used and assigned the vocabulary's IRI: HTTP GET to http://host/v1/resourcetypes?vocabulary=vocabularyIRI This returns all the resource classes defined for the specified vocabulary and their property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface resourceTypesInVocabularyResponse in module resourceResponseFormats . Get all the Vocabularies To get a list of all available vocabularies, the path segment vocabularies can be used: HTTP GET to http://host/v1/vocabularies The response will list all the available vocabularies. See TypeScript interface vocabularyResponse in module resourceResponseFormats . Search for Resources Search for Resources by their Label This is a simplified way for searching for resources just by their label. Search by label automatically adds Lucene operators, search strings are expected not to contain any characters with a special meaning in Lucene Query Parser syntax . It is a simple string-based method: HTTP GET to http://host/v1/resources?searchstr=searchValue Additionally, the following parameters can be appended to the URL (search value is Zeitgl\u00f6cklein ): restype_id=resourceClassIRI : This restricts the search to resources of the specified class (subclasses of that class will also match). -1 is the default value and means no restriction to a specific class. If a resource class IRI is specified, it has to be URL encoded (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&restype_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book ). numprops=Integer : Specifies the number of properties returned for each resource that was found (sorted by GUI order), e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&numprops=4 . limit=Integer : Limits the amount of results returned (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&limit=1 ). The response lists the resources that matched the search criteria (see TypeScript interface resourceLabelSearchResponse in module resourceResponseFormats ). Fulltext Search DSP-API offers a fulltext search that searches through all textual representations of values. The search terms have to be URL encoded. Fulltext search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. HTTP GET to http://host/v1/search/searchValue?searchtype=fulltext[&filter_by_restype=resourceClassIRI] [&filter_by_project=projectIRI][&show_nrows=Integer]{[&start_at=Integer] The parameter searchtype is required and has to be set to fulltext . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See TypeScript interface searchResponse in module searchResponseFormats . Extended Search for Resources HTTP GET to http://host/v1/search/?searchtype=extended [&filter_by_restype=resourceClassIRI][&filter_by_project=projectIRI][&filter_by_owner=userIRI] (&property_id=propertyTypeIRI&compop=comparisonOperator&searchval=searchValue)+ [&show_nrows=Integer][&start_at=Integer] The parameter searchtype is required and has to be set to extended . An extended search requires at least one set of parameters consisting of: property_id=propertyTypeIRI : the property the resource has to have (subproperties of that property will also match). compop=comparisonOperator : the comparison operator to be used to match between the resource's property value and the search term. searchval=searchTerm : the search value to look for. You can also provide several of these sets to make your query more specific. The following table indicates the possible combinations of value types and comparison operators: Value Type Comparison Operator Date Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Integer Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Float Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Text Value MATCH_BOOLEAN, MATCH, EQ, !EQ, LIKE, !LIKE, EXISTS Geometry Value EXISTS Geoname Value EQ, EXISTS URI Value EQ, EXISTS Resource Pointer EQ, EXISTS Color Value EQ, EXISTS List Value EQ, EXISTS Boolean Value EQ, !EQ, EXISTS Explanation of the comparison operators: EQ (equal): checks if a resource's value equals the search value. In case of a text value type, it checks for identity of the strings compared. In case of a date value type, equality is given if the dates overlap in any way. Since dates are internally always treated as periods, equality is given if a date value's period ends after or equals the start of the defined period and a date value's period starts before or equals the end of the defined period. !EQ (not equal): checks if a resource's value does not equal the search value. In case of a text value type, it checks if the compared strings are different. In case of a date value type, inequality is given if the dates do not overlap in any way, meaning that a date starts after the end of the defined period or ends before the beginning of the defined period (dates are internally always treated as periods, see above). GT (greater than): checks if a resource's value is greater than the search value. In case of a date value type, it assures that a period begins after the indicated period's end. GT_EQ (greater than or equal): checks if a resource's value equals or is greater than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period starts after the indicated period's end (see GT ). LT (less than): checks if a resource's value is lower than the search value. In case of a date value type, it assures that a period ends before the indicated period's start. LT_EQ (less than or equal): checks if a resource's value equals or is lower than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period ends before the indicated period's start (see LT ). EXISTS : checks if an instance of the indicated property type exists for a resource. Please always provide an empty search value when using EXISTS: \"searchval=\" . Otherwise, the query syntax rules would be violated. MATCH : checks if a resource's text value matches the search value, see Lucene Query Parser Syntax . LIKE : checks if the search value is contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. !LIKE (not like): checks if the search value is not contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. MATCH_BOOLEAN : checks if a resource's text value matches the provided list of positive (exist) and negative (do not exist) terms. The list takes this form: ([+-]term\\s)+ . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. filter_by_owner : restricts the search to resources owned by the specified user. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. Some sample searches: http://localhost:3333/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=!EQ&searchval=Zeitgl%C3%B6cklein%20des%20Lebens%20und%20Leidens%20Christi : searches for books that have a title that does not equal \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\". http://www.knora.org/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=MATCH&searchval=Zeitgl%C3%B6cklein&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23pubdate&compop=EQ&searchval=JULIAN:1490 : searches for resources of type incunabula:book whose titles match \"Zeitgl\u00f6cklein\" and were published in the year 1490 (according to the Julian calendar). The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See the TypeScript interface searchResponse in module searchResponseFormats . Get a Graph of Resources The path segment graphdata returns a graph of resources that are reachable via links to or from an initial resource. HTTP GET to http://host/v1/graphdata/resourceIRI?depth=Integer The parameter depth specifies the maximum depth of the graph, and defaults to 4. If depth is 1, the operation will return only the initial resource and any resources that are directly linked to or from it. The graph includes any link that is a subproperty of knora-base:hasLinkTo , except for links that are subproperties of knora-base:isPartOf . Specifically, if resource R1 has a link that is a subproperty of knora-base:isPartOf pointing to resource R2 , no link from R1 to R2 is included in the graph. The response represents the graph as a list of nodes (resources) and a list of edges (links). For details, see the TypeScript interface graphDataResponse in module graphDataResponseFormats . Get Hierarchical Lists The knora-base ontology allows for the definition of hierarchical lists. These can be queried by providing the IRI of the root node. Selections are hierarchical list that are just one level deep. Internally, they are represented as hierarchical lists. You can get a hierarchical by using the path segment hlists and appending the hierarchical list's IRI (URL encoded): HTTP GET to http://host/v1/hlists/rootNodeIRI The response shows all of the list nodes that are element of the requested hierarchical list as a tree structure. See TypeScript interface hierarchicalListResponse in module hierarchicalListResponseFormats . For each node, the full path leading to it from the top level can be requested by making a query providing the node's IRI and setting the param reqtype=node : HTTP GET to http://host/v1/hlists/nodeIri?reqtype=node The response presents the full path to the current node. See the TypeScript interface nodePathResponse in module hierarchicalListResponseFormats .","title":"Reading and Searching Resources"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#reading-and-searching-resources","text":"In order to get an existing resource, the HTTP method GET has to be used. The request has to be sent to the Knora server using the resources path segment (depending on the type of request, this segment has to be exchanged, see below). Reading resources may require authentication since some resources may have restricted viewing permissions.","title":"Reading and Searching Resources"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-the-representation-of-a-resource-by-its-iri","text":"","title":"Get the Representation of a Resource by its IRI"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#simple-request-of-a-resource-full-resource-request","text":"A resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL encoded. In order to get the resource with the IRI http://rdfh.ch/c5058f3a (an incunabula book contained in the test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL encoded IRI: HTTP GET to http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a More formalized, the URL looks like this: HTTP GET to http://host/v1/resources/resourceIRI As an answer, the client receives a JSON that represents the requested resource. It has the following members: status : The Knora status code, 0 if everything went well userdata : Data about the user that made the request resinfo : Data describing the requested resource and its class resdata : Short information about the resource and its class (including information about the given user's permissions on the resource) incoming : Resources pointing to the requested resource props : Properties of the requested resource. For a complete and more formalized description of a full resource request, look at the TypeScript interface resourceFullResponse in the module resourceResponseFormats .","title":"Simple Request of a Resource (full Resource Request)"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#provide-request-parameters","text":"To make a request more specific, the following parameters can be appended to the URL ( http://www.knora.org/resources/resourceIRI?param1=value1&param2=value2 ): reqtype=info|context|rights : Specifies the type of request. Setting the parameter's to value info returns short information about the requested resource (contains only resinfo and no properties, see TypeScript interface resourceInfoResponse in module resourceResponseFormats ). Setting the parameter's value to context returns context information ( resource_context ) about the requested resource: Either the dependent parts of a compound resource (e.g. pages of a book) or the parent resource of a dependent resource (e.g. the book a pages belongs to). By default, a context query does not return information about the requested resource itself, but only about its context (see TypeScript interface resourceContextResponse in module resourceResponseFormats ). See below how to get additional information about the resource. The parameter rights returns only the given user's permissions on the requested resource (see TypeScript interface resourceRightsResponse in module resourceResponseFormats ). resinfo=true : Can be used in combination with reqtype=context : If set, resinfo is added to the response representing information about the requested resource (complementary to its context), see TypeScript interface resourceContextResponse in module resourceResponseFormats .","title":"Provide Request Parameters"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#obtain-an-html-representation-of-a-resource","text":"In order to get an HTML representation of a resource (not a JSON), the path segment resources.html can be used: HTTP GET to http://host/v1/resources.html/resourceIRI?reqtype=properties The request returns the properties of the requested resource as an HTML document.","title":"Obtain an HTML Representation of a Resource"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-only-the-properties-belonging-to-a-resource","text":"In order to get only the properties of a resource without any other information, the path segment properties can be used: HTTP GET to http://host/v1/properties/resourceIRI The JSON contains just the member properties representing the requested resource's properties (see TypeScript interface resourcePropertiesResponse in module resourceResponseFormats ).","title":"Get only the Properties belonging to a Resource"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-information-about-a-resource-class","text":"","title":"Get Information about a Resource Class"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-a-resource-class-by-its-iri","text":"In order to get information about a resource class, the path segment resourcetypes can be used. Append the IRI of the resource class to the URL (e.g. http://www.knora.org/ontology/0803/incunabula#book ). HTTP GET to http://host/v1/resourcetypes/resourceClassIRI In the JSON, the information about the resource class and all the property types that it may have are returned. None of these are actual instances of a property, but only types (see TypeScript interface resourceTypeResponse in module resourceResponseFormats ).","title":"Get a Resource Class by its IRI"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-all-the-property-types-of-a-resource-class-or-a-vocabulary","text":"To get a list of all the available property types, the path segment propertylists can be used. It can be restricted to a certain vocbulary using the parameter vocabulary or to a certain resource class using the parameter restype . # returns all the property types for incunabula:page HTTP GET to http://host/v1/propertylists?restype=resourceClassIRI # returns all the property types for the incunabula vocabulary HTTP GET to http://host/v1/propertylists?vocabulary=vocabularyIRI Both of these queries return a list of property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface propertyTypesInResourceClassResponse in module resourceResponseFormats .","title":"Get all the Property Types of a Resource Class or a Vocabulary"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-the-resource-classes-of-a-vocabulary","text":"Resource classes and property types are organized in (project specific) name spaces, so called vocabularies. In order to get all the resource classes defined for a specific vocabulary (e.g. incunabula ), the parameter vocabulary has to be used and assigned the vocabulary's IRI: HTTP GET to http://host/v1/resourcetypes?vocabulary=vocabularyIRI This returns all the resource classes defined for the specified vocabulary and their property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface resourceTypesInVocabularyResponse in module resourceResponseFormats .","title":"Get the Resource Classes of a Vocabulary"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-all-the-vocabularies","text":"To get a list of all available vocabularies, the path segment vocabularies can be used: HTTP GET to http://host/v1/vocabularies The response will list all the available vocabularies. See TypeScript interface vocabularyResponse in module resourceResponseFormats .","title":"Get all the Vocabularies"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#search-for-resources","text":"","title":"Search for Resources"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#search-for-resources-by-their-label","text":"This is a simplified way for searching for resources just by their label. Search by label automatically adds Lucene operators, search strings are expected not to contain any characters with a special meaning in Lucene Query Parser syntax . It is a simple string-based method: HTTP GET to http://host/v1/resources?searchstr=searchValue Additionally, the following parameters can be appended to the URL (search value is Zeitgl\u00f6cklein ): restype_id=resourceClassIRI : This restricts the search to resources of the specified class (subclasses of that class will also match). -1 is the default value and means no restriction to a specific class. If a resource class IRI is specified, it has to be URL encoded (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&restype_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book ). numprops=Integer : Specifies the number of properties returned for each resource that was found (sorted by GUI order), e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&numprops=4 . limit=Integer : Limits the amount of results returned (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&limit=1 ). The response lists the resources that matched the search criteria (see TypeScript interface resourceLabelSearchResponse in module resourceResponseFormats ).","title":"Search for Resources by their Label"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#fulltext-search","text":"DSP-API offers a fulltext search that searches through all textual representations of values. The search terms have to be URL encoded. Fulltext search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. HTTP GET to http://host/v1/search/searchValue?searchtype=fulltext[&filter_by_restype=resourceClassIRI] [&filter_by_project=projectIRI][&show_nrows=Integer]{[&start_at=Integer] The parameter searchtype is required and has to be set to fulltext . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See TypeScript interface searchResponse in module searchResponseFormats .","title":"Fulltext Search"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#extended-search-for-resources","text":"HTTP GET to http://host/v1/search/?searchtype=extended [&filter_by_restype=resourceClassIRI][&filter_by_project=projectIRI][&filter_by_owner=userIRI] (&property_id=propertyTypeIRI&compop=comparisonOperator&searchval=searchValue)+ [&show_nrows=Integer][&start_at=Integer] The parameter searchtype is required and has to be set to extended . An extended search requires at least one set of parameters consisting of: property_id=propertyTypeIRI : the property the resource has to have (subproperties of that property will also match). compop=comparisonOperator : the comparison operator to be used to match between the resource's property value and the search term. searchval=searchTerm : the search value to look for. You can also provide several of these sets to make your query more specific. The following table indicates the possible combinations of value types and comparison operators: Value Type Comparison Operator Date Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Integer Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Float Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Text Value MATCH_BOOLEAN, MATCH, EQ, !EQ, LIKE, !LIKE, EXISTS Geometry Value EXISTS Geoname Value EQ, EXISTS URI Value EQ, EXISTS Resource Pointer EQ, EXISTS Color Value EQ, EXISTS List Value EQ, EXISTS Boolean Value EQ, !EQ, EXISTS Explanation of the comparison operators: EQ (equal): checks if a resource's value equals the search value. In case of a text value type, it checks for identity of the strings compared. In case of a date value type, equality is given if the dates overlap in any way. Since dates are internally always treated as periods, equality is given if a date value's period ends after or equals the start of the defined period and a date value's period starts before or equals the end of the defined period. !EQ (not equal): checks if a resource's value does not equal the search value. In case of a text value type, it checks if the compared strings are different. In case of a date value type, inequality is given if the dates do not overlap in any way, meaning that a date starts after the end of the defined period or ends before the beginning of the defined period (dates are internally always treated as periods, see above). GT (greater than): checks if a resource's value is greater than the search value. In case of a date value type, it assures that a period begins after the indicated period's end. GT_EQ (greater than or equal): checks if a resource's value equals or is greater than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period starts after the indicated period's end (see GT ). LT (less than): checks if a resource's value is lower than the search value. In case of a date value type, it assures that a period ends before the indicated period's start. LT_EQ (less than or equal): checks if a resource's value equals or is lower than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period ends before the indicated period's start (see LT ). EXISTS : checks if an instance of the indicated property type exists for a resource. Please always provide an empty search value when using EXISTS: \"searchval=\" . Otherwise, the query syntax rules would be violated. MATCH : checks if a resource's text value matches the search value, see Lucene Query Parser Syntax . LIKE : checks if the search value is contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. !LIKE (not like): checks if the search value is not contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. MATCH_BOOLEAN : checks if a resource's text value matches the provided list of positive (exist) and negative (do not exist) terms. The list takes this form: ([+-]term\\s)+ . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. filter_by_owner : restricts the search to resources owned by the specified user. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. Some sample searches: http://localhost:3333/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=!EQ&searchval=Zeitgl%C3%B6cklein%20des%20Lebens%20und%20Leidens%20Christi : searches for books that have a title that does not equal \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\". http://www.knora.org/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=MATCH&searchval=Zeitgl%C3%B6cklein&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23pubdate&compop=EQ&searchval=JULIAN:1490 : searches for resources of type incunabula:book whose titles match \"Zeitgl\u00f6cklein\" and were published in the year 1490 (according to the Julian calendar). The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See the TypeScript interface searchResponse in module searchResponseFormats .","title":"Extended Search for Resources"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-a-graph-of-resources","text":"The path segment graphdata returns a graph of resources that are reachable via links to or from an initial resource. HTTP GET to http://host/v1/graphdata/resourceIRI?depth=Integer The parameter depth specifies the maximum depth of the graph, and defaults to 4. If depth is 1, the operation will return only the initial resource and any resources that are directly linked to or from it. The graph includes any link that is a subproperty of knora-base:hasLinkTo , except for links that are subproperties of knora-base:isPartOf . Specifically, if resource R1 has a link that is a subproperty of knora-base:isPartOf pointing to resource R2 , no link from R1 to R2 is included in the graph. The response represents the graph as a list of nodes (resources) and a list of edges (links). For details, see the TypeScript interface graphDataResponse in module graphDataResponseFormats .","title":"Get a Graph of Resources"},{"location":"DSP-API/03-endpoints/api-v1/reading-and-searching-resources/#get-hierarchical-lists","text":"The knora-base ontology allows for the definition of hierarchical lists. These can be queried by providing the IRI of the root node. Selections are hierarchical list that are just one level deep. Internally, they are represented as hierarchical lists. You can get a hierarchical by using the path segment hlists and appending the hierarchical list's IRI (URL encoded): HTTP GET to http://host/v1/hlists/rootNodeIRI The response shows all of the list nodes that are element of the requested hierarchical list as a tree structure. See TypeScript interface hierarchicalListResponse in module hierarchicalListResponseFormats . For each node, the full path leading to it from the top level can be requested by making a query providing the node's IRI and setting the param reqtype=node : HTTP GET to http://host/v1/hlists/nodeIri?reqtype=node The response presents the full path to the current node. See the TypeScript interface nodePathResponse in module hierarchicalListResponseFormats .","title":"Get Hierarchical Lists"},{"location":"DSP-API/03-endpoints/api-v1/reading-values/","text":"Reading Values In order to get an existing value, the HTTP method GET has to be used. The request has to be sent to the Knora server using the values path segment. Reading values may require authentication since some resources may have restricted viewing permissions. Reading a Value The representation of a value can be obtained by making a GET request providing the value's IRI: HTTP GET to http://host/v1/values/valueIRI In the response, the value's type and value are returned (see TypeScript interface valueResponse in module valueResponseFormats ). Getting a Value's Version History In order to get the history of a value (its current and previous versions), the IRI of the resource it belongs to, the IRI of the property type that connects the resource to the value, and its current value IRI have to be submitted. Each of these elements is appended to the URL and separated by a slash. Please note that all of these have to be URL encoded. Additionally to values , the path segment history has to be used: HTTP GET to http://host/v1/values/history/resourceIRI/propertyTypeIRI/valueIRI In the response, the value's versions returned (see TypeScript interface valueVersionsResponse in module valueResponseFormats ). Getting a Linking Value In order to get information about a link between two resources, the path segment links has to be used. The IRI of the source object, the IRI of the property type linking the the two objects, and the IRI of the target object have to be provided in the URL separated by slashes. Each of these has to be URL encoded. HTTP GET to http://host/links/sourceObjectIRI/linkingPropertyIRI/targetObjectIRI In the response, information about the link is returned such as a reference count indicating how many links of the specified direction (source to target) and type (property) between the two objects exist (see TypeScript interface linkResponse in module valueResponseFormats ).","title":"Reading Values"},{"location":"DSP-API/03-endpoints/api-v1/reading-values/#reading-values","text":"In order to get an existing value, the HTTP method GET has to be used. The request has to be sent to the Knora server using the values path segment. Reading values may require authentication since some resources may have restricted viewing permissions.","title":"Reading Values"},{"location":"DSP-API/03-endpoints/api-v1/reading-values/#reading-a-value","text":"The representation of a value can be obtained by making a GET request providing the value's IRI: HTTP GET to http://host/v1/values/valueIRI In the response, the value's type and value are returned (see TypeScript interface valueResponse in module valueResponseFormats ).","title":"Reading a Value"},{"location":"DSP-API/03-endpoints/api-v1/reading-values/#getting-a-values-version-history","text":"In order to get the history of a value (its current and previous versions), the IRI of the resource it belongs to, the IRI of the property type that connects the resource to the value, and its current value IRI have to be submitted. Each of these elements is appended to the URL and separated by a slash. Please note that all of these have to be URL encoded. Additionally to values , the path segment history has to be used: HTTP GET to http://host/v1/values/history/resourceIRI/propertyTypeIRI/valueIRI In the response, the value's versions returned (see TypeScript interface valueVersionsResponse in module valueResponseFormats ).","title":"Getting a Value's Version History"},{"location":"DSP-API/03-endpoints/api-v1/reading-values/#getting-a-linking-value","text":"In order to get information about a link between two resources, the path segment links has to be used. The IRI of the source object, the IRI of the property type linking the the two objects, and the IRI of the target object have to be provided in the URL separated by slashes. Each of these has to be URL encoded. HTTP GET to http://host/links/sourceObjectIRI/linkingPropertyIRI/targetObjectIRI In the response, information about the link is returned such as a reference count indicating how many links of the specified direction (source to target) and type (property) between the two objects exist (see TypeScript interface linkResponse in module valueResponseFormats ).","title":"Getting a Linking Value"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/","text":"XML to Standoff Mapping in API v1 The Knora Standard Mapping Description A mapping allows for the conversion of XML to standoff representation in RDF and back. In order to create a TextValue with markup, the text has to be provided in XML format, along with the IRI of the mapping that will be used to convert the markup to standoff. However, a mapping is only needed if a TextValue with markup should be created. If a text has no markup, it is submitted as a mere sequence of characters. The two cases are described in the TypeScript interfaces simpletext and richtext in module basicMessageComponents . Knora offers a standard mapping with the IRI http://rdfh.ch/standoff/mappings/StandardMapping . The standard mapping covers the HTML elements and attributes supported by the GUI's text editor, CKEditor . (Please note that the HTML has to be encoded in strict XML syntax. CKeditor offers the possibility to define filter rules. They should reflect the elements supported by the mapping; see jquery.htmleditor.js .) The standard mapping contains the following elements and attributes that are mapped to standoff classes and properties defined in the ontology: <text> \u2192 standoff:StandoffRootTag <p> \u2192 standoff:StandoffParagraphTag <em> \u2192 standoff:StandoffItalicTag <strong> \u2192 standoff:StandoffBoldTag <u> \u2192 standoff:StandoffUnderlineTag <sub> \u2192 standoff:StandoffSubscriptTag <sup> \u2192 standoff:StandoffSuperscriptTag <strike> \u2192 standoff:StandoffStrikeTag <a href=\"URL\"> \u2192 knora-base:StandoffUriTag <a class=\"salsah-link\" href=\"Knora IRI\"> \u2192 knora-base:StandoffLinkTag <a class=\"internal-link\" href=\"#fragment\"> \u2192 knora-base:StandoffInternalReferenceTag <h1> to <h6> \u2192 standoff:StandoffHeader1Tag to standoff:StandoffHeader6Tag <ol> \u2192 standoff:StandoffOrderedListTag <ul> \u2192 standoff:StandoffUnrderedListTag <li> \u2192 standoff:StandoffListElementTag <tbody> \u2192 standoff:StandoffTableBodyTag <table> \u2192 standoff:StandoffTableTag <tr> \u2192 standoff:StandoffTableRowTag <td> \u2192 standoff:StandoffTableCellTag <br> \u2192 standoff:StandoffBrTag <hr> \u2192 standoff:StandoffLineTag <pre> \u2192 standoff:StandoffPreTag <cite> \u2192 standoff:StandoffCiteTag <blockquote> \u2192 standoff:StandoffBlockquoteTag <code> \u2192 standoff:StandoffCodeTag The HTML produced by CKEditor is wrapped in an XML doctype and a pair of root tags <text>...</text> and then sent to Knora. The XML sent to the GUI by Knora is unwrapped accordingly (see jquery.htmleditor.js ). Although the GUI supports HTML5, it is treated as if it was XHTML in strict XML notation. Maintenance The standard mapping definition can be found at test_data/test_route/texts/mappingForStandardHTML.xml . It was used to generate the default mapping, distributed as knora-ontologies/standoff-data.ttl and that is loaded at a Knora installation. It should be used to re-generate it, whenever we want to amend or extend it. Note: once the mapping has been generated, one has to rework the resources' UUID in order to maintain backward compatibility. Creating a custom Mapping The Knora standard mapping only supports a few HTML tags. In order to submit more complex XML markup to Knora, a custom mapping has to be created first. Basically, a mapping expresses the relations between XML elements and attributes and their corresponding standoff classes and properties. The relations expressed in a mapping are one-to-one relations, so the XML can be recreated from the data in RDF. However, since HTML offers a very limited set of elements, Knora mappings support the combination of element names and classes. In this way, the same element can be used several times in combination with another classname (please note that <a> without a class is a mere hyperlink whereas <a class=\"salsah-link\"> is an internal link/standoff link). With a mapping, a default XSL transformation may be provided to transform the XML to HTML before sending it back to the client. This is useful when the client is a web-browser expecting HTML (instead of XML). Basic Structure of a Mapping The mapping is written in XML itself (for a formal description, see webapi/src/resources/mappingXMLToStandoff.xsd ). It has the following structure (the indentation corresponds to the nesting in XML): <mapping> : the root element <defaultXSLTransformation> (optional) : the Iri of the default XSL transformation to be applied to the XML when reading it back from Knora. The XSL transformation is expected to produce HTML. If given, the Iri has to refer to a resource of type knora-base:XSLTransformation . <mappingElement> : an element of the mapping (at least one) <tag> : information about the XML element that is mapped to a standoff class <name> : name of the XML element <class> : value of the class attribute of the XML element, if any. If the element has no class attribute, the keyword noClass has to be used. <namespace> : the namespace the XML element belongs to, if any. If the element does not belong to a namespace, the keyword noNamespace has to be used. <separatesWords> : a Boolean value indicating whether this tag separates words in the text. Once an XML document is converted to RDF-standoff the markup is stripped from the text, possibly leading to continuous text that has been separated by tags before. For structural tags like paragraphs etc., <separatesWords> can be set to true in which case a special separator is inserted in the the text in the RDF representation. In this way, words stay separated and are represented in the fulltext index as such. <standoffClass> : information about the standoff class the XML element is mapped to <classIri> : Iri of the standoff class the XML element is mapped to <attributes> : XML attributes to be mapped to standoff properties (other than id or class ), if any <attribute> : an XML attribute to be mapped to a standoff property, may be repeated <attributeName> : the name of the XML attribute <namespace> : the namespace the attribute belongs to, if any. If the attribute does not belong to a namespace, the keyword noNamespace has to be used. <propertyIri> : the Iri of the standoff property the XML attribute is mapped to. <datatype> : the data type of the standoff class, if any. <type> : the Iri of the data type standoff class <attributeName> : the name of the attribute holding the typed value in the expected Knora standard format XML structure of a mapping: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <defaultXSLTransformation> Iri of a knora-base:XSLTransformation </defaultXSLTransformation> <mappingElement> <tag> <name> XML element name </name> <class> XML class name or \"noClass\" </class> <namespace> XML namespace or \"noNamespace\" </namespace> <separatesWords> true or false </separatesWords> </tag> <standoffClass> <classIri> standoff class Iri </classIri> <attributes> <attribute> <attributeName> XML attribute name </attributeName> <namespace> XML namespace or \"noNamespace\" </namespace> <propertyIri> standoff property Iri </propertyIri> </attribute> </attributes> <datatype> <type> standoff data type class </type> <attributeName> XML attribute with the typed value </attributeName> </datatype> </standoffClass> </mappingElement> <mappingElement> ... </mappingElement> </mapping> Please note that the absence of an XML namespace and/or a class have to be explicitly stated using the keywords noNamespace and noClass . (This is because we use XML Schema validation to ensure the one-to-one relations between XML elements and standoff classes. XML Schema validation's unique checks do not support optional values.) id and class Attributes The id and class attributes are supported by default and do not have to be included in the mapping like other attributes. The id attribute identifies an element and must be unique in the document. id is an optional attribute. The class attribute allows for the reuse of an element in the mapping, i.e. the same element can be combined with different class names and mapped to different standoff classes (mapping element <class> in <tag> ). Respecting Cardinalities A mapping from XML elements and attributes to standoff classes and standoff properties must respect the cardinalities defined in the ontology for those very standoff classes. If an XML element is mapped to a certain standoff class and this class requires a standoff property, an attribute must be defined for the XML element mapping to that very standoff property. Equally, all mappings for attributes of an XML element must have corresponding cardinalities for standoff properties defined for the standoff class the XML element maps to. However, since an XML attribute may occur once at maximum, it makes sense to make the corresponding standoff property required ( owl:cardinality of one) in the ontology or optional ( owl:maxCardinality of one), but not allowing it more than once. Standoff Data Types Knora allows the use of all its value types as standoff data types (defined in knora-base.ttl ): knora-base:StandoffLinkTag : Represents a reference to a Knora resource (the IRI of the target resource must be submitted in the data type attribute). knora-base:StandoffInternalReferenceTag : Represents an internal reference inside a document (the id of the target element inside the same document must be indicated in the data type attribute); see Internal References in an XML Document . knora-base:StandoffUriTag : Represents a reference to a URI (the URI of the target resource must be submitted in the data type attribute). knora-base:StandoffDateTag : Represents a date (a Knora date string must be submitted in the data type attribute, e.g. GREGORIAN:2017-01-27 ). knora-base:StandoffColorTag : Represents a color (a hexadecimal RGB color string must be submitted in the data type attribute, e.g. #0000FF ). knora-base:StandoffIntegerTag : Represents an integer (the integer must be submitted in the data type attribute). knora-base:StandoffDecimalTag : Represents a number with fractions (the decimal number must be submitted in the data type attribute, e.g. 1.1 ). knora-base:StandoffIntervalTag : Represents an interval (two decimal numbers separated with a comma must be submitted in the data type attribute, e.g. 1.1,2.2 ). knora-base:StandoffBooleanTag : Represents a Boolean value ( true or false must be submitted in the data type attribute). knora-base:StandoffTimeTag : Represents a timestamp value (an xsd:dateTimeStamp must be submitted in the data type attribute). The basic idea is that parts of a text can be marked up in a way that allows using Knora's built-in data types. In order to do so, the typed values have to be provided in a standardized way in an attribute that has to be defined in the mapping. Data type standoff classes are standoff classes with predefined properties (e.g., a knora-base:StandoffLinkTag has a knora-base:standoffTagHasLink and a knora-base:StandoffIntegerTag has a knora-base:valueHasInteger ). Please note the data type standoff classes can not be combined, i.e. a standoff class can only be the subclass of one data type standoff class. However, standoff data type classes can be subclassed and extended further by assigning properties to them (see below). The following simple mapping illustrates this principle: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name> text </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffRootTag </classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name> mydate </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/0001/anything#StandoffEventTag </classIri> <attributes> <attribute> <attributeName> description </attributeName> <namespace> noNamespace </namespace> <propertyIri> http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription </propertyIri> </attribute> </attributes> <datatype> <type> http://www.knora.org/ontology/knora-base#StandoffDateTag </type> <attributeName> knoraDate </attributeName> </datatype> </standoffClass> </mappingElement> </mapping> <datatype> must hold the Iri of a standoff data type class (see list above). The <classIri> must be a subclass of this type or this type itself (the latter is probably not recommendable since semantics are missing: what is the meaning of the date?). In the example above, the standoff class is anything:StandoffEventTag which has the following definition in the ontology anything-onto.ttl : anything:StandoffEventTag rdf:type owl:Class ; rdfs:subClassOf knora-base:StandoffDateTag, [ rdf:type owl:Restriction ; owl:onProperty :standoffEventTagHasDescription ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:label \"Represents an event in a TextValue\"@en ; rdfs:comment \"\"\"Represents an event in a TextValue\"\"\"@en . anything:StandoffEventTag is a subclass of knora-base:StandoffDateTag and therefore has the data type date. It also requires the standoff property anything:standoffEventTagHasDescription which is defined as an attribute in the mapping. Once the mapping has been created, an XML like the following could be sent to Knora and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description= \"new year\" knoraDate= \"GREGORIAN:2016-12-31\" > New Year's Eve </mydate> . It was a lot of fun. </text> The attribute holds the date in the format of a Knora date string (the format is also documented in the typescript type alias dateString in module basicMessageComponents . There you will also find documentation about the other types like color etc.). Knora date strings have this format: GREGORIAN|JULIAN):YYYY[-MM[-DD]][:YYYY[-MM[-DD]]] . This allows for different formats as well as for imprecision and periods. Intervals are submitted as one attribute in the following format: interval-attribute=\"1.0,2.0\" (two decimal numbers separated with a comma). You will find a sample mapping with all the data types and a sample XML file in the the test data: test_data/test_route/texts/mappingForHTML.xml and test_data/test_route/texts/HTML.xml . Internal References in an XML Document Internal references inside an XML document can be represented using the data type standoff class knora-base:StandoffInternalReferenceTag or a subclass of it. This class has a standoff property that points to a standoff node representing the target XML element when converted to RDF. The following example shows the definition of a mapping element for an internal reference (for reasons of simplicity, only the mapping element for the element is question is depicted): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mappingElement> <tag> <name> ref </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag </classIri> <datatype> <type> http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag </type> <attributeName> internalRef </attributeName> </datatype> </standoffClass> </mappingElement> Now, an internal reference to an element in the same document can be made that will be converted to a pointer in RDF: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This is an <sample id= \"1\" > element </sample> and here is a reference to <ref internalRef= \"#1\" > it </ref> . </text> An internal reference in XML has to start with a # followed by the value of the id attribute of the element referred to. Predefined Standoff Classes and Properties The standoff ontology standoff-onto.ttl offers a set of predefined standoff classes that can be used in a custom mapping like the following: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name> myDoc </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffRootTag </classIri> <attributes> <attribute> <attributeName> documentType </attributeName> <namespace> noNamespace </namespace> <propertyIri> http://www.knora.org/ontology/standoff#standoffRootTagHasDocumentType </propertyIri> </attribute> </attributes> </standoffClass> </mappingElement> <mappingElement> <tag> <name> p </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> true </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffParagraphTag </classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name> i </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffItalicTag </classIri> </standoffClass> </mappingElement> </mapping> Predefined standoff classes may be used by various projects, each providing a custom mapping to be able to recreate the original XML from RDF. Predefined standoff classes may also be inherited and extended in project specific ontologies. The mapping above allows for an XML like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <myDoc documentType= \"letter\" > <p> This my text that is <i> very </i> interesting. </p> <p> And here it goes on. </p> </myDoc> Respecting Property Types When mapping XML attributes to standoff properties, attention has to be paid to the properties' object constraints. In the ontology, standoff property literals may have one of the following knora-base:objectDatatypeConstraint : xsd:string xsd:integer xsd:boolean xsd:decimal xsd:anyURI In XML, all attribute values are submitted as strings. However, these string representations need to be convertible to the types defined in the ontology. If they are not, the request will be rejected. It is recommended to enforce types on attributes by applying XML Schema validations (restrictions). Links (object property) to a knora-base:Resource can be represented using the data type standoff class knora-base:StandoffLinkTag , internal links using the data type standoff class knora-base:StandoffInternalReferenceTag . Validating a Mapping and sending it to Knora A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v1/mapping The multipart request consists of two named parts: \"json\": { \"project_id\": \"projectIRI\", \"label\": \"my mapping\", \"mappingName\": \"MappingNameSegment\" } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the mappingName submitted in the JSON (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the typescript interfaces addMappingRequest and addMappingResponse in module mappingFormats","title":"XML to Standoff Mapping"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#xml-to-standoff-mapping-in-api-v1","text":"","title":"XML to Standoff Mapping in API v1"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#the-knora-standard-mapping","text":"","title":"The Knora Standard Mapping"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#description","text":"A mapping allows for the conversion of XML to standoff representation in RDF and back. In order to create a TextValue with markup, the text has to be provided in XML format, along with the IRI of the mapping that will be used to convert the markup to standoff. However, a mapping is only needed if a TextValue with markup should be created. If a text has no markup, it is submitted as a mere sequence of characters. The two cases are described in the TypeScript interfaces simpletext and richtext in module basicMessageComponents . Knora offers a standard mapping with the IRI http://rdfh.ch/standoff/mappings/StandardMapping . The standard mapping covers the HTML elements and attributes supported by the GUI's text editor, CKEditor . (Please note that the HTML has to be encoded in strict XML syntax. CKeditor offers the possibility to define filter rules. They should reflect the elements supported by the mapping; see jquery.htmleditor.js .) The standard mapping contains the following elements and attributes that are mapped to standoff classes and properties defined in the ontology: <text> \u2192 standoff:StandoffRootTag <p> \u2192 standoff:StandoffParagraphTag <em> \u2192 standoff:StandoffItalicTag <strong> \u2192 standoff:StandoffBoldTag <u> \u2192 standoff:StandoffUnderlineTag <sub> \u2192 standoff:StandoffSubscriptTag <sup> \u2192 standoff:StandoffSuperscriptTag <strike> \u2192 standoff:StandoffStrikeTag <a href=\"URL\"> \u2192 knora-base:StandoffUriTag <a class=\"salsah-link\" href=\"Knora IRI\"> \u2192 knora-base:StandoffLinkTag <a class=\"internal-link\" href=\"#fragment\"> \u2192 knora-base:StandoffInternalReferenceTag <h1> to <h6> \u2192 standoff:StandoffHeader1Tag to standoff:StandoffHeader6Tag <ol> \u2192 standoff:StandoffOrderedListTag <ul> \u2192 standoff:StandoffUnrderedListTag <li> \u2192 standoff:StandoffListElementTag <tbody> \u2192 standoff:StandoffTableBodyTag <table> \u2192 standoff:StandoffTableTag <tr> \u2192 standoff:StandoffTableRowTag <td> \u2192 standoff:StandoffTableCellTag <br> \u2192 standoff:StandoffBrTag <hr> \u2192 standoff:StandoffLineTag <pre> \u2192 standoff:StandoffPreTag <cite> \u2192 standoff:StandoffCiteTag <blockquote> \u2192 standoff:StandoffBlockquoteTag <code> \u2192 standoff:StandoffCodeTag The HTML produced by CKEditor is wrapped in an XML doctype and a pair of root tags <text>...</text> and then sent to Knora. The XML sent to the GUI by Knora is unwrapped accordingly (see jquery.htmleditor.js ). Although the GUI supports HTML5, it is treated as if it was XHTML in strict XML notation.","title":"Description"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#maintenance","text":"The standard mapping definition can be found at test_data/test_route/texts/mappingForStandardHTML.xml . It was used to generate the default mapping, distributed as knora-ontologies/standoff-data.ttl and that is loaded at a Knora installation. It should be used to re-generate it, whenever we want to amend or extend it. Note: once the mapping has been generated, one has to rework the resources' UUID in order to maintain backward compatibility.","title":"Maintenance"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#creating-a-custom-mapping","text":"The Knora standard mapping only supports a few HTML tags. In order to submit more complex XML markup to Knora, a custom mapping has to be created first. Basically, a mapping expresses the relations between XML elements and attributes and their corresponding standoff classes and properties. The relations expressed in a mapping are one-to-one relations, so the XML can be recreated from the data in RDF. However, since HTML offers a very limited set of elements, Knora mappings support the combination of element names and classes. In this way, the same element can be used several times in combination with another classname (please note that <a> without a class is a mere hyperlink whereas <a class=\"salsah-link\"> is an internal link/standoff link). With a mapping, a default XSL transformation may be provided to transform the XML to HTML before sending it back to the client. This is useful when the client is a web-browser expecting HTML (instead of XML).","title":"Creating a custom Mapping"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#basic-structure-of-a-mapping","text":"The mapping is written in XML itself (for a formal description, see webapi/src/resources/mappingXMLToStandoff.xsd ). It has the following structure (the indentation corresponds to the nesting in XML): <mapping> : the root element <defaultXSLTransformation> (optional) : the Iri of the default XSL transformation to be applied to the XML when reading it back from Knora. The XSL transformation is expected to produce HTML. If given, the Iri has to refer to a resource of type knora-base:XSLTransformation . <mappingElement> : an element of the mapping (at least one) <tag> : information about the XML element that is mapped to a standoff class <name> : name of the XML element <class> : value of the class attribute of the XML element, if any. If the element has no class attribute, the keyword noClass has to be used. <namespace> : the namespace the XML element belongs to, if any. If the element does not belong to a namespace, the keyword noNamespace has to be used. <separatesWords> : a Boolean value indicating whether this tag separates words in the text. Once an XML document is converted to RDF-standoff the markup is stripped from the text, possibly leading to continuous text that has been separated by tags before. For structural tags like paragraphs etc., <separatesWords> can be set to true in which case a special separator is inserted in the the text in the RDF representation. In this way, words stay separated and are represented in the fulltext index as such. <standoffClass> : information about the standoff class the XML element is mapped to <classIri> : Iri of the standoff class the XML element is mapped to <attributes> : XML attributes to be mapped to standoff properties (other than id or class ), if any <attribute> : an XML attribute to be mapped to a standoff property, may be repeated <attributeName> : the name of the XML attribute <namespace> : the namespace the attribute belongs to, if any. If the attribute does not belong to a namespace, the keyword noNamespace has to be used. <propertyIri> : the Iri of the standoff property the XML attribute is mapped to. <datatype> : the data type of the standoff class, if any. <type> : the Iri of the data type standoff class <attributeName> : the name of the attribute holding the typed value in the expected Knora standard format XML structure of a mapping: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <defaultXSLTransformation> Iri of a knora-base:XSLTransformation </defaultXSLTransformation> <mappingElement> <tag> <name> XML element name </name> <class> XML class name or \"noClass\" </class> <namespace> XML namespace or \"noNamespace\" </namespace> <separatesWords> true or false </separatesWords> </tag> <standoffClass> <classIri> standoff class Iri </classIri> <attributes> <attribute> <attributeName> XML attribute name </attributeName> <namespace> XML namespace or \"noNamespace\" </namespace> <propertyIri> standoff property Iri </propertyIri> </attribute> </attributes> <datatype> <type> standoff data type class </type> <attributeName> XML attribute with the typed value </attributeName> </datatype> </standoffClass> </mappingElement> <mappingElement> ... </mappingElement> </mapping> Please note that the absence of an XML namespace and/or a class have to be explicitly stated using the keywords noNamespace and noClass . (This is because we use XML Schema validation to ensure the one-to-one relations between XML elements and standoff classes. XML Schema validation's unique checks do not support optional values.)","title":"Basic Structure of a Mapping"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#id-and-class-attributes","text":"The id and class attributes are supported by default and do not have to be included in the mapping like other attributes. The id attribute identifies an element and must be unique in the document. id is an optional attribute. The class attribute allows for the reuse of an element in the mapping, i.e. the same element can be combined with different class names and mapped to different standoff classes (mapping element <class> in <tag> ).","title":"id and class Attributes"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#respecting-cardinalities","text":"A mapping from XML elements and attributes to standoff classes and standoff properties must respect the cardinalities defined in the ontology for those very standoff classes. If an XML element is mapped to a certain standoff class and this class requires a standoff property, an attribute must be defined for the XML element mapping to that very standoff property. Equally, all mappings for attributes of an XML element must have corresponding cardinalities for standoff properties defined for the standoff class the XML element maps to. However, since an XML attribute may occur once at maximum, it makes sense to make the corresponding standoff property required ( owl:cardinality of one) in the ontology or optional ( owl:maxCardinality of one), but not allowing it more than once.","title":"Respecting Cardinalities"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#standoff-data-types","text":"Knora allows the use of all its value types as standoff data types (defined in knora-base.ttl ): knora-base:StandoffLinkTag : Represents a reference to a Knora resource (the IRI of the target resource must be submitted in the data type attribute). knora-base:StandoffInternalReferenceTag : Represents an internal reference inside a document (the id of the target element inside the same document must be indicated in the data type attribute); see Internal References in an XML Document . knora-base:StandoffUriTag : Represents a reference to a URI (the URI of the target resource must be submitted in the data type attribute). knora-base:StandoffDateTag : Represents a date (a Knora date string must be submitted in the data type attribute, e.g. GREGORIAN:2017-01-27 ). knora-base:StandoffColorTag : Represents a color (a hexadecimal RGB color string must be submitted in the data type attribute, e.g. #0000FF ). knora-base:StandoffIntegerTag : Represents an integer (the integer must be submitted in the data type attribute). knora-base:StandoffDecimalTag : Represents a number with fractions (the decimal number must be submitted in the data type attribute, e.g. 1.1 ). knora-base:StandoffIntervalTag : Represents an interval (two decimal numbers separated with a comma must be submitted in the data type attribute, e.g. 1.1,2.2 ). knora-base:StandoffBooleanTag : Represents a Boolean value ( true or false must be submitted in the data type attribute). knora-base:StandoffTimeTag : Represents a timestamp value (an xsd:dateTimeStamp must be submitted in the data type attribute). The basic idea is that parts of a text can be marked up in a way that allows using Knora's built-in data types. In order to do so, the typed values have to be provided in a standardized way in an attribute that has to be defined in the mapping. Data type standoff classes are standoff classes with predefined properties (e.g., a knora-base:StandoffLinkTag has a knora-base:standoffTagHasLink and a knora-base:StandoffIntegerTag has a knora-base:valueHasInteger ). Please note the data type standoff classes can not be combined, i.e. a standoff class can only be the subclass of one data type standoff class. However, standoff data type classes can be subclassed and extended further by assigning properties to them (see below). The following simple mapping illustrates this principle: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name> text </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffRootTag </classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name> mydate </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/0001/anything#StandoffEventTag </classIri> <attributes> <attribute> <attributeName> description </attributeName> <namespace> noNamespace </namespace> <propertyIri> http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription </propertyIri> </attribute> </attributes> <datatype> <type> http://www.knora.org/ontology/knora-base#StandoffDateTag </type> <attributeName> knoraDate </attributeName> </datatype> </standoffClass> </mappingElement> </mapping> <datatype> must hold the Iri of a standoff data type class (see list above). The <classIri> must be a subclass of this type or this type itself (the latter is probably not recommendable since semantics are missing: what is the meaning of the date?). In the example above, the standoff class is anything:StandoffEventTag which has the following definition in the ontology anything-onto.ttl : anything:StandoffEventTag rdf:type owl:Class ; rdfs:subClassOf knora-base:StandoffDateTag, [ rdf:type owl:Restriction ; owl:onProperty :standoffEventTagHasDescription ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:label \"Represents an event in a TextValue\"@en ; rdfs:comment \"\"\"Represents an event in a TextValue\"\"\"@en . anything:StandoffEventTag is a subclass of knora-base:StandoffDateTag and therefore has the data type date. It also requires the standoff property anything:standoffEventTagHasDescription which is defined as an attribute in the mapping. Once the mapping has been created, an XML like the following could be sent to Knora and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description= \"new year\" knoraDate= \"GREGORIAN:2016-12-31\" > New Year's Eve </mydate> . It was a lot of fun. </text> The attribute holds the date in the format of a Knora date string (the format is also documented in the typescript type alias dateString in module basicMessageComponents . There you will also find documentation about the other types like color etc.). Knora date strings have this format: GREGORIAN|JULIAN):YYYY[-MM[-DD]][:YYYY[-MM[-DD]]] . This allows for different formats as well as for imprecision and periods. Intervals are submitted as one attribute in the following format: interval-attribute=\"1.0,2.0\" (two decimal numbers separated with a comma). You will find a sample mapping with all the data types and a sample XML file in the the test data: test_data/test_route/texts/mappingForHTML.xml and test_data/test_route/texts/HTML.xml .","title":"Standoff Data Types"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#internal-references-in-an-xml-document","text":"Internal references inside an XML document can be represented using the data type standoff class knora-base:StandoffInternalReferenceTag or a subclass of it. This class has a standoff property that points to a standoff node representing the target XML element when converted to RDF. The following example shows the definition of a mapping element for an internal reference (for reasons of simplicity, only the mapping element for the element is question is depicted): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mappingElement> <tag> <name> ref </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag </classIri> <datatype> <type> http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag </type> <attributeName> internalRef </attributeName> </datatype> </standoffClass> </mappingElement> Now, an internal reference to an element in the same document can be made that will be converted to a pointer in RDF: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This is an <sample id= \"1\" > element </sample> and here is a reference to <ref internalRef= \"#1\" > it </ref> . </text> An internal reference in XML has to start with a # followed by the value of the id attribute of the element referred to.","title":"Internal References in an XML Document"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#predefined-standoff-classes-and-properties","text":"The standoff ontology standoff-onto.ttl offers a set of predefined standoff classes that can be used in a custom mapping like the following: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name> myDoc </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffRootTag </classIri> <attributes> <attribute> <attributeName> documentType </attributeName> <namespace> noNamespace </namespace> <propertyIri> http://www.knora.org/ontology/standoff#standoffRootTagHasDocumentType </propertyIri> </attribute> </attributes> </standoffClass> </mappingElement> <mappingElement> <tag> <name> p </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> true </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffParagraphTag </classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name> i </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffItalicTag </classIri> </standoffClass> </mappingElement> </mapping> Predefined standoff classes may be used by various projects, each providing a custom mapping to be able to recreate the original XML from RDF. Predefined standoff classes may also be inherited and extended in project specific ontologies. The mapping above allows for an XML like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <myDoc documentType= \"letter\" > <p> This my text that is <i> very </i> interesting. </p> <p> And here it goes on. </p> </myDoc>","title":"Predefined Standoff Classes and Properties"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#respecting-property-types","text":"When mapping XML attributes to standoff properties, attention has to be paid to the properties' object constraints. In the ontology, standoff property literals may have one of the following knora-base:objectDatatypeConstraint : xsd:string xsd:integer xsd:boolean xsd:decimal xsd:anyURI In XML, all attribute values are submitted as strings. However, these string representations need to be convertible to the types defined in the ontology. If they are not, the request will be rejected. It is recommended to enforce types on attributes by applying XML Schema validations (restrictions). Links (object property) to a knora-base:Resource can be represented using the data type standoff class knora-base:StandoffLinkTag , internal links using the data type standoff class knora-base:StandoffInternalReferenceTag .","title":"Respecting Property Types"},{"location":"DSP-API/03-endpoints/api-v1/xml-to-standoff-mapping/#validating-a-mapping-and-sending-it-to-knora","text":"A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v1/mapping The multipart request consists of two named parts: \"json\": { \"project_id\": \"projectIRI\", \"label\": \"my mapping\", \"mappingName\": \"MappingNameSegment\" } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the mappingName submitted in the JSON (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the typescript interfaces addMappingRequest and addMappingResponse in module mappingFormats","title":"Validating a Mapping and sending it to Knora"},{"location":"DSP-API/03-endpoints/api-v2/authentication/","text":"Authentication Access to the DSP-API can for certain operations require a user to authenticate. Authentication can be performed in two ways: By providing password credentials , which are a combination of a identifier and password . The user identifier can be one of the following: the user's IRI, the user's Email, or the user's Username. By providing an access token Submitting Password Credentials When accessing any route and password credentials would need to be sent, we support two options to do so: in the URL submitting the parameters iri / email / username and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedIdentifier&password=pw ), and in the HTTP header ( HTTP basic authentication ), where the identifier can be the user's email (IRI and username not supported). When using Python's module requests , the credentials can simply be submitted as a tuple with each request using the param auth ( python requests ). Access Token / Session / Login and Logout A client can generate an access token by sending a POST request (e.g., {\"identifier_type\":\"identifier_value\", \"password\":\"password_value\"} ) to the /v2/authentication route with identifier and password in the body. The identifier_type can be iri , email , or username . If the credentials are valid, a JSON WEB Token (JWT) will be sent back in the response (e.g., {\"token\": \"eyJ0eXAiOiJ...\"} ). Additionally, for web browser clients a session cookie containing the JWT token is also created, containing KnoraAuthentication=eyJ0eXAiOiJ... . When accessing any route, the access token would need to be supplied, we support three options to do so: the session cookie, in the URL submitting the parameter token (e.g., http://knora-host/v1/resources/resIri?token=1234567890 ), and in the HTTP authorization header with the HTTP bearer scheme . If the token is successfully validated, then the user is deemed authenticated. To logout , the client sends a DELETE request to the same route /v2/authentication and the access token in one of the three described ways. This will invalidate the access token, thus not allowing further request that would supply the invalidated token. Checking Credentials To check the credentials, send a GET request to /v2/authentication with the credentials supplied as URL parameters or HTTP authentication headers as described before. Usage Scenarios Create token by logging-in, send token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Authentication"},{"location":"DSP-API/03-endpoints/api-v2/authentication/#authentication","text":"Access to the DSP-API can for certain operations require a user to authenticate. Authentication can be performed in two ways: By providing password credentials , which are a combination of a identifier and password . The user identifier can be one of the following: the user's IRI, the user's Email, or the user's Username. By providing an access token","title":"Authentication"},{"location":"DSP-API/03-endpoints/api-v2/authentication/#submitting-password-credentials","text":"When accessing any route and password credentials would need to be sent, we support two options to do so: in the URL submitting the parameters iri / email / username and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedIdentifier&password=pw ), and in the HTTP header ( HTTP basic authentication ), where the identifier can be the user's email (IRI and username not supported). When using Python's module requests , the credentials can simply be submitted as a tuple with each request using the param auth ( python requests ).","title":"Submitting Password Credentials"},{"location":"DSP-API/03-endpoints/api-v2/authentication/#access-token-session-login-and-logout","text":"A client can generate an access token by sending a POST request (e.g., {\"identifier_type\":\"identifier_value\", \"password\":\"password_value\"} ) to the /v2/authentication route with identifier and password in the body. The identifier_type can be iri , email , or username . If the credentials are valid, a JSON WEB Token (JWT) will be sent back in the response (e.g., {\"token\": \"eyJ0eXAiOiJ...\"} ). Additionally, for web browser clients a session cookie containing the JWT token is also created, containing KnoraAuthentication=eyJ0eXAiOiJ... . When accessing any route, the access token would need to be supplied, we support three options to do so: the session cookie, in the URL submitting the parameter token (e.g., http://knora-host/v1/resources/resIri?token=1234567890 ), and in the HTTP authorization header with the HTTP bearer scheme . If the token is successfully validated, then the user is deemed authenticated. To logout , the client sends a DELETE request to the same route /v2/authentication and the access token in one of the three described ways. This will invalidate the access token, thus not allowing further request that would supply the invalidated token.","title":"Access Token / Session / Login and Logout"},{"location":"DSP-API/03-endpoints/api-v2/authentication/#checking-credentials","text":"To check the credentials, send a GET request to /v2/authentication with the credentials supplied as URL parameters or HTTP authentication headers as described before.","title":"Checking Credentials"},{"location":"DSP-API/03-endpoints/api-v2/authentication/#usage-scenarios","text":"Create token by logging-in, send token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Usage Scenarios"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/","text":"Creating and Editing Resources Creating a Resource To create a new resources, use this route: HTTP POST to http://host/v2/resources The body of the request is a JSON-LD document in the complex API schema , specifying the type, rdfs:label , and its Knora resource properties and their values. The representation of the resource is the same as when it is returned in a GET request, except that its knora-api:attachedToUser is not given, and the resource IRI and those of its values can be optionally specified. The format of the values submitted is described in Creating and Editing Values . If there are multiple values for a property, these must be given in an array. For example, here is a request to create a resource with various value types: { \"@type\" : \"anything:Thing\" , \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\" , \"knora-api:booleanValueAsBoolean\" : true }, \"anything:hasColor\" : { \"@type\" : \"knora-api:ColorValue\" , \"knora-api:colorValueAsColor\" : \"#ff3333\" }, \"anything:hasDate\" : { \"@type\" : \"knora-api:DateValue\" , \"knora-api:dateValueHasCalendar\" : \"GREGORIAN\" , \"knora-api:dateValueHasEndEra\" : \"CE\" , \"knora-api:dateValueHasEndYear\" : 1489 , \"knora-api:dateValueHasStartEra\" : \"CE\" , \"knora-api:dateValueHasStartYear\" : 1489 }, \"anything:hasDecimal\" : { \"@type\" : \"knora-api:DecimalValue\" , \"knora-api:decimalValueAsDecimal\" : { \"@type\" : \"xsd:decimal\" , \"@value\" : \"100000000000000.000000000000001\" } }, \"anything:hasGeometry\" : { \"@type\" : \"knora-api:GeomValue\" , \"knora-api:geometryValueAsGeometry\" : \"{\\\"status\\\":\\\"active\\\",\\\"lineColor\\\":\\\"#ff3333\\\",\\\"lineWidth\\\":2,\\\"points\\\":[{\\\"x\\\":0.08098591549295775,\\\"y\\\":0.16741071428571427},{\\\"x\\\":0.7394366197183099,\\\"y\\\":0.7299107142857143}],\\\"type\\\":\\\"rectangle\\\",\\\"original_index\\\":0}\" }, \"anything:hasGeoname\" : { \"@type\" : \"knora-api:GeonameValue\" , \"knora-api:geonameValueAsGeonameCode\" : \"2661604\" }, \"anything:hasInteger\" : [ { \"@type\" : \"knora-api:IntValue\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" , \"knora-api:intValueAsInt\" : 5 , \"knora-api:valueHasComment\" : \"this is the number five\" }, { \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 6 } ], \"anything:hasInterval\" : { \"@type\" : \"knora-api:IntervalValue\" , \"knora-api:intervalValueHasEnd\" : { \"@type\" : \"xsd:decimal\" , \"@value\" : \"3.4\" }, \"knora-api:intervalValueHasStart\" : { \"@type\" : \"xsd:decimal\" , \"@value\" : \"1.2\" } }, \"anything:hasListItem\" : { \"@type\" : \"knora-api:ListValue\" , \"knora-api:listValueAsListNode\" : { \"@id\" : \"http://rdfh.ch/lists/0001/treeList03\" } }, \"anything:hasOtherThingValue\" : { \"@type\" : \"knora-api:LinkValue\" , \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" } }, \"anything:hasRichtext\" : { \"@type\" : \"knora-api:TextValue\" , \"knora-api:textValueAsXml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text><p><strong>this is</strong> text</p> with standoff</text>\" , \"knora-api:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\" , \"knora-api:valueAsString\" : \"this is text without standoff\" }, \"anything:hasUri\" : { \"@type\" : \"knora-api:UriValue\" , \"knora-api:uriValueAsUri\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"https://www.knora.org\" } }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"rdfs:label\" : \"test thing\" , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new resource can be given by adding knora-api:hasPermissions , a custom creation date can be specified by adding knora-api:creationDate (an xsd:dateTimeStamp ), and the resource's creator can be specfied by adding knora-api:attachedToUser . For example: { \"@type\" : \"anything:Thing\" , \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\" , \"knora-api:booleanValueAsBoolean\" : true }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"rdfs:label\" : \"test thing\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" , \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a resource, the user must have permission to create resources of that class in that project. The predicate knora-api:attachedToUser can be used to specify a creator other than the requesting user only if the requesting user is an administrator of the project or a system administrator. The specified creator must also have permission to create resources of that class in that project. In addition to the creation date, in the body of the request, it is possible to specify a custom IRI ( of Knora IRI form) for a resource through the @id attribute which will then be assigned to the resource; otherwise the resource will get a unique random IRI. A custom resource IRI must be http://rdfh.ch/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the resource belongs to) plus a custom ID string. Similarly, it is possible to assign a custom IRI to the values using their @id attributes; if not given, random IRIs will be assigned to the values. A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. An optional custom UUID of a value can also be given by adding knora-api:valueHasUUID . Each custom UUID must be base64url-encoded without padding. Each value of the new resource can also have a custom creation date specified by adding knora-api:creationDate (an xsd:dateTimeStamp ). For example: { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw\" , \"@type\" : \"anything:Thing\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw/values/IN4R19yYR0ygi3K2VEHpUQ\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 10 , \"knora-api:valueHasUUID\" : \"IN4R19yYR0ygi3K2VEHpUQ\" , \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2020-06-04T12:58:54.502951Z\" } }, \"rdfs:label\" : \"test thing with custom IRI\" , \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The response is a JSON-LD document containing a preview of the resource. Modifying a Resource's Values See Creating and Editing Values . Modifying a Resource's Metadata You can modify the following metadata attached to a resource: label permissions last modification date To do this, use this route: HTTP PUT to http://host/v2/resources The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. The submitted JSON-LD object must also contain one or more of the following predicates, representing the metadata you want to change: rdfs:label : a string knora-api:hasPermissions , in the format described in Permissions knora-api:newModificationDate : an xsd:dateTimeStamp . Here is an example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"rdfs:label\" : \"this is the new label\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:ProjectMember\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2017-11-20T15:55:17Z\" }, \"knora-api:newModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2018-12-21T16:56:18Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } If you submit a knora-api:lastModificationDate that is different from the resource's actual last modification date, you will get an HTTP 409 (Conflict) error. If you submit a knora-api:newModificationDate that is earlier than the resource's knora-api:lastModificationDate , you will get an HTTP 400 (Bad Request) error. A successful response is an HTTP 200 (OK) status containing the resource's metadata. Deleting a Resource Knora does not normally delete resources; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a resource as deleted, use this route: HTTP POST to http://host/v2/resources/delete The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-05T17:05:35.776747Z\" }, \"knora-api:deleteComment\" : \"This resource was created by mistake.\" , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the resource, explaining why it has been marked as deleted. The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) indicates when the resource was marked as deleted; if not given, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message. Requesting Deleted Resources Resources marked as deleted are not found in search queries. It is however possible to request them directly or from an ARK URL. In these instances, the API will not return the deleted resource, but instead a generic resource of type knora-base:DeletedResource . This resource will be similar to the requested resource, having e.g. the same IRI. The resource will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"rdfs:label\" : \"Deleted Resource\" , \"knora-api:versionArkUrl\" : { \"@value\" : \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO.20211214T084407677335Z\" , \"@type\" : \"xsd:anyURI\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:userHasPermission\" : \"CR\" , \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:ProjectMember|V knora-admin:ProjectMember\" , \"knora-api:isDeleted\" : true , \"@type\" : \"knora-api:DeletedResource\" , \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"knora-api:deleteComment\" : \"This resource is too boring.\" , \"knora-api:arkUrl\" : { \"@value\" : \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO\" , \"@type\" : \"xsd:anyURI\" }, \"knora-api:creationDate\" : { \"@value\" : \"2021-12-14T08:44:07.677335Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2021-12-14T08:44:07.372543Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Links to Deleted Resources If resource A has a link to resource B , and resource B is later marked as deleted, A 's link will still exist. DSP-API v2 will still return the link when A is queried, but without any information about B (except for B 's IRI). If A 's link is necessary to meet the requirements of a cardinality, marking B as deleted will not violate the cardinality. The reason for this design is that A and B might be in different projects, and each project must retain control of its resources and be able to mark them as deleted, even if they are used by another project. Erasing a Resource from the Triplestore Normally, resources are not actually removed from the triplestore; they are only marked as deleted (see Deleting a Resource ). However, sometimes it is necessary to erase a resource from the triplestore. To do so, use this route: HTTP POST to http://host/v2/resources/erase The request body is the same as for Deleting a Resource , except that knora-api:deleteComment is not relevant and will be ignored. To do this, a user must be a system administrator or an administrator of the project containing the resource. The user's permissions on the resource are not otherwise checked. A resource cannot be erased if any other resource has a link to it. Any such links must first be changed or marked as deleted (see Updating a Value and Deleting a Value ). Then, when the resource is erased, the deleted link values that referred to it will also be erased. This operation cannot be undone (except by restoring the repository from a backup), so use it with care.","title":"Creating and Editing Resources"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/#creating-and-editing-resources","text":"","title":"Creating and Editing Resources"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/#creating-a-resource","text":"To create a new resources, use this route: HTTP POST to http://host/v2/resources The body of the request is a JSON-LD document in the complex API schema , specifying the type, rdfs:label , and its Knora resource properties and their values. The representation of the resource is the same as when it is returned in a GET request, except that its knora-api:attachedToUser is not given, and the resource IRI and those of its values can be optionally specified. The format of the values submitted is described in Creating and Editing Values . If there are multiple values for a property, these must be given in an array. For example, here is a request to create a resource with various value types: { \"@type\" : \"anything:Thing\" , \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\" , \"knora-api:booleanValueAsBoolean\" : true }, \"anything:hasColor\" : { \"@type\" : \"knora-api:ColorValue\" , \"knora-api:colorValueAsColor\" : \"#ff3333\" }, \"anything:hasDate\" : { \"@type\" : \"knora-api:DateValue\" , \"knora-api:dateValueHasCalendar\" : \"GREGORIAN\" , \"knora-api:dateValueHasEndEra\" : \"CE\" , \"knora-api:dateValueHasEndYear\" : 1489 , \"knora-api:dateValueHasStartEra\" : \"CE\" , \"knora-api:dateValueHasStartYear\" : 1489 }, \"anything:hasDecimal\" : { \"@type\" : \"knora-api:DecimalValue\" , \"knora-api:decimalValueAsDecimal\" : { \"@type\" : \"xsd:decimal\" , \"@value\" : \"100000000000000.000000000000001\" } }, \"anything:hasGeometry\" : { \"@type\" : \"knora-api:GeomValue\" , \"knora-api:geometryValueAsGeometry\" : \"{\\\"status\\\":\\\"active\\\",\\\"lineColor\\\":\\\"#ff3333\\\",\\\"lineWidth\\\":2,\\\"points\\\":[{\\\"x\\\":0.08098591549295775,\\\"y\\\":0.16741071428571427},{\\\"x\\\":0.7394366197183099,\\\"y\\\":0.7299107142857143}],\\\"type\\\":\\\"rectangle\\\",\\\"original_index\\\":0}\" }, \"anything:hasGeoname\" : { \"@type\" : \"knora-api:GeonameValue\" , \"knora-api:geonameValueAsGeonameCode\" : \"2661604\" }, \"anything:hasInteger\" : [ { \"@type\" : \"knora-api:IntValue\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" , \"knora-api:intValueAsInt\" : 5 , \"knora-api:valueHasComment\" : \"this is the number five\" }, { \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 6 } ], \"anything:hasInterval\" : { \"@type\" : \"knora-api:IntervalValue\" , \"knora-api:intervalValueHasEnd\" : { \"@type\" : \"xsd:decimal\" , \"@value\" : \"3.4\" }, \"knora-api:intervalValueHasStart\" : { \"@type\" : \"xsd:decimal\" , \"@value\" : \"1.2\" } }, \"anything:hasListItem\" : { \"@type\" : \"knora-api:ListValue\" , \"knora-api:listValueAsListNode\" : { \"@id\" : \"http://rdfh.ch/lists/0001/treeList03\" } }, \"anything:hasOtherThingValue\" : { \"@type\" : \"knora-api:LinkValue\" , \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" } }, \"anything:hasRichtext\" : { \"@type\" : \"knora-api:TextValue\" , \"knora-api:textValueAsXml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text><p><strong>this is</strong> text</p> with standoff</text>\" , \"knora-api:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\" , \"knora-api:valueAsString\" : \"this is text without standoff\" }, \"anything:hasUri\" : { \"@type\" : \"knora-api:UriValue\" , \"knora-api:uriValueAsUri\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"https://www.knora.org\" } }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"rdfs:label\" : \"test thing\" , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new resource can be given by adding knora-api:hasPermissions , a custom creation date can be specified by adding knora-api:creationDate (an xsd:dateTimeStamp ), and the resource's creator can be specfied by adding knora-api:attachedToUser . For example: { \"@type\" : \"anything:Thing\" , \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\" , \"knora-api:booleanValueAsBoolean\" : true }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"rdfs:label\" : \"test thing\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" , \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a resource, the user must have permission to create resources of that class in that project. The predicate knora-api:attachedToUser can be used to specify a creator other than the requesting user only if the requesting user is an administrator of the project or a system administrator. The specified creator must also have permission to create resources of that class in that project. In addition to the creation date, in the body of the request, it is possible to specify a custom IRI ( of Knora IRI form) for a resource through the @id attribute which will then be assigned to the resource; otherwise the resource will get a unique random IRI. A custom resource IRI must be http://rdfh.ch/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the resource belongs to) plus a custom ID string. Similarly, it is possible to assign a custom IRI to the values using their @id attributes; if not given, random IRIs will be assigned to the values. A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. An optional custom UUID of a value can also be given by adding knora-api:valueHasUUID . Each custom UUID must be base64url-encoded without padding. Each value of the new resource can also have a custom creation date specified by adding knora-api:creationDate (an xsd:dateTimeStamp ). For example: { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw\" , \"@type\" : \"anything:Thing\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw/values/IN4R19yYR0ygi3K2VEHpUQ\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 10 , \"knora-api:valueHasUUID\" : \"IN4R19yYR0ygi3K2VEHpUQ\" , \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2020-06-04T12:58:54.502951Z\" } }, \"rdfs:label\" : \"test thing with custom IRI\" , \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The response is a JSON-LD document containing a preview of the resource.","title":"Creating a Resource"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/#modifying-a-resources-values","text":"See Creating and Editing Values .","title":"Modifying a Resource's Values"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/#modifying-a-resources-metadata","text":"You can modify the following metadata attached to a resource: label permissions last modification date To do this, use this route: HTTP PUT to http://host/v2/resources The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. The submitted JSON-LD object must also contain one or more of the following predicates, representing the metadata you want to change: rdfs:label : a string knora-api:hasPermissions , in the format described in Permissions knora-api:newModificationDate : an xsd:dateTimeStamp . Here is an example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"rdfs:label\" : \"this is the new label\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:ProjectMember\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2017-11-20T15:55:17Z\" }, \"knora-api:newModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2018-12-21T16:56:18Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } If you submit a knora-api:lastModificationDate that is different from the resource's actual last modification date, you will get an HTTP 409 (Conflict) error. If you submit a knora-api:newModificationDate that is earlier than the resource's knora-api:lastModificationDate , you will get an HTTP 400 (Bad Request) error. A successful response is an HTTP 200 (OK) status containing the resource's metadata.","title":"Modifying a Resource's Metadata"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/#deleting-a-resource","text":"Knora does not normally delete resources; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a resource as deleted, use this route: HTTP POST to http://host/v2/resources/delete The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-05T17:05:35.776747Z\" }, \"knora-api:deleteComment\" : \"This resource was created by mistake.\" , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the resource, explaining why it has been marked as deleted. The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) indicates when the resource was marked as deleted; if not given, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message.","title":"Deleting a Resource"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/#requesting-deleted-resources","text":"Resources marked as deleted are not found in search queries. It is however possible to request them directly or from an ARK URL. In these instances, the API will not return the deleted resource, but instead a generic resource of type knora-base:DeletedResource . This resource will be similar to the requested resource, having e.g. the same IRI. The resource will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"rdfs:label\" : \"Deleted Resource\" , \"knora-api:versionArkUrl\" : { \"@value\" : \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO.20211214T084407677335Z\" , \"@type\" : \"xsd:anyURI\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:userHasPermission\" : \"CR\" , \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:ProjectMember|V knora-admin:ProjectMember\" , \"knora-api:isDeleted\" : true , \"@type\" : \"knora-api:DeletedResource\" , \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"knora-api:deleteComment\" : \"This resource is too boring.\" , \"knora-api:arkUrl\" : { \"@value\" : \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO\" , \"@type\" : \"xsd:anyURI\" }, \"knora-api:creationDate\" : { \"@value\" : \"2021-12-14T08:44:07.677335Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2021-12-14T08:44:07.372543Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Requesting Deleted Resources"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/#links-to-deleted-resources","text":"If resource A has a link to resource B , and resource B is later marked as deleted, A 's link will still exist. DSP-API v2 will still return the link when A is queried, but without any information about B (except for B 's IRI). If A 's link is necessary to meet the requirements of a cardinality, marking B as deleted will not violate the cardinality. The reason for this design is that A and B might be in different projects, and each project must retain control of its resources and be able to mark them as deleted, even if they are used by another project.","title":"Links to Deleted Resources"},{"location":"DSP-API/03-endpoints/api-v2/editing-resources/#erasing-a-resource-from-the-triplestore","text":"Normally, resources are not actually removed from the triplestore; they are only marked as deleted (see Deleting a Resource ). However, sometimes it is necessary to erase a resource from the triplestore. To do so, use this route: HTTP POST to http://host/v2/resources/erase The request body is the same as for Deleting a Resource , except that knora-api:deleteComment is not relevant and will be ignored. To do this, a user must be a system administrator or an administrator of the project containing the resource. The user's permissions on the resource are not otherwise checked. A resource cannot be erased if any other resource has a link to it. Any such links must first be changed or marked as deleted (see Updating a Value and Deleting a Value ). Then, when the resource is erased, the deleted link values that referred to it will also be erased. This operation cannot be undone (except by restoring the repository from a backup), so use it with care.","title":"Erasing a Resource from the Triplestore"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/","text":"Creating and Editing Values Creating a Value To create a value in an existing resource, use this route: HTTP POST to http://host/v2/values The body of the request is a JSON-LD document in the complex API schema , specifying the resource's IRI and type, the resource property, and the content of the value. The representation of the value is the same as when it is returned in a GET request, except that its IRI and knora-api:attachedToUser are not given. For example, to create an integer value: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 4 }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have a comment, given in knora-api:valueHasComment . For example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 4 , \"knora-api:valueHasComment\" : \"This is a comment.\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new value can be given by adding knora-api:hasPermissions . For example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 4 , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have an optional custom IRI (of Knora IRI form) specified by the @id attribute, a custom creation date specified by adding knora-api:valueCreationDate (an xsd:dateTimeStamp ), or a custom UUID given by knora-api:valueHasUUID . Each custom UUID must be base64url-encoded , without padding. If a custom UUID is provided, it will be used in value IRI. If a custom IRI is given for the value, its UUID should match the given custom UUID. If a custom IRI is provided, but there is no custom UUID provided, then the UUID given in the IRI will be assigned to the knora-api:valueHasUUID . A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. For example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/IN4R19yYR0ygi3K2VEHpUQ\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 21 , \"knora-api:valueHasUUID\" : \"IN4R19yYR0ygi3K2VEHpUQ\" , \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2020-06-04T12:58:54.502951Z\" } }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a value, the user must have modify permission on the containing resource. The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions (except for link values, as explained below). Creating a Link Between Resources To create a link, you must create a knora-api:LinkValue , which represents metadata about the link. The property that connects the resource to the LinkValue is a link value property, whose name is constructed by adding Value to the name of the link property (see Links Between Resources ). The triple representing the direct link between the resources is created automatically. For example, if the link property that should connect the resources is anything:hasOtherThing , we can create a link like this: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasOtherThingValue\" : { \"@type\" : \"knora-api:LinkValue\" , \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } As with ordinary values, permissions on links can be specified by adding knora-api:hasPermissions . The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the link is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Changing a link's metadata, without changing its target, creates a new version of the link value with the same UUID. Creating a Text Value Without Standoff Markup Use the predicate knora-api:valueAsString of knora-api:TextValue : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\" , \"knora-api:valueAsString\" : \"This is a text without markup.\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Creating a Text Value with Standoff Markup Currently, the only way to create a text value with standoff markup is to submit it in XML format using an XML-to-standoff mapping . Creating a Text Value with Standard Mapping To create a value with the standard mapping ( http://rdfh.ch/standoff/mappings/StandardMapping ), we can make an XML document like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This text links to another <a class= \"salsah-link\" href= \"http://rdfh.ch/0001/another-thing\" > resource </a> . </text> This document can then be embedded in a JSON-LD request, using the predicate knora-api:textValueAsXml : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\" , \"knora-api:textValueAsXml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text>\\n This text links to another <a class=\\\"salsah-link\\\" href=\\\"http://rdfh.ch/0001/another-thing\\\">resource</a>.\\n</text>\" , \"knora-api:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Note that quotation marks and line breaks in the XML must be escaped, and that the IRI of the mapping must be provided. Creating a Text Value with a Custom Mapping To create a text value with custom mapping, the following steps are required: Optionally, an XSL transformation resource ( kb:XSLTransformation ) can be created that may be defined as the default transformation of the mapping. The mapping resource ( kb:XMLToStandoffMapping ) must be created, if it does not already exist. The text value can be created as in the example above, using the mapping resource IRI in kb:textValueHasMapping . The kb:XSLTransformation resource is a subclass of kb:TextRepresentation , so it has a kb:hasTextFileValue pointing to a kb:TextFileValue which represents the XSLT file stored in SIPI. For more Details, see Creating File Values . The kb:XMLToStandoffMapping resource requires the mapping XML as specified here . If an XSL transformation has been defined, the IRI the transformation can be placed in the <defaultXSLTransformation> tag of the mapping XML. If a mapping has been defined, then requesting the text value will return both the kb:textValueAsXml and the kb:textValueAsHtml properties, where the XML can be used for editing the value, while the HTML can be used to display it. If no mapping has been defined, only kb:textValueAsXml can be returned. Creating File Values Knora supports the storage of certain types of data as files, using Sipi (see FileValue ). DSP-API v2 currently supports using Sipi to store the following types of files: Images: JPEG, JPEG2000, TIFF, or PNG which are stored internally as JPEG2000 Documents: PDF Audio: MPEG or Waveform audio file format (.wav, .x-wav, .vnd.wave) Text files: TXT, XML, or CSV Video files: MP4 Archive files: ZIP, TAR, GZIP Support for other types of files will be added in the future. The following sections describe the steps for creating a file value. Upload Files to Sipi The first step is to upload one or more files to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The token parameter must provide the JSON Web Token that Knora returned when the client logged in. Each body part in the request must contain a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi stores the file in a temporary location. If the file is an image, it is converted first to JPEG2000 format, and the converted file is stored. Sipi then returns a JSON response that looks something like this: { \"uploadedFiles\" : [ { \"originalFilename\" : \"manuscript-1234-page-1.tiff\" , \"internalFilename\" : \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" , \"temporaryBaseIIIFUrl\" : \"http://sipihost/tmp\" }, { \"originalFilename\" : \"manuscript-1234-page-2.tiff\" , \"internalFilename\" : \"2RvJgguglpe-B45EOk0Gx8H.jp2\" , \"temporaryBaseIIIFUrl\" : \"http://sipihost/tmp\" } ] } In this example, we uploaded two files to Sipi, so uploadedFiles is an array with two elements. For each file, we have: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file In the case of an image file, the client may now wish to get a thumbnail of each uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image that is 150 pixels wide, you would add /full/150,/0/default.jpg . Submit A File Value to Knora A Knora Representation (i.e. a resource containing information about a file) must always have exactly one file value attached to it. (see Representations ). Therefore, a request to create a new file value must always be submitted as part of a request to create a new resource (see Creating a Resource ). You can also update a file value in an existing Representation ; see Updating a Value . Instead of providing the file's complete metadata to Knora, you just provide the unique internal filename generated by Sipi. Here is an example of a request to create a resource of class anything:ThingPicture , which is a subclass of knora-api:StillImageRepresentation and therefore has the property knora-api:hasStillImageFileValue : { \"@type\" : \"anything:ThingPicture\" , \"knora-api:hasStillImageFileValue\" : { \"@type\" : \"knora-api:StillImageFileValue\" , \"knora-api:fileValueHasFilename\" : \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"rdfs:label\" : \"test thing\" , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Knora then gets the rest of the file's metadata from Sipi. If the client's request to Knora is valid, Knora saves the file value in the triplestore and instructs Sipi to move the file to permanent storage. Otherwise, the temporary file that was stored by Sipi is deleted. If you're submitting a PDF document, use the resource class knora-api:DocumentRepresentation , which has the property knora-api:hasDocumentFileValue , pointing to a knora-api:DocumentFileValue . For a text file, use knora-api:TextRepresentation , which has the property knora-api:hasTextFileValue , pointing to a knora-api:TextFileValue . For an archive like zip, use knora-api:ArchiveRepresentation , which has the property knora-api:hasArchiveFileValue , pointing to a knora-api:ArchiveFileValue . Updating a Value To update a value, use this route: HTTP PUT to http://host/v2/values Updating a value means creating a new version of an existing value. The new version will have a different IRI. The request is the same as for creating a value, except that the @id of the current value version is given. For example, to update an integer value: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 5 }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The value can be given a comment by using knora-api:valueHasComment . To change only the comment of a value, you can resubmit the existing value with the updated comment. Permissions can be specified by adding knora-api:hasPermissions . Otherwise, the new version has the same permissions as the previous one. To change the permissions on a value, the user must have change rights permission on the value. To update only the permissions on a value, submit it with the new permissions and with its @id and @type but without any other content, like this: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V knora-admin:KnownUser\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } To update a link, the user must have modify permission on the containing resource as well as on the value. To update a value and give it a custom timestamp, add knora-api:valueCreationDate (an xsd:dateTimeStamp ). To update a value and give the new version a custom IRI, add knora-api:newValueVersionIri , like this: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 21 , \"knora-api:newValueVersionIri\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/int-value-IRI\" } }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. The response is a JSON-LD document containing only @id and @type , returning the IRI and type of the new value version. If you submit an outdated value ID in a request to update a value, the response will be an HTTP 404 (Not Found) error. The response to a value update request contains: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the value is a link value and is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Deleting a Value Knora does not normally delete values; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a value as deleted, use this route: HTTP POST to http://host/v2/values/delete The request must include the resource's ID and type, the property that points from the resource to the value, and the value's ID and type. For example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:deleteComment\" : \"This value was created by mistake.\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the value, explaining why it has been marked as deleted The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) specifies a custom timestamp indicating when the value was deleted. If not specified, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message. Requesting Deleted Values Values marked as deleted are not found in search queries. But when requesting a resource that has deleted values, these will show up as generic knora-api:DeletedValue values. This value will be similar to the deleted value, having e.g. the same IRI. The DeletedValue will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"knora-api:DeletedValue\" : [ { \"knora-api:versionArkUrl\" : { \"@value\" : \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU.20211216T18193124797Z\" , \"@type\" : \"xsd:anyURI\" }, \"knora-api:userHasPermission\" : \"RV\" , \"knora-api:valueCreationDate\" : { \"@value\" : \"2021-12-16T18:19:31.247970Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2021-12-16T18:20:02.550828Z\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:valueHasUUID\" : \"sWSymIzAS_qXqyHLhwbwwA\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser|RV knora-admin:UnknownUser\" , \"knora-api:isDeleted\" : true , \"@type\" : \"knora-api:DeletedValue\" , \"http://www.knora.org/ontology/knora-base#DeletedValue\" : \"DeletedValue\" , \"@id\" : \"http://rdfh.ch/0001/a-thing/values/DrXts3Up3DijGriI403nhg\" , \"knora-api:deleteComment\" : \"This value is obsolete\" , \"knora-api:arkUrl\" : { \"@value\" : \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU\" , \"@type\" : \"xsd:anyURI\" } }, {} ] }","title":"Creating and Editing Values"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#creating-and-editing-values","text":"","title":"Creating and Editing Values"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#creating-a-value","text":"To create a value in an existing resource, use this route: HTTP POST to http://host/v2/values The body of the request is a JSON-LD document in the complex API schema , specifying the resource's IRI and type, the resource property, and the content of the value. The representation of the value is the same as when it is returned in a GET request, except that its IRI and knora-api:attachedToUser are not given. For example, to create an integer value: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 4 }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have a comment, given in knora-api:valueHasComment . For example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 4 , \"knora-api:valueHasComment\" : \"This is a comment.\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new value can be given by adding knora-api:hasPermissions . For example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 4 , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have an optional custom IRI (of Knora IRI form) specified by the @id attribute, a custom creation date specified by adding knora-api:valueCreationDate (an xsd:dateTimeStamp ), or a custom UUID given by knora-api:valueHasUUID . Each custom UUID must be base64url-encoded , without padding. If a custom UUID is provided, it will be used in value IRI. If a custom IRI is given for the value, its UUID should match the given custom UUID. If a custom IRI is provided, but there is no custom UUID provided, then the UUID given in the IRI will be assigned to the knora-api:valueHasUUID . A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. For example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/IN4R19yYR0ygi3K2VEHpUQ\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 21 , \"knora-api:valueHasUUID\" : \"IN4R19yYR0ygi3K2VEHpUQ\" , \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2020-06-04T12:58:54.502951Z\" } }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a value, the user must have modify permission on the containing resource. The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions (except for link values, as explained below).","title":"Creating a Value"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#creating-a-link-between-resources","text":"To create a link, you must create a knora-api:LinkValue , which represents metadata about the link. The property that connects the resource to the LinkValue is a link value property, whose name is constructed by adding Value to the name of the link property (see Links Between Resources ). The triple representing the direct link between the resources is created automatically. For example, if the link property that should connect the resources is anything:hasOtherThing , we can create a link like this: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasOtherThingValue\" : { \"@type\" : \"knora-api:LinkValue\" , \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } As with ordinary values, permissions on links can be specified by adding knora-api:hasPermissions . The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the link is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Changing a link's metadata, without changing its target, creates a new version of the link value with the same UUID.","title":"Creating a Link Between Resources"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#creating-a-text-value-without-standoff-markup","text":"Use the predicate knora-api:valueAsString of knora-api:TextValue : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\" , \"knora-api:valueAsString\" : \"This is a text without markup.\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } }","title":"Creating a Text Value Without Standoff Markup"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#creating-a-text-value-with-standoff-markup","text":"Currently, the only way to create a text value with standoff markup is to submit it in XML format using an XML-to-standoff mapping .","title":"Creating a Text Value with Standoff Markup"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#creating-a-text-value-with-standard-mapping","text":"To create a value with the standard mapping ( http://rdfh.ch/standoff/mappings/StandardMapping ), we can make an XML document like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This text links to another <a class= \"salsah-link\" href= \"http://rdfh.ch/0001/another-thing\" > resource </a> . </text> This document can then be embedded in a JSON-LD request, using the predicate knora-api:textValueAsXml : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\" , \"knora-api:textValueAsXml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text>\\n This text links to another <a class=\\\"salsah-link\\\" href=\\\"http://rdfh.ch/0001/another-thing\\\">resource</a>.\\n</text>\" , \"knora-api:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Note that quotation marks and line breaks in the XML must be escaped, and that the IRI of the mapping must be provided.","title":"Creating a Text Value with Standard Mapping"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#creating-a-text-value-with-a-custom-mapping","text":"To create a text value with custom mapping, the following steps are required: Optionally, an XSL transformation resource ( kb:XSLTransformation ) can be created that may be defined as the default transformation of the mapping. The mapping resource ( kb:XMLToStandoffMapping ) must be created, if it does not already exist. The text value can be created as in the example above, using the mapping resource IRI in kb:textValueHasMapping . The kb:XSLTransformation resource is a subclass of kb:TextRepresentation , so it has a kb:hasTextFileValue pointing to a kb:TextFileValue which represents the XSLT file stored in SIPI. For more Details, see Creating File Values . The kb:XMLToStandoffMapping resource requires the mapping XML as specified here . If an XSL transformation has been defined, the IRI the transformation can be placed in the <defaultXSLTransformation> tag of the mapping XML. If a mapping has been defined, then requesting the text value will return both the kb:textValueAsXml and the kb:textValueAsHtml properties, where the XML can be used for editing the value, while the HTML can be used to display it. If no mapping has been defined, only kb:textValueAsXml can be returned.","title":"Creating a Text Value with a Custom Mapping"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#creating-file-values","text":"Knora supports the storage of certain types of data as files, using Sipi (see FileValue ). DSP-API v2 currently supports using Sipi to store the following types of files: Images: JPEG, JPEG2000, TIFF, or PNG which are stored internally as JPEG2000 Documents: PDF Audio: MPEG or Waveform audio file format (.wav, .x-wav, .vnd.wave) Text files: TXT, XML, or CSV Video files: MP4 Archive files: ZIP, TAR, GZIP Support for other types of files will be added in the future. The following sections describe the steps for creating a file value.","title":"Creating File Values"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#upload-files-to-sipi","text":"The first step is to upload one or more files to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The token parameter must provide the JSON Web Token that Knora returned when the client logged in. Each body part in the request must contain a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi stores the file in a temporary location. If the file is an image, it is converted first to JPEG2000 format, and the converted file is stored. Sipi then returns a JSON response that looks something like this: { \"uploadedFiles\" : [ { \"originalFilename\" : \"manuscript-1234-page-1.tiff\" , \"internalFilename\" : \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" , \"temporaryBaseIIIFUrl\" : \"http://sipihost/tmp\" }, { \"originalFilename\" : \"manuscript-1234-page-2.tiff\" , \"internalFilename\" : \"2RvJgguglpe-B45EOk0Gx8H.jp2\" , \"temporaryBaseIIIFUrl\" : \"http://sipihost/tmp\" } ] } In this example, we uploaded two files to Sipi, so uploadedFiles is an array with two elements. For each file, we have: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file In the case of an image file, the client may now wish to get a thumbnail of each uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image that is 150 pixels wide, you would add /full/150,/0/default.jpg .","title":"Upload Files to Sipi"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#submit-a-file-value-to-knora","text":"A Knora Representation (i.e. a resource containing information about a file) must always have exactly one file value attached to it. (see Representations ). Therefore, a request to create a new file value must always be submitted as part of a request to create a new resource (see Creating a Resource ). You can also update a file value in an existing Representation ; see Updating a Value . Instead of providing the file's complete metadata to Knora, you just provide the unique internal filename generated by Sipi. Here is an example of a request to create a resource of class anything:ThingPicture , which is a subclass of knora-api:StillImageRepresentation and therefore has the property knora-api:hasStillImageFileValue : { \"@type\" : \"anything:ThingPicture\" , \"knora-api:hasStillImageFileValue\" : { \"@type\" : \"knora-api:StillImageFileValue\" , \"knora-api:fileValueHasFilename\" : \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"rdfs:label\" : \"test thing\" , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Knora then gets the rest of the file's metadata from Sipi. If the client's request to Knora is valid, Knora saves the file value in the triplestore and instructs Sipi to move the file to permanent storage. Otherwise, the temporary file that was stored by Sipi is deleted. If you're submitting a PDF document, use the resource class knora-api:DocumentRepresentation , which has the property knora-api:hasDocumentFileValue , pointing to a knora-api:DocumentFileValue . For a text file, use knora-api:TextRepresentation , which has the property knora-api:hasTextFileValue , pointing to a knora-api:TextFileValue . For an archive like zip, use knora-api:ArchiveRepresentation , which has the property knora-api:hasArchiveFileValue , pointing to a knora-api:ArchiveFileValue .","title":"Submit A File Value to Knora"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#updating-a-value","text":"To update a value, use this route: HTTP PUT to http://host/v2/values Updating a value means creating a new version of an existing value. The new version will have a different IRI. The request is the same as for creating a value, except that the @id of the current value version is given. For example, to update an integer value: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 5 }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The value can be given a comment by using knora-api:valueHasComment . To change only the comment of a value, you can resubmit the existing value with the updated comment. Permissions can be specified by adding knora-api:hasPermissions . Otherwise, the new version has the same permissions as the previous one. To change the permissions on a value, the user must have change rights permission on the value. To update only the permissions on a value, submit it with the new permissions and with its @id and @type but without any other content, like this: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V knora-admin:KnownUser\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } To update a link, the user must have modify permission on the containing resource as well as on the value. To update a value and give it a custom timestamp, add knora-api:valueCreationDate (an xsd:dateTimeStamp ). To update a value and give the new version a custom IRI, add knora-api:newValueVersionIri , like this: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:intValueAsInt\" : 21 , \"knora-api:newValueVersionIri\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/int-value-IRI\" } }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. The response is a JSON-LD document containing only @id and @type , returning the IRI and type of the new value version. If you submit an outdated value ID in a request to update a value, the response will be an HTTP 404 (Not Found) error. The response to a value update request contains: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the value is a link value and is changed to point to a different resource, in which case it is considered a new link and gets a new UUID.","title":"Updating a Value"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#deleting-a-value","text":"Knora does not normally delete values; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a value as deleted, use this route: HTTP POST to http://host/v2/values/delete The request must include the resource's ID and type, the property that points from the resource to the value, and the value's ID and type. For example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\" , \"@type\" : \"anything:Thing\" , \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\" , \"@type\" : \"knora-api:IntValue\" , \"knora-api:deleteComment\" : \"This value was created by mistake.\" }, \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the value, explaining why it has been marked as deleted The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) specifies a custom timestamp indicating when the value was deleted. If not specified, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message.","title":"Deleting a Value"},{"location":"DSP-API/03-endpoints/api-v2/editing-values/#requesting-deleted-values","text":"Values marked as deleted are not found in search queries. But when requesting a resource that has deleted values, these will show up as generic knora-api:DeletedValue values. This value will be similar to the deleted value, having e.g. the same IRI. The DeletedValue will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"knora-api:DeletedValue\" : [ { \"knora-api:versionArkUrl\" : { \"@value\" : \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU.20211216T18193124797Z\" , \"@type\" : \"xsd:anyURI\" }, \"knora-api:userHasPermission\" : \"RV\" , \"knora-api:valueCreationDate\" : { \"@value\" : \"2021-12-16T18:19:31.247970Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2021-12-16T18:20:02.550828Z\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:valueHasUUID\" : \"sWSymIzAS_qXqyHLhwbwwA\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser|RV knora-admin:UnknownUser\" , \"knora-api:isDeleted\" : true , \"@type\" : \"knora-api:DeletedValue\" , \"http://www.knora.org/ontology/knora-base#DeletedValue\" : \"DeletedValue\" , \"@id\" : \"http://rdfh.ch/0001/a-thing/values/DrXts3Up3DijGriI403nhg\" , \"knora-api:deleteComment\" : \"This value is obsolete\" , \"knora-api:arkUrl\" : { \"@value\" : \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU\" , \"@type\" : \"xsd:anyURI\" } }, {} ] }","title":"Requesting Deleted Values"},{"location":"DSP-API/03-endpoints/api-v2/getting-lists/","text":"Getting Lists Getting a complete List In order to request a complete list, make a HTTP GET request to the lists route appending the Iri of the list's root node (URL-encoded): HTTP GET to http://host/v2/lists/listRootNodeIri Lists are only returned in the complex schema. The response to a list request is a List (see interface List in module ListResponse ). Getting a single Node In order to request a single node of a list, make a HTTP GET request to the node route appending the node's Iri (URL-encoded): HTTP GET to http://host/v2/node/nodeIri Nodes are only returned in the complex schema. The response to a node request is a ListNode (see interface List in module ListResponse ).","title":"Getting Lists"},{"location":"DSP-API/03-endpoints/api-v2/getting-lists/#getting-lists","text":"","title":"Getting Lists"},{"location":"DSP-API/03-endpoints/api-v2/getting-lists/#getting-a-complete-list","text":"In order to request a complete list, make a HTTP GET request to the lists route appending the Iri of the list's root node (URL-encoded): HTTP GET to http://host/v2/lists/listRootNodeIri Lists are only returned in the complex schema. The response to a list request is a List (see interface List in module ListResponse ).","title":"Getting a complete List"},{"location":"DSP-API/03-endpoints/api-v2/getting-lists/#getting-a-single-node","text":"In order to request a single node of a list, make a HTTP GET request to the node route appending the node's Iri (URL-encoded): HTTP GET to http://host/v2/node/nodeIri Nodes are only returned in the complex schema. The response to a node request is a ListNode (see interface List in module ListResponse ).","title":"Getting a single Node"},{"location":"DSP-API/03-endpoints/api-v2/introduction/","text":"Introduction: Using API v2 Version 2 of the DSP-API aims to make both the response and request formats more generic and consistent. Version 1 was basically the result of the reimplementation of the existing API of the SALSAH prototype. Since the development of this prototype has a long history and the specification of API V1 was an evolving process, V1 has various inconsistencies and peculiarities. With V2, we would like to offer a format that is consistent and hence easier to use for a client. API v2 Path Segment Every request to API v2 includes v2 as a path segment, e.g. http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests using any other version of the API will require another path segment. Response Formats All API v2 responses can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation . The client can request these formats using the following MIME types: Format MIME Type JSON-LD application/ld+json Turtle text/turtle RDF/XML application/rdf+xml JSON-LD Our preferred format for data exchange is JSON-LD . JSON-LD allows the DSP-API server to provide responses that are relatively easy for automated processes to interpret, since their structure and semantics is explicitly defined. For example, each user-created Knora resource property is identified by an IRI, which can be dereferenced to get more information about it (e.g. its label in different languages). Moreover, each value has a type represented by an IRI. These are either standard RDF types (e.g. XSD datatypes) or more complex types whose IRIs can be dereferenced to get more information about their structure. At the same time, JSON-LD responses are relatively easy for software developers to work with, and are more concise and easier to read than the equivalent XML. Items in a response can have human-readable names, which can nevertheless be expanded to full IRIs. Also, while a format such as Turtle just provides a set of RDF triples, an equivalent JSON-LD response can explicitly provide data in a hierarchical structure, with objects nested inside other objects. Hierarchical vs. Flat JSON-LD The client can choose between hierarchical and flat JSON-LD. In hierarchical JSON-LD, entities with IRIs are inlined (nested) where they are used. If the same entity is used in more than one place, it is inlined only once, and other uses just refer to its IRI. In Knora's flat JSON-LD, all entities with IRIs are located at the top level of the document (in a @graph if there is more than one of them). This setting does not affect blank nodes, which are always inlined (unlike in standard flat JSON-LD). DSP ontologies are always returned in the flat rendering; other kinds of responses default to hierarchical . To use this setting, submit the HTTP header X-Knora-JSON-LD-Rendering with the value hierarchical or flat . Knora IRIs Resources and entities are identified by IRIs. The format of these IRIs is explained in Knora IRIs . API Schema DSP-API v2 uses RDF data structures that are simpler than the ones actually stored in the triplestore, and more suitable for the development of client software. Thus we refer to the internal schema of data as it is stored in the triplestore, and to external schemas which are used to represent that data in API v2. DSP-API v2 offers a complex schema and a simple one. The main difference is that the complex schema exposes the complexity of value objects, while the simple version does not. A client that needs to edit values must use the complex schema in order to obtain the IRI of each value. A client that reads but does not update data can use the simplified schema. The simple schema is mainly intended to facilitate interoperability with other RDF-based systems in the context of Linked Open Data. It is therefore designed to use the simplest possible datatypes and to require minimal knowledge of Knora. In either case, the client deals only with data whose structure and semantics are defined by external DSP-API ontologies, which are distinct from the internal ontologies that are used to store date in the triplestore. The Knora API server automatically converts back and forth between these internal and external representations. This approach encapsulates the internals and adds a layer of abstraction to them. IRIs representing ontologies and ontology entities are different in different schemas; see Knora IRIs . Some API operations inherently require the client to accept responses in the complex schema. For example, if an ontology is requested using an IRI indicating the simple schema, the ontology will be returned in the simple schema (see Querying, Creating, and Updating Ontologies ). Other API operations can return data in either schema. In this case, the complex schema is used by default in the response, unless the request specifically asks for the simple schema. The client can specify the desired schema by using an HTTP header or a URL parameter: the HTTP header X-Knora-Accept-Schema the URL parameter schema Both the HTTP header and the URL parameter accept the values simple or complex .","title":"Introduction"},{"location":"DSP-API/03-endpoints/api-v2/introduction/#introduction-using-api-v2","text":"Version 2 of the DSP-API aims to make both the response and request formats more generic and consistent. Version 1 was basically the result of the reimplementation of the existing API of the SALSAH prototype. Since the development of this prototype has a long history and the specification of API V1 was an evolving process, V1 has various inconsistencies and peculiarities. With V2, we would like to offer a format that is consistent and hence easier to use for a client.","title":"Introduction: Using API v2"},{"location":"DSP-API/03-endpoints/api-v2/introduction/#api-v2-path-segment","text":"Every request to API v2 includes v2 as a path segment, e.g. http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests using any other version of the API will require another path segment.","title":"API v2 Path Segment"},{"location":"DSP-API/03-endpoints/api-v2/introduction/#response-formats","text":"All API v2 responses can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation . The client can request these formats using the following MIME types: Format MIME Type JSON-LD application/ld+json Turtle text/turtle RDF/XML application/rdf+xml","title":"Response Formats"},{"location":"DSP-API/03-endpoints/api-v2/introduction/#json-ld","text":"Our preferred format for data exchange is JSON-LD . JSON-LD allows the DSP-API server to provide responses that are relatively easy for automated processes to interpret, since their structure and semantics is explicitly defined. For example, each user-created Knora resource property is identified by an IRI, which can be dereferenced to get more information about it (e.g. its label in different languages). Moreover, each value has a type represented by an IRI. These are either standard RDF types (e.g. XSD datatypes) or more complex types whose IRIs can be dereferenced to get more information about their structure. At the same time, JSON-LD responses are relatively easy for software developers to work with, and are more concise and easier to read than the equivalent XML. Items in a response can have human-readable names, which can nevertheless be expanded to full IRIs. Also, while a format such as Turtle just provides a set of RDF triples, an equivalent JSON-LD response can explicitly provide data in a hierarchical structure, with objects nested inside other objects.","title":"JSON-LD"},{"location":"DSP-API/03-endpoints/api-v2/introduction/#hierarchical-vs-flat-json-ld","text":"The client can choose between hierarchical and flat JSON-LD. In hierarchical JSON-LD, entities with IRIs are inlined (nested) where they are used. If the same entity is used in more than one place, it is inlined only once, and other uses just refer to its IRI. In Knora's flat JSON-LD, all entities with IRIs are located at the top level of the document (in a @graph if there is more than one of them). This setting does not affect blank nodes, which are always inlined (unlike in standard flat JSON-LD). DSP ontologies are always returned in the flat rendering; other kinds of responses default to hierarchical . To use this setting, submit the HTTP header X-Knora-JSON-LD-Rendering with the value hierarchical or flat .","title":"Hierarchical vs. Flat JSON-LD"},{"location":"DSP-API/03-endpoints/api-v2/introduction/#knora-iris","text":"Resources and entities are identified by IRIs. The format of these IRIs is explained in Knora IRIs .","title":"Knora IRIs"},{"location":"DSP-API/03-endpoints/api-v2/introduction/#api-schema","text":"DSP-API v2 uses RDF data structures that are simpler than the ones actually stored in the triplestore, and more suitable for the development of client software. Thus we refer to the internal schema of data as it is stored in the triplestore, and to external schemas which are used to represent that data in API v2. DSP-API v2 offers a complex schema and a simple one. The main difference is that the complex schema exposes the complexity of value objects, while the simple version does not. A client that needs to edit values must use the complex schema in order to obtain the IRI of each value. A client that reads but does not update data can use the simplified schema. The simple schema is mainly intended to facilitate interoperability with other RDF-based systems in the context of Linked Open Data. It is therefore designed to use the simplest possible datatypes and to require minimal knowledge of Knora. In either case, the client deals only with data whose structure and semantics are defined by external DSP-API ontologies, which are distinct from the internal ontologies that are used to store date in the triplestore. The Knora API server automatically converts back and forth between these internal and external representations. This approach encapsulates the internals and adds a layer of abstraction to them. IRIs representing ontologies and ontology entities are different in different schemas; see Knora IRIs . Some API operations inherently require the client to accept responses in the complex schema. For example, if an ontology is requested using an IRI indicating the simple schema, the ontology will be returned in the simple schema (see Querying, Creating, and Updating Ontologies ). Other API operations can return data in either schema. In this case, the complex schema is used by default in the response, unless the request specifically asks for the simple schema. The client can specify the desired schema by using an HTTP header or a URL parameter: the HTTP header X-Knora-Accept-Schema the URL parameter schema Both the HTTP header and the URL parameter accept the values simple or complex .","title":"API Schema"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/","text":"Knora IRIs The IRIs used in Knora repositories and in the DSP-API v2 follow certain conventions. Project Short-Codes A project short-code is a hexadecimal number of at least four digits, assigned by the DaSCH to uniquely identify a Knora project regardless of where it is hosted. The IRIs of ontologies that are built into Knora do not contain shortcodes; these ontologies implicitly belong to the Knora system project. A user-created ontology IRI must always include its project shortcode. Project ID 0000 is reserved for shared ontologies (see Shared Ontologies ). The range of project IDs from 0001 to 00FF inclusive is reserved for local testing. Thus, the first useful project will be 0100 . In the beginning, Unil will use the IDs 0100 to 07FF , and Unibas 0800 to 08FF . IRIs for Ontologies and Ontology Entities Internal Ontology IRIs Knora makes a distinction between internal and external ontologies. Internal ontologies are used in the triplestore, while external ontologies are used in API v2. For each internal ontology, there is a corresponding external ontology. Some internal ontologies are built into Knora, while others are user-created. Knora automatically generates external ontologies based on user-created internal ontologies. Each internal ontology has an IRI, which is also the IRI of the named graph that contains the ontology in the triplestore. An internal ontology IRI has the form: http://www.knora.org/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME For example, the internal ontology IRI based on project code 0001 and ontology name example would be: http://www.knora.org/ontology/0001/example An ontology name must be a valid XML NCName and must be URL safe. The following names are reserved for built-in internal DSP ontologies: knora-base standoff salsah-gui Names starting with knora are reserved for future built-in Knora ontologies. A user-created ontology name may not start with the letter v followed by a digit, and may not contain these reserved words: knora ontology simple shared External Ontology IRIs Unlike internal ontology IRIs, external ontology IRIs are meant to be dereferenced as URLs. When an ontology IRI is dereferenced, the ontology itself can be served either in a machine-readable format or as human-readable documentation. The IRI of an external Knora ontology has the form: http://HOST[:PORT]/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME/API_VERSION For built-in and shared ontologies, the host is always api.knora.org . Otherwise, the hostname and port configured in application.conf under app.http.knora-api.host and app.http.knora-api.http-port are used (the port is omitted if it is 80). This means that when a built-in or shared external ontology IRI is dereferenced, the ontology can be served by a DSP-API server running at api.knora.org . When the external IRI of a non-shared, project-specific ontology is dereferenced, the ontology can be served by Knora that hosts the project. During development and testing, this could be localhost . The name of an external ontology is the same as the name of the corresponding internal ontology, with one exception: the external form of knora-base is called knora-api . The API version identifier indicates not only the version of the API, but also an API 'schema'. The DSP-API v2 is available in two schemas: A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. Its version identifier is v2 . A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Its version identifier is simple/v2 . Other schemas could be added in the future for more specific use cases. When requesting an ontology, the client requests a particular schema. (This will also be true of most DSP-API v2 requests: the client will be able to specify which schema the response should be provided in.) For example, suppose a DSP-API server is running at knora.example.org and hosts an ontology whose internal IRI is http://www.knora.org/ontology/0001/example . That ontology can then be requested using either of these IRIs: http://knora.example.org/ontology/0001/example/v2 (in the complex schema) http://knora.example.org/ontology/0001/example/simple/v2 (in the simple schema) While the internal example ontology refers to definitions in knora-base , the external example ontology that is served by the API refers instead to a knora-api ontology, whose IRI depends on the schema being used: http://api.knora.org/ontology/knora-api/v2 (in the complex schema) http://api.knora.org/ontology/knora-api/simple/v2 (in the simple schema) Ontology Entity IRIs DSP ontologies use 'hash namespaces' (see URI Namespaces ). This means that the IRI of an ontology entity (a class or property definition) is constructed by adding a hash character ( # ) to the ontology IRI, followed by the name of the entity. In Knora, an entity name must be a valid XML NCName . Thus, if there is a class called ExampleThing in an ontology whose internal IRI is http://www.knora.org/ontology/0001/example , that class has the following IRIs: http://www.knora.org/ontology/0001/example#ExampleThing (in the internal ontology) http://HOST[:PORT]/ontology/0001/example/v2#ExampleThing (in the API v2 complex schema) http://HOST[:PORT]/ontology/0001/example/simple/v2#ExampleThing (in the API v2 simple schema) Shared Ontology IRIs As explained in Shared Ontologies , a user-created ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. There is currently one project for shared ontologies: http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject Its project code is 0000 . Additional projects for shared ontologies may be supported in future. The internal and external IRIs of shared ontologies always use the hostname api.knora.org , and have an additional segment, shared , after ontology . The project code can be omitted, in which case the default shared ontology project, 0000 , is assumed. The sample shared ontology, example-box , has these IRIs: http://www.knora.org/ontology/shared/example-box (internal) http://api.knora.org/ontology/shared/example-box/v2 (external, complex schema) http://api.knora.org/ontology/shared/example-box/simple/v2 (external, simple schema) IRIs for Data Knora generates IRIs for data that it creates in the triplestore. Each generated data IRI contains one or more UUID identifiers to make it unique. To keep data IRIs relatively short, each UUID is base64url-encoded , without padding; thus each UUID is a 22-character string. DSP-API supports UUID version 4 or 5. Data IRIs are not currently intended to be dereferenced as URLs. Instead, each Knora resource has a separate permalink . A Knora value does not have a stable IRI throughout its version history. Each time a new version of a value is made, the new version gets a new IRI. Therefore, it would not make sense to publish Knora value IRIs. When designing ontologies for Knora projects, keep in mind that if you want something be directly citable, it needs to be a resource, not a value. The formats of generated data IRIs for different types of objects are as follows: Resource: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID . Value: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID Standoff tag: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID/STANDOFF_UUID XML-to-standoff mapping: http://rdfh.ch/projects/PROJECT_SHORTCODE/mappings/MAPPING_NAME XML-to-standoff mapping element: http://rdfh.ch/projects/PROJECT_SHORTCODE/mappings/MAPPING_NAME/elements/MAPPING_ELEMENT_UUID Project: http://rdfh.ch/projects/PROJECT_SHORTCODE (or http://rdfh.ch/projects/PROJECT_UUID ) Group: http://rdfh.ch/groups/PROJECT_SHORTCODE/GROUP_UUID Permission: http://rdfh.ch/permissions/PROJECT_SHORTCODE/PERMISSION_UUID Lists: http://rdfh.ch/lists/PROJECT_SHORTCODE/LIST_UUID User: http://rdfh.ch/users/USER_UUID","title":"Knora IRIs"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/#knora-iris","text":"The IRIs used in Knora repositories and in the DSP-API v2 follow certain conventions.","title":"Knora IRIs"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/#project-short-codes","text":"A project short-code is a hexadecimal number of at least four digits, assigned by the DaSCH to uniquely identify a Knora project regardless of where it is hosted. The IRIs of ontologies that are built into Knora do not contain shortcodes; these ontologies implicitly belong to the Knora system project. A user-created ontology IRI must always include its project shortcode. Project ID 0000 is reserved for shared ontologies (see Shared Ontologies ). The range of project IDs from 0001 to 00FF inclusive is reserved for local testing. Thus, the first useful project will be 0100 . In the beginning, Unil will use the IDs 0100 to 07FF , and Unibas 0800 to 08FF .","title":"Project Short-Codes"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/#iris-for-ontologies-and-ontology-entities","text":"","title":"IRIs for Ontologies and Ontology Entities"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/#internal-ontology-iris","text":"Knora makes a distinction between internal and external ontologies. Internal ontologies are used in the triplestore, while external ontologies are used in API v2. For each internal ontology, there is a corresponding external ontology. Some internal ontologies are built into Knora, while others are user-created. Knora automatically generates external ontologies based on user-created internal ontologies. Each internal ontology has an IRI, which is also the IRI of the named graph that contains the ontology in the triplestore. An internal ontology IRI has the form: http://www.knora.org/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME For example, the internal ontology IRI based on project code 0001 and ontology name example would be: http://www.knora.org/ontology/0001/example An ontology name must be a valid XML NCName and must be URL safe. The following names are reserved for built-in internal DSP ontologies: knora-base standoff salsah-gui Names starting with knora are reserved for future built-in Knora ontologies. A user-created ontology name may not start with the letter v followed by a digit, and may not contain these reserved words: knora ontology simple shared","title":"Internal Ontology IRIs"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/#external-ontology-iris","text":"Unlike internal ontology IRIs, external ontology IRIs are meant to be dereferenced as URLs. When an ontology IRI is dereferenced, the ontology itself can be served either in a machine-readable format or as human-readable documentation. The IRI of an external Knora ontology has the form: http://HOST[:PORT]/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME/API_VERSION For built-in and shared ontologies, the host is always api.knora.org . Otherwise, the hostname and port configured in application.conf under app.http.knora-api.host and app.http.knora-api.http-port are used (the port is omitted if it is 80). This means that when a built-in or shared external ontology IRI is dereferenced, the ontology can be served by a DSP-API server running at api.knora.org . When the external IRI of a non-shared, project-specific ontology is dereferenced, the ontology can be served by Knora that hosts the project. During development and testing, this could be localhost . The name of an external ontology is the same as the name of the corresponding internal ontology, with one exception: the external form of knora-base is called knora-api . The API version identifier indicates not only the version of the API, but also an API 'schema'. The DSP-API v2 is available in two schemas: A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. Its version identifier is v2 . A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Its version identifier is simple/v2 . Other schemas could be added in the future for more specific use cases. When requesting an ontology, the client requests a particular schema. (This will also be true of most DSP-API v2 requests: the client will be able to specify which schema the response should be provided in.) For example, suppose a DSP-API server is running at knora.example.org and hosts an ontology whose internal IRI is http://www.knora.org/ontology/0001/example . That ontology can then be requested using either of these IRIs: http://knora.example.org/ontology/0001/example/v2 (in the complex schema) http://knora.example.org/ontology/0001/example/simple/v2 (in the simple schema) While the internal example ontology refers to definitions in knora-base , the external example ontology that is served by the API refers instead to a knora-api ontology, whose IRI depends on the schema being used: http://api.knora.org/ontology/knora-api/v2 (in the complex schema) http://api.knora.org/ontology/knora-api/simple/v2 (in the simple schema)","title":"External Ontology IRIs"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/#ontology-entity-iris","text":"DSP ontologies use 'hash namespaces' (see URI Namespaces ). This means that the IRI of an ontology entity (a class or property definition) is constructed by adding a hash character ( # ) to the ontology IRI, followed by the name of the entity. In Knora, an entity name must be a valid XML NCName . Thus, if there is a class called ExampleThing in an ontology whose internal IRI is http://www.knora.org/ontology/0001/example , that class has the following IRIs: http://www.knora.org/ontology/0001/example#ExampleThing (in the internal ontology) http://HOST[:PORT]/ontology/0001/example/v2#ExampleThing (in the API v2 complex schema) http://HOST[:PORT]/ontology/0001/example/simple/v2#ExampleThing (in the API v2 simple schema)","title":"Ontology Entity IRIs"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/#shared-ontology-iris","text":"As explained in Shared Ontologies , a user-created ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. There is currently one project for shared ontologies: http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject Its project code is 0000 . Additional projects for shared ontologies may be supported in future. The internal and external IRIs of shared ontologies always use the hostname api.knora.org , and have an additional segment, shared , after ontology . The project code can be omitted, in which case the default shared ontology project, 0000 , is assumed. The sample shared ontology, example-box , has these IRIs: http://www.knora.org/ontology/shared/example-box (internal) http://api.knora.org/ontology/shared/example-box/v2 (external, complex schema) http://api.knora.org/ontology/shared/example-box/simple/v2 (external, simple schema)","title":"Shared Ontology IRIs"},{"location":"DSP-API/03-endpoints/api-v2/knora-iris/#iris-for-data","text":"Knora generates IRIs for data that it creates in the triplestore. Each generated data IRI contains one or more UUID identifiers to make it unique. To keep data IRIs relatively short, each UUID is base64url-encoded , without padding; thus each UUID is a 22-character string. DSP-API supports UUID version 4 or 5. Data IRIs are not currently intended to be dereferenced as URLs. Instead, each Knora resource has a separate permalink . A Knora value does not have a stable IRI throughout its version history. Each time a new version of a value is made, the new version gets a new IRI. Therefore, it would not make sense to publish Knora value IRIs. When designing ontologies for Knora projects, keep in mind that if you want something be directly citable, it needs to be a resource, not a value. The formats of generated data IRIs for different types of objects are as follows: Resource: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID . Value: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID Standoff tag: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID/STANDOFF_UUID XML-to-standoff mapping: http://rdfh.ch/projects/PROJECT_SHORTCODE/mappings/MAPPING_NAME XML-to-standoff mapping element: http://rdfh.ch/projects/PROJECT_SHORTCODE/mappings/MAPPING_NAME/elements/MAPPING_ELEMENT_UUID Project: http://rdfh.ch/projects/PROJECT_SHORTCODE (or http://rdfh.ch/projects/PROJECT_UUID ) Group: http://rdfh.ch/groups/PROJECT_SHORTCODE/GROUP_UUID Permission: http://rdfh.ch/permissions/PROJECT_SHORTCODE/PERMISSION_UUID Lists: http://rdfh.ch/lists/PROJECT_SHORTCODE/LIST_UUID User: http://rdfh.ch/users/USER_UUID","title":"IRIs for Data"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/","text":"Querying, Creating, and Updating Ontologies Querying Ontology Information Before reading this document, you should have a basic understanding of DSP-API v2 external ontology schemas (see API Schema ). Each request returns a single RDF graph, which can be represented in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). The response format uses prefixes to shorten IRIs, making them more human-readable. A client may wish to convert these to full IRIs for processing. This can be done with responses in JSON-LD by using a library that implements the JSON-LD API to compact the document with an empty JSON-LD @context . Querying Ontology Metadata Requests for ontology metadata can return information about more than one ontology, unlike other requests for ontology information. To get metadata about all ontologies: HTTP GET to http://host/v2/ontologies/metadata If you submit a project IRI in the X-Knora-Accept-Project header, only the ontologies for that project will be returned. The response is in the complex API v2 schema. Sample response: { \"@graph\" : [ { \"knora-api:lastModificationDate\" : { \"@value\" : \"2017-12-19T15:23:42.166Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The anything ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The something ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0001/something/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The images demo ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/00FF\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The BEOL ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yTerZGyxjZVqFMNNKXCDPF\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0801/beol/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The Biblio ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yTerZGyxjZVqFMNNKXCDPF\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0801/biblio/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The Newton-Project ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yTerZGyxjZVqFMNNKXCDPF\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0801/newton/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The incunabula ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0803\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0803/incunabula/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The dokubib ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0804\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0804/dokubib/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The Anton Webern project ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/08AE\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/08AE/webern/v2\" }, { \"rdfs:label\" : \"The Knora admin ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\" : true , \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://api.knora.org/ontology/knora-admin/v2\" }, { \"rdfs:label\" : \"The knora-api ontology in the complex schema\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\" : true , \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://api.knora.org/ontology/knora-api/v2\" }, { \"rdfs:label\" : \"The salsah-gui ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\" : true , \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://api.knora.org/ontology/salsah-gui/v2\" }, { \"rdfs:label\" : \"The standoff ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\" : true , \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://api.knora.org/ontology/standoff/v2\" } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" } } To get metadata about the ontologies that belong to one or more particular projects: HTTP GET to http://host/v2/ontologies/metadata/PROJECT_IRI[/PROJECT_IRI...] The project IRIs must be URL-encoded. Example response for the anything test project (project IRI http://rdfh.ch/projects/0001 ): { \"@id\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2\" , \"@type\" : \"owl:Ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:lastModificationDate\" : \"2017-12-19T15:23:42.166Z\" , \"rdfs:label\" : \"The anything ontology\" , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" } } Querying an Ontology An ontology can be queried either by using an API route directly or by simply dereferencing the ontology IRI. The API route is as follows: HTTP GET to http://host/v2/ontologies/allentities/ONTOLOGY_IRI The ontology IRI must be URL-encoded, and may be in either the complex or the simple schema. The response will be in the same schema. For example, if the server is running on 0.0.0.0:3333 , you can request the knora-api ontology in the complex schema as follows: HTTP GET to http://0.0.0.0:3333/v2/ontologies/allentities/http%3A%2F%2Fapi.knora.org%2Fontology%2Fknora-api%2Fv2 By default, this returns the ontology in JSON-LD; to request Turtle or RDF/XML, add an HTTP Accept header (see Response Formats ). If the client dereferences a project-specific ontology IRI as a URL, the DSP-API server running on the hostname in the IRI will serve the ontology. For example, if the server is running on 0.0.0.0:3333 , the IRI http://0.0.0.0:3333/ontology/00FF/images/simple/v2 can be dereferenced to request the images sample ontology in the simple schema. If the client dereferences a built-in Knora ontology, such as http://api.knora.org/ontology/knora-api/simple/v2 , there must be a DSP-API server running at api.knora.org that can serve the ontology. The DaSCH intends to run such as server. For testing, you can configure your local /etc/hosts file to resolve api.knora.org as localhost . Differences Between Internal and External Ontologies The external ontologies used by DSP-API v2 are different to the internal ontologies that are actually stored in the triplestore (see API Schema ). In general, the external ontologies use simpler data structures, but they also provide additional information to make it easier for clients to use them. This is illustrated in the examples in the next sections. The internal predicates knora-base:subjectClassConstraint and knora-base:objectClassConstraint (see Constraints on the Types of Property Subjects and Objects ) are represented as knora-api:subjectType and knora-api:objectType in external ontologies. JSON-LD Representation of an Ontology in the Simple Schema The simple schema is suitable for client applications that need to read but not update data in Knora. For example, here is the response for the images sample ontology in the simple schema, http://0.0.0.0:3333/ontology/00FF/images/simple/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2\" , \"@type\" : \"owl:Ontology\" , \"rdfs:label\" : \"The images demo ontology\" , \"@graph\" : [ { \"@id\" : \"images:bild\" , \"@type\" : \"owl:Class\" , \"knora-api:resourceIcon\" : \"bild.png\" , \"rdfs:comment\" : \"An image of the demo image collection\" , \"rdfs:label\" : \"Image\" , \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFile\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } } ] }, { \"@id\" : \"images:description\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Description\" , \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"knora-api:Date\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Date of acquisition\" , \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"First name of a person\" , \"rdfs:label\" : \"First name\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"Last name of a person\" , \"rdfs:label\" : \"Name\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\" , \"@type\" : \"owl:Class\" , \"knora-api:resourceIcon\" : \"person.png\" , \"rdfs:comment\" : \"Person\" , \"rdfs:label\" : \"Person\" , \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\" , \"rdfs:label\" : \"Creator\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } The response format is an RDF graph. The top level object describes the ontology itself, providing its IRI (in the @id member) and its rdfs:label . The @graph member (see Named Graphs in the JSON-LD specification) contains an array of entities that belong to the ontology. In a class definition, cardinalities for properties of the class are represented as in OWL, using objects of type owl:Restriction . The supported cardinalities are the ones indicated in OWL Cardinalities . The class definitions include cardinalities that are directly defined on each class, as well as cardinalities inherited from base classes. For example, we can see cardinalities inherited from knora-api:Resource , such as knora-api:hasStandoffLinkTo and http://schema.org/name (which represents rdfs:label ). In the simple schema, Knora value properties can be datatype properties. The knora-base:objectType of a Knora value property such as images:description is a literal datatype, in this case xsd:string . Moreover, images:description is a subproperty of the standard property dcterms:description , whose object can be a literal value. A client that understands rdfs:subPropertyOf , and is familiar with dcterms:description , can then work with images:description on the basis of its knowledge about dcterms:description . By default, values for rdfs:label and rdfs:comment are returned only in the user's preferred language, or in the system default language. To obtain these values in all available languages, add the URL parameter ?allLanguages=true . For example, with this parameter, the definition of images:description becomes: { \"@id\" : \"images:description\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : [ { \"@language\" : \"en\" , \"@value\" : \"Description\" }, { \"@language\" : \"de\" , \"@value\" : \"Beschreibung\" }, { \"@language\" : \"fr\" , \"@value\" : \"Description\" }, { \"@language\" : \"it\" , \"@value\" : \"Descrizione\" } ], \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] } To find out more about the knora-api entities used in the response, the client can request the knora-api ontology in the simple schema: http://api.knora.org/ontology/knora-api/simple/v2 . For example, images:erfassungsdatum has a knora-api:objectType of knora-api:Date , which is a subtype of xsd:string with a Knora-specific, human-readable format. In the knora-api simple ontology, there is a definition of this type: { \"@id\" : \"http://api.knora.org/ontology/knora-api/simple/v2\" , \"@type\" : \"owl:Ontology\" , \"rdfs:label\" : \"The knora-api ontology in the simple schema\" , \"@graph\" : [ { \"@id\" : \"knora-api:Date\" , \"@type\" : \"rdfs:Datatype\" , \"rdfs:comment\" : \"Represents a date as a period with different possible precisions.\" , \"rdfs:label\" : \"Date literal\" , \"rdfs:subClassOf\" : { \"@type\" : \"rdfs:Datatype\" , \"owl:onDatatype\" : { \"@id\" : \"xsd:string\" }, \"owl:withRestrictions\" : { \"xsd:pattern\" : \"(GREGORIAN|JULIAN|ISLAMIC):\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?)?\" } } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } JSON-LD Representation of an Ontology in the Complex Schema The complex schema is suitable for client applications that need to update data in Knora. For example, here is the response for the images sample ontology in the complex schema, http://0.0.0.0:3333/ontology/00FF/images/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\" , \"@type\" : \"owl:Ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/00FF\" }, \"rdfs:label\" : \"The images demo ontology\" , \"@graph\" : [ { \"@id\" : \"images:bild\" , \"@type\" : \"owl:Class\" , \"knora-api:canBeInstantiated\" : true , \"knora-api:isResourceClass\" : true , \"knora-api:resourceIcon\" : \"bild.png\" , \"rdfs:comment\" : \"An image of the demo image collection\" , \"rdfs:label\" : \"Image\" , \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFileValue\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 3 , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 8 , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 12 , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 12 , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:urheberValue\" } } ] }, { \"@id\" : \"images:description\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : [ \"rows=10\" , \"width=95%\" , \"wrap=soft\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Textarea\" }, \"rdfs:label\" : \"Description\" , \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:DateValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Date\" }, \"rdfs:label\" : \"Date of acquisition\" , \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\" , \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"First name of a person\" , \"rdfs:label\" : \"First name\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\" , \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"Last name of a person\" , \"rdfs:label\" : \"Name\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\" , \"@type\" : \"owl:Class\" , \"knora-api:canBeInstantiated\" : true , \"knora-api:isResourceClass\" : true , \"knora-api:resourceIcon\" : \"person.png\" , \"rdfs:comment\" : \"Person\" , \"rdfs:label\" : \"Person\" , \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 0 , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 1 , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isLinkProperty\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\" , \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\" , \"rdfs:label\" : \"Creator\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } }, { \"@id\" : \"images:urheberValue\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isLinkValueProperty\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:LinkValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\" , \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\" , \"rdfs:label\" : \"Creator\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkToValue\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the complex schema, all Knora value properties are object properties, whose objects are IRIs, each of which uniquely identifies a value that contains metadata and can potentially be edited. The knora-base:objectType of a Knora value property such as images:description is a Knora value class, in this case knora-api:TextValue . Similarly, images:erfassungsdatum has a knora-api:objectType of knora-api:DateValue , which has a more complex structure than the knora-api:Date datatype shown in the previous section. A client can find out more about these value classes by requesting the knora-api ontology in the complex schema, http://api.knora.org/ontology/knora-api/v2 . Moreover, additional information is provided in the complex schema, to help clients that wish to create or update resources and values. A Knora resource class that can be instantiated is identified with the boolean properties knora-api:isResourceClass and knora-api:canBeInstantiated , to distinguish it from built-in abstract classes. Knora resource properties whose values can be edited by clients are identified with knora-api:isResourceProperty and knora-api:isEditable , to distinguish them from properties whose values are maintained automatically by Knora. Link value properties are shown along with link properties, because a client that updates links will need the IRIs of their link values. The predicate salsah-gui:guiOrder tells a GUI client in what order to display the properties of a class, and the predicates salsah-gui:guiElement and salsah-gui:guiAttribute specify how to configure a GUI element for editing the value of a property. For more information on the salsah-gui ontology, see The SALSAH GUI Ontology . Ontology Updates The ontology update API must ensure that the ontologies it creates are valid and consistent, and that existing data is not invalidated by a change to an ontology. To make this easier to enforce, the ontology update API allows only one entity to be created or modified at a time. It is not possible to submit an entire ontology all at once. Each update request is a JSON-LD document providing only the information that is relevant to the update. Moreover, the API enforces the following rules: An entity (i.e. a class or property) cannot be referred to until it has been created. An entity cannot be modified or deleted if it is used in data, except for changes to its rdfs:label or rdfs:comment . An entity cannot be modified if another entity refers to it, with one exception: a knora-api:subjectType or knora-api:objectType that refers to a class will not prevent the class's cardinalities from being modified. Because of these rules, some operations have to be done in a specific order: Properties have to be defined before they can be used in the cardinalities of a class, but a property's knora-api:subjectType cannot refer to a class that does not yet exist. The recommended approach is to first create a class with no cardinalities, then create the properties that it needs, then add cardinalities for those properties to the class. To delete a class along with its properties, the client must first remove the cardinalities from the class, then delete the property definitions, then delete the class definition. When changing an existing ontology, the client must always supply the ontology's knora-api:lastModificationDate , which is returned in the response to each update or when querying the ontology . If user A attempts to update an ontology, but user B has already updated it since the last time user A received the ontology's knora-api:lastModificationDate , user A's update will be rejected with an HTTP 409 Conflict error. This means that it is possible for two different users to work concurrently on the same ontology, but this is discouraged since it is likely to lead to confusion. An ontology can be created or updated only by a system administrator, or by a project administrator in the ontology's project. Ontology updates always use the complex schema. Creating a New Ontology An ontology is always created within a particular project. HTTP POST to http://host/v2/ontologies { \"knora-api:ontologyName\" : \"ONTOLOGY_NAME\" , \"knora-api:attachedToProject\" : { \"@id\" : \"PROJECT_IRI\" }, \"rdfs:label\" : \"ONTOLOGY_NAME\" , \"@context\" : { \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The ontology name must follow the rules given in Knora IRIs . The ontology metadata can have an optional comment given in the request body as: \"rdfs:comment\": \"some comment\", If the ontology is to be shared by multiple projects, it must be created in the default shared ontologies project, http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject , and the request must have this additional boolean property: \"knora-api:isShared\" : true See Shared Ontologies for details about shared ontologies. A successful response will be a JSON-LD document providing only the ontology's metadata, which includes the ontology's IRI. When the client makes further requests to create entities (classes and properties) in the ontology, it must construct entity IRIs by concatenating the ontology IRI, a # character, and the entity name. An entity name must be a valid XML NCName . Changing an Ontology's Metadata One can modify an ontology's metadata by updating its rdfs:label or rdfs:comment or both. The example below shows the request for changing the label of an ontology. HTTP PUT to http://host/v2/ontologies/metadata { \"@id\" : \"ONTOLOGY_IRI\" , \"rdfs:label\" : \"NEW_ONTOLOGY_LABEL\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Similarly, a user can change an ontology's existing comment or add one by specifying the new comment in the request body: { \"@id\" : \"ONTOLOGY_IRI\" , \"rdfs:comment\" : \"NEW_ONTOLOGY_COMMENT\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The request body can also contain a new label and a new comment for the ontology's metadata. A successful response will be a JSON-LD document providing only the ontology's metadata. Deleting an Ontology's comment HTTP DELETE to http://host/v2/ontologies/comment/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing the ontology's updated metadata. Deleting an Ontology An ontology can be deleted only if it is not used in data. HTTP DELETE to http://host/v2/ontologies/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing a confirmation message. To check whether an ontology can be deleted: HTTP GET to http://host/v2/ontologies/candeleteontology/ONTOLOGY_IRI The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Creating a Class Without Cardinalities HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : { \"@id\" : \"BASE_CLASS_IRI\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided, which can be knora-api:Resource or any of its subclasses. A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Creating a Class With Cardinalities This can work if the new class will have cardinalities for properties that have no knora-api:subjectType , or if the new class will be a subclass of their knora-api:subjectType . HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : [ { \"@id\" : \"BASE_CLASS_IRI\" }, { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" } } ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided. When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Changing the Labels of a Class This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. The submitted labels will replace the existing ones. Changing the Comments of a Class This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. The submitted comments will replace the existing ones. Deleting the Comments of a Class This operation is permitted even if the class is used in data. HTTP DELETE to http://host/v2/ontologies/classes/comment/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. All values i.e. all languages for rdfs:comment are deleted. A successful response will be a JSON-LD document providing the class definition. Creating a Property HTTP POST to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:subjectType\" : { \"@id\" : \"SUBJECT_TYPE\" }, \"knora-api:objectType\" : { \"@id\" : \"OBJECT_TYPE\" }, \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" }, \"rdfs:subPropertyOf\" : { \"@id\" : \"BASE_PROPERTY_IRI\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"GUI_ELEMENT_IRI\" }, \"salsah-gui:guiAttribute\" : [ \"GUI_ATTRIBUTE\" ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base property must be provided, which can be knora-api:hasValue , knora-api:hasLinkTo , or any of their subproperties, with the exception of file properties (subproperties of knora-api:hasFileValue ) and link value properties (subproperties of knora-api:hasLinkToValue ). If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be created. The property definition must specify its knora-api:objectType . If the new property is a subproperty of knora-api:hasValue , its knora-api:objectType must be one of the built-in subclasses of knora-api:Value , which are defined in the knora-api ontology in the complex schema. If the new property is a subproperty of knora-base:hasLinkTo , its knora-api:objectType must be a subclass of knora-api:Resource . To improve consistency checking, it is recommended, but not required, to provide knora-api:subjectType , which must be a subclass of knora-api:Resource . The predicates salsah-gui:guiElement and salsah-gui:guiAttribute are optional. If provided, the object of guiElement must be one of the OWL named individuals defined in The SALSAH GUI Ontology . Some GUI elements take required or optional attributes, which are provided as objects of salsah-gui:guiAttribute ; see The SALSAH GUI Ontology for details. A successful response will be a JSON-LD document providing the new property definition (but not any of the other entities in the ontology). Changing the Labels of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\" , \"@type\" : \"owl:ObjectProperty\" , \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. Changing the Comments of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\" , \"@type\" : \"owl:ObjectProperty\" , \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. Deleting the Comments of a Property This operation is permitted even if the property is used in data. HTTP DELETE to http://host/v2/ontologies/properties/comment/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. All values i.e. all languages for rdfs:comment are deleted. If the property is a link property, the rdfs:comment of its corresponding link value property will automatically be deleted. A successful response will be a JSON-LD document providing the property definition. Changing the GUI Element and GUI Attributes of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties/guielement { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\" , \"@type\" : \"owl:ObjectProperty\" , \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Textarea\" }, \"salsah-gui:guiAttribute\" : [ \"cols=80\" , \"rows=24\" ] } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } To remove the values of salsah-gui:guiElement and salsah-gui:guiAttribute from the property definition, submit the request without those predicates. Adding Cardinalities to a Class If the class (or any of its sub-classes) is used in data, it is not allowed to add cardinalities owl:minCardinality greater than 0 or owl:cardinality 1 to the class. HTTP POST to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:subClassOf\" : { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } At least one cardinality must be submitted. OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Replacing the Cardinalities of a Class It is possible to replace all cardinalities on properties used by a class. If it succeeds the request will effectively replace all direct cardinalities of the class as specified. That is, it removes all the cardinalities from the class and replaces them with the submitted cardinalities. Meaning that, if no cardinalities are submitted (i.e. the request contains no rdfs:subClassOf ), the class is left with no cardinalities. The request will fail if any of the \"Pre-Update Checks\" fails. A partial update of the ontology will not be performed. Pre-Update Checks Ontology Check Any given cardinality on a property must be included in any of the existing cardinalities for the same property of the super-classes. Any given cardinality on a property must include the effective cardinalities for the same property of all subclasses, taking into account the respective inherited cardinalities from the class hierarchy of the subclasses. Consistency Check with existing data Given that instances of the class or any of its subclasses exist then these instances are checked if they conform to the given cardinality. HTTP PUT to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:subClassOf\" : { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). If any of the \"Pre-Update Checks\" fail the endpoint will respond with a 400 Bad Request containing the reasons why the update failed. The \"Pre-Update Checks\" are available on a dedicated endpoint. For a check whether a particular cardinality can be set on a class/property combination, use the following request: HTTP GET to http://host/v2/ontologies/canreplacecardinalities/CLASS_IRI?propertyIri=PROPERTY_IRI&newCardinality=[0-1|1|1-n|0-n] The response will look like this: Failure: { \"knora-api:canDo\" : false , \"knora-api:cannotDoReason\" : \"An explanation, understandable to humans, why the update cannot be carried out.\" , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Success: { \"knora-api:canDo\" : true , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Note : The following check is still available but deprecated - use the more detailed check above. To check whether all class's cardinalities can be replaced: HTTP GET to http://host/v2/ontologies/canreplacecardinalities/CLASS_IRI The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The ontologies/canreplacecardinalities/CLASS_IRI request is only checking if the class is in use. Delete a single cardinality from a class If a class is used in data, it is only allowed to delete a cardinality, if the property a cardinality refers to, is not used inside the data. Also, the property isn't allowed to be used inside the data in any subclasses of this class. HTTP PATCH to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:subClassOf\" : { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinality can be deleted: HTTP POST to http://host/v2/ontologies/candeletecardinalities The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Changing the GUI Order of Cardinalities To change the GUI order of one or more cardinalities in a class: HTTP PUT to http://host/v2/ontologies/guiorder This can be done even if the class is used in data. The request body includes the cardinalities whose GUI order should be changed, using the predicate salsah-gui:guiOrder , whose object is an integer: { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:subClassOf\" : { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" }, \"salsah-gui:guiOrder\" : \"GUI_ORDER_VALUE\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Only the cardinalities whose GUI order is to be changed need to be included in the request. The OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE are ignored; only the GUI_ORDER_VALUE is changed. Deleting a Property A property can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/properties/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be deleted. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a property can be deleted: HTTP GET to http://host/v2/ontologies/candeleteproperty/PROPERTY_IRI The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Deleting a Class A class can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/classes/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a class can be deleted: HTTP GET to http://host/v2/ontologies/candeleteclass/CLASS_IRI The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Querying, Creating, and Updating Ontologies"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#querying-creating-and-updating-ontologies","text":"","title":"Querying, Creating, and Updating Ontologies"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#querying-ontology-information","text":"Before reading this document, you should have a basic understanding of DSP-API v2 external ontology schemas (see API Schema ). Each request returns a single RDF graph, which can be represented in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). The response format uses prefixes to shorten IRIs, making them more human-readable. A client may wish to convert these to full IRIs for processing. This can be done with responses in JSON-LD by using a library that implements the JSON-LD API to compact the document with an empty JSON-LD @context .","title":"Querying Ontology Information"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#querying-ontology-metadata","text":"Requests for ontology metadata can return information about more than one ontology, unlike other requests for ontology information. To get metadata about all ontologies: HTTP GET to http://host/v2/ontologies/metadata If you submit a project IRI in the X-Knora-Accept-Project header, only the ontologies for that project will be returned. The response is in the complex API v2 schema. Sample response: { \"@graph\" : [ { \"knora-api:lastModificationDate\" : { \"@value\" : \"2017-12-19T15:23:42.166Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The anything ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The something ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0001/something/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The images demo ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/00FF\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The BEOL ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yTerZGyxjZVqFMNNKXCDPF\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0801/beol/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The Biblio ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yTerZGyxjZVqFMNNKXCDPF\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0801/biblio/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The Newton-Project ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yTerZGyxjZVqFMNNKXCDPF\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0801/newton/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The incunabula ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0803\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0803/incunabula/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The dokubib ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0804\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/0804/dokubib/v2\" }, { \"knora-api:lastModificationDate\" : { \"@value\" : \"2022-03-23T07:14:17.445208Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"rdfs:label\" : \"The Anton Webern project ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/08AE\" }, \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://0.0.0.0:3333/ontology/08AE/webern/v2\" }, { \"rdfs:label\" : \"The Knora admin ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\" : true , \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://api.knora.org/ontology/knora-admin/v2\" }, { \"rdfs:label\" : \"The knora-api ontology in the complex schema\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\" : true , \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://api.knora.org/ontology/knora-api/v2\" }, { \"rdfs:label\" : \"The salsah-gui ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\" : true , \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://api.knora.org/ontology/salsah-gui/v2\" }, { \"rdfs:label\" : \"The standoff ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\" : true , \"@type\" : \"owl:Ontology\" , \"@id\" : \"http://api.knora.org/ontology/standoff/v2\" } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" } } To get metadata about the ontologies that belong to one or more particular projects: HTTP GET to http://host/v2/ontologies/metadata/PROJECT_IRI[/PROJECT_IRI...] The project IRIs must be URL-encoded. Example response for the anything test project (project IRI http://rdfh.ch/projects/0001 ): { \"@id\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2\" , \"@type\" : \"owl:Ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" }, \"knora-api:lastModificationDate\" : \"2017-12-19T15:23:42.166Z\" , \"rdfs:label\" : \"The anything ontology\" , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" } }","title":"Querying Ontology Metadata"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#querying-an-ontology","text":"An ontology can be queried either by using an API route directly or by simply dereferencing the ontology IRI. The API route is as follows: HTTP GET to http://host/v2/ontologies/allentities/ONTOLOGY_IRI The ontology IRI must be URL-encoded, and may be in either the complex or the simple schema. The response will be in the same schema. For example, if the server is running on 0.0.0.0:3333 , you can request the knora-api ontology in the complex schema as follows: HTTP GET to http://0.0.0.0:3333/v2/ontologies/allentities/http%3A%2F%2Fapi.knora.org%2Fontology%2Fknora-api%2Fv2 By default, this returns the ontology in JSON-LD; to request Turtle or RDF/XML, add an HTTP Accept header (see Response Formats ). If the client dereferences a project-specific ontology IRI as a URL, the DSP-API server running on the hostname in the IRI will serve the ontology. For example, if the server is running on 0.0.0.0:3333 , the IRI http://0.0.0.0:3333/ontology/00FF/images/simple/v2 can be dereferenced to request the images sample ontology in the simple schema. If the client dereferences a built-in Knora ontology, such as http://api.knora.org/ontology/knora-api/simple/v2 , there must be a DSP-API server running at api.knora.org that can serve the ontology. The DaSCH intends to run such as server. For testing, you can configure your local /etc/hosts file to resolve api.knora.org as localhost .","title":"Querying an Ontology"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#differences-between-internal-and-external-ontologies","text":"The external ontologies used by DSP-API v2 are different to the internal ontologies that are actually stored in the triplestore (see API Schema ). In general, the external ontologies use simpler data structures, but they also provide additional information to make it easier for clients to use them. This is illustrated in the examples in the next sections. The internal predicates knora-base:subjectClassConstraint and knora-base:objectClassConstraint (see Constraints on the Types of Property Subjects and Objects ) are represented as knora-api:subjectType and knora-api:objectType in external ontologies.","title":"Differences Between Internal and External Ontologies"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#json-ld-representation-of-an-ontology-in-the-simple-schema","text":"The simple schema is suitable for client applications that need to read but not update data in Knora. For example, here is the response for the images sample ontology in the simple schema, http://0.0.0.0:3333/ontology/00FF/images/simple/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2\" , \"@type\" : \"owl:Ontology\" , \"rdfs:label\" : \"The images demo ontology\" , \"@graph\" : [ { \"@id\" : \"images:bild\" , \"@type\" : \"owl:Class\" , \"knora-api:resourceIcon\" : \"bild.png\" , \"rdfs:comment\" : \"An image of the demo image collection\" , \"rdfs:label\" : \"Image\" , \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFile\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } } ] }, { \"@id\" : \"images:description\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Description\" , \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"knora-api:Date\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Date of acquisition\" , \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"First name of a person\" , \"rdfs:label\" : \"First name\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"Last name of a person\" , \"rdfs:label\" : \"Name\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\" , \"@type\" : \"owl:Class\" , \"knora-api:resourceIcon\" : \"person.png\" , \"rdfs:comment\" : \"Person\" , \"rdfs:label\" : \"Person\" , \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\" , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\" , \"rdfs:label\" : \"Creator\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } The response format is an RDF graph. The top level object describes the ontology itself, providing its IRI (in the @id member) and its rdfs:label . The @graph member (see Named Graphs in the JSON-LD specification) contains an array of entities that belong to the ontology. In a class definition, cardinalities for properties of the class are represented as in OWL, using objects of type owl:Restriction . The supported cardinalities are the ones indicated in OWL Cardinalities . The class definitions include cardinalities that are directly defined on each class, as well as cardinalities inherited from base classes. For example, we can see cardinalities inherited from knora-api:Resource , such as knora-api:hasStandoffLinkTo and http://schema.org/name (which represents rdfs:label ). In the simple schema, Knora value properties can be datatype properties. The knora-base:objectType of a Knora value property such as images:description is a literal datatype, in this case xsd:string . Moreover, images:description is a subproperty of the standard property dcterms:description , whose object can be a literal value. A client that understands rdfs:subPropertyOf , and is familiar with dcterms:description , can then work with images:description on the basis of its knowledge about dcterms:description . By default, values for rdfs:label and rdfs:comment are returned only in the user's preferred language, or in the system default language. To obtain these values in all available languages, add the URL parameter ?allLanguages=true . For example, with this parameter, the definition of images:description becomes: { \"@id\" : \"images:description\" , \"@type\" : \"owl:DatatypeProperty\" , \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : [ { \"@language\" : \"en\" , \"@value\" : \"Description\" }, { \"@language\" : \"de\" , \"@value\" : \"Beschreibung\" }, { \"@language\" : \"fr\" , \"@value\" : \"Description\" }, { \"@language\" : \"it\" , \"@value\" : \"Descrizione\" } ], \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] } To find out more about the knora-api entities used in the response, the client can request the knora-api ontology in the simple schema: http://api.knora.org/ontology/knora-api/simple/v2 . For example, images:erfassungsdatum has a knora-api:objectType of knora-api:Date , which is a subtype of xsd:string with a Knora-specific, human-readable format. In the knora-api simple ontology, there is a definition of this type: { \"@id\" : \"http://api.knora.org/ontology/knora-api/simple/v2\" , \"@type\" : \"owl:Ontology\" , \"rdfs:label\" : \"The knora-api ontology in the simple schema\" , \"@graph\" : [ { \"@id\" : \"knora-api:Date\" , \"@type\" : \"rdfs:Datatype\" , \"rdfs:comment\" : \"Represents a date as a period with different possible precisions.\" , \"rdfs:label\" : \"Date literal\" , \"rdfs:subClassOf\" : { \"@type\" : \"rdfs:Datatype\" , \"owl:onDatatype\" : { \"@id\" : \"xsd:string\" }, \"owl:withRestrictions\" : { \"xsd:pattern\" : \"(GREGORIAN|JULIAN|ISLAMIC):\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?)?\" } } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } }","title":"JSON-LD Representation of an Ontology in the Simple Schema"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#json-ld-representation-of-an-ontology-in-the-complex-schema","text":"The complex schema is suitable for client applications that need to update data in Knora. For example, here is the response for the images sample ontology in the complex schema, http://0.0.0.0:3333/ontology/00FF/images/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\" , \"@type\" : \"owl:Ontology\" , \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/00FF\" }, \"rdfs:label\" : \"The images demo ontology\" , \"@graph\" : [ { \"@id\" : \"images:bild\" , \"@type\" : \"owl:Class\" , \"knora-api:canBeInstantiated\" : true , \"knora-api:isResourceClass\" : true , \"knora-api:resourceIcon\" : \"bild.png\" , \"rdfs:comment\" : \"An image of the demo image collection\" , \"rdfs:label\" : \"Image\" , \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFileValue\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 3 , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 8 , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 12 , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 12 , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:urheberValue\" } } ] }, { \"@id\" : \"images:description\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : [ \"rows=10\" , \"width=95%\" , \"wrap=soft\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Textarea\" }, \"rdfs:label\" : \"Description\" , \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:DateValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Date\" }, \"rdfs:label\" : \"Date of acquisition\" , \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\" , \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"First name of a person\" , \"rdfs:label\" : \"First name\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\" , \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"Last name of a person\" , \"rdfs:label\" : \"Name\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\" , \"@type\" : \"owl:Class\" , \"knora-api:canBeInstantiated\" : true , \"knora-api:isResourceClass\" : true , \"knora-api:resourceIcon\" : \"person.png\" , \"rdfs:comment\" : \"Person\" , \"rdfs:label\" : \"Person\" , \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:minCardinality\" : 0 , \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:maxCardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\" , \"knora-api:isInherited\" : true , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 0 , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\" , \"salsah-gui:guiOrder\" : 1 , \"owl:cardinality\" : 1 , \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isLinkProperty\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\" , \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\" , \"rdfs:label\" : \"Creator\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } }, { \"@id\" : \"images:urheberValue\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:isEditable\" : true , \"knora-api:isLinkValueProperty\" : true , \"knora-api:isResourceProperty\" : true , \"knora-api:objectType\" : { \"@id\" : \"knora-api:LinkValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\" , \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\" , \"rdfs:label\" : \"Creator\" , \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkToValue\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the complex schema, all Knora value properties are object properties, whose objects are IRIs, each of which uniquely identifies a value that contains metadata and can potentially be edited. The knora-base:objectType of a Knora value property such as images:description is a Knora value class, in this case knora-api:TextValue . Similarly, images:erfassungsdatum has a knora-api:objectType of knora-api:DateValue , which has a more complex structure than the knora-api:Date datatype shown in the previous section. A client can find out more about these value classes by requesting the knora-api ontology in the complex schema, http://api.knora.org/ontology/knora-api/v2 . Moreover, additional information is provided in the complex schema, to help clients that wish to create or update resources and values. A Knora resource class that can be instantiated is identified with the boolean properties knora-api:isResourceClass and knora-api:canBeInstantiated , to distinguish it from built-in abstract classes. Knora resource properties whose values can be edited by clients are identified with knora-api:isResourceProperty and knora-api:isEditable , to distinguish them from properties whose values are maintained automatically by Knora. Link value properties are shown along with link properties, because a client that updates links will need the IRIs of their link values. The predicate salsah-gui:guiOrder tells a GUI client in what order to display the properties of a class, and the predicates salsah-gui:guiElement and salsah-gui:guiAttribute specify how to configure a GUI element for editing the value of a property. For more information on the salsah-gui ontology, see The SALSAH GUI Ontology .","title":"JSON-LD Representation of an Ontology in the Complex Schema"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#ontology-updates","text":"The ontology update API must ensure that the ontologies it creates are valid and consistent, and that existing data is not invalidated by a change to an ontology. To make this easier to enforce, the ontology update API allows only one entity to be created or modified at a time. It is not possible to submit an entire ontology all at once. Each update request is a JSON-LD document providing only the information that is relevant to the update. Moreover, the API enforces the following rules: An entity (i.e. a class or property) cannot be referred to until it has been created. An entity cannot be modified or deleted if it is used in data, except for changes to its rdfs:label or rdfs:comment . An entity cannot be modified if another entity refers to it, with one exception: a knora-api:subjectType or knora-api:objectType that refers to a class will not prevent the class's cardinalities from being modified. Because of these rules, some operations have to be done in a specific order: Properties have to be defined before they can be used in the cardinalities of a class, but a property's knora-api:subjectType cannot refer to a class that does not yet exist. The recommended approach is to first create a class with no cardinalities, then create the properties that it needs, then add cardinalities for those properties to the class. To delete a class along with its properties, the client must first remove the cardinalities from the class, then delete the property definitions, then delete the class definition. When changing an existing ontology, the client must always supply the ontology's knora-api:lastModificationDate , which is returned in the response to each update or when querying the ontology . If user A attempts to update an ontology, but user B has already updated it since the last time user A received the ontology's knora-api:lastModificationDate , user A's update will be rejected with an HTTP 409 Conflict error. This means that it is possible for two different users to work concurrently on the same ontology, but this is discouraged since it is likely to lead to confusion. An ontology can be created or updated only by a system administrator, or by a project administrator in the ontology's project. Ontology updates always use the complex schema.","title":"Ontology Updates"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#creating-a-new-ontology","text":"An ontology is always created within a particular project. HTTP POST to http://host/v2/ontologies { \"knora-api:ontologyName\" : \"ONTOLOGY_NAME\" , \"knora-api:attachedToProject\" : { \"@id\" : \"PROJECT_IRI\" }, \"rdfs:label\" : \"ONTOLOGY_NAME\" , \"@context\" : { \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The ontology name must follow the rules given in Knora IRIs . The ontology metadata can have an optional comment given in the request body as: \"rdfs:comment\": \"some comment\", If the ontology is to be shared by multiple projects, it must be created in the default shared ontologies project, http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject , and the request must have this additional boolean property: \"knora-api:isShared\" : true See Shared Ontologies for details about shared ontologies. A successful response will be a JSON-LD document providing only the ontology's metadata, which includes the ontology's IRI. When the client makes further requests to create entities (classes and properties) in the ontology, it must construct entity IRIs by concatenating the ontology IRI, a # character, and the entity name. An entity name must be a valid XML NCName .","title":"Creating a New Ontology"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#changing-an-ontologys-metadata","text":"One can modify an ontology's metadata by updating its rdfs:label or rdfs:comment or both. The example below shows the request for changing the label of an ontology. HTTP PUT to http://host/v2/ontologies/metadata { \"@id\" : \"ONTOLOGY_IRI\" , \"rdfs:label\" : \"NEW_ONTOLOGY_LABEL\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Similarly, a user can change an ontology's existing comment or add one by specifying the new comment in the request body: { \"@id\" : \"ONTOLOGY_IRI\" , \"rdfs:comment\" : \"NEW_ONTOLOGY_COMMENT\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The request body can also contain a new label and a new comment for the ontology's metadata. A successful response will be a JSON-LD document providing only the ontology's metadata.","title":"Changing an Ontology's Metadata"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#deleting-an-ontologys-comment","text":"HTTP DELETE to http://host/v2/ontologies/comment/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing the ontology's updated metadata.","title":"Deleting an Ontology's comment"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#deleting-an-ontology","text":"An ontology can be deleted only if it is not used in data. HTTP DELETE to http://host/v2/ontologies/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing a confirmation message. To check whether an ontology can be deleted: HTTP GET to http://host/v2/ontologies/candeleteontology/ONTOLOGY_IRI The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting an Ontology"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#creating-a-class-without-cardinalities","text":"HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : { \"@id\" : \"BASE_CLASS_IRI\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided, which can be knora-api:Resource or any of its subclasses. A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Creating a Class Without Cardinalities"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#creating-a-class-with-cardinalities","text":"This can work if the new class will have cardinalities for properties that have no knora-api:subjectType , or if the new class will be a subclass of their knora-api:subjectType . HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : [ { \"@id\" : \"BASE_CLASS_IRI\" }, { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" } } ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided. When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Creating a Class With Cardinalities"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#changing-the-labels-of-a-class","text":"This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. The submitted labels will replace the existing ones.","title":"Changing the Labels of a Class"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#changing-the-comments-of-a-class","text":"This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. The submitted comments will replace the existing ones.","title":"Changing the Comments of a Class"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#deleting-the-comments-of-a-class","text":"This operation is permitted even if the class is used in data. HTTP DELETE to http://host/v2/ontologies/classes/comment/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. All values i.e. all languages for rdfs:comment are deleted. A successful response will be a JSON-LD document providing the class definition.","title":"Deleting the Comments of a Class"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#creating-a-property","text":"HTTP POST to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\" , \"@type\" : \"owl:ObjectProperty\" , \"knora-api:subjectType\" : { \"@id\" : \"SUBJECT_TYPE\" }, \"knora-api:objectType\" : { \"@id\" : \"OBJECT_TYPE\" }, \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" }, \"rdfs:subPropertyOf\" : { \"@id\" : \"BASE_PROPERTY_IRI\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"GUI_ELEMENT_IRI\" }, \"salsah-gui:guiAttribute\" : [ \"GUI_ATTRIBUTE\" ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base property must be provided, which can be knora-api:hasValue , knora-api:hasLinkTo , or any of their subproperties, with the exception of file properties (subproperties of knora-api:hasFileValue ) and link value properties (subproperties of knora-api:hasLinkToValue ). If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be created. The property definition must specify its knora-api:objectType . If the new property is a subproperty of knora-api:hasValue , its knora-api:objectType must be one of the built-in subclasses of knora-api:Value , which are defined in the knora-api ontology in the complex schema. If the new property is a subproperty of knora-base:hasLinkTo , its knora-api:objectType must be a subclass of knora-api:Resource . To improve consistency checking, it is recommended, but not required, to provide knora-api:subjectType , which must be a subclass of knora-api:Resource . The predicates salsah-gui:guiElement and salsah-gui:guiAttribute are optional. If provided, the object of guiElement must be one of the OWL named individuals defined in The SALSAH GUI Ontology . Some GUI elements take required or optional attributes, which are provided as objects of salsah-gui:guiAttribute ; see The SALSAH GUI Ontology for details. A successful response will be a JSON-LD document providing the new property definition (but not any of the other entities in the ontology).","title":"Creating a Property"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#changing-the-labels-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\" , \"@type\" : \"owl:ObjectProperty\" , \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects.","title":"Changing the Labels of a Property"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#changing-the-comments-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\" , \"@type\" : \"owl:ObjectProperty\" , \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\" , \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects.","title":"Changing the Comments of a Property"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#deleting-the-comments-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP DELETE to http://host/v2/ontologies/properties/comment/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. All values i.e. all languages for rdfs:comment are deleted. If the property is a link property, the rdfs:comment of its corresponding link value property will automatically be deleted. A successful response will be a JSON-LD document providing the property definition.","title":"Deleting the Comments of a Property"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#changing-the-gui-element-and-gui-attributes-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties/guielement { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\" , \"@type\" : \"owl:ObjectProperty\" , \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Textarea\" }, \"salsah-gui:guiAttribute\" : [ \"cols=80\" , \"rows=24\" ] } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } To remove the values of salsah-gui:guiElement and salsah-gui:guiAttribute from the property definition, submit the request without those predicates.","title":"Changing the GUI Element and GUI Attributes of a Property"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#adding-cardinalities-to-a-class","text":"If the class (or any of its sub-classes) is used in data, it is not allowed to add cardinalities owl:minCardinality greater than 0 or owl:cardinality 1 to the class. HTTP POST to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:subClassOf\" : { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } At least one cardinality must be submitted. OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Adding Cardinalities to a Class"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#replacing-the-cardinalities-of-a-class","text":"It is possible to replace all cardinalities on properties used by a class. If it succeeds the request will effectively replace all direct cardinalities of the class as specified. That is, it removes all the cardinalities from the class and replaces them with the submitted cardinalities. Meaning that, if no cardinalities are submitted (i.e. the request contains no rdfs:subClassOf ), the class is left with no cardinalities. The request will fail if any of the \"Pre-Update Checks\" fails. A partial update of the ontology will not be performed.","title":"Replacing the Cardinalities of a Class"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#pre-update-checks","text":"Ontology Check Any given cardinality on a property must be included in any of the existing cardinalities for the same property of the super-classes. Any given cardinality on a property must include the effective cardinalities for the same property of all subclasses, taking into account the respective inherited cardinalities from the class hierarchy of the subclasses. Consistency Check with existing data Given that instances of the class or any of its subclasses exist then these instances are checked if they conform to the given cardinality. HTTP PUT to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:subClassOf\" : { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). If any of the \"Pre-Update Checks\" fail the endpoint will respond with a 400 Bad Request containing the reasons why the update failed. The \"Pre-Update Checks\" are available on a dedicated endpoint. For a check whether a particular cardinality can be set on a class/property combination, use the following request: HTTP GET to http://host/v2/ontologies/canreplacecardinalities/CLASS_IRI?propertyIri=PROPERTY_IRI&newCardinality=[0-1|1|1-n|0-n] The response will look like this: Failure: { \"knora-api:canDo\" : false , \"knora-api:cannotDoReason\" : \"An explanation, understandable to humans, why the update cannot be carried out.\" , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Success: { \"knora-api:canDo\" : true , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Note : The following check is still available but deprecated - use the more detailed check above. To check whether all class's cardinalities can be replaced: HTTP GET to http://host/v2/ontologies/canreplacecardinalities/CLASS_IRI The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The ontologies/canreplacecardinalities/CLASS_IRI request is only checking if the class is in use.","title":"Pre-Update Checks"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#delete-a-single-cardinality-from-a-class","text":"If a class is used in data, it is only allowed to delete a cardinality, if the property a cardinality refers to, is not used inside the data. Also, the property isn't allowed to be used inside the data in any subclasses of this class. HTTP PATCH to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:subClassOf\" : { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinality can be deleted: HTTP POST to http://host/v2/ontologies/candeletecardinalities The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Delete a single cardinality from a class"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#changing-the-gui-order-of-cardinalities","text":"To change the GUI order of one or more cardinalities in a class: HTTP PUT to http://host/v2/ontologies/guiorder This can be done even if the class is used in data. The request body includes the cardinalities whose GUI order should be changed, using the predicate salsah-gui:guiOrder , whose object is an integer: { \"@id\" : \"ONTOLOGY_IRI\" , \"@type\" : \"owl:Ontology\" , \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\" , \"@type\" : \"owl:Class\" , \"rdfs:subClassOf\" : { \"@type\" : \"owl:Restriction\" , \"OWL_CARDINALITY_PREDICATE\" : \"OWL_CARDINALITY_VALUE\" , \"owl:onProperty\" : { \"@id\" : \"PROPERTY_IRI\" }, \"salsah-gui:guiOrder\" : \"GUI_ORDER_VALUE\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\" , \"owl\" : \"http://www.w3.org/2002/07/owl#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Only the cardinalities whose GUI order is to be changed need to be included in the request. The OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE are ignored; only the GUI_ORDER_VALUE is changed.","title":"Changing the GUI Order of Cardinalities"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#deleting-a-property","text":"A property can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/properties/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be deleted. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a property can be deleted: HTTP GET to http://host/v2/ontologies/candeleteproperty/PROPERTY_IRI The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting a Property"},{"location":"DSP-API/03-endpoints/api-v2/ontology-information/#deleting-a-class","text":"A class can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/classes/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a class can be deleted: HTTP GET to http://host/v2/ontologies/candeleteclass/CLASS_IRI The response will look like this: { \"knora-api:canDo\" : false , \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting a Class"},{"location":"DSP-API/03-endpoints/api-v2/permalinks/","text":"Permalinks Knora provides a permanent, citable URL for each resource and value. These URLs use Archival Resource Key (ARK) Identifiers , and are designed to remain valid even if the resource itself is moved from one Knora repository to another. Obtaining ARK URLs In the complex schema , a resource or value is always returned with two ARK URLs: one that will always refer to the latest version of the resource or value ( knora-api:arkUrl ), and one that refers specifically to the version being returned ( knora-api:versionArkUrl ). For example: { \"@id\" : \"http://rdfh.ch/0803/2a6221216701\" , \"@type\" : \"incunabula:book\" , \"incunabula:book_comment\" : { \"@id\" : \"http://rdfh.ch/0803/2a6221216701/values/56c287fc9505\" , \"@type\" : \"knora-api:TextValue\" , \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB.20160302T150521Z\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\" , \"knora-api:userHasPermission\" : \"V\" , \"knora-api:valueAsString\" : \"Katalogaufnahme anhand ISTC und v.d.Haegen\" , \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:valueHasUUID\" : \"dhaRsvZATjmOxhCOOzHqew\" }, \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W.20160302T150521Z\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0803\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\" , \"knora-api:userHasPermission\" : \"V\" , \"rdfs:label\" : \"Reise ins Heilige Land\" , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"incunabula\" : \"http://0.0.0.0:3333/ontology/0803/incunabula/v2#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the simple schema , resources are returned with ARK URLs, but values are returned as literals, so ARK URLs are not provided for values. For more information on getting past versions of resources and values, see: Get a Full Representation of a Version of a Resource by IRI Get a Version of a Value in a Resource Get the Version History of a Resource Resolving Knora ARK URLs A Knora ARK URL is intended to be resolved by the Knora ARK resolver . Knora ARK URL Format For details, see Archival Resource Key (ARK) Identifiers . ARK URLs for Projects The format of a Knora project ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), and PROJECT is the project's short-code . For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 This could redirect to a page describing the project. ARK URLs for Resources The format of a Knora resource ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , and RESOURCE_UUID is the resource's UUID . For example, given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180604T085622513Z Without a timestamp, a Knora resource ARK URL refers to the latest version of the resource at the time when the URL is resolved. ARK URLs for Values The format of a Knora value ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID/VALUE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , RESOURCE_UUID is the resource's UUID , and VALUE_UUID is the value's knora-api:valueHasUUID . For example, given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Without a timestamp, a Knora value ARK URL refers to the latest version of the value at the time when the URL is resolved.","title":"Permalinks"},{"location":"DSP-API/03-endpoints/api-v2/permalinks/#permalinks","text":"Knora provides a permanent, citable URL for each resource and value. These URLs use Archival Resource Key (ARK) Identifiers , and are designed to remain valid even if the resource itself is moved from one Knora repository to another.","title":"Permalinks"},{"location":"DSP-API/03-endpoints/api-v2/permalinks/#obtaining-ark-urls","text":"In the complex schema , a resource or value is always returned with two ARK URLs: one that will always refer to the latest version of the resource or value ( knora-api:arkUrl ), and one that refers specifically to the version being returned ( knora-api:versionArkUrl ). For example: { \"@id\" : \"http://rdfh.ch/0803/2a6221216701\" , \"@type\" : \"incunabula:book\" , \"incunabula:book_comment\" : { \"@id\" : \"http://rdfh.ch/0803/2a6221216701/values/56c287fc9505\" , \"@type\" : \"knora-api:TextValue\" , \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB.20160302T150521Z\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\" , \"knora-api:userHasPermission\" : \"V\" , \"knora-api:valueAsString\" : \"Katalogaufnahme anhand ISTC und v.d.Haegen\" , \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:valueHasUUID\" : \"dhaRsvZATjmOxhCOOzHqew\" }, \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\" , \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W.20160302T150521Z\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0803\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\" , \"knora-api:userHasPermission\" : \"V\" , \"rdfs:label\" : \"Reise ins Heilige Land\" , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"incunabula\" : \"http://0.0.0.0:3333/ontology/0803/incunabula/v2#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the simple schema , resources are returned with ARK URLs, but values are returned as literals, so ARK URLs are not provided for values. For more information on getting past versions of resources and values, see: Get a Full Representation of a Version of a Resource by IRI Get a Version of a Value in a Resource Get the Version History of a Resource","title":"Obtaining ARK URLs"},{"location":"DSP-API/03-endpoints/api-v2/permalinks/#resolving-knora-ark-urls","text":"A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Resolving Knora ARK URLs"},{"location":"DSP-API/03-endpoints/api-v2/permalinks/#knora-ark-url-format","text":"For details, see Archival Resource Key (ARK) Identifiers .","title":"Knora ARK URL Format"},{"location":"DSP-API/03-endpoints/api-v2/permalinks/#ark-urls-for-projects","text":"The format of a Knora project ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), and PROJECT is the project's short-code . For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 This could redirect to a page describing the project.","title":"ARK URLs for Projects"},{"location":"DSP-API/03-endpoints/api-v2/permalinks/#ark-urls-for-resources","text":"The format of a Knora resource ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , and RESOURCE_UUID is the resource's UUID . For example, given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180604T085622513Z Without a timestamp, a Knora resource ARK URL refers to the latest version of the resource at the time when the URL is resolved.","title":"ARK URLs for Resources"},{"location":"DSP-API/03-endpoints/api-v2/permalinks/#ark-urls-for-values","text":"The format of a Knora value ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID/VALUE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , RESOURCE_UUID is the resource's UUID , and VALUE_UUID is the value's knora-api:valueHasUUID . For example, given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Without a timestamp, a Knora value ARK URL refers to the latest version of the value at the time when the URL is resolved.","title":"ARK URLs for Values"},{"location":"DSP-API/03-endpoints/api-v2/query-language/","text":"Gravsearch: Virtual Graph Search Basic Concept Gravsearch is intended to offer the advantages of SPARQL endpoints (particularly the ability to perform queries using complex search criteria) while avoiding their drawbacks in terms of performance and security (see The Enduring Myth of the SPARQL Endpoint ). It also has the benefit of enabling clients to work with a simpler RDF data model than the one the API actually uses to store data in the triplestore, and makes it possible to provide better error-checking. Rather than being processed directly by the triplestore, a Gravsearch query is interpreted by the API, which enforces certain restrictions on the query, and implements paging and permission checking. The API server generates SPARQL based on the Gravsearch query submitted, queries the triplestore, filters the results according to the user's permissions, and returns each page of query results as an API response. Thus, Gravsearch is a hybrid between a RESTful API and a SPARQL endpoint. A Gravsearch query conforms to a subset of the syntax of a SPARQL CONSTRUCT query, with some additional restrictions and functionality. In particular, the variable representing the top-level (or 'main') resource that will appear in each search result must be identified, statements must be included to specify the types of the entities being queried, OFFSET is used to control paging, and ORDER BY is used to sort the results. It is certainly possible to write Gravsearch queries by hand, but we expect that in general, they will be automatically generated by client software, e.g. by a client user interface. For a more detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data . Submitting Gravsearch Queries The recommended way to submit a Gravsearch query is via HTTP POST: HTTP POST to http://host/v2/searchextended This works like query via POST directly in the SPARQL 1.1 Protocol : the query is sent unencoded as the HTTP request message body, in the UTF-8 charset. It is also possible to submit a Gravsearch query using HTTP GET. The entire query must be URL-encoded and included as the last element of the URL path: HTTP GET to http://host/v2/searchextended/QUERY The response to a Gravsearch query is an RDF graph, which can be requested in various formats (see Responses Describing Resources ). To request the number of results rather than the results themselves, you can do a count query: HTTP POST to http://host/v2/searchextended/count The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. If a gravsearch query times out, a 504 Gateway Timeout will be returned. Gravsearch and API Schemas A Gravsearch query can be written in either of the two DSP-API v2 schemas . The simple schema is easier to work with, and is sufficient if you don't need to query anything below the level of a DSP-API value. If your query needs to refer to standoff markup, you must use the complex schema. Each query must use a single schema, with one exception (see Date Comparisons ). Gravsearch query results can be requested in the simple or complex schema; see API Schema . All examples hereafter run with the DSP stack started locally. If you access another stack, you can check the IRI of the ontology you are targeting by requesting the ontologies metadata . Using the Simple Schema To write a query in the simple schema, use the knora-api ontology in the simple schema, and use the simple schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> In the simple schema, DSP-API values are represented as literals, which can be used FILTER expressions (see Filtering on Values in the Simple Schema ). Using the Complex Schema To write a query in the complex schema, use the knora-api ontology in the complex schema, and use the complex schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> In the complex schema, DSP-API values are represented as objects belonging to subclasses of knora-api:Value , e.g. knora-api:TextValue , and have predicates of their own, which can be used in FILTER expressions (see Filtering on Values in the Complex Schema ). Main and Dependent Resources The main resource is the top-level resource in a search result. Other resources that are in some way connected to the main resource are referred to as dependent resources. If the client asks for a resource A relating to a resource B, then all matches for A will be presented as main resources and those for B as dependent resources. The main resource must be represented by a variable, marked with knora-api:isMainResource , as explained under CONSTRUCT Clause . Virtual incoming Links Depending on the ontology design, a resource A points to B or vice versa. For example, a page A is part of a book B using the property incunabula:partOf . If A is marked as the main resource, then B is nested as a dependent resource in its link value incunabula:partOfValue . But in case B is marked as the main resource, B does not have a link value pointing to A because in fact B is pointed to by A. Instead, B has a virtual property knora-api:hasIncomingLink containing A's link value: \"knora-api:hasIncomingLinkValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasSource\" : { \"@id\" : \"http://rdfh.ch/A\", \"@type\" : \"incunabula:page\", \"incunabula:partOfValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/B\" } } } }, Note that the virtually inserted link value inverts the relation by using knora-api:linkValueHasSource . The source of the link is A and its target B is only represented by an Iri ( knora-api:linkValueHasTargetIri ) since B is the main resource. Graph Patterns and Result Graphs The WHERE clause of a Gravsearch query specifies a graph pattern. Each query result will match this graph pattern, and will have the form of a graph whose starting point is a main resource. The query's graph pattern, and hence each query result graph, can span zero more levels of relations between resources. For example, a query could request regions in images on pages of books written by a certain author, articles by authors who were students of a particular professor, or authors of texts that refer to events that took place within a certain date range. Permission Checking Each matching resource is returned with the values that the user has permission to see. If the user does not have permission to see a matching main resource, it is hidden in the results. If a user does not have permission to see a matching dependent resource, the link value is hidden. Paging Gravsearch results are returned in pages. The maximum number of main resources per page is determined by the API (and can be configured in application.conf via the setting app/v2/resources-sequence/results-per-page ). If some resources have been filtered out because the user does not have permission to see them, a page could contain fewer results, or no results. If it is possible that more results are available in subsequent pages, the Gravsearch response will contain the predicate knora-api:mayHaveMoreResults with the boolean value true , otherwise it will not contain this predicate. Therefore, to retrieve all available results, the client must request each page one at a time, until the response does not contain knora-api:mayHaveMoreResults . Inference Gravsearch queries are understood to imply a subset of RDFS reasoning . This is done by the API by expanding the incoming query. Specifically, if a statement pattern specifies a property, the pattern will also match subproperties of that property, and if a statement specifies that a subject has a particular rdf:type , the statement will also match subjects belonging to subclasses of that type. If you know that reasoning will not return any additional results for your query, you can disable it by adding this line to the WHERE clause, which may improve query performance: knora-api : GravsearchOptions knora-api : useInference false . Gravsearch Syntax Every Gravsearch query is a valid SPARQL 1.1 CONSTRUCT query. However, Gravsearch only supports a subset of the elements that can be used in a SPARQL Construct query, and a Gravsearch CONSTRUCT Clause has to indicate which variable is to be used for the main resource in each search result. Supported SPARQL Syntax The current version of Gravsearch accepts CONSTRUCT queries whose WHERE clauses use the following patterns, with the specified restrictions: OPTIONAL : cannot be nested in a UNION . UNION : cannot be nested in a UNION . FILTER : may contain a complex expression using the Boolean operators AND and OR, as well as comparison operators. The left argument of a comparison operator must be a query variable. A Knora ontology entity IRI used in a FILTER must be a property IRI. FILTER NOT EXISTS MINUS OFFSET : the OFFSET is needed for paging. It does not actually refer to the number of triples to be returned, but to the requested page of results. The default value is 0, which refers to the first page of results. ORDER BY : In SPARQL, the result of a CONSTRUCT query is an unordered set of triples. However, a Gravsearch query returns an ordered list of resources, which can be ordered by the values of specified properties. If the query is written in the complex schema, items below the level of DSP-API values may not be used in ORDER BY . BIND : The value assigned must be a DSP resource IRI. Resources, Properties, and Values Resources can be represented either by an IRI or by a variable, except for the main resource, which must be represented by a variable. It is possible to do a Gravsearch query in which the IRI of the main resource is already known, e.g. to request specific information about that resource and perhaps about linked resources. In this case, the IRI of the main resource must be assigned to a variable using BIND . Note that BIND statements slow the query down, therefore we recommend that you do not use them unless you have to. Properties can be represented by an IRI or a query variable. If a property is represented by a query variable, it can be restricted to certain property IRIs using a FILTER . A Knora value (i.e. a value attached to a knora-api:Resource ) must be represented as a query variable. Filtering on Values Filtering on Values in the Simple Schema In the simple schema, a variable representing a DSP-API value can be used directly in a FILTER expression. For example: ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Here the type of ?title is xsd:string . The following value types can be compared with literals in FILTER expressions in the simple schema: Text values ( xsd:string ) Uri values ( xsd:anyURI ) Integer values ( xsd:integer ) Decimal values ( xsd:decimal ) Boolean values ( xsd:boolean ) Date values ( knora-api:Date ) List values ( knora-api:ListNode ) List values can only be searched for using the equal operator ( = ), performing an exact match on a list node's label. Labels can be given in different languages for a specific list node. If one of the given list node labels matches, it is considered a match. Note that in the simple schema, uniqueness is not guaranteed (as opposed to the complex schema). A DSP-API value may not be represented as the literal object of a predicate; for example, this is not allowed: ?book incunabula:title \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Filtering on Values in the Complex Schema In the complex schema, variables representing DSP-API values are not literals. You must add something to the query (generally a statement) to get a literal from a DSP-API value. For example: ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Here the type of ?title is knora-api:TextValue . Note that no FILTER is needed in this example. But if you want to use a different comparison operator, you need a FILTER : ?page incunabula:seqnum ?seqnum . ?seqnum knora-api:intValueAsInt ?seqnumInt . FILTER(?seqnumInt <= 10) To match a date value in the complex schema, you must use the knora-api:toSimpleDate function in a FILTER (see Date Comparisons ). The predicates of knora-api:DateValue ( knora-api:dateValueHasStartYear , etc.) are not available in Gravsearch. Date Comparisons In the simple schema, you can compare a date value directly with a knora-api:Date in a FILTER : ?book incunabula:pubdate ?pubdate . FILTER(?pubdate < \"JULIAN:1497\"^^knora-api:Date) In the complex schema, you must use the function knora-api:toSimpleDate , passing it the variable representing the date value. The date literal used in the comparison must still be a knora-api:Date in the simple schema. This is the only case in which you can use both schemas in a single query: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true . ?book incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book . ?book incunabula:pubdate ?pubdate . FILTER(knora-api:toSimpleDate(?pubdate) < \"JULIAN:1497\"^^knora-api-simple:Date) } ORDER BY ?pubdate You can also use knora-api:toSimpleDate with to search for date tags in standoff text markup (see Matching Standoff Dates ). Note that the given date value for comparison must have the following format: ``` (GREGORIAN|JULIAN|ISLAMIC):\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?)? ``` E.g. an exact date like GREGORIAN:2015-12-03 or a period like GREGORIAN:2015-12-03:2015-12-04 . Dates may also have month or year precision, e.g. ISLAMIC:1407-02 (the whole month of december) or JULIAN:1330 (the whole year 1330). An optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Era can be given as GREGORIAN:1220 BC or in range as GREGORIAN:600 BC:480 BC . Searching for Matching Words The function knora-api:matchText searches for matching words anywhere in a text value, and is implemented using a full-text search index if available. The first argument must represent a text value (a knore-api:TextValue in the complex schema, or an xsd:string in the simple schema). The second argument is a string literal containing the words to be matched, separated by spaces. The function supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. This function can only be used as the top-level expression in a FILTER . For example, to search for titles that contain the words 'Zeitgl\u00f6cklein' and 'Lebens': ?book incunabule:title ?title . FILTER knora-api:matchText(?title, \"Zeitgl\u00f6cklein Lebens\") Filtering Text by Language To filter a text value by language in the simple schema, use the SPARQL lang function on the text value, e.g.: FILTER(lang(?text) = \"fr\") In the complex schema, the lang function is not supported. Use the text value's knora-api:textValueHasLanguage predicate instead: ?text knora-api:textValueHasLanguage \"fr\" . Regular Expressions The SPARQL regex function is supported. In the simple schema, you can use it directly on the text value, e.g. ?book incunabula:title ?title . FILTER regex(?title, \"Zeit\", \"i\") In the complex schema, use it on the object of the text value's knora-api:valueAsString predicate: ?book incunabula:title ?title . ?title knora-api:valueAsString ?titleStr . FILTER regex(?titleStr, \"Zeit\", \"i\") Searching for Text Markup To refer to standoff markup in text values, you must write your query in the complex schema. A knora-api:TextValue can have the property knora-api:textValueHasStandoff , whose objects are the standoff markup tags in the text. You can match the tags you're interested in using rdf:type or other properties of each tag. Matching Text in a Standoff Tag The function knora-api:matchTextInStandoff searches for standoff tags containing certain terms. The implementation is optimised using the full-text search index if available. The function takes three arguments: A variable representing a text value. A variable representing a standoff tag. A string literal containing space-separated search terms. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . FILTER knora-api:matchTextInStandoff(?text, ?standoffParagraphTag, \"Grund Richtigkeit\") } Here we are looking for letters containing the words \"Grund\" and \"Richtigkeit\" within a single paragraph. Matching Standoff Links If you are only interested in specifying that a resource has some text value containing a standoff link to another resource, the most efficient way is to use the property knora-api:hasStandoffLinkTo , whose subjects and objects are resources. This property is automatically maintained by the API. For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . } Here we are looking for letters containing a link to the historian Claude Jordan, who is identified by his Integrated Authority File identifier, (VIAF)271899510 . However, if you need to specify the context in which the link tag occurs, you must use the function knora-api:standoffLink . It takes three arguments: A variable or IRI representing the resource that is the source of the link. A variable representing the standoff link tag. A variable or IRI representing the resource that is the target of the link. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . } This has the same effect as the previous example, except that because we are matching the link tag itself, we can specify that its immediate parent is a StandoffItalicTag . If you actually want to get the target of the link (in this example, ?person ) in the search results, you need to add a statement like ?letter knora-api:hasStandoffLinkTo ?person . to the WHERE clause and to the CONSTRUCT clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . ?letter knora-api:hasStandoffLinkTo ?person . } Matching Standoff Dates You can use the knora-api:toSimpleDate function (see @ref Date Comparisons ) to match dates in standoff date tags, i.e. instances of knora-api:StandoffDateTag or of one of its subclasses. For example, here we are looking for a text containing an anything:StandoffEventTag (which is a project-specific subclass of knora-api:StandoffDateTag ) representing an event that occurred sometime during the month of December 2016: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffEventTag . ?standoffEventTag a anything:StandoffEventTag . FILTER(knora-api:toSimpleDate(?standoffEventTag) = \"GREGORIAN:2016-12 CE\"^^knora-api-simple:Date) } Matching Ancestor Tags Suppose we want to search for a standoff date in a paragraph, but we know that the paragraph tag might not be the immediate parent of the date tag. For example, the date tag might be in an italics tag, which is in a paragraph tag. In that case, we can use the inferred property knora-api:standoffTagHasStartAncestor . We can modify the previous example to do this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffDateTag . ?standoffDateTag a knora-api:StandoffDateTag . FILTER(knora-api:toSimpleDate(?standoffDateTag) = \"GREGORIAN:2016-12-24 CE\"^^knora-api-simple:Date) ?standoffDateTag knora-api:standoffTagHasStartAncestor ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . } Filtering on rdfs:label The rdfs:label of a resource is not a DSP-API value, but you can still search for it. This can be done in the same ways in the simple or complex schema: Using a string literal object: ?book rdfs:label \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Using a variable and a FILTER: ?book rdfs:label ?label . FILTER(?label = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Using the regex function: ?book rdfs:label ?bookLabel . FILTER regex(?bookLabel, \"Zeit\", \"i\") To match words in an rdfs:label using the full-text search index, use the knora-api:matchLabel function, which works like knora-api:matchText , except that the first argument is a variable representing a resource: FILTER knora-api:matchLabel(?book, \"Zeitgl\u00f6cklein\") Filtering on Resource IRIs A FILTER can compare a variable with another variable or IRI representing a resource. For example, to find a letter whose author and recipient are different persons: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != ?person2) . } OFFSET 0 To find a letter whose author is not a person with a specified IRI: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != <http://rdfh.ch/0801/F4n1xKa3TCiR4llJeElAGA>) . } OFFSET 0 CONSTRUCT Clause In the CONSTRUCT clause of a Gravsearch query, the variable representing the main resource must be indicated with knora-api:isMainResource true . Exactly one variable representing a resource must be marked in this way. Any other statements in the CONSTRUCT clause must also be present in the WHERE clause. If a variable representing a resource or value is used in the WHERE clause but not in the CONSTRUCT clause, the matching resources or values will not be included in the results. If the query is written in the complex schema, all variables in the CONSTRUCT clause must refer to DSP-API resources, DSP-API values, or properties. Data below the level of values may not be mentioned in the CONSTRUCT clause. Predicates from the rdf , rdfs , and owl ontologies may not be used in the CONSTRUCT clause. The rdfs:label of each matching resource is always returned, so there is no need to mention it in the query. Gravsearch by Example In this section, we provide some sample queries of different complexity to illustrate the usage of Gravsearch. Getting All the Components of a Compound Resource In order to get all the components of a compound resource, the following Gravsearch query can be sent to the API. In this case, the compound resource is an incunabula:book identified by the IRI http://rdfh.ch/0803/c5058f3a and the components are of type incunabula:page (test data for the Incunabula project). Since inference is assumed, we can use knora-api:StillImageRepresentation ( incunabula:page is one of its subclasses). This makes the query more generic and allows for reuse (for instance, a client would like to query different types of compound resources defined in different ontologies). ORDER BY is used to sort the components by their sequence number. OFFSET is set to 0 to get the first page of results. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?component knora-api:isMainResource true . # marking of the component searched for as the main resource, required ?component knora-api:seqnum ?seqnum . # return the sequence number in the response ?component knora-api:hasStillImageFileValue ?file . # return the StillImageFile in the response } WHERE { ?component a knora-api:StillImageRepresentation . # restriction of the type of component ?component knora-api:isPartOf <http://rdfh.ch/0803/c5058f3a> . # component relates to a compound resource via this property ?component knora-api:seqnum ?seqnum . # component must have a sequence number ?component knora-api:hasStillImageFileValue ?file . # component must have a StillImageFile } ORDER BY ASC(?seqnum) # order by sequence number, ascending OFFSET 0 # get first page of results The incunabula:book with the IRI http://rdfh.ch/0803/c5058f3a has 402 pages. (This result can be obtained by doing a count query; see Submitting Gravsearch Queries .) However, with OFFSET 0 , only the first page of results is returned. The same query can be sent again with OFFSET 1 to get the next page of results, and so forth. When a page of results is not full (see settings in app/v2 in application.conf ) or is empty, no more results are available. By design, it is not possible for the client to get more than one page of results at a time; this is intended to prevent performance problems that would be caused by huge responses. A client that wants to download all the results of a query must request each page sequentially. Let's assume the client is not interested in all of the book's pages, but just in first ten of them. In that case, the sequence number can be restricted using a FILTER that is added to the query's WHERE clause: FILTER (?seqnum <= 10) The first page starts with sequence number 1, so with this FILTER only the first ten pages are returned. This query would be exactly the same in the complex schema, except for the expansion of the knora-api prefix: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> Traversing Multiple Links Here we are looking for regions of pages that are part of books that have a particular title. In the simple schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") } In the complex schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . } If we remove the line ?book incunabula:title ?title . from the CONSTRUCT clause, so that the CONSTRUCT clause no longer mentions ?title , the response will contain the same matching resources, but the titles of those resources will not be included in the response. Requesting a Graph Starting with a Known Resource Here the IRI of the main resource is already known, and we want specific information about it, as well as about related resources. In this case, the IRI of the main resource must be assigned to a variable using BIND : PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?letter knora-api:isMainResource true ; beol:creationDate ?date ; ?linkingProp1 ?person1 . ?person1 beol:hasFamilyName ?familyName . } WHERE { BIND(<http://rdfh.ch/0801/_B3lQa6tSymIq7_7SowBsA> AS ?letter) ?letter a beol:letter ; beol:creationDate ?date ; ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient) ?person1 beol:hasFamilyName ?familyName . } ORDER BY ?date This query would be the same in the complex schema, except for the prefix expansions: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> Searching for a List Value Referring to a Particular List Node Since list nodes are represented by their Iri in the complex schema, uniqueness is guranteed (as opposed to the simple schema). Also all the subnodes of the given list node are considered a match. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasListItem ?listItem . } WHERE { ?thing anything:hasListItem ?listItem . ?listItem knora-api:listValueAsListNode <http://rdfh.ch/lists/0001/treeList02> . } Type Inference Gravsearch needs to be able to determine the types of the entities that query variables and IRIs refer to in the WHERE clause. In most cases, it can infer these from context and from the ontologies used. In particular, it needs to know: The type of the subject and object of each statement. The type that is expected as the object of each predicate. Type Annotations When one or more types cannot be inferred, Gravsearch will return an error message indicating the entities for which it could not determine types. The missing information must then be given by adding type annotations to the query. This can always done by adding statements with the predicate rdf:type . The subject must be a resource or value, and the object must either be knora-api:Resource (if the subject is a resource) or the subject's specific type (if it is a value). For example, consider this query that uses a non-DSP property: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book dcterms:title ?title . } This produces the error message: The types of one or more entities could not be determined: ?book, <http://purl.org/dc/terms/title>, ?title To solve this problem, it is enough to specify the types of ?book and ?title ; the type of the expected object of dcterms:title can then be inferred from the type of ?title . PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . ?title rdf:type xsd:string . } It would also be possible to annotate the property itself, using the predicate knora-api:objectType ; then the type of ?title would be inferred: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . dcterms:title knora-api:objectType xsd:string . } Note that it only makes sense to use dcterms:title in the simple schema, because its object is supposed to be a literal. Here is another example, using a non-DSP class: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } This produces the error message: Types could not be determined for one or more entities: ?person The solution is to specify that ?person is a knora-api:Resource : PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person a knora-api:Resource . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } Inconsistent Types Gravsearch will also reject a query if an entity is used with inconsistent types. For example: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\") . } This returns the error message: One or more entities have inconsistent types: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#pubdate> knora-api:objectType <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; knora-api:objectType <http://www.w3.org/2001/XMLSchema#string> . ?pubdate rdf:type <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; rdf:type <http://www.w3.org/2001/XMLSchema#string> . This is because the incunabula ontology says that the object of incunabula:pubdate must be a knora-api:Date , but the FILTER expression compares ?pubdate with an xsd:string . The solution is to specify the type of the literal in the FILTER : PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\"^^knora-api:Date) . } Scoping Issues SPARQL is evaluated from the bottom up . A UNION block therefore opens a new scope, in which variables bound at higher levels are not necessarily in scope. This can cause unexpected results if queries are not carefully designed. Gravsearch tries to prevent this by rejecting queries in the following cases. FILTER in UNION A FILTER in a UNION block can only use variables that are bound in the same block, otherwise the query will be rejected. This query is invalid because ?text is not bound in the UNION block containing the FILTER where the variable is used: PREFIX knora-api : <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls : <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api : isMainResource true . ?lemma mls : hasLemmaText ?text . } WHERE { ?lemma a mls : Lemma . ?lemma mls : hasLemmaText ?text . { ?lemma mls : hasPseudonym ?pseudo . FILTER regex ( ?pseudo , \"Abel\" , \"i\" ) . } UNION { FILTER regex ( ?text , \"Abel\" , \"i\" ) . } } ORDER BY ASC ( ?text ) OFFSET 0 It can be corrected like this: PREFIX knora-api : <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls : <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api : isMainResource true . ?lemma mls : hasLemmaText ?text . } WHERE { ?lemma a mls : Lemma . ?lemma mls : hasLemmaText ?text . { ?lemma mls : hasPseudonym ?pseudo . FILTER regex ( ?pseudo , \"Abel\" , \"i\" ) . } UNION { ?lemma mls : hasLemmaText ?text . FILTER regex ( ?text , \"Abel\" , \"i\" ) . } } ORDER BY ASC ( ?text ) OFFSET 0 ORDER BY A variable used in ORDER BY must be bound at the top level of the WHERE clause. This query is invalid, because ?int is not bound at the top level of the WHERE clause: PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything : <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api : isMainResource true . ?thing anything : hasInteger ?int . ?thing anything : hasRichtext ?richtext . ?thing anything : hasText ?text . } WHERE { ?thing a knora-api : Resource . ?thing a anything : Thing . { ?thing anything : hasRichtext ?richtext . FILTER knora-api : matchText ( ?richtext , \"test\" ) ?thing anything : hasInteger ?int . } UNION { ?thing anything : hasText ?text . FILTER knora-api : matchText ( ?text , \"test\" ) ?thing anything : hasInteger ?int . } } ORDER BY ( ?int ) It can be corrected like this: PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything : <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api : isMainResource true . ?thing anything : hasInteger ?int . ?thing anything : hasRichtext ?richtext . ?thing anything : hasText ?text . } WHERE { ?thing a knora-api : Resource . ?thing a anything : Thing . ?thing anything : hasInteger ?int . { ?thing anything : hasRichtext ?richtext . FILTER knora-api : matchText ( ?richtext , \"test\" ) } UNION { ?thing anything : hasText ?text . FILTER knora-api : matchText ( ?text , \"test\" ) } } ORDER BY ( ?int ) Query Optimization by Dependency The query performance of triplestores, such as Fuseki, is highly dependent on the order of query patterns. To improve performance, Gravsearch automatically reorders the statement patterns in the WHERE clause according to their dependencies on each other, to minimise the number of possible matches for each pattern. Consider the following Gravsearch query: PREFIX beol : <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api : isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol : creationDate ?date . } WHERE { ?letter beol : creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER ( ?linkingProp1 = beol : hasAuthor || ?linkingProp1 = beol : hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER ( ?linkingProp2 = beol : hasAuthor || ?linkingProp2 = beol : hasRecipient ) ?person1 beol : hasIAFIdentifier ?gnd1 . ?gnd1 knora-api : valueAsString \"(DE-588)118531379\" . ?person2 beol : hasIAFIdentifier ?gnd2 . ?gnd2 knora-api : valueAsString \"(DE-588)118696149\" . } ORDER BY ?date Gravsearch optimises the performance of this query by moving these statements to the top of the WHERE clause: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the WHERE clause then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date .","title":"Gravsearch - Virtual Graph Search"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#gravsearch-virtual-graph-search","text":"","title":"Gravsearch: Virtual Graph Search"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#basic-concept","text":"Gravsearch is intended to offer the advantages of SPARQL endpoints (particularly the ability to perform queries using complex search criteria) while avoiding their drawbacks in terms of performance and security (see The Enduring Myth of the SPARQL Endpoint ). It also has the benefit of enabling clients to work with a simpler RDF data model than the one the API actually uses to store data in the triplestore, and makes it possible to provide better error-checking. Rather than being processed directly by the triplestore, a Gravsearch query is interpreted by the API, which enforces certain restrictions on the query, and implements paging and permission checking. The API server generates SPARQL based on the Gravsearch query submitted, queries the triplestore, filters the results according to the user's permissions, and returns each page of query results as an API response. Thus, Gravsearch is a hybrid between a RESTful API and a SPARQL endpoint. A Gravsearch query conforms to a subset of the syntax of a SPARQL CONSTRUCT query, with some additional restrictions and functionality. In particular, the variable representing the top-level (or 'main') resource that will appear in each search result must be identified, statements must be included to specify the types of the entities being queried, OFFSET is used to control paging, and ORDER BY is used to sort the results. It is certainly possible to write Gravsearch queries by hand, but we expect that in general, they will be automatically generated by client software, e.g. by a client user interface. For a more detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data .","title":"Basic Concept"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#submitting-gravsearch-queries","text":"The recommended way to submit a Gravsearch query is via HTTP POST: HTTP POST to http://host/v2/searchextended This works like query via POST directly in the SPARQL 1.1 Protocol : the query is sent unencoded as the HTTP request message body, in the UTF-8 charset. It is also possible to submit a Gravsearch query using HTTP GET. The entire query must be URL-encoded and included as the last element of the URL path: HTTP GET to http://host/v2/searchextended/QUERY The response to a Gravsearch query is an RDF graph, which can be requested in various formats (see Responses Describing Resources ). To request the number of results rather than the results themselves, you can do a count query: HTTP POST to http://host/v2/searchextended/count The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. If a gravsearch query times out, a 504 Gateway Timeout will be returned.","title":"Submitting Gravsearch Queries"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#gravsearch-and-api-schemas","text":"A Gravsearch query can be written in either of the two DSP-API v2 schemas . The simple schema is easier to work with, and is sufficient if you don't need to query anything below the level of a DSP-API value. If your query needs to refer to standoff markup, you must use the complex schema. Each query must use a single schema, with one exception (see Date Comparisons ). Gravsearch query results can be requested in the simple or complex schema; see API Schema . All examples hereafter run with the DSP stack started locally. If you access another stack, you can check the IRI of the ontology you are targeting by requesting the ontologies metadata .","title":"Gravsearch and API Schemas"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#using-the-simple-schema","text":"To write a query in the simple schema, use the knora-api ontology in the simple schema, and use the simple schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> In the simple schema, DSP-API values are represented as literals, which can be used FILTER expressions (see Filtering on Values in the Simple Schema ).","title":"Using the Simple Schema"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#using-the-complex-schema","text":"To write a query in the complex schema, use the knora-api ontology in the complex schema, and use the complex schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> In the complex schema, DSP-API values are represented as objects belonging to subclasses of knora-api:Value , e.g. knora-api:TextValue , and have predicates of their own, which can be used in FILTER expressions (see Filtering on Values in the Complex Schema ).","title":"Using the Complex Schema"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#main-and-dependent-resources","text":"The main resource is the top-level resource in a search result. Other resources that are in some way connected to the main resource are referred to as dependent resources. If the client asks for a resource A relating to a resource B, then all matches for A will be presented as main resources and those for B as dependent resources. The main resource must be represented by a variable, marked with knora-api:isMainResource , as explained under CONSTRUCT Clause .","title":"Main and Dependent Resources"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#virtual-incoming-links","text":"Depending on the ontology design, a resource A points to B or vice versa. For example, a page A is part of a book B using the property incunabula:partOf . If A is marked as the main resource, then B is nested as a dependent resource in its link value incunabula:partOfValue . But in case B is marked as the main resource, B does not have a link value pointing to A because in fact B is pointed to by A. Instead, B has a virtual property knora-api:hasIncomingLink containing A's link value: \"knora-api:hasIncomingLinkValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasSource\" : { \"@id\" : \"http://rdfh.ch/A\", \"@type\" : \"incunabula:page\", \"incunabula:partOfValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/B\" } } } }, Note that the virtually inserted link value inverts the relation by using knora-api:linkValueHasSource . The source of the link is A and its target B is only represented by an Iri ( knora-api:linkValueHasTargetIri ) since B is the main resource.","title":"Virtual incoming Links"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#graph-patterns-and-result-graphs","text":"The WHERE clause of a Gravsearch query specifies a graph pattern. Each query result will match this graph pattern, and will have the form of a graph whose starting point is a main resource. The query's graph pattern, and hence each query result graph, can span zero more levels of relations between resources. For example, a query could request regions in images on pages of books written by a certain author, articles by authors who were students of a particular professor, or authors of texts that refer to events that took place within a certain date range.","title":"Graph Patterns and Result Graphs"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#permission-checking","text":"Each matching resource is returned with the values that the user has permission to see. If the user does not have permission to see a matching main resource, it is hidden in the results. If a user does not have permission to see a matching dependent resource, the link value is hidden.","title":"Permission Checking"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#paging","text":"Gravsearch results are returned in pages. The maximum number of main resources per page is determined by the API (and can be configured in application.conf via the setting app/v2/resources-sequence/results-per-page ). If some resources have been filtered out because the user does not have permission to see them, a page could contain fewer results, or no results. If it is possible that more results are available in subsequent pages, the Gravsearch response will contain the predicate knora-api:mayHaveMoreResults with the boolean value true , otherwise it will not contain this predicate. Therefore, to retrieve all available results, the client must request each page one at a time, until the response does not contain knora-api:mayHaveMoreResults .","title":"Paging"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#inference","text":"Gravsearch queries are understood to imply a subset of RDFS reasoning . This is done by the API by expanding the incoming query. Specifically, if a statement pattern specifies a property, the pattern will also match subproperties of that property, and if a statement specifies that a subject has a particular rdf:type , the statement will also match subjects belonging to subclasses of that type. If you know that reasoning will not return any additional results for your query, you can disable it by adding this line to the WHERE clause, which may improve query performance: knora-api : GravsearchOptions knora-api : useInference false .","title":"Inference"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#gravsearch-syntax","text":"Every Gravsearch query is a valid SPARQL 1.1 CONSTRUCT query. However, Gravsearch only supports a subset of the elements that can be used in a SPARQL Construct query, and a Gravsearch CONSTRUCT Clause has to indicate which variable is to be used for the main resource in each search result.","title":"Gravsearch Syntax"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#supported-sparql-syntax","text":"The current version of Gravsearch accepts CONSTRUCT queries whose WHERE clauses use the following patterns, with the specified restrictions: OPTIONAL : cannot be nested in a UNION . UNION : cannot be nested in a UNION . FILTER : may contain a complex expression using the Boolean operators AND and OR, as well as comparison operators. The left argument of a comparison operator must be a query variable. A Knora ontology entity IRI used in a FILTER must be a property IRI. FILTER NOT EXISTS MINUS OFFSET : the OFFSET is needed for paging. It does not actually refer to the number of triples to be returned, but to the requested page of results. The default value is 0, which refers to the first page of results. ORDER BY : In SPARQL, the result of a CONSTRUCT query is an unordered set of triples. However, a Gravsearch query returns an ordered list of resources, which can be ordered by the values of specified properties. If the query is written in the complex schema, items below the level of DSP-API values may not be used in ORDER BY . BIND : The value assigned must be a DSP resource IRI.","title":"Supported SPARQL Syntax"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#resources-properties-and-values","text":"Resources can be represented either by an IRI or by a variable, except for the main resource, which must be represented by a variable. It is possible to do a Gravsearch query in which the IRI of the main resource is already known, e.g. to request specific information about that resource and perhaps about linked resources. In this case, the IRI of the main resource must be assigned to a variable using BIND . Note that BIND statements slow the query down, therefore we recommend that you do not use them unless you have to. Properties can be represented by an IRI or a query variable. If a property is represented by a query variable, it can be restricted to certain property IRIs using a FILTER . A Knora value (i.e. a value attached to a knora-api:Resource ) must be represented as a query variable.","title":"Resources, Properties, and Values"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#filtering-on-values","text":"","title":"Filtering on Values"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#filtering-on-values-in-the-simple-schema","text":"In the simple schema, a variable representing a DSP-API value can be used directly in a FILTER expression. For example: ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Here the type of ?title is xsd:string . The following value types can be compared with literals in FILTER expressions in the simple schema: Text values ( xsd:string ) Uri values ( xsd:anyURI ) Integer values ( xsd:integer ) Decimal values ( xsd:decimal ) Boolean values ( xsd:boolean ) Date values ( knora-api:Date ) List values ( knora-api:ListNode ) List values can only be searched for using the equal operator ( = ), performing an exact match on a list node's label. Labels can be given in different languages for a specific list node. If one of the given list node labels matches, it is considered a match. Note that in the simple schema, uniqueness is not guaranteed (as opposed to the complex schema). A DSP-API value may not be represented as the literal object of a predicate; for example, this is not allowed: ?book incunabula:title \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" .","title":"Filtering on Values in the Simple Schema"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#filtering-on-values-in-the-complex-schema","text":"In the complex schema, variables representing DSP-API values are not literals. You must add something to the query (generally a statement) to get a literal from a DSP-API value. For example: ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Here the type of ?title is knora-api:TextValue . Note that no FILTER is needed in this example. But if you want to use a different comparison operator, you need a FILTER : ?page incunabula:seqnum ?seqnum . ?seqnum knora-api:intValueAsInt ?seqnumInt . FILTER(?seqnumInt <= 10) To match a date value in the complex schema, you must use the knora-api:toSimpleDate function in a FILTER (see Date Comparisons ). The predicates of knora-api:DateValue ( knora-api:dateValueHasStartYear , etc.) are not available in Gravsearch.","title":"Filtering on Values in the Complex Schema"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#date-comparisons","text":"In the simple schema, you can compare a date value directly with a knora-api:Date in a FILTER : ?book incunabula:pubdate ?pubdate . FILTER(?pubdate < \"JULIAN:1497\"^^knora-api:Date) In the complex schema, you must use the function knora-api:toSimpleDate , passing it the variable representing the date value. The date literal used in the comparison must still be a knora-api:Date in the simple schema. This is the only case in which you can use both schemas in a single query: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true . ?book incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book . ?book incunabula:pubdate ?pubdate . FILTER(knora-api:toSimpleDate(?pubdate) < \"JULIAN:1497\"^^knora-api-simple:Date) } ORDER BY ?pubdate You can also use knora-api:toSimpleDate with to search for date tags in standoff text markup (see Matching Standoff Dates ). Note that the given date value for comparison must have the following format: ``` (GREGORIAN|JULIAN|ISLAMIC):\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?)? ``` E.g. an exact date like GREGORIAN:2015-12-03 or a period like GREGORIAN:2015-12-03:2015-12-04 . Dates may also have month or year precision, e.g. ISLAMIC:1407-02 (the whole month of december) or JULIAN:1330 (the whole year 1330). An optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Era can be given as GREGORIAN:1220 BC or in range as GREGORIAN:600 BC:480 BC .","title":"Date Comparisons"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#searching-for-matching-words","text":"The function knora-api:matchText searches for matching words anywhere in a text value, and is implemented using a full-text search index if available. The first argument must represent a text value (a knore-api:TextValue in the complex schema, or an xsd:string in the simple schema). The second argument is a string literal containing the words to be matched, separated by spaces. The function supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. This function can only be used as the top-level expression in a FILTER . For example, to search for titles that contain the words 'Zeitgl\u00f6cklein' and 'Lebens': ?book incunabule:title ?title . FILTER knora-api:matchText(?title, \"Zeitgl\u00f6cklein Lebens\")","title":"Searching for Matching Words"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#filtering-text-by-language","text":"To filter a text value by language in the simple schema, use the SPARQL lang function on the text value, e.g.: FILTER(lang(?text) = \"fr\") In the complex schema, the lang function is not supported. Use the text value's knora-api:textValueHasLanguage predicate instead: ?text knora-api:textValueHasLanguage \"fr\" .","title":"Filtering Text by Language"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#regular-expressions","text":"The SPARQL regex function is supported. In the simple schema, you can use it directly on the text value, e.g. ?book incunabula:title ?title . FILTER regex(?title, \"Zeit\", \"i\") In the complex schema, use it on the object of the text value's knora-api:valueAsString predicate: ?book incunabula:title ?title . ?title knora-api:valueAsString ?titleStr . FILTER regex(?titleStr, \"Zeit\", \"i\")","title":"Regular Expressions"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#searching-for-text-markup","text":"To refer to standoff markup in text values, you must write your query in the complex schema. A knora-api:TextValue can have the property knora-api:textValueHasStandoff , whose objects are the standoff markup tags in the text. You can match the tags you're interested in using rdf:type or other properties of each tag.","title":"Searching for Text Markup"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#matching-text-in-a-standoff-tag","text":"The function knora-api:matchTextInStandoff searches for standoff tags containing certain terms. The implementation is optimised using the full-text search index if available. The function takes three arguments: A variable representing a text value. A variable representing a standoff tag. A string literal containing space-separated search terms. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . FILTER knora-api:matchTextInStandoff(?text, ?standoffParagraphTag, \"Grund Richtigkeit\") } Here we are looking for letters containing the words \"Grund\" and \"Richtigkeit\" within a single paragraph.","title":"Matching Text in a Standoff Tag"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#matching-standoff-links","text":"If you are only interested in specifying that a resource has some text value containing a standoff link to another resource, the most efficient way is to use the property knora-api:hasStandoffLinkTo , whose subjects and objects are resources. This property is automatically maintained by the API. For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . } Here we are looking for letters containing a link to the historian Claude Jordan, who is identified by his Integrated Authority File identifier, (VIAF)271899510 . However, if you need to specify the context in which the link tag occurs, you must use the function knora-api:standoffLink . It takes three arguments: A variable or IRI representing the resource that is the source of the link. A variable representing the standoff link tag. A variable or IRI representing the resource that is the target of the link. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . } This has the same effect as the previous example, except that because we are matching the link tag itself, we can specify that its immediate parent is a StandoffItalicTag . If you actually want to get the target of the link (in this example, ?person ) in the search results, you need to add a statement like ?letter knora-api:hasStandoffLinkTo ?person . to the WHERE clause and to the CONSTRUCT clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . ?letter knora-api:hasStandoffLinkTo ?person . }","title":"Matching Standoff Links"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#matching-standoff-dates","text":"You can use the knora-api:toSimpleDate function (see @ref Date Comparisons ) to match dates in standoff date tags, i.e. instances of knora-api:StandoffDateTag or of one of its subclasses. For example, here we are looking for a text containing an anything:StandoffEventTag (which is a project-specific subclass of knora-api:StandoffDateTag ) representing an event that occurred sometime during the month of December 2016: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffEventTag . ?standoffEventTag a anything:StandoffEventTag . FILTER(knora-api:toSimpleDate(?standoffEventTag) = \"GREGORIAN:2016-12 CE\"^^knora-api-simple:Date) }","title":"Matching Standoff Dates"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#matching-ancestor-tags","text":"Suppose we want to search for a standoff date in a paragraph, but we know that the paragraph tag might not be the immediate parent of the date tag. For example, the date tag might be in an italics tag, which is in a paragraph tag. In that case, we can use the inferred property knora-api:standoffTagHasStartAncestor . We can modify the previous example to do this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffDateTag . ?standoffDateTag a knora-api:StandoffDateTag . FILTER(knora-api:toSimpleDate(?standoffDateTag) = \"GREGORIAN:2016-12-24 CE\"^^knora-api-simple:Date) ?standoffDateTag knora-api:standoffTagHasStartAncestor ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . }","title":"Matching Ancestor Tags"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#filtering-on-rdfslabel","text":"The rdfs:label of a resource is not a DSP-API value, but you can still search for it. This can be done in the same ways in the simple or complex schema: Using a string literal object: ?book rdfs:label \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Using a variable and a FILTER: ?book rdfs:label ?label . FILTER(?label = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Using the regex function: ?book rdfs:label ?bookLabel . FILTER regex(?bookLabel, \"Zeit\", \"i\") To match words in an rdfs:label using the full-text search index, use the knora-api:matchLabel function, which works like knora-api:matchText , except that the first argument is a variable representing a resource: FILTER knora-api:matchLabel(?book, \"Zeitgl\u00f6cklein\")","title":"Filtering on rdfs:label"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#filtering-on-resource-iris","text":"A FILTER can compare a variable with another variable or IRI representing a resource. For example, to find a letter whose author and recipient are different persons: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != ?person2) . } OFFSET 0 To find a letter whose author is not a person with a specified IRI: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != <http://rdfh.ch/0801/F4n1xKa3TCiR4llJeElAGA>) . } OFFSET 0","title":"Filtering on Resource IRIs"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#construct-clause","text":"In the CONSTRUCT clause of a Gravsearch query, the variable representing the main resource must be indicated with knora-api:isMainResource true . Exactly one variable representing a resource must be marked in this way. Any other statements in the CONSTRUCT clause must also be present in the WHERE clause. If a variable representing a resource or value is used in the WHERE clause but not in the CONSTRUCT clause, the matching resources or values will not be included in the results. If the query is written in the complex schema, all variables in the CONSTRUCT clause must refer to DSP-API resources, DSP-API values, or properties. Data below the level of values may not be mentioned in the CONSTRUCT clause. Predicates from the rdf , rdfs , and owl ontologies may not be used in the CONSTRUCT clause. The rdfs:label of each matching resource is always returned, so there is no need to mention it in the query.","title":"CONSTRUCT Clause"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#gravsearch-by-example","text":"In this section, we provide some sample queries of different complexity to illustrate the usage of Gravsearch.","title":"Gravsearch by Example"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#getting-all-the-components-of-a-compound-resource","text":"In order to get all the components of a compound resource, the following Gravsearch query can be sent to the API. In this case, the compound resource is an incunabula:book identified by the IRI http://rdfh.ch/0803/c5058f3a and the components are of type incunabula:page (test data for the Incunabula project). Since inference is assumed, we can use knora-api:StillImageRepresentation ( incunabula:page is one of its subclasses). This makes the query more generic and allows for reuse (for instance, a client would like to query different types of compound resources defined in different ontologies). ORDER BY is used to sort the components by their sequence number. OFFSET is set to 0 to get the first page of results. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?component knora-api:isMainResource true . # marking of the component searched for as the main resource, required ?component knora-api:seqnum ?seqnum . # return the sequence number in the response ?component knora-api:hasStillImageFileValue ?file . # return the StillImageFile in the response } WHERE { ?component a knora-api:StillImageRepresentation . # restriction of the type of component ?component knora-api:isPartOf <http://rdfh.ch/0803/c5058f3a> . # component relates to a compound resource via this property ?component knora-api:seqnum ?seqnum . # component must have a sequence number ?component knora-api:hasStillImageFileValue ?file . # component must have a StillImageFile } ORDER BY ASC(?seqnum) # order by sequence number, ascending OFFSET 0 # get first page of results The incunabula:book with the IRI http://rdfh.ch/0803/c5058f3a has 402 pages. (This result can be obtained by doing a count query; see Submitting Gravsearch Queries .) However, with OFFSET 0 , only the first page of results is returned. The same query can be sent again with OFFSET 1 to get the next page of results, and so forth. When a page of results is not full (see settings in app/v2 in application.conf ) or is empty, no more results are available. By design, it is not possible for the client to get more than one page of results at a time; this is intended to prevent performance problems that would be caused by huge responses. A client that wants to download all the results of a query must request each page sequentially. Let's assume the client is not interested in all of the book's pages, but just in first ten of them. In that case, the sequence number can be restricted using a FILTER that is added to the query's WHERE clause: FILTER (?seqnum <= 10) The first page starts with sequence number 1, so with this FILTER only the first ten pages are returned. This query would be exactly the same in the complex schema, except for the expansion of the knora-api prefix: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#>","title":"Getting All the Components of a Compound Resource"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#traversing-multiple-links","text":"Here we are looking for regions of pages that are part of books that have a particular title. In the simple schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") } In the complex schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . } If we remove the line ?book incunabula:title ?title . from the CONSTRUCT clause, so that the CONSTRUCT clause no longer mentions ?title , the response will contain the same matching resources, but the titles of those resources will not be included in the response.","title":"Traversing Multiple Links"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#requesting-a-graph-starting-with-a-known-resource","text":"Here the IRI of the main resource is already known, and we want specific information about it, as well as about related resources. In this case, the IRI of the main resource must be assigned to a variable using BIND : PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?letter knora-api:isMainResource true ; beol:creationDate ?date ; ?linkingProp1 ?person1 . ?person1 beol:hasFamilyName ?familyName . } WHERE { BIND(<http://rdfh.ch/0801/_B3lQa6tSymIq7_7SowBsA> AS ?letter) ?letter a beol:letter ; beol:creationDate ?date ; ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient) ?person1 beol:hasFamilyName ?familyName . } ORDER BY ?date This query would be the same in the complex schema, except for the prefix expansions: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#>","title":"Requesting a Graph Starting with a Known Resource"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#searching-for-a-list-value-referring-to-a-particular-list-node","text":"Since list nodes are represented by their Iri in the complex schema, uniqueness is guranteed (as opposed to the simple schema). Also all the subnodes of the given list node are considered a match. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasListItem ?listItem . } WHERE { ?thing anything:hasListItem ?listItem . ?listItem knora-api:listValueAsListNode <http://rdfh.ch/lists/0001/treeList02> . }","title":"Searching for a List Value Referring to a Particular List Node"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#type-inference","text":"Gravsearch needs to be able to determine the types of the entities that query variables and IRIs refer to in the WHERE clause. In most cases, it can infer these from context and from the ontologies used. In particular, it needs to know: The type of the subject and object of each statement. The type that is expected as the object of each predicate.","title":"Type Inference"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#type-annotations","text":"When one or more types cannot be inferred, Gravsearch will return an error message indicating the entities for which it could not determine types. The missing information must then be given by adding type annotations to the query. This can always done by adding statements with the predicate rdf:type . The subject must be a resource or value, and the object must either be knora-api:Resource (if the subject is a resource) or the subject's specific type (if it is a value). For example, consider this query that uses a non-DSP property: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book dcterms:title ?title . } This produces the error message: The types of one or more entities could not be determined: ?book, <http://purl.org/dc/terms/title>, ?title To solve this problem, it is enough to specify the types of ?book and ?title ; the type of the expected object of dcterms:title can then be inferred from the type of ?title . PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . ?title rdf:type xsd:string . } It would also be possible to annotate the property itself, using the predicate knora-api:objectType ; then the type of ?title would be inferred: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . dcterms:title knora-api:objectType xsd:string . } Note that it only makes sense to use dcterms:title in the simple schema, because its object is supposed to be a literal. Here is another example, using a non-DSP class: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } This produces the error message: Types could not be determined for one or more entities: ?person The solution is to specify that ?person is a knora-api:Resource : PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person a knora-api:Resource . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") }","title":"Type Annotations"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#inconsistent-types","text":"Gravsearch will also reject a query if an entity is used with inconsistent types. For example: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\") . } This returns the error message: One or more entities have inconsistent types: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#pubdate> knora-api:objectType <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; knora-api:objectType <http://www.w3.org/2001/XMLSchema#string> . ?pubdate rdf:type <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; rdf:type <http://www.w3.org/2001/XMLSchema#string> . This is because the incunabula ontology says that the object of incunabula:pubdate must be a knora-api:Date , but the FILTER expression compares ?pubdate with an xsd:string . The solution is to specify the type of the literal in the FILTER : PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\"^^knora-api:Date) . }","title":"Inconsistent Types"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#scoping-issues","text":"SPARQL is evaluated from the bottom up . A UNION block therefore opens a new scope, in which variables bound at higher levels are not necessarily in scope. This can cause unexpected results if queries are not carefully designed. Gravsearch tries to prevent this by rejecting queries in the following cases.","title":"Scoping Issues"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#filter-in-union","text":"A FILTER in a UNION block can only use variables that are bound in the same block, otherwise the query will be rejected. This query is invalid because ?text is not bound in the UNION block containing the FILTER where the variable is used: PREFIX knora-api : <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls : <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api : isMainResource true . ?lemma mls : hasLemmaText ?text . } WHERE { ?lemma a mls : Lemma . ?lemma mls : hasLemmaText ?text . { ?lemma mls : hasPseudonym ?pseudo . FILTER regex ( ?pseudo , \"Abel\" , \"i\" ) . } UNION { FILTER regex ( ?text , \"Abel\" , \"i\" ) . } } ORDER BY ASC ( ?text ) OFFSET 0 It can be corrected like this: PREFIX knora-api : <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls : <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api : isMainResource true . ?lemma mls : hasLemmaText ?text . } WHERE { ?lemma a mls : Lemma . ?lemma mls : hasLemmaText ?text . { ?lemma mls : hasPseudonym ?pseudo . FILTER regex ( ?pseudo , \"Abel\" , \"i\" ) . } UNION { ?lemma mls : hasLemmaText ?text . FILTER regex ( ?text , \"Abel\" , \"i\" ) . } } ORDER BY ASC ( ?text ) OFFSET 0","title":"FILTER in UNION"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#order-by","text":"A variable used in ORDER BY must be bound at the top level of the WHERE clause. This query is invalid, because ?int is not bound at the top level of the WHERE clause: PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything : <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api : isMainResource true . ?thing anything : hasInteger ?int . ?thing anything : hasRichtext ?richtext . ?thing anything : hasText ?text . } WHERE { ?thing a knora-api : Resource . ?thing a anything : Thing . { ?thing anything : hasRichtext ?richtext . FILTER knora-api : matchText ( ?richtext , \"test\" ) ?thing anything : hasInteger ?int . } UNION { ?thing anything : hasText ?text . FILTER knora-api : matchText ( ?text , \"test\" ) ?thing anything : hasInteger ?int . } } ORDER BY ( ?int ) It can be corrected like this: PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything : <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api : isMainResource true . ?thing anything : hasInteger ?int . ?thing anything : hasRichtext ?richtext . ?thing anything : hasText ?text . } WHERE { ?thing a knora-api : Resource . ?thing a anything : Thing . ?thing anything : hasInteger ?int . { ?thing anything : hasRichtext ?richtext . FILTER knora-api : matchText ( ?richtext , \"test\" ) } UNION { ?thing anything : hasText ?text . FILTER knora-api : matchText ( ?text , \"test\" ) } } ORDER BY ( ?int )","title":"ORDER BY"},{"location":"DSP-API/03-endpoints/api-v2/query-language/#query-optimization-by-dependency","text":"The query performance of triplestores, such as Fuseki, is highly dependent on the order of query patterns. To improve performance, Gravsearch automatically reorders the statement patterns in the WHERE clause according to their dependencies on each other, to minimise the number of possible matches for each pattern. Consider the following Gravsearch query: PREFIX beol : <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api : isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol : creationDate ?date . } WHERE { ?letter beol : creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER ( ?linkingProp1 = beol : hasAuthor || ?linkingProp1 = beol : hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER ( ?linkingProp2 = beol : hasAuthor || ?linkingProp2 = beol : hasRecipient ) ?person1 beol : hasIAFIdentifier ?gnd1 . ?gnd1 knora-api : valueAsString \"(DE-588)118531379\" . ?person2 beol : hasIAFIdentifier ?gnd2 . ?gnd2 knora-api : valueAsString \"(DE-588)118696149\" . } ORDER BY ?date Gravsearch optimises the performance of this query by moving these statements to the top of the WHERE clause: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the WHERE clause then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date .","title":"Query Optimization by Dependency"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/","text":"Reading and Searching Resources To retrieve an existing resource, the HTTP method GET has to be used. Reading resources may require authentication, since some resources may have restricted viewing permissions. Responses Describing Resources Resources can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). Operations for reading and searching resources can return responses in either the simple or the complex ontology schema. The complex schema is used by default. To receive a response in the simple schema, use the HTTP request header or URL parameter described in API Schema . Each DSP-API v2 response describing one or more resources returns a single RDF graph. For example, a request for a single resource returns that resource and all its values. In a full-text search, the resource is returned with the values that matched the search criteria. A response to an extended search may represent a whole graph of interconnected resources. In JSON-LD, if only one resource is returned, it is the top-level object; if more than one resource is returned, they are represented as an array of objects of the @graph member of the top-level object (see Named Graphs in the JSON-LD specification). In the complex schema, dependent resources, i.e. resources that are referred to by other resources on the top level, are nested in link value objects. If resources on the top level are referred to by other resources and these links are part of the response, virtual incoming links are generated; see Gravsearch: Virtual Graph Search ). See the interfaces Resource and ResourcesSequence in module ResourcesResponse (exists for both API schemas: ApiV2Simple and ApiV2WithValueObjects ). Text Markup Options Text markup can be returned in one of two ways: As XML embedded in the response, using an XML to Standoff Mapping . As standoff/RDF , which is DSP-API's internal markup representation. Embedded XML is the default. Requesting Text Markup as XML When requesting a text value with standoff mark up, there are three possibilities: The text value uses standard mapping. The text value uses a custom mapping which does not specify an XSL transformation. The text value uses a custom mapping which specifies an XSL transformation. In the first case, the mapping will be defined as: \"kb:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } the text value will only be available as kb:textValueAsXml , which will be of the following structure: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text documentType= \"html\" > ... </text> where the content of <text> is a limited set of HTML tags that can be handled by CKEditor in DSP-APP. This allows for both displaying and editing the text value. In the second and third case, kb:textValueHasMapping will point to the custom mapping that may or may not specify an XSL transformation. If no transformation is specified (second case), the text value will be returned only as kb:textValueAsXml . This property will be a string containing the contents of the initially uploaded XML. Note: The returned XML document is equivalent to the uploaded document but it is not necessarily identical - the order of the attributes in one element may vary from the original. In the third case, when a transformation is specified, both kb:textValueAsXml and kb:textValueAsHtml will be returned. kb:textValueAsHtml is the result of the XSL transformation applied to kb:textValueAsXml . The HTML representation is intended to display the text value in a human readable and properly styled way, while the XML representation can be used to update the text value. Requesting Text Markup as Standoff Implementation of support for standoff/RDF in API v2 is in its early stages; its use is currently discouraged. The basic procedure works like this: First, request a resource in the complex schema , using any relevant API v2 route, submitting the string standoff as the value of either: the HTTP header X-Knora-Accept-Markup the URL parameter markup If a text value in the resource contains markup, the text value will look something like this: { \"@id\" : \"http://rdfh.ch/0001/LK-wKXDNQJaRHOf0F0aJ2g/values/1Er1OpVwQR2u6peTwyNpJw\" , \"@type\" : \"knora-api:TextValue\" , \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V knora-admin:UnknownUser\" , \"knora-api:textValueHasMarkup\" : true , \"knora-api:textValueHasMaxStandoffStartIndex\" : 6737 , \"knora-api:userHasPermission\" : \"CR\" , \"knora-api:valueAsString\" : \"\\nHamlet\\nACT I\\nSCENE I. Elsinore. A platform before the castle...\" , \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-05-08T17:08:32.158401Z\" } } The object knora-api:valueAsString contains the text without markup. The predicate knora-api:textValueHasMarkup indicates that the text value has markup, and the value of the predicate knora-api:textValueHasMaxStandoffStartIndex gives the start index of the last standoff tag; this gives the client some idea of how much markup there is. You can then request the text value's standoff/RDF, which is returned in pages of a limited size. To get each page: HTTP GET to http://host/v2/standoff/RESOURCE_IRI/TEXT_VALUE_IRI/OFFSET Both RESOURCE_IRI and TEXT_VALUE_IRI must be URL-encoded. The offset is an integer whose initial value is 0. The response will look like this: { \"@graph\" : [ { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffRootTag\" , \"knora-api:standoffTagHasEnd\" : 184716 , \"knora-api:standoffTagHasStart\" : 0 , \"knora-api:standoffTagHasStartIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"sbBzeAaNTzaUXl90UtlYzw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader1Tag\" , \"knora-api:standoffTagHasEnd\" : 7 , \"knora-api:standoffTagHasStart\" : 1 , \"knora-api:standoffTagHasStartIndex\" : 1 , \"knora-api:standoffTagHasStartParentIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"HhXjcdSTS_G6eSQ0apdjUw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\" , \"knora-api:standoffTagHasEnd\" : 14 , \"knora-api:standoffTagHasStart\" : 9 , \"knora-api:standoffTagHasStartIndex\" : 2 , \"knora-api:standoffTagHasStartParentIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"Ymr2aDUqTx6nMwGZGiqduA\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\" , \"knora-api:standoffTagHasEnd\" : 64 , \"knora-api:standoffTagHasStart\" : 16 , \"knora-api:standoffTagHasStartIndex\" : 3 , \"knora-api:standoffTagHasStartParentIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"_Zk0B1edRK6mgdtokmosXg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffBlockquoteTag\" , \"knora-api:standoffTagHasEnd\" : 112 , \"knora-api:standoffTagHasStart\" : 66 , \"knora-api:standoffTagHasStartIndex\" : 4 , \"knora-api:standoffTagHasStartParentIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"1DLdI0LJTCy07w6ZsOM_Sg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffItalicTag\" , \"knora-api:standoffTagHasEnd\" : 111 , \"knora-api:standoffTagHasStart\" : 67 , \"knora-api:standoffTagHasStartIndex\" : 5 , \"knora-api:standoffTagHasStartParentIndex\" : 4 , \"knora-api:standoffTagHasUUID\" : \"XJ6GVO1VQSqrTyLHGnHqcA\" } ], \"knora-api:nextStandoffStartIndex\" : 100 , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } See Text with Standoff Markup for details of the predicates in each standoff tag. If there are more pages of standoff to be requested, the response will contain knora-api:nextStandoffStartIndex , whose object should be submitted as the next OFFSET to the same route. This continues until you receive a response without knora-api:nextStandoffStartIndex . Get the Representation of a Resource by IRI Get a Full Representation of a Resource by IRI A full representation of resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL-encoded. To get the resource with the IRI http://rdfh.ch/c5058f3a (a book from the sample Incunabula project, which is included in the Knora API server's test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL-encoded IRI: HTTP GET to http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a If necessary, several resources can be queried at the same time, their IRIs separated by slashes. Please note that the amount of resources that can be queried in one requested is limited. See the settings for app/v2 in application.conf . More formally, the URL looks like this: HTTP GET to http://host/v2/resources/resourceIRI(/anotherResourceIri)* Get a Full Representation of a Version of a Resource by IRI To get a specific past version of a resource, use the route described in Get a Full Representation of a Resource by IRI , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The resource will be returned with the values that it had at the specified time. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current metadata will be returned. Each value will be returned with the permissions that are attached to the current version of the value (see Permissions ). The returned resource will include the predicate knora-api:versionDate , containing the timestamp that was submitted, and its knora-api:versionArkUrl (see Resource Permalinks ) will contain the same timestamp. Get a Value in a Resource To get a specific value of a resource, use this route: HTTP GET to http://host/v2/values/resourceIRI/valueUUID The resource IRI must be URL-encoded. The path element valueUUID is the string object of the value's knora-api:valueHasUUID . The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Get a Version of a Value in a Resource To get a particular version of a specific value of a resource, use the route described in Get a Value in a Resource , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current resource metadata will be returned. The value will be returned with the permissions that are attached to its current version (see Permissions ). Get the Version History of a Resource To get a list of the changes that have been made to a resource since its creation, use this route: HTTP GET to http://host/v2/resources/history/resourceIRI[?startDate=START_DATE&endDate=END_DATE] The resource IRI must be URL-encoded. The start and end dates are optional, and are URL-encoded timestamps in xsd:dateTimeStamp format. The start date is inclusive, and the end date is exclusive. If the start date is not provided, the resource's history since its creation is returned. If the end date is not provided, the resource's history up to the present is returned. The response is a list of changes made to the resource, in reverse chronological order. Each entry has the properties knora-api:author (the IRI of the user who made the change) and knora-api:versionDate (the date when the change was made). For example: { \"@graph\" : [ { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-11T09:05:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-10T10:30:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-10T10:05:10Z\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The entries include all the dates when the resource's values were created or modified (within the requested date range), as well as the date when the resource was created (if the requested date range allows it). Each date is included only once. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), changes to a resource's metadata are not included in its version history. To request the resource as it was at each of these dates, see Get a Full Representation of a Version of a Resource by IRI . For consistency in citation, we recommend using these dates when requesting resource versions. Get the preview of a resource by IRI In some cases, the client may only want to request the preview of a resource, which just provides its metadata (e.g. its IRI, rdfs:label , and type), without its values. This works exactly like making a conventional resource request, using the path segment resourcespreview : HTTP GET to http://host/v2/resourcespreview/resourceIRI(/anotherResourceIri)* Get a Graph of Resources Knora can return a graph of connections between resources, e.g. for generating a network diagram. HTTP GET to http://host/v2/graph/resourceIRI[depth=Integer] [direction=outbound|inbound|both][excludeProperty=propertyIri] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . depth must be at least 1. The maximum depth is an Knora configuration setting. The default is 4. direction specifies the direction of the links to be queried, i.e. links to and/or from the given resource. The default is outbound . excludeProperty is an optional link property to be excluded from the results. To accommodate large graphs, the graph response format is very concise, and is therefore simpler than the usual resources response format. Each resource represented only by its IRI, class, and label. Direct links are shown instead of link values. For example: { \"@graph\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\" , \"@type\" : \"anything:Thing\" , \"rdfs:label\" : \"Sierra\" }, { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\" , \"@type\" : \"anything:Thing\" , \"rdfs:label\" : \"Victor\" }, { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\" , \"@type\" : \"anything:Thing\" , \"rdfs:label\" : \"Foxtrot\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\" , \"@type\" : \"anything:Thing\" , \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\" }, \"rdfs:label\" : \"Tango\" }, { \"@id\" : \"http://rdfh.ch/0001/start\" , \"@type\" : \"anything:Thing\" , \"anything:hasOtherThing\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } ], \"rdfs:label\" : \"Romeo\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" , \"@type\" : \"anything:Thing\" , \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\" }, \"rdfs:label\" : \"Echo\" } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Search for Resources Search for a Resource by its rdfs:label Knora offers the possibility to search for resources by their rdfs:label . The use case for this search is to find a specific resource as you type. E.g., the user wants to get a list of resources whose rdfs:label contain some search terms separated by a whitespace character: Zeit Zeitg ... Zeitgl\u00f6cklein d ... Zeitgl\u00f6cklein des Lebens With each character added to the last term, the selection gets more specific. The first term should at least contain three characters. To make this kind of \"search as you type\" possible, a wildcard character is automatically added to the last search term. Characters provided by the user that have a special meaning in the Lucene Query Parser syntax are replaced by a whitespace character for this search. If a user types \"Zeit-Gl\u00f6cklein\" it is interpreted as \"Zeit Gl\u00f6cklein\". Whitespace is normalized afterwards. The special characters that are replaced are: + , - , & , | , ! , ( , ) , [ , ] , { , } , ^ , \" , ~ , * , ? , : , \\ , / If the rdfs:label of a resource contains a special character, it is found nonetheless. HTTP GET to http://host/v2/searchbylabel/searchValue[limitToResourceClass=resourceClassIRI] [limitToProject=projectIRI][offset=Integer] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . The default value for the parameter offset is 0, which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . For performance reasons, standoff markup is not queried for this route. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/searchbylabel/count/searchValue[limitToResourceClass=resourceClassIRI][limitToProject=projectIRI][offset=Integer] The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. Full-text Search Knora offers a full-text search that searches through all textual representations of values and rdfs:label of resources. Full-text search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. Please note that the search terms have to be URL-encoded. HTTP GET to http://host/v2/search/searchValue[limitToResourceClass=resourceClassIRI] [limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . A search value must have a minimal length of three characters (default value) as defined in app/v2 in application.conf . A search term may contain wildcards. A ? represents a single character. It has to be URL-encoded as %3F since it has a special meaning in the URL syntax. For example, the term Uniform can be search for like this: HTTP GET to http://host/v2/search/Unif%3Frm A * represents zero, one or multiple characters. For example, the term Uniform can be searched for like this: HTTP GET to http://host/v2/search/Uni*m The default value for the parameter offset is 0 which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . If the parameter limitToStandoffClass is provided, Knora will look for search terms that are marked up with the indicated standoff class. If the parameter returnFiles=true is provided, Knora will return any file value attached to each matching resource. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/search/count/searchValue[limitToResourceClass=resourceClassIRI][limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. Gravsearch For more complex queries than a full-text search, Knora offers a query language called Gravsearch: Virtual Graph Search ). Support of TEI/XML To convert standoff markup to TEI/XML, see TEI/XML . IIIF Manifests This is an experimental feature and may change. To generate a IIIF manifest for a resource, containing the still image representations that have knora-api:isPartOf (or a subproperty) pointing to that resource: HTTP GET to http://host/v2/resources//iiifmanifest/RESOURCE_IRI Reading Resources by Class from a Project To facilitate the development of tabular user interfaces for data entry, it is possible to get a paged list of all the resources belonging to a particular class in a given project, sorted by the value of a property: HTTP GET to http://host/v2/resources?resourceClass=RESOURCE_CLASS_IRI&page=PAGE[&orderByProperty=PROPERTY_IRI] This is useful only if the project does not contain a large amount of data; otherwise, you should use Gravsearch to search using more specific criteria. The specified class and property are used without inference; they will not match subclasses or subproperties. The HTTP header X-Knora-Accept-Project must be submitted; its value is a Knora project IRI. In the request URL, the values of resourceClass and orderByProperty are URL-encoded IRIs in the complex schema . The orderByProperty parameter is optional; if it is not supplied, resources will be sorted alphabetically by resource IRI (an arbitrary but consistent order). The value of page is a 0-based integer page number. Paging works as it does in Gravsearch ). Get the Full History of a Resource and its Values as Events To get a list of the changes that have been made to a resource and its values since its creation as events ordered by date: HTTP GET to http://host/v2/resources/resourceHistoryEvents/<resourceIRI> The resource IRI must be URL-encoded. The response is a list of events describing changes made to the resource and its values, in chronological order. Each entry has the properties: knora-api:eventType (the type of the operation performed on a specific date. The operation can be either createdResource , updatedResourceMetadata , deletedResource , createdValue , updatedValueContent , updatedValuePermissions , or deletedValue .), knora-api:versionDate (the date when the change was made), knora-api:author (the IRI of the user who made the change), knora-api:eventBody (the information necessary to make the same request). For example, the following response contains the list of events describing the version history of the resource http://rdfh.ch/0001/thing-with-history ordered by date: { \"@graph\" : [ { \"knora-api:eventType\" : \"createdResource\" , \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\" : { \"rdfs:label\" : \"A thing with version history\" , \"knora-api:resourceIri\" : \"http://rdfh.ch/0001/thing-with-history\" , \"knora-api:resourceClassIri\" : \"http://www.knora.org/ontology/0001/anything#Thing\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\" , \"knora-api:creationDate\" : { \"@value\" : \"2019-02-08T15:05:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" } }, \"knora-api:versionDate\" : { \"@value\" : \"2019-02-08T15:05:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\" : \"createdValue\" , \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\" : { \"knora-api:resourceIri\" : \"http://rdfh.ch/0001/thing-with-history\" , \"knora-api:resourceClassIri\" : \"http://www.knora.org/ontology/0001/anything#Thing\" , \"knora-api:valueCreationDate\" : { \"@value\" : \"2019-02-10T10:30:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-api:valueHasUUID\" : \"IZGOjVqxTfSNO4ieKyp0SA\" , \"knora-api:hasPermissions\" : \"V knora-admin:UnknownUser|M knora-admin:ProjectMember\" , \"@type\" : \"knora-base:LinkValue\" , \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\" : { \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/2qMtTWvVRXWMBcRNlduvCQ\" } }, \"rdf:Property\" : \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\" , \"@id\" : \"http://rdfh.ch/0001/thing-with-history/values/3a\" }, \"knora-api:versionDate\" : { \"@value\" : \"2019-02-10T10:30:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\" : \"updatedValueContent\" , \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:eventBody\" : { \"knora-api:resourceIri\" : \"http://rdfh.ch/0001/thing-with-history\" , \"knora-api:resourceClassIri\" : \"http://www.knora.org/ontology/0001/anything#Thing\" \"http://www.knora.org/ontology/0001/anything#hasText\" : { \"knora-api:valueAsString\" : \"two\" }, \"knora-api:valueCreationDate\" : { \"@value\" : \"2019-02-11T10:05:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-base:previousValue\" : \"http://rdfh.ch/0001/thing-with-history/values/2a\" , \"knora-api:valueHasUUID\" : \"W5fm67e0QDWxRZumcXcs6g\" , \"@type\" : \"knora-base:TextValue\" , \"rdf:Property\" : \"http://www.knora.org/ontology/0001/anything#hasText\" , \"@id\" : \"http://rdfh.ch/0001/thing-with-history/values/2b\" }, \"knora-api:versionDate\" : { \"@value\" : \"2019-02-11T10:05:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\" : \"deletedValue\" , \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\" : { \"knora-api:resourceIri\" : \"http://rdfh.ch/0001/thing-with-history\" , \"knora-api:resourceClassIri\" : \"http://www.knora.org/ontology/0001/anything#Thing\" , \"knora-base:previousValue\" : \"http://rdfh.ch/0001/thing-with-history/values/3a\" , \"knora-api:deleteDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-13T09:00:10Z\" }, \"knora-api:isDeleted\" : true , \"@type\" : \"knora-base:LinkValue\" , \"rdf:Property\" : \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\" , \"@id\" : \"http://rdfh.ch/0001/thing-with-history/values/3b\" }, \"knora-api:versionDate\" : { \"@value\" : \"2019-02-13T09:00:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Since the history of changes made to the metadata of a resource is not part of resouce's version history, there are no events describing the changes on metadata elements like its rdfs:label or rdfs:comment . The only record depicting a change in a resource's metadata is the knora-api:lastModificationDate of the resource. Thus the event updatedResourceMetadata indicates a change in a resource's metadata, its knora-api:eventBody contains the payload needed to update the value of the resource's lastModificationDate , see modifying metadata of a resource . Get the Full History of all Resources of a Project as Events To get a list of the changes that have been made to the resources and their values of a project as events ordered by date: HTTP GET to http://host/v2/resources/projectHistoryEvents/<projectIRI> The project IRI must be URL-encoded. The response contains the resource history events of all resources that belong to the specified project.","title":"Reading and Searching Resources"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#reading-and-searching-resources","text":"To retrieve an existing resource, the HTTP method GET has to be used. Reading resources may require authentication, since some resources may have restricted viewing permissions.","title":"Reading and Searching Resources"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#responses-describing-resources","text":"Resources can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). Operations for reading and searching resources can return responses in either the simple or the complex ontology schema. The complex schema is used by default. To receive a response in the simple schema, use the HTTP request header or URL parameter described in API Schema . Each DSP-API v2 response describing one or more resources returns a single RDF graph. For example, a request for a single resource returns that resource and all its values. In a full-text search, the resource is returned with the values that matched the search criteria. A response to an extended search may represent a whole graph of interconnected resources. In JSON-LD, if only one resource is returned, it is the top-level object; if more than one resource is returned, they are represented as an array of objects of the @graph member of the top-level object (see Named Graphs in the JSON-LD specification). In the complex schema, dependent resources, i.e. resources that are referred to by other resources on the top level, are nested in link value objects. If resources on the top level are referred to by other resources and these links are part of the response, virtual incoming links are generated; see Gravsearch: Virtual Graph Search ). See the interfaces Resource and ResourcesSequence in module ResourcesResponse (exists for both API schemas: ApiV2Simple and ApiV2WithValueObjects ).","title":"Responses Describing Resources"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#text-markup-options","text":"Text markup can be returned in one of two ways: As XML embedded in the response, using an XML to Standoff Mapping . As standoff/RDF , which is DSP-API's internal markup representation. Embedded XML is the default.","title":"Text Markup Options"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#requesting-text-markup-as-xml","text":"When requesting a text value with standoff mark up, there are three possibilities: The text value uses standard mapping. The text value uses a custom mapping which does not specify an XSL transformation. The text value uses a custom mapping which specifies an XSL transformation. In the first case, the mapping will be defined as: \"kb:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } the text value will only be available as kb:textValueAsXml , which will be of the following structure: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text documentType= \"html\" > ... </text> where the content of <text> is a limited set of HTML tags that can be handled by CKEditor in DSP-APP. This allows for both displaying and editing the text value. In the second and third case, kb:textValueHasMapping will point to the custom mapping that may or may not specify an XSL transformation. If no transformation is specified (second case), the text value will be returned only as kb:textValueAsXml . This property will be a string containing the contents of the initially uploaded XML. Note: The returned XML document is equivalent to the uploaded document but it is not necessarily identical - the order of the attributes in one element may vary from the original. In the third case, when a transformation is specified, both kb:textValueAsXml and kb:textValueAsHtml will be returned. kb:textValueAsHtml is the result of the XSL transformation applied to kb:textValueAsXml . The HTML representation is intended to display the text value in a human readable and properly styled way, while the XML representation can be used to update the text value.","title":"Requesting Text Markup as XML"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#requesting-text-markup-as-standoff","text":"Implementation of support for standoff/RDF in API v2 is in its early stages; its use is currently discouraged. The basic procedure works like this: First, request a resource in the complex schema , using any relevant API v2 route, submitting the string standoff as the value of either: the HTTP header X-Knora-Accept-Markup the URL parameter markup If a text value in the resource contains markup, the text value will look something like this: { \"@id\" : \"http://rdfh.ch/0001/LK-wKXDNQJaRHOf0F0aJ2g/values/1Er1OpVwQR2u6peTwyNpJw\" , \"@type\" : \"knora-api:TextValue\" , \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V knora-admin:UnknownUser\" , \"knora-api:textValueHasMarkup\" : true , \"knora-api:textValueHasMaxStandoffStartIndex\" : 6737 , \"knora-api:userHasPermission\" : \"CR\" , \"knora-api:valueAsString\" : \"\\nHamlet\\nACT I\\nSCENE I. Elsinore. A platform before the castle...\" , \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-05-08T17:08:32.158401Z\" } } The object knora-api:valueAsString contains the text without markup. The predicate knora-api:textValueHasMarkup indicates that the text value has markup, and the value of the predicate knora-api:textValueHasMaxStandoffStartIndex gives the start index of the last standoff tag; this gives the client some idea of how much markup there is. You can then request the text value's standoff/RDF, which is returned in pages of a limited size. To get each page: HTTP GET to http://host/v2/standoff/RESOURCE_IRI/TEXT_VALUE_IRI/OFFSET Both RESOURCE_IRI and TEXT_VALUE_IRI must be URL-encoded. The offset is an integer whose initial value is 0. The response will look like this: { \"@graph\" : [ { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffRootTag\" , \"knora-api:standoffTagHasEnd\" : 184716 , \"knora-api:standoffTagHasStart\" : 0 , \"knora-api:standoffTagHasStartIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"sbBzeAaNTzaUXl90UtlYzw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader1Tag\" , \"knora-api:standoffTagHasEnd\" : 7 , \"knora-api:standoffTagHasStart\" : 1 , \"knora-api:standoffTagHasStartIndex\" : 1 , \"knora-api:standoffTagHasStartParentIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"HhXjcdSTS_G6eSQ0apdjUw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\" , \"knora-api:standoffTagHasEnd\" : 14 , \"knora-api:standoffTagHasStart\" : 9 , \"knora-api:standoffTagHasStartIndex\" : 2 , \"knora-api:standoffTagHasStartParentIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"Ymr2aDUqTx6nMwGZGiqduA\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\" , \"knora-api:standoffTagHasEnd\" : 64 , \"knora-api:standoffTagHasStart\" : 16 , \"knora-api:standoffTagHasStartIndex\" : 3 , \"knora-api:standoffTagHasStartParentIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"_Zk0B1edRK6mgdtokmosXg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffBlockquoteTag\" , \"knora-api:standoffTagHasEnd\" : 112 , \"knora-api:standoffTagHasStart\" : 66 , \"knora-api:standoffTagHasStartIndex\" : 4 , \"knora-api:standoffTagHasStartParentIndex\" : 0 , \"knora-api:standoffTagHasUUID\" : \"1DLdI0LJTCy07w6ZsOM_Sg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffItalicTag\" , \"knora-api:standoffTagHasEnd\" : 111 , \"knora-api:standoffTagHasStart\" : 67 , \"knora-api:standoffTagHasStartIndex\" : 5 , \"knora-api:standoffTagHasStartParentIndex\" : 4 , \"knora-api:standoffTagHasUUID\" : \"XJ6GVO1VQSqrTyLHGnHqcA\" } ], \"knora-api:nextStandoffStartIndex\" : 100 , \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } See Text with Standoff Markup for details of the predicates in each standoff tag. If there are more pages of standoff to be requested, the response will contain knora-api:nextStandoffStartIndex , whose object should be submitted as the next OFFSET to the same route. This continues until you receive a response without knora-api:nextStandoffStartIndex .","title":"Requesting Text Markup as Standoff"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-the-representation-of-a-resource-by-iri","text":"","title":"Get the Representation of a Resource by IRI"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-a-full-representation-of-a-resource-by-iri","text":"A full representation of resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL-encoded. To get the resource with the IRI http://rdfh.ch/c5058f3a (a book from the sample Incunabula project, which is included in the Knora API server's test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL-encoded IRI: HTTP GET to http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a If necessary, several resources can be queried at the same time, their IRIs separated by slashes. Please note that the amount of resources that can be queried in one requested is limited. See the settings for app/v2 in application.conf . More formally, the URL looks like this: HTTP GET to http://host/v2/resources/resourceIRI(/anotherResourceIri)*","title":"Get a Full Representation of a Resource by IRI"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-a-full-representation-of-a-version-of-a-resource-by-iri","text":"To get a specific past version of a resource, use the route described in Get a Full Representation of a Resource by IRI , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The resource will be returned with the values that it had at the specified time. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current metadata will be returned. Each value will be returned with the permissions that are attached to the current version of the value (see Permissions ). The returned resource will include the predicate knora-api:versionDate , containing the timestamp that was submitted, and its knora-api:versionArkUrl (see Resource Permalinks ) will contain the same timestamp.","title":"Get a Full Representation of a Version of a Resource by IRI"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-a-value-in-a-resource","text":"To get a specific value of a resource, use this route: HTTP GET to http://host/v2/values/resourceIRI/valueUUID The resource IRI must be URL-encoded. The path element valueUUID is the string object of the value's knora-api:valueHasUUID . The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values.","title":"Get a Value in a Resource"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-a-version-of-a-value-in-a-resource","text":"To get a particular version of a specific value of a resource, use the route described in Get a Value in a Resource , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current resource metadata will be returned. The value will be returned with the permissions that are attached to its current version (see Permissions ).","title":"Get a Version of a Value in a Resource"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-the-version-history-of-a-resource","text":"To get a list of the changes that have been made to a resource since its creation, use this route: HTTP GET to http://host/v2/resources/history/resourceIRI[?startDate=START_DATE&endDate=END_DATE] The resource IRI must be URL-encoded. The start and end dates are optional, and are URL-encoded timestamps in xsd:dateTimeStamp format. The start date is inclusive, and the end date is exclusive. If the start date is not provided, the resource's history since its creation is returned. If the end date is not provided, the resource's history up to the present is returned. The response is a list of changes made to the resource, in reverse chronological order. Each entry has the properties knora-api:author (the IRI of the user who made the change) and knora-api:versionDate (the date when the change was made). For example: { \"@graph\" : [ { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-11T09:05:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-10T10:30:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-10T10:05:10Z\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The entries include all the dates when the resource's values were created or modified (within the requested date range), as well as the date when the resource was created (if the requested date range allows it). Each date is included only once. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), changes to a resource's metadata are not included in its version history. To request the resource as it was at each of these dates, see Get a Full Representation of a Version of a Resource by IRI . For consistency in citation, we recommend using these dates when requesting resource versions.","title":"Get the Version History of a Resource"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-the-preview-of-a-resource-by-iri","text":"In some cases, the client may only want to request the preview of a resource, which just provides its metadata (e.g. its IRI, rdfs:label , and type), without its values. This works exactly like making a conventional resource request, using the path segment resourcespreview : HTTP GET to http://host/v2/resourcespreview/resourceIRI(/anotherResourceIri)*","title":"Get the preview of a resource by IRI"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-a-graph-of-resources","text":"Knora can return a graph of connections between resources, e.g. for generating a network diagram. HTTP GET to http://host/v2/graph/resourceIRI[depth=Integer] [direction=outbound|inbound|both][excludeProperty=propertyIri] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . depth must be at least 1. The maximum depth is an Knora configuration setting. The default is 4. direction specifies the direction of the links to be queried, i.e. links to and/or from the given resource. The default is outbound . excludeProperty is an optional link property to be excluded from the results. To accommodate large graphs, the graph response format is very concise, and is therefore simpler than the usual resources response format. Each resource represented only by its IRI, class, and label. Direct links are shown instead of link values. For example: { \"@graph\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\" , \"@type\" : \"anything:Thing\" , \"rdfs:label\" : \"Sierra\" }, { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\" , \"@type\" : \"anything:Thing\" , \"rdfs:label\" : \"Victor\" }, { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\" , \"@type\" : \"anything:Thing\" , \"rdfs:label\" : \"Foxtrot\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\" , \"@type\" : \"anything:Thing\" , \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\" }, \"rdfs:label\" : \"Tango\" }, { \"@id\" : \"http://rdfh.ch/0001/start\" , \"@type\" : \"anything:Thing\" , \"anything:hasOtherThing\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } ], \"rdfs:label\" : \"Romeo\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" , \"@type\" : \"anything:Thing\" , \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\" }, \"rdfs:label\" : \"Echo\" } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } }","title":"Get a Graph of Resources"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#search-for-resources","text":"","title":"Search for Resources"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#search-for-a-resource-by-its-rdfslabel","text":"Knora offers the possibility to search for resources by their rdfs:label . The use case for this search is to find a specific resource as you type. E.g., the user wants to get a list of resources whose rdfs:label contain some search terms separated by a whitespace character: Zeit Zeitg ... Zeitgl\u00f6cklein d ... Zeitgl\u00f6cklein des Lebens With each character added to the last term, the selection gets more specific. The first term should at least contain three characters. To make this kind of \"search as you type\" possible, a wildcard character is automatically added to the last search term. Characters provided by the user that have a special meaning in the Lucene Query Parser syntax are replaced by a whitespace character for this search. If a user types \"Zeit-Gl\u00f6cklein\" it is interpreted as \"Zeit Gl\u00f6cklein\". Whitespace is normalized afterwards. The special characters that are replaced are: + , - , & , | , ! , ( , ) , [ , ] , { , } , ^ , \" , ~ , * , ? , : , \\ , / If the rdfs:label of a resource contains a special character, it is found nonetheless. HTTP GET to http://host/v2/searchbylabel/searchValue[limitToResourceClass=resourceClassIRI] [limitToProject=projectIRI][offset=Integer] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . The default value for the parameter offset is 0, which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . For performance reasons, standoff markup is not queried for this route. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/searchbylabel/count/searchValue[limitToResourceClass=resourceClassIRI][limitToProject=projectIRI][offset=Integer] The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value.","title":"Search for a Resource by its rdfs:label"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#full-text-search","text":"Knora offers a full-text search that searches through all textual representations of values and rdfs:label of resources. Full-text search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. Please note that the search terms have to be URL-encoded. HTTP GET to http://host/v2/search/searchValue[limitToResourceClass=resourceClassIRI] [limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . A search value must have a minimal length of three characters (default value) as defined in app/v2 in application.conf . A search term may contain wildcards. A ? represents a single character. It has to be URL-encoded as %3F since it has a special meaning in the URL syntax. For example, the term Uniform can be search for like this: HTTP GET to http://host/v2/search/Unif%3Frm A * represents zero, one or multiple characters. For example, the term Uniform can be searched for like this: HTTP GET to http://host/v2/search/Uni*m The default value for the parameter offset is 0 which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . If the parameter limitToStandoffClass is provided, Knora will look for search terms that are marked up with the indicated standoff class. If the parameter returnFiles=true is provided, Knora will return any file value attached to each matching resource. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/search/count/searchValue[limitToResourceClass=resourceClassIRI][limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value.","title":"Full-text Search"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#gravsearch","text":"For more complex queries than a full-text search, Knora offers a query language called Gravsearch: Virtual Graph Search ).","title":"Gravsearch"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#support-of-teixml","text":"To convert standoff markup to TEI/XML, see TEI/XML .","title":"Support of TEI/XML"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#iiif-manifests","text":"This is an experimental feature and may change. To generate a IIIF manifest for a resource, containing the still image representations that have knora-api:isPartOf (or a subproperty) pointing to that resource: HTTP GET to http://host/v2/resources//iiifmanifest/RESOURCE_IRI","title":"IIIF Manifests"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#reading-resources-by-class-from-a-project","text":"To facilitate the development of tabular user interfaces for data entry, it is possible to get a paged list of all the resources belonging to a particular class in a given project, sorted by the value of a property: HTTP GET to http://host/v2/resources?resourceClass=RESOURCE_CLASS_IRI&page=PAGE[&orderByProperty=PROPERTY_IRI] This is useful only if the project does not contain a large amount of data; otherwise, you should use Gravsearch to search using more specific criteria. The specified class and property are used without inference; they will not match subclasses or subproperties. The HTTP header X-Knora-Accept-Project must be submitted; its value is a Knora project IRI. In the request URL, the values of resourceClass and orderByProperty are URL-encoded IRIs in the complex schema . The orderByProperty parameter is optional; if it is not supplied, resources will be sorted alphabetically by resource IRI (an arbitrary but consistent order). The value of page is a 0-based integer page number. Paging works as it does in Gravsearch ).","title":"Reading Resources by Class from a Project"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-the-full-history-of-a-resource-and-its-values-as-events","text":"To get a list of the changes that have been made to a resource and its values since its creation as events ordered by date: HTTP GET to http://host/v2/resources/resourceHistoryEvents/<resourceIRI> The resource IRI must be URL-encoded. The response is a list of events describing changes made to the resource and its values, in chronological order. Each entry has the properties: knora-api:eventType (the type of the operation performed on a specific date. The operation can be either createdResource , updatedResourceMetadata , deletedResource , createdValue , updatedValueContent , updatedValuePermissions , or deletedValue .), knora-api:versionDate (the date when the change was made), knora-api:author (the IRI of the user who made the change), knora-api:eventBody (the information necessary to make the same request). For example, the following response contains the list of events describing the version history of the resource http://rdfh.ch/0001/thing-with-history ordered by date: { \"@graph\" : [ { \"knora-api:eventType\" : \"createdResource\" , \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\" : { \"rdfs:label\" : \"A thing with version history\" , \"knora-api:resourceIri\" : \"http://rdfh.ch/0001/thing-with-history\" , \"knora-api:resourceClassIri\" : \"http://www.knora.org/ontology/0001/anything#Thing\" , \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\" , \"knora-api:creationDate\" : { \"@value\" : \"2019-02-08T15:05:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/0001\" } }, \"knora-api:versionDate\" : { \"@value\" : \"2019-02-08T15:05:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\" : \"createdValue\" , \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\" : { \"knora-api:resourceIri\" : \"http://rdfh.ch/0001/thing-with-history\" , \"knora-api:resourceClassIri\" : \"http://www.knora.org/ontology/0001/anything#Thing\" , \"knora-api:valueCreationDate\" : { \"@value\" : \"2019-02-10T10:30:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-api:valueHasUUID\" : \"IZGOjVqxTfSNO4ieKyp0SA\" , \"knora-api:hasPermissions\" : \"V knora-admin:UnknownUser|M knora-admin:ProjectMember\" , \"@type\" : \"knora-base:LinkValue\" , \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\" : { \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/2qMtTWvVRXWMBcRNlduvCQ\" } }, \"rdf:Property\" : \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\" , \"@id\" : \"http://rdfh.ch/0001/thing-with-history/values/3a\" }, \"knora-api:versionDate\" : { \"@value\" : \"2019-02-10T10:30:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\" : \"updatedValueContent\" , \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:eventBody\" : { \"knora-api:resourceIri\" : \"http://rdfh.ch/0001/thing-with-history\" , \"knora-api:resourceClassIri\" : \"http://www.knora.org/ontology/0001/anything#Thing\" \"http://www.knora.org/ontology/0001/anything#hasText\" : { \"knora-api:valueAsString\" : \"two\" }, \"knora-api:valueCreationDate\" : { \"@value\" : \"2019-02-11T10:05:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" }, \"knora-base:previousValue\" : \"http://rdfh.ch/0001/thing-with-history/values/2a\" , \"knora-api:valueHasUUID\" : \"W5fm67e0QDWxRZumcXcs6g\" , \"@type\" : \"knora-base:TextValue\" , \"rdf:Property\" : \"http://www.knora.org/ontology/0001/anything#hasText\" , \"@id\" : \"http://rdfh.ch/0001/thing-with-history/values/2b\" }, \"knora-api:versionDate\" : { \"@value\" : \"2019-02-11T10:05:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\" : \"deletedValue\" , \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\" : { \"knora-api:resourceIri\" : \"http://rdfh.ch/0001/thing-with-history\" , \"knora-api:resourceClassIri\" : \"http://www.knora.org/ontology/0001/anything#Thing\" , \"knora-base:previousValue\" : \"http://rdfh.ch/0001/thing-with-history/values/3a\" , \"knora-api:deleteDate\" : { \"@type\" : \"xsd:dateTimeStamp\" , \"@value\" : \"2019-02-13T09:00:10Z\" }, \"knora-api:isDeleted\" : true , \"@type\" : \"knora-base:LinkValue\" , \"rdf:Property\" : \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\" , \"@id\" : \"http://rdfh.ch/0001/thing-with-history/values/3b\" }, \"knora-api:versionDate\" : { \"@value\" : \"2019-02-13T09:00:10Z\" , \"@type\" : \"xsd:dateTimeStamp\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" , \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\" , \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" , \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Since the history of changes made to the metadata of a resource is not part of resouce's version history, there are no events describing the changes on metadata elements like its rdfs:label or rdfs:comment . The only record depicting a change in a resource's metadata is the knora-api:lastModificationDate of the resource. Thus the event updatedResourceMetadata indicates a change in a resource's metadata, its knora-api:eventBody contains the payload needed to update the value of the resource's lastModificationDate , see modifying metadata of a resource .","title":"Get the Full History of a Resource and its Values as Events"},{"location":"DSP-API/03-endpoints/api-v2/reading-and-searching-resources/#get-the-full-history-of-all-resources-of-a-project-as-events","text":"To get a list of the changes that have been made to the resources and their values of a project as events ordered by date: HTTP GET to http://host/v2/resources/projectHistoryEvents/<projectIRI> The project IRI must be URL-encoded. The response contains the resource history events of all resources that belong to the specified project.","title":"Get the Full History of all Resources of a Project as Events"},{"location":"DSP-API/03-endpoints/api-v2/reading-user-permissions/","text":"Reading the User's Permissions on Resources and Values In the complex API schema , each resource and value is returned with the predicate knora-api:userHasPermission . The object of this predicate is a string containing a permission code, which indicates the requesting user's maximum permission on the resource or value. These are the possible permission codes, in ascending order: RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) Each permission implies all lesser permissions. For more details, see Permissions .","title":"Reading the User's Permissions on Resources and Values"},{"location":"DSP-API/03-endpoints/api-v2/reading-user-permissions/#reading-the-users-permissions-on-resources-and-values","text":"In the complex API schema , each resource and value is returned with the predicate knora-api:userHasPermission . The object of this predicate is a string containing a permission code, which indicates the requesting user's maximum permission on the resource or value. These are the possible permission codes, in ascending order: RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) Each permission implies all lesser permissions. For more details, see Permissions .","title":"Reading the User's Permissions on Resources and Values"},{"location":"DSP-API/03-endpoints/api-v2/tei-xml/","text":"TEI/XML: Converting Standoff to TEI/XML General Knora offers a way to convert standoff markup to TEI/XML. The conversion is based on the assumption that a whole resource is to be turned into a TEI document. There is a basic distinction between the body and the header of a TEI document. The resource's property that contains the text with standoff markup is mapped to the TEI document's body. Other of the resource's property may be mapped to the TEI header. Standard Standoff to TEI Conversion Knora offers a built-in conversion form standard standoff entities (defined in the standoff ontology) tags to TEI. In order to obtain a resource as a TEI document, the following request has to be performed. Please note that the URL parameters have to be URL-encoded. HTTP GET to http://host/v2/tei/resourceIri?textProperty=textPropertyIri In addition to the resource's Iri, the Iri of the property containing the text with standoff has to be submitted. This will be converted to the TEI body. Please note that the resource can only have one instance of this property and the text must have standoff markup. The Knora test data contain the resource http://rdfh.ch/0001/thing_with_richtext_with_markup with the text property http://0.0.0.0:3333/ontology/0001/anything/v2#hasRichtext that can be converted to TEI as follows: HTTP GET to http://host/v2/tei/http%3A%2F%2Frdfh.ch%2F0001%2Fthing_with_richtext_with_markup?textProperty=http%3A%2F%2F0.0.0.0%3A3333%2Fontology%2F0001%2Fanything%2Fv2%23hasRichtext The answer to this request is a TEI XML document: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <TEI xmlns= \"http://www.tei-c.org/ns/1.0\" version= \"3.3.0\" > <teiHeader> <fileDesc> <titleStmt> <title> test thing with markup </title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of a resource identified by the Iri http://rdfh.ch/0001/thing_with_richtext_with_markup. </p> </publicationStmt> <sourceDesc> <p> Representation of the resource's text as TEI/XML </p> </sourceDesc> </fileDesc> </teiHeader> <text> <body> <p> This is a test that contains marked up elements. This is <hi rend= \"italic\" > interesting text </hi> in italics. This is <hi rend= \"italic\" > boring text </hi> in italics. </p> </body> </text> </TEI> The body of the TEI document contains the standoff markup as XML. The header contains contains some basic metadata about the resource such as the rdfs:label an its IRI. However, this might not be sufficient for more advanced use cases like digital edition projects. In that case, a custom conversion has to be performed (see below). Custom Conversion If a project defines its own standoff entities, a custom conversion can be provided (body of the TEI document). Also for the TEI header, a custom conversion can be provided. For the custom conversion, additional configuration is required. TEI body: additional mapping from standoff to XML (URL parameter mappingIri ) XSL transformation to turn the XML into a valid TEI body (referred to by the mapping). The mapping has to refer to a defaultXSLTransformation that transforms the XML that was created from standoff markup (see XML To Standoff Mapping in API v1 ). This step is necessary because the mapping assumes a one to one relation between standoff classes and properties and XML elements and attributes. For example, we may want to convert a standoff:StandoffItalicTag into TEI/XML. TEI expresses this as <hi rend=\"italic\">...</hi> . In the mapping, the standoff:StandoffItalicTag may be mapped to a a temporary XML element that is going to be converted to <hi rend=\"italic\">...</hi> in a further step by the XSLT. For sample data, see webapi/_test_data/test_route/texts/beol/BEOLTEIMapping.xml (mapping) and webapi/_test_data/test_route/texts/beol/standoffToTEI.xsl . The standoff entities are defined in beol-onto.ttl . TEI header: Gravsearch template to query the resources metadata, results are serialized to RDF/XML (URL parameter gravsearchTemplateIri ) XSL transformation to turn that RDF/XML into a valid TEI header (URL parameter teiHeaderXSLTIri ) The Gravsearch template is expected to be of type knora-base:TextRepresentation and to contain a placeholder $resourceIri that is to be replaced by the actual resource Iri. The Gravsearch template is expected to contain a query involving the text property (URL parameter textProperty ) and more properties that are going to be mapped to the TEI header. The Gravsearch template is a simple text file with the files extension .txt . A Gravsearch template may look like this (see test_data/test_route/texts/beol/gravsearch.txt ): PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:creationDate ?date . ?letter beol:hasText ?text . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?letter beol:hasRecipient ?person2 . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . } WHERE { BIND(<$resourceIri> as ?letter) ?letter a knora-api:Resource . ?letter a beol:letter . ?letter beol:creationDate ?date . beol:creationDate knora-api:objectType knora-api:Date . ?date a knora-api:Date . ?letter beol:hasText ?text . beol:hasText knora-api:objectType xsd:string . ?text a xsd:string . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?name1 a xsd:string . ?givenName1 a xsd:string . ?iaf1 a xsd:string . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . ?name2 a xsd:string . ?givenName2 a xsd:string . ?iaf2 a xsd:string . beol:hasGivenName knora-api:objectType xsd:string . beol:hasFamilyName knora-api:objectType xsd:string . beol:hasIAFIdentifier knora-api:objectType xsd:string . beol:hasAuthor knora-api:objectType knora-api:Resource . ?letter beol:hasRecipient ?person2 . beol:hasRecipient knora-api:objectType knora-api:Resource . ?person1 a knora-api:Resource . ?person2 a knora-api:Resource . } Note the placeholder BIND(<$resourceIri> as ?letter) that is going to be replaced by the Iri of the resource the request is performed for. The query asks for information about the letter's text beol:hasText and information about its author and recipient. This information is converted to the TEI header in the format required by correspSearch . To write the XSLT, do the Gravsearch query and request the data as RDF/XML using content negotiation (see Introduction ). The Gravsearch query's result may look like this ( RDF/XML ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <rdf:RDF xmlns:rdf= \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs= \"http://www.w3.org/2000/01/rdf-schema#\" xmlns:knora-api= \"http://api.knora.org/ontology/knora-api/v2#\" xmlns:beol= \"http://0.0.0.0:3333/ontology/0801/beol/v2#\" > <beol:letter rdf:about= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA\" > <beol:creationDate rdf:resource= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\" /> <beol:hasAuthorValue rdf:resource= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\" /> <beol:hasRecipientValue rdf:resource= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\" /> <rdfs:label rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Testletter </rdfs:label> </beol:letter> <knora-api:DateValue rdf:about= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\" > <knora-api:dateValueHasCalendar rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > GREGORIAN </knora-api:dateValueHasCalendar> <knora-api:dateValueHasEndDay rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 10 </knora-api:dateValueHasEndDay> <knora-api:dateValueHasEndEra rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > CE </knora-api:dateValueHasEndEra> <knora-api:dateValueHasEndMonth rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 6 </knora-api:dateValueHasEndMonth> <knora-api:dateValueHasEndYear rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 1703 </knora-api:dateValueHasEndYear> <knora-api:dateValueHasStartDay rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 10 </knora-api:dateValueHasStartDay> <knora-api:dateValueHasStartEra rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > CE </knora-api:dateValueHasStartEra> <knora-api:dateValueHasStartMonth rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 6 </knora-api:dateValueHasStartMonth> <knora-api:dateValueHasStartYear rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 1703 </knora-api:dateValueHasStartYear> <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > GREGORIAN:1703-06-10 CE </knora-api:valueAsString> </knora-api:DateValue> <knora-api:LinkValue rdf:about= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\" > <knora-api:linkValueHasTarget> <beol:person rdf:about= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ\" > <beol:hasFamilyName rdf:resource= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\" /> <beol:hasGivenName rdf:resource= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\" /> <beol:hasIAFIdentifier rdf:resource= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\" /> <rdfs:label rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Johann Jacob Scheuchzer </rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Scheuchzer </knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Johann Jacob </knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > (DE-588)118607308 </knora-api:valueAsString> </knora-api:TextValue> <knora-api:LinkValue rdf:about= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\" > <knora-api:linkValueHasTarget> <beol:person rdf:about= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw\" > <beol:hasFamilyName rdf:resource= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\" /> <beol:hasGivenName rdf:resource= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\" /> <beol:hasIAFIdentifier rdf:resource= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\" /> <rdfs:label rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Jacob Hermann </rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Hermann </knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Jacob </knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > (DE-588)119112450 </knora-api:valueAsString> </knora-api:TextValue> </rdf:RDF> In order to convert the metadata (not the actual standoff markup), a knora-base:knora-base:XSLTransformation has to be provided. For our example, it looks like this (see test_data/test_route/texts/beol/header.xsl ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <xsl:transform xmlns:xsl= \"http://www.w3.org/1999/XSL/Transform\" xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" xmlns:rdf= \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs1= \"http://www.w3.org/2000/01/rdf-schema#\" xmlns:beol= \"http://0.0.0.0:3333/ontology/0801/beol/v2#\" xmlns:knora-api= \"http://api.knora.org/ontology/knora-api/v2#\" exclude-result-prefixes= \"rdf beol knora-api xs rdfs1\" version= \"2.0\" > <xsl:output method= \"xml\" omit-xml-declaration= \"yes\" encoding= \"utf-8\" indent= \"yes\" /> <!-- make IAF id a URL --> <xsl:function name= \"knora-api:iaf\" as= \"xs:anyURI\" > <xsl:param name= \"input\" as= \"xs:string\" /> <xsl:value-of select= \"replace($input, '\\(DE-588\\)', 'http://d-nb.info/gnd/')\" /> </xsl:function> <!-- make a standard date (Gregorian calendar assumed) --> <xsl:function name= \"knora-api:dateformat\" as= \"element()*\" > <xsl:param name= \"input\" as= \"element()*\" /> <xsl:choose> <xsl:when test= \"$input/knora-api:dateValueHasStartYear/text() = $input/knora-api:dateValueHasEndYear/text() and $input/knora-api:dateValueHasStartMonth/text() = $input/knora-api:dateValueHasEndMonth/text() and $input/knora-api:dateValueHasStartDay/text() = $input/knora-api:dateValueHasEndDay/text()\" > <!-- no period, day precision --> <date> <xsl:attribute name= \"when\" > <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\" /> </xsl:attribute> </date> </xsl:when> <xsl:otherwise> <!-- period --> <date> <xsl:attribute name= \"notBefore\" > <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartDay/text(), '00')\" /> </xsl:attribute> <xsl:attribute name= \"notAfter\" > <xsl:value-of select= \"format-number($input/knora-api:dateValueHasEndYear/text(), '0000')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasEndMonth/text(), '00')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasEndDay/text(), '00')\" /> </xsl:attribute> </date> </xsl:otherwise> </xsl:choose> </xsl:function> <xsl:template match= \"rdf:RDF\" > <xsl:variable name= \"resourceIri\" select= \"beol:letter/@rdf:about\" /> <xsl:variable name= \"label\" select= \"beol:letter/rdfs1:label/text()\" /> <teiHeader> <fileDesc> <titleStmt> <title> <xsl:value-of select= \"$label\" /> </title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of the resource identified by the Iri <xsl:value-of select= \"$resourceIri\" /> . </p> </publicationStmt> <sourceDesc> <p> Representation of the resource's text as TEI/XML </p> </sourceDesc> </fileDesc> <profileDesc> <correspDesc> <xsl:attribute name= \"ref\" > <xsl:value-of select= \"$resourceIri\" /> </xsl:attribute> <xsl:apply-templates/> </correspDesc> </profileDesc> </teiHeader> </xsl:template> <xsl:template match= \"beol:letter/beol:hasAuthorValue\" > <xsl:variable name= \"authorValue\" select= \"@rdf:resource\" /> <xsl:variable name= \"authorIAFValue\" select= \"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasIAFIdentifier/@rdf:resource\" /> <xsl:variable name= \"authorFamilyNameValue\" select= \"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasFamilyName/@rdf:resource\" /> <xsl:variable name= \"authorGivenNameValue\" select= \"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasGivenName/@rdf:resource\" /> <correspAction type= \"sent\" > <xsl:variable name= \"authorIAFText\" select= \"//knora-api:TextValue[@rdf:about=$authorIAFValue]/knora-api:valueAsString/text()\" /> <xsl:variable name= \"authorFamilyNameText\" select= \"//knora-api:TextValue[@rdf:about=$authorFamilyNameValue]/knora-api:valueAsString/text()\" /> <xsl:variable name= \"authorGivenNameText\" select= \"//knora-api:TextValue[@rdf:about=$authorGivenNameValue]/knora-api:valueAsString/text()\" /> <persName> <xsl:attribute name= \"ref\" ><xsl:value-of select= \"knora-api:iaf($authorIAFText)\" /></xsl:attribute> <xsl:value-of select= \"$authorFamilyNameText\" /> , <xsl:value-of select= \"$authorGivenNameText\" /> </persName> <xsl:variable name= \"dateValue\" select= \"//beol:creationDate/@rdf:resource\" /> <xsl:variable name= \"dateObj\" select= \"//knora-api:DateValue[@rdf:about=$dateValue]\" /> <xsl:copy-of select= \"knora-api:dateformat($dateObj)\" /> </correspAction> </xsl:template> <xsl:template match= \"beol:letter/beol:hasRecipientValue\" > <xsl:variable name= \"recipientValue\" select= \"@rdf:resource\" /> <xsl:variable name= \"recipientIAFValue\" select= \"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasIAFIdentifier/@rdf:resource\" /> <xsl:variable name= \"recipientFamilyNameValue\" select= \"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasFamilyName/@rdf:resource\" /> <xsl:variable name= \"recipientGivenNameValue\" select= \"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasGivenName/@rdf:resource\" /> <correspAction type= \"received\" > <xsl:variable name= \"recipientIAFText\" select= \"//knora-api:TextValue[@rdf:about=$recipientIAFValue]/knora-api:valueAsString/text()\" /> <xsl:variable name= \"recipientFamilyNameText\" select= \"//knora-api:TextValue[@rdf:about=$recipientFamilyNameValue]/knora-api:valueAsString/text()\" /> <xsl:variable name= \"recipientGivenNameText\" select= \"//knora-api:TextValue[@rdf:about=$recipientGivenNameValue]/knora-api:valueAsString/text()\" /> <persName> <xsl:attribute name= \"ref\" ><xsl:value-of select= \"knora-api:iaf($recipientIAFText)\" /></xsl:attribute> <xsl:value-of select= \"$recipientFamilyNameText\" /> , <xsl:value-of select= \"$recipientGivenNameText\" /> </persName> </correspAction> </xsl:template> <!-- ignore text if there is no template for the element containing it --> <xsl:template match= \"text()\" > </xsl:template> </xsl:transform> You can use the functions knora-api:iaf and knora-api:dateformat in your own XSLT in case you want to support correspSearch . The complete request looks like this: HTTP GET request to http://host/v2/tei/resourceIri&textProperty=textPropertyIri&mappingIri=mappingIri&gravsearchTemplateIri=gravsearchTemplateIri&teiHeaderXSLTIri=teiHeaderXSLTIri See webapi/src/it/scala/org/knora/webapi/e2e/v1/KnoraSipiIntegrationV1ITSpec.scala for a complete test case involving the sample data (\"create a mapping for standoff conversion to TEI referring to an XSLT and also create a Gravsearch template and an XSLT for transforming TEI header data\"). When you provide a custom conversion, it is up to you to ensure the validity of the TEI document. You can use this service to validate: TEI by example validator . Problems and bugs caused by XSL transformations are out of scope of the responsibility of the Knora software.","title":"TEI/XML"},{"location":"DSP-API/03-endpoints/api-v2/tei-xml/#teixml-converting-standoff-to-teixml","text":"","title":"TEI/XML: Converting Standoff to TEI/XML"},{"location":"DSP-API/03-endpoints/api-v2/tei-xml/#general","text":"Knora offers a way to convert standoff markup to TEI/XML. The conversion is based on the assumption that a whole resource is to be turned into a TEI document. There is a basic distinction between the body and the header of a TEI document. The resource's property that contains the text with standoff markup is mapped to the TEI document's body. Other of the resource's property may be mapped to the TEI header.","title":"General"},{"location":"DSP-API/03-endpoints/api-v2/tei-xml/#standard-standoff-to-tei-conversion","text":"Knora offers a built-in conversion form standard standoff entities (defined in the standoff ontology) tags to TEI. In order to obtain a resource as a TEI document, the following request has to be performed. Please note that the URL parameters have to be URL-encoded. HTTP GET to http://host/v2/tei/resourceIri?textProperty=textPropertyIri In addition to the resource's Iri, the Iri of the property containing the text with standoff has to be submitted. This will be converted to the TEI body. Please note that the resource can only have one instance of this property and the text must have standoff markup. The Knora test data contain the resource http://rdfh.ch/0001/thing_with_richtext_with_markup with the text property http://0.0.0.0:3333/ontology/0001/anything/v2#hasRichtext that can be converted to TEI as follows: HTTP GET to http://host/v2/tei/http%3A%2F%2Frdfh.ch%2F0001%2Fthing_with_richtext_with_markup?textProperty=http%3A%2F%2F0.0.0.0%3A3333%2Fontology%2F0001%2Fanything%2Fv2%23hasRichtext The answer to this request is a TEI XML document: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <TEI xmlns= \"http://www.tei-c.org/ns/1.0\" version= \"3.3.0\" > <teiHeader> <fileDesc> <titleStmt> <title> test thing with markup </title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of a resource identified by the Iri http://rdfh.ch/0001/thing_with_richtext_with_markup. </p> </publicationStmt> <sourceDesc> <p> Representation of the resource's text as TEI/XML </p> </sourceDesc> </fileDesc> </teiHeader> <text> <body> <p> This is a test that contains marked up elements. This is <hi rend= \"italic\" > interesting text </hi> in italics. This is <hi rend= \"italic\" > boring text </hi> in italics. </p> </body> </text> </TEI> The body of the TEI document contains the standoff markup as XML. The header contains contains some basic metadata about the resource such as the rdfs:label an its IRI. However, this might not be sufficient for more advanced use cases like digital edition projects. In that case, a custom conversion has to be performed (see below).","title":"Standard Standoff to TEI Conversion"},{"location":"DSP-API/03-endpoints/api-v2/tei-xml/#custom-conversion","text":"If a project defines its own standoff entities, a custom conversion can be provided (body of the TEI document). Also for the TEI header, a custom conversion can be provided. For the custom conversion, additional configuration is required. TEI body: additional mapping from standoff to XML (URL parameter mappingIri ) XSL transformation to turn the XML into a valid TEI body (referred to by the mapping). The mapping has to refer to a defaultXSLTransformation that transforms the XML that was created from standoff markup (see XML To Standoff Mapping in API v1 ). This step is necessary because the mapping assumes a one to one relation between standoff classes and properties and XML elements and attributes. For example, we may want to convert a standoff:StandoffItalicTag into TEI/XML. TEI expresses this as <hi rend=\"italic\">...</hi> . In the mapping, the standoff:StandoffItalicTag may be mapped to a a temporary XML element that is going to be converted to <hi rend=\"italic\">...</hi> in a further step by the XSLT. For sample data, see webapi/_test_data/test_route/texts/beol/BEOLTEIMapping.xml (mapping) and webapi/_test_data/test_route/texts/beol/standoffToTEI.xsl . The standoff entities are defined in beol-onto.ttl . TEI header: Gravsearch template to query the resources metadata, results are serialized to RDF/XML (URL parameter gravsearchTemplateIri ) XSL transformation to turn that RDF/XML into a valid TEI header (URL parameter teiHeaderXSLTIri ) The Gravsearch template is expected to be of type knora-base:TextRepresentation and to contain a placeholder $resourceIri that is to be replaced by the actual resource Iri. The Gravsearch template is expected to contain a query involving the text property (URL parameter textProperty ) and more properties that are going to be mapped to the TEI header. The Gravsearch template is a simple text file with the files extension .txt . A Gravsearch template may look like this (see test_data/test_route/texts/beol/gravsearch.txt ): PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:creationDate ?date . ?letter beol:hasText ?text . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?letter beol:hasRecipient ?person2 . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . } WHERE { BIND(<$resourceIri> as ?letter) ?letter a knora-api:Resource . ?letter a beol:letter . ?letter beol:creationDate ?date . beol:creationDate knora-api:objectType knora-api:Date . ?date a knora-api:Date . ?letter beol:hasText ?text . beol:hasText knora-api:objectType xsd:string . ?text a xsd:string . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?name1 a xsd:string . ?givenName1 a xsd:string . ?iaf1 a xsd:string . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . ?name2 a xsd:string . ?givenName2 a xsd:string . ?iaf2 a xsd:string . beol:hasGivenName knora-api:objectType xsd:string . beol:hasFamilyName knora-api:objectType xsd:string . beol:hasIAFIdentifier knora-api:objectType xsd:string . beol:hasAuthor knora-api:objectType knora-api:Resource . ?letter beol:hasRecipient ?person2 . beol:hasRecipient knora-api:objectType knora-api:Resource . ?person1 a knora-api:Resource . ?person2 a knora-api:Resource . } Note the placeholder BIND(<$resourceIri> as ?letter) that is going to be replaced by the Iri of the resource the request is performed for. The query asks for information about the letter's text beol:hasText and information about its author and recipient. This information is converted to the TEI header in the format required by correspSearch . To write the XSLT, do the Gravsearch query and request the data as RDF/XML using content negotiation (see Introduction ). The Gravsearch query's result may look like this ( RDF/XML ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <rdf:RDF xmlns:rdf= \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs= \"http://www.w3.org/2000/01/rdf-schema#\" xmlns:knora-api= \"http://api.knora.org/ontology/knora-api/v2#\" xmlns:beol= \"http://0.0.0.0:3333/ontology/0801/beol/v2#\" > <beol:letter rdf:about= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA\" > <beol:creationDate rdf:resource= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\" /> <beol:hasAuthorValue rdf:resource= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\" /> <beol:hasRecipientValue rdf:resource= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\" /> <rdfs:label rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Testletter </rdfs:label> </beol:letter> <knora-api:DateValue rdf:about= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\" > <knora-api:dateValueHasCalendar rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > GREGORIAN </knora-api:dateValueHasCalendar> <knora-api:dateValueHasEndDay rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 10 </knora-api:dateValueHasEndDay> <knora-api:dateValueHasEndEra rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > CE </knora-api:dateValueHasEndEra> <knora-api:dateValueHasEndMonth rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 6 </knora-api:dateValueHasEndMonth> <knora-api:dateValueHasEndYear rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 1703 </knora-api:dateValueHasEndYear> <knora-api:dateValueHasStartDay rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 10 </knora-api:dateValueHasStartDay> <knora-api:dateValueHasStartEra rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > CE </knora-api:dateValueHasStartEra> <knora-api:dateValueHasStartMonth rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 6 </knora-api:dateValueHasStartMonth> <knora-api:dateValueHasStartYear rdf:datatype= \"http://www.w3.org/2001/XMLSchema#integer\" > 1703 </knora-api:dateValueHasStartYear> <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > GREGORIAN:1703-06-10 CE </knora-api:valueAsString> </knora-api:DateValue> <knora-api:LinkValue rdf:about= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\" > <knora-api:linkValueHasTarget> <beol:person rdf:about= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ\" > <beol:hasFamilyName rdf:resource= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\" /> <beol:hasGivenName rdf:resource= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\" /> <beol:hasIAFIdentifier rdf:resource= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\" /> <rdfs:label rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Johann Jacob Scheuchzer </rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Scheuchzer </knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Johann Jacob </knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > (DE-588)118607308 </knora-api:valueAsString> </knora-api:TextValue> <knora-api:LinkValue rdf:about= \"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\" > <knora-api:linkValueHasTarget> <beol:person rdf:about= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw\" > <beol:hasFamilyName rdf:resource= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\" /> <beol:hasGivenName rdf:resource= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\" /> <beol:hasIAFIdentifier rdf:resource= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\" /> <rdfs:label rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Jacob Hermann </rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Hermann </knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > Jacob </knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about= \"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\" > <knora-api:valueAsString rdf:datatype= \"http://www.w3.org/2001/XMLSchema#string\" > (DE-588)119112450 </knora-api:valueAsString> </knora-api:TextValue> </rdf:RDF> In order to convert the metadata (not the actual standoff markup), a knora-base:knora-base:XSLTransformation has to be provided. For our example, it looks like this (see test_data/test_route/texts/beol/header.xsl ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <xsl:transform xmlns:xsl= \"http://www.w3.org/1999/XSL/Transform\" xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" xmlns:rdf= \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs1= \"http://www.w3.org/2000/01/rdf-schema#\" xmlns:beol= \"http://0.0.0.0:3333/ontology/0801/beol/v2#\" xmlns:knora-api= \"http://api.knora.org/ontology/knora-api/v2#\" exclude-result-prefixes= \"rdf beol knora-api xs rdfs1\" version= \"2.0\" > <xsl:output method= \"xml\" omit-xml-declaration= \"yes\" encoding= \"utf-8\" indent= \"yes\" /> <!-- make IAF id a URL --> <xsl:function name= \"knora-api:iaf\" as= \"xs:anyURI\" > <xsl:param name= \"input\" as= \"xs:string\" /> <xsl:value-of select= \"replace($input, '\\(DE-588\\)', 'http://d-nb.info/gnd/')\" /> </xsl:function> <!-- make a standard date (Gregorian calendar assumed) --> <xsl:function name= \"knora-api:dateformat\" as= \"element()*\" > <xsl:param name= \"input\" as= \"element()*\" /> <xsl:choose> <xsl:when test= \"$input/knora-api:dateValueHasStartYear/text() = $input/knora-api:dateValueHasEndYear/text() and $input/knora-api:dateValueHasStartMonth/text() = $input/knora-api:dateValueHasEndMonth/text() and $input/knora-api:dateValueHasStartDay/text() = $input/knora-api:dateValueHasEndDay/text()\" > <!-- no period, day precision --> <date> <xsl:attribute name= \"when\" > <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\" /> </xsl:attribute> </date> </xsl:when> <xsl:otherwise> <!-- period --> <date> <xsl:attribute name= \"notBefore\" > <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasStartDay/text(), '00')\" /> </xsl:attribute> <xsl:attribute name= \"notAfter\" > <xsl:value-of select= \"format-number($input/knora-api:dateValueHasEndYear/text(), '0000')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasEndMonth/text(), '00')\" /> - <xsl:value-of select= \"format-number($input/knora-api:dateValueHasEndDay/text(), '00')\" /> </xsl:attribute> </date> </xsl:otherwise> </xsl:choose> </xsl:function> <xsl:template match= \"rdf:RDF\" > <xsl:variable name= \"resourceIri\" select= \"beol:letter/@rdf:about\" /> <xsl:variable name= \"label\" select= \"beol:letter/rdfs1:label/text()\" /> <teiHeader> <fileDesc> <titleStmt> <title> <xsl:value-of select= \"$label\" /> </title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of the resource identified by the Iri <xsl:value-of select= \"$resourceIri\" /> . </p> </publicationStmt> <sourceDesc> <p> Representation of the resource's text as TEI/XML </p> </sourceDesc> </fileDesc> <profileDesc> <correspDesc> <xsl:attribute name= \"ref\" > <xsl:value-of select= \"$resourceIri\" /> </xsl:attribute> <xsl:apply-templates/> </correspDesc> </profileDesc> </teiHeader> </xsl:template> <xsl:template match= \"beol:letter/beol:hasAuthorValue\" > <xsl:variable name= \"authorValue\" select= \"@rdf:resource\" /> <xsl:variable name= \"authorIAFValue\" select= \"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasIAFIdentifier/@rdf:resource\" /> <xsl:variable name= \"authorFamilyNameValue\" select= \"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasFamilyName/@rdf:resource\" /> <xsl:variable name= \"authorGivenNameValue\" select= \"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasGivenName/@rdf:resource\" /> <correspAction type= \"sent\" > <xsl:variable name= \"authorIAFText\" select= \"//knora-api:TextValue[@rdf:about=$authorIAFValue]/knora-api:valueAsString/text()\" /> <xsl:variable name= \"authorFamilyNameText\" select= \"//knora-api:TextValue[@rdf:about=$authorFamilyNameValue]/knora-api:valueAsString/text()\" /> <xsl:variable name= \"authorGivenNameText\" select= \"//knora-api:TextValue[@rdf:about=$authorGivenNameValue]/knora-api:valueAsString/text()\" /> <persName> <xsl:attribute name= \"ref\" ><xsl:value-of select= \"knora-api:iaf($authorIAFText)\" /></xsl:attribute> <xsl:value-of select= \"$authorFamilyNameText\" /> , <xsl:value-of select= \"$authorGivenNameText\" /> </persName> <xsl:variable name= \"dateValue\" select= \"//beol:creationDate/@rdf:resource\" /> <xsl:variable name= \"dateObj\" select= \"//knora-api:DateValue[@rdf:about=$dateValue]\" /> <xsl:copy-of select= \"knora-api:dateformat($dateObj)\" /> </correspAction> </xsl:template> <xsl:template match= \"beol:letter/beol:hasRecipientValue\" > <xsl:variable name= \"recipientValue\" select= \"@rdf:resource\" /> <xsl:variable name= \"recipientIAFValue\" select= \"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasIAFIdentifier/@rdf:resource\" /> <xsl:variable name= \"recipientFamilyNameValue\" select= \"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasFamilyName/@rdf:resource\" /> <xsl:variable name= \"recipientGivenNameValue\" select= \"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasGivenName/@rdf:resource\" /> <correspAction type= \"received\" > <xsl:variable name= \"recipientIAFText\" select= \"//knora-api:TextValue[@rdf:about=$recipientIAFValue]/knora-api:valueAsString/text()\" /> <xsl:variable name= \"recipientFamilyNameText\" select= \"//knora-api:TextValue[@rdf:about=$recipientFamilyNameValue]/knora-api:valueAsString/text()\" /> <xsl:variable name= \"recipientGivenNameText\" select= \"//knora-api:TextValue[@rdf:about=$recipientGivenNameValue]/knora-api:valueAsString/text()\" /> <persName> <xsl:attribute name= \"ref\" ><xsl:value-of select= \"knora-api:iaf($recipientIAFText)\" /></xsl:attribute> <xsl:value-of select= \"$recipientFamilyNameText\" /> , <xsl:value-of select= \"$recipientGivenNameText\" /> </persName> </correspAction> </xsl:template> <!-- ignore text if there is no template for the element containing it --> <xsl:template match= \"text()\" > </xsl:template> </xsl:transform> You can use the functions knora-api:iaf and knora-api:dateformat in your own XSLT in case you want to support correspSearch . The complete request looks like this: HTTP GET request to http://host/v2/tei/resourceIri&textProperty=textPropertyIri&mappingIri=mappingIri&gravsearchTemplateIri=gravsearchTemplateIri&teiHeaderXSLTIri=teiHeaderXSLTIri See webapi/src/it/scala/org/knora/webapi/e2e/v1/KnoraSipiIntegrationV1ITSpec.scala for a complete test case involving the sample data (\"create a mapping for standoff conversion to TEI referring to an XSLT and also create a Gravsearch template and an XSLT for transforming TEI header data\"). When you provide a custom conversion, it is up to you to ensure the validity of the TEI document. You can use this service to validate: TEI by example validator . Problems and bugs caused by XSL transformations are out of scope of the responsibility of the Knora software.","title":"Custom Conversion"},{"location":"DSP-API/03-endpoints/api-v2/xml-to-standoff-mapping/","text":"XML to Standoff Mapping in API v2 General Information Please see v1 documentation for general information about the XML to standoff mapping: XML To Standoff Mapping in API v1 . Validating a Mapping and sending it to Knora A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v2/mapping The multipart request consists of two named parts: \"json\": { \"knora-api:mappingHasName\": \"My Mapping\", \"knora-api:attachedToProject\": \"projectIRI\", \"rdfs:label\": \"MappingNameSegment\", \"@context\": { \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the knora-api:mappingHasName submitted in the JSON-LD (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the v2 typescript interfaces AddMappingRequest and AddMappingResponse in module MappingFormats","title":"XML to Standoff Mapping"},{"location":"DSP-API/03-endpoints/api-v2/xml-to-standoff-mapping/#xml-to-standoff-mapping-in-api-v2","text":"","title":"XML to Standoff Mapping in API v2"},{"location":"DSP-API/03-endpoints/api-v2/xml-to-standoff-mapping/#general-information","text":"Please see v1 documentation for general information about the XML to standoff mapping: XML To Standoff Mapping in API v1 .","title":"General Information"},{"location":"DSP-API/03-endpoints/api-v2/xml-to-standoff-mapping/#validating-a-mapping-and-sending-it-to-knora","text":"A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v2/mapping The multipart request consists of two named parts: \"json\": { \"knora-api:mappingHasName\": \"My Mapping\", \"knora-api:attachedToProject\": \"projectIRI\", \"rdfs:label\": \"MappingNameSegment\", \"@context\": { \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the knora-api:mappingHasName submitted in the JSON-LD (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the v2 typescript interfaces AddMappingRequest and AddMappingResponse in module MappingFormats","title":"Validating a Mapping and sending it to Knora"},{"location":"DSP-API/03-endpoints/instrumentation/health/","text":"Health The health endpoint provides information about the health state of the dsp-stack. Example request GET /health Example response { \"name\" : \"AppState\" , \"message\" : \"Application is healthy\" , \"severity\" : \"non fatal\" , \"status\" : \"healthy\" }","title":"Health Endpoint"},{"location":"DSP-API/03-endpoints/instrumentation/health/#health","text":"The health endpoint provides information about the health state of the dsp-stack.","title":"Health"},{"location":"DSP-API/03-endpoints/instrumentation/health/#example-request","text":"GET /health","title":"Example request"},{"location":"DSP-API/03-endpoints/instrumentation/health/#example-response","text":"{ \"name\" : \"AppState\" , \"message\" : \"Application is healthy\" , \"severity\" : \"non fatal\" , \"status\" : \"healthy\" }","title":"Example response"},{"location":"DSP-API/03-endpoints/instrumentation/introduction/","text":"Instrumentation The instrumentation endpoints are running on a separate port (default 3339 ) defined in application.conf under the key: app.instrumentaion-server-config.port and can also be set through the environment variable: KNORA_INSTRUMENTATION_SERVER_PORT . The exposed endpoints are: - /metrics - a metrics endpoint, backed by the ZIO metrics backend exposing metrics in the prometheus format - /health - provides information about the health state, see Health Endpoint","title":"Introduction"},{"location":"DSP-API/03-endpoints/instrumentation/introduction/#instrumentation","text":"The instrumentation endpoints are running on a separate port (default 3339 ) defined in application.conf under the key: app.instrumentaion-server-config.port and can also be set through the environment variable: KNORA_INSTRUMENTATION_SERVER_PORT . The exposed endpoints are: - /metrics - a metrics endpoint, backed by the ZIO metrics backend exposing metrics in the prometheus format - /health - provides information about the health state, see Health Endpoint","title":"Instrumentation"},{"location":"DSP-API/03-endpoints/instrumentation/metrics/","text":"Metrics Endpoint The metrics endpoint exposes metrics gathered through the ZIO metrics frontend in the Prometheus format. Additionally, ZIO runtime, JVM and ZIO-HTTP metrics are also exposed. Configuration The refresh interval is configured in application.conf under the key: app.instrumentaion-server-config.interval which es per default set to 5 seconds . Example request GET /metrics Example response # TYPE jvm_memory_pool_allocated_bytes_total counter # HELP jvm_memory_pool_allocated_bytes_total Some help jvm_memory_pool_allocated_bytes_total{pool=\"G1 Survivor Space\"} 4828024.0 1671021037947 # TYPE jvm_memory_pool_allocated_bytes_total counter # HELP jvm_memory_pool_allocated_bytes_total Some help jvm_memory_pool_allocated_bytes_total{pool=\"G1 Eden Space\"} 3.3554432E7 1671021037947 # TYPE zio_fiber_successes counter # HELP zio_fiber_successes Some help zio_fiber_successes 17.0 1671021037947 # TYPE zio_fiber_lifetimes histogram # HELP zio_fiber_lifetimes Some help zio_fiber_lifetimes_bucket{le=\"1.0\"} 17.0 1671021037947 zio_fiber_lifetimes_bucket{le=\"2.0\"} 17.0 1671021037947 ... ZIO-HTTP metrics Metrics of all routes served by ZIO-HTTP (default: port 5555 ) are exposed through a default metrics middleware. However, instead of http_concurrent_requests_total etc. they are labeled zio_http_concurrent_requests_total etc. with zio prepended, so that they are clearly distinguishable while we still run ZIO-HTTP and Akka-HTTP in parallel. To prevent excessive amounts of labels, it is considered good practice, to replace dynamic path segments with slugs (e.g. /projects/shortcode/0000 with /projects/shortcode/:shortcode ). Like this, requesting different projects by identifier will add multiple values to the histogram of a single route, instead of creating a histogram for each project: zio_http_request_duration_seconds_bucket{method=\"GET\",path=\"/admin/projects/shortcode/:shortcode\",status=\"200\",le=\"0.005\"} 0.0 1676481606015 ... Instead of: zio_http_request_duration_seconds_bucket{method=\"GET\",path=\"/admin/projects/shortcode/0000\",status=\"200\",le=\"0.005\"} 0.0 1676481606015 zio_http_request_duration_seconds_bucket{method=\"GET\",path=\"/admin/projects/shortcode/0001\",status=\"200\",le=\"0.005\"} 0.0 1676481606015 ... This is achieved by providing the middleware a pathLabelMapper ; when adding new routes, it is advisable to assert that this replacement works correctly for the newly added route.","title":"Metrics Endpoint"},{"location":"DSP-API/03-endpoints/instrumentation/metrics/#metrics-endpoint","text":"The metrics endpoint exposes metrics gathered through the ZIO metrics frontend in the Prometheus format. Additionally, ZIO runtime, JVM and ZIO-HTTP metrics are also exposed.","title":"Metrics Endpoint"},{"location":"DSP-API/03-endpoints/instrumentation/metrics/#configuration","text":"The refresh interval is configured in application.conf under the key: app.instrumentaion-server-config.interval which es per default set to 5 seconds .","title":"Configuration"},{"location":"DSP-API/03-endpoints/instrumentation/metrics/#example-request","text":"GET /metrics","title":"Example request"},{"location":"DSP-API/03-endpoints/instrumentation/metrics/#example-response","text":"# TYPE jvm_memory_pool_allocated_bytes_total counter # HELP jvm_memory_pool_allocated_bytes_total Some help jvm_memory_pool_allocated_bytes_total{pool=\"G1 Survivor Space\"} 4828024.0 1671021037947 # TYPE jvm_memory_pool_allocated_bytes_total counter # HELP jvm_memory_pool_allocated_bytes_total Some help jvm_memory_pool_allocated_bytes_total{pool=\"G1 Eden Space\"} 3.3554432E7 1671021037947 # TYPE zio_fiber_successes counter # HELP zio_fiber_successes Some help zio_fiber_successes 17.0 1671021037947 # TYPE zio_fiber_lifetimes histogram # HELP zio_fiber_lifetimes Some help zio_fiber_lifetimes_bucket{le=\"1.0\"} 17.0 1671021037947 zio_fiber_lifetimes_bucket{le=\"2.0\"} 17.0 1671021037947 ...","title":"Example response"},{"location":"DSP-API/03-endpoints/instrumentation/metrics/#zio-http-metrics","text":"Metrics of all routes served by ZIO-HTTP (default: port 5555 ) are exposed through a default metrics middleware. However, instead of http_concurrent_requests_total etc. they are labeled zio_http_concurrent_requests_total etc. with zio prepended, so that they are clearly distinguishable while we still run ZIO-HTTP and Akka-HTTP in parallel. To prevent excessive amounts of labels, it is considered good practice, to replace dynamic path segments with slugs (e.g. /projects/shortcode/0000 with /projects/shortcode/:shortcode ). Like this, requesting different projects by identifier will add multiple values to the histogram of a single route, instead of creating a histogram for each project: zio_http_request_duration_seconds_bucket{method=\"GET\",path=\"/admin/projects/shortcode/:shortcode\",status=\"200\",le=\"0.005\"} 0.0 1676481606015 ... Instead of: zio_http_request_duration_seconds_bucket{method=\"GET\",path=\"/admin/projects/shortcode/0000\",status=\"200\",le=\"0.005\"} 0.0 1676481606015 zio_http_request_duration_seconds_bucket{method=\"GET\",path=\"/admin/projects/shortcode/0001\",status=\"200\",le=\"0.005\"} 0.0 1676481606015 ... This is achieved by providing the middleware a pathLabelMapper ; when adding new routes, it is advisable to assert that this replacement works correctly for the newly added route.","title":"ZIO-HTTP metrics"},{"location":"DSP-API/04-publishing-deployment/configuration/","text":"Configuration All configuration for Knora is done in application.conf . Besides the Knora application specific configuration, there we can also find configuration for the underlying Akka library. For optimal performance it is important to tune the configuration to the hardware used, mainly to the number of CPUs and cores per CPU. The relevant sections for tuning are: akka.actor.deployment knora-actor-dispatcher knora-blocking-dispatcher System Environment Variables A number of core settings is additionally configurable through system environment variables. These are: key in application.conf environment variable default value akka.log-config-on-start KNORA_AKKA_LOG_CONFIG_ON_START off akka.loglevel KNORA_AKKA_LOGLEVEL INFO akka.stdout-loglevel KNORA_AKKA_STDOUT_LOGLEVEL INFO app.print-extended-config KNORA_WEBAPI_PRINT_EXTENDED_CONFIG false app.bcrypt-password-strength KNORA_WEBAPI_BCRYPT_PASSWORD_STRENGTH 12 app.jwt-secret-key KNORA_WEBAPI_JWT_SECRET_KEY super-secret-key app.jwt-longevity KNORA_WEBAPI_JWT_LONGEVITY 30 days app.cookie-domain KNORA_WEBAPI_COOKIE_DOMAIN localhost app.allow-reload-over-http KNORA_WEBAPI_ALLOW_RELOAD_OVER_HTTP false app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.knora-api.internal-host KNORA_WEBAPI_KNORA_API_INTERNAL_HOST 0.0.0.0 app.knora-api.internal-port KNORA_WEBAPI_KNORA_API_INTERNAL_PORT 3333 app.knora-api.external-protocol KNORA_WEBAPI_KNORA_API_EXTERNAL_PROTOCOL http app.knora-api.external-host KNORA_WEBAPI_KNORA_API_EXTERNAL_HOST 0.0.0.0 app.knora-api.external-port KNORA_WEBAPI_KNORA_API_EXTERNAL_PORT 3333 app.sipi.internal-protocol KNORA_WEBAPI_SIPI_INTERNAL_PROTOCOL http app.sipi.internal-host KNORA_WEBAPI_SIPI_INTERNAL_HOST localhost app.sipi.internal-port KNORA_WEBAPI_SIPI_INTERNAL_PORT 1024 app.sipi.external-protocol KNORA_WEBAPI_SIPI_EXTERNAL_PROTOCOL http app.sipi.external-host KNORA_WEBAPI_SIPI_EXTERNAL_HOST localhost app.sipi.external-port KNORA_WEBAPI_SIPI_EXTERNAL_PORT 443 app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.salsah1.base-url KNORA_WEBAPI_SALSAH1_BASE_URL http://localhost:3335 app.triplestore.dbtype KNORA_WEBAPI_TRIPLESTORE_DBTYPE fuseki app.triplestore.use-https KNORA_WEBAPI_TRIPLESTORE_USE_HTTPS false app.triplestore.host KNORA_WEBAPI_TRIPLESTORE_HOST localhost app.triplestore.auto-init KNORA_WEBAPI_TRIPLESTORE_AUTOINIT false app.triplestore.fuseki.port KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PORT 3030 app.triplestore.fuseki.repository-name KNORA_WEBAPI_TRIPLESTORE_FUSEKI_REPOSITORY_NAME knora-test app.triplestore.fuseki.username KNORA_WEBAPI_TRIPLESTORE_FUSEKI_USERNAME admin app.triplestore.fuseki.password KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PASSWORD test app.cache-service.enabled KNORA_WEBAPI_CACHE_SERVICE_ENABLED true Selectively Disabling Routes In application.conf the setting app.routes-to-reject contains a list of strings, representing routes which should be rejected. For Example, the string \"v1/users\" would lead to rejection of any route which contains this string. Startup Flags There is a number of flags that can be set on startup, they will override any value set in the application configuration file: loadDemoData , --loadDemoData , -d : Loads the demo data. allowReloadOverHTTP , --allow-reload-over-http , -r : Allows reloading of data over HTTP. -c : Print the configuration at startup. --help : Shows the help message with all startup flags.","title":"Configuration"},{"location":"DSP-API/04-publishing-deployment/configuration/#configuration","text":"All configuration for Knora is done in application.conf . Besides the Knora application specific configuration, there we can also find configuration for the underlying Akka library. For optimal performance it is important to tune the configuration to the hardware used, mainly to the number of CPUs and cores per CPU. The relevant sections for tuning are: akka.actor.deployment knora-actor-dispatcher knora-blocking-dispatcher","title":"Configuration"},{"location":"DSP-API/04-publishing-deployment/configuration/#system-environment-variables","text":"A number of core settings is additionally configurable through system environment variables. These are: key in application.conf environment variable default value akka.log-config-on-start KNORA_AKKA_LOG_CONFIG_ON_START off akka.loglevel KNORA_AKKA_LOGLEVEL INFO akka.stdout-loglevel KNORA_AKKA_STDOUT_LOGLEVEL INFO app.print-extended-config KNORA_WEBAPI_PRINT_EXTENDED_CONFIG false app.bcrypt-password-strength KNORA_WEBAPI_BCRYPT_PASSWORD_STRENGTH 12 app.jwt-secret-key KNORA_WEBAPI_JWT_SECRET_KEY super-secret-key app.jwt-longevity KNORA_WEBAPI_JWT_LONGEVITY 30 days app.cookie-domain KNORA_WEBAPI_COOKIE_DOMAIN localhost app.allow-reload-over-http KNORA_WEBAPI_ALLOW_RELOAD_OVER_HTTP false app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.knora-api.internal-host KNORA_WEBAPI_KNORA_API_INTERNAL_HOST 0.0.0.0 app.knora-api.internal-port KNORA_WEBAPI_KNORA_API_INTERNAL_PORT 3333 app.knora-api.external-protocol KNORA_WEBAPI_KNORA_API_EXTERNAL_PROTOCOL http app.knora-api.external-host KNORA_WEBAPI_KNORA_API_EXTERNAL_HOST 0.0.0.0 app.knora-api.external-port KNORA_WEBAPI_KNORA_API_EXTERNAL_PORT 3333 app.sipi.internal-protocol KNORA_WEBAPI_SIPI_INTERNAL_PROTOCOL http app.sipi.internal-host KNORA_WEBAPI_SIPI_INTERNAL_HOST localhost app.sipi.internal-port KNORA_WEBAPI_SIPI_INTERNAL_PORT 1024 app.sipi.external-protocol KNORA_WEBAPI_SIPI_EXTERNAL_PROTOCOL http app.sipi.external-host KNORA_WEBAPI_SIPI_EXTERNAL_HOST localhost app.sipi.external-port KNORA_WEBAPI_SIPI_EXTERNAL_PORT 443 app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.salsah1.base-url KNORA_WEBAPI_SALSAH1_BASE_URL http://localhost:3335 app.triplestore.dbtype KNORA_WEBAPI_TRIPLESTORE_DBTYPE fuseki app.triplestore.use-https KNORA_WEBAPI_TRIPLESTORE_USE_HTTPS false app.triplestore.host KNORA_WEBAPI_TRIPLESTORE_HOST localhost app.triplestore.auto-init KNORA_WEBAPI_TRIPLESTORE_AUTOINIT false app.triplestore.fuseki.port KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PORT 3030 app.triplestore.fuseki.repository-name KNORA_WEBAPI_TRIPLESTORE_FUSEKI_REPOSITORY_NAME knora-test app.triplestore.fuseki.username KNORA_WEBAPI_TRIPLESTORE_FUSEKI_USERNAME admin app.triplestore.fuseki.password KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PASSWORD test app.cache-service.enabled KNORA_WEBAPI_CACHE_SERVICE_ENABLED true","title":"System Environment Variables"},{"location":"DSP-API/04-publishing-deployment/configuration/#selectively-disabling-routes","text":"In application.conf the setting app.routes-to-reject contains a list of strings, representing routes which should be rejected. For Example, the string \"v1/users\" would lead to rejection of any route which contains this string.","title":"Selectively Disabling Routes"},{"location":"DSP-API/04-publishing-deployment/configuration/#startup-flags","text":"There is a number of flags that can be set on startup, they will override any value set in the application configuration file: loadDemoData , --loadDemoData , -d : Loads the demo data. allowReloadOverHTTP , --allow-reload-over-http , -r : Allows reloading of data over HTTP. -c : Print the configuration at startup. --help : Shows the help message with all startup flags.","title":"Startup Flags"},{"location":"DSP-API/04-publishing-deployment/publishing/","text":"Publishing DSP is published as a set of Docker images under the DaSCH Dockerhub Organization . The following Docker images are published: DSP-API: https://hub.docker.com/r/daschswiss/knora-api Sipi (includes DSP's specific Sipi scripts): https://hub.docker.com/r/daschswiss/knora-sipi DSP-APP: https://hub.docker.com/r/daschswiss/dsp-app DSP's Docker images are published automatically through Github CI each time a pull-request is merged into the main branch. Each image is tagged with a version number, which is derived by using the result of git describe . The describe version is built from the last tag + number of commits since tag + short hash , e.g., 8.0.0-7-ga7827e9 . The images can be published locally by running: $ make docker-build or to Dockerhub: $ make docker-publish","title":"Publishing"},{"location":"DSP-API/04-publishing-deployment/publishing/#publishing","text":"DSP is published as a set of Docker images under the DaSCH Dockerhub Organization . The following Docker images are published: DSP-API: https://hub.docker.com/r/daschswiss/knora-api Sipi (includes DSP's specific Sipi scripts): https://hub.docker.com/r/daschswiss/knora-sipi DSP-APP: https://hub.docker.com/r/daschswiss/dsp-app DSP's Docker images are published automatically through Github CI each time a pull-request is merged into the main branch. Each image is tagged with a version number, which is derived by using the result of git describe . The describe version is built from the last tag + number of commits since tag + short hash , e.g., 8.0.0-7-ga7827e9 . The images can be published locally by running: $ make docker-build or to Dockerhub: $ make docker-publish","title":"Publishing"},{"location":"DSP-API/04-publishing-deployment/updates/","text":"Updating Repositories When Upgrading Knora When a new version of Knora introduces changes that are not backwards-compatible with existing data, your repository will need to be updated. Upgrading from Knora Version 7.0.0 or Later In most cases, Knora will update your repository automatically when it starts. If manual changes are needed, these will be described in the release notes, and must be done first. Before starting a new version of Knora, back up your repository, so you can restore it in case the automatic repository update fails. For Fuseki use fuseki-dump-repository.sh script located in webapi/scripts . For information on command-line options, run the script with no arguments.","title":"Updating Repositories when Upgrading DSP-API"},{"location":"DSP-API/04-publishing-deployment/updates/#updating-repositories-when-upgrading-knora","text":"When a new version of Knora introduces changes that are not backwards-compatible with existing data, your repository will need to be updated.","title":"Updating Repositories When Upgrading Knora"},{"location":"DSP-API/04-publishing-deployment/updates/#upgrading-from-knora-version-700-or-later","text":"In most cases, Knora will update your repository automatically when it starts. If manual changes are needed, these will be described in the release notes, and must be done first. Before starting a new version of Knora, back up your repository, so you can restore it in case the automatic repository update fails. For Fuseki use fuseki-dump-repository.sh script located in webapi/scripts . For information on command-line options, run the script with no arguments.","title":"Upgrading from Knora Version 7.0.0 or Later"},{"location":"DSP-API/05-internals/design/adr/ADR-0001-record-architecture-decisions/","text":"ADR-0001 Record architectural decisions as ADR Date: 2022-03-14 Status Accepted Context We need to record the architectural decisions made on this project. Decision We will use Architectural Decision Records, as described by Michael Nygard . Consequences See Michael Nygard's article, linked above. For a lightweight ADR toolset, see Nat Pryce's adr-tools .","title":"0001 Record Architectural Decisions"},{"location":"DSP-API/05-internals/design/adr/ADR-0001-record-architecture-decisions/#adr-0001-record-architectural-decisions-as-adr","text":"Date: 2022-03-14","title":"ADR-0001 Record architectural decisions as ADR"},{"location":"DSP-API/05-internals/design/adr/ADR-0001-record-architecture-decisions/#status","text":"Accepted","title":"Status"},{"location":"DSP-API/05-internals/design/adr/ADR-0001-record-architecture-decisions/#context","text":"We need to record the architectural decisions made on this project.","title":"Context"},{"location":"DSP-API/05-internals/design/adr/ADR-0001-record-architecture-decisions/#decision","text":"We will use Architectural Decision Records, as described by Michael Nygard .","title":"Decision"},{"location":"DSP-API/05-internals/design/adr/ADR-0001-record-architecture-decisions/#consequences","text":"See Michael Nygard's article, linked above. For a lightweight ADR toolset, see Nat Pryce's adr-tools .","title":"Consequences"},{"location":"DSP-API/05-internals/design/adr/ADR-0002-change-cache-service-manager-from-akka-actor-to-zlayer/","text":"ADR-0002 Change Cache Service Manager from Akka-Actor to ZLayer Date: 2022-04-06 Status Accepted Context The org.knora.webapi.store.cacheservice.CacheServiceManager was implemented as an Akka-Actor . Decision As part of the move from Akka to ZIO , it was decided that the CacheServiceManager and the whole implementation of the in-memory and Redis backed cache is refactored using ZIO. Consequences The usage from other actors stays the same. The actor messages and responses don't change.","title":"0002 Change Cache Service Manager from Akka-Actor to ZLayer"},{"location":"DSP-API/05-internals/design/adr/ADR-0002-change-cache-service-manager-from-akka-actor-to-zlayer/#adr-0002-change-cache-service-manager-from-akka-actor-to-zlayer","text":"Date: 2022-04-06","title":"ADR-0002 Change Cache Service Manager from Akka-Actor to ZLayer"},{"location":"DSP-API/05-internals/design/adr/ADR-0002-change-cache-service-manager-from-akka-actor-to-zlayer/#status","text":"Accepted","title":"Status"},{"location":"DSP-API/05-internals/design/adr/ADR-0002-change-cache-service-manager-from-akka-actor-to-zlayer/#context","text":"The org.knora.webapi.store.cacheservice.CacheServiceManager was implemented as an Akka-Actor .","title":"Context"},{"location":"DSP-API/05-internals/design/adr/ADR-0002-change-cache-service-manager-from-akka-actor-to-zlayer/#decision","text":"As part of the move from Akka to ZIO , it was decided that the CacheServiceManager and the whole implementation of the in-memory and Redis backed cache is refactored using ZIO.","title":"Decision"},{"location":"DSP-API/05-internals/design/adr/ADR-0002-change-cache-service-manager-from-akka-actor-to-zlayer/#consequences","text":"The usage from other actors stays the same. The actor messages and responses don't change.","title":"Consequences"},{"location":"DSP-API/05-internals/design/adr/ADR-0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/","text":"ADR-0003 Change IIIF Service Manager and Sipi implementation to zlayer Date: 2022-04-29 Status Accepted Context Both org.knora.webapi.store.iiif.IIIFServiceManager and org.knora.webapi.store.iiif.impl.IIIFServiceSipiImpl where implemented as Akka-Actors Decision As part of the move from Akka to ZIO , it was decided that the IIIFServiceManager and the IIIFServiceSipiImpl is refactored using ZIO. Consequences The usage from other actors stays the same. The actor messages and responses don't change.","title":"0003 Change IIIF Service Manager and Sipi implementation to zlayer"},{"location":"DSP-API/05-internals/design/adr/ADR-0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#adr-0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer","text":"Date: 2022-04-29","title":"ADR-0003 Change IIIF Service Manager and Sipi implementation to zlayer"},{"location":"DSP-API/05-internals/design/adr/ADR-0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#status","text":"Accepted","title":"Status"},{"location":"DSP-API/05-internals/design/adr/ADR-0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#context","text":"Both org.knora.webapi.store.iiif.IIIFServiceManager and org.knora.webapi.store.iiif.impl.IIIFServiceSipiImpl where implemented as Akka-Actors","title":"Context"},{"location":"DSP-API/05-internals/design/adr/ADR-0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#decision","text":"As part of the move from Akka to ZIO , it was decided that the IIIFServiceManager and the IIIFServiceSipiImpl is refactored using ZIO.","title":"Decision"},{"location":"DSP-API/05-internals/design/adr/ADR-0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#consequences","text":"The usage from other actors stays the same. The actor messages and responses don't change.","title":"Consequences"},{"location":"DSP-API/05-internals/design/adr/ADR-0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/","text":"ADR-0004 Change Triplestore Service Manager and Fuseki implementation to ZLayer Date: 2022-05-23 Status Accepted Context Both org.knora.webapi.store.triplestore.TriplestoreServiceManager and org.knora.webapi.store.triplestore.impl.TriplestoreServiceHttpConnectorImpl where implemented as Akka-Actors. Decision As part of the move from Akka to ZIO , it was decided that the TriplestoreServiceManager and the TriplestoreServiceHttpConnectorImpl is refactored using ZIO. Consequences The usage from other actors stays the same. The actor messages and responses don't change.","title":"0004 Change Triplestore Service Manager and Fuseki implementation to ZLayer"},{"location":"DSP-API/05-internals/design/adr/ADR-0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#adr-0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer","text":"Date: 2022-05-23","title":"ADR-0004 Change Triplestore Service Manager and Fuseki implementation to ZLayer"},{"location":"DSP-API/05-internals/design/adr/ADR-0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#status","text":"Accepted","title":"Status"},{"location":"DSP-API/05-internals/design/adr/ADR-0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#context","text":"Both org.knora.webapi.store.triplestore.TriplestoreServiceManager and org.knora.webapi.store.triplestore.impl.TriplestoreServiceHttpConnectorImpl where implemented as Akka-Actors.","title":"Context"},{"location":"DSP-API/05-internals/design/adr/ADR-0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#decision","text":"As part of the move from Akka to ZIO , it was decided that the TriplestoreServiceManager and the TriplestoreServiceHttpConnectorImpl is refactored using ZIO.","title":"Decision"},{"location":"DSP-API/05-internals/design/adr/ADR-0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#consequences","text":"The usage from other actors stays the same. The actor messages and responses don't change.","title":"Consequences"},{"location":"DSP-API/05-internals/design/adr/ADR-0005-change-respondermanager-to-a-simple-case-class/","text":"ADR-0005 Change ResponderManager to a simple case class Date: 2022-06-06 Status Accepted Context The org.knora.webapi.responders.ResponderManager was implemented as an Akka-Actor. Decision In preparation of the move from Akka to ZIO , it was decided that the ResponderManager is refactored using plain case classes. Consequences The actor messages and responses don't change. All calls made previously to the ResponderManager and the StorageManager are now changed to the ApplicationActor which will route the calls to either the ResponderManager or the StorageManager based on the message type. The ApplicationActor is the only actor that is allowed to make calls to either the ResponderManager or the StorageManager . All requests from routes are now routed to the ApplicationActor .","title":"0005 Change ResponderManager to a simple case class"},{"location":"DSP-API/05-internals/design/adr/ADR-0005-change-respondermanager-to-a-simple-case-class/#adr-0005-change-respondermanager-to-a-simple-case-class","text":"Date: 2022-06-06","title":"ADR-0005 Change ResponderManager to a simple case class"},{"location":"DSP-API/05-internals/design/adr/ADR-0005-change-respondermanager-to-a-simple-case-class/#status","text":"Accepted","title":"Status"},{"location":"DSP-API/05-internals/design/adr/ADR-0005-change-respondermanager-to-a-simple-case-class/#context","text":"The org.knora.webapi.responders.ResponderManager was implemented as an Akka-Actor.","title":"Context"},{"location":"DSP-API/05-internals/design/adr/ADR-0005-change-respondermanager-to-a-simple-case-class/#decision","text":"In preparation of the move from Akka to ZIO , it was decided that the ResponderManager is refactored using plain case classes.","title":"Decision"},{"location":"DSP-API/05-internals/design/adr/ADR-0005-change-respondermanager-to-a-simple-case-class/#consequences","text":"The actor messages and responses don't change. All calls made previously to the ResponderManager and the StorageManager are now changed to the ApplicationActor which will route the calls to either the ResponderManager or the StorageManager based on the message type. The ApplicationActor is the only actor that is allowed to make calls to either the ResponderManager or the StorageManager . All requests from routes are now routed to the ApplicationActor .","title":"Consequences"},{"location":"DSP-API/05-internals/design/adr/ADR-0006-use-zio-http/","text":"ADR-0006 Use ZIO HTTP Date: 2022-12-01 Status Accepted Context The current routes use the Akka Http library. Because of changes to the licensing of the Akka framework, we want to move away from using Akka Http . This also fits the general strategic decision to use ZIO for the backend. Decision In preparation of the move from Akka to ZIO , it was decided that the routes should be ported to use the ZIO HTTP server / library instead of Akka Http . Consequences In a first step only the routes are going to be ported, one by one, to use ZIO HTTP instead of being routed through Akka Http . The Akka Actor System still remains and will be dealt with later.","title":"0006 Gradually Replace AKKA-HTTP with ZIO-HTTP"},{"location":"DSP-API/05-internals/design/adr/ADR-0006-use-zio-http/#adr-0006-use-zio-http","text":"Date: 2022-12-01","title":"ADR-0006 Use ZIO HTTP"},{"location":"DSP-API/05-internals/design/adr/ADR-0006-use-zio-http/#status","text":"Accepted","title":"Status"},{"location":"DSP-API/05-internals/design/adr/ADR-0006-use-zio-http/#context","text":"The current routes use the Akka Http library. Because of changes to the licensing of the Akka framework, we want to move away from using Akka Http . This also fits the general strategic decision to use ZIO for the backend.","title":"Context"},{"location":"DSP-API/05-internals/design/adr/ADR-0006-use-zio-http/#decision","text":"In preparation of the move from Akka to ZIO , it was decided that the routes should be ported to use the ZIO HTTP server / library instead of Akka Http .","title":"Decision"},{"location":"DSP-API/05-internals/design/adr/ADR-0006-use-zio-http/#consequences","text":"In a first step only the routes are going to be ported, one by one, to use ZIO HTTP instead of being routed through Akka Http . The Akka Actor System still remains and will be dealt with later.","title":"Consequences"},{"location":"DSP-API/05-internals/design/api-admin/administration/","text":"Administration (Users, Projects, Groups, Institutions, Permissions) Scope This Section includes management (creation, updating, deletion) of Users , Projects , Groups , Institutions , and Permissions . Implementation All administration functions will be implemented as part of the Knora API in the webapi codebase. There is also a separate web-application as part of DSP-APP and [DSP-TOOLS]{https://github.com/dasch-swiss/dsp-tools} using this API, allowing basic management operations. Overview During the initial deployment of a Knora server, the main administration user ( root ) is created. This root user has the right to do anything. DSP\u2019s concept of access control is that permissions can only be granted to groups and not to individual users. There are two distinct ways of granting permission. Firstly, an object (a resource or value) can grant permissions to groups of users, and secondly, permissions can be granted directly to a group of users (not bound to a specific object). There are six built-in groups: UnknownUser , KnownUser , Creator , ProjectMember , ProjectAdmin , and SystemAdmin . These groups can be used in the same way as normal user created groups for permission management, i.e. can be used to give certain groups of users, certain permissions, without the need to explicitly create them. A user becomes implicitly a member of such a group by satisfying certain conditions: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:Creator : When checking a user\u2019s permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectMember : When checking a user\u2019s permissions, the user is automatically assigned to this group by being a member of a project designated by the knora-admin:isInProject property. knora-admin:ProjectAdmin : When checking a user's permission, the user is automatically assigned to this group through the knora-admin:isInProjectAdminGroup property, which points to the project in question. knora-admin:SystemAdmin : Membership is received by setting the property knora-admin:isInSystemAdminGroup to true on a knora-admin:User . To use these build-in groups as values for properties (Object Access and Default Permissions), the IRI is constructed by appending the name of the built-in group to knora-admin , e.g., knora-admin:KnownUser where knora-admin corresponds to http://www.knora.org/ontology/knora-admin# . Permissions The permissions API endpoint is described here . The default permissions when a project is created are described here . Up until know, we have mentioned two groups of permissions. The first called object access permissions , which contains permissions that point from explicit objects (resources/values) to groups. The second group of permissions called administrative permissions , and which contains permissions that are put on instances of knora-admin:Permission objects directly affecting groups. There is another, third group of permissions, called default object access permissions which is also put on instances of knora-admin:Permission , and which also directly affect groups. Object Access Permissions An object (resource / value) can grant the following permissions, which are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions : Restricted view permission (RV) : Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) : Allows an unrestricted view of the object. Having view permission on a resource only affects the user\u2019s ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) : For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) : Allows the item to be marked as deleted. Change rights permission (CR) : Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user\u2019s permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember and/or ProjectAdmin if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar (|). For example, if an object grants view permission to unknown and known users , and modify permission to project members , the resulting permission literal would be: : V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember Administrative Permissions The following permissions can be set via instances of knora-admin:AdministrativePermission on any group belonging to a project. For users that are members of a number of groups with administrative permissions attached, the final set of permissions is additive and most permissive. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The following permission values can be used: Resource / Value Creation Permissions: 1) ProjectResourceCreateAllPermission : description: gives the permission to create resources inside the project. usage: used as a value for knora-base:hasPermissions . 2) ProjectResourceCreateRestrictedPermission : description: gives restricted resource creation permission inside the project. usage: used as a value for knora-base:hasPermissions . value: RestrictedProjectResourceCreatePermission followed by a comma-separated list of ResourceClasses the user should only be able to create instances of. Project Administration Permissions: 1) ProjectAdminAllPermission : description: gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ( group info , group membership , resource creation permissions , project administration permissions , and default permissions ). usage: used as a value for knora-base:hasPermissions . 2) ProjectAdminGroupAllPermission : description: gives the user the permission to modify group info and group membership on all groups belonging to the project. usage: used as a value for the knora-base:hasPermissions property. 3) ProjectAdminGroupRestrictedPermission : description: gives the user the permission to modify group info and group membership on certain groups belonging to the project. usage: used as a value for knora-base:hasPermissions value: ProjectGroupAdminRestrictedPermission followed by a comma-separated list of knora-admin:UserGroup . 4) ProjectAdminRightsAllPermission : description: gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). usage: used as a value for the knora-base:hasPermissions property. Ontology Administration Permissions: 1) ProjectAdminOntologyAllPermission : description: gives the user the permission to administrate the project ontologies usage: used as a value for the knora-base:hasPermissions property. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the name given above. Each permission is followed by a space, then if applicable, by a comma separated list of IRIs, as defined above. The IRIs of built-in values (e.g., built-in groups, resource classes, etc.) are shortened using the knora-admin prefix knora-admin: . Multiple permissions are separated by a vertical bar (|). For example, if an administrative permission grants the knora-admin:ProjectMember group the permission to create all resources ( ProjectResourceCreateAllPermission ), the resulting administrative permission object with the compact form literal would be: : <http://rdfh.ch/permissions/001 rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Default Object Access Permissions Default Object Access Permissions are used when new objects (resources and/or values) are created. They represent object access permissions with which the new object will be initially outfitted. As with administrative permissions, these default object access permissions can be defined for any number of groups. Additionally, they can be also defined for resource classes and properties. The following default object access permissions can be attached to groups, resource classes and/or properties via instances of knora-admin:DefaultObjectAccessPermission (described further bellow). The default object access permissions correspond to the earlier described object access permission: Default Restricted View Permission (RV) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: RV followed by a comma-separated list of knora-admin:UserGroup Default View Permission (V) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: V followed by a comma-separated list of knora-admin:UserGroup Default Modify Permission (M) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: M followed by a comma-separated list of knora-admin:UserGroup Default Delete Permission (D) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: D followed by a comma-separated list of knora-admin:UserGroup Default Change Rights Permission (CR) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: CR followed by a comma-separated list of knora-admin:UserGroup A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. Example default object access permission instance: <http://rdfh.ch/permissions/002 rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser\"^^xsd:string . This instance is setting default object access permissions to the project member group of a project, giving change right permission to the creator, modify permission to all project members, and view permission to known users. Further, this implicitly applies to all resource classes and all their properties inside the project. Permission Precedence Rules For both administrative permissions and default object access permissions, the resulting permissions are derived by applying precedence rules, for the case that the user is member of more than one group. The following list is sorted by the permission precedence level in descending order: permissions on knora-admin:ProjectAdmin (highest level) permissions on resource classes and property combination (own project) permissions on resource classes and property combination ( knora-admin:SystemProject ) permissions on resource classes / properties (own project) permissions on resource classes / properties ( knora-admin:SystemProject ) permissions on custom groups permissions on knora-admin:ProjectMember permissions on knora-admin:KnownUser (lowest level) The permissions on resource classes / properties are only relevant for default object access permissions. Administrative Permissions : When a user performs an operation requiring administrative permissions, then only the permissions from the highest level are taken into account. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and all are taken into account. Default Object Access Permissions : When a user creates a resource or value, then only the default object permissions from the highest level are applied. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and the most permissive are applied. In the case of the user belonging to the SystemAdmin group, but which is not member of a project and thus not member of any group belonging to the project, the default object access permissions from the ProjectAdmin , ProjectMember , or KnownUser group will be applied in the order of precedence. If no permissions are defined on either of these groups, then the resulting permission will be CR knora-admin:Creator . Implicit Permissions The knora-admin:SystemAdmin group receives implicitly the following permissions: receives implicitly ProjectAdminAllPermission for all projects. receives implicitly ProjectResourceCreateAllPermission for all projects. receives implicitly CR on all objects from all projects. Theses permissions are baked into the system, and cannot be changed. Default Permissions Matrix for new Projects The access control matrix defines what are the default operations a subject (i.e. User), being a member of a built-in group (represented by row headers), is permitted to perform on an object (represented by column headers). The different operation abbreviations used are defined as follows: C : Create - the subject inside the group is allowed to create the object. U : Update - the subject inside the group is allowed to update the object. R : Read - the subject inside the group is allowed to read all information about the object. D : Delete - the subject inside the group is allowed to delete the object. P : Permission - the subject inside the group is allowed to change the permissions on the object. - : none - none or not applicable Built-In Group Project Group User Resource Value SystemAdmin CRUD CRUDP CRUDP all CRUDP all CRUDP all ProjectAdmin -RUD CRUDP CRUDP +/- project CRUDP (in project) CRUDP (in project) ProjectMember ---- ----- ----- CRU-- (in project) ----- (in project) Creator ---- ----- ----- ----- (his resource) ----- (his value) KnownUser C--- C---- CRUD- himself ----- (in project) ----- (in project) Default Permissions Matrix for new Projects The explicitly defined default permissions for a new project are as follows: knora-admin:ProjectAdmin group: Administrative Permissions: ProjectResourceCreateAllPermission . ProjectAdminAllPermission . Default Object Access Permissions: CR for the knora-admin:ProjectAdmin group D for the knora-admin:ProjectAdmin group M for the knora-admin:ProjectAdmin group V for the knora-admin:ProjectAdmin group RV for the knora-admin:ProjectAdmin group The knora-admin:ProjectMember group: Administrative Permissions: ProjectResourceCreateAllPermission . Default Object Access Permissions: M for the knora-admin:ProjectMember group V for the knora-admin:ProjectMember group RV for the knora-admin:ProjectMember group Basic Workflows involving Permissions Creating a new Resource Accessing a Resource/Value Project / Group Administration Implementation The requirements for defining default permissions imposed by all the different use cases are very broad. Potentially, we need to be able to define default permissions per project, per group, per resource class, per resource property, and all their possible combinations. For this reason, we introduce the knora-admin:Permission class with two sub-classes, namely knora-admin:AdministrativePermission and knora-admin:DefaultObjectAccessPermission , which instances will carry all the necessary information. Permission Class Hierarchy and Structure The following graphs show the class hierarchy and the structure of each permission class. Permission Class Hierarchy Administrative Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectResourceCreateRestrictedPermission \"<Resource Class IRI>\"| ProjectAdminAllPermission| ProjectAdminGroupAllPermission| ProjectAdminGroupRestrictedPermission \"<http://rdfh.ch/groups/[shortcode]/[UUID]>, <http://rdfh.ch/groups/[shortcode]/[UUID]>\"| ProjectAdminRightsAllPermission| ProjectAdminOntologyAllPermission\"^^xsd:string . Default Object Access Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-admin:forResourceClass \"Resource Class Name\" ; knora-admin:forProperty \"Resource Property Name\" ; knora-base:hasPermissions \"RV <http://rdfh.ch/groups/[shortcode]/[UUID]>| V <http://rdfh.ch/groups/[shortcode]/[UUID]>| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| D <http://rdfh.ch/groups/[shortcode]/[UUID]>| CR <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Querying Permission Instances The properties forProject and either of forGroup , forResourceClass , and forProperty form together a compound key , allowing finding existing permission instances, that address the same set of Project / Group / ResourceClass / Property combination, thus making it possible to extend or change the attached permissions. Administrative Permission Instances : For each group inside the project, there can be zero or one instance holding administrative permission information. Querying is straitforward by using the knora-admin:forProject and knora-admin:forGroup properties as the compound key. Default Object Access Permission Instances : For each group, resource class, or property inside the project, there can be zero or one instances holding default object access permission informations. Querying is straitforward by using the knora-admin:forProject and either knora-admin:forGroup , knora-admin:forResourceClass , or knora-admin:forProperty properties as part of the compound key. Example Data stored in the permissions graph Administrative permissions on a 'ProjectAdmin' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectAdmin ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectAdminAllPermission\"^^xsd:string . Administrative permissions on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Administrative permission restricting project admin permission on a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:Permission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectGroupAdminRestrictedPermission <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Administrative permission restricting resource creation for a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateRestrictedPermission <http://www.knora.org/ontology/00FF/images#Person>\"^^xsd:string . Default object access permission on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| V knora-admin:KnownUser\"^^xsd:string . Default object access permission on a resource class: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a resource property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"D knora-admin:ProjectMember,knora-admin:Creator| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^ . Default object access permission on a resource class and property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a knora-admin property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject knora-admin:SystemProject ; knora-admin:forProperty <http://www.knora.org/ontology/knora-admin#hasStillImageFileValue> ; knora-base:hasPermissions \"RV knora-admin:UnknownUser| V knora-admin:KnownUser| M knora-admin:ProjectMember,knora-admin:Creator\"^^xsd:string . A the time the user's UserProfile is queried, all permissions for all projects and groups the user is a member of are also queried. This information is then stored as an easy accessible object inside the UserProfile , being readily available wherever needed. As this is a somewhat expensive operation, built-in caching mechanism at different levels (e.g., UsersResponder, PermissionsResponder), will be applied.","title":"Administration"},{"location":"DSP-API/05-internals/design/api-admin/administration/#administration-users-projects-groups-institutions-permissions","text":"","title":"Administration (Users, Projects, Groups, Institutions, Permissions)"},{"location":"DSP-API/05-internals/design/api-admin/administration/#scope","text":"This Section includes management (creation, updating, deletion) of Users , Projects , Groups , Institutions , and Permissions .","title":"Scope"},{"location":"DSP-API/05-internals/design/api-admin/administration/#implementation","text":"All administration functions will be implemented as part of the Knora API in the webapi codebase. There is also a separate web-application as part of DSP-APP and [DSP-TOOLS]{https://github.com/dasch-swiss/dsp-tools} using this API, allowing basic management operations.","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-admin/administration/#overview","text":"During the initial deployment of a Knora server, the main administration user ( root ) is created. This root user has the right to do anything. DSP\u2019s concept of access control is that permissions can only be granted to groups and not to individual users. There are two distinct ways of granting permission. Firstly, an object (a resource or value) can grant permissions to groups of users, and secondly, permissions can be granted directly to a group of users (not bound to a specific object). There are six built-in groups: UnknownUser , KnownUser , Creator , ProjectMember , ProjectAdmin , and SystemAdmin . These groups can be used in the same way as normal user created groups for permission management, i.e. can be used to give certain groups of users, certain permissions, without the need to explicitly create them. A user becomes implicitly a member of such a group by satisfying certain conditions: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:Creator : When checking a user\u2019s permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectMember : When checking a user\u2019s permissions, the user is automatically assigned to this group by being a member of a project designated by the knora-admin:isInProject property. knora-admin:ProjectAdmin : When checking a user's permission, the user is automatically assigned to this group through the knora-admin:isInProjectAdminGroup property, which points to the project in question. knora-admin:SystemAdmin : Membership is received by setting the property knora-admin:isInSystemAdminGroup to true on a knora-admin:User . To use these build-in groups as values for properties (Object Access and Default Permissions), the IRI is constructed by appending the name of the built-in group to knora-admin , e.g., knora-admin:KnownUser where knora-admin corresponds to http://www.knora.org/ontology/knora-admin# .","title":"Overview"},{"location":"DSP-API/05-internals/design/api-admin/administration/#permissions","text":"The permissions API endpoint is described here . The default permissions when a project is created are described here . Up until know, we have mentioned two groups of permissions. The first called object access permissions , which contains permissions that point from explicit objects (resources/values) to groups. The second group of permissions called administrative permissions , and which contains permissions that are put on instances of knora-admin:Permission objects directly affecting groups. There is another, third group of permissions, called default object access permissions which is also put on instances of knora-admin:Permission , and which also directly affect groups.","title":"Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#object-access-permissions","text":"An object (resource / value) can grant the following permissions, which are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions : Restricted view permission (RV) : Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) : Allows an unrestricted view of the object. Having view permission on a resource only affects the user\u2019s ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) : For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) : Allows the item to be marked as deleted. Change rights permission (CR) : Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user\u2019s permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember and/or ProjectAdmin if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar (|). For example, if an object grants view permission to unknown and known users , and modify permission to project members , the resulting permission literal would be: : V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember","title":"Object Access Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#administrative-permissions","text":"The following permissions can be set via instances of knora-admin:AdministrativePermission on any group belonging to a project. For users that are members of a number of groups with administrative permissions attached, the final set of permissions is additive and most permissive. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The following permission values can be used: Resource / Value Creation Permissions: 1) ProjectResourceCreateAllPermission : description: gives the permission to create resources inside the project. usage: used as a value for knora-base:hasPermissions . 2) ProjectResourceCreateRestrictedPermission : description: gives restricted resource creation permission inside the project. usage: used as a value for knora-base:hasPermissions . value: RestrictedProjectResourceCreatePermission followed by a comma-separated list of ResourceClasses the user should only be able to create instances of. Project Administration Permissions: 1) ProjectAdminAllPermission : description: gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ( group info , group membership , resource creation permissions , project administration permissions , and default permissions ). usage: used as a value for knora-base:hasPermissions . 2) ProjectAdminGroupAllPermission : description: gives the user the permission to modify group info and group membership on all groups belonging to the project. usage: used as a value for the knora-base:hasPermissions property. 3) ProjectAdminGroupRestrictedPermission : description: gives the user the permission to modify group info and group membership on certain groups belonging to the project. usage: used as a value for knora-base:hasPermissions value: ProjectGroupAdminRestrictedPermission followed by a comma-separated list of knora-admin:UserGroup . 4) ProjectAdminRightsAllPermission : description: gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). usage: used as a value for the knora-base:hasPermissions property. Ontology Administration Permissions: 1) ProjectAdminOntologyAllPermission : description: gives the user the permission to administrate the project ontologies usage: used as a value for the knora-base:hasPermissions property. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the name given above. Each permission is followed by a space, then if applicable, by a comma separated list of IRIs, as defined above. The IRIs of built-in values (e.g., built-in groups, resource classes, etc.) are shortened using the knora-admin prefix knora-admin: . Multiple permissions are separated by a vertical bar (|). For example, if an administrative permission grants the knora-admin:ProjectMember group the permission to create all resources ( ProjectResourceCreateAllPermission ), the resulting administrative permission object with the compact form literal would be: : <http://rdfh.ch/permissions/001 rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string .","title":"Administrative Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#default-object-access-permissions","text":"Default Object Access Permissions are used when new objects (resources and/or values) are created. They represent object access permissions with which the new object will be initially outfitted. As with administrative permissions, these default object access permissions can be defined for any number of groups. Additionally, they can be also defined for resource classes and properties. The following default object access permissions can be attached to groups, resource classes and/or properties via instances of knora-admin:DefaultObjectAccessPermission (described further bellow). The default object access permissions correspond to the earlier described object access permission: Default Restricted View Permission (RV) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: RV followed by a comma-separated list of knora-admin:UserGroup Default View Permission (V) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: V followed by a comma-separated list of knora-admin:UserGroup Default Modify Permission (M) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: M followed by a comma-separated list of knora-admin:UserGroup Default Delete Permission (D) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: D followed by a comma-separated list of knora-admin:UserGroup Default Change Rights Permission (CR) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: CR followed by a comma-separated list of knora-admin:UserGroup A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. Example default object access permission instance: <http://rdfh.ch/permissions/002 rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser\"^^xsd:string . This instance is setting default object access permissions to the project member group of a project, giving change right permission to the creator, modify permission to all project members, and view permission to known users. Further, this implicitly applies to all resource classes and all their properties inside the project.","title":"Default Object Access Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#permission-precedence-rules","text":"For both administrative permissions and default object access permissions, the resulting permissions are derived by applying precedence rules, for the case that the user is member of more than one group. The following list is sorted by the permission precedence level in descending order: permissions on knora-admin:ProjectAdmin (highest level) permissions on resource classes and property combination (own project) permissions on resource classes and property combination ( knora-admin:SystemProject ) permissions on resource classes / properties (own project) permissions on resource classes / properties ( knora-admin:SystemProject ) permissions on custom groups permissions on knora-admin:ProjectMember permissions on knora-admin:KnownUser (lowest level) The permissions on resource classes / properties are only relevant for default object access permissions. Administrative Permissions : When a user performs an operation requiring administrative permissions, then only the permissions from the highest level are taken into account. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and all are taken into account. Default Object Access Permissions : When a user creates a resource or value, then only the default object permissions from the highest level are applied. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and the most permissive are applied. In the case of the user belonging to the SystemAdmin group, but which is not member of a project and thus not member of any group belonging to the project, the default object access permissions from the ProjectAdmin , ProjectMember , or KnownUser group will be applied in the order of precedence. If no permissions are defined on either of these groups, then the resulting permission will be CR knora-admin:Creator .","title":"Permission Precedence Rules"},{"location":"DSP-API/05-internals/design/api-admin/administration/#implicit-permissions","text":"The knora-admin:SystemAdmin group receives implicitly the following permissions: receives implicitly ProjectAdminAllPermission for all projects. receives implicitly ProjectResourceCreateAllPermission for all projects. receives implicitly CR on all objects from all projects. Theses permissions are baked into the system, and cannot be changed.","title":"Implicit Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#default-permissions-matrix-for-new-projects","text":"The access control matrix defines what are the default operations a subject (i.e. User), being a member of a built-in group (represented by row headers), is permitted to perform on an object (represented by column headers). The different operation abbreviations used are defined as follows: C : Create - the subject inside the group is allowed to create the object. U : Update - the subject inside the group is allowed to update the object. R : Read - the subject inside the group is allowed to read all information about the object. D : Delete - the subject inside the group is allowed to delete the object. P : Permission - the subject inside the group is allowed to change the permissions on the object. - : none - none or not applicable Built-In Group Project Group User Resource Value SystemAdmin CRUD CRUDP CRUDP all CRUDP all CRUDP all ProjectAdmin -RUD CRUDP CRUDP +/- project CRUDP (in project) CRUDP (in project) ProjectMember ---- ----- ----- CRU-- (in project) ----- (in project) Creator ---- ----- ----- ----- (his resource) ----- (his value) KnownUser C--- C---- CRUD- himself ----- (in project) ----- (in project) Default Permissions Matrix for new Projects The explicitly defined default permissions for a new project are as follows: knora-admin:ProjectAdmin group: Administrative Permissions: ProjectResourceCreateAllPermission . ProjectAdminAllPermission . Default Object Access Permissions: CR for the knora-admin:ProjectAdmin group D for the knora-admin:ProjectAdmin group M for the knora-admin:ProjectAdmin group V for the knora-admin:ProjectAdmin group RV for the knora-admin:ProjectAdmin group The knora-admin:ProjectMember group: Administrative Permissions: ProjectResourceCreateAllPermission . Default Object Access Permissions: M for the knora-admin:ProjectMember group V for the knora-admin:ProjectMember group RV for the knora-admin:ProjectMember group","title":"Default Permissions Matrix for new Projects"},{"location":"DSP-API/05-internals/design/api-admin/administration/#basic-workflows-involving-permissions","text":"","title":"Basic Workflows involving Permissions"},{"location":"DSP-API/05-internals/design/api-admin/administration/#creating-a-new-resource","text":"","title":"Creating a new Resource"},{"location":"DSP-API/05-internals/design/api-admin/administration/#accessing-a-resourcevalue","text":"","title":"Accessing a Resource/Value"},{"location":"DSP-API/05-internals/design/api-admin/administration/#project-group-administration","text":"","title":"Project / Group Administration"},{"location":"DSP-API/05-internals/design/api-admin/administration/#implementation_1","text":"The requirements for defining default permissions imposed by all the different use cases are very broad. Potentially, we need to be able to define default permissions per project, per group, per resource class, per resource property, and all their possible combinations. For this reason, we introduce the knora-admin:Permission class with two sub-classes, namely knora-admin:AdministrativePermission and knora-admin:DefaultObjectAccessPermission , which instances will carry all the necessary information.","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-admin/administration/#permission-class-hierarchy-and-structure","text":"The following graphs show the class hierarchy and the structure of each permission class. Permission Class Hierarchy Administrative Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectResourceCreateRestrictedPermission \"<Resource Class IRI>\"| ProjectAdminAllPermission| ProjectAdminGroupAllPermission| ProjectAdminGroupRestrictedPermission \"<http://rdfh.ch/groups/[shortcode]/[UUID]>, <http://rdfh.ch/groups/[shortcode]/[UUID]>\"| ProjectAdminRightsAllPermission| ProjectAdminOntologyAllPermission\"^^xsd:string . Default Object Access Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-admin:forResourceClass \"Resource Class Name\" ; knora-admin:forProperty \"Resource Property Name\" ; knora-base:hasPermissions \"RV <http://rdfh.ch/groups/[shortcode]/[UUID]>| V <http://rdfh.ch/groups/[shortcode]/[UUID]>| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| D <http://rdfh.ch/groups/[shortcode]/[UUID]>| CR <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string .","title":"Permission Class Hierarchy and Structure"},{"location":"DSP-API/05-internals/design/api-admin/administration/#querying-permission-instances","text":"The properties forProject and either of forGroup , forResourceClass , and forProperty form together a compound key , allowing finding existing permission instances, that address the same set of Project / Group / ResourceClass / Property combination, thus making it possible to extend or change the attached permissions. Administrative Permission Instances : For each group inside the project, there can be zero or one instance holding administrative permission information. Querying is straitforward by using the knora-admin:forProject and knora-admin:forGroup properties as the compound key. Default Object Access Permission Instances : For each group, resource class, or property inside the project, there can be zero or one instances holding default object access permission informations. Querying is straitforward by using the knora-admin:forProject and either knora-admin:forGroup , knora-admin:forResourceClass , or knora-admin:forProperty properties as part of the compound key.","title":"Querying Permission Instances"},{"location":"DSP-API/05-internals/design/api-admin/administration/#example-data-stored-in-the-permissions-graph","text":"Administrative permissions on a 'ProjectAdmin' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectAdmin ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectAdminAllPermission\"^^xsd:string . Administrative permissions on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Administrative permission restricting project admin permission on a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:Permission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectGroupAdminRestrictedPermission <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Administrative permission restricting resource creation for a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateRestrictedPermission <http://www.knora.org/ontology/00FF/images#Person>\"^^xsd:string . Default object access permission on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/00FF> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| V knora-admin:KnownUser\"^^xsd:string . Default object access permission on a resource class: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a resource property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"D knora-admin:ProjectMember,knora-admin:Creator| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^ . Default object access permission on a resource class and property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a knora-admin property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject knora-admin:SystemProject ; knora-admin:forProperty <http://www.knora.org/ontology/knora-admin#hasStillImageFileValue> ; knora-base:hasPermissions \"RV knora-admin:UnknownUser| V knora-admin:KnownUser| M knora-admin:ProjectMember,knora-admin:Creator\"^^xsd:string . A the time the user's UserProfile is queried, all permissions for all projects and groups the user is a member of are also queried. This information is then stored as an easy accessible object inside the UserProfile , being readily available wherever needed. As this is a somewhat expensive operation, built-in caching mechanism at different levels (e.g., UsersResponder, PermissionsResponder), will be applied.","title":"Example Data stored in the permissions graph"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/","text":"How to Add an API v1 Route Write SPARQL templates Add any SPARQL templates you need to src/main/twirl/queries/sparql/v1 , using the Twirl template engine. Write Responder Request and Response Messages Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Response message classes that represent a complete API response must extend KnoraResponseV1 , and must therefore have a toJsValue method that converts the response message to a JSON AST using spray-json . Write a Responder Write a class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v1 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate an object for your responder class. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them to the responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details. Write a Route Add a class to the org.knora.webapi.routing.v1 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV1.runRdfRouteWithFuture to handle the request. Finally, add your knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"How to Add an API v1 Route"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#how-to-add-an-api-v1-route","text":"","title":"How to Add an API v1 Route"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#write-sparql-templates","text":"Add any SPARQL templates you need to src/main/twirl/queries/sparql/v1 , using the Twirl template engine.","title":"Write SPARQL templates"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#write-responder-request-and-response-messages","text":"Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Response message classes that represent a complete API response must extend KnoraResponseV1 , and must therefore have a toJsValue method that converts the response message to a JSON AST using spray-json .","title":"Write Responder Request and Response Messages"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#write-a-responder","text":"Write a class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v1 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate an object for your responder class. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them to the responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details.","title":"Write a Responder"},{"location":"DSP-API/05-internals/design/api-v1/how-to-add-a-route/#write-a-route","text":"Add a class to the org.knora.webapi.routing.v1 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV1.runRdfRouteWithFuture to handle the request. Finally, add your knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"Write a Route"},{"location":"DSP-API/05-internals/design/api-v1/json/","text":"JSON in API v1 DSP-API v1 parses and generates JSON using the spray-json library. The triplestore returns results in JSON, and these are parsed into SparqlSelectResponse objects in the store package (by SparqlUtils , which can be used by any actor in that package). A SparqlSelectResponse has a structure that's very close to the JSON returned by a triplestore via the SPARQL 1.1 Protocol : it contains a header (listing the variables that were used in the query) and a body (containing rows of query results). Each row of query results is represented by a VariableResultsRow , which contains a Map[String, String] of variable names to values. The Jsonable trait marks classes that can convert themselves into spray-json AST objects when you call their toJsValue method; it returns a JsValue object, which can then be converted to text by calling its prettyPrint or compactPrint methods. Case classes representing complete API responses extend the KnoraResponseV1 trait, which extends Jsonable . Case classes representing Knora values extend the ApiValueV1 trait, which also extends Jsonable . To make the responders reusable, the JSON for API responses is generated only at the last moment, by the RouteUtilV1.runJsonRoute() function.","title":"JSON in API v1"},{"location":"DSP-API/05-internals/design/api-v1/json/#json-in-api-v1","text":"DSP-API v1 parses and generates JSON using the spray-json library. The triplestore returns results in JSON, and these are parsed into SparqlSelectResponse objects in the store package (by SparqlUtils , which can be used by any actor in that package). A SparqlSelectResponse has a structure that's very close to the JSON returned by a triplestore via the SPARQL 1.1 Protocol : it contains a header (listing the variables that were used in the query) and a body (containing rows of query results). Each row of query results is represented by a VariableResultsRow , which contains a Map[String, String] of variable names to values. The Jsonable trait marks classes that can convert themselves into spray-json AST objects when you call their toJsValue method; it returns a JsValue object, which can then be converted to text by calling its prettyPrint or compactPrint methods. Case classes representing complete API responses extend the KnoraResponseV1 trait, which extends Jsonable . Case classes representing Knora values extend the ApiValueV1 trait, which also extends Jsonable . To make the responders reusable, the JSON for API responses is generated only at the last moment, by the RouteUtilV1.runJsonRoute() function.","title":"JSON in API v1"},{"location":"DSP-API/05-internals/design/api-v2/ark/","text":"Archival Resource Key (ARK) Identifiers Requirements Knora must produce an ARK URL for each resource and each value. The ARK identifiers used by Knora must respect the draft ARK specification . The format of Knora\u2019s ARK URLs must be able to change over time, while ensuring that previously generated ARK URLs still work. Design ARK URL Format The format of a Knora ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[/VALUE_UUID][.TIMESTAMP] HOST : the hostname of the ARK resolver. NAAN : the Name Assigning Authority Number (NAAN) that the ARK resolver uses. VERSION : the version of the Knora ARK URL format being used (always 1 for now). PROJECT : the short code of the project that the resource belongs to. RESOURCE_UUID : the resource's unique ID, which is normally a base64url-encoded UUID, as described in IRIs for Data . VALUE_UUID : optionally, the knora-base:valueHasUUID of one of the resource's values, normally a base64url-encoded UUID, as described in IRIs for Data . TIMESTAMP : an optional timestamp indicating that the ARK URL represents the state of the resource at a specific time in the past. The format of the timestamp is an ISO 8601 date in Coordinated universal time (UTC), including date, time, and an optional nano-of-second field (of at most 9 digits), without the characters - , : , and . (because - and . are reserved characters in ARK, and : would have to be URL-encoded). Example: 20180528T155203897Z . Following the ARK ID spec, / represents object hierarchy and . represents an object variant . A value is thus contained in a resource, which is contained in its project, which is contained in a repository (represented by the URL version number). A timestamp is a type of variant. Since sub-objects are optional, there is also implicitly an ARK URL for each project, as well as for the repository as a whole. The RESOURCE_UUID and VALUE_UUID are processed as follows: A check digit is calculated, using the algorithm in the Scala class org.knora.webapi.util.Base64UrlCheckDigit , and appended to the UUID. Any - characters in the resulting string are replaced with = , because base64url encoding uses - , which is a reserved character in ARK URLs. For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 Given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180528T155203897Z Given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Serving ARK URLs SmartIri converts Knora resource IRIs to ARK URLs. This conversion is invoked in ReadResourceV2.toJsonLD , when returning a resource's metadata in JSON-LD format. Resolving Knora ARK URLs A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Archival Resource Key (ARK)"},{"location":"DSP-API/05-internals/design/api-v2/ark/#archival-resource-key-ark-identifiers","text":"","title":"Archival Resource Key (ARK) Identifiers"},{"location":"DSP-API/05-internals/design/api-v2/ark/#requirements","text":"Knora must produce an ARK URL for each resource and each value. The ARK identifiers used by Knora must respect the draft ARK specification . The format of Knora\u2019s ARK URLs must be able to change over time, while ensuring that previously generated ARK URLs still work.","title":"Requirements"},{"location":"DSP-API/05-internals/design/api-v2/ark/#design","text":"","title":"Design"},{"location":"DSP-API/05-internals/design/api-v2/ark/#ark-url-format","text":"The format of a Knora ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[/VALUE_UUID][.TIMESTAMP] HOST : the hostname of the ARK resolver. NAAN : the Name Assigning Authority Number (NAAN) that the ARK resolver uses. VERSION : the version of the Knora ARK URL format being used (always 1 for now). PROJECT : the short code of the project that the resource belongs to. RESOURCE_UUID : the resource's unique ID, which is normally a base64url-encoded UUID, as described in IRIs for Data . VALUE_UUID : optionally, the knora-base:valueHasUUID of one of the resource's values, normally a base64url-encoded UUID, as described in IRIs for Data . TIMESTAMP : an optional timestamp indicating that the ARK URL represents the state of the resource at a specific time in the past. The format of the timestamp is an ISO 8601 date in Coordinated universal time (UTC), including date, time, and an optional nano-of-second field (of at most 9 digits), without the characters - , : , and . (because - and . are reserved characters in ARK, and : would have to be URL-encoded). Example: 20180528T155203897Z . Following the ARK ID spec, / represents object hierarchy and . represents an object variant . A value is thus contained in a resource, which is contained in its project, which is contained in a repository (represented by the URL version number). A timestamp is a type of variant. Since sub-objects are optional, there is also implicitly an ARK URL for each project, as well as for the repository as a whole. The RESOURCE_UUID and VALUE_UUID are processed as follows: A check digit is calculated, using the algorithm in the Scala class org.knora.webapi.util.Base64UrlCheckDigit , and appended to the UUID. Any - characters in the resulting string are replaced with = , because base64url encoding uses - , which is a reserved character in ARK URLs. For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 Given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180528T155203897Z Given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z","title":"ARK URL Format"},{"location":"DSP-API/05-internals/design/api-v2/ark/#serving-ark-urls","text":"SmartIri converts Knora resource IRIs to ARK URLs. This conversion is invoked in ReadResourceV2.toJsonLD , when returning a resource's metadata in JSON-LD format.","title":"Serving ARK URLs"},{"location":"DSP-API/05-internals/design/api-v2/ark/#resolving-knora-ark-urls","text":"A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Resolving Knora ARK URLs"},{"location":"DSP-API/05-internals/design/api-v2/content-wrappers/","text":"Content Wrappers Whenever possible, the same data structures are used to represent the same types of data, regardless of the API operation (reading, creating, or modifying). However, often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. The implementation of API v2 therefore uses content wrappers. For each type, there is a case class that represents the lowest common denominator of the type, the data that will be present regardless of the API operation. For example, the trait ValueContentV2 represents a Knora value, regardless of whether it is received as input or returned as output. Case classes such as DateValueContentV2 and TextValueContentV2 implement this trait. An instance of this lowest-common-denominator class, or \"content class\", can then be wrapped in an instance of an operation-specific class that carries additional data. For example, when a Knora value is returned from the triplestore, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A read wrapper can be wrapped in another read wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. In general, DSP-API v2 responders deal only with the internal schema. (The exception is OntologyResponderV2 , which can return ontology information that exists only in an external schema.) Therefore, a content class needs to be able to convert itself from the internal schema to an external schema (when it is being used for output) and vice versa (when it is being used for input). Each content class class should therefore extend KnoraContentV2 , and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction: /** * A trait for content classes that can convert themselves between internal and internal schemas. * * @tparam C the type of the content class that extends this trait. */ trait KnoraContentV2[C <: KnoraContentV2[C]] { this: C => def toOntologySchema(targetSchema: OntologySchema): C } Since read wrappers are used only for output, they need to be able convert themselves only from the internal schema to an external schema. Each read wrapper class should extend KnoraReadV2 , and thus have a method for doing this: /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C }","title":"Content Wrappers"},{"location":"DSP-API/05-internals/design/api-v2/content-wrappers/#content-wrappers","text":"Whenever possible, the same data structures are used to represent the same types of data, regardless of the API operation (reading, creating, or modifying). However, often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. The implementation of API v2 therefore uses content wrappers. For each type, there is a case class that represents the lowest common denominator of the type, the data that will be present regardless of the API operation. For example, the trait ValueContentV2 represents a Knora value, regardless of whether it is received as input or returned as output. Case classes such as DateValueContentV2 and TextValueContentV2 implement this trait. An instance of this lowest-common-denominator class, or \"content class\", can then be wrapped in an instance of an operation-specific class that carries additional data. For example, when a Knora value is returned from the triplestore, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A read wrapper can be wrapped in another read wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. In general, DSP-API v2 responders deal only with the internal schema. (The exception is OntologyResponderV2 , which can return ontology information that exists only in an external schema.) Therefore, a content class needs to be able to convert itself from the internal schema to an external schema (when it is being used for output) and vice versa (when it is being used for input). Each content class class should therefore extend KnoraContentV2 , and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction: /** * A trait for content classes that can convert themselves between internal and internal schemas. * * @tparam C the type of the content class that extends this trait. */ trait KnoraContentV2[C <: KnoraContentV2[C]] { this: C => def toOntologySchema(targetSchema: OntologySchema): C } Since read wrappers are used only for output, they need to be able convert themselves only from the internal schema to an external schema. Each read wrapper class should extend KnoraReadV2 , and thus have a method for doing this: /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C }","title":"Content Wrappers"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/","text":"Gravsearch Design For a detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data . Gravsearch Package The classes that process Gravsearch queries and results can be found in org.knora.webapi.messages.util.search.gravsearch . Type Inspection The code that converts Gravserch queries into SPARQL queries, and processes the query results, needs to know the types of the entities that are used in the input query. As explained in Type Inference , these types can be inferred, or they can be specified in the query using type annotations. Type inspection is implemented in the package org.knora.webapi.messages.util.search.gravsearch.types . The entry point to this package is GravsearchTypeInspectionRunner , which is instantiated by SearchResponderV2 . The result of type inspection is a GravsearchTypeInspectionResult , in which each typeable entity in the input query is associated with a GravsearchEntityTypeInfo , which can be either: A PropertyTypeInfo , which specifies the type of object that a property is expected to have. A NonPropertyTypeInfo , which specifies the type of a variable, or the type of an IRI representing a resource or value. Identifying Typeable Entities After parsing a Gravsearch query, SearchResponderV2 calls GravsearchTypeInspectionRunner.inspectTypes , passing the WHERE clause of the input query. This method first identifies the entities whose types need to be determined. Each of these entities is represented as a TypeableEntity . To do this, GravsearchTypeInspectionRunner uses QueryTraverser to traverse the WHERE clause, collecting typeable entities in a visitor called TypeableEntityCollectingWhereVisitor . The entities that are considered to need type information are: All variables. All IRIs except for those that represent type annotations or types. The Type Inspection Pipeline GravsearchTypeInspectionRunner contains a pipeline of type inspectors, each of which extends GravsearchTypeInspector . There are two type inspectors in the pipeline: AnnotationReadingGravsearchTypeInspector : reads type annotations included in a Gravsearch query. InferringGravsearchTypeInspector : infers the types of entities from the context in which they are used, as well as from ontology information that it requests from OntologyResponderV2 . Each type inspector takes as input, and returns as output, an IntermediateTypeInspectionResult , which associates each TypeableEntity with zero or more types. Initially, each TypeableEntity has no types. Each type inspector adds whatever types it finds for each entity. At the end of the pipeline, each entity should have exactly one type. Therefore, to only keep the most specific type for an entity, the method refineDeterminedTypes refines the determined types by removing those that are base classes of others. However, it can be that inconsistent types are determined for entities. For example, in cases where multiple resource class types are determined, but one is not a base class of the others. From the following statement { ?document a beol:manuscript . } UNION { ?document a beol:letter .} two inconsistent types can be inferred for ?document : beol:letter and beol:manuscript . In these cases, a sanitizer sanitizeInconsistentResourceTypes replaces the inconsistent resource types by their common base resource class (in the above example, it would be beol:writtenSource ). Lastly, an error is returned if An entity's type could not be determined. The client must add a type annotation to make the query work. Inconsistent types could not be sanitized (an entity appears to have more than one type). The client must correct the query. If there are no errors, GravsearchTypeInspectionRunner converts the pipeline's output to a GravsearchTypeInspectionResult , in which each entity is associated with exactly one type. AnnotationReadingGravsearchTypeInspector This inspector uses QueryTraverser to traverse the WHERE clause, collecting type annotations in a visitor called AnnotationCollectingWhereVisitor . It then converts each annotation to a GravsearchEntityTypeInfo . InferringGravsearchTypeInspector This inspector first uses QueryTraverser to traverse the WHERE clause, assembling an index of usage information about typeable entities in a visitor called UsageIndexCollectingWhereVisitor . The UsageIndex contains, for example, an index of all the entities that are used as subjects, predicates, or objects, along with the statements in which they are used. It also contains sets of all the Knora class and property IRIs that are used in the WHERE clause. InferringGravsearchTypeInspector then asks OntologyResponderV2 for information about those classes and properties, as well as about the classes that are subject types or object types of those properties. Next, the inspector runs inference rules (which extend InferenceRule ) on each TypeableEntity . Each rule takes as input a TypeableEntity , the usage index, the ontology information, and the IntermediateTypeInspectionResult , and returns a new IntermediateTypeInspectionResult . For example, TypeOfObjectFromPropertyRule infers an entity's type if the entity is used as the object of a statement and the predicate's knora-api:objectType is known. For each TypeableEntity , if a type is inferred from a property, the entity and the inferred type are added to IntermediateTypeInspectionResult.entitiesInferredFromProperty . The inference rules are run repeatedly, because the output of one rule may allow another rule to infer additional information. There are two pipelines of rules: a pipeline for the first iteration of type inference, and a pipeline for subsequent iterations. This is because some rules can return additional information if they are run more than once on the same entity, while others cannot. The number of iterations is limited to InferringGravsearchTypeInspector.MAX_ITERATIONS , but in practice two iterations are sufficient for most realistic queries, and it is difficult to design a query that requires more than six iterations. Transformation of a Gravsearch Query A Gravsearch query submitted by the client is parsed by GravsearchParser and preprocessed by GravsearchTypeInspector to get type information about the elements used in the query (resources, values, properties etc.) and do some basic sanity checks. In SearchResponderV2 , two queries are generated from a given Gravsearch query: a prequery and a main query. Query Transformers The Gravsearch query is passed to QueryTraverser along with a query transformer. Query transformers are classes that implement traits supported by QueryTraverser : WhereTransformer : instructions how to convert statements in the WHERE clause of a SPARQL query (to generate the prequery's Where clause). To improve query performance, this trait defines the method optimiseQueryPatterns whose implementation can call private methods to optimise the generated SPARQL. For example, before transformation of statements in WHERE clause, query pattern orders must be optimised by moving LuceneQueryPatterns to the beginning and isDeleted statement patterns to the end of the WHERE clause. ConstructToSelectTransformer (extends WhereTransformer ): instructions how to turn a Construct query into a Select query (converts a Gravsearch query into a prequery) SelectToSelectTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Select query into a triplestore dependent Select query (implementation of inference). ConstructToConstructTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Construct query into a triplestore dependent Construct query (implementation of inference). The traits listed above define methods that are implemented in the transformer classes and called by QueryTraverser to perform SPARQL to SPARQL conversions. When iterating over the statements of the input query, the transformer class' transformation methods are called to perform the conversion. Prequery The purpose of the prequery is to get an ordered collection of results representing only the IRIs of one page of matching resources and values. Sort criteria can be submitted by the user, but the result is always deterministic also without sort criteria. This is necessary to support paging. A prequery is a SPARQL SELECT query. The classes involved in generating prequeries can be found in org.knora.webapi.messages.util.search.gravsearch.prequery . If the client submits a count query, the prequery returns the overall number of hits, but not the results themselves. In a first step, before transforming the WHERE clause, query patterns must be further optimised by removing the rdfs:type statement for entities whose type could be inferred from their use with a property IRI, since there would be no need for explicit rdfs:type statements for them (unless the property IRI from which the type of an entity must be inferred from is wrapped in an OPTIONAL block). This optimisation takes the Gravsearch query as input (rather than the generated SPARQL), because it uses type information that refers to entities in the Gravsearch query, and the generated SPARQL might have different entities. Next, the Gravsearch query's WHERE clause is transformed and the prequery (SELECT and WHERE clause) is generated from this result. The transformation of the Gravsearch query's WHERE clause relies on the implementation of the abstract class AbstractPrequeryGenerator . AbstractPrequeryGenerator contains members whose state is changed during the iteration over the statements of the input query. They can then be used to create the converted query. mainResourceVariable: Option[QueryVariable] : SPARQL variable representing the main resource of the input query. Present in the prequery's SELECT clause. dependentResourceVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing dependent resources in the input query. Used in an aggregation function in the prequery's SELECT clause (see below). dependentResourceVariablesGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of dependent resources. Present in the prequery's SELECT clause. valueObjectVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing value objects. Used in an aggregation function in the prequery's SELECT clause (see below). valueObjectVarsGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of value objects. Present in the prequery's SELECT clause. The variables mentioned above are present in the prequery's result rows because they are part of the prequery's SELECT clause. The following example illustrates the handling of variables. The following Gravsearch query looks for pages with a sequence number of 10 that are part of a book: PREFIX incunabula : <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api : <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?page knora-api : isMainResource true . ?page knora-api : isPartOf ?book . ?page incunabula : seqnum ?seqnum . } WHERE { ?page a incunabula : page . ?page knora-api : isPartOf ?book . ?book a incunabula : book . ?page incunabula : seqnum ?seqnum . FILTER ( ?seqnum = 10 ) } The prequery's SELECT clause is built by NonTriplestoreSpecificGravsearchToPrequeryTransformer.getSelectColumns , based on the variables used in the input query's CONSTRUCT clause. The resulting SELECT clause looks as follows: SELECT DISTINCT ?page ( GROUP_CONCAT ( DISTINCT ( IF ( BOUND ( ?book ), STR ( ?book ), \"\" )); SEPARATOR = '' ) AS ?book__Concat ) ( GROUP_CONCAT ( DISTINCT ( IF ( BOUND ( ?seqnum ), STR ( ?seqnum ), \"\" )); SEPARATOR = '' ) AS ?seqnum__Concat ) ( GROUP_CONCAT ( DISTINCT ( IF ( BOUND ( ?book__LinkValue ), STR ( ?book__LinkValue ), \"\" )); SEPARATOR = '' ) AS ?book__LinkValue__Concat ) WHERE {...} GROUP BY ?page ORDER BY ASC ( ?page ) LIMIT 25 ?page represents the main resource. When accessing the prequery's result rows, ?page contains the IRI of the main resource. The prequery's results are grouped by the main resource so that there is exactly one result row per matching main resource. ?page is also used as a sort criterion although none has been defined in the input query. This is necessary to make paging work: results always have to be returned in the same order (the prequery is always deterministic). Like this, results can be fetched page by page using LIMIT and OFFSET. Grouping by main resource requires other results to be aggregated using the function GROUP_CONCAT . ?book is used as an argument of the aggregation function. The aggregation's result is accessible in the prequery's result rows as ?book__Concat . The variable ?book is bound to an IRI. Since more than one IRI could be bound to a variable representing a dependent resource, the results have to be aggregated. GROUP_CONCAT takes two arguments: a collection of strings (IRIs in our use case) and a separator (we use the non-printing Unicode character INFORMATION SEPARATOR ONE ). When accessing ?book__Concat in the prequery's results containing the IRIs of dependent resources, the string has to be split with the separator used in the aggregation function. The result is a collection of IRIs representing dependent resources. The same logic applies to value objects. Each GROUP_CONCAT checks whether the concatenated variable is bound in each result in the group; if a variable is unbound, we concatenate an empty string. This is necessary because, in Apache Jena (and perhaps other triplestores), \"If GROUP_CONCAT has an unbound value in the list of values to concat, the overall result is 'error'\" (see this Jena issue ). If the input query contains a UNION , and a variable is bound in one branch of the UNION and not in another branch, it is possible that the prequery will return more than one row per main resource. To deal with this situation, SearchResponderV2 merges rows that contain the same main resource IRI. Main Query The purpose of the main query is to get all requested information about the main resource, dependent resources, and value objects. The IRIs of those resources and value objects were returned by the prequery. Since the prequery only returns resources and value objects matching the input query's criteria, the main query can specifically ask for more detailed information on these resources and values without having to reconsider these criteria. Generating the Main Query The classes involved in generating the main query can be found in org.knora.webapi.messages.util.search.gravsearch.mainquery . The main query is a SPARQL CONSTRUCT query. Its generation is handled by the method GravsearchMainQueryGenerator.createMainQuery . It takes three arguments: mainResourceIris: Set[IriRef], dependentResourceIris: Set[IriRef], valueObjectIris: Set[IRI] . These sets are constructed based on information about variables representing dependent resources and value objects in the prequery, which is provided by NonTriplestoreSpecificGravsearchToPrequeryTransformer : dependentResourceVariablesGroupConcat : Set(QueryVariable(book__Concat)) valueObjectVariablesGroupConcat : Set(QueryVariable(seqnum__Concat), QueryVariable(book__LinkValue__Concat)) From the given Iris, statements are generated that ask for complete information on exactly these resources and values. For any given resource Iri, only the values present in valueObjectIris are to be queried. This is achieved by using SPARQL's VALUES expression for the main resource and dependent resources as well as for values. Processing the Main Query's results To do the permission checking, the results of the main query are passed to ConstructResponseUtilV2.splitMainResourcesAndValueRdfData , which transforms a SparqlConstructResponse (a set of RDF triples) into a structure organized by main resource Iris. In this structure, dependent resources and values are nested and can be accessed via their main resource, and resources and values that the user does not have permission to see are filtered out. As a result, a page of results may contain fewer than the maximum allowed number of results per page, even if more pages of results are available. MainQueryResultProcessor.getRequestedValuesFromResultsWithFullGraphPattern then filters out values that the user did not explicitly ask for in the input query. Finally, ConstructResponseUtilV2.createApiResponse transforms the query results into an API response (a ReadResourcesSequenceV2 ). If the number of main resources found (even if filtered out because of permissions) is equal to the maximum allowed page size, the predicate knora-api:mayHaveMoreResults: true is included in the response. Inference Gravsearch queries support a subset of RDFS reasoning (see Inference in the API documentation on Gravsearch). This is implemented as follows: To simulate RDF inference, the API expands the prequery on basis of the available ontologies. For that reason, SparqlTransformer.transformStatementInWhereForNoInference expands all rdfs:subClassOf and rdfs:subPropertyOf statements using UNION statements for all subclasses and subproperties from the ontologies (equivalent to rdfs:subClassOf* and rdfs:subPropertyOf* ). Similarly, SparqlTransformer.transformStatementInWhereForNoInference replaces knora-api:standoffTagHasStartAncestor with knora-base:standoffTagHasStartParent* . Optimisation of generated SPARQL The triplestore-specific transformers in SparqlTransformer.scala can run optimisations on the generated SPARQL, in the method optimiseQueryPatterns inherited from WhereTransformer . For example, moveLuceneToBeginning moves Lucene queries to the beginning of the block in which they occur. Query Optimization by Topological Sorting of Statements In Jena Fuseki, the performance of a query highly depends on the order of the query statements. For example, a query such as the one below: PREFIX beol : <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api : isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol : creationDate ?date . } WHERE { ?letter beol : creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER ( ?linkingProp1 = beol : hasAuthor || ?linkingProp1 = beol : hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER ( ?linkingProp2 = beol : hasAuthor || ?linkingProp2 = beol : hasRecipient ) ?person1 beol : hasIAFIdentifier ?gnd1 . ?gnd1 knora-api : valueAsString \"(DE-588)118531379\" . ?person2 beol : hasIAFIdentifier ?gnd2 . ?gnd2 knora-api : valueAsString \"(DE-588)118696149\" . } ORDER BY ?date takes a very long time with Fuseki. The performance of this query can be improved by moving up the statements with literal objects that are not dependent on any other statement: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the query then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date . Since users cannot be expected to know about performance of triplestores in order to write efficient queries, an optimization method to automatically rearrange the statements of the given queries has been implemented. Upon receiving the Gravsearch query, the algorithm converts the query to a graph. For each statement pattern, the subject of the statement is the origin node, the predicate is a directed edge, and the object is the target node. For the query above, this conversion would result in the following graph: The Graph for Scala library is used to construct the graph and sort it using Kahn's topological sorting algorithm . The algorithm returns the nodes of the graph ordered in several layers, where the root element ?letter is in layer 0, [?date, ?person1, ?person2] are in layer 1, [?gnd1, ?gnd2] in layer 2, and the leaf nodes [(DE-588)118531379, (DE-588)118696149] are given in the last layer (i.e. layer 3). According to Kahn's algorithm, there are multiple valid permutations of the topological order. The graph in the example above has 24 valid permutations of topological order. Here are two of them (nodes are ordered from left to right with the highest order to the lowest): (?letter, ?date, ?person2, ?person1, ?gnd2, ?gnd1, (DE-588)118696149, (DE-588)118531379) (?letter, ?date, ?person1, ?person2, ?gnd1, ?gnd2, (DE-588)118531379, (DE-588)118696149) . From all valid topological orders, one is chosen based on certain criteria; for example, the leaf node should not belong to a statement that has predicate rdf:type , since that could match all resources of the specified type. Once the best order is chosen, it is used to re-arrange the query statements. Starting from the last leaf node, i.e. (DE-588)118696149 , the method finds the statement pattern which has this node as its object, and brings this statement to the top of the query. This rearrangement continues so that the statements with the fewest dependencies on other statements are all brought to the top of the query. The resulting query is as follows: PREFIX beol : <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api : isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol : creationDate ?date . } WHERE { ?gnd2 knora-api : valueAsString \"(DE-588)118696149\" . ?gnd1 knora-api : valueAsString \"(DE-588)118531379\" . ?person2 beol : hasIAFIdentifier ?gnd2 . ?person1 beol : hasIAFIdentifier ?gnd1 . ?letter ?linkingProp2 ?person2 . ?letter ?linkingProp1 ?person1 . ?letter beol : creationDate ?date . FILTER ( ?linkingProp1 = beol : hasAuthor || ?linkingProp1 = beol : hasRecipient ) FILTER ( ?linkingProp2 = beol : hasAuthor || ?linkingProp2 = beol : hasRecipient ) } ORDER BY ?date Note that position of the FILTER statements does not play a significant role in the optimization. If a Gravsearch query contains statements in UNION , OPTIONAL , MINUS , or FILTER NOT EXISTS , they are reordered by defining a graph per block. For example, consider the following query with UNION : { ?thing anything : hasRichtext ?richtext . FILTER knora-api : matchText ( ?richtext , \"test\" ) ?thing anything : hasInteger ?int . ?int knora-api : intValueAsInt 1 . } UNION { ?thing anything : hasText ?text . FILTER knora-api : matchText ( ?text , \"test\" ) ?thing anything : hasInteger ?int . ?int knora-api : intValueAsInt 3 . } This would result in one graph per block of the UNION . Each graph is then sorted, and the statements of its block are rearranged according to the topological order of graph. This is the result: { ?int knora-api : intValueAsInt 1 . ?thing anything : hasRichtext ?richtext . ?thing anything : hasInteger ?int . FILTER ( knora-api : matchText ( ?richtext , \"test\" )) } UNION { ?int knora-api : intValueAsInt 3 . ?thing anything : hasText ?text . ?thing anything : hasInteger ?int . FILTER ( knora-api : matchText ( ?text , \"test\" )) } Cyclic Graphs The topological sorting algorithm can only be used for DAGs (directed acyclic graphs). However, a Gravsearch query can contains statements that result in a cyclic graph, e.g.: PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . } WHERE { ?thing anything:hasOtherThing ?thing1 . ?thing1 anything:hasOtherThing ?thing2 . ?thing2 anything:hasOtherThing ?thing . In this case, the algorithm tries to break the cycles in order to sort the graph. If this is not possible, the query statements are not reordered.","title":"Gravsearch Design"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#gravsearch-design","text":"For a detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data .","title":"Gravsearch Design"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#gravsearch-package","text":"The classes that process Gravsearch queries and results can be found in org.knora.webapi.messages.util.search.gravsearch .","title":"Gravsearch Package"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#type-inspection","text":"The code that converts Gravserch queries into SPARQL queries, and processes the query results, needs to know the types of the entities that are used in the input query. As explained in Type Inference , these types can be inferred, or they can be specified in the query using type annotations. Type inspection is implemented in the package org.knora.webapi.messages.util.search.gravsearch.types . The entry point to this package is GravsearchTypeInspectionRunner , which is instantiated by SearchResponderV2 . The result of type inspection is a GravsearchTypeInspectionResult , in which each typeable entity in the input query is associated with a GravsearchEntityTypeInfo , which can be either: A PropertyTypeInfo , which specifies the type of object that a property is expected to have. A NonPropertyTypeInfo , which specifies the type of a variable, or the type of an IRI representing a resource or value.","title":"Type Inspection"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#identifying-typeable-entities","text":"After parsing a Gravsearch query, SearchResponderV2 calls GravsearchTypeInspectionRunner.inspectTypes , passing the WHERE clause of the input query. This method first identifies the entities whose types need to be determined. Each of these entities is represented as a TypeableEntity . To do this, GravsearchTypeInspectionRunner uses QueryTraverser to traverse the WHERE clause, collecting typeable entities in a visitor called TypeableEntityCollectingWhereVisitor . The entities that are considered to need type information are: All variables. All IRIs except for those that represent type annotations or types.","title":"Identifying Typeable Entities"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#the-type-inspection-pipeline","text":"GravsearchTypeInspectionRunner contains a pipeline of type inspectors, each of which extends GravsearchTypeInspector . There are two type inspectors in the pipeline: AnnotationReadingGravsearchTypeInspector : reads type annotations included in a Gravsearch query. InferringGravsearchTypeInspector : infers the types of entities from the context in which they are used, as well as from ontology information that it requests from OntologyResponderV2 . Each type inspector takes as input, and returns as output, an IntermediateTypeInspectionResult , which associates each TypeableEntity with zero or more types. Initially, each TypeableEntity has no types. Each type inspector adds whatever types it finds for each entity. At the end of the pipeline, each entity should have exactly one type. Therefore, to only keep the most specific type for an entity, the method refineDeterminedTypes refines the determined types by removing those that are base classes of others. However, it can be that inconsistent types are determined for entities. For example, in cases where multiple resource class types are determined, but one is not a base class of the others. From the following statement { ?document a beol:manuscript . } UNION { ?document a beol:letter .} two inconsistent types can be inferred for ?document : beol:letter and beol:manuscript . In these cases, a sanitizer sanitizeInconsistentResourceTypes replaces the inconsistent resource types by their common base resource class (in the above example, it would be beol:writtenSource ). Lastly, an error is returned if An entity's type could not be determined. The client must add a type annotation to make the query work. Inconsistent types could not be sanitized (an entity appears to have more than one type). The client must correct the query. If there are no errors, GravsearchTypeInspectionRunner converts the pipeline's output to a GravsearchTypeInspectionResult , in which each entity is associated with exactly one type.","title":"The Type Inspection Pipeline"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#annotationreadinggravsearchtypeinspector","text":"This inspector uses QueryTraverser to traverse the WHERE clause, collecting type annotations in a visitor called AnnotationCollectingWhereVisitor . It then converts each annotation to a GravsearchEntityTypeInfo .","title":"AnnotationReadingGravsearchTypeInspector"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#inferringgravsearchtypeinspector","text":"This inspector first uses QueryTraverser to traverse the WHERE clause, assembling an index of usage information about typeable entities in a visitor called UsageIndexCollectingWhereVisitor . The UsageIndex contains, for example, an index of all the entities that are used as subjects, predicates, or objects, along with the statements in which they are used. It also contains sets of all the Knora class and property IRIs that are used in the WHERE clause. InferringGravsearchTypeInspector then asks OntologyResponderV2 for information about those classes and properties, as well as about the classes that are subject types or object types of those properties. Next, the inspector runs inference rules (which extend InferenceRule ) on each TypeableEntity . Each rule takes as input a TypeableEntity , the usage index, the ontology information, and the IntermediateTypeInspectionResult , and returns a new IntermediateTypeInspectionResult . For example, TypeOfObjectFromPropertyRule infers an entity's type if the entity is used as the object of a statement and the predicate's knora-api:objectType is known. For each TypeableEntity , if a type is inferred from a property, the entity and the inferred type are added to IntermediateTypeInspectionResult.entitiesInferredFromProperty . The inference rules are run repeatedly, because the output of one rule may allow another rule to infer additional information. There are two pipelines of rules: a pipeline for the first iteration of type inference, and a pipeline for subsequent iterations. This is because some rules can return additional information if they are run more than once on the same entity, while others cannot. The number of iterations is limited to InferringGravsearchTypeInspector.MAX_ITERATIONS , but in practice two iterations are sufficient for most realistic queries, and it is difficult to design a query that requires more than six iterations.","title":"InferringGravsearchTypeInspector"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#transformation-of-a-gravsearch-query","text":"A Gravsearch query submitted by the client is parsed by GravsearchParser and preprocessed by GravsearchTypeInspector to get type information about the elements used in the query (resources, values, properties etc.) and do some basic sanity checks. In SearchResponderV2 , two queries are generated from a given Gravsearch query: a prequery and a main query.","title":"Transformation of a Gravsearch Query"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#query-transformers","text":"The Gravsearch query is passed to QueryTraverser along with a query transformer. Query transformers are classes that implement traits supported by QueryTraverser : WhereTransformer : instructions how to convert statements in the WHERE clause of a SPARQL query (to generate the prequery's Where clause). To improve query performance, this trait defines the method optimiseQueryPatterns whose implementation can call private methods to optimise the generated SPARQL. For example, before transformation of statements in WHERE clause, query pattern orders must be optimised by moving LuceneQueryPatterns to the beginning and isDeleted statement patterns to the end of the WHERE clause. ConstructToSelectTransformer (extends WhereTransformer ): instructions how to turn a Construct query into a Select query (converts a Gravsearch query into a prequery) SelectToSelectTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Select query into a triplestore dependent Select query (implementation of inference). ConstructToConstructTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Construct query into a triplestore dependent Construct query (implementation of inference). The traits listed above define methods that are implemented in the transformer classes and called by QueryTraverser to perform SPARQL to SPARQL conversions. When iterating over the statements of the input query, the transformer class' transformation methods are called to perform the conversion.","title":"Query Transformers"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#prequery","text":"The purpose of the prequery is to get an ordered collection of results representing only the IRIs of one page of matching resources and values. Sort criteria can be submitted by the user, but the result is always deterministic also without sort criteria. This is necessary to support paging. A prequery is a SPARQL SELECT query. The classes involved in generating prequeries can be found in org.knora.webapi.messages.util.search.gravsearch.prequery . If the client submits a count query, the prequery returns the overall number of hits, but not the results themselves. In a first step, before transforming the WHERE clause, query patterns must be further optimised by removing the rdfs:type statement for entities whose type could be inferred from their use with a property IRI, since there would be no need for explicit rdfs:type statements for them (unless the property IRI from which the type of an entity must be inferred from is wrapped in an OPTIONAL block). This optimisation takes the Gravsearch query as input (rather than the generated SPARQL), because it uses type information that refers to entities in the Gravsearch query, and the generated SPARQL might have different entities. Next, the Gravsearch query's WHERE clause is transformed and the prequery (SELECT and WHERE clause) is generated from this result. The transformation of the Gravsearch query's WHERE clause relies on the implementation of the abstract class AbstractPrequeryGenerator . AbstractPrequeryGenerator contains members whose state is changed during the iteration over the statements of the input query. They can then be used to create the converted query. mainResourceVariable: Option[QueryVariable] : SPARQL variable representing the main resource of the input query. Present in the prequery's SELECT clause. dependentResourceVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing dependent resources in the input query. Used in an aggregation function in the prequery's SELECT clause (see below). dependentResourceVariablesGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of dependent resources. Present in the prequery's SELECT clause. valueObjectVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing value objects. Used in an aggregation function in the prequery's SELECT clause (see below). valueObjectVarsGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of value objects. Present in the prequery's SELECT clause. The variables mentioned above are present in the prequery's result rows because they are part of the prequery's SELECT clause. The following example illustrates the handling of variables. The following Gravsearch query looks for pages with a sequence number of 10 that are part of a book: PREFIX incunabula : <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api : <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?page knora-api : isMainResource true . ?page knora-api : isPartOf ?book . ?page incunabula : seqnum ?seqnum . } WHERE { ?page a incunabula : page . ?page knora-api : isPartOf ?book . ?book a incunabula : book . ?page incunabula : seqnum ?seqnum . FILTER ( ?seqnum = 10 ) } The prequery's SELECT clause is built by NonTriplestoreSpecificGravsearchToPrequeryTransformer.getSelectColumns , based on the variables used in the input query's CONSTRUCT clause. The resulting SELECT clause looks as follows: SELECT DISTINCT ?page ( GROUP_CONCAT ( DISTINCT ( IF ( BOUND ( ?book ), STR ( ?book ), \"\" )); SEPARATOR = '' ) AS ?book__Concat ) ( GROUP_CONCAT ( DISTINCT ( IF ( BOUND ( ?seqnum ), STR ( ?seqnum ), \"\" )); SEPARATOR = '' ) AS ?seqnum__Concat ) ( GROUP_CONCAT ( DISTINCT ( IF ( BOUND ( ?book__LinkValue ), STR ( ?book__LinkValue ), \"\" )); SEPARATOR = '' ) AS ?book__LinkValue__Concat ) WHERE {...} GROUP BY ?page ORDER BY ASC ( ?page ) LIMIT 25 ?page represents the main resource. When accessing the prequery's result rows, ?page contains the IRI of the main resource. The prequery's results are grouped by the main resource so that there is exactly one result row per matching main resource. ?page is also used as a sort criterion although none has been defined in the input query. This is necessary to make paging work: results always have to be returned in the same order (the prequery is always deterministic). Like this, results can be fetched page by page using LIMIT and OFFSET. Grouping by main resource requires other results to be aggregated using the function GROUP_CONCAT . ?book is used as an argument of the aggregation function. The aggregation's result is accessible in the prequery's result rows as ?book__Concat . The variable ?book is bound to an IRI. Since more than one IRI could be bound to a variable representing a dependent resource, the results have to be aggregated. GROUP_CONCAT takes two arguments: a collection of strings (IRIs in our use case) and a separator (we use the non-printing Unicode character INFORMATION SEPARATOR ONE ). When accessing ?book__Concat in the prequery's results containing the IRIs of dependent resources, the string has to be split with the separator used in the aggregation function. The result is a collection of IRIs representing dependent resources. The same logic applies to value objects. Each GROUP_CONCAT checks whether the concatenated variable is bound in each result in the group; if a variable is unbound, we concatenate an empty string. This is necessary because, in Apache Jena (and perhaps other triplestores), \"If GROUP_CONCAT has an unbound value in the list of values to concat, the overall result is 'error'\" (see this Jena issue ). If the input query contains a UNION , and a variable is bound in one branch of the UNION and not in another branch, it is possible that the prequery will return more than one row per main resource. To deal with this situation, SearchResponderV2 merges rows that contain the same main resource IRI.","title":"Prequery"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#main-query","text":"The purpose of the main query is to get all requested information about the main resource, dependent resources, and value objects. The IRIs of those resources and value objects were returned by the prequery. Since the prequery only returns resources and value objects matching the input query's criteria, the main query can specifically ask for more detailed information on these resources and values without having to reconsider these criteria.","title":"Main Query"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#generating-the-main-query","text":"The classes involved in generating the main query can be found in org.knora.webapi.messages.util.search.gravsearch.mainquery . The main query is a SPARQL CONSTRUCT query. Its generation is handled by the method GravsearchMainQueryGenerator.createMainQuery . It takes three arguments: mainResourceIris: Set[IriRef], dependentResourceIris: Set[IriRef], valueObjectIris: Set[IRI] . These sets are constructed based on information about variables representing dependent resources and value objects in the prequery, which is provided by NonTriplestoreSpecificGravsearchToPrequeryTransformer : dependentResourceVariablesGroupConcat : Set(QueryVariable(book__Concat)) valueObjectVariablesGroupConcat : Set(QueryVariable(seqnum__Concat), QueryVariable(book__LinkValue__Concat)) From the given Iris, statements are generated that ask for complete information on exactly these resources and values. For any given resource Iri, only the values present in valueObjectIris are to be queried. This is achieved by using SPARQL's VALUES expression for the main resource and dependent resources as well as for values.","title":"Generating the Main Query"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#processing-the-main-querys-results","text":"To do the permission checking, the results of the main query are passed to ConstructResponseUtilV2.splitMainResourcesAndValueRdfData , which transforms a SparqlConstructResponse (a set of RDF triples) into a structure organized by main resource Iris. In this structure, dependent resources and values are nested and can be accessed via their main resource, and resources and values that the user does not have permission to see are filtered out. As a result, a page of results may contain fewer than the maximum allowed number of results per page, even if more pages of results are available. MainQueryResultProcessor.getRequestedValuesFromResultsWithFullGraphPattern then filters out values that the user did not explicitly ask for in the input query. Finally, ConstructResponseUtilV2.createApiResponse transforms the query results into an API response (a ReadResourcesSequenceV2 ). If the number of main resources found (even if filtered out because of permissions) is equal to the maximum allowed page size, the predicate knora-api:mayHaveMoreResults: true is included in the response.","title":"Processing the Main Query's results"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#inference","text":"Gravsearch queries support a subset of RDFS reasoning (see Inference in the API documentation on Gravsearch). This is implemented as follows: To simulate RDF inference, the API expands the prequery on basis of the available ontologies. For that reason, SparqlTransformer.transformStatementInWhereForNoInference expands all rdfs:subClassOf and rdfs:subPropertyOf statements using UNION statements for all subclasses and subproperties from the ontologies (equivalent to rdfs:subClassOf* and rdfs:subPropertyOf* ). Similarly, SparqlTransformer.transformStatementInWhereForNoInference replaces knora-api:standoffTagHasStartAncestor with knora-base:standoffTagHasStartParent* .","title":"Inference"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#optimisation-of-generated-sparql","text":"The triplestore-specific transformers in SparqlTransformer.scala can run optimisations on the generated SPARQL, in the method optimiseQueryPatterns inherited from WhereTransformer . For example, moveLuceneToBeginning moves Lucene queries to the beginning of the block in which they occur.","title":"Optimisation of generated SPARQL"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#query-optimization-by-topological-sorting-of-statements","text":"In Jena Fuseki, the performance of a query highly depends on the order of the query statements. For example, a query such as the one below: PREFIX beol : <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api : isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol : creationDate ?date . } WHERE { ?letter beol : creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER ( ?linkingProp1 = beol : hasAuthor || ?linkingProp1 = beol : hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER ( ?linkingProp2 = beol : hasAuthor || ?linkingProp2 = beol : hasRecipient ) ?person1 beol : hasIAFIdentifier ?gnd1 . ?gnd1 knora-api : valueAsString \"(DE-588)118531379\" . ?person2 beol : hasIAFIdentifier ?gnd2 . ?gnd2 knora-api : valueAsString \"(DE-588)118696149\" . } ORDER BY ?date takes a very long time with Fuseki. The performance of this query can be improved by moving up the statements with literal objects that are not dependent on any other statement: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the query then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date . Since users cannot be expected to know about performance of triplestores in order to write efficient queries, an optimization method to automatically rearrange the statements of the given queries has been implemented. Upon receiving the Gravsearch query, the algorithm converts the query to a graph. For each statement pattern, the subject of the statement is the origin node, the predicate is a directed edge, and the object is the target node. For the query above, this conversion would result in the following graph: The Graph for Scala library is used to construct the graph and sort it using Kahn's topological sorting algorithm . The algorithm returns the nodes of the graph ordered in several layers, where the root element ?letter is in layer 0, [?date, ?person1, ?person2] are in layer 1, [?gnd1, ?gnd2] in layer 2, and the leaf nodes [(DE-588)118531379, (DE-588)118696149] are given in the last layer (i.e. layer 3). According to Kahn's algorithm, there are multiple valid permutations of the topological order. The graph in the example above has 24 valid permutations of topological order. Here are two of them (nodes are ordered from left to right with the highest order to the lowest): (?letter, ?date, ?person2, ?person1, ?gnd2, ?gnd1, (DE-588)118696149, (DE-588)118531379) (?letter, ?date, ?person1, ?person2, ?gnd1, ?gnd2, (DE-588)118531379, (DE-588)118696149) . From all valid topological orders, one is chosen based on certain criteria; for example, the leaf node should not belong to a statement that has predicate rdf:type , since that could match all resources of the specified type. Once the best order is chosen, it is used to re-arrange the query statements. Starting from the last leaf node, i.e. (DE-588)118696149 , the method finds the statement pattern which has this node as its object, and brings this statement to the top of the query. This rearrangement continues so that the statements with the fewest dependencies on other statements are all brought to the top of the query. The resulting query is as follows: PREFIX beol : <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api : <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api : isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol : creationDate ?date . } WHERE { ?gnd2 knora-api : valueAsString \"(DE-588)118696149\" . ?gnd1 knora-api : valueAsString \"(DE-588)118531379\" . ?person2 beol : hasIAFIdentifier ?gnd2 . ?person1 beol : hasIAFIdentifier ?gnd1 . ?letter ?linkingProp2 ?person2 . ?letter ?linkingProp1 ?person1 . ?letter beol : creationDate ?date . FILTER ( ?linkingProp1 = beol : hasAuthor || ?linkingProp1 = beol : hasRecipient ) FILTER ( ?linkingProp2 = beol : hasAuthor || ?linkingProp2 = beol : hasRecipient ) } ORDER BY ?date Note that position of the FILTER statements does not play a significant role in the optimization. If a Gravsearch query contains statements in UNION , OPTIONAL , MINUS , or FILTER NOT EXISTS , they are reordered by defining a graph per block. For example, consider the following query with UNION : { ?thing anything : hasRichtext ?richtext . FILTER knora-api : matchText ( ?richtext , \"test\" ) ?thing anything : hasInteger ?int . ?int knora-api : intValueAsInt 1 . } UNION { ?thing anything : hasText ?text . FILTER knora-api : matchText ( ?text , \"test\" ) ?thing anything : hasInteger ?int . ?int knora-api : intValueAsInt 3 . } This would result in one graph per block of the UNION . Each graph is then sorted, and the statements of its block are rearranged according to the topological order of graph. This is the result: { ?int knora-api : intValueAsInt 1 . ?thing anything : hasRichtext ?richtext . ?thing anything : hasInteger ?int . FILTER ( knora-api : matchText ( ?richtext , \"test\" )) } UNION { ?int knora-api : intValueAsInt 3 . ?thing anything : hasText ?text . ?thing anything : hasInteger ?int . FILTER ( knora-api : matchText ( ?text , \"test\" )) }","title":"Query Optimization by Topological Sorting of Statements"},{"location":"DSP-API/05-internals/design/api-v2/gravsearch/#cyclic-graphs","text":"The topological sorting algorithm can only be used for DAGs (directed acyclic graphs). However, a Gravsearch query can contains statements that result in a cyclic graph, e.g.: PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . } WHERE { ?thing anything:hasOtherThing ?thing1 . ?thing1 anything:hasOtherThing ?thing2 . ?thing2 anything:hasOtherThing ?thing . In this case, the algorithm tries to break the cycles in order to sort the graph. If this is not possible, the query statements are not reordered.","title":"Cyclic Graphs"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/","text":"How to Add an API v2 Route Write SPARQL templates Add any SPARQL templates you need to src/main/twirl/queries/sparql/v2 , using the Twirl template engine. Write Responder Request and Response Messages Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Request and response messages should be designed following the patterns described in JSON-LD Parsing and Formatting . Each responder's request messages should extend a responder-specific trait, so that ResponderManager will know which responder to route those messages to. Write a Responder Write an Akka actor class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v2 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate the new responder. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them them to that responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details. Write a Route Add a class to the org.knora.webapi.routing.v2 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV2.runRdfRouteWithFuture to handle the request. Finally, add your route's knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"How to Add an API v2 Route"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#how-to-add-an-api-v2-route","text":"","title":"How to Add an API v2 Route"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#write-sparql-templates","text":"Add any SPARQL templates you need to src/main/twirl/queries/sparql/v2 , using the Twirl template engine.","title":"Write SPARQL templates"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#write-responder-request-and-response-messages","text":"Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Request and response messages should be designed following the patterns described in JSON-LD Parsing and Formatting . Each responder's request messages should extend a responder-specific trait, so that ResponderManager will know which responder to route those messages to.","title":"Write Responder Request and Response Messages"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#write-a-responder","text":"Write an Akka actor class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v2 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate the new responder. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them them to that responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details.","title":"Write a Responder"},{"location":"DSP-API/05-internals/design/api-v2/how-to-add-a-route/#write-a-route","text":"Add a class to the org.knora.webapi.routing.v2 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV2.runRdfRouteWithFuture to handle the request. Finally, add your route's knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"Write a Route"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/","text":"JSON-LD Parsing and Formatting JsonLDUtil Knora provides a utility object called JsonLDUtil , which wraps the titanium-json-ld Java library , and parses JSON-LD text to a Knora data structure called JsonLDDocument . These classes provide commonly needed functionality for extracting and validating data from JSON-LD documents, as well as for constructing new documents. Parsing JSON-LD A route that expects a JSON-LD request must first parse the JSON-LD using JsonLDUtil . For example, this is how ValuesRouteV2 parses a JSON-LD request to create a value: post { entity ( as [ String ]) { jsonRequest => requestContext => { val requestDoc : JsonLDDocument = JsonLDUtil . parseJsonLD ( jsonRequest ) The result is a JsonLDDocument in which all prefixes have been expanded to full IRIs, with an empty JSON-LD context. The next step is to convert the JsonLDDocument to a request message that can be sent to the Knora responder that will handle the request. val requestMessageFuture : Future [ CreateValueRequestV2 ] = for { requestingUser <- getUserADM ( requestContext ) requestMessage : CreateValueRequestV2 <- CreateValueRequestV2 . fromJsonLD ( requestDoc , apiRequestID = UUID . randomUUID , requestingUser = requestingUser , responderManager = responderManager , storeManager = storeManager , settings = settings , log = log ) } yield requestMessage This is done in a Future , because the processing of JSON-LD input could in itself involve sending messages to responders. Each request message case class (in this case CreateValueRequestV2 ) has a companion object that implements the KnoraJsonLDRequestReaderV2 trait: /** * A trait for objects that can generate case class instances based on JSON-LD input. * * @tparam C the type of the case class that can be generated. */ trait KnoraJsonLDRequestReaderV2 [ C ] { /** * Converts JSON-LD input into a case class instance. * * @param jsonLDDocument the JSON-LD input. * @param apiRequestID the UUID of the API request. * @param requestingUser the user making the request. * @param responderManager a reference to the responder manager. * @param storeManager a reference to the store manager. * @param settings the application settings. * @param log a logging adapter. * @param timeout a timeout for `ask` messages. * @param executionContext an execution context for futures. * @return a case class instance representing the input. */ def fromJsonLD ( jsonLDDocument : JsonLDDocument , apiRequestID : UUID , requestingUser : UserADM , responderManager : ActorRef , storeManager : ActorRef , settings : KnoraSettingsImpl , log : LoggingAdapter )( implicit timeout : Timeout , executionContext : ExecutionContext ): Future [ C ] } This means that the companion object has a method fromJsonLD that takes a JsonLDDocument and returns an instance of the case class. The fromJsonLD method can use the functionality of the JsonLDDocument data structure for extracting and validating the content of the request. For example, JsonLDObject.requireStringWithValidation gets a required member of a JSON-LD object, and validates it using a function that is passed as an argument. Here is an example of getting and validating a SmartIri : for { valueType : SmartIri <- Future ( jsonLDObject . requireStringWithValidation ( JsonLDConstants . TYPE , stringFormatter . toSmartIriWithErr )) The validation function (in this case stringFormatter.toSmartIriWithErr ) has to take two arguments: a string to be validated, and a function that that throws an exception if the string is invalid. The return value of requireStringWithValidation is the return value of the validation function, which in this case is a SmartIri . If the string is invalid, requireStringWithValidation throws BadRequestException . It is also possible to get and validate an optional JSON-LD object member: val maybeDateValueHasStartEra : Option [ DateEraV2 ] = jsonLDObject . maybeStringWithValidation ( OntologyConstants . KnoraApiV2Complex . DateValueHasStartEra , DateEraV2 . parse ) Here JsonLDObject.maybeStringWithValidation returns an Option that contains the return value of the validation function ( DateEraV2.parse ) if it was given, otherwise None . Returning a JSON-LD Response Each API response is represented by a message class that extends KnoraJsonLDResponseV2 , which has a method toJsonLDDocument that specifies the target ontology schema. The implementation of this method constructs a JsonLDDocument , in which all object keys are full IRIs (no prefixes are used), but in which the JSON-LD context also specifies the prefixes that will be used when the document is returned to the client. The function JsonLDUtil.makeContext is a convenient way to construct the JSON-LD context. Since toJsonLDDocument has to return an object that uses the specified ontology schema, the recommended design is to separate schema conversion as much as possible from JSON-LD generation. As a first step, schema conversion (or at the very least, the conversion of Knora type IRIs to the target schema) can be done via an implementation of KnoraReadV2 : /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2 [ C <: KnoraReadV2 [ C ]] { this : C => def toOntologySchema ( targetSchema : ApiV2Schema ): C } This means that the response message class has the method toOntologySchema , which returns a copy of the same message, with Knora type IRIs (and perhaps other content) adjusted for the target schema. (See Smart IRIs on how to convert Knora type IRIs to the target schema.) The response message class could then have a private method called generateJsonLD , which generates a JsonLDDocument that has the correct structure for the target schema, like this: private def generateJsonLD ( targetSchema : ApiV2Schema , settings : KnoraSettingsImpl , schemaOptions : Set [ SchemaOption ]): JsonLDDocument This way, the implementation of toJsonLDDocument can call toOntologySchema , then construct a JsonLDDocument from the resulting object. For example: override def toJsonLDDocument ( targetSchema : ApiV2Schema , settings : KnoraSettingsImpl , schemaOptions : Set [ SchemaOption ] = Set . empty ): JsonLDDocument = { toOntologySchema ( targetSchema ). generateJsonLD ( targetSchema = targetSchema , settings = settings , schemaOptions = schemaOptions ) } Selecting the Response Schema Most routes complete by calling RouteUtilV2.runRdfRouteWithFuture , which calls the response message's toJsonLDDocument method. The runRdfRouteWithFuture function has a parameter that enables the route to select the schema that should be used in the response. It is up to each route to determine what the appropriate response schema should be. Some routes support only one response schema. Others allow the client to choose. To use the schema requested by the client, the route can call RouteUtilV2.getOntologySchema : RouteUtilV2 . runRdfRouteWithFuture ( requestMessageF = requestMessageFuture , requestContext = requestContext , settings = settings , responderManager = responderManager , log = log , targetSchema = targetSchema , schemaOptions = schemaOptions ) If the route only supports one schema, it can specify the schema directly instead: RouteUtilV2 . runRdfRouteWithFuture ( requestMessageF = requestMessageFuture , requestContext = requestContext , settings = settings , responderManager = responderManager , log = log , targetSchema = ApiV2Complex , schemaOptions = RouteUtilV2 . getSchemaOptions ( requestContext ) ) Generating Other RDF Formats RouteUtilV2.runRdfRouteWithFuture implements HTTP content negotiation . After determining the client's preferred format, it asks the KnoraResponseV2 to convert itself into that format. KnoraResponseV2 has an abstract format method, whose implementations select the most efficient conversion between the response message's internal representation (which could be JSON-LD or Turtle) and the requested format.","title":"JSON-LD Parsing and Formatting"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#json-ld-parsing-and-formatting","text":"","title":"JSON-LD Parsing and Formatting"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#jsonldutil","text":"Knora provides a utility object called JsonLDUtil , which wraps the titanium-json-ld Java library , and parses JSON-LD text to a Knora data structure called JsonLDDocument . These classes provide commonly needed functionality for extracting and validating data from JSON-LD documents, as well as for constructing new documents.","title":"JsonLDUtil"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#parsing-json-ld","text":"A route that expects a JSON-LD request must first parse the JSON-LD using JsonLDUtil . For example, this is how ValuesRouteV2 parses a JSON-LD request to create a value: post { entity ( as [ String ]) { jsonRequest => requestContext => { val requestDoc : JsonLDDocument = JsonLDUtil . parseJsonLD ( jsonRequest ) The result is a JsonLDDocument in which all prefixes have been expanded to full IRIs, with an empty JSON-LD context. The next step is to convert the JsonLDDocument to a request message that can be sent to the Knora responder that will handle the request. val requestMessageFuture : Future [ CreateValueRequestV2 ] = for { requestingUser <- getUserADM ( requestContext ) requestMessage : CreateValueRequestV2 <- CreateValueRequestV2 . fromJsonLD ( requestDoc , apiRequestID = UUID . randomUUID , requestingUser = requestingUser , responderManager = responderManager , storeManager = storeManager , settings = settings , log = log ) } yield requestMessage This is done in a Future , because the processing of JSON-LD input could in itself involve sending messages to responders. Each request message case class (in this case CreateValueRequestV2 ) has a companion object that implements the KnoraJsonLDRequestReaderV2 trait: /** * A trait for objects that can generate case class instances based on JSON-LD input. * * @tparam C the type of the case class that can be generated. */ trait KnoraJsonLDRequestReaderV2 [ C ] { /** * Converts JSON-LD input into a case class instance. * * @param jsonLDDocument the JSON-LD input. * @param apiRequestID the UUID of the API request. * @param requestingUser the user making the request. * @param responderManager a reference to the responder manager. * @param storeManager a reference to the store manager. * @param settings the application settings. * @param log a logging adapter. * @param timeout a timeout for `ask` messages. * @param executionContext an execution context for futures. * @return a case class instance representing the input. */ def fromJsonLD ( jsonLDDocument : JsonLDDocument , apiRequestID : UUID , requestingUser : UserADM , responderManager : ActorRef , storeManager : ActorRef , settings : KnoraSettingsImpl , log : LoggingAdapter )( implicit timeout : Timeout , executionContext : ExecutionContext ): Future [ C ] } This means that the companion object has a method fromJsonLD that takes a JsonLDDocument and returns an instance of the case class. The fromJsonLD method can use the functionality of the JsonLDDocument data structure for extracting and validating the content of the request. For example, JsonLDObject.requireStringWithValidation gets a required member of a JSON-LD object, and validates it using a function that is passed as an argument. Here is an example of getting and validating a SmartIri : for { valueType : SmartIri <- Future ( jsonLDObject . requireStringWithValidation ( JsonLDConstants . TYPE , stringFormatter . toSmartIriWithErr )) The validation function (in this case stringFormatter.toSmartIriWithErr ) has to take two arguments: a string to be validated, and a function that that throws an exception if the string is invalid. The return value of requireStringWithValidation is the return value of the validation function, which in this case is a SmartIri . If the string is invalid, requireStringWithValidation throws BadRequestException . It is also possible to get and validate an optional JSON-LD object member: val maybeDateValueHasStartEra : Option [ DateEraV2 ] = jsonLDObject . maybeStringWithValidation ( OntologyConstants . KnoraApiV2Complex . DateValueHasStartEra , DateEraV2 . parse ) Here JsonLDObject.maybeStringWithValidation returns an Option that contains the return value of the validation function ( DateEraV2.parse ) if it was given, otherwise None .","title":"Parsing JSON-LD"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#returning-a-json-ld-response","text":"Each API response is represented by a message class that extends KnoraJsonLDResponseV2 , which has a method toJsonLDDocument that specifies the target ontology schema. The implementation of this method constructs a JsonLDDocument , in which all object keys are full IRIs (no prefixes are used), but in which the JSON-LD context also specifies the prefixes that will be used when the document is returned to the client. The function JsonLDUtil.makeContext is a convenient way to construct the JSON-LD context. Since toJsonLDDocument has to return an object that uses the specified ontology schema, the recommended design is to separate schema conversion as much as possible from JSON-LD generation. As a first step, schema conversion (or at the very least, the conversion of Knora type IRIs to the target schema) can be done via an implementation of KnoraReadV2 : /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2 [ C <: KnoraReadV2 [ C ]] { this : C => def toOntologySchema ( targetSchema : ApiV2Schema ): C } This means that the response message class has the method toOntologySchema , which returns a copy of the same message, with Knora type IRIs (and perhaps other content) adjusted for the target schema. (See Smart IRIs on how to convert Knora type IRIs to the target schema.) The response message class could then have a private method called generateJsonLD , which generates a JsonLDDocument that has the correct structure for the target schema, like this: private def generateJsonLD ( targetSchema : ApiV2Schema , settings : KnoraSettingsImpl , schemaOptions : Set [ SchemaOption ]): JsonLDDocument This way, the implementation of toJsonLDDocument can call toOntologySchema , then construct a JsonLDDocument from the resulting object. For example: override def toJsonLDDocument ( targetSchema : ApiV2Schema , settings : KnoraSettingsImpl , schemaOptions : Set [ SchemaOption ] = Set . empty ): JsonLDDocument = { toOntologySchema ( targetSchema ). generateJsonLD ( targetSchema = targetSchema , settings = settings , schemaOptions = schemaOptions ) }","title":"Returning a JSON-LD Response"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#selecting-the-response-schema","text":"Most routes complete by calling RouteUtilV2.runRdfRouteWithFuture , which calls the response message's toJsonLDDocument method. The runRdfRouteWithFuture function has a parameter that enables the route to select the schema that should be used in the response. It is up to each route to determine what the appropriate response schema should be. Some routes support only one response schema. Others allow the client to choose. To use the schema requested by the client, the route can call RouteUtilV2.getOntologySchema : RouteUtilV2 . runRdfRouteWithFuture ( requestMessageF = requestMessageFuture , requestContext = requestContext , settings = settings , responderManager = responderManager , log = log , targetSchema = targetSchema , schemaOptions = schemaOptions ) If the route only supports one schema, it can specify the schema directly instead: RouteUtilV2 . runRdfRouteWithFuture ( requestMessageF = requestMessageFuture , requestContext = requestContext , settings = settings , responderManager = responderManager , log = log , targetSchema = ApiV2Complex , schemaOptions = RouteUtilV2 . getSchemaOptions ( requestContext ) )","title":"Selecting the Response Schema"},{"location":"DSP-API/05-internals/design/api-v2/json-ld/#generating-other-rdf-formats","text":"RouteUtilV2.runRdfRouteWithFuture implements HTTP content negotiation . After determining the client's preferred format, it asks the KnoraResponseV2 to convert itself into that format. KnoraResponseV2 has an abstract format method, whose implementations select the most efficient conversion between the response message's internal representation (which could be JSON-LD or Turtle) and the requested format.","title":"Generating Other RDF Formats"},{"location":"DSP-API/05-internals/design/api-v2/ontology-management/","text":"Ontology Management The core of Knora's ontology management logic is OntologyResponderV2 . It is responsible for: Loading ontologies from the triplestore when Knora starts. Maintaining an ontology cache to improve performance. Returning requested ontology entities from the cache. Requests for ontology information never access the triplestore. Creating and updating ontologies in response to API requests. Ensuring that all user-created ontologies are consistent and conform to knora-base . When Knora starts, the ontology responder receives a LoadOntologiesRequestV2 message. It then: Loads all ontologies found in the triplestore into suitable Scala data structures, which include indexes of relations between entities (e.g. rdfs:subClassOf relations), to facilitate validity checks. Checks user-created ontologies for consistency and conformance to knora-base , according to the rules described in Summary of Restrictions on User-Created Ontologies . Caches all the loaded ontologies using CacheUtil . The ontology responder assumes that nothing except itself modifies ontologies in the triplestore while Knora is running. Therefore, the ontology cache is updated only when the ontology responder processes a request to update an ontology. By design, the ontology responder can update only one ontology entity per request, to simplify the necessary validity checks. This requires the client to construct an ontology by submitting a sequence of requests in a certain order, as explained in Ontology Updates . The ontology responder mainly works with ontologies in the internal schema. However, it knows that some entities in built-in ontologies have hard-coded definitions in external schemas, and it checks the relevant transformation rules and returns those entities directly when they are requested (see Generation of Ontologies in External Schemas ).","title":"Ontology Management"},{"location":"DSP-API/05-internals/design/api-v2/ontology-management/#ontology-management","text":"The core of Knora's ontology management logic is OntologyResponderV2 . It is responsible for: Loading ontologies from the triplestore when Knora starts. Maintaining an ontology cache to improve performance. Returning requested ontology entities from the cache. Requests for ontology information never access the triplestore. Creating and updating ontologies in response to API requests. Ensuring that all user-created ontologies are consistent and conform to knora-base . When Knora starts, the ontology responder receives a LoadOntologiesRequestV2 message. It then: Loads all ontologies found in the triplestore into suitable Scala data structures, which include indexes of relations between entities (e.g. rdfs:subClassOf relations), to facilitate validity checks. Checks user-created ontologies for consistency and conformance to knora-base , according to the rules described in Summary of Restrictions on User-Created Ontologies . Caches all the loaded ontologies using CacheUtil . The ontology responder assumes that nothing except itself modifies ontologies in the triplestore while Knora is running. Therefore, the ontology cache is updated only when the ontology responder processes a request to update an ontology. By design, the ontology responder can update only one ontology entity per request, to simplify the necessary validity checks. This requires the client to construct an ontology by submitting a sequence of requests in a certain order, as explained in Ontology Updates . The ontology responder mainly works with ontologies in the internal schema. However, it knows that some entities in built-in ontologies have hard-coded definitions in external schemas, and it checks the relevant transformation rules and returns those entities directly when they are requested (see Generation of Ontologies in External Schemas ).","title":"Ontology Management"},{"location":"DSP-API/05-internals/design/api-v2/ontology-schemas/","text":"Ontology Schemas OntologySchema Type As explained in API Schema , Knora can represent the same RDF data in different forms: an \"internal schema\" for use in the triplestore, and different \"external schemas\" for use in Knora API v2. Different schemas use different IRIs, as explained in Knora IRIs . Internally, Knora uses a SmartIri class to convert IRIs between schemas. The data type representing a schema itself is OntologySchema , which uses the sealed trait pattern: package org . knora . webapi /** * Indicates the schema that a Knora ontology or ontology entity conforms to. */ sealed trait OntologySchema /** * The schema of DSP ontologies and entities that are used in the triplestore. */ case object InternalSchema extends OntologySchema /** * The schema of DSP ontologies and entities that are used in API v2. */ sealed trait ApiV2Schema extends OntologySchema /** * The simple schema for representing DSP ontologies and entities. This schema represents values as literals * when possible. */ case object ApiV2Simple extends ApiV2Schema /** * The default (or complex) schema for representing DSP ontologies and entities. This * schema always represents values as objects. */ case object ApiV2Complex extends ApiV2Schema /** * A trait representing options that can be submitted to configure an ontology schema. */ sealed trait SchemaOption /** * A trait representing options that affect the rendering of markup when text values are returned. */ sealed trait MarkupRendering extends SchemaOption /** * Indicates that markup should be rendered as XML when text values are returned. */ case object MarkupAsXml extends MarkupRendering /** * Indicates that markup should not be returned with text values, because it will be requested * separately as standoff. */ case object MarkupAsStandoff extends MarkupRendering /** * Indicates that no markup should be returned with text values. Used only internally. */ case object NoMarkup extends MarkupRendering /** * Utility functions for working with schema options. */ object SchemaOptions { /** * A set of schema options for querying all standoff markup along with text values. */ val ForStandoffWithTextValues : Set [ SchemaOption ] = Set ( MarkupAsXml ) /** * A set of schema options for querying standoff markup separately from text values. */ val ForStandoffSeparateFromTextValues : Set [ SchemaOption ] = Set ( MarkupAsStandoff ) /** * Determines whether standoff should be queried when a text value is queried. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if standoff should be queried. */ def queryStandoffWithTextValues ( targetSchema : ApiV2Schema , schemaOptions : Set [ SchemaOption ]): Boolean = { targetSchema == ApiV2Complex && ! schemaOptions . contains ( MarkupAsStandoff ) } /** * Determines whether markup should be rendered as XML. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as XML. */ def renderMarkupAsXml ( targetSchema : ApiV2Schema , schemaOptions : Set [ SchemaOption ]): Boolean = { targetSchema == ApiV2Complex && ! schemaOptions . contains ( MarkupAsStandoff ) } /** * Determines whether markup should be rendered as standoff, separately from text values. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as standoff. */ def renderMarkupAsStandoff ( targetSchema : ApiV2Schema , schemaOptions : Set [ SchemaOption ]): Boolean = { targetSchema == ApiV2Complex && schemaOptions . contains ( MarkupAsStandoff ) } } This class hierarchy allows method declarations to restrict the schemas they accept. A method that can accept any schema can take a parameter of type OntologySchema , while a method that accepts only external schemas can take a parameter of type ApiV2Schema . For examples, see Content Wrappers . Generation of Ontologies in External Schemas Ontologies are stored only in the internal schema, and are converted on the fly to external schemas. For each external schema, there is a Scala object in org.knora.webapi.messages.v2.responder.ontologymessages that provides rules for this conversion: KnoraApiV2SimpleTransformationRules for the API v2 simple schema KnoraApiV2WithValueObjectsTransformationRules for the API v2 complex schema Since these are Scala objects rather than classes, they are initialised before the Akka ActorSystem starts, and therefore need a special instance of Knora's StringFormatter class (see Smart IRIs ). Each of these rule objects implements this trait: /** * A trait for objects that provide rules for converting an ontology from the internal schema to an external schema. * * See also [[OntologyConstants.CorrespondingIris]]. */ trait OntologyTransformationRules { /** * The metadata to be used for the transformed ontology. */ val ontologyMetadata : OntologyMetadataV2 /** * Properties to remove from the ontology before converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val internalPropertiesToRemove : Set [ SmartIri ] /** * Classes to remove from the ontology before converting it to the target schema. */ val internalClassesToRemove : Set [ SmartIri ] /** * After the ontology has been converted to the target schema, these cardinalities must be * added to the specified classes. */ val externalCardinalitiesToAdd : Map [ SmartIri , Map [ SmartIri , KnoraCardinalityInfo ]] /** * Classes that need to be added to the ontology after converting it to the target schema. */ val externalClassesToAdd : Map [ SmartIri , ReadClassInfoV2 ] /** * Properties that need to be added to the ontology after converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val externalPropertiesToAdd : Map [ SmartIri , ReadPropertyInfoV2 ] } These rules are applied to knora-base as well as to user-created ontologies. For example, knora-base:Resource has different cardinalities depending on its schema ( knora-api:Resource has an additional cardinality on knora-api:hasIncomingLink ), and this is therefore also true of its user-created subclasses. The transformation is implemented: In the implementations of the toOntologySchema method in classes defined in OntologyMessagesV2.scala : ReadOntologyV2 , ReadClassInfoV2 , ClassInfoContentV2 , PropertyInfoContentV2 , and OntologyMetadataV2 . In OntologyResponderV2.getEntityInfoResponseV2 , which handles requests for specific ontology entities. If the requested entity is hard-coded in a transformation rule, this method returns the hard-coded external entity, otherwise it returns the relevant internal entity.","title":"Ontology Schemas"},{"location":"DSP-API/05-internals/design/api-v2/ontology-schemas/#ontology-schemas","text":"","title":"Ontology Schemas"},{"location":"DSP-API/05-internals/design/api-v2/ontology-schemas/#ontologyschema-type","text":"As explained in API Schema , Knora can represent the same RDF data in different forms: an \"internal schema\" for use in the triplestore, and different \"external schemas\" for use in Knora API v2. Different schemas use different IRIs, as explained in Knora IRIs . Internally, Knora uses a SmartIri class to convert IRIs between schemas. The data type representing a schema itself is OntologySchema , which uses the sealed trait pattern: package org . knora . webapi /** * Indicates the schema that a Knora ontology or ontology entity conforms to. */ sealed trait OntologySchema /** * The schema of DSP ontologies and entities that are used in the triplestore. */ case object InternalSchema extends OntologySchema /** * The schema of DSP ontologies and entities that are used in API v2. */ sealed trait ApiV2Schema extends OntologySchema /** * The simple schema for representing DSP ontologies and entities. This schema represents values as literals * when possible. */ case object ApiV2Simple extends ApiV2Schema /** * The default (or complex) schema for representing DSP ontologies and entities. This * schema always represents values as objects. */ case object ApiV2Complex extends ApiV2Schema /** * A trait representing options that can be submitted to configure an ontology schema. */ sealed trait SchemaOption /** * A trait representing options that affect the rendering of markup when text values are returned. */ sealed trait MarkupRendering extends SchemaOption /** * Indicates that markup should be rendered as XML when text values are returned. */ case object MarkupAsXml extends MarkupRendering /** * Indicates that markup should not be returned with text values, because it will be requested * separately as standoff. */ case object MarkupAsStandoff extends MarkupRendering /** * Indicates that no markup should be returned with text values. Used only internally. */ case object NoMarkup extends MarkupRendering /** * Utility functions for working with schema options. */ object SchemaOptions { /** * A set of schema options for querying all standoff markup along with text values. */ val ForStandoffWithTextValues : Set [ SchemaOption ] = Set ( MarkupAsXml ) /** * A set of schema options for querying standoff markup separately from text values. */ val ForStandoffSeparateFromTextValues : Set [ SchemaOption ] = Set ( MarkupAsStandoff ) /** * Determines whether standoff should be queried when a text value is queried. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if standoff should be queried. */ def queryStandoffWithTextValues ( targetSchema : ApiV2Schema , schemaOptions : Set [ SchemaOption ]): Boolean = { targetSchema == ApiV2Complex && ! schemaOptions . contains ( MarkupAsStandoff ) } /** * Determines whether markup should be rendered as XML. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as XML. */ def renderMarkupAsXml ( targetSchema : ApiV2Schema , schemaOptions : Set [ SchemaOption ]): Boolean = { targetSchema == ApiV2Complex && ! schemaOptions . contains ( MarkupAsStandoff ) } /** * Determines whether markup should be rendered as standoff, separately from text values. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as standoff. */ def renderMarkupAsStandoff ( targetSchema : ApiV2Schema , schemaOptions : Set [ SchemaOption ]): Boolean = { targetSchema == ApiV2Complex && schemaOptions . contains ( MarkupAsStandoff ) } } This class hierarchy allows method declarations to restrict the schemas they accept. A method that can accept any schema can take a parameter of type OntologySchema , while a method that accepts only external schemas can take a parameter of type ApiV2Schema . For examples, see Content Wrappers .","title":"OntologySchema Type"},{"location":"DSP-API/05-internals/design/api-v2/ontology-schemas/#generation-of-ontologies-in-external-schemas","text":"Ontologies are stored only in the internal schema, and are converted on the fly to external schemas. For each external schema, there is a Scala object in org.knora.webapi.messages.v2.responder.ontologymessages that provides rules for this conversion: KnoraApiV2SimpleTransformationRules for the API v2 simple schema KnoraApiV2WithValueObjectsTransformationRules for the API v2 complex schema Since these are Scala objects rather than classes, they are initialised before the Akka ActorSystem starts, and therefore need a special instance of Knora's StringFormatter class (see Smart IRIs ). Each of these rule objects implements this trait: /** * A trait for objects that provide rules for converting an ontology from the internal schema to an external schema. * * See also [[OntologyConstants.CorrespondingIris]]. */ trait OntologyTransformationRules { /** * The metadata to be used for the transformed ontology. */ val ontologyMetadata : OntologyMetadataV2 /** * Properties to remove from the ontology before converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val internalPropertiesToRemove : Set [ SmartIri ] /** * Classes to remove from the ontology before converting it to the target schema. */ val internalClassesToRemove : Set [ SmartIri ] /** * After the ontology has been converted to the target schema, these cardinalities must be * added to the specified classes. */ val externalCardinalitiesToAdd : Map [ SmartIri , Map [ SmartIri , KnoraCardinalityInfo ]] /** * Classes that need to be added to the ontology after converting it to the target schema. */ val externalClassesToAdd : Map [ SmartIri , ReadClassInfoV2 ] /** * Properties that need to be added to the ontology after converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val externalPropertiesToAdd : Map [ SmartIri , ReadPropertyInfoV2 ] } These rules are applied to knora-base as well as to user-created ontologies. For example, knora-base:Resource has different cardinalities depending on its schema ( knora-api:Resource has an additional cardinality on knora-api:hasIncomingLink ), and this is therefore also true of its user-created subclasses. The transformation is implemented: In the implementations of the toOntologySchema method in classes defined in OntologyMessagesV2.scala : ReadOntologyV2 , ReadClassInfoV2 , ClassInfoContentV2 , PropertyInfoContentV2 , and OntologyMetadataV2 . In OntologyResponderV2.getEntityInfoResponseV2 , which handles requests for specific ontology entities. If the requested entity is hard-coded in a transformation rule, this method returns the hard-coded external entity, otherwise it returns the relevant internal entity.","title":"Generation of Ontologies in External Schemas"},{"location":"DSP-API/05-internals/design/api-v2/overview/","text":"API v2 Design Overview General Principles DSP-API v2 requests and responses are RDF documents. Any API v2 response can be returned as JSON-LD , Turtle , or RDF/XML . Each class or property used in a request or response has a definition in an ontology, which Knora can serve. Response formats are reused for different requests whenever possible, to minimise the number of different response formats a client has to handle. For example, any request for one or more resources (such as a search result, or a request for one specific resource) returns a response in the same format. Response size is limited by design. Large amounts of data must be retrieved by requesting small pages of data, one after the other. Responses that provide data are distinct from responses that provide definitions (i.e. ontology entities). Data responses indicate which types are used, and the client can request information about these types separately. API Schemas The types used in the triplestore are not exposed directly in the API. Instead, they are mapped onto API 'schemas'. Two schemas are currently provided. A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Each schema has its own type IRIs, which are derived from the ones used in the triplestore. For details of these different IRI formats, see Knora IRIs . Implementation JSON-LD Parsing and Formatting Each API response is represented by a class that extends KnoraResponseV2 , which has a method toJsonLDDocument that specifies the target schema. It is currently up to each route to determine what the appropriate response schema should be. Some routes will support only one response schema. Others will allow the client to choose, and there will be one or more standard ways for the client to specify the desired response schema. A route calls RouteUtilV2.runRdfRoute , passing a request message and a response schema. When RouteUtilV2 gets the response message from the responder, it calls toJsonLDDocument on it, specifying that schema. The response message returns a JsonLDDocument , which is a simple data structure that is then converted to Java objects and passed to the JSON-LD Java library for formatting. In general, toJsonLDDocument is implemented in two stages: first the object converts itself to the target schema, and then the resulting object is converted to a JsonLDDocument . A route that receives JSON-LD requests should use JsonLDUtil.parseJsonLD to convert each request to a JsonLDDocument . Generation of Other RDF Formats RouteUtilV2.runRdfRoute implements HTTP content negotiation , and converts JSON-LD responses into Turtle or RDF/XML as appropriate. Operation Wrappers Whenever possible, the same data structures are used for input and output. Often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. In such cases, there is a class like ValueContentV2 , which represents the data that is used both for input and for output. When a value is read, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A Read* wrapper can be wrapped in another Read* wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. Each *Content* class should extend KnoraContentV2 and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction. Each Read* wrapper class should have a method for converting itself to JSON-LD in a particular external schema. If the Read* wrapper is a KnoraResponseV2 , this method is toJsonLDDocument . Smart IRIs Usage The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org . knora . webapi . messages .{ SmartIri , StringFormatter } import org . knora . webapi . messages . IriConversions . _ Ensure that an implicit instance of StringFormatter is in scope: implicit val stringFormatter : StringFormatter = StringFormatter . getGeneralInstance Then, if iriStr is a string representing an IRI, you can can convert it to a SmartIri like this: val iri : SmartIri = iriStr . toSmartIri If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: val iri : SmartIri = iriStr . toSmartIriWithErr ( () => throw BadRequestException ( s\"Invalid IRI: $ iriStr \" ) ) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. Parsing and caching a SmartIri instance takes about 10-20 \u00b5s, and retrieving a cached SmartIri takes about 1 \u00b5s. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri . Implementation The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies. This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"API v2 Design Overview"},{"location":"DSP-API/05-internals/design/api-v2/overview/#api-v2-design-overview","text":"","title":"API v2 Design Overview"},{"location":"DSP-API/05-internals/design/api-v2/overview/#general-principles","text":"DSP-API v2 requests and responses are RDF documents. Any API v2 response can be returned as JSON-LD , Turtle , or RDF/XML . Each class or property used in a request or response has a definition in an ontology, which Knora can serve. Response formats are reused for different requests whenever possible, to minimise the number of different response formats a client has to handle. For example, any request for one or more resources (such as a search result, or a request for one specific resource) returns a response in the same format. Response size is limited by design. Large amounts of data must be retrieved by requesting small pages of data, one after the other. Responses that provide data are distinct from responses that provide definitions (i.e. ontology entities). Data responses indicate which types are used, and the client can request information about these types separately.","title":"General Principles"},{"location":"DSP-API/05-internals/design/api-v2/overview/#api-schemas","text":"The types used in the triplestore are not exposed directly in the API. Instead, they are mapped onto API 'schemas'. Two schemas are currently provided. A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Each schema has its own type IRIs, which are derived from the ones used in the triplestore. For details of these different IRI formats, see Knora IRIs .","title":"API Schemas"},{"location":"DSP-API/05-internals/design/api-v2/overview/#implementation","text":"","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-v2/overview/#json-ld-parsing-and-formatting","text":"Each API response is represented by a class that extends KnoraResponseV2 , which has a method toJsonLDDocument that specifies the target schema. It is currently up to each route to determine what the appropriate response schema should be. Some routes will support only one response schema. Others will allow the client to choose, and there will be one or more standard ways for the client to specify the desired response schema. A route calls RouteUtilV2.runRdfRoute , passing a request message and a response schema. When RouteUtilV2 gets the response message from the responder, it calls toJsonLDDocument on it, specifying that schema. The response message returns a JsonLDDocument , which is a simple data structure that is then converted to Java objects and passed to the JSON-LD Java library for formatting. In general, toJsonLDDocument is implemented in two stages: first the object converts itself to the target schema, and then the resulting object is converted to a JsonLDDocument . A route that receives JSON-LD requests should use JsonLDUtil.parseJsonLD to convert each request to a JsonLDDocument .","title":"JSON-LD Parsing and Formatting"},{"location":"DSP-API/05-internals/design/api-v2/overview/#generation-of-other-rdf-formats","text":"RouteUtilV2.runRdfRoute implements HTTP content negotiation , and converts JSON-LD responses into Turtle or RDF/XML as appropriate.","title":"Generation of Other RDF Formats"},{"location":"DSP-API/05-internals/design/api-v2/overview/#operation-wrappers","text":"Whenever possible, the same data structures are used for input and output. Often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. In such cases, there is a class like ValueContentV2 , which represents the data that is used both for input and for output. When a value is read, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A Read* wrapper can be wrapped in another Read* wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. Each *Content* class should extend KnoraContentV2 and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction. Each Read* wrapper class should have a method for converting itself to JSON-LD in a particular external schema. If the Read* wrapper is a KnoraResponseV2 , this method is toJsonLDDocument .","title":"Operation Wrappers"},{"location":"DSP-API/05-internals/design/api-v2/overview/#smart-iris","text":"","title":"Smart IRIs"},{"location":"DSP-API/05-internals/design/api-v2/overview/#usage","text":"The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org . knora . webapi . messages .{ SmartIri , StringFormatter } import org . knora . webapi . messages . IriConversions . _ Ensure that an implicit instance of StringFormatter is in scope: implicit val stringFormatter : StringFormatter = StringFormatter . getGeneralInstance Then, if iriStr is a string representing an IRI, you can can convert it to a SmartIri like this: val iri : SmartIri = iriStr . toSmartIri If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: val iri : SmartIri = iriStr . toSmartIriWithErr ( () => throw BadRequestException ( s\"Invalid IRI: $ iriStr \" ) ) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. Parsing and caching a SmartIri instance takes about 10-20 \u00b5s, and retrieving a cached SmartIri takes about 1 \u00b5s. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri .","title":"Usage"},{"location":"DSP-API/05-internals/design/api-v2/overview/#implementation_1","text":"The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies. This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-v2/query-design/","text":"SPARQL Query Design Inference DSP-API does not require the triplestore to perform inference, as different triplestores implement inference quite differently, so that taking advantage of inference would require triplestore specific code, which is not well maintainable. Instead, the API simulates inference for each Gravsearch query, so that the expected results are returned. Gravsearch queries currently need to do the following: Given a base property, find triples using a subproperty as predicate, and return the subproperty used in each case. Given a base class, find triples using an instance of subclass as subject or object, and return the subclass used in each case. Without inference, this can be done using property path syntax. CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject . WHERE { ?resource a ?resourceClass . ?resourceType rdfs : subClassOf * knora-base : Resource . ?resource ?resourceValueProperty ?valueObject . ?resourceValueProperty rdfs : subPropertyOf * knora-base : hasValue . This query: Checks that the queried resource belongs to a subclass of knora-base:Resource . Returns the class that the resource explicitly belongs to. Finds the Knora values attached to the resource, and returns each value along with the property that explicitly attaches it to the resource. However, such a query is very inefficient. Instead, the API does inference on the query, so that the relevant information can be found in a timely manner. For this, the query is analyzed to check which project ontologies are relevant to the query. If an ontology is not relevant to a query, then all class and property definitions of this ontology are disregarded for inference. Then, each statement that requires inference (i.e. that could be phrased with property path syntax, as described above) is cross-referenced with the relevant ontologies, to see which property/class definitions would fit the statement according to the rules of RDF inference. And each of those definitions is added to the query as a separate UNION statement. E.g.: Given the resource class B is a subclass of A and the property hasY is a subproperty of hasX , then the following query SELECT { ?res ?prop . } WHERE { ?res a <A> . ?res <hasX> ?prop . } can be rewritten as SELECT { ?res ?prop . } WHERE { { ?res a <A> } UNION { ?res a <B> } . { ?res <hasX> ?prop } UNION { ?res <hasY> ?prop } . } Querying Past Value Versions Value versions are a linked list, starting with the current version. Each value points to the previous version via knora-base:previousValue . The resource points only to the current version. Past value versions are queried in getResourcePropertiesAndValues.scala.txt , which can take a timestamp argument. Given the current value version, we must find the most recent past version that existed at the target date. First, we get the set of previous values that were created on or before the target date: ?currentValue knora-base:previousValue* ?valueObject . ?valueObject knora-base:valueCreationDate ?valueObjectCreationDate . FILTER(?valueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) The resulting versions are now possible values of ?valueObject . Next, out of this set of versions, we exclude all versions except for the most recent one. We do this by checking, for each ?valueObject , whether there is another version, ?otherValueObject , that is more recent and was also created before the target date. If such a version exists, we exclude the one we are looking at. FILTER NOT EXISTS { ?currentValue knora-base:previousValue* ?otherValueObject . ?otherValueObject knora-base:valueCreationDate ?otherValueObjectCreationDate . FILTER( (?otherValueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) && (?otherValueObjectCreationDate > ?valueObjectCreationDate) ) } This excludes all past versions except the one we are interested in.","title":"SPARQL Query Design"},{"location":"DSP-API/05-internals/design/api-v2/query-design/#sparql-query-design","text":"","title":"SPARQL Query Design"},{"location":"DSP-API/05-internals/design/api-v2/query-design/#inference","text":"DSP-API does not require the triplestore to perform inference, as different triplestores implement inference quite differently, so that taking advantage of inference would require triplestore specific code, which is not well maintainable. Instead, the API simulates inference for each Gravsearch query, so that the expected results are returned. Gravsearch queries currently need to do the following: Given a base property, find triples using a subproperty as predicate, and return the subproperty used in each case. Given a base class, find triples using an instance of subclass as subject or object, and return the subclass used in each case. Without inference, this can be done using property path syntax. CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject . WHERE { ?resource a ?resourceClass . ?resourceType rdfs : subClassOf * knora-base : Resource . ?resource ?resourceValueProperty ?valueObject . ?resourceValueProperty rdfs : subPropertyOf * knora-base : hasValue . This query: Checks that the queried resource belongs to a subclass of knora-base:Resource . Returns the class that the resource explicitly belongs to. Finds the Knora values attached to the resource, and returns each value along with the property that explicitly attaches it to the resource. However, such a query is very inefficient. Instead, the API does inference on the query, so that the relevant information can be found in a timely manner. For this, the query is analyzed to check which project ontologies are relevant to the query. If an ontology is not relevant to a query, then all class and property definitions of this ontology are disregarded for inference. Then, each statement that requires inference (i.e. that could be phrased with property path syntax, as described above) is cross-referenced with the relevant ontologies, to see which property/class definitions would fit the statement according to the rules of RDF inference. And each of those definitions is added to the query as a separate UNION statement. E.g.: Given the resource class B is a subclass of A and the property hasY is a subproperty of hasX , then the following query SELECT { ?res ?prop . } WHERE { ?res a <A> . ?res <hasX> ?prop . } can be rewritten as SELECT { ?res ?prop . } WHERE { { ?res a <A> } UNION { ?res a <B> } . { ?res <hasX> ?prop } UNION { ?res <hasY> ?prop } . }","title":"Inference"},{"location":"DSP-API/05-internals/design/api-v2/query-design/#querying-past-value-versions","text":"Value versions are a linked list, starting with the current version. Each value points to the previous version via knora-base:previousValue . The resource points only to the current version. Past value versions are queried in getResourcePropertiesAndValues.scala.txt , which can take a timestamp argument. Given the current value version, we must find the most recent past version that existed at the target date. First, we get the set of previous values that were created on or before the target date: ?currentValue knora-base:previousValue* ?valueObject . ?valueObject knora-base:valueCreationDate ?valueObjectCreationDate . FILTER(?valueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) The resulting versions are now possible values of ?valueObject . Next, out of this set of versions, we exclude all versions except for the most recent one. We do this by checking, for each ?valueObject , whether there is another version, ?otherValueObject , that is more recent and was also created before the target date. If such a version exists, we exclude the one we are looking at. FILTER NOT EXISTS { ?currentValue knora-base:previousValue* ?otherValueObject . ?otherValueObject knora-base:valueCreationDate ?otherValueObjectCreationDate . FILTER( (?otherValueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) && (?otherValueObjectCreationDate > ?valueObjectCreationDate) ) } This excludes all past versions except the one we are interested in.","title":"Querying Past Value Versions"},{"location":"DSP-API/05-internals/design/api-v2/sipi/","text":"DSP-API and Sipi Configuration The DSP-API specific configuration and scripts for Sipi are in the sipi subdirectory of the DSP-API source tree. See the README.md for instructions on how to start Sipi with DSP-API. Lua Scripts DSP-API v2 uses custom Lua scripts to control Sipi. These scripts can be found in sipi/scripts in the DSP-API source tree. Each of these scripts expects a JSON Web Token in the URL parameter token . In all cases, the token must be signed by DSP-API, it must have an expiration date and not have expired, its issuer must equal the hostname and port of the API, and its audience must include Sipi . The other contents of the expected tokens are described below. upload.lua The upload.lua script is available at Sipi's upload route. It processes one or more file uploads submitted to Sipi. It converts uploaded images to JPEG 2000 format, and stores them in Sipi's tmp directory. The usage of this script is described in Upload Files to Sipi . Each time upload.lua processes a request, it also deletes old temporary files from tmp and (recursively) from any subdirectories. The maximum allowed age of temporary files can be set in Sipi's configuration file, using the parameter max_temp_file_age , which takes a value in seconds, and defaults to 86400 (1 day). store.lua The store.lua script is available at Sipi's store route. It moves a file from temporary to permanent storage. It expects an HTTP POST request containing application/x-www-form-urlencoded data with the parameters prefix (the project shortcode) and filename (the internal Sipi-generated filename of the file to be moved). The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be StoreFile prefix : the project shortcode submitted in the form data filename : the filename submitted in the form data delete_temp_file.lua The delete_temp_file.lua script is available at Sipi's delete_temp_file route. It is used only if DSP-API rejects a file value update request. It expects an HTTP DELETE request, with a filename as the last component of the URL. The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be DeleteTempFile filename : must be the same as the filename submitted in the URL SipiConnector In DSP-API, the org.knora.webapi.iiif.SipiConnector handles all communication with Sipi. It blocks while processing each request, to ensure that the number of concurrent requests to Sipi is not greater than akka.actor.deployment./storeManager/iiifManager/sipiConnector.nr-of-instances . If it encounters an error, it returns SipiException . The Image File Upload Workflow The client uploads an image file to the upload route, which runs upload.lua . The image is converted to JPEG 2000 and stored in Sipi's tmp directory. In the response, the client receives the JPEG 2000's unique, randomly generated filename. The client submits a JSON-LD request to a DSP-API route ( /v2/values or /v2/resources ) to create or change a file value. The request includes Sipi's internal filename. During parsing of this JSON-LD request, a StillImageFileValueContentV2 is constructed to represent the file value. During the construction of this object, a GetFileMetadataRequestV2 is sent to SipiConnector , which uses Sipi's built-in knora.json route to get the rest of the file's metadata. A responder ( ResourcesResponderV2 or ValuesResponderV2 ) validates the request and updates the triplestore. (If it is ResourcesResponderV2 , it asks ValuesResponderV2 to generate SPARQL for the values.) The responder that did the update calls ValueUtilV2.doSipiPostUpdate . If the triplestore update was successful, this method sends MoveTemporaryFileToPermanentStorageRequestV2 to SipiConnector , which makes a request to Sipi's store route. Otherwise, the same method sends DeleteTemporaryFileRequestV2 to SipiConnector , which makes a request to Sipi's delete_temp_file route. If the request to DSP-API cannot be parsed, the temporary file is not deleted immediately, but it will be deleted during the processing of a subsequent request by Sipi's upload route. If Sipi's store route fails, DSP-API returns the SipiException to the client. In this case, manual intervention may be necessary to restore consistency between DSP-API and Sipi. If Sipi's delete_temp_file route fails, the error is not returned to the client, because there is already a DSP-API error that needs to be returned to the client. In this case, the Sipi error is simply logged.","title":"DSP-API and Sipi"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#dsp-api-and-sipi","text":"","title":"DSP-API and Sipi"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#configuration","text":"The DSP-API specific configuration and scripts for Sipi are in the sipi subdirectory of the DSP-API source tree. See the README.md for instructions on how to start Sipi with DSP-API.","title":"Configuration"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#lua-scripts","text":"DSP-API v2 uses custom Lua scripts to control Sipi. These scripts can be found in sipi/scripts in the DSP-API source tree. Each of these scripts expects a JSON Web Token in the URL parameter token . In all cases, the token must be signed by DSP-API, it must have an expiration date and not have expired, its issuer must equal the hostname and port of the API, and its audience must include Sipi . The other contents of the expected tokens are described below.","title":"Lua Scripts"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#uploadlua","text":"The upload.lua script is available at Sipi's upload route. It processes one or more file uploads submitted to Sipi. It converts uploaded images to JPEG 2000 format, and stores them in Sipi's tmp directory. The usage of this script is described in Upload Files to Sipi . Each time upload.lua processes a request, it also deletes old temporary files from tmp and (recursively) from any subdirectories. The maximum allowed age of temporary files can be set in Sipi's configuration file, using the parameter max_temp_file_age , which takes a value in seconds, and defaults to 86400 (1 day).","title":"upload.lua"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#storelua","text":"The store.lua script is available at Sipi's store route. It moves a file from temporary to permanent storage. It expects an HTTP POST request containing application/x-www-form-urlencoded data with the parameters prefix (the project shortcode) and filename (the internal Sipi-generated filename of the file to be moved). The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be StoreFile prefix : the project shortcode submitted in the form data filename : the filename submitted in the form data","title":"store.lua"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#delete_temp_filelua","text":"The delete_temp_file.lua script is available at Sipi's delete_temp_file route. It is used only if DSP-API rejects a file value update request. It expects an HTTP DELETE request, with a filename as the last component of the URL. The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be DeleteTempFile filename : must be the same as the filename submitted in the URL","title":"delete_temp_file.lua"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#sipiconnector","text":"In DSP-API, the org.knora.webapi.iiif.SipiConnector handles all communication with Sipi. It blocks while processing each request, to ensure that the number of concurrent requests to Sipi is not greater than akka.actor.deployment./storeManager/iiifManager/sipiConnector.nr-of-instances . If it encounters an error, it returns SipiException .","title":"SipiConnector"},{"location":"DSP-API/05-internals/design/api-v2/sipi/#the-image-file-upload-workflow","text":"The client uploads an image file to the upload route, which runs upload.lua . The image is converted to JPEG 2000 and stored in Sipi's tmp directory. In the response, the client receives the JPEG 2000's unique, randomly generated filename. The client submits a JSON-LD request to a DSP-API route ( /v2/values or /v2/resources ) to create or change a file value. The request includes Sipi's internal filename. During parsing of this JSON-LD request, a StillImageFileValueContentV2 is constructed to represent the file value. During the construction of this object, a GetFileMetadataRequestV2 is sent to SipiConnector , which uses Sipi's built-in knora.json route to get the rest of the file's metadata. A responder ( ResourcesResponderV2 or ValuesResponderV2 ) validates the request and updates the triplestore. (If it is ResourcesResponderV2 , it asks ValuesResponderV2 to generate SPARQL for the values.) The responder that did the update calls ValueUtilV2.doSipiPostUpdate . If the triplestore update was successful, this method sends MoveTemporaryFileToPermanentStorageRequestV2 to SipiConnector , which makes a request to Sipi's store route. Otherwise, the same method sends DeleteTemporaryFileRequestV2 to SipiConnector , which makes a request to Sipi's delete_temp_file route. If the request to DSP-API cannot be parsed, the temporary file is not deleted immediately, but it will be deleted during the processing of a subsequent request by Sipi's upload route. If Sipi's store route fails, DSP-API returns the SipiException to the client. In this case, manual intervention may be necessary to restore consistency between DSP-API and Sipi. If Sipi's delete_temp_file route fails, the error is not returned to the client, because there is already a DSP-API error that needs to be returned to the client. In this case, the Sipi error is simply logged.","title":"The Image File Upload Workflow"},{"location":"DSP-API/05-internals/design/api-v2/smart-iris/","text":"Smart IRIs Usage The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org . knora . webapi . messages . SmartIri import org . knora . webapi . messages . IriConversions . _ Ensure that an implicit instance of StringFormatter is in scope: import org . knora . webapi . messages . StringFormatter implicit val stringFormatter : StringFormatter = StringFormatter . getGeneralInstance Then, if you have a string representing an IRI, you can can convert it to a SmartIri like this: val propertyIri : SmartIri = \"http://0.0.0.0:3333/ontology/0001/anything/v2#hasInteger\" . toSmartIri ``` ` If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: ` `` scala val propertyIri : SmartIri = propertyIriStr . toSmartIriWithErr ( throw BadRequestException ( s\"Invalid property IRI: < $ propertyIriStr >\" )) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri , and represent it as an org.knora.webapi.IRI (an alias for String ). Implementation The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the Scala type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance , which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies (see Generation of Ontologies in External Schemas ). This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Smart IRIs"},{"location":"DSP-API/05-internals/design/api-v2/smart-iris/#smart-iris","text":"","title":"Smart IRIs"},{"location":"DSP-API/05-internals/design/api-v2/smart-iris/#usage","text":"The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org . knora . webapi . messages . SmartIri import org . knora . webapi . messages . IriConversions . _ Ensure that an implicit instance of StringFormatter is in scope: import org . knora . webapi . messages . StringFormatter implicit val stringFormatter : StringFormatter = StringFormatter . getGeneralInstance Then, if you have a string representing an IRI, you can can convert it to a SmartIri like this: val propertyIri : SmartIri = \"http://0.0.0.0:3333/ontology/0001/anything/v2#hasInteger\" . toSmartIri ``` ` If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: ` `` scala val propertyIri : SmartIri = propertyIriStr . toSmartIriWithErr ( throw BadRequestException ( s\"Invalid property IRI: < $ propertyIriStr >\" )) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri , and represent it as an org.knora.webapi.IRI (an alias for String ).","title":"Usage"},{"location":"DSP-API/05-internals/design/api-v2/smart-iris/#implementation","text":"The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the Scala type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance , which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies (see Generation of Ontologies in External Schemas ). This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Implementation"},{"location":"DSP-API/05-internals/design/api-v2/standoff/","text":"Standoff Markup Requirements In Knora, text with markup is stored using standoff markup, i.e. markup that is stored separately from the content it applies to. Knora's standoff design is based on these requirements: Overlapping markup should be supported. Markup should be stored as RDF, so it can be searched and analysed using the same tools that are used with other data managed by Knora. In particular, Gravsearch queries should be able to specify search criteria that refer to the markup tags attached to a text, together with any other search criteria relating to the resource that contains the text. It should be possible to import any XML document into Knora, store the markup as standoff, and at any time export the document as an equivalent XML document. RDF Design See Text with Standoff Markup . Querying Standoff Since the number of standoff tags that can be attached to a text value is unlimited, standoff is queried in pages of a limited size, to avoid requesting huge SPARQL query results from the triplestore. When ResourcesResponderV2 or SearchResponderV2 need to return a text value with all its markup, they first query the text value with at most one page of standoff. If the text value has more than one page of standoff, ConstructResponseUtilV2.makeTextValueContentV2 then sends a GetRemainingStandoffFromTextValueRequestV2 message to StandoffResponderV2 , which queries the rest of the standoff in the text value, one page at a time. The resulting standoff is concatenated together and returned. To optimise query performance: Each text value with standoff has the predicate knora-base:valueHasMaxStandoffStartIndex , so that when Knora queries a page of standoff, it knows whether it has reached the last page. The last path component of the IRI of a standoff tag is the integer object of its knora-base:standoffTagHasStartIndex predicate. When querying standoff, it is necessary to convert the IRI objects of knora-base:standoffTagHasStartParent and knora-base:standoffTagHasEndParent to integer indexes (the start indexes of those tags). Including each tag's start index in its IRI makes it unnecessary to query the parent tags to determine their start indexes. Conversion Between Standoff and XML XMLToStandoffUtil does the low-level conversion of documents between standoff and XML, using a simple data structure to represent standoff. This data structure knows nothing about RDF, and each standoff tag contains its XML element name and namespace and those of its attributes. In Knora, it is possible to define mappings to control how standoff/RDF is converted to XML and vice versa. Different mappings can be used to convert the same standoff/RDF to different sorts of XML documents. StandoffTagUtilV2 converts between standoff/RDF and XML using mappings, delegating the lower-level work to XMLToStandoffUtil .","title":"Standoff Markup"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#standoff-markup","text":"","title":"Standoff Markup"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#requirements","text":"In Knora, text with markup is stored using standoff markup, i.e. markup that is stored separately from the content it applies to. Knora's standoff design is based on these requirements: Overlapping markup should be supported. Markup should be stored as RDF, so it can be searched and analysed using the same tools that are used with other data managed by Knora. In particular, Gravsearch queries should be able to specify search criteria that refer to the markup tags attached to a text, together with any other search criteria relating to the resource that contains the text. It should be possible to import any XML document into Knora, store the markup as standoff, and at any time export the document as an equivalent XML document.","title":"Requirements"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#rdf-design","text":"See Text with Standoff Markup .","title":"RDF Design"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#querying-standoff","text":"Since the number of standoff tags that can be attached to a text value is unlimited, standoff is queried in pages of a limited size, to avoid requesting huge SPARQL query results from the triplestore. When ResourcesResponderV2 or SearchResponderV2 need to return a text value with all its markup, they first query the text value with at most one page of standoff. If the text value has more than one page of standoff, ConstructResponseUtilV2.makeTextValueContentV2 then sends a GetRemainingStandoffFromTextValueRequestV2 message to StandoffResponderV2 , which queries the rest of the standoff in the text value, one page at a time. The resulting standoff is concatenated together and returned. To optimise query performance: Each text value with standoff has the predicate knora-base:valueHasMaxStandoffStartIndex , so that when Knora queries a page of standoff, it knows whether it has reached the last page. The last path component of the IRI of a standoff tag is the integer object of its knora-base:standoffTagHasStartIndex predicate. When querying standoff, it is necessary to convert the IRI objects of knora-base:standoffTagHasStartParent and knora-base:standoffTagHasEndParent to integer indexes (the start indexes of those tags). Including each tag's start index in its IRI makes it unnecessary to query the parent tags to determine their start indexes.","title":"Querying Standoff"},{"location":"DSP-API/05-internals/design/api-v2/standoff/#conversion-between-standoff-and-xml","text":"XMLToStandoffUtil does the low-level conversion of documents between standoff and XML, using a simple data structure to represent standoff. This data structure knows nothing about RDF, and each standoff tag contains its XML element name and namespace and those of its attributes. In Knora, it is possible to define mappings to control how standoff/RDF is converted to XML and vice versa. Different mappings can be used to convert the same standoff/RDF to different sorts of XML documents. StandoffTagUtilV2 converts between standoff/RDF and XML using mappings, delegating the lower-level work to XMLToStandoffUtil .","title":"Conversion Between Standoff and XML"},{"location":"DSP-API/05-internals/design/principles/authentication/","text":"Authentication in Knora Scope Authentication is the process of making sure that if someone is accessing something then this someone is actually also the someone he pretends to be. The process of making sure that someone is authorized, i.e. has the permission to access something, is handled as described in Authorisation ). Implementation The authentication in Knora is based on Basic Auth HTTP basic authentication , URL parameters, JSON Web Token , and cookies. This means that on every request (to any of the routes), credentials need to be sent either via authorization header, URL parameters or cookie header. All routes are always accessible and if there are no credentials provided, a default user is assumed. If credentials are sent and they are not correct (e.g., wrong username, password incorrect, token expired), then the request will end in an error message. There are some differences in V1 and V2 of the API regarding authentication. They differ mainly in the format of the response and that creation of session cookies are only supported in V1 and tokens in V2 . After login via either version, all routes ( V1 and V2 ) are accessible. Skipping Authentication There is the possibility to turn skipping authentication on and use a hardcoded user (Test User). In application.conf set the skip-authentication = true and Test User will be always assumed.","title":"Authentication"},{"location":"DSP-API/05-internals/design/principles/authentication/#authentication-in-knora","text":"","title":"Authentication in Knora"},{"location":"DSP-API/05-internals/design/principles/authentication/#scope","text":"Authentication is the process of making sure that if someone is accessing something then this someone is actually also the someone he pretends to be. The process of making sure that someone is authorized, i.e. has the permission to access something, is handled as described in Authorisation ).","title":"Scope"},{"location":"DSP-API/05-internals/design/principles/authentication/#implementation","text":"The authentication in Knora is based on Basic Auth HTTP basic authentication , URL parameters, JSON Web Token , and cookies. This means that on every request (to any of the routes), credentials need to be sent either via authorization header, URL parameters or cookie header. All routes are always accessible and if there are no credentials provided, a default user is assumed. If credentials are sent and they are not correct (e.g., wrong username, password incorrect, token expired), then the request will end in an error message. There are some differences in V1 and V2 of the API regarding authentication. They differ mainly in the format of the response and that creation of session cookies are only supported in V1 and tokens in V2 . After login via either version, all routes ( V1 and V2 ) are accessible.","title":"Implementation"},{"location":"DSP-API/05-internals/design/principles/authentication/#skipping-authentication","text":"There is the possibility to turn skipping authentication on and use a hardcoded user (Test User). In application.conf set the skip-authentication = true and Test User will be always assumed.","title":"Skipping Authentication"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/","text":"Consistency Checking Attention! GraphDB is not supported anymore, therefore parts related to it in this document are redundant. Requirements Knora is designed to prevent inconsistencies in RDF data, as far as is practical, in a triplestore-independent way (see Triplestore Updates ). However, it is also useful to enforce consistency constraints in the triplestore itself, for two reasons: To prevent inconsistencies resulting from bugs in the DSP-API server. To prevent users from inserting inconsistent data directly into the triplestore, bypassing Knora. The design of the knora-base ontology supports two ways of specifying constraints on data (see knora-base: Consistency Checking for details): A property definition should specify the types that are allowed as subjects and objects of the property, using knora-base:subjectClassConstraint and (if it is an object property) knora-base:objectClassConstraint . Every subproperty of knora-base:hasValue or a knora-base:hasLinkTo (i.e. every property of a resource that points to a knora-base:Value or to another resource) is required have this constraint, because the DSP-API server relies on it to know what type of object to expect for the property. Use of knora-base:subjectClassConstraint is recommended but not required. A class definition should use OWL cardinalities (see OWL 2 Quick Reference Guide ) to indicate the properties that instances of the class are allowed to have, and to constrain the number of objects that each property can have. Subclasses of knora-base:Resource are required to have a cardinality for each subproperty of knora-base:hasValue or a knora-base:hasLinkTo that resources of that class can have. Specifically, consistency checking should prevent the following: An object property or datatype property has a subject of the wrong class, or an object property has an object of the wrong class (GraphDB's consistency checke cannot check the types of literals). An object property has an object that does not exist (i.e. the object is an IRI that is not used as the subject of any statements in the repository). This can be treated as if the object is of the wrong type (i.e. it can cause a violation of knora-base:objectClassConstraint , because there is no compatible rdf:type statement for the object). A class has owl:cardinality 1 or owl:minCardinality 1 on an object property or datatype property, and an instance of the class does not have that property. A class has owl:cardinality 1 or owl:maxCardinality 1 on an object property or datatype property, and an instance of the class has more than one object for that property. An instance of knora-base:Resource has an object property pointing to a knora-base:Value or to another Resource , and its class has no cardinality for that property. An instance of knora-base:Value has a subproperty of knora-base:valueHas , and its class has no cardinality for that property. A datatype property has an empty string as an object. Cardinalities in base classes are inherited by derived classes. Derived classes can override inherited cardinalities by making them more restrictive, i.e. by specifying a subproperty of the one specified in the original cardinality. Instances of Resource and Value can be marked as deleted, using the property isDeleted . This must be taken into account as follows: With owl:cardinality 1 or owl:maxCardinality 1 , if the object of the property can be marked as deleted, the property must not have more than one object that has not been marked as deleted. In other words, it's OK if there is more than one object, as long only one of them has knora-base:isDeleted false . With owl:cardinality 1 or owl:minCardinality 1 , the property must have an object, but it's OK if the property's only object is marked as deleted. We allow this because the subject and object may have different owners, and it may not be feasible for them to coordinate their work. The owner of the object should always be able to mark it as deleted. (It could be useful to notify the owner of the subject when this happens, but that is beyond the scope of consistency checking.) Design Ontotext GraphDB provides a mechanism for checking the consistency of data in a repository each time an update transaction is committed. Knora provides GraphDB-specific consistency rules that take advantage of this feature to provide an extra layer of consistency checks, in addition to the checks that are implemented in Knora. When a repository is created in GraphDB, a set of consistency rules can be provided, and GraphDB's consistency checker can be turned on to ensure that each update transaction respects these rules, as described in the section Reasoning of the GraphDB documentation. Like custom inference rules, consistency rules are defined in files with the .pie filename extension, in a GraphDB-specific syntax. We have added rules to the standard RDFS inference rules file builtin_RdfsRules.pie , to create the file KnoraRules.pie . The .ttl configuration file that is used to create the repository must contain these settings: owlim:ruleset \"/path/to/KnoraRules.pie\" ; owlim:check-for-inconsistencies \"true\" ; The path to KnoraRules.pie must be an absolute path. The scripts provided with Knora to create test repositories set this path automatically. Consistency checking in GraphDB relies on reasoning. GraphDB's reasoning is Forward-chaining , which means that reasoning is applied to the contents of each update, before the update transaction is committed, and the inferred statements are added to the repository. A GraphDB rules file can contain two types of rules: inference rules and consistency rules. Before committing an update transaction, GraphDB applies inference rules, then consistency rules. If any of the consistency rules are violated, the transaction is rolled back. An inference rule has this form: Id: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The premises are a pattern that tries to match statements found in the data. Optional constraints, which are enclosed in square brackets, make it possible to specify the premises more precisely, or to specify a named graph (see examples below). Consequences are the statements that will be inferred if the premises match. A line of hyphens separates premises from consequences. A GraphDB consistency rule has a similar form: Consistency: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The differences between inference rules and consistency rules are: A consistency rule begins with Consistency instead of Id . In a consistency rule, the consequences are optional. Instead of representing statements to be inferred, they represent statements that must exist if the premises are satisfied. In other words, if the premises are satisfied and the consequences are not found, the rule is violated. If a consistency rule doesn't specify any consequences, and the premises are satisfied, the rule is violated. Rules use variable names for subjects, predicates, and objects, and they can use actual property names. Empty string as object If subject i has a predicate p whose object is an empty string, the constraint is violated: Consistency: empty_string i p \"\" ------------------------------------ Subject and object class constraints If subject i has a predicate p that requires a subject of type t , and i is not a t , the constraint is violated: Consistency: subject_class_constraint p <knora-base:subjectClassConstraint> t i p j ------------------------------------ i <rdf:type> t If subject i has a predicate p that requires an object of type t , and the object of p is not a t , the constraint is violated: Consistency: object_class_constraint p <knora-base:objectClassConstraint> t i p j ------------------------------------ j <rdf:type> t Cardinality constraints A simple implementation of a consistency rule to check owl:maxCardinality 1 , for objects that can be marked as deleted, could look like this: Consistency: max_cardinality_1_with_deletion_flag i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p i p j i p k [Constraint j != k] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ This means: if resource i is a subclass of an owl:Restriction r with owl:maxCardinality 1 on property p , and the resource has two different objects for that property, neither of which is marked as deleted, the rule is violated. Note that this takes advantage of the fact that Resource and Value have owl:cardinality 1 on isDeleted ( isDeleted must be present even if false), so we do not need to check whether i is actually something that can be marked as deleted. However, this implementation would be much too slow. We therefore use two optimisations suggested by Ontotext: Add custom inference rules to make tables (i.e. named graphs) of pre-calculated information about the cardinalities on properties of subjects, and use those tables to simplify the consistency rules. Use the [Cut] constraint to avoid generating certain redundant compiled rules (see Entailment rules ). For example, to construct a table of subjects belonging to classes that have owl:maxCardinality 1 on some property p , we use the following custom inference rule: Id: maxCardinality_1_table i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p ------------------------------------ i p r [Context <onto:_maxCardinality_1_table>] The constraint [Context <onto:_maxCardinality_1_table>] means that the inferred triples are added to the context (i.e. the named graph) http://www.ontotext.com/_maxCardinality_1_table . (Note that we have defined the prefix onto as http://www.ontotext.com/ in the Prefices section of the rules file.) As the GraphDB documentation on Rules explains: If the context is provided, the statements produced as rule consequences are not \u2018visible\u2019 during normal query answering. Instead, they can only be used as input to this or other rules and only when the rule premise explicitly uses the given context. Now, to find out whether a subject belongs to a class with that cardinality on a given property, we only need to match one triple. The revised implementation of the rule max_cardinality_1_with_deletion_flag is as follows: Consistency: max_cardinality_1_with_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ The constraint [Constraint j != k] means that the premises will be satisfied only if the variables j and k do not refer to the same thing. With these optimisations, the rule is faster by several orders of magnitude. Since properties whose objects can be marked as deleted must be handled differently to properties whose objects cannot be marked as deleted, the knora-base ontology provides a property called objectCannotBeMarkedAsDeleted . All properties in knora-base whose objects cannot take the isDeleted flag (including datatype properties) should be derived from this property. This is how it is used to check owl:maxCardinality 1 for objects that cannot be marked as deleted: Consistency: max_cardinality_1_without_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] p <rdfs:subPropertyOf> <knora-base:objectCannotBeMarkedAsDeleted> i p j [Constraint j != k] i p k [Cut] ------------------------------------ To check owl:minCardinality 1 , we do not care whether the object can be marked as deleted, so we can use this simple rule: Consistency: min_cardinality_1_any_object i p r [Context <onto:_minCardinality_1_table>] ------------------------------------ i p j This means: if a subject i belongs to a class that has owl:minCardinality 1 on property p , and i has no object for p , the rule is violated. To check owl:cardinality 1 , we need two rules: one that checks whether there are too few objects, and one that checks whether there are too many. To check whether there are too few objects, we don't care whether the objects can be marked as deleted, so the rule is the same as min_cardinality_1_any_object , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j To check whether there are too many objects, we need to know whether the objects can be marked as deleted or not. In the case where the objects can be marked as deleted, the rule is the same as max_cardinality_1_with_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_greater_with_deletion_flag i p r [Context <onto:_cardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ In the case where the objects cannot be marked as deleted, the rule is the same as max_cardinality_1_without_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j Knora allows a subproperty of knora-base:hasValue or knora-base:hasLinkTo to be a predicate of a resource only if the resource's class has some cardinality for the property. For convenience, knora-base:hasValue and knora-base:hasLinkTo are subproperties of knora-base:resourceProperty , which is used to check this constraint in the following rule: Consistency: resource_prop_cardinality_any i <knora-base:resourceProperty> j ------------------------------------ i p j i <rdf:type> r r <owl:onProperty> p If resource i has a subproperty of knora-base:resourceProperty , and i is not a member of a subclass of an owl:Restriction r with a cardinality on that property (or on one of its base properties), the rule is violated. A similar rule, value_prop_cardinality_any , ensures that if a value has a subproperty of knora-base:valueHas , the value's class has some cardinality for that property.","title":"Consistency Checking"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#consistency-checking","text":"Attention! GraphDB is not supported anymore, therefore parts related to it in this document are redundant.","title":"Consistency Checking"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#requirements","text":"Knora is designed to prevent inconsistencies in RDF data, as far as is practical, in a triplestore-independent way (see Triplestore Updates ). However, it is also useful to enforce consistency constraints in the triplestore itself, for two reasons: To prevent inconsistencies resulting from bugs in the DSP-API server. To prevent users from inserting inconsistent data directly into the triplestore, bypassing Knora. The design of the knora-base ontology supports two ways of specifying constraints on data (see knora-base: Consistency Checking for details): A property definition should specify the types that are allowed as subjects and objects of the property, using knora-base:subjectClassConstraint and (if it is an object property) knora-base:objectClassConstraint . Every subproperty of knora-base:hasValue or a knora-base:hasLinkTo (i.e. every property of a resource that points to a knora-base:Value or to another resource) is required have this constraint, because the DSP-API server relies on it to know what type of object to expect for the property. Use of knora-base:subjectClassConstraint is recommended but not required. A class definition should use OWL cardinalities (see OWL 2 Quick Reference Guide ) to indicate the properties that instances of the class are allowed to have, and to constrain the number of objects that each property can have. Subclasses of knora-base:Resource are required to have a cardinality for each subproperty of knora-base:hasValue or a knora-base:hasLinkTo that resources of that class can have. Specifically, consistency checking should prevent the following: An object property or datatype property has a subject of the wrong class, or an object property has an object of the wrong class (GraphDB's consistency checke cannot check the types of literals). An object property has an object that does not exist (i.e. the object is an IRI that is not used as the subject of any statements in the repository). This can be treated as if the object is of the wrong type (i.e. it can cause a violation of knora-base:objectClassConstraint , because there is no compatible rdf:type statement for the object). A class has owl:cardinality 1 or owl:minCardinality 1 on an object property or datatype property, and an instance of the class does not have that property. A class has owl:cardinality 1 or owl:maxCardinality 1 on an object property or datatype property, and an instance of the class has more than one object for that property. An instance of knora-base:Resource has an object property pointing to a knora-base:Value or to another Resource , and its class has no cardinality for that property. An instance of knora-base:Value has a subproperty of knora-base:valueHas , and its class has no cardinality for that property. A datatype property has an empty string as an object. Cardinalities in base classes are inherited by derived classes. Derived classes can override inherited cardinalities by making them more restrictive, i.e. by specifying a subproperty of the one specified in the original cardinality. Instances of Resource and Value can be marked as deleted, using the property isDeleted . This must be taken into account as follows: With owl:cardinality 1 or owl:maxCardinality 1 , if the object of the property can be marked as deleted, the property must not have more than one object that has not been marked as deleted. In other words, it's OK if there is more than one object, as long only one of them has knora-base:isDeleted false . With owl:cardinality 1 or owl:minCardinality 1 , the property must have an object, but it's OK if the property's only object is marked as deleted. We allow this because the subject and object may have different owners, and it may not be feasible for them to coordinate their work. The owner of the object should always be able to mark it as deleted. (It could be useful to notify the owner of the subject when this happens, but that is beyond the scope of consistency checking.)","title":"Requirements"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#design","text":"Ontotext GraphDB provides a mechanism for checking the consistency of data in a repository each time an update transaction is committed. Knora provides GraphDB-specific consistency rules that take advantage of this feature to provide an extra layer of consistency checks, in addition to the checks that are implemented in Knora. When a repository is created in GraphDB, a set of consistency rules can be provided, and GraphDB's consistency checker can be turned on to ensure that each update transaction respects these rules, as described in the section Reasoning of the GraphDB documentation. Like custom inference rules, consistency rules are defined in files with the .pie filename extension, in a GraphDB-specific syntax. We have added rules to the standard RDFS inference rules file builtin_RdfsRules.pie , to create the file KnoraRules.pie . The .ttl configuration file that is used to create the repository must contain these settings: owlim:ruleset \"/path/to/KnoraRules.pie\" ; owlim:check-for-inconsistencies \"true\" ; The path to KnoraRules.pie must be an absolute path. The scripts provided with Knora to create test repositories set this path automatically. Consistency checking in GraphDB relies on reasoning. GraphDB's reasoning is Forward-chaining , which means that reasoning is applied to the contents of each update, before the update transaction is committed, and the inferred statements are added to the repository. A GraphDB rules file can contain two types of rules: inference rules and consistency rules. Before committing an update transaction, GraphDB applies inference rules, then consistency rules. If any of the consistency rules are violated, the transaction is rolled back. An inference rule has this form: Id: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The premises are a pattern that tries to match statements found in the data. Optional constraints, which are enclosed in square brackets, make it possible to specify the premises more precisely, or to specify a named graph (see examples below). Consequences are the statements that will be inferred if the premises match. A line of hyphens separates premises from consequences. A GraphDB consistency rule has a similar form: Consistency: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The differences between inference rules and consistency rules are: A consistency rule begins with Consistency instead of Id . In a consistency rule, the consequences are optional. Instead of representing statements to be inferred, they represent statements that must exist if the premises are satisfied. In other words, if the premises are satisfied and the consequences are not found, the rule is violated. If a consistency rule doesn't specify any consequences, and the premises are satisfied, the rule is violated. Rules use variable names for subjects, predicates, and objects, and they can use actual property names.","title":"Design"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#empty-string-as-object","text":"If subject i has a predicate p whose object is an empty string, the constraint is violated: Consistency: empty_string i p \"\" ------------------------------------","title":"Empty string as object"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#subject-and-object-class-constraints","text":"If subject i has a predicate p that requires a subject of type t , and i is not a t , the constraint is violated: Consistency: subject_class_constraint p <knora-base:subjectClassConstraint> t i p j ------------------------------------ i <rdf:type> t If subject i has a predicate p that requires an object of type t , and the object of p is not a t , the constraint is violated: Consistency: object_class_constraint p <knora-base:objectClassConstraint> t i p j ------------------------------------ j <rdf:type> t","title":"Subject and object class constraints"},{"location":"DSP-API/05-internals/design/principles/consistency-checking/#cardinality-constraints","text":"A simple implementation of a consistency rule to check owl:maxCardinality 1 , for objects that can be marked as deleted, could look like this: Consistency: max_cardinality_1_with_deletion_flag i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p i p j i p k [Constraint j != k] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ This means: if resource i is a subclass of an owl:Restriction r with owl:maxCardinality 1 on property p , and the resource has two different objects for that property, neither of which is marked as deleted, the rule is violated. Note that this takes advantage of the fact that Resource and Value have owl:cardinality 1 on isDeleted ( isDeleted must be present even if false), so we do not need to check whether i is actually something that can be marked as deleted. However, this implementation would be much too slow. We therefore use two optimisations suggested by Ontotext: Add custom inference rules to make tables (i.e. named graphs) of pre-calculated information about the cardinalities on properties of subjects, and use those tables to simplify the consistency rules. Use the [Cut] constraint to avoid generating certain redundant compiled rules (see Entailment rules ). For example, to construct a table of subjects belonging to classes that have owl:maxCardinality 1 on some property p , we use the following custom inference rule: Id: maxCardinality_1_table i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p ------------------------------------ i p r [Context <onto:_maxCardinality_1_table>] The constraint [Context <onto:_maxCardinality_1_table>] means that the inferred triples are added to the context (i.e. the named graph) http://www.ontotext.com/_maxCardinality_1_table . (Note that we have defined the prefix onto as http://www.ontotext.com/ in the Prefices section of the rules file.) As the GraphDB documentation on Rules explains: If the context is provided, the statements produced as rule consequences are not \u2018visible\u2019 during normal query answering. Instead, they can only be used as input to this or other rules and only when the rule premise explicitly uses the given context. Now, to find out whether a subject belongs to a class with that cardinality on a given property, we only need to match one triple. The revised implementation of the rule max_cardinality_1_with_deletion_flag is as follows: Consistency: max_cardinality_1_with_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ The constraint [Constraint j != k] means that the premises will be satisfied only if the variables j and k do not refer to the same thing. With these optimisations, the rule is faster by several orders of magnitude. Since properties whose objects can be marked as deleted must be handled differently to properties whose objects cannot be marked as deleted, the knora-base ontology provides a property called objectCannotBeMarkedAsDeleted . All properties in knora-base whose objects cannot take the isDeleted flag (including datatype properties) should be derived from this property. This is how it is used to check owl:maxCardinality 1 for objects that cannot be marked as deleted: Consistency: max_cardinality_1_without_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] p <rdfs:subPropertyOf> <knora-base:objectCannotBeMarkedAsDeleted> i p j [Constraint j != k] i p k [Cut] ------------------------------------ To check owl:minCardinality 1 , we do not care whether the object can be marked as deleted, so we can use this simple rule: Consistency: min_cardinality_1_any_object i p r [Context <onto:_minCardinality_1_table>] ------------------------------------ i p j This means: if a subject i belongs to a class that has owl:minCardinality 1 on property p , and i has no object for p , the rule is violated. To check owl:cardinality 1 , we need two rules: one that checks whether there are too few objects, and one that checks whether there are too many. To check whether there are too few objects, we don't care whether the objects can be marked as deleted, so the rule is the same as min_cardinality_1_any_object , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j To check whether there are too many objects, we need to know whether the objects can be marked as deleted or not. In the case where the objects can be marked as deleted, the rule is the same as max_cardinality_1_with_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_greater_with_deletion_flag i p r [Context <onto:_cardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ In the case where the objects cannot be marked as deleted, the rule is the same as max_cardinality_1_without_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j Knora allows a subproperty of knora-base:hasValue or knora-base:hasLinkTo to be a predicate of a resource only if the resource's class has some cardinality for the property. For convenience, knora-base:hasValue and knora-base:hasLinkTo are subproperties of knora-base:resourceProperty , which is used to check this constraint in the following rule: Consistency: resource_prop_cardinality_any i <knora-base:resourceProperty> j ------------------------------------ i p j i <rdf:type> r r <owl:onProperty> p If resource i has a subproperty of knora-base:resourceProperty , and i is not a member of a subclass of an owl:Restriction r with a cardinality on that property (or on one of its base properties), the rule is violated. A similar rule, value_prop_cardinality_any , ensures that if a value has a subproperty of knora-base:valueHas , the value's class has some cardinality for that property.","title":"Cardinality constraints"},{"location":"DSP-API/05-internals/design/principles/design-overview/","text":"DSP-API Server Design Overview Introduction DSP-API's responsibilites are: Querying, creating, updating, and deleting data Creating, updating and deleting data models (ontologies) Managing projects and users Authentication of clients Authorisation of clients' requests DSP-API is developed with Scala and uses the Akka framework for message-based concurrency. It is designed to work with the Apache Jena Fuseki triplestore which is compliant to the SPARQL 1.1 Protocol . For file storage, it uses Sipi . DSP-API Versions There are two versions of DSP-API: DSP-API v2, the latest DSP-API that should be used DSP-API v1, legacy API compatibile with applications that used the prototype software. There is also an Admin API for administrating DSP projects. Internally, DSP-API v1 and v2 both use functionality in the admin API. DSP-API v1 uses some functionality from API v2, but API v2 does not depend on API v1. Error Handling The error-handling design has these aims: Simplify the error-handling code in actors as much as possible. Produce error messages that clearly indicate the context in which the error occurred (i.e. what the application was trying to do). Ensure that clients receive an appropriate error message when an error occurs. Ensure that ask requests are properly terminated with an akka.actor.Status.Failure message in the event of an error, without which they will simply time out (see Ask: Send and Receive Future ). When a actor encounters an error that isn't the client's fault (e.g. a triplestore failure), log it, but don't do this with errors caused by bad input. When logging errors, include the full JVM stack trace. A hierarchy of exception classes is defined in Exceptions.scala , representing different sorts of errors that could occur. The hierarchy has two main branches: RequestRejectedException , an abstract class for errors that are the client's fault. These errors are not logged. InternalServerException , an abstract class for errors that are not the client's fault. These errors are logged. Exception classes in this hierarchy can be defined to include a wrapped cause exception. When an exception is logged, its stack trace will be logged along with the stack trace of its cause . It is therefore recommended that low-level code should catch low-level exceptions, and wrap them in one of our higher-level exceptions, in order to clarify the context in which the error occurred. To simplify error-handling in responders, a utility method called future2Message is provided in ActorUtils . It is intended to be used in an actor's receive method to respond to messages in the ask pattern. If the responder's computation is successful, it is sent to the requesting actor as a response to the ask . If the computation fails, the exception representing the failure is wrapped in a Status.Failure , which is sent as a response to the ask . If the error is a subclass of RequestRejectedException , only the sender is notified of the error; otherwise, the error is also logged and rethrown (so that the KnoraExceptionHandler can handle the exception). In many cases, we transform data from the triplestore into a Map object. To simplify checking for required values in these collections, the class ErrorHandlingMap is provided. You can wrap any Map in an ErrorHandlingMap . You must provide a function that will generate an error message when a required value is missing, and optionally a function that throws a particular exception. Rows of SPARQL query results are already returned in ErrorHandlingMap objects. If you want to add a new exception class, see the comments in Exceptions.scala for instructions. Transformation of Exception to Client Responses The org.knora.webapi.KnoraExceptionHandler is brought implicitly into scope of akka-http , and by doing so registered and used to handle the transformation of all KnoraExceptions into HttpResponses . This handler handles only exceptions thrown inside the route and not the actors. However, the design of reply message passing from actors (by using future2Message ), makes sure that any exceptions thrown inside actors, will reach the route, where they will be handled. See also Futures with Akka . API Routing The API routes in the routing package are defined using the DSL provided by the akka-http library. A routing function has to do the following: Authenticate the client. Figure out what the client is asking for. Construct an appropriate request message and send it to ResponderManagerV1 , using the ask pattern. Return a result to the client. To simplify the coding of routing functions, they are contained in objects that extend org.knora.webapi.routing.Authenticator . Each routing function performs the following operations: Authenticator.getUserADM is called to authenticate the user. The request parameters are interpreted and validated, and a request message is constructed to send to the responder. If the request is invalid, BadRequestException is thrown. If the request message is requesting an update operation, it must include a UUID generated by UUID.randomUUID , so the responder can obtain a write lock on the resource being updated. The routing function then passes the message to a function in an API-specific routing utility: RouteUtilV1 , RouteUtilV2 , or RouteUtilADM . This utility function sends the message to ResponderManager (which forwards it to the relevant responder), returns a response to the client in the appropriate format, and handles any errors. Logging Logging in DSP-API is configurable through logback.xml , allowing fine grain configuration of what classes / objects should be logged from which level. The Akka Actors use Akka Logging while logging inside plain Scala Objects and Classes is done through Scala Logging .","title":"Design Overview"},{"location":"DSP-API/05-internals/design/principles/design-overview/#dsp-api-server-design-overview","text":"","title":"DSP-API Server Design Overview"},{"location":"DSP-API/05-internals/design/principles/design-overview/#introduction","text":"DSP-API's responsibilites are: Querying, creating, updating, and deleting data Creating, updating and deleting data models (ontologies) Managing projects and users Authentication of clients Authorisation of clients' requests DSP-API is developed with Scala and uses the Akka framework for message-based concurrency. It is designed to work with the Apache Jena Fuseki triplestore which is compliant to the SPARQL 1.1 Protocol . For file storage, it uses Sipi .","title":"Introduction"},{"location":"DSP-API/05-internals/design/principles/design-overview/#dsp-api-versions","text":"There are two versions of DSP-API: DSP-API v2, the latest DSP-API that should be used DSP-API v1, legacy API compatibile with applications that used the prototype software. There is also an Admin API for administrating DSP projects. Internally, DSP-API v1 and v2 both use functionality in the admin API. DSP-API v1 uses some functionality from API v2, but API v2 does not depend on API v1.","title":"DSP-API Versions"},{"location":"DSP-API/05-internals/design/principles/design-overview/#error-handling","text":"The error-handling design has these aims: Simplify the error-handling code in actors as much as possible. Produce error messages that clearly indicate the context in which the error occurred (i.e. what the application was trying to do). Ensure that clients receive an appropriate error message when an error occurs. Ensure that ask requests are properly terminated with an akka.actor.Status.Failure message in the event of an error, without which they will simply time out (see Ask: Send and Receive Future ). When a actor encounters an error that isn't the client's fault (e.g. a triplestore failure), log it, but don't do this with errors caused by bad input. When logging errors, include the full JVM stack trace. A hierarchy of exception classes is defined in Exceptions.scala , representing different sorts of errors that could occur. The hierarchy has two main branches: RequestRejectedException , an abstract class for errors that are the client's fault. These errors are not logged. InternalServerException , an abstract class for errors that are not the client's fault. These errors are logged. Exception classes in this hierarchy can be defined to include a wrapped cause exception. When an exception is logged, its stack trace will be logged along with the stack trace of its cause . It is therefore recommended that low-level code should catch low-level exceptions, and wrap them in one of our higher-level exceptions, in order to clarify the context in which the error occurred. To simplify error-handling in responders, a utility method called future2Message is provided in ActorUtils . It is intended to be used in an actor's receive method to respond to messages in the ask pattern. If the responder's computation is successful, it is sent to the requesting actor as a response to the ask . If the computation fails, the exception representing the failure is wrapped in a Status.Failure , which is sent as a response to the ask . If the error is a subclass of RequestRejectedException , only the sender is notified of the error; otherwise, the error is also logged and rethrown (so that the KnoraExceptionHandler can handle the exception). In many cases, we transform data from the triplestore into a Map object. To simplify checking for required values in these collections, the class ErrorHandlingMap is provided. You can wrap any Map in an ErrorHandlingMap . You must provide a function that will generate an error message when a required value is missing, and optionally a function that throws a particular exception. Rows of SPARQL query results are already returned in ErrorHandlingMap objects. If you want to add a new exception class, see the comments in Exceptions.scala for instructions.","title":"Error Handling"},{"location":"DSP-API/05-internals/design/principles/design-overview/#transformation-of-exception-to-client-responses","text":"The org.knora.webapi.KnoraExceptionHandler is brought implicitly into scope of akka-http , and by doing so registered and used to handle the transformation of all KnoraExceptions into HttpResponses . This handler handles only exceptions thrown inside the route and not the actors. However, the design of reply message passing from actors (by using future2Message ), makes sure that any exceptions thrown inside actors, will reach the route, where they will be handled. See also Futures with Akka .","title":"Transformation of Exception to Client Responses"},{"location":"DSP-API/05-internals/design/principles/design-overview/#api-routing","text":"The API routes in the routing package are defined using the DSL provided by the akka-http library. A routing function has to do the following: Authenticate the client. Figure out what the client is asking for. Construct an appropriate request message and send it to ResponderManagerV1 , using the ask pattern. Return a result to the client. To simplify the coding of routing functions, they are contained in objects that extend org.knora.webapi.routing.Authenticator . Each routing function performs the following operations: Authenticator.getUserADM is called to authenticate the user. The request parameters are interpreted and validated, and a request message is constructed to send to the responder. If the request is invalid, BadRequestException is thrown. If the request message is requesting an update operation, it must include a UUID generated by UUID.randomUUID , so the responder can obtain a write lock on the resource being updated. The routing function then passes the message to a function in an API-specific routing utility: RouteUtilV1 , RouteUtilV2 , or RouteUtilADM . This utility function sends the message to ResponderManager (which forwards it to the relevant responder), returns a response to the client in the appropriate format, and handles any errors.","title":"API Routing"},{"location":"DSP-API/05-internals/design/principles/design-overview/#logging","text":"Logging in DSP-API is configurable through logback.xml , allowing fine grain configuration of what classes / objects should be logged from which level. The Akka Actors use Akka Logging while logging inside plain Scala Objects and Classes is done through Scala Logging .","title":"Logging"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/","text":"Futures with Akka Introduction Scala's documentation on futures introduces them in this way: Futures provide a nice way to reason about performing many operations in parallel \u2013 in an efficient and non-blocking way. The idea is simple, a Future is a sort of a placeholder object that you can create for a result that does not yet exist. Generally, the result of the Future is computed concurrently and can be later collected. Composing concurrent tasks in this way tends to result in faster, asynchronous, non-blocking parallel code. The rest of that page is well worth reading to get an overview of how futures work and what you can do with them. In Akka , one of the standard patterns for communication between actors is the ask pattern , in which you send a message to an actor and you expect a reply. When you call the ask function (which can be written as a question mark, ? , which acts as an infix operator), it immediately returns a Future , which will complete when the reply is sent. As the Akka documentation explains in Use with Actors , it is possible to block the calling thread until the future completes, using Await.result . However, they say: 'Blocking is discouraged though as it will cause performance problems.' In particular, by not blocking, you can do several ask requests in parallel. One way to avoid blocking is to register a callback on the future, which will be called when it completes (perhaps by another thread), like this: future . onComplete { case Success ( result ) => println ( result ) case Failure ( ex ) => ex . printStackTrace () } But this won't work if you're writing a method that needs return a value based on the result of a future. In this case, you can register a callback that transforms the result of a future into another future: val newFuture = future . map ( x => x + 1 ) However, registering callbacks explicitly gets cumbersome when you need to work with several futures together. In this case, the most convenient alternative to blocking is to use Future as a monad. The links above explain what this means in detail, but the basic idea is that a special syntax, called a for -comprehension, allows you to write code that uses futures as if they were complete, without blocking. In reality, a for -comprehension is syntactic sugar for calling methods like map , but it's much easier to write and to read. You can do things like this: val fooFuture = ( fooActor ? GetFoo ( \"foo\" )). mapTo [ Foo ] val barFuture = ( barActor ? GetBar ( \"bar\" )). mapTo [ Bar ] val totalFuture = for { foo : Foo <- fooFuture bar : Bar <- barFuture total = foo . getCount + bar . getCount } yield total Here the messages to fooActor and barActor are sent and processed in parallel, but you're guaranteed that total won't be calculated until the values it needs are available. Note that if you construct fooFuture and barFuture inside the for comprehension, they won't be run in parallel (see Scala for-comprehension with concurrently running futures ). Handling Errors with Futures The constructors and methods of Future (like those of Try ) catch exceptions, which cause the future to fail. This very useful property of futures means that you usually don't need try - catch blocks when using the Future monad (although it is sometimes helpful to include them, in order to catch low-level exceptions and wrap them in higher-level ones). Any exception thrown in code that's being run asynchronously by Future (including in the yield expression of a for comprehension) will be caught, and the result will be a Future containing a Failure . Also, in the previous example, if fooActor or barActor returns a Status.Failure message, the for -comprehension will also yield a failed future. However, you need to be careful with the first line of the for -comprehension. For example, this code doesn't handle exceptions correctly: private def doFooQuery ( iri : IRI ): Future [ String ] = { for { queryResponse <- ( storeManager ? SparqlSelectRequest ( queries . sparql . v1 . txt . getFoo ( iri ). toString ())). mapTo [ SparqlSelectResponse ] ... } yield ... } The getFoo() method calls a Twirl template function to generate SPARQL. The ? operator returns a Future . However, the template function is not run asynchronously , because it is called before the Future constructor is called. So if the template function throws an exception, it won't be caught here. Instead, you can do this: private def doFooQuery ( iri : IRI ): Future [ String ] = { for { queryString <- Future ( queries . sparql . v1 . txt . getFoo ( iri ). toString ()) queryResponse <- ( storeManager ? SparqlSelectRequest ( queryString )). mapTo [ SparqlSelectResponse ] ... } yield ... } Here the Future constructor will call the template function asynchronously, and catch any exceptions it throws. This is only necessary if you need to call the template function at the very beginning of a for -comprehension. In the rest of the for comprehension, you'll already implicitly have a Future object. Using recover on Futures By using recover on a Future , an apt error message can be thrown if the Future fails. This is particularly useful when an an error message should be made more clear depending on the context the Future is used in. For example, we are asking the resources responder to query for a certain resource in order to process it in a special way. However, the client does not know that the resources responder is sent a request and in case the resource cannot be found, the message sent back from the resources responder ( NotFoundException ) would not make sense to it. Instead, we would like to handle the message in a way so that it makes sense for the operation the client actually executed. We can do this by calling recover on a Future . private def mySpecialResourceRequest ( iri : IRI , userProfile : UserProfileV1 ): Future [...] = { val resourceRequestFuture = for { resResponse : ResourceFullResponseV1 <- ( responderManager ? ResourceFullGetRequestV1 ( iri = iri , userProfile = userProfile , getIncoming = false )). mapTo [ ResourceFullResponseV1 ] } yield resResponse val resourceRequestFutureRecovered = resourceRequestFuture . recover { case notFound : NotFoundException => throw BadRequestException ( s\"Special resource handling failed because the resource could not be found: ${ notFound . message } \" ) } for { res <- resourceRequestFutureRecovered ... } yield ... } Please note that the content of the Future has to be accessed using <- to make this work correctly. Otherwise the content will never be looked at. Designing with Futures In the current design, Knora almost never blocks to wait for a future to complete. The normal flow of control works like this: Incoming HTTP requests are handled by an actor called KnoraService , which delegates them to routing functions (in the routing package). For each request, a routing function gets an Akka HTTP RequestContext , and calls RouteUtilV1.runJsonRoute (in API v1) or RouteUtilV2.runRdfRouteWithFuture (in API v2) to send a message to a supervisor actor to fulfil the request. This creates a Future that will complete when the relevant responder sends its reply. The routing utility registers a callback on this Future to handle the reply message when it becomes available. The supervisor forwards the message to be handled by the appropriate responder. The responder's receive method receives the message, and calls some private method that produces a reply message inside a Future . This may involve sending messages to other actors using ask , getting futures back, and combining them into a single future containing the reply message. The responder passes that future to ActorUtils.future2Message , which registers a callback on it. When the future completes (perhaps in another thread), the callback sends the reply message. In the meantime, the responder doesn't block, so it can start handling the next request. When the responder's reply becomes available, the routing utility's callback registered in (2) calls complete on the RequestContext , which sends an HTTP response to the client. The basic rule of thumb is this: if you're writing a method in an actor, and anything in the method needs to come from a future (e.g. because you need to use ask to get some information from another actor), have the method return a future. Mixing Futures with non-Futures If you have a match ... case or if expression, and one branch obtains some data in a future, but another branch can produce the data immediately, you can wrap the result of the latter branch in a future, so that both branches have the same type. Here we use an alternative implementation of scala.concurrent.Future , found in akka.http.scaladsl.util.FastFuture , which tries to avoid scheduling to an scala.concurrent.ExecutionContext if possible, i.e. if the given future value is already present: def getTotalOfFooAndBar ( howToGetFoo : String ): Future [ Int ] = { for { foo <- howToGetFoo match { case \"askForIt\" => ( fooActor ? GetFoo ( \"foo\" )). mapTo [ Foo ] case \"createIt\" => FastFuture . successful ( new Foo ()) } bar <- ( barActor ? GetBar ( \"bar\" )). mapTo [ Bar ] total = foo . getCount + bar . getCount } yield total } How to Write For-Comprehensions Here are some basic rules for writing for -comprehensions: The first line of a for -comprehension has to be a \"generator\", i.e. it has to use the <- operator. If you want to write an assignment (using = ) as the first line, the workaround is to wrap the right-hand side in a monad (like Future ) and use <- instead. Assignments (using = ) are written without val . You're not allowed to write statements that throw away their return values, so if you want to call something like println that returns Unit , you have to assign its return value to _ . The yield returns an object of the same type as the generators, which all have to produce the same type (e.g. Future ). Execution Contexts Whenever you use a future, there has to be an implicit 'execution context' in scope. Scala's documentation on futures says, 'you can think of execution contexts as thread pools'. If you don't have an execution context in scope, you'll get a compile error asking you to include one, and suggesting that you could use import scala.concurrent.ExecutionContext.Implicits.global . Don't do this, because the global Scala execution context is not the most efficient option. Instead, use Knora's custom execution context like so: implicit val executionContext : ExecutionContext = system . dispatchers . lookup ( KnoraDispatchers . KnoraActorDispatcher )","title":"Futures with Akka"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#futures-with-akka","text":"","title":"Futures with Akka"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#introduction","text":"Scala's documentation on futures introduces them in this way: Futures provide a nice way to reason about performing many operations in parallel \u2013 in an efficient and non-blocking way. The idea is simple, a Future is a sort of a placeholder object that you can create for a result that does not yet exist. Generally, the result of the Future is computed concurrently and can be later collected. Composing concurrent tasks in this way tends to result in faster, asynchronous, non-blocking parallel code. The rest of that page is well worth reading to get an overview of how futures work and what you can do with them. In Akka , one of the standard patterns for communication between actors is the ask pattern , in which you send a message to an actor and you expect a reply. When you call the ask function (which can be written as a question mark, ? , which acts as an infix operator), it immediately returns a Future , which will complete when the reply is sent. As the Akka documentation explains in Use with Actors , it is possible to block the calling thread until the future completes, using Await.result . However, they say: 'Blocking is discouraged though as it will cause performance problems.' In particular, by not blocking, you can do several ask requests in parallel. One way to avoid blocking is to register a callback on the future, which will be called when it completes (perhaps by another thread), like this: future . onComplete { case Success ( result ) => println ( result ) case Failure ( ex ) => ex . printStackTrace () } But this won't work if you're writing a method that needs return a value based on the result of a future. In this case, you can register a callback that transforms the result of a future into another future: val newFuture = future . map ( x => x + 1 ) However, registering callbacks explicitly gets cumbersome when you need to work with several futures together. In this case, the most convenient alternative to blocking is to use Future as a monad. The links above explain what this means in detail, but the basic idea is that a special syntax, called a for -comprehension, allows you to write code that uses futures as if they were complete, without blocking. In reality, a for -comprehension is syntactic sugar for calling methods like map , but it's much easier to write and to read. You can do things like this: val fooFuture = ( fooActor ? GetFoo ( \"foo\" )). mapTo [ Foo ] val barFuture = ( barActor ? GetBar ( \"bar\" )). mapTo [ Bar ] val totalFuture = for { foo : Foo <- fooFuture bar : Bar <- barFuture total = foo . getCount + bar . getCount } yield total Here the messages to fooActor and barActor are sent and processed in parallel, but you're guaranteed that total won't be calculated until the values it needs are available. Note that if you construct fooFuture and barFuture inside the for comprehension, they won't be run in parallel (see Scala for-comprehension with concurrently running futures ).","title":"Introduction"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#handling-errors-with-futures","text":"The constructors and methods of Future (like those of Try ) catch exceptions, which cause the future to fail. This very useful property of futures means that you usually don't need try - catch blocks when using the Future monad (although it is sometimes helpful to include them, in order to catch low-level exceptions and wrap them in higher-level ones). Any exception thrown in code that's being run asynchronously by Future (including in the yield expression of a for comprehension) will be caught, and the result will be a Future containing a Failure . Also, in the previous example, if fooActor or barActor returns a Status.Failure message, the for -comprehension will also yield a failed future. However, you need to be careful with the first line of the for -comprehension. For example, this code doesn't handle exceptions correctly: private def doFooQuery ( iri : IRI ): Future [ String ] = { for { queryResponse <- ( storeManager ? SparqlSelectRequest ( queries . sparql . v1 . txt . getFoo ( iri ). toString ())). mapTo [ SparqlSelectResponse ] ... } yield ... } The getFoo() method calls a Twirl template function to generate SPARQL. The ? operator returns a Future . However, the template function is not run asynchronously , because it is called before the Future constructor is called. So if the template function throws an exception, it won't be caught here. Instead, you can do this: private def doFooQuery ( iri : IRI ): Future [ String ] = { for { queryString <- Future ( queries . sparql . v1 . txt . getFoo ( iri ). toString ()) queryResponse <- ( storeManager ? SparqlSelectRequest ( queryString )). mapTo [ SparqlSelectResponse ] ... } yield ... } Here the Future constructor will call the template function asynchronously, and catch any exceptions it throws. This is only necessary if you need to call the template function at the very beginning of a for -comprehension. In the rest of the for comprehension, you'll already implicitly have a Future object.","title":"Handling Errors with Futures"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#using-recover-on-futures","text":"By using recover on a Future , an apt error message can be thrown if the Future fails. This is particularly useful when an an error message should be made more clear depending on the context the Future is used in. For example, we are asking the resources responder to query for a certain resource in order to process it in a special way. However, the client does not know that the resources responder is sent a request and in case the resource cannot be found, the message sent back from the resources responder ( NotFoundException ) would not make sense to it. Instead, we would like to handle the message in a way so that it makes sense for the operation the client actually executed. We can do this by calling recover on a Future . private def mySpecialResourceRequest ( iri : IRI , userProfile : UserProfileV1 ): Future [...] = { val resourceRequestFuture = for { resResponse : ResourceFullResponseV1 <- ( responderManager ? ResourceFullGetRequestV1 ( iri = iri , userProfile = userProfile , getIncoming = false )). mapTo [ ResourceFullResponseV1 ] } yield resResponse val resourceRequestFutureRecovered = resourceRequestFuture . recover { case notFound : NotFoundException => throw BadRequestException ( s\"Special resource handling failed because the resource could not be found: ${ notFound . message } \" ) } for { res <- resourceRequestFutureRecovered ... } yield ... } Please note that the content of the Future has to be accessed using <- to make this work correctly. Otherwise the content will never be looked at.","title":"Using recover on Futures"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#designing-with-futures","text":"In the current design, Knora almost never blocks to wait for a future to complete. The normal flow of control works like this: Incoming HTTP requests are handled by an actor called KnoraService , which delegates them to routing functions (in the routing package). For each request, a routing function gets an Akka HTTP RequestContext , and calls RouteUtilV1.runJsonRoute (in API v1) or RouteUtilV2.runRdfRouteWithFuture (in API v2) to send a message to a supervisor actor to fulfil the request. This creates a Future that will complete when the relevant responder sends its reply. The routing utility registers a callback on this Future to handle the reply message when it becomes available. The supervisor forwards the message to be handled by the appropriate responder. The responder's receive method receives the message, and calls some private method that produces a reply message inside a Future . This may involve sending messages to other actors using ask , getting futures back, and combining them into a single future containing the reply message. The responder passes that future to ActorUtils.future2Message , which registers a callback on it. When the future completes (perhaps in another thread), the callback sends the reply message. In the meantime, the responder doesn't block, so it can start handling the next request. When the responder's reply becomes available, the routing utility's callback registered in (2) calls complete on the RequestContext , which sends an HTTP response to the client. The basic rule of thumb is this: if you're writing a method in an actor, and anything in the method needs to come from a future (e.g. because you need to use ask to get some information from another actor), have the method return a future.","title":"Designing with Futures"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#mixing-futures-with-non-futures","text":"If you have a match ... case or if expression, and one branch obtains some data in a future, but another branch can produce the data immediately, you can wrap the result of the latter branch in a future, so that both branches have the same type. Here we use an alternative implementation of scala.concurrent.Future , found in akka.http.scaladsl.util.FastFuture , which tries to avoid scheduling to an scala.concurrent.ExecutionContext if possible, i.e. if the given future value is already present: def getTotalOfFooAndBar ( howToGetFoo : String ): Future [ Int ] = { for { foo <- howToGetFoo match { case \"askForIt\" => ( fooActor ? GetFoo ( \"foo\" )). mapTo [ Foo ] case \"createIt\" => FastFuture . successful ( new Foo ()) } bar <- ( barActor ? GetBar ( \"bar\" )). mapTo [ Bar ] total = foo . getCount + bar . getCount } yield total }","title":"Mixing Futures with non-Futures"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#how-to-write-for-comprehensions","text":"Here are some basic rules for writing for -comprehensions: The first line of a for -comprehension has to be a \"generator\", i.e. it has to use the <- operator. If you want to write an assignment (using = ) as the first line, the workaround is to wrap the right-hand side in a monad (like Future ) and use <- instead. Assignments (using = ) are written without val . You're not allowed to write statements that throw away their return values, so if you want to call something like println that returns Unit , you have to assign its return value to _ . The yield returns an object of the same type as the generators, which all have to produce the same type (e.g. Future ).","title":"How to Write For-Comprehensions"},{"location":"DSP-API/05-internals/design/principles/futures-with-akka/#execution-contexts","text":"Whenever you use a future, there has to be an implicit 'execution context' in scope. Scala's documentation on futures says, 'you can think of execution contexts as thread pools'. If you don't have an execution context in scope, you'll get a compile error asking you to include one, and suggesting that you could use import scala.concurrent.ExecutionContext.Implicits.global . Don't do this, because the global Scala execution context is not the most efficient option. Instead, use Knora's custom execution context like so: implicit val executionContext : ExecutionContext = system . dispatchers . lookup ( KnoraDispatchers . KnoraActorDispatcher )","title":"Execution Contexts"},{"location":"DSP-API/05-internals/design/principles/http-module/","text":"HTTP Module The http module holds only a convenience method for adding CORS support to api routes. The CORS implementation uses the akka-http-cors directives implementation.","title":"HTTP Module"},{"location":"DSP-API/05-internals/design/principles/http-module/#http-module","text":"The http module holds only a convenience method for adding CORS support to api routes. The CORS implementation uses the akka-http-cors directives implementation.","title":"HTTP Module"},{"location":"DSP-API/05-internals/design/principles/rdf-api/","text":"RDF Processing API DSP provides an API for parsing and formatting RDF data and for working with RDF graphs. This allows DSP developers to use a single, idiomatic Scala API as a fa\u00e7ade for a Java RDF library. Overview The API is in the package org.knora.webapi.messages.util.rdf . It includes: RdfModel , which represents a set of RDF graphs (a default graph and/or one or more named graphs). A model can be constructed from scratch, modified, and searched. RdfNode and its subclasses, which represent RDF nodes (IRIs, blank nodes, and literals). Statement , which represents a triple or quad. RdfNodeFactory , which creates nodes and statements. RdfModelFactory , which creates empty RDF models. RdfFormatUtil , which parses and formats RDF models. JsonLDUtil , which provides specialised functionality for working with RDF in JSON-LD format, and for converting between RDF models and JSON-LD documents. RdfFormatUtil uses JsonLDUtil when appropriate. ShaclValidator , which validates RDF models using SHACL shapes. To work with RDF models, start with RdfFeatureFactory , which returns instances of RdfNodeFactory , RdfModelFactory , RdfFormatUtil , and ShaclValidator . JsonLDUtil does not need a feature factory. To iterate efficiently over the statements in an RdfModel , use its iterator method. An RdfModel cannot be modified while you are iterating over it. If you are iterating to look for statements to modify, you can collect a Set of statements to remove and a Set of statements to add, and perform these update operations after you have finished the iteration. RDF stream processing To read or write a large amount of RDF data without generating a large string object, you can use the stream processing methods in RdfFormatUtil . To parse an InputStream to an RdfModel , use inputStreamToRdfModel . To format an RdfModel to an OutputStream , use rdfModelToOutputStream . To parse RDF data from an InputStream and process it one statement at a time, you can write a class that implements the RdfStreamProcessor trait, and use it with the RdfFormatUtil.parseWithStreamProcessor method. Your RdfStreamProcessor can also send one statement at a time to a formatting stream processor, which knows how to write RDF to an OutputStream in a particular format. Use RdfFormatUtil.makeFormattingStreamProcessor to construct one of these. SPARQL queries In tests, it can be useful to run SPARQL queries to check the content of an RdfModel . To do this, use the RdfModel.asRepository method, which returns an RdfRepository that can run SELECT queries. The configuration of the default graph depends on which underlying RDF library is used. If you are querying data in named graphs, use FROM or quad patterns rather than the default graph. SHACL validation On startup, graphs of SHACL shapes are loaded from Turtle files in a directory specified by app.shacl.shapes-dir in application.conf , and in subdirectories of that directory. To validate the default graph of an RdfModel using a graph of SHACL shapes, call ShaclValidator.validate , specifying the relative path of the Turtle file containing the graph of shapes. Implementations The Jena-based implementation, in package org.knora.webapi.messages.util.rdf.jenaimpl . The RDF4J-based implementation, in package org.knora.webapi.messages.util.rdf.rdf4jimpl . TODO SHACL validation.","title":"RDF Processing API"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#rdf-processing-api","text":"DSP provides an API for parsing and formatting RDF data and for working with RDF graphs. This allows DSP developers to use a single, idiomatic Scala API as a fa\u00e7ade for a Java RDF library.","title":"RDF Processing API"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#overview","text":"The API is in the package org.knora.webapi.messages.util.rdf . It includes: RdfModel , which represents a set of RDF graphs (a default graph and/or one or more named graphs). A model can be constructed from scratch, modified, and searched. RdfNode and its subclasses, which represent RDF nodes (IRIs, blank nodes, and literals). Statement , which represents a triple or quad. RdfNodeFactory , which creates nodes and statements. RdfModelFactory , which creates empty RDF models. RdfFormatUtil , which parses and formats RDF models. JsonLDUtil , which provides specialised functionality for working with RDF in JSON-LD format, and for converting between RDF models and JSON-LD documents. RdfFormatUtil uses JsonLDUtil when appropriate. ShaclValidator , which validates RDF models using SHACL shapes. To work with RDF models, start with RdfFeatureFactory , which returns instances of RdfNodeFactory , RdfModelFactory , RdfFormatUtil , and ShaclValidator . JsonLDUtil does not need a feature factory. To iterate efficiently over the statements in an RdfModel , use its iterator method. An RdfModel cannot be modified while you are iterating over it. If you are iterating to look for statements to modify, you can collect a Set of statements to remove and a Set of statements to add, and perform these update operations after you have finished the iteration.","title":"Overview"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#rdf-stream-processing","text":"To read or write a large amount of RDF data without generating a large string object, you can use the stream processing methods in RdfFormatUtil . To parse an InputStream to an RdfModel , use inputStreamToRdfModel . To format an RdfModel to an OutputStream , use rdfModelToOutputStream . To parse RDF data from an InputStream and process it one statement at a time, you can write a class that implements the RdfStreamProcessor trait, and use it with the RdfFormatUtil.parseWithStreamProcessor method. Your RdfStreamProcessor can also send one statement at a time to a formatting stream processor, which knows how to write RDF to an OutputStream in a particular format. Use RdfFormatUtil.makeFormattingStreamProcessor to construct one of these.","title":"RDF stream processing"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#sparql-queries","text":"In tests, it can be useful to run SPARQL queries to check the content of an RdfModel . To do this, use the RdfModel.asRepository method, which returns an RdfRepository that can run SELECT queries. The configuration of the default graph depends on which underlying RDF library is used. If you are querying data in named graphs, use FROM or quad patterns rather than the default graph.","title":"SPARQL queries"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#shacl-validation","text":"On startup, graphs of SHACL shapes are loaded from Turtle files in a directory specified by app.shacl.shapes-dir in application.conf , and in subdirectories of that directory. To validate the default graph of an RdfModel using a graph of SHACL shapes, call ShaclValidator.validate , specifying the relative path of the Turtle file containing the graph of shapes.","title":"SHACL validation"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#implementations","text":"The Jena-based implementation, in package org.knora.webapi.messages.util.rdf.jenaimpl . The RDF4J-based implementation, in package org.knora.webapi.messages.util.rdf.rdf4jimpl .","title":"Implementations"},{"location":"DSP-API/05-internals/design/principles/rdf-api/#todo","text":"SHACL validation.","title":"TODO"},{"location":"DSP-API/05-internals/design/principles/store-module/","text":"Store Module Overview GraphDB and embedded Jena TDB triplestores support is deprecated since v20.1.1 of DSP-API. The store module houses the different types of data stores supported by Knora. At the moment, only triplestores and IIIF servers (Sipi) are supported. The triplestore support is implemented in the org.knora.webapi.store.triplestore package and the IIIF server support in org.knora.webapi.store.iiif package. Lifecycle At the top level, the store package houses the StoreManager -Actor which is started when Knora starts. The StoreManager then starts the TriplestoreManager and IIIFManager , which each in turn starts their correct actor implementation. Triplestores Currently, the only supported triplestore is Apache Jena Fuseki , a HTTP-based triplestore. HTTP-based triplestore support is implemented in the org.knora.webapi.triplestore.http package. An HTTP-based triplestore is one that is accessed remotely over the HTTP protocol. HttpTriplestoreConnector supports the open source triplestore Apache Jena Fuseki . IIIF Servers Currently, only support for SIPI is implemented in org.knora.webapi.store.iiifSipiConnector .","title":"Store Module"},{"location":"DSP-API/05-internals/design/principles/store-module/#store-module","text":"","title":"Store Module"},{"location":"DSP-API/05-internals/design/principles/store-module/#overview","text":"GraphDB and embedded Jena TDB triplestores support is deprecated since v20.1.1 of DSP-API. The store module houses the different types of data stores supported by Knora. At the moment, only triplestores and IIIF servers (Sipi) are supported. The triplestore support is implemented in the org.knora.webapi.store.triplestore package and the IIIF server support in org.knora.webapi.store.iiif package.","title":"Overview"},{"location":"DSP-API/05-internals/design/principles/store-module/#lifecycle","text":"At the top level, the store package houses the StoreManager -Actor which is started when Knora starts. The StoreManager then starts the TriplestoreManager and IIIFManager , which each in turn starts their correct actor implementation.","title":"Lifecycle"},{"location":"DSP-API/05-internals/design/principles/store-module/#triplestores","text":"Currently, the only supported triplestore is Apache Jena Fuseki , a HTTP-based triplestore. HTTP-based triplestore support is implemented in the org.knora.webapi.triplestore.http package. An HTTP-based triplestore is one that is accessed remotely over the HTTP protocol. HttpTriplestoreConnector supports the open source triplestore Apache Jena Fuseki .","title":"Triplestores"},{"location":"DSP-API/05-internals/design/principles/store-module/#iiif-servers","text":"Currently, only support for SIPI is implemented in org.knora.webapi.store.iiifSipiConnector .","title":"IIIF Servers"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/","text":"Triplestore Updates Requirements General The supported update operations are: Create a new resource with its initial values. Add a new value. Change a value. Delete a value (i.e. mark it as deleted). Delete a resource (i.e. mark it as deleted). Users must be able to edit the same data concurrently. Each update must be atomic and leave the database in a consistent, meaningful state, respecting ontology constraints and permissions. The application must not use any sort of long-lived locks, because they tend to hinder concurrent edits, and it is difficult to ensure that they are released when they are no longer needed. Instead, if a user requests an update based on outdated information (because another user has just changed something, and the first user has not found out yet), the update must be not performed, and the application must notify the user who requested it, suggesting that the user should check the relevant data and try again if necessary. (We may eventually provide functionality to help users merge edits in such a situation. The application can also encourage users to coordinate with one another when they are working on the same data, and may eventually provide functionality to facilitate this coordination.) We can assume that each SPARQL update operation will run in its own database transaction with an isolation level of 'read committed'. We cannot assume that it is possible to run more than one SPARQL update in a single database transaction. The SPARQL 1.1 Protocol does not provide a way to do this, and currently it can be done only by embedding the triplestore in the application and using a vendor-specific API, but we cannot require this in Knora.) Permissions To create a new value (as opposed to a new version of an existing value), the user must have permission to modify the containing resource. To create a new version of an existing value, the user needs only to have permission to modify the current version of the value; no permissions on the resource are needed. Since changing a link requires deleting the old link and creating a new one (as described in Linking ), a user wishing to change a link must have modify permission on both the containing resource and the knora-base:LinkValue for the existing link. When a new resource or value is created, it can be given default permissions specified the project's admin data, or (only in API v2) custom permissions can be specified. Ontology Constraints Knora must not allow an update that would violate an ontology constraint. When creating a new value (as opposed to adding a new version of an existing value), Knora must not allow the update if the containing resource's OWL class does not contain a cardinality restriction for the submitted property, or if the new value would violate the cardinality restriction. It must also not allow the update if the type of the submitted value does not match the knora-base:objectClassConstraint of the property, or if the property has no knora-base:objectClassConstraint . In the case of a property that points to a resource, Knora must ensure that the target resource belongs to the OWL class specified in the property's knora-base:objectClassConstraint , or to a subclass of that class. Duplicate and Redundant Values When creating a new value, or changing an existing value, Knora checks whether the submitted value would duplicate an existing value for the same property in the resource. The definition of 'duplicate' depends on the type of value; it does not necessarily mean that the two values are strictly equal. For example, if two text values contain the same Unicode string, they are considered duplicates, even if they have different Standoff markup. If resource R has property P with value V1 , and V1 is a duplicate of V2 , the API server must not add another instance of property P with value V2 . However, if the requesting user does not have permission to see V2 , the duplicate is allowed, because forbidding it would reveal the contents of V2 to the user. When creating a new version of a value, Knora also checks whether the new version is redundant, given the existing value. It is possible for the definition of 'redundant' can depend on the type of value, but in practice, it means that the values are strictly equal: any change, however trivial, is allowed. Versioning Each Knora value (i.e. something belonging to an OWL class derived from knora-base:Value ) is versioned. This means that once created, a value is never modified. Instead, 'changing' a value means creating a new version of the value --- actually a new value --- that points to the previous version using knora-base:previousValue . The versions of a value are a singly-linked list, pointing backwards into the past. When a new version of a value is made, the triple that points from the resource to the old version (using a subproperty of knora-base:hasValue ) is removed, and a triple is added to point from the resource to the new version. Thus the resource always points only to the current version of the value, and the older versions are available only via the current version's knora-base:previousValue predicate. Unlike values, resources (members of OWL classes derived from knora-base:Resource ) are not versioned. The data that is attached to a resource, other than its values, can be modified. Deleting Knora does not actually delete resources or values; it only marks them as deleted. Deleted data is normally hidden. All resources and values must have the predicate knora- base:isDeleted , whose object is a boolean. If a resource or value has been marked as deleted, it has knora-base:isDeleted true and has a knora-base:deleteDate . An optional knora-base:deleteComment may be added to explain why the resource or value has been marked as deleted. Normally, a value is marked as deleted without creating a new version of it. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. Since it is necessary to be able to find out when a resource was deleted, it is not possible to undelete a resource. Moreover, to simplify the checking of cardinality constraints, and for consistency with resources, it is not possible to undelete a value, and no new versions of a deleted value can be made. Instead, if desired, a new resource or value can be created by copying data from a deleted resource or value. Linking Links must be treated differently to other types of values. Knora needs to maintain information about the link, including permissions and a version history. Since the link does not have a unique IRI of its own, Knora uses RDF reifications for this purpose. Each link between two resources has exactly one (non-deleted) knora-base:LinkValue . The resource itself has a predicate that points to the LinkValue , using a naming convention in which the word Value is appended to the name of the link predicate to produce the link value predicate. For example, if a resource representing a book has a predicate called hasAuthor that points to another resource, it must also have a predicate called hasAuthorValue that points to the LinkValue in which information about the link is stored. To find a particular LinkValue , one can query it either by using its IRI (if known), or by using its rdf:subject , rdf:predicate , and rdf:object (and excluding link values that are marked as deleted). Like other values, link values are versioned. The link value predicate always points from the resource to the current version of the link value, and previous versions are available only via the current version's knora-base:previousValue predicate. Deleting a link means deleting the triple that links the two resources, and making a new version of the link value, marked with knora-base:isDeleted . A triple then points from the resource to this new, deleted version (using the link value property). The API allows a link to be 'changed' so that it points to a different target resource. This is implemented as follows: the existing triple connecting the two resources is removed, and a new triple is added using the same link property and pointing to the new target resource. A new version of the old link's LinkValue is made, marked with knora-base:isDeleted . A new LinkValue is made for the new link. The new LinkValue has no connection to the old one. When a resource contains knora-base:TextValue with Standoff markup that includes a reference to another resource, this reference is materialised as a direct link between the two resources, to make it easier to query. A special link property, knora-base:hasStandoffLinkTo , is used for this purpose. The corresponding link value property, knora-base:hasStandoffLinkToValue , points to a LinkValue . This LinkValue contains a reference count, indicated by knora-base:valueHasRefCount , that represents the number of text values in the containing resource that include one or more Standoff references to the specified target resource. Each time this number changes, a new version of this LinkValue is made. When the reference count reaches zero, the triple with knora-base:hasStandoffLinkTo is removed, and a new version of the LinkValue is made and marked with knora-base:isDeleted . If the same resource reference later appears again in a text value, a new triple is added using knora-base:hasStandoffLinkTo , and a new LinkValue is made, with no connection to the old one. For consistency, every LinkValue contains a reference count. If the link property is not knora-base:hasStandoffLinkTo , the reference count will always be either 1 (if the link exists) or 0 (if it has been deleted, in which case the link value will also be marked with knora-base:isDeleted ). When a LinkValue is created for a standoff resource reference, it is given the same permissions as the text value containing the reference. Design Responsibilities of Responders The resources responder ( ResourcesResponderV1 in API v1, ResourcesResponderV2 in API v2) has sole responsibility for generating SPARQL to create and updating resources, and the values responder ( ValuesResponderV1 or ValuesResponderV2 ) has sole responsibility for generating SPARQL to create and update values. When a new resource is created with its values, the values responder generates SPARQL statements that can be included in the INSERT clause of a SPARQL update to create the values, and the resources responder adds these statements to the SPARQL update that creates the resource. This ensures that the resource and its values are created in a single SPARQL update operation, and hence in a single triplestore transaction. Application-level Locking The 'read committed' isolation level cannot prevent a scenario where two users want to add the same data at the same time. It is possible that both requests would do pre-update checks and simultaneously find that it is OK to add the data, and that both updates would then succeed, inserting redundant data and possibly violating ontology constraints. Therefore, Knora uses short-lived, application-level write locks on resources, to ensure that only one request at a time can update a given resource. Before each update, the application acquires a lock on a resource. To prevent deadlocks, Knora locks only one resource per API operation. It then does the pre-update checks and the update, then releases the lock. The lock implementation (in IriLocker ) requires each API request message to include a random UUID, which is generated in the API Routing package. Using application-level locks allows us to do pre-update checks in their own transactions, and finally to do the SPARQL update in its own transaction. Ensuring Data Consistency Knora enforces consistency constraints using three redundant mechanisms: By doing pre-update checks using SPARQL SELECT queries and cached ontology data. By doing checks in the WHERE clauses of SPARQL updates. Deprecated : By using GraphDB's built-in consistency checker (see Consistency Checking ). We take the view that redundant consistency checks are a good thing. Pre-update checks are SPARQL SELECT queries that are executed while holding an application-level lock on the resource to be updated. These checks should work with any triplestore, and can return helpful, Knora-specific error messages to the client if the request would violate a consistency constraint. However, the SPARQL update itself is our only chance to do pre-update checks in the same transaction that will perform the update. The design of the SPARQL 1.1 Update standard makes it possible to ensure that if certain conditions are not met, the update will not be performed. In our SPARQL update code, each update contains a WHERE clause, possibly a DELETE clause, and an INSERT clause. The WHERE clause is executed first. It performs consistency checks and provides values for variables that are used in the DELETE and/or INSERT clauses. In our updates, if the expectations of the WHERE clause are not met (e.g. because the data to be updated does not exist), the WHERE clause should return no results; as a result, the update will not be performed. Regardless of whether the update changes the contents of the triplestore, it returns nothing. If the update did nothing because the conditions of the WHERE clause were not met, the only way to find out is to do a SELECT afterwards. Moreover, in this case, there is no straightforward way to find out which conditions was not met. This is one reason why Knora does pre-update checks using separate SELECT queries and/or cached ontology data, before performing the update. This makes it possible to return specific error messages to the user to indicate why an update cannot be performed. Moreover, while some checks are easy to do in a SPARQL update, others are difficult, impractical, or impossible. Easy checks include checking whether a resource or value exists or is deleted, and checking that the knora-base:objectClassConstraint of a predicate matches the rdf:type of its intended object. Cardinality checks are not very difficult, but they perform poorly on Jena. Knora does not do permission checks in SPARQL, because its permission-checking algorithm is too complex to be implemented in SPARQL. For this reason, Knora's check for duplicate values cannot be done in SPARQL update code, because it relies on permission checks. In a bulk import operation, which can create a large number of resources in a single SPARQL update, a WHERE clause can become very expensive for the triplestore, in terms of memory as well as execution time. Moreover, RDF4J (and hence GraphDB) uses a recursive algorithm to parse SPARQL queries with WHERE clauses, so the size of a WHERE clause is limited by the stack space available to the Java Virtual Machine. Therefore, in bulk import operations, Knora uses INSERT DATA , which does not involve a WHERE clause. Bulk imports thus rely on checks (1) and (3) above. SPARQL Update Examples The following sample SPARQL update code is simpler than what Knora actually does. It is included here to illustrate the way Knora's SPARQL updates are structured and how concurrent updates are handled. Finding a value IRI in a value's version history We will need this query below. If a value is present in a resource property's version history, the query returns everything known about the value, or nothing otherwise: prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?p ?o WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") as ?searchValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?searchValue . ?searchValue ?p ?o . } Creating the initial version of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 1\"\"\" ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) # Do nothing if the resource doesn't exist. ?resource rdf:type ?resourceClass . # Do nothing if the submitted value has the wrong type. ?property knora-base:objectClassConstraint ?valueType . } To find out whether the insert succeeded, the application can use the query in Finding a value IRI in a value's version history to look for the new IRI in the property's version history. Adding a new version of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> DELETE { ?resource ?property ?currentValue . } INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 2\"\"\" ; knora-base:previousValue ?currentValue ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?currentValue) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) ?resource ?property ?currentValue . ?property knora-base:objectClassConstraint ?valueType . } The update request must contain the IRI of the most recent version of the value ( http://rdfh.ch/c5058f3a/values/c3295339 ). If this is not in fact the most recent version (because someone else has done an update), this operation will do nothing (because the WHERE clause will return no rows). To find out whether the update succeeded, the application will then need to do a SELECT query using the query in Finding a value IRI in a value's version history . In the case of concurrent updates, there are two possibilities: Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2, which user A verifies using a SELECT. User B then submits an update to version 1 but it fails, because version 1 is no longer the latest version. User B's SELECT will find that user B's new value IRI is absent from the value's version history. Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2. Before User A has time to do a SELECT, user B reads the new value and updates it again. Both users then do a SELECT, and find that both their new value IRIs are present in the value's version history. Getting all versions of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?value ?valueTimestamp ?previousValue WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?currentValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?value . OPTIONAL { ?value knora-base:valueTimestamp ?valueTimestamp . } OPTIONAL { ?value knora-base:previousValue ?previousValue . } } This assumes that we know the current version of the value. If the version we have is not actually the current version, this query will return no rows.","title":"Triplestore Updates"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#triplestore-updates","text":"","title":"Triplestore Updates"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#requirements","text":"","title":"Requirements"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#general","text":"The supported update operations are: Create a new resource with its initial values. Add a new value. Change a value. Delete a value (i.e. mark it as deleted). Delete a resource (i.e. mark it as deleted). Users must be able to edit the same data concurrently. Each update must be atomic and leave the database in a consistent, meaningful state, respecting ontology constraints and permissions. The application must not use any sort of long-lived locks, because they tend to hinder concurrent edits, and it is difficult to ensure that they are released when they are no longer needed. Instead, if a user requests an update based on outdated information (because another user has just changed something, and the first user has not found out yet), the update must be not performed, and the application must notify the user who requested it, suggesting that the user should check the relevant data and try again if necessary. (We may eventually provide functionality to help users merge edits in such a situation. The application can also encourage users to coordinate with one another when they are working on the same data, and may eventually provide functionality to facilitate this coordination.) We can assume that each SPARQL update operation will run in its own database transaction with an isolation level of 'read committed'. We cannot assume that it is possible to run more than one SPARQL update in a single database transaction. The SPARQL 1.1 Protocol does not provide a way to do this, and currently it can be done only by embedding the triplestore in the application and using a vendor-specific API, but we cannot require this in Knora.)","title":"General"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#permissions","text":"To create a new value (as opposed to a new version of an existing value), the user must have permission to modify the containing resource. To create a new version of an existing value, the user needs only to have permission to modify the current version of the value; no permissions on the resource are needed. Since changing a link requires deleting the old link and creating a new one (as described in Linking ), a user wishing to change a link must have modify permission on both the containing resource and the knora-base:LinkValue for the existing link. When a new resource or value is created, it can be given default permissions specified the project's admin data, or (only in API v2) custom permissions can be specified.","title":"Permissions"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#ontology-constraints","text":"Knora must not allow an update that would violate an ontology constraint. When creating a new value (as opposed to adding a new version of an existing value), Knora must not allow the update if the containing resource's OWL class does not contain a cardinality restriction for the submitted property, or if the new value would violate the cardinality restriction. It must also not allow the update if the type of the submitted value does not match the knora-base:objectClassConstraint of the property, or if the property has no knora-base:objectClassConstraint . In the case of a property that points to a resource, Knora must ensure that the target resource belongs to the OWL class specified in the property's knora-base:objectClassConstraint , or to a subclass of that class.","title":"Ontology Constraints"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#duplicate-and-redundant-values","text":"When creating a new value, or changing an existing value, Knora checks whether the submitted value would duplicate an existing value for the same property in the resource. The definition of 'duplicate' depends on the type of value; it does not necessarily mean that the two values are strictly equal. For example, if two text values contain the same Unicode string, they are considered duplicates, even if they have different Standoff markup. If resource R has property P with value V1 , and V1 is a duplicate of V2 , the API server must not add another instance of property P with value V2 . However, if the requesting user does not have permission to see V2 , the duplicate is allowed, because forbidding it would reveal the contents of V2 to the user. When creating a new version of a value, Knora also checks whether the new version is redundant, given the existing value. It is possible for the definition of 'redundant' can depend on the type of value, but in practice, it means that the values are strictly equal: any change, however trivial, is allowed.","title":"Duplicate and Redundant Values"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#versioning","text":"Each Knora value (i.e. something belonging to an OWL class derived from knora-base:Value ) is versioned. This means that once created, a value is never modified. Instead, 'changing' a value means creating a new version of the value --- actually a new value --- that points to the previous version using knora-base:previousValue . The versions of a value are a singly-linked list, pointing backwards into the past. When a new version of a value is made, the triple that points from the resource to the old version (using a subproperty of knora-base:hasValue ) is removed, and a triple is added to point from the resource to the new version. Thus the resource always points only to the current version of the value, and the older versions are available only via the current version's knora-base:previousValue predicate. Unlike values, resources (members of OWL classes derived from knora-base:Resource ) are not versioned. The data that is attached to a resource, other than its values, can be modified.","title":"Versioning"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#deleting","text":"Knora does not actually delete resources or values; it only marks them as deleted. Deleted data is normally hidden. All resources and values must have the predicate knora- base:isDeleted , whose object is a boolean. If a resource or value has been marked as deleted, it has knora-base:isDeleted true and has a knora-base:deleteDate . An optional knora-base:deleteComment may be added to explain why the resource or value has been marked as deleted. Normally, a value is marked as deleted without creating a new version of it. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. Since it is necessary to be able to find out when a resource was deleted, it is not possible to undelete a resource. Moreover, to simplify the checking of cardinality constraints, and for consistency with resources, it is not possible to undelete a value, and no new versions of a deleted value can be made. Instead, if desired, a new resource or value can be created by copying data from a deleted resource or value.","title":"Deleting"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#linking","text":"Links must be treated differently to other types of values. Knora needs to maintain information about the link, including permissions and a version history. Since the link does not have a unique IRI of its own, Knora uses RDF reifications for this purpose. Each link between two resources has exactly one (non-deleted) knora-base:LinkValue . The resource itself has a predicate that points to the LinkValue , using a naming convention in which the word Value is appended to the name of the link predicate to produce the link value predicate. For example, if a resource representing a book has a predicate called hasAuthor that points to another resource, it must also have a predicate called hasAuthorValue that points to the LinkValue in which information about the link is stored. To find a particular LinkValue , one can query it either by using its IRI (if known), or by using its rdf:subject , rdf:predicate , and rdf:object (and excluding link values that are marked as deleted). Like other values, link values are versioned. The link value predicate always points from the resource to the current version of the link value, and previous versions are available only via the current version's knora-base:previousValue predicate. Deleting a link means deleting the triple that links the two resources, and making a new version of the link value, marked with knora-base:isDeleted . A triple then points from the resource to this new, deleted version (using the link value property). The API allows a link to be 'changed' so that it points to a different target resource. This is implemented as follows: the existing triple connecting the two resources is removed, and a new triple is added using the same link property and pointing to the new target resource. A new version of the old link's LinkValue is made, marked with knora-base:isDeleted . A new LinkValue is made for the new link. The new LinkValue has no connection to the old one. When a resource contains knora-base:TextValue with Standoff markup that includes a reference to another resource, this reference is materialised as a direct link between the two resources, to make it easier to query. A special link property, knora-base:hasStandoffLinkTo , is used for this purpose. The corresponding link value property, knora-base:hasStandoffLinkToValue , points to a LinkValue . This LinkValue contains a reference count, indicated by knora-base:valueHasRefCount , that represents the number of text values in the containing resource that include one or more Standoff references to the specified target resource. Each time this number changes, a new version of this LinkValue is made. When the reference count reaches zero, the triple with knora-base:hasStandoffLinkTo is removed, and a new version of the LinkValue is made and marked with knora-base:isDeleted . If the same resource reference later appears again in a text value, a new triple is added using knora-base:hasStandoffLinkTo , and a new LinkValue is made, with no connection to the old one. For consistency, every LinkValue contains a reference count. If the link property is not knora-base:hasStandoffLinkTo , the reference count will always be either 1 (if the link exists) or 0 (if it has been deleted, in which case the link value will also be marked with knora-base:isDeleted ). When a LinkValue is created for a standoff resource reference, it is given the same permissions as the text value containing the reference.","title":"Linking"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#design","text":"","title":"Design"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#responsibilities-of-responders","text":"The resources responder ( ResourcesResponderV1 in API v1, ResourcesResponderV2 in API v2) has sole responsibility for generating SPARQL to create and updating resources, and the values responder ( ValuesResponderV1 or ValuesResponderV2 ) has sole responsibility for generating SPARQL to create and update values. When a new resource is created with its values, the values responder generates SPARQL statements that can be included in the INSERT clause of a SPARQL update to create the values, and the resources responder adds these statements to the SPARQL update that creates the resource. This ensures that the resource and its values are created in a single SPARQL update operation, and hence in a single triplestore transaction.","title":"Responsibilities of Responders"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#application-level-locking","text":"The 'read committed' isolation level cannot prevent a scenario where two users want to add the same data at the same time. It is possible that both requests would do pre-update checks and simultaneously find that it is OK to add the data, and that both updates would then succeed, inserting redundant data and possibly violating ontology constraints. Therefore, Knora uses short-lived, application-level write locks on resources, to ensure that only one request at a time can update a given resource. Before each update, the application acquires a lock on a resource. To prevent deadlocks, Knora locks only one resource per API operation. It then does the pre-update checks and the update, then releases the lock. The lock implementation (in IriLocker ) requires each API request message to include a random UUID, which is generated in the API Routing package. Using application-level locks allows us to do pre-update checks in their own transactions, and finally to do the SPARQL update in its own transaction.","title":"Application-level Locking"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#ensuring-data-consistency","text":"Knora enforces consistency constraints using three redundant mechanisms: By doing pre-update checks using SPARQL SELECT queries and cached ontology data. By doing checks in the WHERE clauses of SPARQL updates. Deprecated : By using GraphDB's built-in consistency checker (see Consistency Checking ). We take the view that redundant consistency checks are a good thing. Pre-update checks are SPARQL SELECT queries that are executed while holding an application-level lock on the resource to be updated. These checks should work with any triplestore, and can return helpful, Knora-specific error messages to the client if the request would violate a consistency constraint. However, the SPARQL update itself is our only chance to do pre-update checks in the same transaction that will perform the update. The design of the SPARQL 1.1 Update standard makes it possible to ensure that if certain conditions are not met, the update will not be performed. In our SPARQL update code, each update contains a WHERE clause, possibly a DELETE clause, and an INSERT clause. The WHERE clause is executed first. It performs consistency checks and provides values for variables that are used in the DELETE and/or INSERT clauses. In our updates, if the expectations of the WHERE clause are not met (e.g. because the data to be updated does not exist), the WHERE clause should return no results; as a result, the update will not be performed. Regardless of whether the update changes the contents of the triplestore, it returns nothing. If the update did nothing because the conditions of the WHERE clause were not met, the only way to find out is to do a SELECT afterwards. Moreover, in this case, there is no straightforward way to find out which conditions was not met. This is one reason why Knora does pre-update checks using separate SELECT queries and/or cached ontology data, before performing the update. This makes it possible to return specific error messages to the user to indicate why an update cannot be performed. Moreover, while some checks are easy to do in a SPARQL update, others are difficult, impractical, or impossible. Easy checks include checking whether a resource or value exists or is deleted, and checking that the knora-base:objectClassConstraint of a predicate matches the rdf:type of its intended object. Cardinality checks are not very difficult, but they perform poorly on Jena. Knora does not do permission checks in SPARQL, because its permission-checking algorithm is too complex to be implemented in SPARQL. For this reason, Knora's check for duplicate values cannot be done in SPARQL update code, because it relies on permission checks. In a bulk import operation, which can create a large number of resources in a single SPARQL update, a WHERE clause can become very expensive for the triplestore, in terms of memory as well as execution time. Moreover, RDF4J (and hence GraphDB) uses a recursive algorithm to parse SPARQL queries with WHERE clauses, so the size of a WHERE clause is limited by the stack space available to the Java Virtual Machine. Therefore, in bulk import operations, Knora uses INSERT DATA , which does not involve a WHERE clause. Bulk imports thus rely on checks (1) and (3) above.","title":"Ensuring Data Consistency"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#sparql-update-examples","text":"The following sample SPARQL update code is simpler than what Knora actually does. It is included here to illustrate the way Knora's SPARQL updates are structured and how concurrent updates are handled.","title":"SPARQL Update Examples"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#finding-a-value-iri-in-a-values-version-history","text":"We will need this query below. If a value is present in a resource property's version history, the query returns everything known about the value, or nothing otherwise: prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?p ?o WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") as ?searchValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?searchValue . ?searchValue ?p ?o . }","title":"Finding a value IRI in a value's version history"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#creating-the-initial-version-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 1\"\"\" ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) # Do nothing if the resource doesn't exist. ?resource rdf:type ?resourceClass . # Do nothing if the submitted value has the wrong type. ?property knora-base:objectClassConstraint ?valueType . } To find out whether the insert succeeded, the application can use the query in Finding a value IRI in a value's version history to look for the new IRI in the property's version history.","title":"Creating the initial version of a value"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#adding-a-new-version-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> DELETE { ?resource ?property ?currentValue . } INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 2\"\"\" ; knora-base:previousValue ?currentValue ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?currentValue) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) ?resource ?property ?currentValue . ?property knora-base:objectClassConstraint ?valueType . } The update request must contain the IRI of the most recent version of the value ( http://rdfh.ch/c5058f3a/values/c3295339 ). If this is not in fact the most recent version (because someone else has done an update), this operation will do nothing (because the WHERE clause will return no rows). To find out whether the update succeeded, the application will then need to do a SELECT query using the query in Finding a value IRI in a value's version history . In the case of concurrent updates, there are two possibilities: Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2, which user A verifies using a SELECT. User B then submits an update to version 1 but it fails, because version 1 is no longer the latest version. User B's SELECT will find that user B's new value IRI is absent from the value's version history. Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2. Before User A has time to do a SELECT, user B reads the new value and updates it again. Both users then do a SELECT, and find that both their new value IRIs are present in the value's version history.","title":"Adding a new version of a value"},{"location":"DSP-API/05-internals/design/principles/triplestore-updates/#getting-all-versions-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?value ?valueTimestamp ?previousValue WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?currentValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?value . OPTIONAL { ?value knora-base:valueTimestamp ?valueTimestamp . } OPTIONAL { ?value knora-base:previousValue ?previousValue . } } This assumes that we know the current version of the value. If the version we have is not actually the current version, this query will return no rows.","title":"Getting all versions of a value"},{"location":"DSP-API/05-internals/development/building-and-running/","text":"Building and Running Running the stack With Docker installed, Run the following: $ make init-db-test to create the knora-test repository and initialize it with loading some test data into the triplestore (Fuseki). Start the entire knora-stack (fuseki (db), sipi, api, salsah1) with the following command: $ make stack-up Then try opening http://localhost:3333/v1/resources/http%3A%2F%2Frdfh.ch%2F0803%2Fc5058f3a in a web browser. You should see a response in JSON describing a book. Note : To delete the existing containers and for a clean start, before creating the knora-test repository explained in the first step above, run the following: $ make stack-down-delete-volumes This stops the knora-stack and deletes any created volumes (deletes the database!). To only shut down the Knora-Stack without deleting the containers: $ make stack-down To restart the knora-api use the following command: $ make stack-restart-api If a change is made to knora-api code, only its image needs to be rebuilt. In that case, use $ make stack-up-fast which starts the knora-stack by skipping rebuilding most of the images (only api image is rebuilt). To work on Metadata, use $ make stack-up-with-metadata which will put three example metadata sets to the projects anything , images and dokubib . This data can then be consumed from localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 , localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F00FF and localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0804 . Managing Containers in Docker Dashboard The Docker Desktop is installed on your computer during the installation of docker, it enables easy management of docker containers and access to Docker Hub. To manage your docker containers, docker desktop provides a dashbord. In docker dashboard, you can see all the running containers, stop, start, restart, or completely delete them. For example, when you start the knora-stack as explained above, in the docker dashboard you will see following: Access the logs To read information logged out of any container (db, api, etc.), click on the container in the dashboard and choose logs . The example, below shows the logs of the database (db) container that includes the last SPARQL query sent to the triplestore. Note that, you can also print out the log information directly from the command line. For example, the same logs of the database container can be printed out using the following command: $ make stack-logs-db Similarly, the logs of the other containers can be printed out by running make with stack-logs-api or stack-logs-sipi . These commands print out and follow the logs, to only print the logs out without following, use -no-follow version of the commands for example: $ make stack-logs-db-no-follow Lastly, to print out the entire logs of the running knora-stack, use $ make stack-logs With the Docker plugin installed, you can attach a terminal to the docker container within VS Code. This will stream the docker logs to the terminal window of the editor. The docker plugin also allows for a number of other useful features, like inspecting the container's file system or attaching a shell to the container. Running the automated tests To run all test targets, use the following in the command line: $ make test-all To run a single test from the command line, for example SearchV1R2RSpec , run the following: $ sbt \" webapi / testOnly *SearchV1R2RSpec* \" Note: to run tests, the api container must be stopped first! Build and Publish Documentation First, you need to install the requirements through: $ make docs-install-requirements Then, to build docs into the local site folder, run the following command: $ make docs-build At this point, you can serve the docs to view them locally using $ make docs-serve Lastly, to build and publish docs to Github Pages, use $ make docs-publish Build and Publish Docker Images To build and publish all Docker images locally $ make docker-build To publish all Docker images to Dockerhub $ make docker-publish Load Testing on Mac OS X To test Knora with many concurrent connections on Mac OS X, you will need to adjust some kernel parameters to allow more open connections, to recycle ephemeral ports more quickly, and to use a wider range of ephemeral port numbers. The script webapi/scripts/macOS-kernel-test-config.sh will do this. Continuous Integration For continuous integration testing, we use Github CI Actions. Every commit pushed to the git repository or every pull request, triggers the build. Additionally, in Github there is a small checkmark beside every commit, signaling the status of the build (successful, unsuccessful, ongoing). The build that is executed on Github CI Actions is defined in .github/workflows/main.yml . Webapi Server Startup-Flags The Webapi-Server can be started with a number of flags. loadDemoData - Flag When the webapi-server is started with the loadDemoData flag, then at startup, the data which is configured in application.conf under the app.triplestore.rdf-data key is loaded into the triplestore, and any data in the triplestore is removed beforehand. allowReloadOverHTTP - Flag When the webapi.server is started with the allowReloadOverHTTP flag ( reStart -r ), then the v1/store/ResetTriplestoreContent route is activated. This route accepts a POST request, with a JSON payload consisting of the following example content: [ { \"path\": \"knora-ontologies/knora-base.ttl\", \"name\": \"http://www.knora.org/ontology/knora-base\" }, { \"path\": \"knora-ontologies/salsah-gui.ttl\", \"name\": \"http://www.knora.org/ontology/salsah-gui\" }, { \"path\": \"test_data/ontologies/incunabula-onto.ttl\", \"name\": \"http://www.knora.org/ontology/0803/incunabula\" }, { \"path\": \"test_data/all_data/incunabula-data.ttl\", \"name\": \"http://www.knora.org/data/incunabula\" } ] This content corresponds to the payload sent with the ResetTriplestoreContent message, defined inside the org.knora.webapi.messages.v1.store.triplestoremessages package. The path being the relative path to the ttl file which will be loaded into a named graph by the name of name .","title":"Build and Running"},{"location":"DSP-API/05-internals/development/building-and-running/#building-and-running","text":"","title":"Building and Running"},{"location":"DSP-API/05-internals/development/building-and-running/#running-the-stack","text":"With Docker installed, Run the following: $ make init-db-test to create the knora-test repository and initialize it with loading some test data into the triplestore (Fuseki). Start the entire knora-stack (fuseki (db), sipi, api, salsah1) with the following command: $ make stack-up Then try opening http://localhost:3333/v1/resources/http%3A%2F%2Frdfh.ch%2F0803%2Fc5058f3a in a web browser. You should see a response in JSON describing a book. Note : To delete the existing containers and for a clean start, before creating the knora-test repository explained in the first step above, run the following: $ make stack-down-delete-volumes This stops the knora-stack and deletes any created volumes (deletes the database!). To only shut down the Knora-Stack without deleting the containers: $ make stack-down To restart the knora-api use the following command: $ make stack-restart-api If a change is made to knora-api code, only its image needs to be rebuilt. In that case, use $ make stack-up-fast which starts the knora-stack by skipping rebuilding most of the images (only api image is rebuilt). To work on Metadata, use $ make stack-up-with-metadata which will put three example metadata sets to the projects anything , images and dokubib . This data can then be consumed from localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 , localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F00FF and localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0804 .","title":"Running the stack"},{"location":"DSP-API/05-internals/development/building-and-running/#managing-containers-in-docker-dashboard","text":"The Docker Desktop is installed on your computer during the installation of docker, it enables easy management of docker containers and access to Docker Hub. To manage your docker containers, docker desktop provides a dashbord. In docker dashboard, you can see all the running containers, stop, start, restart, or completely delete them. For example, when you start the knora-stack as explained above, in the docker dashboard you will see following:","title":"Managing Containers in Docker Dashboard"},{"location":"DSP-API/05-internals/development/building-and-running/#access-the-logs","text":"To read information logged out of any container (db, api, etc.), click on the container in the dashboard and choose logs . The example, below shows the logs of the database (db) container that includes the last SPARQL query sent to the triplestore. Note that, you can also print out the log information directly from the command line. For example, the same logs of the database container can be printed out using the following command: $ make stack-logs-db Similarly, the logs of the other containers can be printed out by running make with stack-logs-api or stack-logs-sipi . These commands print out and follow the logs, to only print the logs out without following, use -no-follow version of the commands for example: $ make stack-logs-db-no-follow Lastly, to print out the entire logs of the running knora-stack, use $ make stack-logs With the Docker plugin installed, you can attach a terminal to the docker container within VS Code. This will stream the docker logs to the terminal window of the editor. The docker plugin also allows for a number of other useful features, like inspecting the container's file system or attaching a shell to the container.","title":"Access the logs"},{"location":"DSP-API/05-internals/development/building-and-running/#running-the-automated-tests","text":"To run all test targets, use the following in the command line: $ make test-all To run a single test from the command line, for example SearchV1R2RSpec , run the following: $ sbt \" webapi / testOnly *SearchV1R2RSpec* \" Note: to run tests, the api container must be stopped first!","title":"Running the automated tests"},{"location":"DSP-API/05-internals/development/building-and-running/#build-and-publish-documentation","text":"First, you need to install the requirements through: $ make docs-install-requirements Then, to build docs into the local site folder, run the following command: $ make docs-build At this point, you can serve the docs to view them locally using $ make docs-serve Lastly, to build and publish docs to Github Pages, use $ make docs-publish","title":"Build and Publish Documentation"},{"location":"DSP-API/05-internals/development/building-and-running/#build-and-publish-docker-images","text":"To build and publish all Docker images locally $ make docker-build To publish all Docker images to Dockerhub $ make docker-publish","title":"Build and Publish Docker Images"},{"location":"DSP-API/05-internals/development/building-and-running/#load-testing-on-mac-os-x","text":"To test Knora with many concurrent connections on Mac OS X, you will need to adjust some kernel parameters to allow more open connections, to recycle ephemeral ports more quickly, and to use a wider range of ephemeral port numbers. The script webapi/scripts/macOS-kernel-test-config.sh will do this.","title":"Load Testing on Mac OS X"},{"location":"DSP-API/05-internals/development/building-and-running/#continuous-integration","text":"For continuous integration testing, we use Github CI Actions. Every commit pushed to the git repository or every pull request, triggers the build. Additionally, in Github there is a small checkmark beside every commit, signaling the status of the build (successful, unsuccessful, ongoing). The build that is executed on Github CI Actions is defined in .github/workflows/main.yml .","title":"Continuous Integration"},{"location":"DSP-API/05-internals/development/building-and-running/#webapi-server-startup-flags","text":"The Webapi-Server can be started with a number of flags.","title":"Webapi Server Startup-Flags"},{"location":"DSP-API/05-internals/development/building-and-running/#loaddemodata-flag","text":"When the webapi-server is started with the loadDemoData flag, then at startup, the data which is configured in application.conf under the app.triplestore.rdf-data key is loaded into the triplestore, and any data in the triplestore is removed beforehand.","title":"loadDemoData - Flag"},{"location":"DSP-API/05-internals/development/building-and-running/#allowreloadoverhttp-flag","text":"When the webapi.server is started with the allowReloadOverHTTP flag ( reStart -r ), then the v1/store/ResetTriplestoreContent route is activated. This route accepts a POST request, with a JSON payload consisting of the following example content: [ { \"path\": \"knora-ontologies/knora-base.ttl\", \"name\": \"http://www.knora.org/ontology/knora-base\" }, { \"path\": \"knora-ontologies/salsah-gui.ttl\", \"name\": \"http://www.knora.org/ontology/salsah-gui\" }, { \"path\": \"test_data/ontologies/incunabula-onto.ttl\", \"name\": \"http://www.knora.org/ontology/0803/incunabula\" }, { \"path\": \"test_data/all_data/incunabula-data.ttl\", \"name\": \"http://www.knora.org/data/incunabula\" } ] This content corresponds to the payload sent with the ResetTriplestoreContent message, defined inside the org.knora.webapi.messages.v1.store.triplestoremessages package. The path being the relative path to the ttl file which will be loaded into a named graph by the name of name .","title":"allowReloadOverHTTP - Flag"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/","text":"Docker Cheat Sheet A complete cheat sheet can be found here Lifecycle docker create creates a container but does not start it. docker run creates and starts a container in one operation. docker rename allows the container to be renamed. docker rm deletes a container. docker update updates a container's resource limits. If you want a transient container, docker run --rm will remove the container after it stops. If you want to map a directory on the host to a docker container, docker run -v $HOSTDIR:$DOCKERDIR . Starting and Stopping docker start starts a container so it is running. docker stop stops a running container. docker restart stops and starts a container. docker pause pauses a running container, \"freezing\" it in place. docker attach will connect to a running container. Info docker ps shows running containers. docker logs gets logs from container. (You can use a custom log driver, but logs is only available for json-file and journald in 1.10) docker inspect looks at all the info on a container (including IP address). docker events gets events from container. docker port shows public facing port of container. docker top shows running processes in container. docker stats shows containers' resource usage statistics. docker diff shows changed files in the container's FS. docker ps -a shows running and stopped containers. docker stats --all shows a running list of containers. Executing Commands docker exec to execute a command in container. To enter a running container, attach a new shell process to a running container called foo, use: docker exec -it foo /bin/bash . Images docker images shows all images. docker build creates image from Dockerfile.","title":"Docker Cheat Sheet"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#docker-cheat-sheet","text":"A complete cheat sheet can be found here","title":"Docker Cheat Sheet"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#lifecycle","text":"docker create creates a container but does not start it. docker run creates and starts a container in one operation. docker rename allows the container to be renamed. docker rm deletes a container. docker update updates a container's resource limits. If you want a transient container, docker run --rm will remove the container after it stops. If you want to map a directory on the host to a docker container, docker run -v $HOSTDIR:$DOCKERDIR .","title":"Lifecycle"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#starting-and-stopping","text":"docker start starts a container so it is running. docker stop stops a running container. docker restart stops and starts a container. docker pause pauses a running container, \"freezing\" it in place. docker attach will connect to a running container.","title":"Starting and Stopping"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#info","text":"docker ps shows running containers. docker logs gets logs from container. (You can use a custom log driver, but logs is only available for json-file and journald in 1.10) docker inspect looks at all the info on a container (including IP address). docker events gets events from container. docker port shows public facing port of container. docker top shows running processes in container. docker stats shows containers' resource usage statistics. docker diff shows changed files in the container's FS. docker ps -a shows running and stopped containers. docker stats --all shows a running list of containers.","title":"Info"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#executing-commands","text":"docker exec to execute a command in container. To enter a running container, attach a new shell process to a running container called foo, use: docker exec -it foo /bin/bash .","title":"Executing Commands"},{"location":"DSP-API/05-internals/development/docker-cheat-sheet/#images","text":"docker images shows all images. docker build creates image from Dockerfile.","title":"Images"},{"location":"DSP-API/05-internals/development/docker-compose/","text":"Starting the Knora Stack inside Docker Container To run Knora locally, we provide docker-compose.yml which can be used to start Fuseki, Sipi, Webapi running each in its own Docker container. To run the whole stack: $ make stack-up For additional information please see the Docker Compose documentation","title":"Starting the DSP-Stack inside Docker Container"},{"location":"DSP-API/05-internals/development/docker-compose/#starting-the-knora-stack-inside-docker-container","text":"To run Knora locally, we provide docker-compose.yml which can be used to start Fuseki, Sipi, Webapi running each in its own Docker container. To run the whole stack: $ make stack-up For additional information please see the Docker Compose documentation","title":"Starting the Knora Stack inside Docker Container"},{"location":"DSP-API/05-internals/development/generating-client-test-data/","text":"Generating Client Test Data Requirements Generate test requests and responses for Knora's routes, to be used in testing client code without the need for a running Knora instance. Implementation Client test data is generated as a side effect of running E2E tests. E2E tests use ClientTestDataCollector to collect API requests and responses. When the E2E tests have completed, the script webapi/scripts/dump-client-test-data.sh saves the collected test data in a Zip file. It then checks the filenames in the Zip file by comparing them with the list in webapi/scripts/expected-client-test-data.txt . Usage To generate client test data, type: make client-test-data When the tests have finished running, you will find the file client-test-data.zip in the current directory. Then, run this script to update the list of expected test data files: webapi/scripts/update-expected-client-test-data.sh client-test-data.zip","title":"Generating Client Test Data"},{"location":"DSP-API/05-internals/development/generating-client-test-data/#generating-client-test-data","text":"","title":"Generating Client Test Data"},{"location":"DSP-API/05-internals/development/generating-client-test-data/#requirements","text":"Generate test requests and responses for Knora's routes, to be used in testing client code without the need for a running Knora instance.","title":"Requirements"},{"location":"DSP-API/05-internals/development/generating-client-test-data/#implementation","text":"Client test data is generated as a side effect of running E2E tests. E2E tests use ClientTestDataCollector to collect API requests and responses. When the E2E tests have completed, the script webapi/scripts/dump-client-test-data.sh saves the collected test data in a Zip file. It then checks the filenames in the Zip file by comparing them with the list in webapi/scripts/expected-client-test-data.txt .","title":"Implementation"},{"location":"DSP-API/05-internals/development/generating-client-test-data/#usage","text":"To generate client test data, type: make client-test-data When the tests have finished running, you will find the file client-test-data.zip in the current directory. Then, run this script to update the list of expected test data files: webapi/scripts/update-expected-client-test-data.sh client-test-data.zip","title":"Usage"},{"location":"DSP-API/05-internals/development/overview/","text":"Overview Developing for DSP-API requires a complete local installation of Knora. The different parts are: The cloned DSP-API Github repository Fuseki - supplied triplestore in the DSP-API Github repository. Sipi by building from source or using the docker image Knora Github Repository $ git clone https://github.com/dasch-swiss/dsp-api Triplestore A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Apache Jena Fuseki . Sipi Build Sipi Docker Image The Sipi docker image needs to be build by hand, as it requires the Kakadu distribution. To build the image, and push it to the docker hub, follow the following steps: $ git clone https://github.com/dhlab-basel/docker-sipi (copy the Kakadu distribution ``v7_8-01382N.zip`` to the ``docker-sipi`` directory) $ docker build -t daschswiss/sipi $ docker run --name sipi --rm -it -p 1024:1024 daschswiss/sipi (Ctrl-c out of terminal will stop and delete container) $ docker push daschswiss/sipi Pushing the image to the docker hub requires prior authentication with $ docker login . The user needs to be registered on hub.docker.com . Also, the user needs to be allowed to push to the dblabbasel organisation. Running Sipi To use the docker image stored locally or on the docker hub repository type: $ docker run --name sipi -d -p 1024:1024 daschswiss/sipi This will create and start a docker container with the daschswiss/sipi image in the background. The default behaviour is to start Sipi by calling the following command: $ /sipi/local/bin/sipi -config /sipi/config/sipi.test-config.lua To override this default behaviour, start the container by supplying another config file: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /sipi/config/sipi.config.lua You can also mount a directory (the local directory in this example), and use a config file that is outside of the docker container: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ -v $PWD:/localdir \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /localdir/sipi.test-config.lua","title":"Overview"},{"location":"DSP-API/05-internals/development/overview/#overview","text":"Developing for DSP-API requires a complete local installation of Knora. The different parts are: The cloned DSP-API Github repository Fuseki - supplied triplestore in the DSP-API Github repository. Sipi by building from source or using the docker image","title":"Overview"},{"location":"DSP-API/05-internals/development/overview/#knora-github-repository","text":"$ git clone https://github.com/dasch-swiss/dsp-api","title":"Knora Github Repository"},{"location":"DSP-API/05-internals/development/overview/#triplestore","text":"A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Apache Jena Fuseki .","title":"Triplestore"},{"location":"DSP-API/05-internals/development/overview/#sipi","text":"","title":"Sipi"},{"location":"DSP-API/05-internals/development/overview/#build-sipi-docker-image","text":"The Sipi docker image needs to be build by hand, as it requires the Kakadu distribution. To build the image, and push it to the docker hub, follow the following steps: $ git clone https://github.com/dhlab-basel/docker-sipi (copy the Kakadu distribution ``v7_8-01382N.zip`` to the ``docker-sipi`` directory) $ docker build -t daschswiss/sipi $ docker run --name sipi --rm -it -p 1024:1024 daschswiss/sipi (Ctrl-c out of terminal will stop and delete container) $ docker push daschswiss/sipi Pushing the image to the docker hub requires prior authentication with $ docker login . The user needs to be registered on hub.docker.com . Also, the user needs to be allowed to push to the dblabbasel organisation.","title":"Build Sipi Docker Image"},{"location":"DSP-API/05-internals/development/overview/#running-sipi","text":"To use the docker image stored locally or on the docker hub repository type: $ docker run --name sipi -d -p 1024:1024 daschswiss/sipi This will create and start a docker container with the daschswiss/sipi image in the background. The default behaviour is to start Sipi by calling the following command: $ /sipi/local/bin/sipi -config /sipi/config/sipi.test-config.lua To override this default behaviour, start the container by supplying another config file: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /sipi/config/sipi.config.lua You can also mount a directory (the local directory in this example), and use a config file that is outside of the docker container: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ -v $PWD:/localdir \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /localdir/sipi.test-config.lua","title":"Running Sipi"},{"location":"DSP-API/05-internals/development/testing/","text":"Testing How to Write and Run Unit Tests A test is not a unit test if: It talks to the database It communicates across the network It touches the file system It can\u2019t run at the same time as any of your other unit tests You have to do special things to your environment (such as editing config files) to run it Unit tests live in the src/test folder of our sbt projects. Run all unit tests from terminal: sbt test How to Write and Run Integration Tests Mostly you should consider writing unit tests . These can be executed fast and help developers more in their daily work. You might need to create an integration test because: The test needs to talk to a database It requires network It is slow and cannot run in parallel with other tests You have to do special things to the environment in order to run it In this case create it in the src/it source set of our projects. .NOTE Currently only the webapi project supports integration tests. Run all integration tests from the terminal. make integration-test .NOTE The integration tests currently depend on a locally published Sipi container, the make target helps you with that. Debugging You can debug unit tests directly in your IDE. For debugging the integration tests locally with sbt or your IDE you need to have a fresh SIPI container build: make docker-build-sipi-image","title":"Testing"},{"location":"DSP-API/05-internals/development/testing/#testing","text":"","title":"Testing"},{"location":"DSP-API/05-internals/development/testing/#how-to-write-and-run-unit-tests","text":"A test is not a unit test if: It talks to the database It communicates across the network It touches the file system It can\u2019t run at the same time as any of your other unit tests You have to do special things to your environment (such as editing config files) to run it Unit tests live in the src/test folder of our sbt projects. Run all unit tests from terminal: sbt test","title":"How to Write and Run Unit Tests"},{"location":"DSP-API/05-internals/development/testing/#how-to-write-and-run-integration-tests","text":"Mostly you should consider writing unit tests . These can be executed fast and help developers more in their daily work. You might need to create an integration test because: The test needs to talk to a database It requires network It is slow and cannot run in parallel with other tests You have to do special things to the environment in order to run it In this case create it in the src/it source set of our projects. .NOTE Currently only the webapi project supports integration tests. Run all integration tests from the terminal. make integration-test .NOTE The integration tests currently depend on a locally published Sipi container, the make target helps you with that.","title":"How to Write and Run Integration Tests"},{"location":"DSP-API/05-internals/development/testing/#debugging","text":"You can debug unit tests directly in your IDE. For debugging the integration tests locally with sbt or your IDE you need to have a fresh SIPI container build: make docker-build-sipi-image","title":"Debugging"},{"location":"DSP-API/05-internals/development/third-party/","text":"Third-Party Dependencies Third party libraries are managed by SBT. Defining Dependencies in Dependencies.scala Within the build.sbt file, the Dependencies package is referenced, which is located in project/Dependencies.scala . All third party dependencies need to be declared there. Referencing a third party library There is an object Dependencies where each library should be declared in a val . val akkaHttpCors = \"ch.megard\" %% \"akka-http-cors\" % \"1.0.0\" The first string corresponds to the group/organization in the library's maven artefact, the second string corresponds to the artefact ID and the third string defines the version. The strings are combined with % or %% operators, the latter fixing the dependency to the specified scala-version. It is also possible to use variables in these definitions, e.g. if multiple dependencies share a version number: val ZioVersion = \"2.0.0-RC2\" val zio = \"dev.zio\" %% \"zio\" % ZioVersion val zioTest = \"dev.zio\" %% \"zio-test\" % ZioVersion Assigning the dependencies to a specific subproject For each SBT project, there is one Seq in the Dependencies object. In order to make use of the declared dependencies, they must be referred to in the Seq of the respective subproject. val webapiLibraryDependencies = Seq ( akkaActor , akkaHttp , akkaSlf4j % Runtime , akkaHttpTestkit % Test , ... ) By default, the dependencies will be scoped to compile time. But it's possible to override this to Runtime or Test . Docker Image Versions The required Docker image versions of Sipi and Fuseki are also defined in the Dependencies.scala file.","title":"Third-Party Dependencies"},{"location":"DSP-API/05-internals/development/third-party/#third-party-dependencies","text":"Third party libraries are managed by SBT.","title":"Third-Party Dependencies"},{"location":"DSP-API/05-internals/development/third-party/#defining-dependencies-in-dependenciesscala","text":"Within the build.sbt file, the Dependencies package is referenced, which is located in project/Dependencies.scala . All third party dependencies need to be declared there.","title":"Defining Dependencies in Dependencies.scala"},{"location":"DSP-API/05-internals/development/third-party/#referencing-a-third-party-library","text":"There is an object Dependencies where each library should be declared in a val . val akkaHttpCors = \"ch.megard\" %% \"akka-http-cors\" % \"1.0.0\" The first string corresponds to the group/organization in the library's maven artefact, the second string corresponds to the artefact ID and the third string defines the version. The strings are combined with % or %% operators, the latter fixing the dependency to the specified scala-version. It is also possible to use variables in these definitions, e.g. if multiple dependencies share a version number: val ZioVersion = \"2.0.0-RC2\" val zio = \"dev.zio\" %% \"zio\" % ZioVersion val zioTest = \"dev.zio\" %% \"zio-test\" % ZioVersion","title":"Referencing a third party library"},{"location":"DSP-API/05-internals/development/third-party/#assigning-the-dependencies-to-a-specific-subproject","text":"For each SBT project, there is one Seq in the Dependencies object. In order to make use of the declared dependencies, they must be referred to in the Seq of the respective subproject. val webapiLibraryDependencies = Seq ( akkaActor , akkaHttp , akkaSlf4j % Runtime , akkaHttpTestkit % Test , ... ) By default, the dependencies will be scoped to compile time. But it's possible to override this to Runtime or Test .","title":"Assigning the dependencies to a specific subproject"},{"location":"DSP-API/05-internals/development/third-party/#docker-image-versions","text":"The required Docker image versions of Sipi and Fuseki are also defined in the Dependencies.scala file.","title":"Docker Image Versions"},{"location":"DSP-API/05-internals/development/updating-repositories/","text":"Updating Repositories Requirements When a new version of Knora requires an existing repository to be updated, do this automatically when Knora starts, if possible. Make the update process as fast as possible, with some indication of progress as it runs. Design As explained in Knora Ontology Versions , the knora-base ontology contains a version string to ensure compatibility between a repository and a given version of Knora. The same version string is therefore hard-coded in the Knora source code, in the string constant org.knora.webapi.KnoraBaseVersion . For new pull requests, the format of this string is knora-base vN , where N is an integer that is incremented for each version. During Knora's startup process, ApplicationActor sends an UpdateRepositoryRequest message to the StoreManager , which forwards it to TriplestoreManager , which delegates it to org.knora.webapi.store.triplestore.upgrade.RepositoryUpdater . RepositoryUpdater does the following procedure: Check the knora-base version string in the repository. Consult org.knora.webapi.store.triplestore.upgrade.RepositoryUpdatePlan to see which transformations are needed. Download the entire repository from the triplestore into an N-Quads file. Read the N-Quads file into an RdfModel . Update the RdfModel by running the necessary transformations, and replacing the built-in DSP ontologies with the current ones. Save the RdfModel to a new N-Quads file. Empty the repository in the triplestore. Upload the transformed repository file to the triplestore. To update the RdfModel , RepositoryUpdater runs a sequence of upgrade plugins, each of which is a class in org.knora.webapi.store.triplestore.upgrade.plugins and is registered in RepositoryUpdatePlan . Design Rationale We tried and rejected several other designs: Running SPARQL updates in the triplestore: too slow, and no way to report progress during the update. Downloading the repository and transforming it in Python using rdflib : too slow. Downloading the repository and transforming it in C++ using Redland : also too slow. The Scala implementation is the fastest by far. The whole repository is uploaded in a single transaction, rather than uploading one named graph at a time, because GraphDB's consistency checker can enforce dependencies between named graphs. Adding an Upgrade Plugin Each time a pull request introduces changes that are not compatible with existing data, the following must happen: The knora-base version number must be incremented in knora-base.ttl and in the string constant org.knora.webapi.KnoraBaseVersion . A plugin must be added in the package org.knora.webapi.store.triplestore.upgrade.plugins , to transform existing repositories so that they are compatible with the code changes introduced in the pull request. Each new plugin must be registered by adding it to the sequence returned by RepositoryUpdatePlan.makePluginsForVersions . The order of version numbers (and the plugins) must correspond to the order in which the pull requests are merged. An upgrade plugin is a Scala class that extends UpgradePlugin . The name of the plugin class should refer to the pull request that made the transformation necessary, using the format UpgradePluginPRNNNN , where NNNN is the number of the pull request. A plugin's transform method takes an RdfModel (a mutable object representing the repository) and modifies it as needed. Before transforming the data, a plugin can check whether a required manual transformation has been carried out. If the requirement is not met, the plugin can throw InconsistentRepositoryDataException to abort the upgrade process. Testing Update Plugins Each plugin should have a unit test that extends UpgradePluginSpec . A typical test loads a file containing RDF test data into a RdfModel , runs the plugin, makes an RdfRepository containing the transformed RdfModel , and uses SPARQL to check the result.","title":"Updating Repositories"},{"location":"DSP-API/05-internals/development/updating-repositories/#updating-repositories","text":"","title":"Updating Repositories"},{"location":"DSP-API/05-internals/development/updating-repositories/#requirements","text":"When a new version of Knora requires an existing repository to be updated, do this automatically when Knora starts, if possible. Make the update process as fast as possible, with some indication of progress as it runs.","title":"Requirements"},{"location":"DSP-API/05-internals/development/updating-repositories/#design","text":"As explained in Knora Ontology Versions , the knora-base ontology contains a version string to ensure compatibility between a repository and a given version of Knora. The same version string is therefore hard-coded in the Knora source code, in the string constant org.knora.webapi.KnoraBaseVersion . For new pull requests, the format of this string is knora-base vN , where N is an integer that is incremented for each version. During Knora's startup process, ApplicationActor sends an UpdateRepositoryRequest message to the StoreManager , which forwards it to TriplestoreManager , which delegates it to org.knora.webapi.store.triplestore.upgrade.RepositoryUpdater . RepositoryUpdater does the following procedure: Check the knora-base version string in the repository. Consult org.knora.webapi.store.triplestore.upgrade.RepositoryUpdatePlan to see which transformations are needed. Download the entire repository from the triplestore into an N-Quads file. Read the N-Quads file into an RdfModel . Update the RdfModel by running the necessary transformations, and replacing the built-in DSP ontologies with the current ones. Save the RdfModel to a new N-Quads file. Empty the repository in the triplestore. Upload the transformed repository file to the triplestore. To update the RdfModel , RepositoryUpdater runs a sequence of upgrade plugins, each of which is a class in org.knora.webapi.store.triplestore.upgrade.plugins and is registered in RepositoryUpdatePlan .","title":"Design"},{"location":"DSP-API/05-internals/development/updating-repositories/#design-rationale","text":"We tried and rejected several other designs: Running SPARQL updates in the triplestore: too slow, and no way to report progress during the update. Downloading the repository and transforming it in Python using rdflib : too slow. Downloading the repository and transforming it in C++ using Redland : also too slow. The Scala implementation is the fastest by far. The whole repository is uploaded in a single transaction, rather than uploading one named graph at a time, because GraphDB's consistency checker can enforce dependencies between named graphs.","title":"Design Rationale"},{"location":"DSP-API/05-internals/development/updating-repositories/#adding-an-upgrade-plugin","text":"Each time a pull request introduces changes that are not compatible with existing data, the following must happen: The knora-base version number must be incremented in knora-base.ttl and in the string constant org.knora.webapi.KnoraBaseVersion . A plugin must be added in the package org.knora.webapi.store.triplestore.upgrade.plugins , to transform existing repositories so that they are compatible with the code changes introduced in the pull request. Each new plugin must be registered by adding it to the sequence returned by RepositoryUpdatePlan.makePluginsForVersions . The order of version numbers (and the plugins) must correspond to the order in which the pull requests are merged. An upgrade plugin is a Scala class that extends UpgradePlugin . The name of the plugin class should refer to the pull request that made the transformation necessary, using the format UpgradePluginPRNNNN , where NNNN is the number of the pull request. A plugin's transform method takes an RdfModel (a mutable object representing the repository) and modifies it as needed. Before transforming the data, a plugin can check whether a required manual transformation has been carried out. If the requirement is not met, the plugin can throw InconsistentRepositoryDataException to abort the upgrade process.","title":"Adding an Upgrade Plugin"},{"location":"DSP-API/05-internals/development/updating-repositories/#testing-update-plugins","text":"Each plugin should have a unit test that extends UpgradePluginSpec . A typical test loads a file containing RDF test data into a RdfModel , runs the plugin, makes an RdfRepository containing the transformed RdfModel , and uses SPARQL to check the result.","title":"Testing Update Plugins"},{"location":"DSP-API/05-internals/development/vscode-config/","text":"Setup Visual Studio Code for development of DSP-API To have full functionality, the Scala Metals plugin should be installed. Additionally, a number of plugins can be installed for convenience, but are not required. Those include but are by no means limited to: - Docker - to attach to running docker containers - Stardog RDF grammar - TTL syntax highlighting - Lua - REST client - ... Formatter As a formatter, we use Scalafmt . Metals automatically recognizes the formatting configuration in the .scalafmt.conf file in the root directory. VSCode should be configured so that it austomatically formats (e.g. on file saved). Running Tests The tests can be run through make commands or through SBT. The most convenient way to run the tests is through VSCode. Metals recognizes scalatest suits and lets you run them in the text explorer: Or with the setting \"metals.testUserInterface\": \"Code Lenses\" directly in the text: Debugger It is currently not possible to start the stack in debug mode. Tests can be run in debug mode by running them as described above but choosing debug test instead of test .","title":"Setup Visual Studio Code for development of DSP-API"},{"location":"DSP-API/05-internals/development/vscode-config/#setup-visual-studio-code-for-development-of-dsp-api","text":"To have full functionality, the Scala Metals plugin should be installed. Additionally, a number of plugins can be installed for convenience, but are not required. Those include but are by no means limited to: - Docker - to attach to running docker containers - Stardog RDF grammar - TTL syntax highlighting - Lua - REST client - ...","title":"Setup Visual Studio Code for development of DSP-API"},{"location":"DSP-API/05-internals/development/vscode-config/#formatter","text":"As a formatter, we use Scalafmt . Metals automatically recognizes the formatting configuration in the .scalafmt.conf file in the root directory. VSCode should be configured so that it austomatically formats (e.g. on file saved).","title":"Formatter"},{"location":"DSP-API/05-internals/development/vscode-config/#running-tests","text":"The tests can be run through make commands or through SBT. The most convenient way to run the tests is through VSCode. Metals recognizes scalatest suits and lets you run them in the text explorer: Or with the setting \"metals.testUserInterface\": \"Code Lenses\" directly in the text:","title":"Running Tests"},{"location":"DSP-API/05-internals/development/vscode-config/#debugger","text":"It is currently not possible to start the stack in debug mode. Tests can be run in debug mode by running them as described above but choosing debug test instead of test .","title":"Debugger"},{"location":"DSP-API/06-sipi/","text":"The Sipi Media Server Sipi is a high-performance media server written in C++, for serving and converting binary media files such as images and video. Sipi can efficiently convert between many different formats on demand, preserving embedded metadata, and implements the International Image Interoperability Framework (IIIF) . DSP-API is designed to use Sipi for converting and serving media files. Setting Up Sipi for DSP-API Interaction Between Sipi and DSP-API","title":"Overview"},{"location":"DSP-API/06-sipi/#the-sipi-media-server","text":"Sipi is a high-performance media server written in C++, for serving and converting binary media files such as images and video. Sipi can efficiently convert between many different formats on demand, preserving embedded metadata, and implements the International Image Interoperability Framework (IIIF) . DSP-API is designed to use Sipi for converting and serving media files. Setting Up Sipi for DSP-API Interaction Between Sipi and DSP-API","title":"The Sipi Media Server"},{"location":"DSP-API/06-sipi/setup-sipi-for-dsp-api/","text":"Setting Up Sipi for DSP-API Setup and Execution In order to serve files to the client application like the Salsah GUI, Sipi must be set up and running. Sipi can be downloaded from its own GitHub repository: https://github.com/dasch-swiss/sipi (which requires building from source), or the published docker image . can be used. To start Sipi, run the following command from inside the sipi/ folder: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.docker-config.lua where LOCAL_IP_ADDRESS is the IP of the host running DSP-API . --config=/sipi/config/sipi.docker-config.lua . Please see sipi.docker-config.lua for the settings like URL, port number etc. These settings need to be set according to DSP-API's application.conf . If you use the default settings both in Sipi and DSP-API, there is no need to change these settings. Whenever a file is requested from Sipi (e.g. a browser trying to dereference an image link served by DSP-API), a preflight function is called. This function is defined in sipi.init.lua present in the Sipi root directory. It takes three parameters: prefix , identifier (the name of the requested file), and cookie . The prefix is the shortcode of the project that the resource containing the file value belongs to. Given this information, Sipi asks the API about the current user's permissions on the given file. The cookie contains the current user's session id, so the API can match Sipi's request with a given user profile and determine the permissions this user has on the file. If the response grants sufficient permissions, the file is served in the requested quality. If the user has preview rights, Sipi serves the file in reduced quality or integrates a watermark. If the user has no permissions, Sipi refuses to serve the file. However, all of this behaviour is defined in the preflight function in Sipi and not controlled by the API. DSP-API only provides the permission code. See Authentication of Users with Sipi for more information about sharing the session ID. Using Sipi in Test Mode If you just want to test Sipi with DSP-API without serving the actual files (e.g. when executing browser tests), you can simply start Sipi like this: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.docker-test-config.lua Then always the same test file will be served which is delivered with Sipi. In test mode, Sipi will not ask DSP-API about the user's permission on the requested file. Additional Sipi Environment Variables Additionally, these environment variables can be used to further configure Sipi: SIPI_WEBAPI_HOSTNAME=localhost : overrides knora_path in Sipi's config SIPI_WEBAPI_PORT=3333 : overrides knora_port in Sipi's config These variables need to be explicitly used like in sipi.init.lua : -- -- Allows to set SIPI_WEBAPI_HOSTNAME environment variable and use its value. -- local webapi_hostname = os.getenv ( \"SIPI_WEBAPI_HOSTNAME\" ) if webapi_hostname == nil then webapi_hostname = config . knora_path end server . log ( \"webapi_hostname: \" .. webapi_hostname , server . loglevel . LOG_DEBUG ) -- -- Allows to set SIPI_WEBAPI_PORT environment variable and use its value. -- local webapi_port = os.getenv ( \"SIPI_WEBAPI_PORT\" ) if webapi_port == nil then webapi_port = config . knora_port end server . log ( \"webapi_port: \" .. webapi_port , server . loglevel . LOG_DEBUG ) knora_url = 'http://' .. webapi_hostname .. ':' .. webapi_port .. '/admin/files/' .. prefix .. '/' .. identifier","title":"Setting Up Sipi for DSP-API"},{"location":"DSP-API/06-sipi/setup-sipi-for-dsp-api/#setting-up-sipi-for-dsp-api","text":"","title":"Setting Up Sipi for DSP-API"},{"location":"DSP-API/06-sipi/setup-sipi-for-dsp-api/#setup-and-execution","text":"In order to serve files to the client application like the Salsah GUI, Sipi must be set up and running. Sipi can be downloaded from its own GitHub repository: https://github.com/dasch-swiss/sipi (which requires building from source), or the published docker image . can be used. To start Sipi, run the following command from inside the sipi/ folder: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.docker-config.lua where LOCAL_IP_ADDRESS is the IP of the host running DSP-API . --config=/sipi/config/sipi.docker-config.lua . Please see sipi.docker-config.lua for the settings like URL, port number etc. These settings need to be set according to DSP-API's application.conf . If you use the default settings both in Sipi and DSP-API, there is no need to change these settings. Whenever a file is requested from Sipi (e.g. a browser trying to dereference an image link served by DSP-API), a preflight function is called. This function is defined in sipi.init.lua present in the Sipi root directory. It takes three parameters: prefix , identifier (the name of the requested file), and cookie . The prefix is the shortcode of the project that the resource containing the file value belongs to. Given this information, Sipi asks the API about the current user's permissions on the given file. The cookie contains the current user's session id, so the API can match Sipi's request with a given user profile and determine the permissions this user has on the file. If the response grants sufficient permissions, the file is served in the requested quality. If the user has preview rights, Sipi serves the file in reduced quality or integrates a watermark. If the user has no permissions, Sipi refuses to serve the file. However, all of this behaviour is defined in the preflight function in Sipi and not controlled by the API. DSP-API only provides the permission code. See Authentication of Users with Sipi for more information about sharing the session ID.","title":"Setup and Execution"},{"location":"DSP-API/06-sipi/setup-sipi-for-dsp-api/#using-sipi-in-test-mode","text":"If you just want to test Sipi with DSP-API without serving the actual files (e.g. when executing browser tests), you can simply start Sipi like this: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.docker-test-config.lua Then always the same test file will be served which is delivered with Sipi. In test mode, Sipi will not ask DSP-API about the user's permission on the requested file.","title":"Using Sipi in Test Mode"},{"location":"DSP-API/06-sipi/setup-sipi-for-dsp-api/#additional-sipi-environment-variables","text":"Additionally, these environment variables can be used to further configure Sipi: SIPI_WEBAPI_HOSTNAME=localhost : overrides knora_path in Sipi's config SIPI_WEBAPI_PORT=3333 : overrides knora_port in Sipi's config These variables need to be explicitly used like in sipi.init.lua : -- -- Allows to set SIPI_WEBAPI_HOSTNAME environment variable and use its value. -- local webapi_hostname = os.getenv ( \"SIPI_WEBAPI_HOSTNAME\" ) if webapi_hostname == nil then webapi_hostname = config . knora_path end server . log ( \"webapi_hostname: \" .. webapi_hostname , server . loglevel . LOG_DEBUG ) -- -- Allows to set SIPI_WEBAPI_PORT environment variable and use its value. -- local webapi_port = os.getenv ( \"SIPI_WEBAPI_PORT\" ) if webapi_port == nil then webapi_port = config . knora_port end server . log ( \"webapi_port: \" .. webapi_port , server . loglevel . LOG_DEBUG ) knora_url = 'http://' .. webapi_hostname .. ':' .. webapi_port .. '/admin/files/' .. prefix .. '/' .. identifier","title":"Additional Sipi Environment Variables"},{"location":"DSP-API/06-sipi/sipi-and-dsp-api/","text":"Interaction Between Sipi and DSP-API General Remarks DSP-API and Sipi (Simple Image Presentation Interface) are two complementary software projects. Whereas DSP-API deals with data that is written to and read from a triplestore (metadata and annotations), Sipi takes care of storing, converting and serving image files as well as other types of files such as audio, video, or documents (binary files it just stores and serves). DSP-API and Sipi stick to a clear division of responsibility regarding files: DSP-API knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from Sipi, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by Sipi. Adding Files to DSP A file is first uploaded to Sipi, then its metadata is submitted to DSP. The implementation of this procedure is described in DSP-API and Sipi . Instructions for the client are given in Creating File Values (for DSP-API v2) and in Adding Resources with Image Files (for API v1). Retrieving Files from Sipi File URLs in API v2 In DSP-API v2, image file URLs are provided in IIIF format. In the simple ontology schema , a file value is simply a IIIF URL that can be used to retrieve the file from Sipi. In the complex schema, it is a StillImageFileValue with additional properties that the client can use to construct different IIIF URLs, e.g. at different resolutions. See the knora-api ontology for details. File URLs in API v1 In API v1, for each file value, DSP-API creates several Sipi URLs for accessing the file at different resolutions: \"resinfo\": { \"locations\": [ { \"duration\": \u200b0, \"nx\": \u200b95, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jpg/full/max/0/default.jpg\", \"ny\": \u200b128, \"fps\": \u200b0, \"format_name\": \"JPEG\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b82, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/82,110/0/default.jpg\", \"ny\": \u200b110, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b163, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/163,219/0/default.jpg\", \"ny\": \u200b219, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" } ... ], \"restype_label\": \"Seite\", \"resclass_has_location\": true, Each of these paths has to be handled by the browser by making a call to Sipi, obtaining the binary representation in the desired quality. Authentication of Users with Sipi Whenever a file is requested, Sipi asks the DSP-API about the current user's permissions on the given file. This is achieved by sharing the session cookie with Sipi. When the user logs in to DSP using his browser (using either V1 or V2 authentication route), a session cookie containing a JWT token representing the user is stored in the user's client. This session cookie is then read by Sipi and used to ask DSP-API for the user's image permissions. For the session cookie to be sent to Sipi, both the DSP-API and Sipi endpoints need to be under the same domain, e.g., api.example.com and iiif.example.com .","title":"Interaction between Sipi and DSP-API"},{"location":"DSP-API/06-sipi/sipi-and-dsp-api/#interaction-between-sipi-and-dsp-api","text":"","title":"Interaction Between Sipi and DSP-API"},{"location":"DSP-API/06-sipi/sipi-and-dsp-api/#general-remarks","text":"DSP-API and Sipi (Simple Image Presentation Interface) are two complementary software projects. Whereas DSP-API deals with data that is written to and read from a triplestore (metadata and annotations), Sipi takes care of storing, converting and serving image files as well as other types of files such as audio, video, or documents (binary files it just stores and serves). DSP-API and Sipi stick to a clear division of responsibility regarding files: DSP-API knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from Sipi, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by Sipi.","title":"General Remarks"},{"location":"DSP-API/06-sipi/sipi-and-dsp-api/#adding-files-to-dsp","text":"A file is first uploaded to Sipi, then its metadata is submitted to DSP. The implementation of this procedure is described in DSP-API and Sipi . Instructions for the client are given in Creating File Values (for DSP-API v2) and in Adding Resources with Image Files (for API v1).","title":"Adding Files to DSP"},{"location":"DSP-API/06-sipi/sipi-and-dsp-api/#retrieving-files-from-sipi","text":"","title":"Retrieving Files from Sipi"},{"location":"DSP-API/06-sipi/sipi-and-dsp-api/#file-urls-in-api-v2","text":"In DSP-API v2, image file URLs are provided in IIIF format. In the simple ontology schema , a file value is simply a IIIF URL that can be used to retrieve the file from Sipi. In the complex schema, it is a StillImageFileValue with additional properties that the client can use to construct different IIIF URLs, e.g. at different resolutions. See the knora-api ontology for details.","title":"File URLs in API v2"},{"location":"DSP-API/06-sipi/sipi-and-dsp-api/#file-urls-in-api-v1","text":"In API v1, for each file value, DSP-API creates several Sipi URLs for accessing the file at different resolutions: \"resinfo\": { \"locations\": [ { \"duration\": \u200b0, \"nx\": \u200b95, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jpg/full/max/0/default.jpg\", \"ny\": \u200b128, \"fps\": \u200b0, \"format_name\": \"JPEG\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b82, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/82,110/0/default.jpg\", \"ny\": \u200b110, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b163, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/163,219/0/default.jpg\", \"ny\": \u200b219, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" } ... ], \"restype_label\": \"Seite\", \"resclass_has_location\": true, Each of these paths has to be handled by the browser by making a call to Sipi, obtaining the binary representation in the desired quality.","title":"File URLs in API v1"},{"location":"DSP-API/06-sipi/sipi-and-dsp-api/#authentication-of-users-with-sipi","text":"Whenever a file is requested, Sipi asks the DSP-API about the current user's permissions on the given file. This is achieved by sharing the session cookie with Sipi. When the user logs in to DSP using his browser (using either V1 or V2 authentication route), a session cookie containing a JWT token representing the user is stored in the user's client. This session cookie is then read by Sipi and used to ask DSP-API for the user's image permissions. For the session cookie to be sent to Sipi, both the DSP-API and Sipi endpoints need to be under the same domain, e.g., api.example.com and iiif.example.com .","title":"Authentication of Users with Sipi"},{"location":"DSP-API/07-lucene/lucene-query-parser-syntax/","text":"Lucene The Lucene full-text index provided by the triplestore is used to perform full-text searches in Knora. The exact behavior can be different depending on the triplestore. Lucene Query Parser Syntax Full-text searches in Knora are based on Lucene. Therefore, full-text searches support the Lucene Query Parser Syntax . A full-text search consists of a single word in the simplest case, but could also be composed of several words combined with Boolean operators . By default, Lucene combines two or more terms separated by space with a logical OR. For examples, see Lucene Query Parser Syntax .","title":"Lucene Query Parser Syntax"},{"location":"DSP-API/07-lucene/lucene-query-parser-syntax/#lucene","text":"The Lucene full-text index provided by the triplestore is used to perform full-text searches in Knora. The exact behavior can be different depending on the triplestore.","title":"Lucene"},{"location":"DSP-API/07-lucene/lucene-query-parser-syntax/#lucene-query-parser-syntax","text":"Full-text searches in Knora are based on Lucene. Therefore, full-text searches support the Lucene Query Parser Syntax . A full-text search consists of a single word in the simplest case, but could also be composed of several words combined with Boolean operators . By default, Lucene combines two or more terms separated by space with a logical OR. For examples, see Lucene Query Parser Syntax .","title":"Lucene Query Parser Syntax"},{"location":"DSP-API/08-faq/","text":"Frequently Asked Questions File Formats What file formats does Knora store? See File Formats in Knora . Does Knora store XML files? XML files do not lend themselves to searching and linking. Knora's RDF storage is better suited to its goal of facilitating data reuse. If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF . This will allow both text and markup to be searched using Gravsearch . Knora can also regenerate, at any time, an XML document that is equivalent to the original one. If you have XML that simply represents structured data (rather than text documents), we recommend converting it to Knora resources, which are stored as RDF. Triplestores Which triplestores can be used with DSP-API? DSP-API is tested with Apache Jena Fuseki . DSP Ontologies Can a project use classes or properties defined in another project's ontology? DSP-API does not allow this to be done with project-specific ontologies. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators promise not to change it in ways that could affect other ontologies or data that are based on it. See Shared Ontologies for details. Why doesn't DSP-API use rdfs:domain and rdfs:range for consistency checking? DSP-API's consistency checking uses specific properties, which are called knora-base:subjectClassConstraint and knora-base:objectClassConstraint in the knora-base ontology, and knora-api:subjectType and knora-api:objectType in the knora-api ontologies. These properties express restrictions on the possible subjects and objects of a property. If a property's subject or object does not conform to the specified restrictions, DSP-API considers it an error. In contrast, the RDF Schema specification says that rdfs:domain and rdfs:range can be used to \"infer additional information\" about the subjects and objects of properties, rather than to enforce restrictions. This is, in fact, what RDFS reasoners do in practice. For example, consider these statements: example:hasAuthor rdfs:range example:Person . data:book1 example:hasAuthor data:oxygen . To an RDFS reasoner, the first statement means: if something is used as the object of example:hasAuthor , we can infer that it's an example:Person . The second statement is a mistake; oxygen is not a person. But an RDFS reasoner would infer that data:oxygen is actually an example:Person , since it is used as the object of example:hasAuthor . Queries looking for persons would then get data:oxygen in their results, which would be incorrect. Therefore, rdfs:domain and rdfs:range are not suitable for consistency checking. DSP-API therefore uses its own properties, along with OWL cardinalities, which it interprets according to a \"closed world\" assumption. DSP-API performs its own consistency checks to enforce these restrictions. DSP-API repositories can also take advantage of triplestore-specific consistency checking mechanisms. The constraint language SHACL may someday provide a standard, triplestore-independent way to implement consistency checks, if the obstacles to its adoption can be overcome (see Diverging views of SHACL ). For further discussion of these issues, see SHACL and OWL Compared . Can a user-created property be an owl:TransitiveProperty ? No, because in DSP-API, a resource controls its properties. This basic assumption is what allows DSP-API to enforce permissions and transaction integrity. The concept of a transitive property would break this assumption. Consider a link property hasLinkToFoo that is defined as an owl:TransitiveProperty , and is used to link resource Foo1 to resource Foo2 : Suppose that Foo1 and Foo2 are owned by different users, and that the owner of Foo2 does not have permission to change Foo1 . Now suppose that the owner of Foo2 adds a link from Foo2 to Foo3 , using the transitive property: Since the property is transitive, a link from Foo1 to Foo3 is now inferred. But this should not be allowed, because the owner of Foo2 does not have permission to add a link to Foo1 . Moreover, even if the owner of Foo2 did have that permission, the inferred link would not have a knora-base:LinkValue (a reification), which every link must have. The LinkValue is what stores metadata about the creator of the link, its creation date, its permissions, and so on (see LinkValue ). Finally, if an update to a resource could modify another resource, this would violate DSP-API's model of transaction integrity, in which each transaction can modify only one resource (see Application-level Locking ). DSP-API would then be unable to ensure that concurrent transactions do not interfere with each other. General Why should I use 0.0.0.0 instead of localhost when running the DSP stack locally? When running locally with the default configuration, if you want authorization cookies to be shared between webapi and sipi , then both webapi and sipi must be accessed over 0.0.0.0 , or otherwise, the cookie will not be sent to sipi . If no authorization cookie sharing is necessary, then both 0.0.0.0 and localhost will work.","title":"Frequently Asked Questions"},{"location":"DSP-API/08-faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"DSP-API/08-faq/#file-formats","text":"","title":"File Formats"},{"location":"DSP-API/08-faq/#what-file-formats-does-knora-store","text":"See File Formats in Knora .","title":"What file formats does Knora store?"},{"location":"DSP-API/08-faq/#does-knora-store-xml-files","text":"XML files do not lend themselves to searching and linking. Knora's RDF storage is better suited to its goal of facilitating data reuse. If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF . This will allow both text and markup to be searched using Gravsearch . Knora can also regenerate, at any time, an XML document that is equivalent to the original one. If you have XML that simply represents structured data (rather than text documents), we recommend converting it to Knora resources, which are stored as RDF.","title":"Does Knora store XML files?"},{"location":"DSP-API/08-faq/#triplestores","text":"","title":"Triplestores"},{"location":"DSP-API/08-faq/#which-triplestores-can-be-used-with-dsp-api","text":"DSP-API is tested with Apache Jena Fuseki .","title":"Which triplestores can be used with DSP-API?"},{"location":"DSP-API/08-faq/#dsp-ontologies","text":"","title":"DSP Ontologies"},{"location":"DSP-API/08-faq/#can-a-project-use-classes-or-properties-defined-in-another-projects-ontology","text":"DSP-API does not allow this to be done with project-specific ontologies. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators promise not to change it in ways that could affect other ontologies or data that are based on it. See Shared Ontologies for details.","title":"Can a project use classes or properties defined in another project's ontology?"},{"location":"DSP-API/08-faq/#why-doesnt-dsp-api-use-rdfsdomain-and-rdfsrange-for-consistency-checking","text":"DSP-API's consistency checking uses specific properties, which are called knora-base:subjectClassConstraint and knora-base:objectClassConstraint in the knora-base ontology, and knora-api:subjectType and knora-api:objectType in the knora-api ontologies. These properties express restrictions on the possible subjects and objects of a property. If a property's subject or object does not conform to the specified restrictions, DSP-API considers it an error. In contrast, the RDF Schema specification says that rdfs:domain and rdfs:range can be used to \"infer additional information\" about the subjects and objects of properties, rather than to enforce restrictions. This is, in fact, what RDFS reasoners do in practice. For example, consider these statements: example:hasAuthor rdfs:range example:Person . data:book1 example:hasAuthor data:oxygen . To an RDFS reasoner, the first statement means: if something is used as the object of example:hasAuthor , we can infer that it's an example:Person . The second statement is a mistake; oxygen is not a person. But an RDFS reasoner would infer that data:oxygen is actually an example:Person , since it is used as the object of example:hasAuthor . Queries looking for persons would then get data:oxygen in their results, which would be incorrect. Therefore, rdfs:domain and rdfs:range are not suitable for consistency checking. DSP-API therefore uses its own properties, along with OWL cardinalities, which it interprets according to a \"closed world\" assumption. DSP-API performs its own consistency checks to enforce these restrictions. DSP-API repositories can also take advantage of triplestore-specific consistency checking mechanisms. The constraint language SHACL may someday provide a standard, triplestore-independent way to implement consistency checks, if the obstacles to its adoption can be overcome (see Diverging views of SHACL ). For further discussion of these issues, see SHACL and OWL Compared .","title":"Why doesn't DSP-API use rdfs:domain and rdfs:range for consistency checking?"},{"location":"DSP-API/08-faq/#can-a-user-created-property-be-an-owltransitiveproperty","text":"No, because in DSP-API, a resource controls its properties. This basic assumption is what allows DSP-API to enforce permissions and transaction integrity. The concept of a transitive property would break this assumption. Consider a link property hasLinkToFoo that is defined as an owl:TransitiveProperty , and is used to link resource Foo1 to resource Foo2 : Suppose that Foo1 and Foo2 are owned by different users, and that the owner of Foo2 does not have permission to change Foo1 . Now suppose that the owner of Foo2 adds a link from Foo2 to Foo3 , using the transitive property: Since the property is transitive, a link from Foo1 to Foo3 is now inferred. But this should not be allowed, because the owner of Foo2 does not have permission to add a link to Foo1 . Moreover, even if the owner of Foo2 did have that permission, the inferred link would not have a knora-base:LinkValue (a reification), which every link must have. The LinkValue is what stores metadata about the creator of the link, its creation date, its permissions, and so on (see LinkValue ). Finally, if an update to a resource could modify another resource, this would violate DSP-API's model of transaction integrity, in which each transaction can modify only one resource (see Application-level Locking ). DSP-API would then be unable to ensure that concurrent transactions do not interfere with each other.","title":"Can a user-created property be an owl:TransitiveProperty?"},{"location":"DSP-API/08-faq/#general","text":"","title":"General"},{"location":"DSP-API/08-faq/#why-should-i-use-0000-instead-of-localhost-when-running-the-dsp-stack-locally","text":"When running locally with the default configuration, if you want authorization cookies to be shared between webapi and sipi , then both webapi and sipi must be accessed over 0.0.0.0 , or otherwise, the cookie will not be sent to sipi . If no authorization cookie sharing is necessary, then both 0.0.0.0 and localhost will work.","title":"Why should I use 0.0.0.0 instead of localhost when running the DSP stack locally?"},{"location":"DSP-API/09-release-notes/","text":"Changelog 27.0.0 (2023-02-16) \u26a0 BREAKING CHANGES return empty list instead of an error on GET /admin/groups route (DEV-1599) ( #2439 ) Bug Fixes CORS: explicitly assign allowed CORS methods ( #2443 ) ( 99fe6fa ) fix JVM metrics and logging DEV-1639 ( #2426 ) ( 97eb0fc ) return empty list instead of an error on GET /admin/groups route (DEV-1599) ( #2439 ) ( f966f7c ) Enhancements expose GET /admin/projects/[ iri | shortname | shortcode ]/{iri | shortname | shortcode }/admin-members as ZIO HTTP route (DEV-1587) ( #2423 ) ( d7c2cd6 ) expose GET /admin/projects/[ iri | shortname | shortcode ]/{iri | shortname | shortcode }/members as ZIO HTTP route (DEV-1587) ( #2422 ) ( b5300b5 ) expose GET /admin/projects/[iri | shortname | shortcode]/{projectIri | shortname | shortcode}/RestrictedViewSettings as ZIO HTTP route (DEV-1587) ( #2428 ) ( 8080951 ) expose GET /admin/projects/iri/{projectIri}/Keywords as ZIO HTTP route (DEV-1587) ( #2425 ) ( 3b86834 ) expose GET /admin/projects/Keywords as ZIO HTTP route (DEV-1587) ( #2424 ) ( 39607a2 ) Documentation fix broken links in docs and remove unused files ( #2433 ) ( 34df59d ) replace/canset cardinality documentation (DEV-1564 & DEV-1563) ( #2420 ) ( adf1a34 ) Maintenance add 0.0.0.0 to allowed origins in config ( #2430 ) ( 9afd7a0 ) add complete in-memory triple store implementation (DEV-628) ( #2432 ) ( 708c217 ) Add more tests for the ZIO HTTP routes (DEV-1695) ( #2419 ) ( 84e2ead ) Clean-up ZIO HTTP routes and related code ( #2429 ) ( 1684718 ) cleanup remove unused shacl and redundant StringFormatter setup ( #2438 ) ( 293f6a3 ) instrumentation: expose ZIO-HTTP metrics (DEV-1714) ( #2452 ) ( a76b6f9 ) Rename ITTestDataFactory ( #2440 ) ( dc8b4b5 ) update PR template and GH release action ( #2427 ) ( 65180ef ) 26.2.0 (2023-02-02) Bug Fixes Search by label returns an Error when searching with a slash (DEV-1656) ( #2406 ) ( bb02464 ) Test file issue ( #2418 ) ( 78612e0 ) Maintenance cleanup Cache class, ie. scaladoc, renaming, code improvements ( #2411 ) ( 5efa7ac ) deps: change schedule of dependency updates check ( #2414 ) ( a5c7a38 ) deps: update scalafmt-core, kamon-core, kamon-scala-future ( #2412 ) ( a02408a ) enable publishing docker image in both arm64 and amd64 architectures (DEV-1684) ( #2410 ) ( f224b24 ) rename ReplaceCardinalitiesRequestV2, remove old code, simplify and extract methods in OntologyResponder ( #2389 ) ( 5a4f4b6 ) Replace Cardinality isStricterThan with isIncludedIn ( #2405 ) ( 229b362 ) update Scala to 2.13.10 ( #2415 ) ( d501f59 ) upgrade dependencies ( #2404 ) ( 0d78030 ) Enhancements add CORS to ZIO-HTTP routes (DEV-1619) ( #2390 ) ( 8dad4b2 ) allow setting a cardinality given the count in the persisted data is compatible DEV-1563 ( #2416 ) ( 789bdd1 ) Allow setting new Cardinalities if they are more restrictive than the respective Cardinalities of a possibly existing super class ( #2397 ) ( dbde740 ) expose GET /admin/projects/iri/{project_iri}/allData as ZIO HTTP route (DEV-1587) ( #2413 ) ( eefaf62 ) expose PUT /admin/projects/iri/{project_iri} as ZIO HTTP route (DEV-1587) ( #2394 ) ( a832868 ) 26.1.0 (2023-01-19) Bug Fixes API starts up and reports healthy despite failing to load ontologies ( #2363 ) ( 1696f7d ) Enhancements Add check for can a cardinality be set for specific class and property ( #2382 ) ( 17e7064 ) Add mimetype image/jpx as accepted ( #2378 ) ( d590e38 ) expose DELETE /admin/projects as ZIO HTTP route (DEV-1587) ( #2386 ) ( 6059012 ) expose POST /admin/projects as ZIO HTTP route (DEV-1587) ( #2376 ) ( 983bec7 ) Documentation clean up ADRs and add new one for ZIO HTTP ( #2380 ) ( 3a03733 ) Fix broken links in docs ( #2392 ) ( 85d25e3 ) Maintenance add authentication middleware ( #2370 ) ( 73a18ff ) Add tests for ZIO HTTP project routes ( #2377 ) ( 88e067b ) Cleanup and remove unused code ( #2383 ) ( 6aaf1bf ) Expose the zio-http port in docker-compose.yml for the frontend (DEV-1482) ( #2381 ) ( b11d493 ) fix manual release form branch (DEV-1519) ( #2393 ) ( 97d7399 ) Remove deprecated Cardinality model ( #2387 ) ( 3c13e3a ) Suppress compiler warnings ( #2368 ) ( 62e1193 ) switch zio http implementation from d11 to dev.zio ( #2395 ) ( 0ef6d2f ) update create-release.yml ( #2371 ) ( f97f1bd ) update year in the copyright header ( #2391 ) ( d3740f8 ) 26.0.0 (2023-01-05) \u26a0 BREAKING CHANGES return external representation of ontology IRIs in admin routes (#2330) Bug Fixes return external representation of ontology IRIs in admin routes ( #2330 ) ( b58828a ) Documentation update admin documentation ( #2328 ) ( cedb603 ) Maintenance Add BEOL exception to UUID validation (DEV-1570) ( #2349 ) ( ed34df1 ) add docker healthcheck to SIPI image (INFRA-130) ( #2359 ) ( 8554e3b ) Add dorny/test-reporter for webapi test results DEV-1544 ( #2322 ) ( 5c76338 ) add metrics endpoint (DEV-1555) ( #2331 ) ( b06f5b4 ) Add sbt-header plugin to webapi project and add missing headers ( #2317 ) ( afec4a7 ) add stack-without-app target ( #2324 ) ( 5ec3223 ) Add test report generation for integration tests (DEV-1544) ( #2325 ) ( a61f227 ) Extract common code from responders into EntityAndClassIriS\u2026 ( #2348 ) ( 238ed71 ) make it possible to debug integration tests with sbt or IDE ( #2327 ) ( 3a222bb ) refactor project route for ZIO HTTP ( #2338 ) ( e5be1db ) remove methods that gets project and members by UUID ( #2346 ) ( 2c8da6c ) remove PR2255 plugin and revert project IRIs (DEV-1571) ( #2350 ) ( 86a19ab ) remove Redis cache implementation leftovers (DEV-1503) ( #2290 ) ( a678dc5 ) Remove unused dependency to gatling ( #2361 ) ( baca8a8 ) remove unused route GET /admin/stores ( #2329 ) ( 1e11655 ) replace Spray-JSON with ZIO-JSON in health route ( #2360 ) ( 1b8e74b ) simplify health route setup ( #2337 ) ( 26e9596 ) Simplify layer setup for integration-tests and reduce to two layers ( #2339 ) ( 94836e8 ) Split long running integration tests and fast unit tests (DEV-1537) ( #2315 ) ( 5b4d601 ) update dependencies ( #2347 ) ( 560b84f ) update dependencies ( #2358 ) ( 6007266 ) upgrade Apache Jena Fuseki docker image to v2.0.11 (DEV-1299) ( #2362 ) ( c91d284 ) Enhancements Add resources/info endpoint (DEV-792) ( #2309 ) ( c3f96a9 ) expose GET /admin/projects as ZIO HTTP route ( #2366 ) ( b19f81c ) expose GET /admin/projects/[shortname | shortcode]/{shortname | shortcode} as ZIO HTTP routes ( #2365 ) ( 9907cdf ) Expose GET /admin/projects/iri/{iriUrlEncoded} as zio-http route ( #2355 ) ( 2f42906 ) 25.0.0 (2022-12-02) \u26a0 BREAKING CHANGES partOf and sequenceOf properties are not marked as isEditable (#2268) change all project IRIs to contain UUID instead of shortcode (DEV-1400) (#2255) Bug Fixes Allow warn logging for requests/responses which are failures ( #2273 ) ( 92531ce ) Ask timeouts with GetUserADM (DEV-1443) ( #2267 ) ( 3f77b6e ) Deprecation warnings for SCryptPasswordEncoder ( #2308 ) ( 86dc389 ) Don't log hashes (DEV-1442) ( #2265 ) ( adaf4b0 ) Exclude characters with special meaning in Lucene Query Parser syntax from searchbylabel search (DEV-1446) ( #2269 ) ( b359916 ) fix RepositoryUpdater that is not timing out during repository upgrade (DEV-1534) ( #2313 ) ( 213a5f0 ) Increase timeout when emptying repository (DEV-1506) ( #2289 ) ( 39771ed ) key frame extraction (DEV-1513) ( #2300 ) ( 729f071 ) partOf and sequenceOf properties are not marked as isEditable ( #2268 ) ( 68f19c3 ) Enhancements projectsADM: add possibility to get project and members by UUID (DEV-1408) ( #2272 ) ( 4b66682 ) Documentation improve permissions documentation ( #2314 ) ( f4004b2 ) publish architectural decision records ( #2301 ) ( be6bcd0 ) Remove warning which considers v2 as not production ready ( #2282 ) ( 0246522 ) Maintenance add GH workflow to publish manually from branches ( #2316 ) ( 6f5020e ) change all project IRIs to contain UUID instead of shortcode (DEV-1400) ( #2255 ) ( f2b2584 ) Decrease timeout for emptying repository (DEV-1518) ( #2310 ) ( a83000b ) Introduce ZIO HTTP (DEV-1425) ( #2256 ) ( 7ae6d24 ) make possible to run Publish GH Action manually (DEV-1519) ( #2297 ) ( bfe578a ) SIPI: add timestamp to some SIPI Lua logs ( #2311 ) ( 8f3f19f ) slight improvements to PR template ( #2312 ) ( ca3a8d0 ) update dependencies ( #2264 ) ( 41d5315 ) update dependencies ( #2281 ) ( 725bc0f ) 24.0.8 (2022-10-18) Bug Fixes User can be project admin without being project member (DEV-1383) ( #2248 ) ( c1aa8f0 ) Maintenance automatically clean sipi image files (DEV-1395) ( #2237 ) ( eddb34d ) fix project name ( #2239 ) ( 5af65eb ) update dependencies ( #2247 ) ( 2eefcbc ) 24.0.7 (2022-10-07) Bug Fixes DSP-API project IRI validation fails for BEOL project IRI ( #2240 ) ( 4b63a72 ) 24.0.6 (2022-10-06) Bug Fixes Ask timeouts when requesting projects (DEV-1386) ( #2235 ) ( 1820367 ) User can't be edited by project admin (DEV-1373) ( #2232 ) ( e0b1433 ) 24.0.5 (2022-10-05) Bug Fixes Timeout for multiple Gravsearch queries (DEV-1379) ( #2234 ) ( c63567b ) Maintenance app actor cleanup ( #2230 ) ( a67c98f ) 24.0.4 (2022-09-29) Bug Fixes API returns invalid file URLs, due to including the port ( #2223 ) ( 1a0b09c ) Value update or deletion doesn't work for properties of other ontology (DEV-1367) ( #2222 ) ( 472b375 ) 24.0.3 (2022-09-21) Maintenance application actor (DEV-956) ( #2166 ) ( 4852425 ) remove swagger route and docs annotations (DEV-1335) ( #2203 ) ( bec5b8a ) Replace Settings with AppConfig (DEV-1312) ( #2202 ) ( 9b76417 ) update dependencies ( #2214 ) ( 3706acd ) 24.0.2 (2022-09-08) Bug Fixes sipi: remove support for audio/mp4 file format (DEV-1300) ( #2195 ) ( 122bf52 ) Maintenance Adjust GitHub template (DEV-1313) ( #2183 ) ( 5782494 ) bump dependencies ( #2196 ) ( 2fbf664 ) Ignore push on certain branches from tests (DEV-1112) ( #2187 ) ( e0a0fbb ) Improve GitHub actions (DEV-1112) ( #2182 ) ( 71c772f ) Skip tests with success (DEV-1112) ( #2188 ) ( 82703d7 ) v3: add project slice (DEV-1009) ( #2076 ) ( bd2d31e ) 24.0.1 (2022-08-26) Bug Fixes cardinality: Check cardinality with multiple inherited classes (DEV-1189) ( #2164 ) ( f183d7d ) Fuseki doesn't stop after client's timeout (DEV-1190) ( #2175 ) ( 90f86b5 ) v2 test: fix test data collection ( #2174 ) ( 468df8f ) Documentation update file formats (DEV-1185) ( #2158 ) ( 4fab193 ) Maintenance add codacy coverage reporter ( #2177 ) ( c30390f ) add code coverage ( #2135 ) ( 1a02f49 ) add code coverage ( #2163 ) ( b026442 ) add coverage upload to codecov ( #2179 ) ( 5d4e57e ) feature-toggles: remove remnants of feature toggles (DEV-217) ( #2176 ) ( ed1cbd0 ) remove github action for deploying docs (DEV-824) ( #2155 ) ( a55eef4 ) update dependencies ( #2173 ) ( 79b88d2 ) 24.0.0 (2022-08-08) \u26a0 BREAKING CHANGES add isSequenceOf to knora-base ontology (DEV-745) (#2061) Bug Fixes sipi: SIPI returns 404 instead of images if cookie is invalid (DEV-1135) ( #2142 ) ( eb797f0 ) Enhancements add isSequenceOf to knora-base ontology (DEV-745) ( #2061 ) ( 74366d4 ) Maintenance dependencies: bulk upgrade dependencies ( #2144 ) ( 4602150 ) update dependencies ( 4cd9812 ) 23.0.3 (2022-08-02) Bug Fixes triplestore-connector: stack crashes on invalid search (DEV-1154) ( #2140 ) ( e5426dc ) Maintenance dependencies: update akka-http-cors to 1.1.3 ( #2103 ) ( 5d0d522 ) dependencies: update jwt-spray-json to 9.0.2 ( #2111 ) ( 6e54443 ) dependencies: update Saxon-HE to 11.4 ( #2137 ) ( 08c9f68 ) dependencies: update scalatest to 3.2.13 ( #2138 ) ( a345079 ) dependencies: update spring-security-core to 5.6.6 ( #2130 ) ( c83645d ) dependencies: update spring-security-core to 5.7.2 ( #2139 ) ( 3a12562 ) dependencies: update titanium-json-ld to 1.3.1 ( #2104 ) ( 4850525 ) 23.0.2 (2022-07-29) Bug Fixes ontology: link value property is still not editable after updating the property metadata (DEV-1116) ( #2133 ) ( d5b48db ) sipi: cookie parsing can cause an error which leads to 404 for images (DEV-1135) ( #2134 ) ( bd023a5 ) Maintenance add dependency checking ( #2100 ) ( 8017b1f ) add dependency checking ( #2102 ) ( 856277b ) Improve validation of GUI elements and GUI attributes (DEV-1082) ( #2098 ) ( 5cec8ba ) v3: add role slice (DEV-1010) ( #2099 ) ( 6920716 ) 23.0.1 (2022-07-19) Bug Fixes ontology: Don't accept list values without gui attribute (DEV-775) ( #2089 ) ( 74a14e1 ) 23.0.0 (2022-07-14) \u26a0 BREAKING CHANGES transform valueHasUri values from node to string type (DEV-1047) (#2094) Bug Fixes authentication: make cookie name unique between environments ( #2095 ) ( 7d420a4 ) ontology: existing cardinalities get duplicated in the triplestore when adding a new cardinality to a class (DEV-937) ( #2092 ) ( 9fa26db ) transform valueHasUri values from node to string type (DEV-1047) ( #2094 ) ( e1d8d95 ) 22.0.1 (2022-07-08) Bug Fixes authentication: make cookie name unique between environments ( #2091 ) ( 680021e ) value: make impossible to set list root node as a value (DEV-973) ( #2088 ) ( 94d2b46 ) Maintenance triplestore: ZIO-fying triplestore service (DSP-904) ( #2059 ) ( 9e038ec ) v3: finish user slice (DEV-671) ( #2078 ) ( 48592ad ) 22.0.0 (2022-06-30) \u26a0 BREAKING CHANGES add upgrade plugin that fixes invalid date serialisations (#2081) Bug Fixes add upgrade plugin that fixes invalid date serialisations ( #2081 ) ( 3a0902e ) ontology: link value property is not editable after editing the property metadata (DEV-1037) ( #2084 ) ( 09688f5 ) Maintenance temporarily ignore KnoraSipiIntegrationV2ITSpec ( #2085 ) ( 59f93b3 ) 21.0.1 (2022-06-23) Bug Fixes fix RepositoryUpdater by removing old way of adding plugins ( #2082 ) ( 6599b68 ) 21.0.0 (2022-06-23) \u26a0 BREAKING CHANGES fix valueHasUri bad values and missing types (DEV-1036) (#2079) Bug Fixes fix valueHasUri bad values and missing types (DEV-1036) ( #2079 ) ( de1e5a4 ) 20.4.1 (2022-06-16) Bug Fixes admin: return list labels and comments sorted by language ( #2074 ) ( f3a66cb ) Maintenance add missing client test data (DEV-979) ( #2072 ) ( 54446bc ) audio: remove not required properties ( #2070 ) ( 96362f4 ) exceptions: Create sbt project \"shared\" and move exceptions (DEV-990) ( #2075 ) ( c09392d ) move value objects to separate project (DEV-615) ( #2069 ) ( b55eb12 ) responder manager as plain case class ( #2073 ) ( 7f55697 ) user: add user project (DEV-586) ( #2063 ) ( 0c5ec03 ) 20.4.0 (2022-05-25) Bug Fixes cache: cache does not update correctly when an ontology is modified (DEV-939) ( #2068 ) ( 8541519 ) Enhancements admin: add list child node deletion route (DEV-729) ( #2064 ) ( 179ad19 ) 20.3.1 (2022-05-12) Bug Fixes authentication: Add bouncyCastle dependency (DEV-922) ( #2065 ) ( 4ac799d ) 20.3.0 (2022-05-12) Bug Fixes Problem with updating cache after deleting comments (DEV-508) ( #2060 ) ( a9fda7e ) Maintenance check that the expected Fuseki version is present (DEV-331) ( #2057 ) ( 2a695ec ) deps: bump ZIO version (DEV-893) ( #2056 ) ( 933f91e ) Enhancements add Romansh as supported language (DEV-557) ( #2053 ) ( 58971c8 ) gravsearch: improve gravsearch performance by using unions in prequery (DEV-492) ( #2045 ) ( 40354a7 ) 20.2.1 (2022-05-05) Bug Fixes projectsADM: fix cache issue in getSingleProjectADM ( #2054 ) ( 77bfadc ) Maintenance IIIFService: zio-fying iiif service (DEV-801) ( #2044 ) ( 224b664 ) 20.2.0 (2022-04-28) Bug Fixes Cleaning sipi tmp folder results in an error when there are lots of files (DEV-316) ( #2052 ) ( 33e6896 ) Enhancements error-handling: return status 504 instead of 500 for triplestore timeout exception (DEV-749) ( #2046 ) ( a47096e ) ontology: allow deleting comments of classes (DEV-804) ( #2048 ) ( eca9206 ) ontology: allow deleting comments of properties (DEV-696) ( #2042 ) ( 985c5fd ) Maintenance formatting-logging: reformat scala code and change logging policy (DEV-839) ( #2051 ) ( 5e4e914 ) formatting: reformat turtle files (DEV-430) ( #2050 ) ( 0389e52 ) triplestore: remove embedded-jena-tdb related code ( #2043 ) ( a5ea62e ) 20.1.1 (2022-04-14) Bug Fixes sipi: extract frames from video even without aspect ratio (DEV-802) ( #2041 ) ( 57d40f7 ) Documentation ingest: Add accepted file formats to documentation (DEV-677) ( #2038 ) ( f72e7a0 ) Maintenance cacheservice: use ZIO (DEV-546) ( #2022 ) ( 521150f ) triplestore: remove graphDB support ( #2037 ) ( bf17bca ) 20.1.0 (2022-04-07) Bug Fixes docs/requirements.txt to reduce vulnerabilities ( #2034 ) ( b07600d ) Maintenance distinguish between compile, runtime and test dependencies ( #2028 ) ( 7cb326f ) inventory and upgrade of dependencies (DEV-478) ( #2033 ) ( 470b77f ) Documentation replace Bazel and Intellij documentation with SBT and VSCode (DEV-607) ( #2035 ) ( 603efef ) Enhancements ontology: Add support for additional ontologies (DEV-512) ( #2029 ) ( 50e3186 ) sipi: upload video support (DEV-771 / DEV-207) ( #1952 ) ( 47f2e28 ) 20.0.0 (2022-03-31) \u26a0 BREAKING CHANGES ontology: make knora-base:lastModificationDate required property (#2018) Maintenance fix docker containers timezone ( #2027 ) ( 6bbb3fe ) Enhancements ontology: make knora-base:lastModificationDate required property ( #2018 ) ( 64cdce9 ) 19.0.0 (2022-03-24) \u26a0 BREAKING CHANGES authentication: add server specific issuer to JWT token (DEV-555) (#2024) Bug Fixes authentication: add server specific issuer to JWT token (DEV-555) ( #2024 ) ( 4bd5b2f ) version: fix displayed versions ( #2026 ) ( 566285c ) Maintenance improve logging (DEV-634) ( #2021 ) ( 85d1057 ) remove warnings (DEV-621) ( #2015 ) ( 70630f1 ) test: get tests to run in vs code (DEV-601) ( #2020 ) ( 747d13d ) 18.0.0 (2022-03-08) \u26a0 BREAKING CHANGES standoff: return XML alongside HTML for textValue with custom standoff mapping and default XSL transformation (DEV-201) (#1991) Bug Fixes Use correct docker image tag after publishing (DEV-614) ( #2016 ) ( 7649515 ) Maintenance improve code structure (DEV-612) ( #2012 ) ( eac0049 ) Enhancements standoff: return XML alongside HTML for textValue with custom standoff mapping and default XSL transformation (DEV-201) ( #1991 ) ( 2548b8f ) 17.5.3 (2022-03-04) Bug Fixes RepositoryUpdater: make sure temp directories are deleted ( #2010 ) ( 9c9a1bd ) Documentation fix permissions design documentation (DEV-495) ( #1997 ) ( 5154adc ) Maintenance fix docker image name (DEV-574) ( #2007 ) ( 7a186ba ) remove fuseki image creation and change sipi image creation to sbt (DEV-544) ( #2011 ) ( eed2767 ) start on a functional domain design implementation for ontologies (DEV-227) ( #2009 ) ( 54cee7a ) 17.5.2 (2022-02-23) Bug Fixes permissions: Update default object access permissions (DEV-514) ( #2004 ) ( 04a8d3d ) timeout: Increase timeouts (DEV-536) ( #2005 ) ( f1f8005 ) Maintenance BAZEL to SBT migration (DEV-508) ( #2002 ) ( 38faa9e ) 17.5.1 (2022-02-16) Maintenance deps: upgrade Jena Fuseki docker image to v2.0.8 ( #2001 ) ( 3e2eccc ) deps: upgrate Jena API to v4.4.0 ( #1999 ) ( 3eecc69 ) Documentation fix markdown issues in documentation (DEV-504) ( #2003 ) ( ff6b4cf ) 17.5.0 (2022-02-11) Enhancements ontologies: make comments optional for property and class creation (DEV-342) ( #1996 ) ( a3c286c ) 17.4.1 (2022-02-07) Maintenance deps: upgrade Jena to v4.3.2 (DEV-473) ( #1995 ) ( 216dcb4 ) deps: upgrade titanium-json-ld to v1.2.0 & jakarta-json to v2.0.1 (DEV-335) ( #1993 ) ( ad01bf9 ) 17.4.0 (2022-02-04) Bug Fixes version-upgrade: add upgrade plugin for ArchiveRepresentation and DeletedResource (DEV-467) ( #1992 ) ( e1566e9 ) Maintenance add support for building native API and Fuseki Docker images on Apple M1 (DEV-435) ( #1987 ) ( ab80e72 ) refactor test models (DEV-264) ( #1975 ) ( 65952f9 ) Enhancements resource: add ArchiveRepresentation to API V1 (DEV-393) (DEV-394) ( #1984 ) ( 65b88a2 ) UUID: add IRI validation that allows only to create IRIs using UUID version 4 and 5 (DEV-402) ( #1990 ) ( 74d4344 ) 17.3.1 (2022-01-28) Bug Fixes ontology: Sub-properties of link values aren't created correctly (DEV-426) ( #1985 ) ( 70a8b08 ) Maintenance deps: bump fuseki image to 2.0.7 (DEV-389) ( #1983 ) ( fcbfb1d ) license: update the license (DEV-374) ( #1981 ) ( 044fdc5 ) 17.3.0 (2022-01-17) Bug Fixes ontology: DSP-API creates wrong partOfValue property (DEV-216) ( #1978 ) ( 27b5c86 ) resource: return sensible CreationDate for DeletedResource ( #1979 ) ( 1658103 ) Enhancements resource: add support for 7z files in ArchiveRepresentation (DEV-322) ( #1977 ) ( 729689c ) Maintenance admin: refactor projects & users value objects (DEV-240) ( #1976 ) ( 563d252 ) CI: add disk cache and other cleanup (DEV-388) ( #1982 ) ( e590d12 ) 17.2.0 (2022-01-10) Bug Fixes search: Return matching sub-nodes when searching for list label (DEV-158) ( #1973 ) ( 7e8c759 ) Enhancements return a DeletedResource or DeletedValue instead of 404 if a deleted resource or value is requested (DEV-226) ( #1960 ) ( c78e252 ) 17.1.0 (2021-12-20) Enhancements listsADM: add canDeleteList route ( #1968 ) ( c276625 ) Maintenance deps: bump log4j to 2.17.0 and Fuseki to 4.3.2 (DEV-334) ( #1972 ) ( afb6587 ) 17.0.4 (2021-12-17) Bug Fixes authentication: delete cookie (in chrome) on logout (DEV-325) ( #1970 ) ( b2c9204 ) candeletecardinalities: return canDoResponse of false instead of throwing an exception for inherited cardinalities (DEV-314) ( #1966 ) ( 55b5d4b ) ontology: cardinality of one can be added to classes as long as not used in data ( #1958 ) ( 2cebac7 ) Maintenance bump logging libraries (DEV-333) ( #1969 ) ( f680c4f ) 17.0.3 (2021-12-14) Maintenance bump Fuseki (log4shell fix) (IT-4) ( #1965 ) ( 86fa251 ) projectMetadataV2: remove projectMetadataV2 implementation ( #1962 ) ( 7b95d66 ) 17.0.2 (2021-12-10) Maintenance bump db version (add shiro.ini)(DEV-302)( #1961 ) ( d147bf6 ) 17.0.1 (2021-12-06) Maintenance fix issues with fuseki (DEV-277) ( #1953 ) ( 4c1a5f1 ) Documentation Updated readme ( #1956 ) ( 774b68d ) 17.0.0 (2021-11-25) \u26a0 BREAKING CHANGES add archive representation to DSP-API (DEV-17) (#1926) Maintenance bump fuseki base container version ( #1946 ) ( cf8bdec ) bump java and sipi version (only security updates) (DEV-263) ( #1950 ) ( fe6106f ) Enhancements add archive representation to DSP-API (DEV-17) ( #1926 ) ( 0123a8f ) 16.0.1 (2021-11-22) Bug Fixes canDeleteCardinalities: canDeleteCardinalities checks too eagerly (DEV-187) ( #1941 ) ( 298ba47 ) 16.0.0 (2021-11-19) \u26a0 BREAKING CHANGES listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) Bug Fixes projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 ) Maintenance groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) release v16.0.0 ( 8e5f494 ) release v16.0.0 ( ba6923d ) 15.1.3 (2021-11-19) \u26a0 BREAKING CHANGES listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) Bug Fixes projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 ) Maintenance groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) 15.1.2 (2021-11-12) Maintenance bump bazel ( #1938 ) ( 39417e6 ) improve validation handling (DEV-228) ( #1937 ) ( 94d7d3f ) 15.1.1 (2021-11-09) Bug Fixes list: add support for special characters in list update (DEV-200) ( #1934 ) ( 3c2865c ) Maintenance init-db: init db test data from test server (DEV-198) ( #1936 ) ( 1c24bea ) 15.1.0 (2021-11-03) Bug Fixes users: fix bug adding user to group or project (DEV-184) ( #1925 ) ( a24a320 ) Enhancements add value objects to list routes - old and new (DEV-65) ( #1917 ) ( 7752a36 ) Maintenance bump sipi version (DEV-188) ( #1931 ) ( d302b5e ) change license to Apache 2.0 (DEV-82) ( #1924 ) ( 2d39a1f ) deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #1927 ) ( cbbf1b6 ) fix warnings (DEV-80) ( #1929 ) ( 1368769 ) 15.0.3 (2021-10-21) Bug Fixes list: find list labels in full-text search ( #1922 ) ( cc3b06c ) 15.0.2 (2021-10-14) Bug Fixes authenticator: improve performance ( #1914 ) ( d6a0d27 ) groups: update test data and documentation to use language specific group descriptions (DEV-123) ( #1921 ) ( 0f45b51 ) removing cardinality of a link property (DEV-90) ( #1919 ) ( c79c194 ) Maintenance groups: refactor groups route using value objects (DEV-66) ( #1913 ) ( 1cd98e6 ) knora-base: fix typo ( #1918 ) ( 720aa65 ) projects: cleaner value objects usage in addProject route (DEV-119) ( #1920 ) ( 32b9e49 ) 15.0.1 (2021-09-29) Bug Fixes candeletecardinalities: return correct response on route negative case (DEV-36) ( #1910 ) ( 652c747 ) escape-special-characters: escape special characters in user routes (DSP-1557) ( #1902 ) ( 689d92a ) Maintenance contributors: remove contributors file (DEV-77) ( #1911 ) ( 7d925b6 ) projects: refactor projects route with value objects (DEV-64) ( #1909 ) ( 172cf77 ) reformatting Scala files (DSP-1897) ( #1908 ) ( 8df70a2 ) 15.0.0 (2021-09-14) \u26a0 BREAKING CHANGES ontology: use patch instead of delete for deleting cardinalities (DSP-1700) (#1903) Documentation add username to changeable attributes (DSP-1895) ( #1904 ) ( 719cd0d ) Maintenance ontology: use patch instead of delete for deleting cardinalities (DSP-1700) ( #1903 ) ( 91ef4ec ) 14.1.0 (2021-08-19) Bug Fixes ontology V2: use internal iri when updating a property (DSP-1868) ( #1898 ) ( a746f65 ) Enhancements v2-ontologies: add remove cardinalities from class if property not used in resources (DSP-1700) ( #1869 ) ( a30668b ) 14.0.1 (2021-08-04) Bug Fixes add-test-file: add response file for test case (DSP-1841) ( #1894 ) ( 028e685 ) 14.0.0 (2021-08-02) \u26a0 BREAKING CHANGES projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) (#1886) Bug Fixes api-v2, api-admin: ontology name and project name should be URL safe (DSP-1749) ( #1889 ) ( 17601a7 ) permissions: reject malformed doap and ap create/update request (DSP-1328) ( #1890 ) ( 3e3a3ce ) Enhancements customIRIs: custom IRIs must contain a UUID (DSP-1763) ( #1884 ) ( 593d9cb ) projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) ( #1886 ) ( b3c2d5f ) resource-metadata: return resource metadata after metadata update request (DSP-1828) ( #1893 ) ( a4e878a ) video: add support for video/mp4 to both v1 and v2 (DSP-1204) ( #1891 ) ( 83fb4b8 ) 13.12.0 (2021-06-24) Enhancements resourceHistoryEvents: route for resource history events (DSP-1749) ( #1882 ) ( f86de53 ) 13.11.0 (2021-06-17) Enhancements events: update resource last modification date event ( #1877 ) ( d5e70ba ) Maintenance build: cleanup ( #1880 ) ( 749e8ea ) cache-service: add in-memory implementation ( #1870 ) ( 61531ab ) gh-ci: update docs deployment (DSP-1741) ( #1878 ) ( ff65323 ) 13.10.0 (2021-06-09) Enhancements gravsearch: use layer info for topological order permutations (DSP-1389) ( #1872 ) ( b49d5ba ) Documentation prepare documentation for docs.dasch.swiss (DSP-1721) ( #1873 ) ( 66751a0 ) 13.9.2 (2021-06-02) Maintenance sipi: add comments ( #1864 ) ( 06e8b0c ) Documentation ontology: update term ( #1865 ) ( cd37580 ) 13.9.1 (2021-05-28) Maintenance bazel: bump bazel version ( #1866 ) ( c754cbf ) 13.9.0 (2021-05-25) Enhancements api-v2: Add routes for checking whether ontology entities can be changed (DSP-1621) ( #1861 ) ( fdd098f ) 13.8.0 (2021-05-19) Bug Fixes api-v2: Update subclasses in ontology cache when base class changes (DSP-1643) ( #1860 ) ( beb951d ) gravsearch: don't move the patterns with resource IRI after topological sorting (DSP-1620) ( #1856 ) ( 6022c91 ) Maintenance documentation: bug fix in documentation deployment (DSP-1605) ( bb852c9 ) documentation: bug fix in documentation deployment (DSP-1605) ( #1854 ) ( 999a2bb ) Enhancements api-v2: Change GUI element and attribute of a property (DSP-1600) ( #1855 ) ( ce9ba3a ) api-v2: Generate IIIF manifest (DSP-50) ( #1784 ) ( 74feb2c ) conf: Rule to dump prod data and load locally (DSP-1485) ( #1857 ) ( 161ea31 ) ontology: Allow adding new property to a resource class in use (DSP-1629) ( #1859 ) ( 061875e ) 13.7.0 (2021-05-06) Bug Fixes doc: correct remaining incorrect copyright dates ( #1847 ) ( d1473ed ) gravsearch: Keep rdf:type knora-api:Resource when needed. ( #1835 ) ( e561d94 ) lists: Escape special characters in comment, label, and name of a list node (DSP-1529) ( #1846 ) ( f96c069 ) test-data: change webern shortcode in test data (DSP-1520) ( #1843 ) ( 5f06a10 ) values v1 route: fix geoname case (DSP-1487) ( #1839 ) ( 9d0e93e ) Documentation replace knora by dsp or dsp-api in documentation (DSP-1469) ( #1836 ) ( 923abe8 ) v1: improve search docs ( #1848 ) ( 5a81f73 ) Enhancements api-v2: Add route for changing GUI order of cardinalities ( #1850 ) ( d8dbb4f ) api-v2: Return events describing version history of resources and values of a project ordered by data (DSP-1528) ( #1844 ) ( 84f7c14 ) ext search v1: add support for URI values (DSP-1522) ( #1842 ) ( b119757 ) Maintenance bumb Bazel to version with apple silicon support ( #1852 ) ( 286d289 ) bump scala to 2.13 ( #1851 ) ( 5feb915 ) deps: bump versions (DSP-1569) ( #1849 ) ( f69f008 ) 13.6.0 (2021-03-16) Enhancements api-v2: Improve error message when an XSLT transformation file is not found (DSP-1404) ( #1831 ) ( 153a674 ) 13.5.1 (2021-03-11) Bug Fixes OntologiesRouteV2: Reject internal ontology names in external schema (DSP-1394) ( #1827 ) ( e392bf1 ) OntologyResponderV2: Fix check when updating ontology label and comment (DSP-1390) ( #1826 ) ( 26cce48 ) 13.5.0 (2021-03-08) Bug Fixes replaceCardinalities.scala.txt: Fix blank node insertion. ( #1829 ) ( d24c5d2 ) Maintenance gh-ci: update release please configuration (DSP-1382) ( #1825 ) ( 7ce4b65 ) Enhancements Add support for audio files (DSP-1343) ( #1818 ) ( 7497023 ) gravsearch: Optimise Gravsearch queries using topological sort (DSP-1327) ( #1813 ) ( efbecee ) store: Return 404 if the triplestore returns 404. ( #1828 ) ( 5250f6d ) 13.4.0 (2021-02-17) Bug Fixes Lists: fix bug in shifting the second of two children after deletion of the first one. ( #1820 ) ( d92bb01 ) Enhancements projects: add default set of permissions when creating new project (DSP-1347) ( #1822 ) ( b7c71ca ) 13.3.1 (2021-02-09) Bug Fixes Lists: fix bug in deleting the single child of a node (DSP-1355) ( #1816 ) ( 1d06572 ) 13.3.0 (2021-02-05) Enhancements sipi: add storing of original and sidecar (DSP-1318) ( #1808 ) ( 022ed7e ) 13.2.0 (2021-02-04) Bug Fixes api-v1: Optimise SPARQL queries. ( #1814 ) ( 4edc27c ) Lists: Repositioning the node when new position equals length of new parent's children (DSP-1322) ( #1811 ) ( 3fead13 ) Enhancements api-v1: Add support for PDF files (DSP-1267) ( #1797 ) ( c3b2e84 ) api-v2: Allow resubmitting existing class/property lablels/comments. ( #1812 ) ( 6a13852 ) Maintenance make targets for adding metadata (DSP-1289) ( #1810 ) ( 9c1a70a ) salsah1: delete from repository ( #1805 )(DSP-1294) ( 3251a74 ) 13.1.1 (2021-01-30) Maintenance gh-ci: Bring back the client-test-data command to github actions ( #1804 ) ( e6b0fbf ) revert release 13.1.0 ( #1800 ) ( 565e5ac ) 13.1.0 (2021-01-29) Bug Fixes api-v1: Optimise link value queries for Fuseki (DSP-1243) ( #1791 ) ( b1e1b9e ) api-v2: Don't allow an invalid cardinality on a boolean property (DSP-1236) ( #1788 ) ( 3d5f802 ) gravsearch: Handle UNION scopes with FILTER correctly (DSP-1240) ( #1790 ) ( 61d2e86 ) HttpTriplestoreConnector: Always parse triplestore responses as UTF-8. ( #1789 ) ( 61d2e86 ) permissions : fix getting builtin groups while creating a permission (DSP-1296 ) ( #1799 ) ( d390014 ) Maintenance gh-ci: fix issue in the release process ( #1782 ) ( afe61b7 ) ghi-ci: google chat release notification ( #1785 ) ( 4718cdc ) Enhancements permissions: add delete permissions: (DSP-1169) ( #1787 ) ( 3fe8c14 ) store: Return a clearer exception when a triplestore read timeout occurs. ( #1795 ) ( 0eeb3b3 ) 13.0.0 (2021-01-11) \u26a0 BREAKING CHANGES New features and refactoring (#1779) Bug Fixes (dependencies) add the missing dependency ( #1755 ) ( 0e37d21 ) api-v2: Change link value comment ( #1582 ) ( faa2e55 ) api-v2: Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) ( #1749 ) ( 905766f ) api-v2: Fix custom datatypes in knora-api simple ontology ( #1601 ) ( e0cfd4e ) api-v2: Fix generated SPARQL for updating property comment ( #1693 ) ( 7b70339 ) api-v2: Fix ontology deletion ( #1584 ) ( 70b0841 ) api-v2: Fix post-update check for resource with standoff link (DSP-841) ( #1728 ) ( 35d449f ) failing repository upgrade at startup (DSP-654) ( #1712 ) ( 0d6b4ee ) gravsearch: Prevent duplicate results ( #1626 ) ( 9313b88 ) gravsearch: When link property compared in filter, don't compare link value property, too ( #1699 ) ( a3b1665 ) init db scripts (DSP-511) ( #1681 ) ( d4505ce ) loading of data (DSP-445) ( #1669 ) ( 3f8d406 ) OntologyResponderV2: Add a global ontology cache lock ( #1637 ) ( 1853865 ) OntologyResponderV2: Fix ontology cache update when ontology metadata changed ( #1709 ) ( 4f57977 ) server header (DSP-537) ( #1691 ) ( 8d7bee8 ) sipi makefile ( #1616 ) ( 73a0afe ) sipi: Don't expect API v1 status code (DSP-1114) ( #1763 ) ( 3236d25 ) sipi: Improve performance of file value query ( #1697 ) ( 8214877 ) test: Fix typos in IRIs in anything-data.ttl. ( #1625 ) ( 23d51ce ) upgrade: Fix log output. ( #1774 ) ( b43fab0 ) webapi: unique username/email check on change user ( #1561 ) ( 4f26e22 ) rdf-api : Use the Jena RDF API implementation by default (DSP-1153) ( 1772 ) ( 389feb4 ) Documentation api-v2: Document what happens when a resource has a link to a deleted resource ( #1685 ) ( 1c88651 ) fix broken links ( #1688 ) ( 9c0292c ) fix make targets docker-build and docker-publish ( #1694 ) ( d06b6a6 ) Update README (DSP-1142) ( #1771 ) ( 7ba7fc6 ) Update required mkdocs package ( #1725 ) ( 27de65e ) Maintenance api-v2: Delete obsolete files. ( #1634 ) ( e80bf52 ) api-v2: Switch from JSONLD-Java to Titanium ( #1715 ) ( 9e28e5b ) build: Bump testcontainers version. ( #1723 ) ( 24ae1d3 ) build: Update ScalaTest (DSP-919) ( #1745 ) ( bbaeadd ) build: Upgrade Sipi to 3.0.0-rc.8 (DSP-916) ( #1743 ) ( 23395fc ) bump sipi to rc.7 (DSP-733) ( #1721 ) ( b635495 ) gh-ci: Fix gren issue ( #1666 ) ( 2dc5361 ) gh-ci: Publish on release only ( #1662 ) ( 787dca8 ) rdf-api: Use the Jena RDF API implementation by default (DSP-1153) ( #1772 ) ( 389feb4 ) Remove obsolete functions from StringFormatter. ( #1640 ) ( 5fa6de4 ) Update ci workflow release notes ( #1707 ) ( d8e0b39 ) gh-ci CI is failing to test upgrade correctly (DSP-667) ( #1073 ) ( 13cbdab ) bazel Update Bazel maven rules to see if it fixes problems with macOS Big Sur (DSP-1099) ( #1761 ) ( a2c9941 ) Enhancements Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) ( #1759 ) ( 346873d ) Add feature toggles (DSP-910) ( #1742 ) ( 2e6db2e ) Add time value type ( #1403 ) ( d925c85 ) api-v1: Change API v1 file uploads to work like API v2 (DSP-41, PR 3) ( #1722 ) ( a824bcc ) api-v2: Accept custom new value IRI when updating value ( #1698 ) ( 4d8f867 ) api-v2: Accept custom timestamps in update/delete requests ( #1686 ) ( 0fbe5a8 ) api-v2: Add an RDF processing fa\u00e7ade (DSP-1020) ( #1754 ) ( 9170419 ) api-v2: Add metadata routes (DSP-662) ( #1734 ) ( bf48968 ) api-v2: Add support for text file upload (DSP-44) ( #1664 ) ( a88d20d ) api-v2: Add test data. ( #1704 ) ( de14ab1 ) api-v2: Allow querying for rdfs:label in Gravsearch ( #1649 ) ( d56004b ) api-v2: Control JSON-LD nesting via an HTTP header (DSP-1084) ( #1758 ) ( b13eecf ) api-v2: Make inference optional in Gravsearch ( #1696 ) ( 166a260 ) api-v2: Optionally return file values in full-text search results (DSP-1191) ( #1776 ) ( 01f59bd ) api-v2: Remove client code generation ( #1610 ) ( 6977ab3 ) api-v2: Remove ForbiddenResource ( #1615 ) ( 992596e ) api-v2: Return value UUID on value creation and update ( #1602 ) ( cbed601 ) api-v2: Specify custom IRIs when creating resources/values ( #1646 ) ( 135b039 ) clientapi: Change method signature. ( #1583 ) ( c2a2559 ) gh-ci: Release please and update gh actions (DSP-1168) ( #1777 ) ( 593ffab ) gravsearch: Allow comparing variables representing resource IRIs ( #1713 ) ( f359c8e ) gravsearch: Remove deprecated functions ( #1660 ) ( 5d3af46 ) New features and refactoring ( #1779 ) ( 9a5fb77 ) rdf-api: Add a general-purpose SHACL validation utility (DSP-930) ( #1762 ) ( bfd3192 ) sipi: Improve error message if XSL file not found ( #1590 ) ( bbb42f6 ) triplestores: Support Apache Jena Fuseki ( #1375 ) ( 82f8a55 ) upgrade: Update repository on startup ( #1643 ) ( 0127dca ) v13.0.0-rc.25 (08/12/2020) Enhancements #1768 | DSP-1106 Update Permission #1767 | enhancement(triplestore): Use N-Quads instead of TriG for repository upgrade (DSP-1129) #1764 | DSP-1033 Reposition List Nodes #1762 | feat(rdf-api): Add a general-purpose SHACL validation utility (DSP-930) #1759 | feat: Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) #1760 | (DSP-1031) Delete list items #1753 | Edit lists routes (DSP-597 ) #1758 | feat(api-v2): Control JSON-LD nesting via an HTTP header (DSP-1084) Bug fixes #1763 | fix(sipi): Don't expect API v1 status code (DSP-1114) Documentation #1771 | docs: Update README (DSP-1142) Maintenance #1770 | refactor: Use java.nio.file.Path instead of java.io.File (DSP-1124) #1765 | DSP-1094 Upgrade Swagger version #1766 | style: Add Scalafmt config file #1769 | style: Reformat code with Scalafmt (DSP-1137) #1754 | feat(api-v2): Add an RDF processing fa\u00e7ade (DSP-1020) #1757 | build: bazel workspace cleanup v13.0.0-rc.24 (13/11/2020) #1756 | DSP-1052 : Migration task to replace empty strings with dummy \"FIXME\" v13.0.0-rc.23 (09/11/2020) Bug fixes #1755 | DSP-1029: Add the missing dependency v13.0.0-rc.22 (09/11/2020) Breaking changes #1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions Enhancements #1403 | feat: Add time value type #1537 | build: Add env var to set triplestore actor pool #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30) Bug Fixes #1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1576 | Add missing env var #1571 | fixed date string format #1564 | enable click on save button in case of recoverable error #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445) Documentation #1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering Other #1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes Dependencies #1721 | chore: bump sipi to rc.7 (DSP-733) #1735 | DSP-496 Bump Apache Jena Fuseki and Apache Jena Libraries to 3.16 #1737 | DSP-842 Bump used Bazel version to newly released 3.7.0 #1743 | chore(build): Upgrade Sipi to 3.0.0-rc.8 (DSP-916) #1745 | chore(build): Update ScalaTest (DSP-919) #1752 | DSP-1017 Upgrade to Sipi v3.0.0-rc.9 v13.0.0-rc.21 (09/11/2020) Breaking changes #1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions Enhancements #1403 | feat: Add time value type #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30) Bug Fixes #1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445) Documentation #1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering Other #1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes v12.0.0 (27/01/2020) Breaking API Changes #1439 JSON-LD Serialization of an xsd:dateTimeStamp New Features and Enhancements #1509 Support lists admin endpoint #1466 Optimise generated SPARQL Bug Fixes #1569 broken ark #1559 Admin lists: createChildNode should send a httpPost request, not httpPut v11.0.0 (16/12/2019) Breaking Changes #1344 Gravsearch ForbiddenResource result and permissions of linked resources #1202 Implement upload of PDF and text files in API v2. Users with files in Sipi under /server must move them to /images when upgrading. Bug Fixes #1531 Sipi's mimetype_consistency fails with .bin file #1430 Creating the first resource with an image inside a project fails with Sipi not finding the project folder #924 Get dependent resources Iris v10.1.1 (27/11/2019) v10.1.0 (27/11/2019) v10.0.0 (22/10/2019) Breaking Changes #1346 Richtext/HTML in page anchor link Enhancements #1457 Upgrade sipi to 2.0.1 Bug Fixes #1460 Build banner in README is broken Documentation #1481 build badge in README has broken link Other #1449 Add Makefile-based task execution #1401 Enable testing docs generation in Travis v9.1.0 (26/09/2019) Enhancements #1421 Physically deleting a resource Documentation #1407 Document ARK URLs for projects v9.0.0 (29/08/2019) Breaking Changes #1411 Moved /admin/groups/members/GROUP_IRI to /admin/groups/GROUP_IRI/members #1231 Change value permissions #763 refactor splitMainResourcesAndValueRdfData so it uses SparqlExtendedConstructResponse Enhancements #1373 The startup ends in a thrown exception if the triplestore is not up-to-date #1364 Add support for Redis cache #1360 Build and publish Knora version specific docker images for GraphDB Free and SE #1358 Add admin route to dump project data Bug Fixes #1394 Using dockerComposeUp to start the stack, fails to find Redis at startup Documentation #1386 Add lists admin API documentation Other #1412 Change release notes to be based on issues v8.0.0 (14/06/2019) feature(webapi): Add GraphDB-Free startup support (#1351) - @subotic feature(webapi): Add returning of fixed public user information (#1348) - @subotic feat(api-v2): No custom permissions higher than defaults (#1337) - @benjamingeer feat(upgrade): Improve upgrade framework (#1345) - @benjamingeer test(webapi): Add new user authentication (#1201) - @subotic chore(webapi): Add request duration logging (#1347) - @subotic feat(api-v2): Make values citable (#1322) - @benjamingeer Leibniz ontology (#1326) - @SepidehAlassi feature(webapi): add CORS allow header (#1340) - @subotic fix(sipi): Return permissions for a previous version of a file value. (#1339) - @benjamingeer fix(scripts): add admin ontology data to correct graph (#1333) - @subotic fix(sipi): Don't try to read a file value in a deleted resource. (#1329) - @benjamingeer docs(api-v2): Fix sample responses. (#1327) - @benjamingeer fix(api-v2): Fix typo. (#1325) - @benjamingeer Handle List Nodes in Response (#1321) - @tobiasschweizer feat(api-v2): Return standoff markup separately from text values (#1307) - @benjamingeer BEOL: Import comments for Meditationes (#1281) - @tobiasschweizer feat(triplestore): Log SPARQL query if triplestore doesn't respond. (#1292) - @benjamingeer Support list nodes in Gravsearch (#1314) - @tobiasschweizer v7.0.0 (03/05/2019) fix(api-v2): Cache base class IRIs correctly when creating/updating class (#1311) - @benjamingeer chore(standoff): Use Base64-encoded UUIDs in standoff tags. (#1301) - @benjamingeer feat(api-v2): Allow a resource to be created as a specified user (#1306) - @benjamingeer feat(admin): Give the admin ontology an external schema (#1291) - @benjamingeer fix(api-v2): Remove INFORMATION SEPARATOR TWO from text in the simple schema. (#1299) - @benjamingeer test: Compare Knora response with its class definition (#1297) - @benjamingeer docs(api-admin): fix description of the change password payload (#1285) - @loicjaouen fix(api-v1): Fix double escaping of newline. (#1296) - @benjamingeer fix (tei beol): fix problems in XSLT (#1260) - @tobiasschweizer refactor(ontology): Make knora-admin a separate ontology (#1263) - @benjamingeer a handfull of changes in documentation and error messages (#1278) - @loicjaouen docs: fix missing username (#1269) - @loicjaouen feat(api-v2): Get resources in a particular class from a project (#1251) - @benjamingeer fix(sipi): Improve error checking of Sipi's knora.json response. (#1279) - @benjamingeer feat(api-v2): Return user's permission on resources and values (#1257) - @benjamingeer fix(api-v1): Escape rdfs:label in bulk import. (#1276) - @benjamingeer chore(webapi): Remove persistent map code (#1254) - @benjamingeer docs (api-v2): Update outdated ARK documentation. (#1252) - @benjamingeer Update build.properties (#1265) - @subotic v6.0.1 (22/03/2019) chore: releasing-v6.0.1 (#1270) - @subotic chore(webapi): Add script for loading of a minimal set of data (#1267) - @subotic fix (beolPersonLabel) typo in label of hasBirthPlace (#1248) - @SepidehAlassi fix (webapi): message typo (#1244) - @subotic Unescape standoff string attributes when verifying text value update (#1242) - @benjamingeer docs: fix user admin api (#1237) - @subotic v6.0.0 (28/02/2019) Release Notes MAJOR: Use HTTP POST to mark resources and values as deleted (#1203) MAJOR: Reorganize user and project routes (#1209) FEATURE: Secure routes returning user information (#961) MAJOR: Change all xsd:dateTimeStamp to xsd:dateTime in the triplestore (#1211). Existing data must be updated; see upgrade/1211-datetime for instructions. FIX: Ignore order of attributes when comparing standoff (#1224). FEATURE: Query version history (#1214) FIX: Don't allow conflicting cardinalities (#1229) MAJOR: Remove preview file values (#1230). Existing data must be updated; see upgrade/1230-delete-previews for instructions. v5.0.0 (05/02/2019) Release Notes MAJOR: Fix property names for incoming links (#1144)) MAJOR: Generate and resolve ARK URLs for resources (#1161). Projects that have resource IRIs that do not conform to the format specified in https://docs.knora.org/paradox/03-endpoints/api-v2/knora-iris.html#iris-for-data must update them. MAJOR: Use project shortcode in IIIF URLs (#1191). If you have file value IRIs containing the substring /reps/ , you must replace /reps/ with /values/ . FEATURE: Update resource metadata in API v2 (#1131) FEATURE: Allow setting resource creation date in bulk import #1151) FEATURE: The v2/authentication route now also initiates cookie creation (the same as v1/authentication ) (#1159) FEATURE: Allow to specify restricted view settings for a project which Sipi will adhere to (#690). FIX: Triplestore connection error when using dockerComposeUp (#1122) FIX: Reject link value properties in Gravsearch queries in the simple schema (#1145) FIX: Fix error-checking when updating cardinalities in ontology API (#1142) FIX: Allow hasRepresentation in an ontology used in a bulk import (#1171) FIX: Set cookie domain to the value specified in application.conf with the setting cookie-domain (#1169) FIX: Fix processing of shared property in bulk import (#1182) v4.0.0 (12/12/2018) v4.0.0 Release Notes MAJOR CHANGE: mapping creation request and response formats have changed (#1094) MINOR CHANGE: Update technical user docs (#1085) BUGFIX CHANGE: Fix permission checking in API v2 resource creation (#1104) v3.0.0 (30/11/2018) v3.0.0 Release Notes [BREAKING ONTOLOGY CHANGE] The property knora-base:username was added and is required for knora-base:User . (#1047) [BREAKING API CHANGE] The /admin/user API has changed due to adding the username property. (#1047) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Add default permission caching (#1062) [FIX] Fix unescaping in update check and reading standoff URL (#1074) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Create image file values in API v2 (#1011). Requires Sipi with tagged commit v1.4.1-SNAPSHOT or later. v2.1.0 (02/11/2018) New features Implement graph query in API v2 (#1009) Expose additional webapi settings as environment variables. Please see the Configuration section in the documentation for more information (#1025) Bugfixes sipi container config / sipi not able to talk to knora (#994) v2.1.0-snapshot (22/10/2018) v2.0.0 (13/09/2018) This is the first release with the new version numbering convention. From now on, if any changes to the existing data are necessary for a release, then this release will have its major number increased. Please see the Release Versioning Convention description. Required changes to existing data a knora-base:ListNode must have at least one rdfs:label . (@github #991 ) New features add developer-centric docker-compose.yml for starting the Knora / GraphDB / Sipi / Salsah1 (@github #979 ) configure webapi and salsah1 thorough environment variables (@github #979 ) update for Java 10 (@github #979 ) comment out the generation of fat jars from KnoraBuild.sbt (for now) (@github #979 ) update ehcache (@github #979 ) update sbt to 1.2.1 (@github #979 ) remove Kamon monitoring (for now) since we don't see anything meaningful there. We probably will have to instrument Knora by hand and then use Kamon for access. (@github #979 ) update Dockerfiles for webapi and salsah1 (@github #979 ) follow subClassOf when including ontologies in XML import schemas (@github #991 ) add support for adding list child nodes (@github #991 ) add support for shared ontologies (@github #987 ) Bugfixes trouble with xml-checker and/or consistency-checker during bulk import (@github #978 ) ontology API error with link values (@github #988 ) v1.7.1 (29/08/2018) Knora-Stack compatible versions Knora v1.7.1 - Salsah v2.1.2 - Sipi v1.4.0 - GraphDB v8.5.0 doc (webapi): add yourkit acknowledgment (#983) Don't allow class with cardinalities on P and on a subproperty of P (#982) doc (webapi): add LHTT project shortcode (#981) feature (webapi): not return or allow changing of built-in users (#975) fix (webapi): startup check does not detect running triplestore (#969) Fix bulk import parsing bug and limit concurrent client connections (#973) v1.7.0 (16/08/2018) See the closed tickets on the v1.7.0 milestone . Knora-Stack compatible versions Knora v1.7.0 - Salsah v2.1.0 - Sipi v1.4.0 - GraphDB v8.5.0 Required changes to existing data To use the inferred Gravsearch predicate knora-api:standoffTagHasStartAncestor , you must recreate your repository with the updated KnoraRules.pie . New features Gravsearch queries can now match standoff markup (#910). Add Graphdb-Free initialization scripts for local and docker installation (#955). Create temp dirs at startup (#951) Update versions of monitoring tools (#951) Bugfixes timeout or java.lang.OutOfMemoryError when using /v1/resources/xmlimportschemas/ for some ontologies (#944) Timeout cleanup (#951) Add separate dispatchers (#945) v1.6.0 (29/06/2018) v1.6.0 Release Notes See the release and closed tickets on the v1.6.0 milestone on Github. Required changes to existing data A project is now required to have at least one description, so potentially a description will need to be added to those projects that don't have one. New features General: Added a /health endpoint KnoraService waits on startup for a triplestore before trying to load the ontologies Gravsearch enhancements: Accept queries in POST requests (@github #650 ). Allow a Gravsearch query to specify the IRI of the main resource (@github #871 ) (by allowing BIND ). Allow lang to be used with != . A UNION or OPTIONAL can now be nested in an OPTIONAL (@github #882 ). Gravsearch now does type inference (@github #884 ). The Knora API v2 complex schema can now be used in Gravsearch, making it possible to search for list nodes (@github #899 ). Admin API: Make project description required (@github #875 ). Conversion to TEI: Conversion of standard standoff entities to TEI Custom conversion of project specific standoff entities and metadata to TEI Sipi integration: The Knora specific Sipi configuration and scripts can now be found under the sipi/ directory (@github #404 ). Documentation on how Sipi can be started changed (@github #404 ). Bugfixes Allow a class or property definition to have more than one object for rdf:type (@github #885 ). Exclude list values from v2 fulltext search (@github #906 ). Gravsearch fixes: Allow the lang function to be used in a comparison inside AND/OR (@github #846 ). Fix the processing of resources with multiple incoming links that use the same property (@github #878 ). Fix the parsing of a FILTER inside an OPTIONAL (@github #879 ). Require the match function to be the top-level expression in a FILTER . v1.5.0 (31/05/2018) See v1.5.0 milestone for a full list of closed tickets. New features Resources can be returned in the simple ontology schema (#833). Text values can specify the language of the text (#819). Responses can be returned in Turtle and RDF/XML (#851). Bugfixes Incorrect representation of IRI object values in JSON-LD (#835) GenerateContributorsFile broken (#797) v1.4.0 (30/04/2018) Required changes to existing data Every ontology must now have the property knora-base:attachedToProject , which points to the IRI of the project that is responsible for the ontology. This must be added to each project-specific ontology in existing repositories. All built-in ontologies have been updated to have this property, and must, therefore, be reloaded into existing repositories. The property knora-base:projectOntology has been removed, and must be removed from project definitions in existing repositories. Every project now needs to have the property knora-base:projectShortcode set. New features Added OpenAPI / Swagger API documentation route The Knora API server now checks the validity of ontologies on startup. The property knora-base:projectShortcode is now a required property (was optional). Bugfixes API v1 extended search was not properly handling multiple conditions on list values (issue #800) Fix image orientation in SALSAH 1 (issue #726) v1.3.1 (06/04/2018) v1.3.0 (28/03/2018) Required changes to existing data 1. Replace salsah-gui ontology You must replace the salsah-gui ontology that you have in the triplestore with the one in salsah-gui.ttl . New features More support for salsah-gui elements and attributes in ontologies Serve the salsah-gui ontology in API v2 in the default schema. Show salsah-gui:guiElement and salsah-gui:guiAttribute when serving ontologies in API v2 in the default schema. Allow salsah-gui:guiElement and salsah-gui:guiAttribute to be included in new property definitions created via API v2. Change salsah-gui so that GraphDB's consistency checker can check the use of guiElement and guiAttribute . Changes to application.conf . The sipi and web-api sections have received a big update, adding separate settings for internal and external host settings: app { knora-api { // relevant for direct communication inside the knora stack internal-host = \"0.0.0.0\" internal-port = 3333 // relevant for the client, i.e. browser external-protocol = \"http\" // optional ssl termination needs to be done by the proxy external-host = \"0.0.0.0\" external-port = 3333 } sipi { // relevant for direct communication inside the knora stack internal-protocol = \"http\" internal-host = \"localhost\" internal-port = 1024 // relevant for the client, i.e. browser external-protocol = \"http\" external-host = \"localhost\" external-port = 1024 prefix = \"knora\" file-server-path = \"server\" path-conversion-route = \"convert_from_binaries\" file-conversion-route = \"convert_from_file\" image-mime-types = [\"image/tiff\", \"image/jpeg\", \"image/png\", \"image/jp2\"] movie-mime-types = [] sound-mime-types = [] } salsah1 { base-url = \"http://localhost:3335/\" project-icons-basepath = \"project-icons/\" } } Bugfixes When API v2 served knora-api (default schema), salsah-gui:guiElement and salsah-gui:guiAttribute were not shown in properties in that ontology. The predicate salsah-gui:guiOrder was not accepted when creating a property via API v2.","title":"Changelog"},{"location":"DSP-API/09-release-notes/#changelog","text":"","title":"Changelog"},{"location":"DSP-API/09-release-notes/#2700-2023-02-16","text":"","title":"27.0.0 (2023-02-16)"},{"location":"DSP-API/09-release-notes/#breaking-changes","text":"return empty list instead of an error on GET /admin/groups route (DEV-1599) ( #2439 )","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes","text":"CORS: explicitly assign allowed CORS methods ( #2443 ) ( 99fe6fa ) fix JVM metrics and logging DEV-1639 ( #2426 ) ( 97eb0fc ) return empty list instead of an error on GET /admin/groups route (DEV-1599) ( #2439 ) ( f966f7c )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements","text":"expose GET /admin/projects/[ iri | shortname | shortcode ]/{iri | shortname | shortcode }/admin-members as ZIO HTTP route (DEV-1587) ( #2423 ) ( d7c2cd6 ) expose GET /admin/projects/[ iri | shortname | shortcode ]/{iri | shortname | shortcode }/members as ZIO HTTP route (DEV-1587) ( #2422 ) ( b5300b5 ) expose GET /admin/projects/[iri | shortname | shortcode]/{projectIri | shortname | shortcode}/RestrictedViewSettings as ZIO HTTP route (DEV-1587) ( #2428 ) ( 8080951 ) expose GET /admin/projects/iri/{projectIri}/Keywords as ZIO HTTP route (DEV-1587) ( #2425 ) ( 3b86834 ) expose GET /admin/projects/Keywords as ZIO HTTP route (DEV-1587) ( #2424 ) ( 39607a2 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#documentation","text":"fix broken links in docs and remove unused files ( #2433 ) ( 34df59d ) replace/canset cardinality documentation (DEV-1564 & DEV-1563) ( #2420 ) ( adf1a34 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance","text":"add 0.0.0.0 to allowed origins in config ( #2430 ) ( 9afd7a0 ) add complete in-memory triple store implementation (DEV-628) ( #2432 ) ( 708c217 ) Add more tests for the ZIO HTTP routes (DEV-1695) ( #2419 ) ( 84e2ead ) Clean-up ZIO HTTP routes and related code ( #2429 ) ( 1684718 ) cleanup remove unused shacl and redundant StringFormatter setup ( #2438 ) ( 293f6a3 ) instrumentation: expose ZIO-HTTP metrics (DEV-1714) ( #2452 ) ( a76b6f9 ) Rename ITTestDataFactory ( #2440 ) ( dc8b4b5 ) update PR template and GH release action ( #2427 ) ( 65180ef )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2620-2023-02-02","text":"","title":"26.2.0 (2023-02-02)"},{"location":"DSP-API/09-release-notes/#bug-fixes_1","text":"Search by label returns an Error when searching with a slash (DEV-1656) ( #2406 ) ( bb02464 ) Test file issue ( #2418 ) ( 78612e0 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_1","text":"cleanup Cache class, ie. scaladoc, renaming, code improvements ( #2411 ) ( 5efa7ac ) deps: change schedule of dependency updates check ( #2414 ) ( a5c7a38 ) deps: update scalafmt-core, kamon-core, kamon-scala-future ( #2412 ) ( a02408a ) enable publishing docker image in both arm64 and amd64 architectures (DEV-1684) ( #2410 ) ( f224b24 ) rename ReplaceCardinalitiesRequestV2, remove old code, simplify and extract methods in OntologyResponder ( #2389 ) ( 5a4f4b6 ) Replace Cardinality isStricterThan with isIncludedIn ( #2405 ) ( 229b362 ) update Scala to 2.13.10 ( #2415 ) ( d501f59 ) upgrade dependencies ( #2404 ) ( 0d78030 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_1","text":"add CORS to ZIO-HTTP routes (DEV-1619) ( #2390 ) ( 8dad4b2 ) allow setting a cardinality given the count in the persisted data is compatible DEV-1563 ( #2416 ) ( 789bdd1 ) Allow setting new Cardinalities if they are more restrictive than the respective Cardinalities of a possibly existing super class ( #2397 ) ( dbde740 ) expose GET /admin/projects/iri/{project_iri}/allData as ZIO HTTP route (DEV-1587) ( #2413 ) ( eefaf62 ) expose PUT /admin/projects/iri/{project_iri} as ZIO HTTP route (DEV-1587) ( #2394 ) ( a832868 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#2610-2023-01-19","text":"","title":"26.1.0 (2023-01-19)"},{"location":"DSP-API/09-release-notes/#bug-fixes_2","text":"API starts up and reports healthy despite failing to load ontologies ( #2363 ) ( 1696f7d )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_2","text":"Add check for can a cardinality be set for specific class and property ( #2382 ) ( 17e7064 ) Add mimetype image/jpx as accepted ( #2378 ) ( d590e38 ) expose DELETE /admin/projects as ZIO HTTP route (DEV-1587) ( #2386 ) ( 6059012 ) expose POST /admin/projects as ZIO HTTP route (DEV-1587) ( #2376 ) ( 983bec7 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#documentation_1","text":"clean up ADRs and add new one for ZIO HTTP ( #2380 ) ( 3a03733 ) Fix broken links in docs ( #2392 ) ( 85d25e3 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_2","text":"add authentication middleware ( #2370 ) ( 73a18ff ) Add tests for ZIO HTTP project routes ( #2377 ) ( 88e067b ) Cleanup and remove unused code ( #2383 ) ( 6aaf1bf ) Expose the zio-http port in docker-compose.yml for the frontend (DEV-1482) ( #2381 ) ( b11d493 ) fix manual release form branch (DEV-1519) ( #2393 ) ( 97d7399 ) Remove deprecated Cardinality model ( #2387 ) ( 3c13e3a ) Suppress compiler warnings ( #2368 ) ( 62e1193 ) switch zio http implementation from d11 to dev.zio ( #2395 ) ( 0ef6d2f ) update create-release.yml ( #2371 ) ( f97f1bd ) update year in the copyright header ( #2391 ) ( d3740f8 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2600-2023-01-05","text":"","title":"26.0.0 (2023-01-05)"},{"location":"DSP-API/09-release-notes/#breaking-changes_1","text":"return external representation of ontology IRIs in admin routes (#2330)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_3","text":"return external representation of ontology IRIs in admin routes ( #2330 ) ( b58828a )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_2","text":"update admin documentation ( #2328 ) ( cedb603 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_3","text":"Add BEOL exception to UUID validation (DEV-1570) ( #2349 ) ( ed34df1 ) add docker healthcheck to SIPI image (INFRA-130) ( #2359 ) ( 8554e3b ) Add dorny/test-reporter for webapi test results DEV-1544 ( #2322 ) ( 5c76338 ) add metrics endpoint (DEV-1555) ( #2331 ) ( b06f5b4 ) Add sbt-header plugin to webapi project and add missing headers ( #2317 ) ( afec4a7 ) add stack-without-app target ( #2324 ) ( 5ec3223 ) Add test report generation for integration tests (DEV-1544) ( #2325 ) ( a61f227 ) Extract common code from responders into EntityAndClassIriS\u2026 ( #2348 ) ( 238ed71 ) make it possible to debug integration tests with sbt or IDE ( #2327 ) ( 3a222bb ) refactor project route for ZIO HTTP ( #2338 ) ( e5be1db ) remove methods that gets project and members by UUID ( #2346 ) ( 2c8da6c ) remove PR2255 plugin and revert project IRIs (DEV-1571) ( #2350 ) ( 86a19ab ) remove Redis cache implementation leftovers (DEV-1503) ( #2290 ) ( a678dc5 ) Remove unused dependency to gatling ( #2361 ) ( baca8a8 ) remove unused route GET /admin/stores ( #2329 ) ( 1e11655 ) replace Spray-JSON with ZIO-JSON in health route ( #2360 ) ( 1b8e74b ) simplify health route setup ( #2337 ) ( 26e9596 ) Simplify layer setup for integration-tests and reduce to two layers ( #2339 ) ( 94836e8 ) Split long running integration tests and fast unit tests (DEV-1537) ( #2315 ) ( 5b4d601 ) update dependencies ( #2347 ) ( 560b84f ) update dependencies ( #2358 ) ( 6007266 ) upgrade Apache Jena Fuseki docker image to v2.0.11 (DEV-1299) ( #2362 ) ( c91d284 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_3","text":"Add resources/info endpoint (DEV-792) ( #2309 ) ( c3f96a9 ) expose GET /admin/projects as ZIO HTTP route ( #2366 ) ( b19f81c ) expose GET /admin/projects/[shortname | shortcode]/{shortname | shortcode} as ZIO HTTP routes ( #2365 ) ( 9907cdf ) Expose GET /admin/projects/iri/{iriUrlEncoded} as zio-http route ( #2355 ) ( 2f42906 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#2500-2022-12-02","text":"","title":"25.0.0 (2022-12-02)"},{"location":"DSP-API/09-release-notes/#breaking-changes_2","text":"partOf and sequenceOf properties are not marked as isEditable (#2268) change all project IRIs to contain UUID instead of shortcode (DEV-1400) (#2255)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_4","text":"Allow warn logging for requests/responses which are failures ( #2273 ) ( 92531ce ) Ask timeouts with GetUserADM (DEV-1443) ( #2267 ) ( 3f77b6e ) Deprecation warnings for SCryptPasswordEncoder ( #2308 ) ( 86dc389 ) Don't log hashes (DEV-1442) ( #2265 ) ( adaf4b0 ) Exclude characters with special meaning in Lucene Query Parser syntax from searchbylabel search (DEV-1446) ( #2269 ) ( b359916 ) fix RepositoryUpdater that is not timing out during repository upgrade (DEV-1534) ( #2313 ) ( 213a5f0 ) Increase timeout when emptying repository (DEV-1506) ( #2289 ) ( 39771ed ) key frame extraction (DEV-1513) ( #2300 ) ( 729f071 ) partOf and sequenceOf properties are not marked as isEditable ( #2268 ) ( 68f19c3 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_4","text":"projectsADM: add possibility to get project and members by UUID (DEV-1408) ( #2272 ) ( 4b66682 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#documentation_3","text":"improve permissions documentation ( #2314 ) ( f4004b2 ) publish architectural decision records ( #2301 ) ( be6bcd0 ) Remove warning which considers v2 as not production ready ( #2282 ) ( 0246522 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_4","text":"add GH workflow to publish manually from branches ( #2316 ) ( 6f5020e ) change all project IRIs to contain UUID instead of shortcode (DEV-1400) ( #2255 ) ( f2b2584 ) Decrease timeout for emptying repository (DEV-1518) ( #2310 ) ( a83000b ) Introduce ZIO HTTP (DEV-1425) ( #2256 ) ( 7ae6d24 ) make possible to run Publish GH Action manually (DEV-1519) ( #2297 ) ( bfe578a ) SIPI: add timestamp to some SIPI Lua logs ( #2311 ) ( 8f3f19f ) slight improvements to PR template ( #2312 ) ( ca3a8d0 ) update dependencies ( #2264 ) ( 41d5315 ) update dependencies ( #2281 ) ( 725bc0f )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2408-2022-10-18","text":"","title":"24.0.8 (2022-10-18)"},{"location":"DSP-API/09-release-notes/#bug-fixes_5","text":"User can be project admin without being project member (DEV-1383) ( #2248 ) ( c1aa8f0 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_5","text":"automatically clean sipi image files (DEV-1395) ( #2237 ) ( eddb34d ) fix project name ( #2239 ) ( 5af65eb ) update dependencies ( #2247 ) ( 2eefcbc )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2407-2022-10-07","text":"","title":"24.0.7 (2022-10-07)"},{"location":"DSP-API/09-release-notes/#bug-fixes_6","text":"DSP-API project IRI validation fails for BEOL project IRI ( #2240 ) ( 4b63a72 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#2406-2022-10-06","text":"","title":"24.0.6 (2022-10-06)"},{"location":"DSP-API/09-release-notes/#bug-fixes_7","text":"Ask timeouts when requesting projects (DEV-1386) ( #2235 ) ( 1820367 ) User can't be edited by project admin (DEV-1373) ( #2232 ) ( e0b1433 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#2405-2022-10-05","text":"","title":"24.0.5 (2022-10-05)"},{"location":"DSP-API/09-release-notes/#bug-fixes_8","text":"Timeout for multiple Gravsearch queries (DEV-1379) ( #2234 ) ( c63567b )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_6","text":"app actor cleanup ( #2230 ) ( a67c98f )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2404-2022-09-29","text":"","title":"24.0.4 (2022-09-29)"},{"location":"DSP-API/09-release-notes/#bug-fixes_9","text":"API returns invalid file URLs, due to including the port ( #2223 ) ( 1a0b09c ) Value update or deletion doesn't work for properties of other ontology (DEV-1367) ( #2222 ) ( 472b375 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#2403-2022-09-21","text":"","title":"24.0.3 (2022-09-21)"},{"location":"DSP-API/09-release-notes/#maintenance_7","text":"application actor (DEV-956) ( #2166 ) ( 4852425 ) remove swagger route and docs annotations (DEV-1335) ( #2203 ) ( bec5b8a ) Replace Settings with AppConfig (DEV-1312) ( #2202 ) ( 9b76417 ) update dependencies ( #2214 ) ( 3706acd )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2402-2022-09-08","text":"","title":"24.0.2 (2022-09-08)"},{"location":"DSP-API/09-release-notes/#bug-fixes_10","text":"sipi: remove support for audio/mp4 file format (DEV-1300) ( #2195 ) ( 122bf52 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_8","text":"Adjust GitHub template (DEV-1313) ( #2183 ) ( 5782494 ) bump dependencies ( #2196 ) ( 2fbf664 ) Ignore push on certain branches from tests (DEV-1112) ( #2187 ) ( e0a0fbb ) Improve GitHub actions (DEV-1112) ( #2182 ) ( 71c772f ) Skip tests with success (DEV-1112) ( #2188 ) ( 82703d7 ) v3: add project slice (DEV-1009) ( #2076 ) ( bd2d31e )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2401-2022-08-26","text":"","title":"24.0.1 (2022-08-26)"},{"location":"DSP-API/09-release-notes/#bug-fixes_11","text":"cardinality: Check cardinality with multiple inherited classes (DEV-1189) ( #2164 ) ( f183d7d ) Fuseki doesn't stop after client's timeout (DEV-1190) ( #2175 ) ( 90f86b5 ) v2 test: fix test data collection ( #2174 ) ( 468df8f )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_4","text":"update file formats (DEV-1185) ( #2158 ) ( 4fab193 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_9","text":"add codacy coverage reporter ( #2177 ) ( c30390f ) add code coverage ( #2135 ) ( 1a02f49 ) add code coverage ( #2163 ) ( b026442 ) add coverage upload to codecov ( #2179 ) ( 5d4e57e ) feature-toggles: remove remnants of feature toggles (DEV-217) ( #2176 ) ( ed1cbd0 ) remove github action for deploying docs (DEV-824) ( #2155 ) ( a55eef4 ) update dependencies ( #2173 ) ( 79b88d2 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2400-2022-08-08","text":"","title":"24.0.0 (2022-08-08)"},{"location":"DSP-API/09-release-notes/#breaking-changes_3","text":"add isSequenceOf to knora-base ontology (DEV-745) (#2061)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_12","text":"sipi: SIPI returns 404 instead of images if cookie is invalid (DEV-1135) ( #2142 ) ( eb797f0 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_5","text":"add isSequenceOf to knora-base ontology (DEV-745) ( #2061 ) ( 74366d4 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#maintenance_10","text":"dependencies: bulk upgrade dependencies ( #2144 ) ( 4602150 ) update dependencies ( 4cd9812 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2303-2022-08-02","text":"","title":"23.0.3 (2022-08-02)"},{"location":"DSP-API/09-release-notes/#bug-fixes_13","text":"triplestore-connector: stack crashes on invalid search (DEV-1154) ( #2140 ) ( e5426dc )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_11","text":"dependencies: update akka-http-cors to 1.1.3 ( #2103 ) ( 5d0d522 ) dependencies: update jwt-spray-json to 9.0.2 ( #2111 ) ( 6e54443 ) dependencies: update Saxon-HE to 11.4 ( #2137 ) ( 08c9f68 ) dependencies: update scalatest to 3.2.13 ( #2138 ) ( a345079 ) dependencies: update spring-security-core to 5.6.6 ( #2130 ) ( c83645d ) dependencies: update spring-security-core to 5.7.2 ( #2139 ) ( 3a12562 ) dependencies: update titanium-json-ld to 1.3.1 ( #2104 ) ( 4850525 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2302-2022-07-29","text":"","title":"23.0.2 (2022-07-29)"},{"location":"DSP-API/09-release-notes/#bug-fixes_14","text":"ontology: link value property is still not editable after updating the property metadata (DEV-1116) ( #2133 ) ( d5b48db ) sipi: cookie parsing can cause an error which leads to 404 for images (DEV-1135) ( #2134 ) ( bd023a5 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_12","text":"add dependency checking ( #2100 ) ( 8017b1f ) add dependency checking ( #2102 ) ( 856277b ) Improve validation of GUI elements and GUI attributes (DEV-1082) ( #2098 ) ( 5cec8ba ) v3: add role slice (DEV-1010) ( #2099 ) ( 6920716 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2301-2022-07-19","text":"","title":"23.0.1 (2022-07-19)"},{"location":"DSP-API/09-release-notes/#bug-fixes_15","text":"ontology: Don't accept list values without gui attribute (DEV-775) ( #2089 ) ( 74a14e1 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#2300-2022-07-14","text":"","title":"23.0.0 (2022-07-14)"},{"location":"DSP-API/09-release-notes/#breaking-changes_4","text":"transform valueHasUri values from node to string type (DEV-1047) (#2094)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_16","text":"authentication: make cookie name unique between environments ( #2095 ) ( 7d420a4 ) ontology: existing cardinalities get duplicated in the triplestore when adding a new cardinality to a class (DEV-937) ( #2092 ) ( 9fa26db ) transform valueHasUri values from node to string type (DEV-1047) ( #2094 ) ( e1d8d95 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#2201-2022-07-08","text":"","title":"22.0.1 (2022-07-08)"},{"location":"DSP-API/09-release-notes/#bug-fixes_17","text":"authentication: make cookie name unique between environments ( #2091 ) ( 680021e ) value: make impossible to set list root node as a value (DEV-973) ( #2088 ) ( 94d2b46 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_13","text":"triplestore: ZIO-fying triplestore service (DSP-904) ( #2059 ) ( 9e038ec ) v3: finish user slice (DEV-671) ( #2078 ) ( 48592ad )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2200-2022-06-30","text":"","title":"22.0.0 (2022-06-30)"},{"location":"DSP-API/09-release-notes/#breaking-changes_5","text":"add upgrade plugin that fixes invalid date serialisations (#2081)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_18","text":"add upgrade plugin that fixes invalid date serialisations ( #2081 ) ( 3a0902e ) ontology: link value property is not editable after editing the property metadata (DEV-1037) ( #2084 ) ( 09688f5 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_14","text":"temporarily ignore KnoraSipiIntegrationV2ITSpec ( #2085 ) ( 59f93b3 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2101-2022-06-23","text":"","title":"21.0.1 (2022-06-23)"},{"location":"DSP-API/09-release-notes/#bug-fixes_19","text":"fix RepositoryUpdater by removing old way of adding plugins ( #2082 ) ( 6599b68 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#2100-2022-06-23","text":"","title":"21.0.0 (2022-06-23)"},{"location":"DSP-API/09-release-notes/#breaking-changes_6","text":"fix valueHasUri bad values and missing types (DEV-1036) (#2079)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_20","text":"fix valueHasUri bad values and missing types (DEV-1036) ( #2079 ) ( de1e5a4 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#2041-2022-06-16","text":"","title":"20.4.1 (2022-06-16)"},{"location":"DSP-API/09-release-notes/#bug-fixes_21","text":"admin: return list labels and comments sorted by language ( #2074 ) ( f3a66cb )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_15","text":"add missing client test data (DEV-979) ( #2072 ) ( 54446bc ) audio: remove not required properties ( #2070 ) ( 96362f4 ) exceptions: Create sbt project \"shared\" and move exceptions (DEV-990) ( #2075 ) ( c09392d ) move value objects to separate project (DEV-615) ( #2069 ) ( b55eb12 ) responder manager as plain case class ( #2073 ) ( 7f55697 ) user: add user project (DEV-586) ( #2063 ) ( 0c5ec03 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2040-2022-05-25","text":"","title":"20.4.0 (2022-05-25)"},{"location":"DSP-API/09-release-notes/#bug-fixes_22","text":"cache: cache does not update correctly when an ontology is modified (DEV-939) ( #2068 ) ( 8541519 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_6","text":"admin: add list child node deletion route (DEV-729) ( #2064 ) ( 179ad19 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#2031-2022-05-12","text":"","title":"20.3.1 (2022-05-12)"},{"location":"DSP-API/09-release-notes/#bug-fixes_23","text":"authentication: Add bouncyCastle dependency (DEV-922) ( #2065 ) ( 4ac799d )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#2030-2022-05-12","text":"","title":"20.3.0 (2022-05-12)"},{"location":"DSP-API/09-release-notes/#bug-fixes_24","text":"Problem with updating cache after deleting comments (DEV-508) ( #2060 ) ( a9fda7e )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_16","text":"check that the expected Fuseki version is present (DEV-331) ( #2057 ) ( 2a695ec ) deps: bump ZIO version (DEV-893) ( #2056 ) ( 933f91e )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_7","text":"add Romansh as supported language (DEV-557) ( #2053 ) ( 58971c8 ) gravsearch: improve gravsearch performance by using unions in prequery (DEV-492) ( #2045 ) ( 40354a7 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#2021-2022-05-05","text":"","title":"20.2.1 (2022-05-05)"},{"location":"DSP-API/09-release-notes/#bug-fixes_25","text":"projectsADM: fix cache issue in getSingleProjectADM ( #2054 ) ( 77bfadc )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_17","text":"IIIFService: zio-fying iiif service (DEV-801) ( #2044 ) ( 224b664 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2020-2022-04-28","text":"","title":"20.2.0 (2022-04-28)"},{"location":"DSP-API/09-release-notes/#bug-fixes_26","text":"Cleaning sipi tmp folder results in an error when there are lots of files (DEV-316) ( #2052 ) ( 33e6896 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_8","text":"error-handling: return status 504 instead of 500 for triplestore timeout exception (DEV-749) ( #2046 ) ( a47096e ) ontology: allow deleting comments of classes (DEV-804) ( #2048 ) ( eca9206 ) ontology: allow deleting comments of properties (DEV-696) ( #2042 ) ( 985c5fd )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#maintenance_18","text":"formatting-logging: reformat scala code and change logging policy (DEV-839) ( #2051 ) ( 5e4e914 ) formatting: reformat turtle files (DEV-430) ( #2050 ) ( 0389e52 ) triplestore: remove embedded-jena-tdb related code ( #2043 ) ( a5ea62e )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2011-2022-04-14","text":"","title":"20.1.1 (2022-04-14)"},{"location":"DSP-API/09-release-notes/#bug-fixes_27","text":"sipi: extract frames from video even without aspect ratio (DEV-802) ( #2041 ) ( 57d40f7 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_5","text":"ingest: Add accepted file formats to documentation (DEV-677) ( #2038 ) ( f72e7a0 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_19","text":"cacheservice: use ZIO (DEV-546) ( #2022 ) ( 521150f ) triplestore: remove graphDB support ( #2037 ) ( bf17bca )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#2010-2022-04-07","text":"","title":"20.1.0 (2022-04-07)"},{"location":"DSP-API/09-release-notes/#bug-fixes_28","text":"docs/requirements.txt to reduce vulnerabilities ( #2034 ) ( b07600d )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_20","text":"distinguish between compile, runtime and test dependencies ( #2028 ) ( 7cb326f ) inventory and upgrade of dependencies (DEV-478) ( #2033 ) ( 470b77f )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#documentation_6","text":"replace Bazel and Intellij documentation with SBT and VSCode (DEV-607) ( #2035 ) ( 603efef )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#enhancements_9","text":"ontology: Add support for additional ontologies (DEV-512) ( #2029 ) ( 50e3186 ) sipi: upload video support (DEV-771 / DEV-207) ( #1952 ) ( 47f2e28 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#2000-2022-03-31","text":"","title":"20.0.0 (2022-03-31)"},{"location":"DSP-API/09-release-notes/#breaking-changes_7","text":"ontology: make knora-base:lastModificationDate required property (#2018)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#maintenance_21","text":"fix docker containers timezone ( #2027 ) ( 6bbb3fe )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_10","text":"ontology: make knora-base:lastModificationDate required property ( #2018 ) ( 64cdce9 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1900-2022-03-24","text":"","title":"19.0.0 (2022-03-24)"},{"location":"DSP-API/09-release-notes/#breaking-changes_8","text":"authentication: add server specific issuer to JWT token (DEV-555) (#2024)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_29","text":"authentication: add server specific issuer to JWT token (DEV-555) ( #2024 ) ( 4bd5b2f ) version: fix displayed versions ( #2026 ) ( 566285c )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_22","text":"improve logging (DEV-634) ( #2021 ) ( 85d1057 ) remove warnings (DEV-621) ( #2015 ) ( 70630f1 ) test: get tests to run in vs code (DEV-601) ( #2020 ) ( 747d13d )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1800-2022-03-08","text":"","title":"18.0.0 (2022-03-08)"},{"location":"DSP-API/09-release-notes/#breaking-changes_9","text":"standoff: return XML alongside HTML for textValue with custom standoff mapping and default XSL transformation (DEV-201) (#1991)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_30","text":"Use correct docker image tag after publishing (DEV-614) ( #2016 ) ( 7649515 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_23","text":"improve code structure (DEV-612) ( #2012 ) ( eac0049 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_11","text":"standoff: return XML alongside HTML for textValue with custom standoff mapping and default XSL transformation (DEV-201) ( #1991 ) ( 2548b8f )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1753-2022-03-04","text":"","title":"17.5.3 (2022-03-04)"},{"location":"DSP-API/09-release-notes/#bug-fixes_31","text":"RepositoryUpdater: make sure temp directories are deleted ( #2010 ) ( 9c9a1bd )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_7","text":"fix permissions design documentation (DEV-495) ( #1997 ) ( 5154adc )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_24","text":"fix docker image name (DEV-574) ( #2007 ) ( 7a186ba ) remove fuseki image creation and change sipi image creation to sbt (DEV-544) ( #2011 ) ( eed2767 ) start on a functional domain design implementation for ontologies (DEV-227) ( #2009 ) ( 54cee7a )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1752-2022-02-23","text":"","title":"17.5.2 (2022-02-23)"},{"location":"DSP-API/09-release-notes/#bug-fixes_32","text":"permissions: Update default object access permissions (DEV-514) ( #2004 ) ( 04a8d3d ) timeout: Increase timeouts (DEV-536) ( #2005 ) ( f1f8005 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_25","text":"BAZEL to SBT migration (DEV-508) ( #2002 ) ( 38faa9e )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1751-2022-02-16","text":"","title":"17.5.1 (2022-02-16)"},{"location":"DSP-API/09-release-notes/#maintenance_26","text":"deps: upgrade Jena Fuseki docker image to v2.0.8 ( #2001 ) ( 3e2eccc ) deps: upgrate Jena API to v4.4.0 ( #1999 ) ( 3eecc69 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#documentation_8","text":"fix markdown issues in documentation (DEV-504) ( #2003 ) ( ff6b4cf )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#1750-2022-02-11","text":"","title":"17.5.0 (2022-02-11)"},{"location":"DSP-API/09-release-notes/#enhancements_12","text":"ontologies: make comments optional for property and class creation (DEV-342) ( #1996 ) ( a3c286c )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1741-2022-02-07","text":"","title":"17.4.1 (2022-02-07)"},{"location":"DSP-API/09-release-notes/#maintenance_27","text":"deps: upgrade Jena to v4.3.2 (DEV-473) ( #1995 ) ( 216dcb4 ) deps: upgrade titanium-json-ld to v1.2.0 & jakarta-json to v2.0.1 (DEV-335) ( #1993 ) ( ad01bf9 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1740-2022-02-04","text":"","title":"17.4.0 (2022-02-04)"},{"location":"DSP-API/09-release-notes/#bug-fixes_33","text":"version-upgrade: add upgrade plugin for ArchiveRepresentation and DeletedResource (DEV-467) ( #1992 ) ( e1566e9 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_28","text":"add support for building native API and Fuseki Docker images on Apple M1 (DEV-435) ( #1987 ) ( ab80e72 ) refactor test models (DEV-264) ( #1975 ) ( 65952f9 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_13","text":"resource: add ArchiveRepresentation to API V1 (DEV-393) (DEV-394) ( #1984 ) ( 65b88a2 ) UUID: add IRI validation that allows only to create IRIs using UUID version 4 and 5 (DEV-402) ( #1990 ) ( 74d4344 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1731-2022-01-28","text":"","title":"17.3.1 (2022-01-28)"},{"location":"DSP-API/09-release-notes/#bug-fixes_34","text":"ontology: Sub-properties of link values aren't created correctly (DEV-426) ( #1985 ) ( 70a8b08 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_29","text":"deps: bump fuseki image to 2.0.7 (DEV-389) ( #1983 ) ( fcbfb1d ) license: update the license (DEV-374) ( #1981 ) ( 044fdc5 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1730-2022-01-17","text":"","title":"17.3.0 (2022-01-17)"},{"location":"DSP-API/09-release-notes/#bug-fixes_35","text":"ontology: DSP-API creates wrong partOfValue property (DEV-216) ( #1978 ) ( 27b5c86 ) resource: return sensible CreationDate for DeletedResource ( #1979 ) ( 1658103 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_14","text":"resource: add support for 7z files in ArchiveRepresentation (DEV-322) ( #1977 ) ( 729689c )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#maintenance_30","text":"admin: refactor projects & users value objects (DEV-240) ( #1976 ) ( 563d252 ) CI: add disk cache and other cleanup (DEV-388) ( #1982 ) ( e590d12 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1720-2022-01-10","text":"","title":"17.2.0 (2022-01-10)"},{"location":"DSP-API/09-release-notes/#bug-fixes_36","text":"search: Return matching sub-nodes when searching for list label (DEV-158) ( #1973 ) ( 7e8c759 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_15","text":"return a DeletedResource or DeletedValue instead of 404 if a deleted resource or value is requested (DEV-226) ( #1960 ) ( c78e252 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1710-2021-12-20","text":"","title":"17.1.0 (2021-12-20)"},{"location":"DSP-API/09-release-notes/#enhancements_16","text":"listsADM: add canDeleteList route ( #1968 ) ( c276625 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#maintenance_31","text":"deps: bump log4j to 2.17.0 and Fuseki to 4.3.2 (DEV-334) ( #1972 ) ( afb6587 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1704-2021-12-17","text":"","title":"17.0.4 (2021-12-17)"},{"location":"DSP-API/09-release-notes/#bug-fixes_37","text":"authentication: delete cookie (in chrome) on logout (DEV-325) ( #1970 ) ( b2c9204 ) candeletecardinalities: return canDoResponse of false instead of throwing an exception for inherited cardinalities (DEV-314) ( #1966 ) ( 55b5d4b ) ontology: cardinality of one can be added to classes as long as not used in data ( #1958 ) ( 2cebac7 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_32","text":"bump logging libraries (DEV-333) ( #1969 ) ( f680c4f )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1703-2021-12-14","text":"","title":"17.0.3 (2021-12-14)"},{"location":"DSP-API/09-release-notes/#maintenance_33","text":"bump Fuseki (log4shell fix) (IT-4) ( #1965 ) ( 86fa251 ) projectMetadataV2: remove projectMetadataV2 implementation ( #1962 ) ( 7b95d66 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1702-2021-12-10","text":"","title":"17.0.2 (2021-12-10)"},{"location":"DSP-API/09-release-notes/#maintenance_34","text":"bump db version (add shiro.ini)(DEV-302)( #1961 ) ( d147bf6 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1701-2021-12-06","text":"","title":"17.0.1 (2021-12-06)"},{"location":"DSP-API/09-release-notes/#maintenance_35","text":"fix issues with fuseki (DEV-277) ( #1953 ) ( 4c1a5f1 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#documentation_9","text":"Updated readme ( #1956 ) ( 774b68d )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#1700-2021-11-25","text":"","title":"17.0.0 (2021-11-25)"},{"location":"DSP-API/09-release-notes/#breaking-changes_10","text":"add archive representation to DSP-API (DEV-17) (#1926)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#maintenance_36","text":"bump fuseki base container version ( #1946 ) ( cf8bdec ) bump java and sipi version (only security updates) (DEV-263) ( #1950 ) ( fe6106f )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_17","text":"add archive representation to DSP-API (DEV-17) ( #1926 ) ( 0123a8f )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1601-2021-11-22","text":"","title":"16.0.1 (2021-11-22)"},{"location":"DSP-API/09-release-notes/#bug-fixes_38","text":"canDeleteCardinalities: canDeleteCardinalities checks too eagerly (DEV-187) ( #1941 ) ( 298ba47 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#1600-2021-11-19","text":"","title":"16.0.0 (2021-11-19)"},{"location":"DSP-API/09-release-notes/#breaking-changes_11","text":"listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_39","text":"projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_37","text":"groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) release v16.0.0 ( 8e5f494 ) release v16.0.0 ( ba6923d )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1513-2021-11-19","text":"","title":"15.1.3 (2021-11-19)"},{"location":"DSP-API/09-release-notes/#breaking-changes_12","text":"listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_40","text":"projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_38","text":"groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1512-2021-11-12","text":"","title":"15.1.2 (2021-11-12)"},{"location":"DSP-API/09-release-notes/#maintenance_39","text":"bump bazel ( #1938 ) ( 39417e6 ) improve validation handling (DEV-228) ( #1937 ) ( 94d7d3f )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1511-2021-11-09","text":"","title":"15.1.1 (2021-11-09)"},{"location":"DSP-API/09-release-notes/#bug-fixes_41","text":"list: add support for special characters in list update (DEV-200) ( #1934 ) ( 3c2865c )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_40","text":"init-db: init db test data from test server (DEV-198) ( #1936 ) ( 1c24bea )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1510-2021-11-03","text":"","title":"15.1.0 (2021-11-03)"},{"location":"DSP-API/09-release-notes/#bug-fixes_42","text":"users: fix bug adding user to group or project (DEV-184) ( #1925 ) ( a24a320 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_18","text":"add value objects to list routes - old and new (DEV-65) ( #1917 ) ( 7752a36 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#maintenance_41","text":"bump sipi version (DEV-188) ( #1931 ) ( d302b5e ) change license to Apache 2.0 (DEV-82) ( #1924 ) ( 2d39a1f ) deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #1927 ) ( cbbf1b6 ) fix warnings (DEV-80) ( #1929 ) ( 1368769 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1503-2021-10-21","text":"","title":"15.0.3 (2021-10-21)"},{"location":"DSP-API/09-release-notes/#bug-fixes_43","text":"list: find list labels in full-text search ( #1922 ) ( cc3b06c )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#1502-2021-10-14","text":"","title":"15.0.2 (2021-10-14)"},{"location":"DSP-API/09-release-notes/#bug-fixes_44","text":"authenticator: improve performance ( #1914 ) ( d6a0d27 ) groups: update test data and documentation to use language specific group descriptions (DEV-123) ( #1921 ) ( 0f45b51 ) removing cardinality of a link property (DEV-90) ( #1919 ) ( c79c194 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_42","text":"groups: refactor groups route using value objects (DEV-66) ( #1913 ) ( 1cd98e6 ) knora-base: fix typo ( #1918 ) ( 720aa65 ) projects: cleaner value objects usage in addProject route (DEV-119) ( #1920 ) ( 32b9e49 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1501-2021-09-29","text":"","title":"15.0.1 (2021-09-29)"},{"location":"DSP-API/09-release-notes/#bug-fixes_45","text":"candeletecardinalities: return correct response on route negative case (DEV-36) ( #1910 ) ( 652c747 ) escape-special-characters: escape special characters in user routes (DSP-1557) ( #1902 ) ( 689d92a )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_43","text":"contributors: remove contributors file (DEV-77) ( #1911 ) ( 7d925b6 ) projects: refactor projects route with value objects (DEV-64) ( #1909 ) ( 172cf77 ) reformatting Scala files (DSP-1897) ( #1908 ) ( 8df70a2 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1500-2021-09-14","text":"","title":"15.0.0 (2021-09-14)"},{"location":"DSP-API/09-release-notes/#breaking-changes_13","text":"ontology: use patch instead of delete for deleting cardinalities (DSP-1700) (#1903)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#documentation_10","text":"add username to changeable attributes (DSP-1895) ( #1904 ) ( 719cd0d )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_44","text":"ontology: use patch instead of delete for deleting cardinalities (DSP-1700) ( #1903 ) ( 91ef4ec )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1410-2021-08-19","text":"","title":"14.1.0 (2021-08-19)"},{"location":"DSP-API/09-release-notes/#bug-fixes_46","text":"ontology V2: use internal iri when updating a property (DSP-1868) ( #1898 ) ( a746f65 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_19","text":"v2-ontologies: add remove cardinalities from class if property not used in resources (DSP-1700) ( #1869 ) ( a30668b )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1401-2021-08-04","text":"","title":"14.0.1 (2021-08-04)"},{"location":"DSP-API/09-release-notes/#bug-fixes_47","text":"add-test-file: add response file for test case (DSP-1841) ( #1894 ) ( 028e685 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#1400-2021-08-02","text":"","title":"14.0.0 (2021-08-02)"},{"location":"DSP-API/09-release-notes/#breaking-changes_14","text":"projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) (#1886)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_48","text":"api-v2, api-admin: ontology name and project name should be URL safe (DSP-1749) ( #1889 ) ( 17601a7 ) permissions: reject malformed doap and ap create/update request (DSP-1328) ( #1890 ) ( 3e3a3ce )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_20","text":"customIRIs: custom IRIs must contain a UUID (DSP-1763) ( #1884 ) ( 593d9cb ) projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) ( #1886 ) ( b3c2d5f ) resource-metadata: return resource metadata after metadata update request (DSP-1828) ( #1893 ) ( a4e878a ) video: add support for video/mp4 to both v1 and v2 (DSP-1204) ( #1891 ) ( 83fb4b8 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#13120-2021-06-24","text":"","title":"13.12.0 (2021-06-24)"},{"location":"DSP-API/09-release-notes/#enhancements_21","text":"resourceHistoryEvents: route for resource history events (DSP-1749) ( #1882 ) ( f86de53 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#13110-2021-06-17","text":"","title":"13.11.0 (2021-06-17)"},{"location":"DSP-API/09-release-notes/#enhancements_22","text":"events: update resource last modification date event ( #1877 ) ( d5e70ba )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#maintenance_45","text":"build: cleanup ( #1880 ) ( 749e8ea ) cache-service: add in-memory implementation ( #1870 ) ( 61531ab ) gh-ci: update docs deployment (DSP-1741) ( #1878 ) ( ff65323 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#13100-2021-06-09","text":"","title":"13.10.0 (2021-06-09)"},{"location":"DSP-API/09-release-notes/#enhancements_23","text":"gravsearch: use layer info for topological order permutations (DSP-1389) ( #1872 ) ( b49d5ba )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#documentation_11","text":"prepare documentation for docs.dasch.swiss (DSP-1721) ( #1873 ) ( 66751a0 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#1392-2021-06-02","text":"","title":"13.9.2 (2021-06-02)"},{"location":"DSP-API/09-release-notes/#maintenance_46","text":"sipi: add comments ( #1864 ) ( 06e8b0c )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#documentation_12","text":"ontology: update term ( #1865 ) ( cd37580 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#1391-2021-05-28","text":"","title":"13.9.1 (2021-05-28)"},{"location":"DSP-API/09-release-notes/#maintenance_47","text":"bazel: bump bazel version ( #1866 ) ( c754cbf )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1390-2021-05-25","text":"","title":"13.9.0 (2021-05-25)"},{"location":"DSP-API/09-release-notes/#enhancements_24","text":"api-v2: Add routes for checking whether ontology entities can be changed (DSP-1621) ( #1861 ) ( fdd098f )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1380-2021-05-19","text":"","title":"13.8.0 (2021-05-19)"},{"location":"DSP-API/09-release-notes/#bug-fixes_49","text":"api-v2: Update subclasses in ontology cache when base class changes (DSP-1643) ( #1860 ) ( beb951d ) gravsearch: don't move the patterns with resource IRI after topological sorting (DSP-1620) ( #1856 ) ( 6022c91 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_48","text":"documentation: bug fix in documentation deployment (DSP-1605) ( bb852c9 ) documentation: bug fix in documentation deployment (DSP-1605) ( #1854 ) ( 999a2bb )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_25","text":"api-v2: Change GUI element and attribute of a property (DSP-1600) ( #1855 ) ( ce9ba3a ) api-v2: Generate IIIF manifest (DSP-50) ( #1784 ) ( 74feb2c ) conf: Rule to dump prod data and load locally (DSP-1485) ( #1857 ) ( 161ea31 ) ontology: Allow adding new property to a resource class in use (DSP-1629) ( #1859 ) ( 061875e )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1370-2021-05-06","text":"","title":"13.7.0 (2021-05-06)"},{"location":"DSP-API/09-release-notes/#bug-fixes_50","text":"doc: correct remaining incorrect copyright dates ( #1847 ) ( d1473ed ) gravsearch: Keep rdf:type knora-api:Resource when needed. ( #1835 ) ( e561d94 ) lists: Escape special characters in comment, label, and name of a list node (DSP-1529) ( #1846 ) ( f96c069 ) test-data: change webern shortcode in test data (DSP-1520) ( #1843 ) ( 5f06a10 ) values v1 route: fix geoname case (DSP-1487) ( #1839 ) ( 9d0e93e )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_13","text":"replace knora by dsp or dsp-api in documentation (DSP-1469) ( #1836 ) ( 923abe8 ) v1: improve search docs ( #1848 ) ( 5a81f73 )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#enhancements_26","text":"api-v2: Add route for changing GUI order of cardinalities ( #1850 ) ( d8dbb4f ) api-v2: Return events describing version history of resources and values of a project ordered by data (DSP-1528) ( #1844 ) ( 84f7c14 ) ext search v1: add support for URI values (DSP-1522) ( #1842 ) ( b119757 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#maintenance_49","text":"bumb Bazel to version with apple silicon support ( #1852 ) ( 286d289 ) bump scala to 2.13 ( #1851 ) ( 5feb915 ) deps: bump versions (DSP-1569) ( #1849 ) ( f69f008 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1360-2021-03-16","text":"","title":"13.6.0 (2021-03-16)"},{"location":"DSP-API/09-release-notes/#enhancements_27","text":"api-v2: Improve error message when an XSLT transformation file is not found (DSP-1404) ( #1831 ) ( 153a674 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1351-2021-03-11","text":"","title":"13.5.1 (2021-03-11)"},{"location":"DSP-API/09-release-notes/#bug-fixes_51","text":"OntologiesRouteV2: Reject internal ontology names in external schema (DSP-1394) ( #1827 ) ( e392bf1 ) OntologyResponderV2: Fix check when updating ontology label and comment (DSP-1390) ( #1826 ) ( 26cce48 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#1350-2021-03-08","text":"","title":"13.5.0 (2021-03-08)"},{"location":"DSP-API/09-release-notes/#bug-fixes_52","text":"replaceCardinalities.scala.txt: Fix blank node insertion. ( #1829 ) ( d24c5d2 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_50","text":"gh-ci: update release please configuration (DSP-1382) ( #1825 ) ( 7ce4b65 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_28","text":"Add support for audio files (DSP-1343) ( #1818 ) ( 7497023 ) gravsearch: Optimise Gravsearch queries using topological sort (DSP-1327) ( #1813 ) ( efbecee ) store: Return 404 if the triplestore returns 404. ( #1828 ) ( 5250f6d )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1340-2021-02-17","text":"","title":"13.4.0 (2021-02-17)"},{"location":"DSP-API/09-release-notes/#bug-fixes_53","text":"Lists: fix bug in shifting the second of two children after deletion of the first one. ( #1820 ) ( d92bb01 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_29","text":"projects: add default set of permissions when creating new project (DSP-1347) ( #1822 ) ( b7c71ca )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1331-2021-02-09","text":"","title":"13.3.1 (2021-02-09)"},{"location":"DSP-API/09-release-notes/#bug-fixes_54","text":"Lists: fix bug in deleting the single child of a node (DSP-1355) ( #1816 ) ( 1d06572 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#1330-2021-02-05","text":"","title":"13.3.0 (2021-02-05)"},{"location":"DSP-API/09-release-notes/#enhancements_30","text":"sipi: add storing of original and sidecar (DSP-1318) ( #1808 ) ( 022ed7e )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1320-2021-02-04","text":"","title":"13.2.0 (2021-02-04)"},{"location":"DSP-API/09-release-notes/#bug-fixes_55","text":"api-v1: Optimise SPARQL queries. ( #1814 ) ( 4edc27c ) Lists: Repositioning the node when new position equals length of new parent's children (DSP-1322) ( #1811 ) ( 3fead13 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#enhancements_31","text":"api-v1: Add support for PDF files (DSP-1267) ( #1797 ) ( c3b2e84 ) api-v2: Allow resubmitting existing class/property lablels/comments. ( #1812 ) ( 6a13852 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#maintenance_51","text":"make targets for adding metadata (DSP-1289) ( #1810 ) ( 9c1a70a ) salsah1: delete from repository ( #1805 )(DSP-1294) ( 3251a74 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1311-2021-01-30","text":"","title":"13.1.1 (2021-01-30)"},{"location":"DSP-API/09-release-notes/#maintenance_52","text":"gh-ci: Bring back the client-test-data command to github actions ( #1804 ) ( e6b0fbf ) revert release 13.1.0 ( #1800 ) ( 565e5ac )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#1310-2021-01-29","text":"","title":"13.1.0 (2021-01-29)"},{"location":"DSP-API/09-release-notes/#bug-fixes_56","text":"api-v1: Optimise link value queries for Fuseki (DSP-1243) ( #1791 ) ( b1e1b9e ) api-v2: Don't allow an invalid cardinality on a boolean property (DSP-1236) ( #1788 ) ( 3d5f802 ) gravsearch: Handle UNION scopes with FILTER correctly (DSP-1240) ( #1790 ) ( 61d2e86 ) HttpTriplestoreConnector: Always parse triplestore responses as UTF-8. ( #1789 ) ( 61d2e86 ) permissions : fix getting builtin groups while creating a permission (DSP-1296 ) ( #1799 ) ( d390014 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#maintenance_53","text":"gh-ci: fix issue in the release process ( #1782 ) ( afe61b7 ) ghi-ci: google chat release notification ( #1785 ) ( 4718cdc )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_32","text":"permissions: add delete permissions: (DSP-1169) ( #1787 ) ( 3fe8c14 ) store: Return a clearer exception when a triplestore read timeout occurs. ( #1795 ) ( 0eeb3b3 )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#1300-2021-01-11","text":"","title":"13.0.0 (2021-01-11)"},{"location":"DSP-API/09-release-notes/#breaking-changes_15","text":"New features and refactoring (#1779)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-API/09-release-notes/#bug-fixes_57","text":"(dependencies) add the missing dependency ( #1755 ) ( 0e37d21 ) api-v2: Change link value comment ( #1582 ) ( faa2e55 ) api-v2: Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) ( #1749 ) ( 905766f ) api-v2: Fix custom datatypes in knora-api simple ontology ( #1601 ) ( e0cfd4e ) api-v2: Fix generated SPARQL for updating property comment ( #1693 ) ( 7b70339 ) api-v2: Fix ontology deletion ( #1584 ) ( 70b0841 ) api-v2: Fix post-update check for resource with standoff link (DSP-841) ( #1728 ) ( 35d449f ) failing repository upgrade at startup (DSP-654) ( #1712 ) ( 0d6b4ee ) gravsearch: Prevent duplicate results ( #1626 ) ( 9313b88 ) gravsearch: When link property compared in filter, don't compare link value property, too ( #1699 ) ( a3b1665 ) init db scripts (DSP-511) ( #1681 ) ( d4505ce ) loading of data (DSP-445) ( #1669 ) ( 3f8d406 ) OntologyResponderV2: Add a global ontology cache lock ( #1637 ) ( 1853865 ) OntologyResponderV2: Fix ontology cache update when ontology metadata changed ( #1709 ) ( 4f57977 ) server header (DSP-537) ( #1691 ) ( 8d7bee8 ) sipi makefile ( #1616 ) ( 73a0afe ) sipi: Don't expect API v1 status code (DSP-1114) ( #1763 ) ( 3236d25 ) sipi: Improve performance of file value query ( #1697 ) ( 8214877 ) test: Fix typos in IRIs in anything-data.ttl. ( #1625 ) ( 23d51ce ) upgrade: Fix log output. ( #1774 ) ( b43fab0 ) webapi: unique username/email check on change user ( #1561 ) ( 4f26e22 ) rdf-api : Use the Jena RDF API implementation by default (DSP-1153) ( 1772 ) ( 389feb4 )","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_14","text":"api-v2: Document what happens when a resource has a link to a deleted resource ( #1685 ) ( 1c88651 ) fix broken links ( #1688 ) ( 9c0292c ) fix make targets docker-build and docker-publish ( #1694 ) ( d06b6a6 ) Update README (DSP-1142) ( #1771 ) ( 7ba7fc6 ) Update required mkdocs package ( #1725 ) ( 27de65e )","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_54","text":"api-v2: Delete obsolete files. ( #1634 ) ( e80bf52 ) api-v2: Switch from JSONLD-Java to Titanium ( #1715 ) ( 9e28e5b ) build: Bump testcontainers version. ( #1723 ) ( 24ae1d3 ) build: Update ScalaTest (DSP-919) ( #1745 ) ( bbaeadd ) build: Upgrade Sipi to 3.0.0-rc.8 (DSP-916) ( #1743 ) ( 23395fc ) bump sipi to rc.7 (DSP-733) ( #1721 ) ( b635495 ) gh-ci: Fix gren issue ( #1666 ) ( 2dc5361 ) gh-ci: Publish on release only ( #1662 ) ( 787dca8 ) rdf-api: Use the Jena RDF API implementation by default (DSP-1153) ( #1772 ) ( 389feb4 ) Remove obsolete functions from StringFormatter. ( #1640 ) ( 5fa6de4 ) Update ci workflow release notes ( #1707 ) ( d8e0b39 ) gh-ci CI is failing to test upgrade correctly (DSP-667) ( #1073 ) ( 13cbdab ) bazel Update Bazel maven rules to see if it fixes problems with macOS Big Sur (DSP-1099) ( #1761 ) ( a2c9941 )","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#enhancements_33","text":"Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) ( #1759 ) ( 346873d ) Add feature toggles (DSP-910) ( #1742 ) ( 2e6db2e ) Add time value type ( #1403 ) ( d925c85 ) api-v1: Change API v1 file uploads to work like API v2 (DSP-41, PR 3) ( #1722 ) ( a824bcc ) api-v2: Accept custom new value IRI when updating value ( #1698 ) ( 4d8f867 ) api-v2: Accept custom timestamps in update/delete requests ( #1686 ) ( 0fbe5a8 ) api-v2: Add an RDF processing fa\u00e7ade (DSP-1020) ( #1754 ) ( 9170419 ) api-v2: Add metadata routes (DSP-662) ( #1734 ) ( bf48968 ) api-v2: Add support for text file upload (DSP-44) ( #1664 ) ( a88d20d ) api-v2: Add test data. ( #1704 ) ( de14ab1 ) api-v2: Allow querying for rdfs:label in Gravsearch ( #1649 ) ( d56004b ) api-v2: Control JSON-LD nesting via an HTTP header (DSP-1084) ( #1758 ) ( b13eecf ) api-v2: Make inference optional in Gravsearch ( #1696 ) ( 166a260 ) api-v2: Optionally return file values in full-text search results (DSP-1191) ( #1776 ) ( 01f59bd ) api-v2: Remove client code generation ( #1610 ) ( 6977ab3 ) api-v2: Remove ForbiddenResource ( #1615 ) ( 992596e ) api-v2: Return value UUID on value creation and update ( #1602 ) ( cbed601 ) api-v2: Specify custom IRIs when creating resources/values ( #1646 ) ( 135b039 ) clientapi: Change method signature. ( #1583 ) ( c2a2559 ) gh-ci: Release please and update gh actions (DSP-1168) ( #1777 ) ( 593ffab ) gravsearch: Allow comparing variables representing resource IRIs ( #1713 ) ( f359c8e ) gravsearch: Remove deprecated functions ( #1660 ) ( 5d3af46 ) New features and refactoring ( #1779 ) ( 9a5fb77 ) rdf-api: Add a general-purpose SHACL validation utility (DSP-930) ( #1762 ) ( bfd3192 ) sipi: Improve error message if XSL file not found ( #1590 ) ( bbb42f6 ) triplestores: Support Apache Jena Fuseki ( #1375 ) ( 82f8a55 ) upgrade: Update repository on startup ( #1643 ) ( 0127dca )","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#v1300-rc25-08122020","text":"","title":"v13.0.0-rc.25 (08/12/2020)"},{"location":"DSP-API/09-release-notes/#enhancements_34","text":"#1768 | DSP-1106 Update Permission #1767 | enhancement(triplestore): Use N-Quads instead of TriG for repository upgrade (DSP-1129) #1764 | DSP-1033 Reposition List Nodes #1762 | feat(rdf-api): Add a general-purpose SHACL validation utility (DSP-930) #1759 | feat: Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) #1760 | (DSP-1031) Delete list items #1753 | Edit lists routes (DSP-597 ) #1758 | feat(api-v2): Control JSON-LD nesting via an HTTP header (DSP-1084)","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#bug-fixes_58","text":"#1763 | fix(sipi): Don't expect API v1 status code (DSP-1114)","title":"Bug fixes"},{"location":"DSP-API/09-release-notes/#documentation_15","text":"#1771 | docs: Update README (DSP-1142)","title":"Documentation"},{"location":"DSP-API/09-release-notes/#maintenance_55","text":"#1770 | refactor: Use java.nio.file.Path instead of java.io.File (DSP-1124) #1765 | DSP-1094 Upgrade Swagger version #1766 | style: Add Scalafmt config file #1769 | style: Reformat code with Scalafmt (DSP-1137) #1754 | feat(api-v2): Add an RDF processing fa\u00e7ade (DSP-1020) #1757 | build: bazel workspace cleanup","title":"Maintenance"},{"location":"DSP-API/09-release-notes/#v1300-rc24-13112020","text":"#1756 | DSP-1052 : Migration task to replace empty strings with dummy \"FIXME\"","title":"v13.0.0-rc.24 (13/11/2020)"},{"location":"DSP-API/09-release-notes/#v1300-rc23-09112020","text":"","title":"v13.0.0-rc.23 (09/11/2020)"},{"location":"DSP-API/09-release-notes/#bug-fixes_59","text":"#1755 | DSP-1029: Add the missing dependency","title":"Bug fixes"},{"location":"DSP-API/09-release-notes/#v1300-rc22-09112020","text":"","title":"v13.0.0-rc.22 (09/11/2020)"},{"location":"DSP-API/09-release-notes/#breaking-changes_16","text":"#1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions","title":"Breaking changes"},{"location":"DSP-API/09-release-notes/#enhancements_35","text":"#1403 | feat: Add time value type #1537 | build: Add env var to set triplestore actor pool #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30)","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#bug-fixes_60","text":"#1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1576 | Add missing env var #1571 | fixed date string format #1564 | enable click on save button in case of recoverable error #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445)","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_16","text":"#1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering","title":"Documentation"},{"location":"DSP-API/09-release-notes/#other","text":"#1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes","title":"Other"},{"location":"DSP-API/09-release-notes/#dependencies","text":"#1721 | chore: bump sipi to rc.7 (DSP-733) #1735 | DSP-496 Bump Apache Jena Fuseki and Apache Jena Libraries to 3.16 #1737 | DSP-842 Bump used Bazel version to newly released 3.7.0 #1743 | chore(build): Upgrade Sipi to 3.0.0-rc.8 (DSP-916) #1745 | chore(build): Update ScalaTest (DSP-919) #1752 | DSP-1017 Upgrade to Sipi v3.0.0-rc.9","title":"Dependencies"},{"location":"DSP-API/09-release-notes/#v1300-rc21-09112020","text":"","title":"v13.0.0-rc.21 (09/11/2020)"},{"location":"DSP-API/09-release-notes/#breaking-changes_17","text":"#1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions","title":"Breaking changes"},{"location":"DSP-API/09-release-notes/#enhancements_36","text":"#1403 | feat: Add time value type #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30)","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#bug-fixes_61","text":"#1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445)","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_17","text":"#1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering","title":"Documentation"},{"location":"DSP-API/09-release-notes/#other_1","text":"#1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes","title":"Other"},{"location":"DSP-API/09-release-notes/#v1200-27012020","text":"","title":"v12.0.0 (27/01/2020)"},{"location":"DSP-API/09-release-notes/#breaking-api-changes","text":"#1439 JSON-LD Serialization of an xsd:dateTimeStamp","title":"Breaking API Changes"},{"location":"DSP-API/09-release-notes/#new-features-and-enhancements","text":"#1509 Support lists admin endpoint #1466 Optimise generated SPARQL","title":"New Features and Enhancements"},{"location":"DSP-API/09-release-notes/#bug-fixes_62","text":"#1569 broken ark #1559 Admin lists: createChildNode should send a httpPost request, not httpPut","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#v1100-16122019","text":"","title":"v11.0.0 (16/12/2019)"},{"location":"DSP-API/09-release-notes/#breaking-changes_18","text":"#1344 Gravsearch ForbiddenResource result and permissions of linked resources #1202 Implement upload of PDF and text files in API v2. Users with files in Sipi under /server must move them to /images when upgrading.","title":"Breaking Changes"},{"location":"DSP-API/09-release-notes/#bug-fixes_63","text":"#1531 Sipi's mimetype_consistency fails with .bin file #1430 Creating the first resource with an image inside a project fails with Sipi not finding the project folder #924 Get dependent resources Iris","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#v1011-27112019","text":"","title":"v10.1.1 (27/11/2019)"},{"location":"DSP-API/09-release-notes/#v1010-27112019","text":"","title":"v10.1.0 (27/11/2019)"},{"location":"DSP-API/09-release-notes/#v1000-22102019","text":"","title":"v10.0.0 (22/10/2019)"},{"location":"DSP-API/09-release-notes/#breaking-changes_19","text":"#1346 Richtext/HTML in page anchor link","title":"Breaking Changes"},{"location":"DSP-API/09-release-notes/#enhancements_37","text":"#1457 Upgrade sipi to 2.0.1","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#bug-fixes_64","text":"#1460 Build banner in README is broken","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_18","text":"#1481 build badge in README has broken link","title":"Documentation"},{"location":"DSP-API/09-release-notes/#other_2","text":"#1449 Add Makefile-based task execution #1401 Enable testing docs generation in Travis","title":"Other"},{"location":"DSP-API/09-release-notes/#v910-26092019","text":"","title":"v9.1.0 (26/09/2019)"},{"location":"DSP-API/09-release-notes/#enhancements_38","text":"#1421 Physically deleting a resource","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#documentation_19","text":"#1407 Document ARK URLs for projects","title":"Documentation"},{"location":"DSP-API/09-release-notes/#v900-29082019","text":"","title":"v9.0.0 (29/08/2019)"},{"location":"DSP-API/09-release-notes/#breaking-changes_20","text":"#1411 Moved /admin/groups/members/GROUP_IRI to /admin/groups/GROUP_IRI/members #1231 Change value permissions #763 refactor splitMainResourcesAndValueRdfData so it uses SparqlExtendedConstructResponse","title":"Breaking Changes"},{"location":"DSP-API/09-release-notes/#enhancements_39","text":"#1373 The startup ends in a thrown exception if the triplestore is not up-to-date #1364 Add support for Redis cache #1360 Build and publish Knora version specific docker images for GraphDB Free and SE #1358 Add admin route to dump project data","title":"Enhancements"},{"location":"DSP-API/09-release-notes/#bug-fixes_65","text":"#1394 Using dockerComposeUp to start the stack, fails to find Redis at startup","title":"Bug Fixes"},{"location":"DSP-API/09-release-notes/#documentation_20","text":"#1386 Add lists admin API documentation","title":"Documentation"},{"location":"DSP-API/09-release-notes/#other_3","text":"#1412 Change release notes to be based on issues","title":"Other"},{"location":"DSP-API/09-release-notes/#v800-14062019","text":"feature(webapi): Add GraphDB-Free startup support (#1351) - @subotic feature(webapi): Add returning of fixed public user information (#1348) - @subotic feat(api-v2): No custom permissions higher than defaults (#1337) - @benjamingeer feat(upgrade): Improve upgrade framework (#1345) - @benjamingeer test(webapi): Add new user authentication (#1201) - @subotic chore(webapi): Add request duration logging (#1347) - @subotic feat(api-v2): Make values citable (#1322) - @benjamingeer Leibniz ontology (#1326) - @SepidehAlassi feature(webapi): add CORS allow header (#1340) - @subotic fix(sipi): Return permissions for a previous version of a file value. (#1339) - @benjamingeer fix(scripts): add admin ontology data to correct graph (#1333) - @subotic fix(sipi): Don't try to read a file value in a deleted resource. (#1329) - @benjamingeer docs(api-v2): Fix sample responses. (#1327) - @benjamingeer fix(api-v2): Fix typo. (#1325) - @benjamingeer Handle List Nodes in Response (#1321) - @tobiasschweizer feat(api-v2): Return standoff markup separately from text values (#1307) - @benjamingeer BEOL: Import comments for Meditationes (#1281) - @tobiasschweizer feat(triplestore): Log SPARQL query if triplestore doesn't respond. (#1292) - @benjamingeer Support list nodes in Gravsearch (#1314) - @tobiasschweizer","title":"v8.0.0 (14/06/2019)"},{"location":"DSP-API/09-release-notes/#v700-03052019","text":"fix(api-v2): Cache base class IRIs correctly when creating/updating class (#1311) - @benjamingeer chore(standoff): Use Base64-encoded UUIDs in standoff tags. (#1301) - @benjamingeer feat(api-v2): Allow a resource to be created as a specified user (#1306) - @benjamingeer feat(admin): Give the admin ontology an external schema (#1291) - @benjamingeer fix(api-v2): Remove INFORMATION SEPARATOR TWO from text in the simple schema. (#1299) - @benjamingeer test: Compare Knora response with its class definition (#1297) - @benjamingeer docs(api-admin): fix description of the change password payload (#1285) - @loicjaouen fix(api-v1): Fix double escaping of newline. (#1296) - @benjamingeer fix (tei beol): fix problems in XSLT (#1260) - @tobiasschweizer refactor(ontology): Make knora-admin a separate ontology (#1263) - @benjamingeer a handfull of changes in documentation and error messages (#1278) - @loicjaouen docs: fix missing username (#1269) - @loicjaouen feat(api-v2): Get resources in a particular class from a project (#1251) - @benjamingeer fix(sipi): Improve error checking of Sipi's knora.json response. (#1279) - @benjamingeer feat(api-v2): Return user's permission on resources and values (#1257) - @benjamingeer fix(api-v1): Escape rdfs:label in bulk import. (#1276) - @benjamingeer chore(webapi): Remove persistent map code (#1254) - @benjamingeer docs (api-v2): Update outdated ARK documentation. (#1252) - @benjamingeer Update build.properties (#1265) - @subotic","title":"v7.0.0 (03/05/2019)"},{"location":"DSP-API/09-release-notes/#v601-22032019","text":"chore: releasing-v6.0.1 (#1270) - @subotic chore(webapi): Add script for loading of a minimal set of data (#1267) - @subotic fix (beolPersonLabel) typo in label of hasBirthPlace (#1248) - @SepidehAlassi fix (webapi): message typo (#1244) - @subotic Unescape standoff string attributes when verifying text value update (#1242) - @benjamingeer docs: fix user admin api (#1237) - @subotic","title":"v6.0.1 (22/03/2019)"},{"location":"DSP-API/09-release-notes/#v600-28022019","text":"","title":"v6.0.0 (28/02/2019)"},{"location":"DSP-API/09-release-notes/#release-notes","text":"MAJOR: Use HTTP POST to mark resources and values as deleted (#1203) MAJOR: Reorganize user and project routes (#1209) FEATURE: Secure routes returning user information (#961) MAJOR: Change all xsd:dateTimeStamp to xsd:dateTime in the triplestore (#1211). Existing data must be updated; see upgrade/1211-datetime for instructions. FIX: Ignore order of attributes when comparing standoff (#1224). FEATURE: Query version history (#1214) FIX: Don't allow conflicting cardinalities (#1229) MAJOR: Remove preview file values (#1230). Existing data must be updated; see upgrade/1230-delete-previews for instructions.","title":"Release Notes"},{"location":"DSP-API/09-release-notes/#v500-05022019","text":"","title":"v5.0.0 (05/02/2019)"},{"location":"DSP-API/09-release-notes/#release-notes_1","text":"MAJOR: Fix property names for incoming links (#1144)) MAJOR: Generate and resolve ARK URLs for resources (#1161). Projects that have resource IRIs that do not conform to the format specified in https://docs.knora.org/paradox/03-endpoints/api-v2/knora-iris.html#iris-for-data must update them. MAJOR: Use project shortcode in IIIF URLs (#1191). If you have file value IRIs containing the substring /reps/ , you must replace /reps/ with /values/ . FEATURE: Update resource metadata in API v2 (#1131) FEATURE: Allow setting resource creation date in bulk import #1151) FEATURE: The v2/authentication route now also initiates cookie creation (the same as v1/authentication ) (#1159) FEATURE: Allow to specify restricted view settings for a project which Sipi will adhere to (#690). FIX: Triplestore connection error when using dockerComposeUp (#1122) FIX: Reject link value properties in Gravsearch queries in the simple schema (#1145) FIX: Fix error-checking when updating cardinalities in ontology API (#1142) FIX: Allow hasRepresentation in an ontology used in a bulk import (#1171) FIX: Set cookie domain to the value specified in application.conf with the setting cookie-domain (#1169) FIX: Fix processing of shared property in bulk import (#1182)","title":"Release Notes"},{"location":"DSP-API/09-release-notes/#v400-12122018","text":"","title":"v4.0.0 (12/12/2018)"},{"location":"DSP-API/09-release-notes/#v400-release-notes","text":"MAJOR CHANGE: mapping creation request and response formats have changed (#1094) MINOR CHANGE: Update technical user docs (#1085) BUGFIX CHANGE: Fix permission checking in API v2 resource creation (#1104)","title":"v4.0.0 Release Notes"},{"location":"DSP-API/09-release-notes/#v300-30112018","text":"","title":"v3.0.0 (30/11/2018)"},{"location":"DSP-API/09-release-notes/#v300-release-notes","text":"[BREAKING ONTOLOGY CHANGE] The property knora-base:username was added and is required for knora-base:User . (#1047) [BREAKING API CHANGE] The /admin/user API has changed due to adding the username property. (#1047) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Add default permission caching (#1062) [FIX] Fix unescaping in update check and reading standoff URL (#1074) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Create image file values in API v2 (#1011). Requires Sipi with tagged commit v1.4.1-SNAPSHOT or later.","title":"v3.0.0 Release Notes"},{"location":"DSP-API/09-release-notes/#v210-02112018","text":"","title":"v2.1.0 (02/11/2018)"},{"location":"DSP-API/09-release-notes/#new-features","text":"Implement graph query in API v2 (#1009) Expose additional webapi settings as environment variables. Please see the Configuration section in the documentation for more information (#1025)","title":"New features"},{"location":"DSP-API/09-release-notes/#bugfixes","text":"sipi container config / sipi not able to talk to knora (#994)","title":"Bugfixes"},{"location":"DSP-API/09-release-notes/#v210-snapshot-22102018","text":"","title":"v2.1.0-snapshot (22/10/2018)"},{"location":"DSP-API/09-release-notes/#v200-13092018","text":"This is the first release with the new version numbering convention. From now on, if any changes to the existing data are necessary for a release, then this release will have its major number increased. Please see the Release Versioning Convention description.","title":"v2.0.0 (13/09/2018)"},{"location":"DSP-API/09-release-notes/#required-changes-to-existing-data","text":"a knora-base:ListNode must have at least one rdfs:label . (@github #991 )","title":"Required changes to existing data"},{"location":"DSP-API/09-release-notes/#new-features_1","text":"add developer-centric docker-compose.yml for starting the Knora / GraphDB / Sipi / Salsah1 (@github #979 ) configure webapi and salsah1 thorough environment variables (@github #979 ) update for Java 10 (@github #979 ) comment out the generation of fat jars from KnoraBuild.sbt (for now) (@github #979 ) update ehcache (@github #979 ) update sbt to 1.2.1 (@github #979 ) remove Kamon monitoring (for now) since we don't see anything meaningful there. We probably will have to instrument Knora by hand and then use Kamon for access. (@github #979 ) update Dockerfiles for webapi and salsah1 (@github #979 ) follow subClassOf when including ontologies in XML import schemas (@github #991 ) add support for adding list child nodes (@github #991 ) add support for shared ontologies (@github #987 )","title":"New features"},{"location":"DSP-API/09-release-notes/#bugfixes_1","text":"trouble with xml-checker and/or consistency-checker during bulk import (@github #978 ) ontology API error with link values (@github #988 )","title":"Bugfixes"},{"location":"DSP-API/09-release-notes/#v171-29082018","text":"","title":"v1.7.1 (29/08/2018)"},{"location":"DSP-API/09-release-notes/#knora-stack-compatible-versions","text":"Knora v1.7.1 - Salsah v2.1.2 - Sipi v1.4.0 - GraphDB v8.5.0 doc (webapi): add yourkit acknowledgment (#983) Don't allow class with cardinalities on P and on a subproperty of P (#982) doc (webapi): add LHTT project shortcode (#981) feature (webapi): not return or allow changing of built-in users (#975) fix (webapi): startup check does not detect running triplestore (#969) Fix bulk import parsing bug and limit concurrent client connections (#973)","title":"Knora-Stack compatible versions"},{"location":"DSP-API/09-release-notes/#v170-16082018","text":"See the closed tickets on the v1.7.0 milestone .","title":"v1.7.0 (16/08/2018)"},{"location":"DSP-API/09-release-notes/#knora-stack-compatible-versions_1","text":"Knora v1.7.0 - Salsah v2.1.0 - Sipi v1.4.0 - GraphDB v8.5.0","title":"Knora-Stack compatible versions"},{"location":"DSP-API/09-release-notes/#required-changes-to-existing-data_1","text":"To use the inferred Gravsearch predicate knora-api:standoffTagHasStartAncestor , you must recreate your repository with the updated KnoraRules.pie .","title":"Required changes to existing data"},{"location":"DSP-API/09-release-notes/#new-features_2","text":"Gravsearch queries can now match standoff markup (#910). Add Graphdb-Free initialization scripts for local and docker installation (#955). Create temp dirs at startup (#951) Update versions of monitoring tools (#951)","title":"New features"},{"location":"DSP-API/09-release-notes/#bugfixes_2","text":"timeout or java.lang.OutOfMemoryError when using /v1/resources/xmlimportschemas/ for some ontologies (#944) Timeout cleanup (#951) Add separate dispatchers (#945)","title":"Bugfixes"},{"location":"DSP-API/09-release-notes/#v160-29062018","text":"","title":"v1.6.0 (29/06/2018)"},{"location":"DSP-API/09-release-notes/#v160-release-notes","text":"See the release and closed tickets on the v1.6.0 milestone on Github.","title":"v1.6.0 Release Notes"},{"location":"DSP-API/09-release-notes/#required-changes-to-existing-data_2","text":"A project is now required to have at least one description, so potentially a description will need to be added to those projects that don't have one.","title":"Required changes to existing data"},{"location":"DSP-API/09-release-notes/#new-features_3","text":"General: Added a /health endpoint KnoraService waits on startup for a triplestore before trying to load the ontologies Gravsearch enhancements: Accept queries in POST requests (@github #650 ). Allow a Gravsearch query to specify the IRI of the main resource (@github #871 ) (by allowing BIND ). Allow lang to be used with != . A UNION or OPTIONAL can now be nested in an OPTIONAL (@github #882 ). Gravsearch now does type inference (@github #884 ). The Knora API v2 complex schema can now be used in Gravsearch, making it possible to search for list nodes (@github #899 ). Admin API: Make project description required (@github #875 ). Conversion to TEI: Conversion of standard standoff entities to TEI Custom conversion of project specific standoff entities and metadata to TEI Sipi integration: The Knora specific Sipi configuration and scripts can now be found under the sipi/ directory (@github #404 ). Documentation on how Sipi can be started changed (@github #404 ).","title":"New features"},{"location":"DSP-API/09-release-notes/#bugfixes_3","text":"Allow a class or property definition to have more than one object for rdf:type (@github #885 ). Exclude list values from v2 fulltext search (@github #906 ). Gravsearch fixes: Allow the lang function to be used in a comparison inside AND/OR (@github #846 ). Fix the processing of resources with multiple incoming links that use the same property (@github #878 ). Fix the parsing of a FILTER inside an OPTIONAL (@github #879 ). Require the match function to be the top-level expression in a FILTER .","title":"Bugfixes"},{"location":"DSP-API/09-release-notes/#v150-31052018","text":"See v1.5.0 milestone for a full list of closed tickets.","title":"v1.5.0 (31/05/2018)"},{"location":"DSP-API/09-release-notes/#new-features_4","text":"Resources can be returned in the simple ontology schema (#833). Text values can specify the language of the text (#819). Responses can be returned in Turtle and RDF/XML (#851).","title":"New features"},{"location":"DSP-API/09-release-notes/#bugfixes_4","text":"Incorrect representation of IRI object values in JSON-LD (#835) GenerateContributorsFile broken (#797)","title":"Bugfixes"},{"location":"DSP-API/09-release-notes/#v140-30042018","text":"","title":"v1.4.0 (30/04/2018)"},{"location":"DSP-API/09-release-notes/#required-changes-to-existing-data_3","text":"Every ontology must now have the property knora-base:attachedToProject , which points to the IRI of the project that is responsible for the ontology. This must be added to each project-specific ontology in existing repositories. All built-in ontologies have been updated to have this property, and must, therefore, be reloaded into existing repositories. The property knora-base:projectOntology has been removed, and must be removed from project definitions in existing repositories. Every project now needs to have the property knora-base:projectShortcode set.","title":"Required changes to existing data"},{"location":"DSP-API/09-release-notes/#new-features_5","text":"Added OpenAPI / Swagger API documentation route The Knora API server now checks the validity of ontologies on startup. The property knora-base:projectShortcode is now a required property (was optional).","title":"New features"},{"location":"DSP-API/09-release-notes/#bugfixes_5","text":"API v1 extended search was not properly handling multiple conditions on list values (issue #800) Fix image orientation in SALSAH 1 (issue #726)","title":"Bugfixes"},{"location":"DSP-API/09-release-notes/#v131-06042018","text":"","title":"v1.3.1 (06/04/2018)"},{"location":"DSP-API/09-release-notes/#v130-28032018","text":"","title":"v1.3.0 (28/03/2018)"},{"location":"DSP-API/09-release-notes/#required-changes-to-existing-data_4","text":"","title":"Required changes to existing data"},{"location":"DSP-API/09-release-notes/#1-replace-salsah-gui-ontology","text":"You must replace the salsah-gui ontology that you have in the triplestore with the one in salsah-gui.ttl .","title":"1. Replace salsah-gui ontology"},{"location":"DSP-API/09-release-notes/#new-features_6","text":"More support for salsah-gui elements and attributes in ontologies Serve the salsah-gui ontology in API v2 in the default schema. Show salsah-gui:guiElement and salsah-gui:guiAttribute when serving ontologies in API v2 in the default schema. Allow salsah-gui:guiElement and salsah-gui:guiAttribute to be included in new property definitions created via API v2. Change salsah-gui so that GraphDB's consistency checker can check the use of guiElement and guiAttribute . Changes to application.conf . The sipi and web-api sections have received a big update, adding separate settings for internal and external host settings: app { knora-api { // relevant for direct communication inside the knora stack internal-host = \"0.0.0.0\" internal-port = 3333 // relevant for the client, i.e. browser external-protocol = \"http\" // optional ssl termination needs to be done by the proxy external-host = \"0.0.0.0\" external-port = 3333 } sipi { // relevant for direct communication inside the knora stack internal-protocol = \"http\" internal-host = \"localhost\" internal-port = 1024 // relevant for the client, i.e. browser external-protocol = \"http\" external-host = \"localhost\" external-port = 1024 prefix = \"knora\" file-server-path = \"server\" path-conversion-route = \"convert_from_binaries\" file-conversion-route = \"convert_from_file\" image-mime-types = [\"image/tiff\", \"image/jpeg\", \"image/png\", \"image/jp2\"] movie-mime-types = [] sound-mime-types = [] } salsah1 { base-url = \"http://localhost:3335/\" project-icons-basepath = \"project-icons/\" } }","title":"New features"},{"location":"DSP-API/09-release-notes/#bugfixes_6","text":"When API v2 served knora-api (default schema), salsah-gui:guiElement and salsah-gui:guiAttribute were not shown in properties in that ontology. The predicate salsah-gui:guiOrder was not accepted when creating a property via API v2.","title":"Bugfixes"},{"location":"DSP-API/architecture/","text":"C4 Model and ADRs Installation $ brew install adr-tools Usage Run the following command from the root directory to start the C4 model browser: $ make structurizer","title":"C4 Model and ADRs"},{"location":"DSP-API/architecture/#c4-model-and-adrs","text":"","title":"C4 Model and ADRs"},{"location":"DSP-API/architecture/#installation","text":"$ brew install adr-tools","title":"Installation"},{"location":"DSP-API/architecture/#usage","text":"Run the following command from the root directory to start the C4 model browser: $ make structurizer","title":"Usage"},{"location":"DSP-API/architecture/docs/http-request-flow-with-events/","text":"Example for an HTTP Request Flow with Events Create a User sequenceDiagram autonumber user ->> userRoute: \"sends HTTP request\" userRoute ->> userRoute: \"validates input (payload) and creates value objects\" userRoute ->> userHandler: \"sends value objects\" userHandler ->> userRepo: \"reserves username\" userRepo ->> eventStoreService: \"reserves username\" eventStoreService ->> eventStoreService: \"checks if username exists\" eventStoreService ->> eventStoreService: \"reserves username\" userHandler ->> userDomain: \"calls User.make() with value objects\" userDomain ->> userDomain: \"creates userDomainEntity + userCreatedEvent(who, what)\" userDomain ->> userHandler: \"returns (userDomainEntity + userCreatedEvent)\" userHandler ->> userRepo: \"storeUser(userDomainEntity + userCreatedEvent)\" userRepo ->> eventStoreService: \"storeUser(userDomainEntity + userCreatedEvent)\" eventStoreService ->> eventStoreService: \"store event(s), userCreatedEvent(who, what, when(!))\" eventStoreService ->> eventListener: \"publishEvent(userCreatedEvent)\" eventListener ->> triplestoreService: \"writeToTsService(E)\" triplestoreService ->> triplestoreService: \"SPARQL update - write user to triplestore\" eventListener ->> arkService: \"writeToArkService(E)\" arkService ->> arkService: \"create ARK(URL)\" eventListener ->> elasticSearchService: \"writeToEsService(E)\" elasticSearchService ->> elasticSearchService: \"write\"","title":"Http request flow with events"},{"location":"DSP-API/architecture/docs/http-request-flow-with-events/#example-for-an-http-request-flow-with-events","text":"","title":"Example for an HTTP Request Flow with Events"},{"location":"DSP-API/architecture/docs/http-request-flow-with-events/#create-a-user","text":"sequenceDiagram autonumber user ->> userRoute: \"sends HTTP request\" userRoute ->> userRoute: \"validates input (payload) and creates value objects\" userRoute ->> userHandler: \"sends value objects\" userHandler ->> userRepo: \"reserves username\" userRepo ->> eventStoreService: \"reserves username\" eventStoreService ->> eventStoreService: \"checks if username exists\" eventStoreService ->> eventStoreService: \"reserves username\" userHandler ->> userDomain: \"calls User.make() with value objects\" userDomain ->> userDomain: \"creates userDomainEntity + userCreatedEvent(who, what)\" userDomain ->> userHandler: \"returns (userDomainEntity + userCreatedEvent)\" userHandler ->> userRepo: \"storeUser(userDomainEntity + userCreatedEvent)\" userRepo ->> eventStoreService: \"storeUser(userDomainEntity + userCreatedEvent)\" eventStoreService ->> eventStoreService: \"store event(s), userCreatedEvent(who, what, when(!))\" eventStoreService ->> eventListener: \"publishEvent(userCreatedEvent)\" eventListener ->> triplestoreService: \"writeToTsService(E)\" triplestoreService ->> triplestoreService: \"SPARQL update - write user to triplestore\" eventListener ->> arkService: \"writeToArkService(E)\" arkService ->> arkService: \"create ARK(URL)\" eventListener ->> elasticSearchService: \"writeToEsService(E)\" elasticSearchService ->> elasticSearchService: \"write\"","title":"Create a User"},{"location":"DSP-API/architecture/docs/http-request-flow/","text":"HTTP Request Flow V2 vs. V3 V1 / V2 / admin: sequenceDiagram autonumber client ->> route: send http request route ->> authenticator: authenticate user authenticator ->> route: user authenticated route ->> application actor: send message application actor ->> responder manager: forward message responder manager ->> responder: forward message responder ->> responder manager: return result responder manager ->> application actor: forward result application actor ->> route: forward result route ->> client: send http response V3: sequenceDiagram autonumber client ->> route: send http request route ->> authenticator: authenticate user authenticator ->> route: user authenticated route ->> handler: call handler method handler ->> route: return result route ->> client: send result as http response","title":"Http request flow"},{"location":"DSP-API/architecture/docs/http-request-flow/#http-request-flow-v2-vs-v3","text":"V1 / V2 / admin: sequenceDiagram autonumber client ->> route: send http request route ->> authenticator: authenticate user authenticator ->> route: user authenticated route ->> application actor: send message application actor ->> responder manager: forward message responder manager ->> responder: forward message responder ->> responder manager: return result responder manager ->> application actor: forward result application actor ->> route: forward result route ->> client: send http response V3: sequenceDiagram autonumber client ->> route: send http request route ->> authenticator: authenticate user authenticator ->> route: user authenticated route ->> handler: call handler method handler ->> route: return result route ->> client: send result as http response","title":"HTTP Request Flow V2 vs. V3"},{"location":"DSP-APP/","text":"DSP-APP \u2014 Generic user interface of DaSCH Service Platform NOTE: The current DSP-APP version presents the admin view only. This app is a simple user interface for the Data and Service Center for the Humanities DaSCH, which uses the DSP-API server application in the backend. It's a system for annotation and linkage of resources in arts and humanities. DSP-APP implements DSP-JS-LIB to connect with DSP-API . DSP (DaSCH Service Platform) is a software framework for storing, sharing, and working with primary resources and data in the humanities. DSP-APP is free software , released under GNU Affero General Public license. Documentation User guide \u27a1 for latest released version Developer docs \u27a1 for developers Contribution If you would like to contribute to the development of the DSP-APP alongside us, please consult the general DSP contribution guidelines . Documentation / User guidelines We built the user guidelines and developer documentation with MkDocs . Get more information in the appropriate README .","title":"Introduction"},{"location":"DSP-APP/#dsp-app-generic-user-interface-of-dasch-service-platform","text":"NOTE: The current DSP-APP version presents the admin view only. This app is a simple user interface for the Data and Service Center for the Humanities DaSCH, which uses the DSP-API server application in the backend. It's a system for annotation and linkage of resources in arts and humanities. DSP-APP implements DSP-JS-LIB to connect with DSP-API . DSP (DaSCH Service Platform) is a software framework for storing, sharing, and working with primary resources and data in the humanities. DSP-APP is free software , released under GNU Affero General Public license.","title":"DSP-APP &mdash; Generic user interface of DaSCH Service Platform"},{"location":"DSP-APP/#documentation","text":"","title":"Documentation"},{"location":"DSP-APP/#user-guide","text":"\u27a1 for latest released version","title":"User guide"},{"location":"DSP-APP/#developer-docs","text":"\u27a1 for developers","title":"Developer docs"},{"location":"DSP-APP/#contribution","text":"If you would like to contribute to the development of the DSP-APP alongside us, please consult the general DSP contribution guidelines .","title":"Contribution"},{"location":"DSP-APP/#documentation-user-guidelines","text":"We built the user guidelines and developer documentation with MkDocs . Get more information in the appropriate README .","title":"Documentation / User guidelines"},{"location":"DSP-APP/contribution/","text":"How to Contribute to this Project Development server DSP-APP is built with Angular and uses NPM . You have to install the corresponding packages with npm i . Now you have to possibilites to run the application in developer mode: With a local installed DSP-API environment run ng serve or npm run start . If you want to connect to the DSP-API on our test server run ng serve --configuration=test-server or npm run start-with-test-server . Please consider which version of DSP-API is currently running on the test server (see webapi: https://api.test.dasch.swiss/version ). With this solution you will also have access to all the representation files. In both case navigate to http://0.0.0.0:4200/ . The app will automatically reload if you change any of the resource files. Code scaffolding Run ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module . Build Run npm run build to build the app. The build artifacts will be stored in the dist/ directory. Run the command npm run build-prod for a production build. Test The following tests (unit, e2e and lint) are part of the Github Actions (CI) workflow and has to be run successfully before the code can be merged into the main branch. Running unit tests Run npm run test-local to execute the unit tests via Karma on your local computer. Run npm run test-ci to execute the unit tests via Karma without a browser. It is used in the Github Actions (CI) workflow. Running end-to-end tests Run npm run test-e2e-protractor to execute the end-to-end tests via Protractor . Running code linter Run npm run lint-local to execute the lint service via ESLint . This command uses the --fix flag which fixes simple errors like redundant type if you have default value assigned. In the Github Actions (CI) workflow the linter runs as npm run lint-ci . To integrate ESLint with Visual Studio Code, do the following: Install the ESLint extension. Create a task via the Tasks: Configure Task command and select npm: lint-local . In the resulting tasks.json file, configure the problem matcher to be $eslint-stylish . Further help To get more help on the Angular CLI use ng help or go check out the Angular CLI README .","title":"How to contribute"},{"location":"DSP-APP/contribution/#how-to-contribute-to-this-project","text":"","title":"How to Contribute to this Project"},{"location":"DSP-APP/contribution/#development-server","text":"DSP-APP is built with Angular and uses NPM . You have to install the corresponding packages with npm i . Now you have to possibilites to run the application in developer mode: With a local installed DSP-API environment run ng serve or npm run start . If you want to connect to the DSP-API on our test server run ng serve --configuration=test-server or npm run start-with-test-server . Please consider which version of DSP-API is currently running on the test server (see webapi: https://api.test.dasch.swiss/version ). With this solution you will also have access to all the representation files. In both case navigate to http://0.0.0.0:4200/ . The app will automatically reload if you change any of the resource files.","title":"Development server"},{"location":"DSP-APP/contribution/#code-scaffolding","text":"Run ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module .","title":"Code scaffolding"},{"location":"DSP-APP/contribution/#build","text":"Run npm run build to build the app. The build artifacts will be stored in the dist/ directory. Run the command npm run build-prod for a production build.","title":"Build"},{"location":"DSP-APP/contribution/#test","text":"The following tests (unit, e2e and lint) are part of the Github Actions (CI) workflow and has to be run successfully before the code can be merged into the main branch.","title":"Test"},{"location":"DSP-APP/contribution/#running-unit-tests","text":"Run npm run test-local to execute the unit tests via Karma on your local computer. Run npm run test-ci to execute the unit tests via Karma without a browser. It is used in the Github Actions (CI) workflow.","title":"Running unit tests"},{"location":"DSP-APP/contribution/#running-end-to-end-tests","text":"Run npm run test-e2e-protractor to execute the end-to-end tests via Protractor .","title":"Running end-to-end tests"},{"location":"DSP-APP/contribution/#running-code-linter","text":"Run npm run lint-local to execute the lint service via ESLint . This command uses the --fix flag which fixes simple errors like redundant type if you have default value assigned. In the Github Actions (CI) workflow the linter runs as npm run lint-ci . To integrate ESLint with Visual Studio Code, do the following: Install the ESLint extension. Create a task via the Tasks: Configure Task command and select npm: lint-local . In the resulting tasks.json file, configure the problem matcher to be $eslint-stylish .","title":"Running code linter"},{"location":"DSP-APP/contribution/#further-help","text":"To get more help on the Angular CLI use ng help or go check out the Angular CLI README .","title":"Further help"},{"location":"DSP-APP/contribution/docs-documentation/","text":"DSP-APP Documentation This is the DSP-APP documentation, based on MkDocs and published under https://docs.dasch.swiss/latest/DSP-APP/ . Contribute If you would like to add your own contributions to the docs, please read the following information regarding the file structure to ensure you follow the same structure. File structure The documentation consists of three main topics with subordinate themes: index contains all information about the DSP-APP user-guide contains the DSP-APP user guide Index = Introduction: All about login, registration and DSP APP information in general. Project = All about project administration; part of DSP-ADMIN User = All about user administration; part of DSP-ADMIN System = All about system administration; part of DSP-ADMIN Data = All about data management; part of VRE. In the current DSP-APP ADMIN version it's commented out contribution contains all information for people who wants to contribute to DSP-APP Index = How to contribute incl. link to the general DSP contribution guidelines Release Notes = Contains the CHANGELOG file of DSP-APP Images like screenshots and so on have to be stored in assets/images . The mkdocs.yml file is present in the top-level directory of the repo and the source files are in the docs/ folder. Plugins have to be defined in requirements.txt and in the github actions workflow deploy-docs step under EXTRA_PACKAGES . Getting Started To run the documentation locally you'll need Python installed, as well as the Python package manager pip . You can check if you already have these installed by running the following commands from the command line: $ python --version Python 3 .8.2 $ pip --version pip 20 .0.2 from /usr/local/lib/python3.8/site-packages/pip ( python 3 .8 ) MkDocs supports Python versions 3.5, 3.6, 3.7, 3.8, and pypy3. Installing dependencies Install the required packages by running the following command: make docs-install-requirements Running the documentation locally MkDocs comes with a built-in dev-server that lets you preview your documentation as you work on it. Make sure you're in the same directory as the mkdocs.yml (repository's root folder) configuration file, and then start the server by running the following command: $ make docs-serve INFO - Building documentation... INFO - Cleaning site directory [ I 160402 15 :50:43 server:271 ] Serving on http://127.0.0.1:8000 [ I 160402 15 :50:43 handlers:58 ] Start watching changes [ I 160402 15 :50:43 handlers:60 ] Start detecting changes Open up http://127.0.0.1:8000/ in your browser, and you'll see the documentation start page being. In case you need to clean the project directory, run: make docs-clean To get some help about the make commands, run: make help Building the documentation To build the documentation, run: make docs-build Deploying GitHub page On each release of DSP-APP, the documentation is generated by the dsp-docs GitHub repository . Behind the scenes, MkDocs builds the documentation and uses the mkdocs-deploy-gh-pages actions script to deploy them to the gh-pages. That's it!","title":"Docs Documentation"},{"location":"DSP-APP/contribution/docs-documentation/#dsp-app-documentation","text":"This is the DSP-APP documentation, based on MkDocs and published under https://docs.dasch.swiss/latest/DSP-APP/ .","title":"DSP-APP Documentation"},{"location":"DSP-APP/contribution/docs-documentation/#contribute","text":"If you would like to add your own contributions to the docs, please read the following information regarding the file structure to ensure you follow the same structure.","title":"Contribute"},{"location":"DSP-APP/contribution/docs-documentation/#file-structure","text":"The documentation consists of three main topics with subordinate themes: index contains all information about the DSP-APP user-guide contains the DSP-APP user guide Index = Introduction: All about login, registration and DSP APP information in general. Project = All about project administration; part of DSP-ADMIN User = All about user administration; part of DSP-ADMIN System = All about system administration; part of DSP-ADMIN Data = All about data management; part of VRE. In the current DSP-APP ADMIN version it's commented out contribution contains all information for people who wants to contribute to DSP-APP Index = How to contribute incl. link to the general DSP contribution guidelines Release Notes = Contains the CHANGELOG file of DSP-APP Images like screenshots and so on have to be stored in assets/images . The mkdocs.yml file is present in the top-level directory of the repo and the source files are in the docs/ folder. Plugins have to be defined in requirements.txt and in the github actions workflow deploy-docs step under EXTRA_PACKAGES .","title":"File structure"},{"location":"DSP-APP/contribution/docs-documentation/#getting-started","text":"To run the documentation locally you'll need Python installed, as well as the Python package manager pip . You can check if you already have these installed by running the following commands from the command line: $ python --version Python 3 .8.2 $ pip --version pip 20 .0.2 from /usr/local/lib/python3.8/site-packages/pip ( python 3 .8 ) MkDocs supports Python versions 3.5, 3.6, 3.7, 3.8, and pypy3.","title":"Getting Started"},{"location":"DSP-APP/contribution/docs-documentation/#installing-dependencies","text":"Install the required packages by running the following command: make docs-install-requirements","title":"Installing dependencies"},{"location":"DSP-APP/contribution/docs-documentation/#running-the-documentation-locally","text":"MkDocs comes with a built-in dev-server that lets you preview your documentation as you work on it. Make sure you're in the same directory as the mkdocs.yml (repository's root folder) configuration file, and then start the server by running the following command: $ make docs-serve INFO - Building documentation... INFO - Cleaning site directory [ I 160402 15 :50:43 server:271 ] Serving on http://127.0.0.1:8000 [ I 160402 15 :50:43 handlers:58 ] Start watching changes [ I 160402 15 :50:43 handlers:60 ] Start detecting changes Open up http://127.0.0.1:8000/ in your browser, and you'll see the documentation start page being. In case you need to clean the project directory, run: make docs-clean To get some help about the make commands, run: make help","title":"Running the documentation locally"},{"location":"DSP-APP/contribution/docs-documentation/#building-the-documentation","text":"To build the documentation, run: make docs-build","title":"Building the documentation"},{"location":"DSP-APP/contribution/docs-documentation/#deploying-github-page","text":"On each release of DSP-APP, the documentation is generated by the dsp-docs GitHub repository . Behind the scenes, MkDocs builds the documentation and uses the mkdocs-deploy-gh-pages actions script to deploy them to the gh-pages. That's it!","title":"Deploying GitHub page"},{"location":"DSP-APP/contribution/release-notes/","text":"Changelog 10.14.0 (2023-02-17) Enhancements cardinalities: implement cardinalities user workflow (Dev-1615 ) ( #917 ) ( 4f0347a ) Documentation Fix broken links ( #921 ) ( ad368aa ) Maintenance bump js-lib to 8.0.0 ( #923 ) ( f7c4847 ) deps: fix breaking changes from js-lib v8.0.0 ( #918 ) ( f2d14be ) enable publishing docker image arm64 and amd64 architectures (DEV-1701) ( #915 ) ( 65d3120 ) 10.13.0 (2023-02-03) Bug Fixes adapt link to search doc ( #907 ) ( dc294af ) fix disappeared buttons colors (DEV-1686) ( #906 ) ( 9594a6e ) project: disable closing sidenav with esc key (DEV-1687) ( #909 ) ( 1dea40f ) Maintenance fix test logs (DEV-1610) ( #893 ) ( 681fc7a ) make possible to publish manually to DockerHub using GH Actions ( #911 ) ( 5f72fa9 ) ontology editor: restyle ontology editor for cardinalities (DEV-1614) ( #900 ) ( 57b41d9 ) Enhancements zio: add support for new zio routes (DEV-1636) ( #898 ) ( d4e2a94 ) 10.12.1 (2023-01-23) Bug Fixes create-link-resource: fix issue when creating a new linked resource (DEV-1637) ( #899 ) ( cf9008a ) 10.12.0 (2023-01-20) Bug Fixes firefox audio representation (DEV 1553) ( #884 ) ( 420d54f ) fulltext-search: don't allow search queries of less than 3 characters (DEV-1602) ( #890 ) ( 5b6a131 ) ontology: fix old view ontology editor not appearing (DEV-1603) ( #891 ) ( 00ad45e ) project: Prevent adding new data model for deactivated projects (DEV-1582) ( #892 ) ( c5fcc30 ) Enhancements releasenotes: Integrate releasenotes (DEV-1600) ( #895 ) ( 64ef14b ) Maintenance bump JS-LIB to v7.4.10 ( #896 ) ( 775b012 ) deps: bump engine.io from 6.2.0 to 6.2.1 ( #872 ) ( 3e208a5 ) deps: bump json5 from 1.0.1 to 1.0.2 ( #886 ) ( 6064d42 ) deps: bump loader-utils from 2.0.2 to 2.0.4 ( #866 ) ( 2dfaa61 ) 10.11.2 (2023-01-09) Bug Fixes fix gravsearch results infinite loading (DEV-1541) ( #887 ) ( 3c8e1a9 ) ontology: Displaying ontology on click (DEV-1545) ( #882 ) ( 479c1e8 ) Maintenance bump JS-LIB to v7.4.9 ( #888 ) ( 4b958e2 ) header: Logo & favicon (DEV-1574) ( #885 ) ( 384d8ef ) 10.11.1 (2022-12-07) Bug Fixes properties: fixing incoming links bug in compound view (DEV-1493) ( #873 ) ( d606cf0 ) Maintenance bump js-lib to v7.4.8 ( #880 ) ( c412dfd ) project IRI refactor (DEV-1468) ( #862 ) ( d898109 ) representations: move repeated code to a shared service (DEV-1488) ( #869 ) ( c2dcb17 ) text-value-as-string: no longer account for richText gui attribute (DEV-1471) ( #874 ) ( 21f7c6c ) 10.11.0 (2022-11-02) Bug Fixes css: adjust css of form error message (DEV-1458) ( #861 ) ( 54e15d0 ) ontology: list of class properties sometimes not loading correctly (DEV-1435) ( #857 ) ( 302d83b ) Enhancements link-value, search-link-value: add debouncing to search requests (DEV-1463) ( #860 ) ( a49af8e ) result list: Internal links open resource in new window (DEV-1405) ( #855 ) ( 3396701 ) 10.10.2 (2022-10-21) Bug Fixes edit-list-item: only send delete comment request if necessary (DEV-1406) ( #850 ) ( a2bddfc ) list-value: fix payload for API request to update a link value (DEV-1420) ( #854 ) ( e350d21 ) Maintenance deps: bump JS-LIB to 7.4.7 ( #856 ) ( d10f9c4 ) project workspace: Remove grid view from the project workspace (DEV-1318) ( #849 ) ( 1083512 ) replace substr with substring (DEV-1409) ( #853 ) ( 5b94d3b ) 10.10.1 (2022-10-07) Bug Fixes list-info-form: fix project iri generation (DEV-1387) ( #845 ) ( 79c4791 ) Maintenance deps: bump JS-LIB to 7.4.6 ( #847 ) ( 17d3af1 ) 10.10.0 (2022-10-06) Bug Fixes sidenav: sort data models (DEV-1359) ( #841 ) ( 75087b5 ) upload: convert file extensions to lowercase before checking for validity (DEV-1391) ( #844 ) ( 61005c6 ) Maintenance maintain dependencies (DEV-1358) ( #839 ) ( e8c5140 ) update release-please-action to v3 ( #837 ) ( 9b1e7e1 ) upgrade Angular and Material to v14 (DEV-1322) ( #830 ) ( a46609f ) Enhancements add support for Romansh language (DEV-557) ( #840 ) ( 1ec8cff ) forms: Comments are disabled or highlighted to be not saved if there is a invalid or an empty property value (DEV-1124) ( #836 ) ( f5b7abd ) 10.9.1 (2022-09-26) Bug Fixes project: fix route to lists ( #834 ) ( 1d32a03 ) 10.9.0 (2022-09-26) Bug Fixes list-view: refresh list view after a resource is deleted or erased (DEV-1353) ( #828 ) ( c15d87b ) Onto editor 404 error (DEV-1355) ( #831 ) ( e7836a9 ) Ontologies displayed twice (DEV-1325) ( #832 ) ( ba35d6f ) property-form: set the cache after the ontology changes with the new lastModificationDate to prevent 409 http errors ( #824 ) ( 0304943 ) Enhancements lists: read mode project member (DEV-1343) ( #825 ) ( b818288 ) Maintenance update js-lib to v7.4.5 ( #833 ) ( 6d14ca7 ) 10.8.1 (2022-09-14) Bug Fixes make deactivated projects invisible for all except sysadmin (DEV-1261) ( #821 ) ( 88a2cbd ) properties: resolve 409 conflict ( #822 ) ( bf0ed83 ) 10.8.0 (2022-09-09) Bug Fixes audio: download audio file with original filename ( #810 ) ( 8001fab ) int-value: fix int-value validation (DEV-1277) ( #815 ) ( d86dc7b ) ontology: don't show 403 error is user is a system admin or project admin and not a project member ( #816 ) ( ffe00c0 ) resource: fix properties sorting (DEV-1204) ( #818 ) ( fbee603 ) resource: reinit representationsToDisplay array to fix undefined issue in template ( #813 ) ( 375166a ) rollbar fixes (DEV-1324) ( #817 ) ( e79eee5 ) Enhancements document: document viewer for non-pdf documents (DEV-1303) ( #812 ) ( 36008c6 ) Maintenance deps: bump js-lib to 7.4.4 ( #820 ) ( 57e3ccf ) deps: bump js-lib version to 7.4.3 ( #814 ) ( c97c569 ) upload: use file extensions for valid file types instead of MIME types (DEV-1203) ( #808 ) ( 448e783 ) Documentation Add documentation about the different file types and their functionalities ( #804 ) ( 8c64276 ) Reorganise the main menu and the data menu ( #807 ) ( f8ef81d ) 10.7.0 (2022-08-24) Enhancements list-value: show hierarchy of list node (DEV-1092) ( #805 ) ( 26e88c3 ) 10.6.0 (2022-08-19) Bug Fixes list: hide title ( #801 ) ( 19fcaba ) Documentation Update the section Linkage and annotation ( #802 ) ( 5f4d52f ) Enhancements ontology: ontology editor read mode (DEV-1183) ( #799 ) ( 02b5a48 ) video: add download button and overlay to video player (DEV-1151) ( #798 ) ( ac06f6b ) Maintenance file-representation: add credentials to all file download requests ( #803 ) ( b247f85 ) 10.5.0 (2022-08-15) Bug Fixes login-form: keep user on same page after login (DEV-1158) ( #788 ) ( 9ec6870 ) notification: fix snackbar notification only appearing for a split second ( #794 ) ( 110039d ) resource view: dsp app the resource viewer does not reload properly after deselecting a resource from the comparison viewer(Dev-1123) ( #793 ) ( f690a37 ) Enhancements archive: new archive representation view (DEV-1084) ( #785 ) ( db40310 ) audio: Make changes to audio component (DEV-1148) ( #796 ) ( 0cabfe3 ) document: changes to pdf viewer (DEV-1149) ( #789 ) ( d39ed14 ) document: make changes to text component (DEV-1147) ( #791 ) ( e8adde9 ) projects: changes to nav bar (DEV-1101) ( #790 ) ( d9570b9 ) still-image: new still-image viewer (DEV-1150) ( #792 ) ( 2eccd8a ) Maintenance file-representations: adjust styling of file representation components ( #797 ) ( 18aa134 ) 10.4.3 (2022-07-29) Bug Fixes property-form: only send API request to change the guiElement for TextValue object types ( #783 ) ( 109ca05 ) 10.4.2 (2022-07-28) Bug Fixes package.json & package-lock.json to reduce vulnerabilities ( #775 ) ( 064a7dc ) Maintenance deps: bump moment from 2.29.2 to 2.29.4 ( #774 ) ( 2831255 ) login-form: don't redirect user if they are a member of only one project AND they are a sysAdmin ( #782 ) ( 1a103ba ) 10.4.1 (2022-07-28) Maintenance routing: home button should direct to overview page (DEV-1152) ( #779 ) ( d3011ae ) 10.4.0 (2022-07-27) Enhancements overview: add overview and project tile components (DEV-984) ( #777 ) ( a64359b ) 10.3.3 (2022-07-19) Documentation Update the user guide (DEV-1049) ( #769 ) ( 12d0edc ) 10.3.2 (2022-06-30) Bug Fixes date-value-handler: add some null checks to ensure component has everything it needs before trying to use a property ( #771 ) ( 4076f3e ) Maintenance deps: bump version of js-lib ( #773 ) ( 9a5252d ) 10.3.1 (2022-06-23) Bug Fixes link-value: add onto iri to api request ( #770 ) ( d16e5b5 ) update broken links of the main README file ( #767 ) ( a3408f6 ) 10.3.0 (2022-06-16) Bug Fixes docs: resolve dead links to documentation ( #764 ) ( 9c83b7e ) link-value: loop through all ontologies of a project to create list of resource classes ( #766 ) ( 7c824bf ) Maintenance change codeowner before I leave ( #762 ) ( 5884f51 ) link-value: recursively loop through all of a superclass's subclasses ( #763 ) ( 5efed72 ) Enhancements project: proof of new project workflow concept (DEV-1001) ( #765 ) ( fb29253 ) project: proof of new project workflow concept (DEV-985) ( #760 ) ( 2391f2a ) resource: create new resource instance directly from ontology's class (DEV-959) ( #755 ) ( 5f30719 ) 10.2.0 (2022-06-02) Bug Fixes ontology: check if value exists without refreshing the page (DEV-923) ( #756 ) ( 3c2409a ) user: bring back password field and resolve loading issue (DEV-967) ( #753 ) ( 694cb06 ) Maintenance form: replace matAutosize by cdkAutosize (DEV-968) ( #754 ) ( 449493b ) Enhancements list: add support for deleting child node comments (DEV-965) ( #758 ) ( 50c2d17 ) text-file: add support for text file representations (DEV-920) ( #751 ) ( 84975d7 ) value: improve list value (DEV-951) ( #757 ) ( 4d9b747 ) 10.1.0 (2022-05-23) Bug Fixes representation: resolve timeline issue when resizing window (DEV-819) ( #741 ) ( da985fc ) Maintenance classes: sort resource classes by label (DEV-952) ( #748 ) ( e060cce ) resource: display incoming links the same way as prop values (DEV-567) ( #747 ) ( 7d2f6f3 ) Enhancements resource: open annotation (region) the correct way (DEV-785) ( #749 ) ( 3983f9b ) resource: open resource instances from ontology class (DEV-950) ( #746 ) ( e937b5f ) 10.0.0 (2022-05-18) \u26a0 BREAKING CHANGES representation: new navigation in still-image viewer (DEV-895) (#742) Bug Fixes error: resolve error handler issues (DEV-938) ( #744 ) ( ceebf7b ) ontology: unsupported property type was displayed wrong (DEV-936) ( #740 ) ( 87124e9 ) Maintenance message: use only one static error component (DEV-900) ( #727 ) ( 404f1f6 ) project: resolve issues in lists and with status 204 ( #738 ) ( 52f904b ) Enhancements error: add file representation error message (DEV-791) ( #729 ) ( 462771e ) error: handle 504 timeout error with snackbar (DEV-751) ( #739 ) ( 8f6c409 ) hint: display hint about fulltext search (DEV-901) ( #734 ) ( f54dafc ) link-value: UI now shows that there are no search results ( #736 ) ( 88b81bf ) ontology: select link class from all ontologies (DEV-688) ( #737 ) ( 8dcdd8f ) representation: new navigation in still-image viewer (DEV-895) ( #742 ) ( dbc75ff ) 9.8.1 (2022-05-09) Bug Fixes representation: disable progress indicator correctly (DEV-905) ( #730 ) ( 92efbeb ) 9.8.0 (2022-05-05) Bug Fixes ontology-editor: bring back the gui-attr for pulldown (DEV-856) ( #719 ) ( 0c2a43d ) resource: show progress indicator until whole resource is loaded (DEV-638) ( #725 ) ( 946af20 ) Maintenance clean up jsDocs and delete deprecated methods (DEV-741) ( #722 ) ( 8457119 ) ontology: crop loooong ontology labels (DEV-493) ( #723 ) ( 1b7384f ) Enhancements ontology: add properties to a class from other ontologies (DEV-689 / DEV-880) ( #721 ) ( b90fc70 ) 9.7.0 (2022-04-22) Bug Fixes package.json & package-lock.json to reduce vulnerabilities ( #714 ) ( 0e90296 ) text-value-as-string: links in text values (DEV-797) ( #718 ) ( af3cdc2 ) Maintenance deps: bump async from 2.6.3 to 2.6.4 ( #716 ) ( c77c208 ) Enhancements representation: implement video player incl. preview (DEV-701) ( #698 ) ( 86fc2a7 ) 9.6.0 (2022-04-13) Bug Fixes create-link-value: bring back functionality to create a new link resource instance when adding a new value to a linked resource class property ( #709 ) ( c6fe803 ) link-value: re-validate form when cancel button is clicked ( #711 ) ( 7768fb9 ) ontology: display all classes in a property (DEV-564) ( #701 ) ( f90aedc ) package.json & package-lock.json to reduce vulnerabilities ( #704 ) ( 5d4bb7c ) region: highlight info of clicked region (DEV-724) ( #703 ) ( 2d98369 ) resource-instance-form: disable \"next\" button when form is not valid (DEV-803) ( #713 ) ( 124b953 ) Enhancements link-value: add progress indicator (DEV-605) ( #708 ) ( 5efd981 ) link-value: enter newly created value automatically ( #710 ) ( 5ccd18d ) resource: upload video (DEV-204) ( #577 ) ( 29201d4 ) Maintenance gh-ci: add style to the release notes ( #706 ) ( 8e9e143 ) help: update support links (DEV-779) ( #700 ) ( d97113f ) resource: display class label of incoming link (DEV-568) ( #702 ) ( aad1c5a ) use constants from js-lib directly (DEV-799) ( #712 ) ( 374b5a8 ) 9.5.0 (2022-04-04) Bug Fixes mkdocs: update version of mkdocs ( #696 ) ( e154fa3 ) Enhancements replace-file: Replace Uploaded Files (DEV-684) ( #695 ) ( df9de8c ) 9.4.0 (2022-03-23) Bug Fixes help: refactor version number and fix dead link (DEV-678) ( #693 ) ( e255ac9 ) Enhancements resource-instance: add subclass creation support (DEV-553) ( #686 ) ( d0a260d ) still-image: IIIF URL copy button (DEV-524) ( #690 ) ( b0d72a6 ) still-image: new draw region icon (DEV-569) ( #689 ) ( bee5caf ) Maintenance clean up code, tests and packages ( #694 ) ( 1ad0879 ) deps: bump node-forge from 1.2.1 to 1.3.0 ( #692 ) ( cf58030 ) 9.3.0 (2022-03-21) Bug Fixes error: display 500 server error when the api is not healthy (DEV-475) ( #673 ) ( b374a3b ) gravsearch: cleanse gravsearch date query ( #681 ) ( a0f34ce ) gravsearch: fix list value restriction (DEV-486) ( #682 ) ( 1eccfc0 ) permission-info: close permission info on scrolling (DEV-552) ( #671 ) ( 8ac1d25 ) value: do not use linkify in text value as html (DEV-563) ( #683 ) ( 3b159b5 ) Enhancements advanced-search: support subclasses in cross-resource query ( #685 ) ( fde5d99 ) archive-value: Download archive files with original filename (DEV-295) ( #677 ) ( a87dfae ) ontology: adjust tooltip text when property is inherited (DEV-323) ( #674 ) ( d3a1e49 ) Maintenance deps-dev: bump karma from 6.3.14 to 6.3.16 ( #678 ) ( df0ef65 ) deps: bump angular to version 13 (DEV-631) ( #679 ) ( a7d2098 ) deps: bump js-lib to latest (DEV-669) ( #687 ) ( b4836b8 ) deps: bump url-parse from 1.5.7 to 1.5.10 ( #676 ) ( 150e8ae ) dockerfile: add dependabot config to keep base image up-to-date (INFRA-13) ( #670 ) ( 485a57e ) error: use error handler everywhere (DEV-475) ( #688 ) ( eabfa64 ) value: remove old date value components (DEV-633) ( #684 ) ( 76233ea ) 9.2.1 (2022-02-21) Bug Fixes permission-info: better permission string handling (DEV-537) ( #667 ) ( 8be1efe ) resource: resource viewer is broken if fileRepresentation has restricted view (DEV-455) ( #666 ) ( 6a360ac ) still-image: fix image displayed as black square (DEV-525) ( #668 ) ( 33833f6 ) Maintenance deps: bump url-parse from 1.5.4 to 1.5.7 ( #664 ) ( 54a348f ) rollbar: add environment to the config ( #669 ) ( 8a587b9 ) 9.2.0 (2022-02-17) Bug Fixes ontology-editor: display sub-properties the correct way (DEV-530) ( #661 ) ( a2cf6e0 ) Enhancements resource: display permissions (DEV-454) ( #660 ) ( 13a3a49 ) 9.1.0 (2022-02-15) Enhancements add-link-resource-button: Add Link Resource Button (DEV-404) ( #645 ) ( f762c3c ) Maintenance deps-dev: bump karma from 6.3.13 to 6.3.14 ( #653 ) ( 1794e47 ) deps: bump follow-redirects from 1.14.7 to 1.14.8 ( #656 ) ( 8554764 ) google fonts: switches back to self hosting google fonts ( #654 ) ( 938721b ) open-sea-dragon: updates package to v3.0.0 ( #658 ) ( 42bffa6 ) 9.0.1 (2022-02-09) Bug Fixes main: bug fix in configuration file in case of prod mode (DEV-491) ( #651 ) ( a6c9e87 ) 9.0.0 (2022-02-02) \u26a0 BREAKING CHANGES display dsp release number (DEV-420) (#644) Bug Fixes ontology: support subproperty in ontology editor (DEV-332) ( #643 ) ( c838043 ) Enhancements display dsp release number (DEV-420) ( #644 ) ( b6c9f1c ) Maintenance deps: bump log4js from 6.3.0 to 6.4.1 ( #648 ) ( dd2eebe ) deps: bump nanoid from 3.1.30 to 3.2.0 ( #647 ) ( 13c6f2a ) deps: update packages ( #650 ) ( cc60b0b ) 8.5.0 (2022-01-19) Bug Fixes project: better project form validation (DEV-336) ( #641 ) ( a7563a3 ) Maintenance angular: optimize ng s in dev mode ( #640 ) ( 9812b9c ) deps: fix security vulnerability ( #638 ) ( f19434e ) Enhancements ontology: support partOf value to create book res class (DEV-180) ( #634 ) ( 3051a67 ) 8.4.0 (2022-01-17) Bug Fixes advanced search: update comparison operators in case of rich text (DEV-326) ( #633 ) ( cd01d87 ) archive representation: a resource with an archive representation now loads correctly again ( #630 ) ( 299ecf9 ) date-value: do not submit in case of period button (DEV-373) ( #635 ) ( d7ac1b6 ) Maintenance clean up after bump dsp-js ( #628 ) ( 374fc78 ) ontology: clean up unused code (DEV-304) ( #629 ) ( 3d029a1 ) Enhancements resource: display deleted resource (DEV-299) ( #632 ) ( 2c5fd80 ) 8.3.3 (2022-01-04) Bug Fixes resource: bug fix in pdf viewer (DEV-338) ( #626 ) ( 4b5d5d5 ) 8.3.2 (2021-12-16) Bug Fixes authentication: set active datadog rum user (DEV-325) ( #624 ) ( 69308e0 ) 8.3.1 (2021-12-15) Bug Fixes upload: fix thumbnail preview (DEV-268) ( #619 ) ( 7cb8505 ) Maintenance authentication: new login / logout structure (DEV-325) ( #622 ) ( e8bec98 ) fonts: delete fonts and icons (DEV-327) ( #623 ) ( 08e088b ) google fonts: switch to using fonts hosted by google ( #620 ) ( daa4167 ) 8.3.0 (2021-12-09) Bug Fixes resource: update lastModificationDate after editing label (DEV-315) ( #616 ) ( 3b9d93b ) Enhancements still-image: display iiif url under the image caption (DEV-243) ( #613 ) ( 109978f ) Maintenance metadata: remove \"old\" implementation of the project metadata (DEV-282) ( #615 ) ( 29acf3a ) 8.2.0 (2021-12-08) Bug Fixes ontology: bug fix in ontology form (DEV-280) ( #603 ) ( 4c1bc24 ) resource: create resource iri from route only in certain cases (DEV-306) ( #605 ) ( a38abd0 ) value: fix linkify pipe (DEV-270) ( #602 ) ( f2c8d7a ) Enhancements representation: add support for uploading and viewing archive files (DEV-18) ( #600 ) ( 9bb63d7 ) Maintenance deps: update outdated angular packages ( #604 ) ( 80b3f93 ) deps: use correct nginx-server (DEV-263) ( #610 ) ( ccae958 ) angular: fix budget in prod mode ( #606 ) ( 5072948 ) 8.1.2 (2021-12-01) Maintenance lists: adds changes required for lists to work due to the change in js-lib ( #599 ) ( ca83584 ) projects: don't use the cache when refreshing the projects list. Also renames some labels and methods to clarify that these things are for deactivating a project as opposed to deleting a project. ( #597 ) ( faebe3e ) 8.1.1 (2021-11-19) Bug Fixes results: display xml a better way (DEV-96) ( #593 ) ( d968f2f ) value: bug fix in text-value-as-string (DEV-242) ( #595 ) ( 0fb95ee ) 8.1.0 (2021-11-18) Bug Fixes fulltext-search: updates the projects list when a new project is created (DEV-212) ( #586 ) ( 43fcbfa ) ontology: resolve gui order issue (DEV-222) ( #590 ) ( 4ddbf7c ) ontology: send modified label (DEV-221) ( #589 ) ( 9d7ffea ) text-value: resource-instance-form and display-edit components now correctly display a paragraph text with line breaks (DEV-211) ( #584 ) ( be9d6f4 ) Maintenance deps: update angular to v12 ( #588 ) ( 37e65a8 ) Enhancements properties: ckEditor Internal Links (DEV-118) ( #591 ) ( cac988b ) update UI on region color change (DEV-215) ( #583 ) ( b497d0e ) 8.0.0 (2021-11-10) \u26a0 BREAKING CHANGES resource: new resource route (DEV-196) (#581) Maintenance small code improvements ( #579 ) ( d19e353 ) Enhancements resource: add additional routing for an ark url of a value (DEV-196) ( #575 ) ( c1b0b94 ) resource: new resource route (DEV-196) ( #581 ) ( 3fbd94c ) still-image: uses the color of the color property for the line color if a color property for the region exists ( #580 ) ( 7680353 ) 7.0.1 (2021-11-05) Bug Fixes error: resolve error handler in case of server error (DEV-205) ( #576 ) ( ff9d097 ) ontology: class and property name has to be unique (DEV-183) ( #569 ) ( 059dd2a ) value: display ckEditor in case of rich-text property (DEV-182) ( #571 ) ( 6bfe254 ) Maintenance annotations will now only be drawn when the user is on the annotations tab ( #574 ) ( bddc2f1 ) deps: use release of ckeditor custom build (DEV-189) ( #570 ) ( fb55fd7 ) main: use version route (DEV-124) ( #565 ) ( 16f26ce ) move datadog rum methods to service (DEV-190) ( #572 ) ( 77191cb ) refactors upload-file service to use the string generated in the iiif-config file and changes the public class members in app-init service to private with getters. ( #573 ) ( c39ca5b ) 7.0.0 (2021-10-28) \u26a0 BREAKING CHANGES error logging: rollbar implementation (DEV-20) (#543) Bug Fixes ontology: use correct label (DEV-168) ( #564 ) ( 70cc7d8 ) Maintenance gh: update issue templates ( #562 ) ( 6d510c7 ) Enhancements error logging: rollbar implementation (DEV-20) ( #543 ) ( d0a9e3f ) 6.5.0 (2021-10-21) Enhancements ontology: bring back the name input field (DEV-157) ( #559 ) ( 51e539d ) 6.4.1 (2021-10-20) Bug Fixes value: fix boolean value issue ( #557 ) ( 4d35cd2 ) Maintenance deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #556 ) ( 5f8213c ) 6.4.0 (2021-10-20) Enhancements ontology: delete property from resource class (DSP-1854 / DEV-28) ( #499 ) ( 436c270 ) value: refactor boolean value (DEV-98) ( #554 ) ( 7affa5e ) 6.3.0 (2021-10-15) Bug Fixes disable edit/delete action in deactivated projects (DEV-52) ( #550 ) ( d7bec78 ) properties: do not submit res instance form by adding new value (DEV-150) ( #553 ) ( 99a3022 ) value: fix broken time value component (DEV-147) ( #552 ) ( fb846f9 ) Enhancements datadog RUM implementation (DEV-50) ( #546 ) ( ec59ee5 ) resource: new date picker (DEV-112) ( #532 ) ( 04e4b32 ) 6.2.0 (2021-10-08) Bug Fixes error: improve the current error handler in DSP-APP (DSP-1911) ( #540 ) ( 0eb621b ) gravsearch results now appear after page refresh ( #542 ) ( a88dd79 ) resource-instance-form: reloads cached resource to show changes made to the data model ( #547 ) ( 37bb2a7 ) Enhancements ontology: display id / name in property and class (DEV-37) ( #544 ) ( 0a2bcfb ) search: add missing search resource component (DEV-95) ( #548 ) ( 79abd10 ) Maintenance fulltext-search: persist fulltext search term in input field (DSP-1674) ( #539 ) ( 67a52a3 ) resource: improve still image annotation form (DEV-53) ( #549 ) ( 38bbe41 ) 6.1.0 (2021-09-20) Bug Fixes annotations: empty annotations on upload of new region ( #536 ) ( 075e6b1 ) links: trust the external links (DSP-1904) ( #537 ) ( 303ac3d ) resource-instance-form: resource class name now updates correctly in the event that the name was changed and the page was not refreshed ( #531 ) ( 5783d27 ) resource: increase width of space between entries of incoming links (DSP-1908) ( #538 ) ( 79b4d29 ) still-image-viewer: fix zoom buttons (DSP-1798) ( #533 ) ( b07ec63 ) Enhancements resource: draw regions (DSP-1845) ( #524 ) ( f08706b ) textarea is now provided is the gui-element is a textarea ( #529 ) ( e80a4d2 ) Maintenance modules: clean up imports and npm packages ( #535 ) ( 4310ff7 ) openseadragon prod build fix (DSP-1779) ( #534 ) ( 0a34eaa ) 6.0.0 (2021-09-08) \u26a0 BREAKING CHANGES config: update config file for better iiif support (DSP-1880) (#511) Bug Fixes audio: sanitize audio url (DSP-1819) ( #513 ) ( 35871cd ) deps: fix security vulnerability ( #514 ) ( d793fb8 ) Enhancements config: update config file for better iiif support (DSP-1880) ( #511 ) ( b799600 ) resource: display incoming links (DSP-1846) ( #507 ) ( 9c3abce ) resource: optimize resource instance form (DSP-1256) ( #518 ) ( 5151677 ) Maintenance action: migrate action module (DSP-1852) ( #509 ) ( 725c45e ) core: migrate core module from UI-lib (DSP-1853) ( #505 ) ( ea1cd55 ) deps: bump dsp-js to latest version (DSP-1883) ( #521 ) ( c956d4b ) deps: bump dsp-ui to latest ( #502 ) ( 5d79065 ) fix style in resource, search-panel and progress-indicator (DSP-1887) ( #520 ) ( 854aff2 ) gh-ci: split workflow tasks ( #515 ) ( 83d5874 ) login: add autocomplete to login form (DSP-1892) ( #527 ) ( dd6be15 ) project: handle mandatory keyword field (DSP-1829) ( #503 ) ( 35f6e7b ) remove CoreModule dependency (DSP-1884) ( #519 ) ( 8549104 ) remove ViewerModule dependency (DSP-1890) ( #525 ) ( a99546e ) removes ActionModule dependency ( #523 ) ( bd60f00 ) removes SearchModule dependency ( #522 ) ( 269be23 ) resource: migrate viewer from UI-lib (DSP-1850) ( #504 ) ( b742a98 ) search: migrate search module (DSP-1851) ( #510 ) ( fc7ea5c ) update imports step 1 (DSP-1882) ( #516 ) ( e7a2c4f ) update remaining dsp-ui imports (DSP-1891) ( #526 ) ( 43888a6 ) 5.3.0 (2021-08-12) Maintenance header: clean up code and use notification service after login ( #498 ) ( fb6c368 ) ontology: update create ontology tooltip for unique name (DSP-1139) ( #500 ) ( 946d00f ) Enhancements resource: create link / collection resource (DSP-1835) ( #501 ) ( 8060756 ) workspace: add intermediate view (DSP-1834) ( #494 ) ( d0e475a ) 5.2.1 (2021-08-03) Maintenance deps: bump dsp-ui to latest version (DSP-1838) ( #495 ) ( 4adc49a ) 5.2.0 (2021-08-02) Enhancements resource: add comparison view (DSP-1796) ( #490 ) ( 731ea04 ) resource: update resource's label (DSP-1801) ( #492 ) ( e2c9867 ) improve error handler and fix search results issue (DSP-1826 / DSP-1831) ( #493 ) ( fa2f4b0 ) 5.1.0 (2021-07-26) Bug Fixes ontology: fix regex pattern in ontology form (DSP-1139) ( #483 ) ( 4d0703f ) Documentation user-guide: update user-guide about ontology (DSP-976) ( #480 ) ( e12f196 ) Maintenance ontology: better regex for onto name (DSP-1139) ( #488 ) ( ec881ef ) resource: hide file value in properties (DSP-1261) ( #484 ) ( 4ade17f ) Enhancements resource: add document viewer with download (DSP-1791) ( #485 ) ( ce51bce ) resource: audio player (DSP-1805) ( #487 ) ( bf372dc ) resource: delete and erase resource (DSP-1228) ( #489 ) ( 8b1fdba ) resource: upload audio (DSP-1799) ( #486 ) ( d865df5 ) resource: upload pdf document (DSP-1776) ( #481 ) ( d916b4b ) 5.0.0 (2021-07-05) \u26a0 BREAKING CHANGES upload: add upload form for still images (DSP-1761) (#472) config: add geoname config (DSP-1672) (#473) Documentation ontology: update docs and show hint in ontology-form (DSP-1139) ( #476 ) ( 927237d ) Enhancements config: add geoname config (DSP-1672) ( #473 ) ( d4222ba ) ontology: add property to res class that is in use (DSP-1631) ( #477 ) ( b18e6ec ) ontology: change gui element for text value properties ( #478 ) ( 6af1f7e ) ontology: display description for default and existing props (DSP-1154) ( #475 ) ( 8be7e55 ) upload: add upload form for still images (DSP-1761) ( #472 ) ( 2f314a2 ) Maintenance deps: bump jdnconvertiblecalendar to v0.0.7 (DSP-1770) ( #479 ) ( b2ec64a ) 4.11.1 (2021-06-23) Documentation search: add advanced search user guide (DSP-1662) ( #470 ) ( 30edc96 ) user-guide: fix navigation links ( #468 ) ( 49c68f8 ) Maintenance fix dead links to the documentation ( #471 ) ( d7ae022 ) 4.11.0 (2021-06-22) Enhancements ontology: check if an ontology, a class or a property can be deleted (DSP-1750) ( #457 ) ( fb0c275 ) Maintenance empty landing page instead login (DSP-1756) ( #466 ) ( 32cd462 ) gh-ci: update docs deployment (DSP-1741) ( #463 ) ( 6415152 ) Documentation refactor documentation and set correct links ( #467 ) ( cbeb274 ) 4.10.1 (2021-06-15) Documentation fix dead links and replace screenshots in project ( #460 ) ( a13b8ba ) prepare documentation for docs.dasch.swiss (DSP-1721) ( #458 ) ( 09259f1 ) Maintenance analytics: add fathom ( #462 ) ( f1e0244 ) cookie-policy: reactivate the cookie policy banner (DSP-1727) ( #461 ) ( ac99fbc ) 4.10.0 (2021-06-07) Enhancements ontology: new cardinality workflow (DSP-1652) ( #455 ) ( f1d049c ) 4.9.1 (2021-05-26) Maintenance resource: improve list of properties in resource viewer ( #453 ) ( 49d9b7f ) 4.9.0 (2021-05-26) Bug Fixes disable progress bar if search results are empty (DSP-1575) ( #442 ) ( 8c67d60 ) resource: add if condition (DSP-1655) ( #448 ) ( 656da04 ) Documentation update documentation about contribution (DSP-1657) ( #449 ) ( c25280d ) Enhancements resource: display region annotations in still images (DSP-1585) ( #445 ) ( 86e75b9 ) search: specify linked resource in advanced search (DSP-1661) ( #451 ) ( 3f0d6d9 ) Maintenance deps: update packages to resolve security issues ( #450 ) ( 8e927f7 ) project: resolve regex term (DSP-1654) ( #444 ) ( 739beba ) 4.8.0 (2021-05-21) Maintenance CD/CI: automatically detect common vulnerabilities and coding errors ( #438 ) ( af02332 ) compiler: enable strict template (DSP-1403) ( #432 ) ( 583a338 ) environment: add test-server config (DSP-1650) ( #443 ) ( a56a45b ) Replace favicon and term Knora by DSP (DSP-1181 / DSP-1342) ( #441 ) ( 3b038b6 ) Enhancements ontology: new method to change gui order (DSP-1567/DSP-1646) ( #440 ) ( dfd0ce0 ) 4.7.0 (2021-05-07) Maintenance search results: disable grid view (DSP-1597) ( #435 ) ( c4726fe ) Enhancements DMP: own resource viewer (DSP-1586) ( #434 ) ( 35bd7b3 ) 4.6.0 (2021-04-27) Enhancements DMP: bring back the workspace ( #431 ) ( e8b1c8e ) 4.5.2 (2021-04-22) Bug Fixes list: list no longer displays after deletion if it was the only list among lists ( #429 ) ( b05484e ) project: bug fix in project member management (DSP-1563) ( #425 ) ( ac820dd ) Maintenance ontology: disable ontology graph view (DSP-1560) ( #427 ) ( 0a567d2 ) ontology: disable rti image class (DSP-1559) ( #430 ) ( 48c3c76 ) ontology: rename boolean prop type (DSP-1561) ( #426 ) ( 4dd23d3 ) 4.5.1 (2021-04-20) Bug Fixes ontology: bug fix in create ontology process (DSP-1558) ( #423 ) ( bbd825b ) 4.5.0 (2021-04-20) Bug Fixes users: update session the correct way (DSP-690) ( #419 ) ( 3ec049e ) Enhancements project: better error handler in case a project does not exist (DSP-1401) ( #421 ) ( d7470a0 ) 4.4.3 (2021-04-14) Bug Fixes ontology: Bug fix in ontology form ( #417 ) ( 96dc804 ) 4.4.2 (2021-04-12) Maintenance migrate to angular11: changes (DSP-1471) ( #415 ) ( 3271ece ) 4.4.1 (2021-04-08) Maintenance migrate to angular10: changes (DSP-1415) ( #412 ) ( cec564d ) 4.4.0 (2021-03-23) Bug Fixes deps: package dependency build errors (DSP-1400) ( #410 ) ( 17e0e1a ) Maintenance list-editor: new list form refactor (DSP-1392) ( #403 ) ( 8824682 ) ontology: improve ontology editor design (DSP-1376) ( #401 ) ( 6de83b8 ) project landing page: update metadata typings (DSP-1393) ( #407 ) ( b4f101b ) project metadata page: enable error handler ( #411 ) ( a4004ed ) Enhancements eslint: migrate tslint to eslint (DSP-1372) ( #394 ) ( 6ffc3b6 ) ontology: edit data model info (DSP-1208) ( #385 ) ( 86a5fb8 ) ontology: form to create and edit property (DSP-1210) ( #406 ) ( 91ebb68 ) 4.3.1 (2021-03-03) Bug Fixes project: disable error handler in metadata request (DSP-1395) ( #404 ) ( 86ebfcf ) 4.3.0 (2021-03-02) Bug Fixes ontology: set the cache earlier in case of only one ontology (DSP-1374) ( #397 ) ( c23ae61 ) Enhancements list-editor: insert a child node at a specific position (DSP-1301) ( #395 ) ( 5107200 ) ontology: separate list of ontology properties (DSP-1364) ( #391 ) ( 0f94df6 ) Maintenance deps: bump three from 0.118.3 to 0.125.0 ( #402 ) ( 5ab9c49 ) gh-ci: update release please configuration (DSP-1381) ( #399 ) ( 040df19 ) project landing page: use metadata endpoint to get data from backend (DSP-1199) ( #400 ) ( 5dde42f ) tests: script to find ignored tests ( #396 ) ( 9ca249d ) 4.2.1 (2021-02-24) Bug Fixes ontology: bug fix in list property (DSP-1368) ( #390 ) ( 2fb448e ) 4.2.0 (2021-02-22) Enhancements list-editor: add deletion functionality (DSP-1334) ( #378 ) ( 34c74a6 ) list-editor: delete list root node (DSP-1356) ( #386 ) ( 5d5eabf ) list-editor: reposition a child node amongst its siblings (DSP-1340) ( #388 ) ( 0a9be0e ) ontology: default language for property label ( #382 ) ( 97230d1 ) ontology: edit res class info (DSP-1209) ( #380 ) ( 2debd03 ) ontology: refactor list of properties in resource class (DSP-1360) ( #389 ) ( aa565b3 ) 4.1.0 (2021-02-12) Documentation init mkdocs and move documentation from DSP-DOCS into DSP-APP repo (DSP-380) ( #379 ) ( 07f5067 ) Maintenance bumps DSP-JS to 1.3.0 and DSP-UI to 1.2.1 ( #374 ) ( 7b795ee ) deps: bump socket.io from 2.3.0 to 2.4.1 ( #367 ) ( 8133d87 ) Enhancements list editor: Adds support for editing lists (DSP-741) ( #365 ) ( 5b6ee4b ) ontology: update cardinality in resource class (DSP-1266) ( #377 ) ( 5a766c1 ) 4.0.0 (2021-01-28) \u26a0 BREAKING CHANGES set up the login page as a starting page (DSP-1292) (#370) app+main: comment out the search and everything related to resources (DSP-1291) (#371) Bug Fixes dialog: Diaolog box height issue fixed ( #358 ) ( 15d1182 ) routing: bring back the route handler in main component (DSP-1303) ( #373 ) ( 8492c1a ) Maintenance update pr template (DSP-1189) ( #353 ) ( f348e70 ) update the dsp-ui and dsp-js versions to the latest ( #364 ) ( 66931f0 ) Enhancements display metadata on project landing page (DSP-1065) ( #348 ) ( 3012ef5 ) error: Server error handler (DSP-710) ( #355 ) ( d5b77bf ) new-resource-form: make visible the required prop fields (DSP-1115) ( #342 ) ( 5885b04 ) project landing page: add copy to clipboard functionality (DSP-1248) ( #368 ) ( 17bf71c ) select-resource-class: allow accented character (DSP-1241) ( #363 ) ( 8a2654b ) refactor app+main: comment out the search and everything related to resources (DSP-1291) ( #371 ) ( 50b1309 ) set up the login page as a starting page (DSP-1292) ( #370 ) ( 46dfdbb ) 3.0.0 (2020-12-18) \u26a0 BREAKING CHANGES Prepare next big release (#350) Bug Fixes header: Replace search-panel with fulltext-search ( #313 ) ( d234fa7 ) node_modules: Update dependencies ( #318 ) ( f85e4a2 ) project: Bug fix in project view when not logged-in ( #339 ) ( ce5acf1 ) workspace: Fix broken link ( #306 ) ( 52b324d ) Open external link in new tab ( #297 ) ( 99f188e ) Replaced reset buttons with cancel button ( #284 ) ( 1481018 ) Update docker environment ( #294 ) ( db6d277 ) Documentation Update README ( #292 ) ( fa72ee1 ) Enhancements Prepare next big release ( #350 ) ( 6a39180 ) header: display form link when the session is active ( #332 ) ( d609bd5 ) header+dialog: create button in the header + dialog box ( #320 ) ( 5e4890d ) PR: Add template for PRs ( #305 ) ( 1468ee1 ) Maintenance ci: Update package-name in gh actions workflow ( #352 ) ( 3d9bb13 ) Update js- and ui-lib version ( #293 ) ( 5409d9b )","title":"Release Notes"},{"location":"DSP-APP/contribution/release-notes/#changelog","text":"","title":"Changelog"},{"location":"DSP-APP/contribution/release-notes/#10140-2023-02-17","text":"","title":"10.14.0 (2023-02-17)"},{"location":"DSP-APP/contribution/release-notes/#enhancements","text":"cardinalities: implement cardinalities user workflow (Dev-1615 ) ( #917 ) ( 4f0347a )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#documentation","text":"Fix broken links ( #921 ) ( ad368aa )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance","text":"bump js-lib to 8.0.0 ( #923 ) ( f7c4847 ) deps: fix breaking changes from js-lib v8.0.0 ( #918 ) ( f2d14be ) enable publishing docker image arm64 and amd64 architectures (DEV-1701) ( #915 ) ( 65d3120 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#10130-2023-02-03","text":"","title":"10.13.0 (2023-02-03)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes","text":"adapt link to search doc ( #907 ) ( dc294af ) fix disappeared buttons colors (DEV-1686) ( #906 ) ( 9594a6e ) project: disable closing sidenav with esc key (DEV-1687) ( #909 ) ( 1dea40f )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_1","text":"fix test logs (DEV-1610) ( #893 ) ( 681fc7a ) make possible to publish manually to DockerHub using GH Actions ( #911 ) ( 5f72fa9 ) ontology editor: restyle ontology editor for cardinalities (DEV-1614) ( #900 ) ( 57b41d9 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_1","text":"zio: add support for new zio routes (DEV-1636) ( #898 ) ( d4e2a94 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#10121-2023-01-23","text":"","title":"10.12.1 (2023-01-23)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_1","text":"create-link-resource: fix issue when creating a new linked resource (DEV-1637) ( #899 ) ( cf9008a )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#10120-2023-01-20","text":"","title":"10.12.0 (2023-01-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_2","text":"firefox audio representation (DEV 1553) ( #884 ) ( 420d54f ) fulltext-search: don't allow search queries of less than 3 characters (DEV-1602) ( #890 ) ( 5b6a131 ) ontology: fix old view ontology editor not appearing (DEV-1603) ( #891 ) ( 00ad45e ) project: Prevent adding new data model for deactivated projects (DEV-1582) ( #892 ) ( c5fcc30 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_2","text":"releasenotes: Integrate releasenotes (DEV-1600) ( #895 ) ( 64ef14b )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_2","text":"bump JS-LIB to v7.4.10 ( #896 ) ( 775b012 ) deps: bump engine.io from 6.2.0 to 6.2.1 ( #872 ) ( 3e208a5 ) deps: bump json5 from 1.0.1 to 1.0.2 ( #886 ) ( 6064d42 ) deps: bump loader-utils from 2.0.2 to 2.0.4 ( #866 ) ( 2dfaa61 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#10112-2023-01-09","text":"","title":"10.11.2 (2023-01-09)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_3","text":"fix gravsearch results infinite loading (DEV-1541) ( #887 ) ( 3c8e1a9 ) ontology: Displaying ontology on click (DEV-1545) ( #882 ) ( 479c1e8 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_3","text":"bump JS-LIB to v7.4.9 ( #888 ) ( 4b958e2 ) header: Logo & favicon (DEV-1574) ( #885 ) ( 384d8ef )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#10111-2022-12-07","text":"","title":"10.11.1 (2022-12-07)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_4","text":"properties: fixing incoming links bug in compound view (DEV-1493) ( #873 ) ( d606cf0 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_4","text":"bump js-lib to v7.4.8 ( #880 ) ( c412dfd ) project IRI refactor (DEV-1468) ( #862 ) ( d898109 ) representations: move repeated code to a shared service (DEV-1488) ( #869 ) ( c2dcb17 ) text-value-as-string: no longer account for richText gui attribute (DEV-1471) ( #874 ) ( 21f7c6c )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#10110-2022-11-02","text":"","title":"10.11.0 (2022-11-02)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_5","text":"css: adjust css of form error message (DEV-1458) ( #861 ) ( 54e15d0 ) ontology: list of class properties sometimes not loading correctly (DEV-1435) ( #857 ) ( 302d83b )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_3","text":"link-value, search-link-value: add debouncing to search requests (DEV-1463) ( #860 ) ( a49af8e ) result list: Internal links open resource in new window (DEV-1405) ( #855 ) ( 3396701 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#10102-2022-10-21","text":"","title":"10.10.2 (2022-10-21)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_6","text":"edit-list-item: only send delete comment request if necessary (DEV-1406) ( #850 ) ( a2bddfc ) list-value: fix payload for API request to update a link value (DEV-1420) ( #854 ) ( e350d21 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_5","text":"deps: bump JS-LIB to 7.4.7 ( #856 ) ( d10f9c4 ) project workspace: Remove grid view from the project workspace (DEV-1318) ( #849 ) ( 1083512 ) replace substr with substring (DEV-1409) ( #853 ) ( 5b94d3b )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#10101-2022-10-07","text":"","title":"10.10.1 (2022-10-07)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_7","text":"list-info-form: fix project iri generation (DEV-1387) ( #845 ) ( 79c4791 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_6","text":"deps: bump JS-LIB to 7.4.6 ( #847 ) ( 17d3af1 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#10100-2022-10-06","text":"","title":"10.10.0 (2022-10-06)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_8","text":"sidenav: sort data models (DEV-1359) ( #841 ) ( 75087b5 ) upload: convert file extensions to lowercase before checking for validity (DEV-1391) ( #844 ) ( 61005c6 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_7","text":"maintain dependencies (DEV-1358) ( #839 ) ( e8c5140 ) update release-please-action to v3 ( #837 ) ( 9b1e7e1 ) upgrade Angular and Material to v14 (DEV-1322) ( #830 ) ( a46609f )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_4","text":"add support for Romansh language (DEV-557) ( #840 ) ( 1ec8cff ) forms: Comments are disabled or highlighted to be not saved if there is a invalid or an empty property value (DEV-1124) ( #836 ) ( f5b7abd )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#1091-2022-09-26","text":"","title":"10.9.1 (2022-09-26)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_9","text":"project: fix route to lists ( #834 ) ( 1d32a03 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#1090-2022-09-26","text":"","title":"10.9.0 (2022-09-26)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_10","text":"list-view: refresh list view after a resource is deleted or erased (DEV-1353) ( #828 ) ( c15d87b ) Onto editor 404 error (DEV-1355) ( #831 ) ( e7836a9 ) Ontologies displayed twice (DEV-1325) ( #832 ) ( ba35d6f ) property-form: set the cache after the ontology changes with the new lastModificationDate to prevent 409 http errors ( #824 ) ( 0304943 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_5","text":"lists: read mode project member (DEV-1343) ( #825 ) ( b818288 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_8","text":"update js-lib to v7.4.5 ( #833 ) ( 6d14ca7 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#1081-2022-09-14","text":"","title":"10.8.1 (2022-09-14)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_11","text":"make deactivated projects invisible for all except sysadmin (DEV-1261) ( #821 ) ( 88a2cbd ) properties: resolve 409 conflict ( #822 ) ( bf0ed83 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#1080-2022-09-09","text":"","title":"10.8.0 (2022-09-09)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_12","text":"audio: download audio file with original filename ( #810 ) ( 8001fab ) int-value: fix int-value validation (DEV-1277) ( #815 ) ( d86dc7b ) ontology: don't show 403 error is user is a system admin or project admin and not a project member ( #816 ) ( ffe00c0 ) resource: fix properties sorting (DEV-1204) ( #818 ) ( fbee603 ) resource: reinit representationsToDisplay array to fix undefined issue in template ( #813 ) ( 375166a ) rollbar fixes (DEV-1324) ( #817 ) ( e79eee5 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_6","text":"document: document viewer for non-pdf documents (DEV-1303) ( #812 ) ( 36008c6 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_9","text":"deps: bump js-lib to 7.4.4 ( #820 ) ( 57e3ccf ) deps: bump js-lib version to 7.4.3 ( #814 ) ( c97c569 ) upload: use file extensions for valid file types instead of MIME types (DEV-1203) ( #808 ) ( 448e783 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#documentation_1","text":"Add documentation about the different file types and their functionalities ( #804 ) ( 8c64276 ) Reorganise the main menu and the data menu ( #807 ) ( f8ef81d )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#1070-2022-08-24","text":"","title":"10.7.0 (2022-08-24)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_7","text":"list-value: show hierarchy of list node (DEV-1092) ( #805 ) ( 26e88c3 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#1060-2022-08-19","text":"","title":"10.6.0 (2022-08-19)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_13","text":"list: hide title ( #801 ) ( 19fcaba )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#documentation_2","text":"Update the section Linkage and annotation ( #802 ) ( 5f4d52f )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#enhancements_8","text":"ontology: ontology editor read mode (DEV-1183) ( #799 ) ( 02b5a48 ) video: add download button and overlay to video player (DEV-1151) ( #798 ) ( ac06f6b )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_10","text":"file-representation: add credentials to all file download requests ( #803 ) ( b247f85 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#1050-2022-08-15","text":"","title":"10.5.0 (2022-08-15)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_14","text":"login-form: keep user on same page after login (DEV-1158) ( #788 ) ( 9ec6870 ) notification: fix snackbar notification only appearing for a split second ( #794 ) ( 110039d ) resource view: dsp app the resource viewer does not reload properly after deselecting a resource from the comparison viewer(Dev-1123) ( #793 ) ( f690a37 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_9","text":"archive: new archive representation view (DEV-1084) ( #785 ) ( db40310 ) audio: Make changes to audio component (DEV-1148) ( #796 ) ( 0cabfe3 ) document: changes to pdf viewer (DEV-1149) ( #789 ) ( d39ed14 ) document: make changes to text component (DEV-1147) ( #791 ) ( e8adde9 ) projects: changes to nav bar (DEV-1101) ( #790 ) ( d9570b9 ) still-image: new still-image viewer (DEV-1150) ( #792 ) ( 2eccd8a )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_11","text":"file-representations: adjust styling of file representation components ( #797 ) ( 18aa134 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#1043-2022-07-29","text":"","title":"10.4.3 (2022-07-29)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_15","text":"property-form: only send API request to change the guiElement for TextValue object types ( #783 ) ( 109ca05 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#1042-2022-07-28","text":"","title":"10.4.2 (2022-07-28)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_16","text":"package.json & package-lock.json to reduce vulnerabilities ( #775 ) ( 064a7dc )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_12","text":"deps: bump moment from 2.29.2 to 2.29.4 ( #774 ) ( 2831255 ) login-form: don't redirect user if they are a member of only one project AND they are a sysAdmin ( #782 ) ( 1a103ba )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#1041-2022-07-28","text":"","title":"10.4.1 (2022-07-28)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_13","text":"routing: home button should direct to overview page (DEV-1152) ( #779 ) ( d3011ae )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#1040-2022-07-27","text":"","title":"10.4.0 (2022-07-27)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_10","text":"overview: add overview and project tile components (DEV-984) ( #777 ) ( a64359b )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#1033-2022-07-19","text":"","title":"10.3.3 (2022-07-19)"},{"location":"DSP-APP/contribution/release-notes/#documentation_3","text":"Update the user guide (DEV-1049) ( #769 ) ( 12d0edc )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#1032-2022-06-30","text":"","title":"10.3.2 (2022-06-30)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_17","text":"date-value-handler: add some null checks to ensure component has everything it needs before trying to use a property ( #771 ) ( 4076f3e )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_14","text":"deps: bump version of js-lib ( #773 ) ( 9a5252d )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#1031-2022-06-23","text":"","title":"10.3.1 (2022-06-23)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_18","text":"link-value: add onto iri to api request ( #770 ) ( d16e5b5 ) update broken links of the main README file ( #767 ) ( a3408f6 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#1030-2022-06-16","text":"","title":"10.3.0 (2022-06-16)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_19","text":"docs: resolve dead links to documentation ( #764 ) ( 9c83b7e ) link-value: loop through all ontologies of a project to create list of resource classes ( #766 ) ( 7c824bf )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_15","text":"change codeowner before I leave ( #762 ) ( 5884f51 ) link-value: recursively loop through all of a superclass's subclasses ( #763 ) ( 5efed72 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_11","text":"project: proof of new project workflow concept (DEV-1001) ( #765 ) ( fb29253 ) project: proof of new project workflow concept (DEV-985) ( #760 ) ( 2391f2a ) resource: create new resource instance directly from ontology's class (DEV-959) ( #755 ) ( 5f30719 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#1020-2022-06-02","text":"","title":"10.2.0 (2022-06-02)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_20","text":"ontology: check if value exists without refreshing the page (DEV-923) ( #756 ) ( 3c2409a ) user: bring back password field and resolve loading issue (DEV-967) ( #753 ) ( 694cb06 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_16","text":"form: replace matAutosize by cdkAutosize (DEV-968) ( #754 ) ( 449493b )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_12","text":"list: add support for deleting child node comments (DEV-965) ( #758 ) ( 50c2d17 ) text-file: add support for text file representations (DEV-920) ( #751 ) ( 84975d7 ) value: improve list value (DEV-951) ( #757 ) ( 4d9b747 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#1010-2022-05-23","text":"","title":"10.1.0 (2022-05-23)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_21","text":"representation: resolve timeline issue when resizing window (DEV-819) ( #741 ) ( da985fc )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_17","text":"classes: sort resource classes by label (DEV-952) ( #748 ) ( e060cce ) resource: display incoming links the same way as prop values (DEV-567) ( #747 ) ( 7d2f6f3 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_13","text":"resource: open annotation (region) the correct way (DEV-785) ( #749 ) ( 3983f9b ) resource: open resource instances from ontology class (DEV-950) ( #746 ) ( e937b5f )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#1000-2022-05-18","text":"","title":"10.0.0 (2022-05-18)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes","text":"representation: new navigation in still-image viewer (DEV-895) (#742)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_22","text":"error: resolve error handler issues (DEV-938) ( #744 ) ( ceebf7b ) ontology: unsupported property type was displayed wrong (DEV-936) ( #740 ) ( 87124e9 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_18","text":"message: use only one static error component (DEV-900) ( #727 ) ( 404f1f6 ) project: resolve issues in lists and with status 204 ( #738 ) ( 52f904b )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_14","text":"error: add file representation error message (DEV-791) ( #729 ) ( 462771e ) error: handle 504 timeout error with snackbar (DEV-751) ( #739 ) ( 8f6c409 ) hint: display hint about fulltext search (DEV-901) ( #734 ) ( f54dafc ) link-value: UI now shows that there are no search results ( #736 ) ( 88b81bf ) ontology: select link class from all ontologies (DEV-688) ( #737 ) ( 8dcdd8f ) representation: new navigation in still-image viewer (DEV-895) ( #742 ) ( dbc75ff )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#981-2022-05-09","text":"","title":"9.8.1 (2022-05-09)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_23","text":"representation: disable progress indicator correctly (DEV-905) ( #730 ) ( 92efbeb )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#980-2022-05-05","text":"","title":"9.8.0 (2022-05-05)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_24","text":"ontology-editor: bring back the gui-attr for pulldown (DEV-856) ( #719 ) ( 0c2a43d ) resource: show progress indicator until whole resource is loaded (DEV-638) ( #725 ) ( 946af20 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_19","text":"clean up jsDocs and delete deprecated methods (DEV-741) ( #722 ) ( 8457119 ) ontology: crop loooong ontology labels (DEV-493) ( #723 ) ( 1b7384f )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_15","text":"ontology: add properties to a class from other ontologies (DEV-689 / DEV-880) ( #721 ) ( b90fc70 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#970-2022-04-22","text":"","title":"9.7.0 (2022-04-22)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_25","text":"package.json & package-lock.json to reduce vulnerabilities ( #714 ) ( 0e90296 ) text-value-as-string: links in text values (DEV-797) ( #718 ) ( af3cdc2 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_20","text":"deps: bump async from 2.6.3 to 2.6.4 ( #716 ) ( c77c208 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_16","text":"representation: implement video player incl. preview (DEV-701) ( #698 ) ( 86fc2a7 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#960-2022-04-13","text":"","title":"9.6.0 (2022-04-13)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_26","text":"create-link-value: bring back functionality to create a new link resource instance when adding a new value to a linked resource class property ( #709 ) ( c6fe803 ) link-value: re-validate form when cancel button is clicked ( #711 ) ( 7768fb9 ) ontology: display all classes in a property (DEV-564) ( #701 ) ( f90aedc ) package.json & package-lock.json to reduce vulnerabilities ( #704 ) ( 5d4bb7c ) region: highlight info of clicked region (DEV-724) ( #703 ) ( 2d98369 ) resource-instance-form: disable \"next\" button when form is not valid (DEV-803) ( #713 ) ( 124b953 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_17","text":"link-value: add progress indicator (DEV-605) ( #708 ) ( 5efd981 ) link-value: enter newly created value automatically ( #710 ) ( 5ccd18d ) resource: upload video (DEV-204) ( #577 ) ( 29201d4 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_21","text":"gh-ci: add style to the release notes ( #706 ) ( 8e9e143 ) help: update support links (DEV-779) ( #700 ) ( d97113f ) resource: display class label of incoming link (DEV-568) ( #702 ) ( aad1c5a ) use constants from js-lib directly (DEV-799) ( #712 ) ( 374b5a8 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#950-2022-04-04","text":"","title":"9.5.0 (2022-04-04)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_27","text":"mkdocs: update version of mkdocs ( #696 ) ( e154fa3 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_18","text":"replace-file: Replace Uploaded Files (DEV-684) ( #695 ) ( df9de8c )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#940-2022-03-23","text":"","title":"9.4.0 (2022-03-23)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_28","text":"help: refactor version number and fix dead link (DEV-678) ( #693 ) ( e255ac9 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_19","text":"resource-instance: add subclass creation support (DEV-553) ( #686 ) ( d0a260d ) still-image: IIIF URL copy button (DEV-524) ( #690 ) ( b0d72a6 ) still-image: new draw region icon (DEV-569) ( #689 ) ( bee5caf )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_22","text":"clean up code, tests and packages ( #694 ) ( 1ad0879 ) deps: bump node-forge from 1.2.1 to 1.3.0 ( #692 ) ( cf58030 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#930-2022-03-21","text":"","title":"9.3.0 (2022-03-21)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_29","text":"error: display 500 server error when the api is not healthy (DEV-475) ( #673 ) ( b374a3b ) gravsearch: cleanse gravsearch date query ( #681 ) ( a0f34ce ) gravsearch: fix list value restriction (DEV-486) ( #682 ) ( 1eccfc0 ) permission-info: close permission info on scrolling (DEV-552) ( #671 ) ( 8ac1d25 ) value: do not use linkify in text value as html (DEV-563) ( #683 ) ( 3b159b5 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_20","text":"advanced-search: support subclasses in cross-resource query ( #685 ) ( fde5d99 ) archive-value: Download archive files with original filename (DEV-295) ( #677 ) ( a87dfae ) ontology: adjust tooltip text when property is inherited (DEV-323) ( #674 ) ( d3a1e49 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_23","text":"deps-dev: bump karma from 6.3.14 to 6.3.16 ( #678 ) ( df0ef65 ) deps: bump angular to version 13 (DEV-631) ( #679 ) ( a7d2098 ) deps: bump js-lib to latest (DEV-669) ( #687 ) ( b4836b8 ) deps: bump url-parse from 1.5.7 to 1.5.10 ( #676 ) ( 150e8ae ) dockerfile: add dependabot config to keep base image up-to-date (INFRA-13) ( #670 ) ( 485a57e ) error: use error handler everywhere (DEV-475) ( #688 ) ( eabfa64 ) value: remove old date value components (DEV-633) ( #684 ) ( 76233ea )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#921-2022-02-21","text":"","title":"9.2.1 (2022-02-21)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_30","text":"permission-info: better permission string handling (DEV-537) ( #667 ) ( 8be1efe ) resource: resource viewer is broken if fileRepresentation has restricted view (DEV-455) ( #666 ) ( 6a360ac ) still-image: fix image displayed as black square (DEV-525) ( #668 ) ( 33833f6 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_24","text":"deps: bump url-parse from 1.5.4 to 1.5.7 ( #664 ) ( 54a348f ) rollbar: add environment to the config ( #669 ) ( 8a587b9 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#920-2022-02-17","text":"","title":"9.2.0 (2022-02-17)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_31","text":"ontology-editor: display sub-properties the correct way (DEV-530) ( #661 ) ( a2cf6e0 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_21","text":"resource: display permissions (DEV-454) ( #660 ) ( 13a3a49 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#910-2022-02-15","text":"","title":"9.1.0 (2022-02-15)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_22","text":"add-link-resource-button: Add Link Resource Button (DEV-404) ( #645 ) ( f762c3c )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_25","text":"deps-dev: bump karma from 6.3.13 to 6.3.14 ( #653 ) ( 1794e47 ) deps: bump follow-redirects from 1.14.7 to 1.14.8 ( #656 ) ( 8554764 ) google fonts: switches back to self hosting google fonts ( #654 ) ( 938721b ) open-sea-dragon: updates package to v3.0.0 ( #658 ) ( 42bffa6 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#901-2022-02-09","text":"","title":"9.0.1 (2022-02-09)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_32","text":"main: bug fix in configuration file in case of prod mode (DEV-491) ( #651 ) ( a6c9e87 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#900-2022-02-02","text":"","title":"9.0.0 (2022-02-02)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_1","text":"display dsp release number (DEV-420) (#644)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_33","text":"ontology: support subproperty in ontology editor (DEV-332) ( #643 ) ( c838043 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_23","text":"display dsp release number (DEV-420) ( #644 ) ( b6c9f1c )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_26","text":"deps: bump log4js from 6.3.0 to 6.4.1 ( #648 ) ( dd2eebe ) deps: bump nanoid from 3.1.30 to 3.2.0 ( #647 ) ( 13c6f2a ) deps: update packages ( #650 ) ( cc60b0b )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#850-2022-01-19","text":"","title":"8.5.0 (2022-01-19)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_34","text":"project: better project form validation (DEV-336) ( #641 ) ( a7563a3 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_27","text":"angular: optimize ng s in dev mode ( #640 ) ( 9812b9c ) deps: fix security vulnerability ( #638 ) ( f19434e )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_24","text":"ontology: support partOf value to create book res class (DEV-180) ( #634 ) ( 3051a67 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#840-2022-01-17","text":"","title":"8.4.0 (2022-01-17)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_35","text":"advanced search: update comparison operators in case of rich text (DEV-326) ( #633 ) ( cd01d87 ) archive representation: a resource with an archive representation now loads correctly again ( #630 ) ( 299ecf9 ) date-value: do not submit in case of period button (DEV-373) ( #635 ) ( d7ac1b6 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_28","text":"clean up after bump dsp-js ( #628 ) ( 374fc78 ) ontology: clean up unused code (DEV-304) ( #629 ) ( 3d029a1 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_25","text":"resource: display deleted resource (DEV-299) ( #632 ) ( 2c5fd80 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#833-2022-01-04","text":"","title":"8.3.3 (2022-01-04)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_36","text":"resource: bug fix in pdf viewer (DEV-338) ( #626 ) ( 4b5d5d5 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#832-2021-12-16","text":"","title":"8.3.2 (2021-12-16)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_37","text":"authentication: set active datadog rum user (DEV-325) ( #624 ) ( 69308e0 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#831-2021-12-15","text":"","title":"8.3.1 (2021-12-15)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_38","text":"upload: fix thumbnail preview (DEV-268) ( #619 ) ( 7cb8505 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_29","text":"authentication: new login / logout structure (DEV-325) ( #622 ) ( e8bec98 ) fonts: delete fonts and icons (DEV-327) ( #623 ) ( 08e088b ) google fonts: switch to using fonts hosted by google ( #620 ) ( daa4167 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#830-2021-12-09","text":"","title":"8.3.0 (2021-12-09)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_39","text":"resource: update lastModificationDate after editing label (DEV-315) ( #616 ) ( 3b9d93b )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_26","text":"still-image: display iiif url under the image caption (DEV-243) ( #613 ) ( 109978f )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_30","text":"metadata: remove \"old\" implementation of the project metadata (DEV-282) ( #615 ) ( 29acf3a )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#820-2021-12-08","text":"","title":"8.2.0 (2021-12-08)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_40","text":"ontology: bug fix in ontology form (DEV-280) ( #603 ) ( 4c1bc24 ) resource: create resource iri from route only in certain cases (DEV-306) ( #605 ) ( a38abd0 ) value: fix linkify pipe (DEV-270) ( #602 ) ( f2c8d7a )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_27","text":"representation: add support for uploading and viewing archive files (DEV-18) ( #600 ) ( 9bb63d7 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_31","text":"deps: update outdated angular packages ( #604 ) ( 80b3f93 ) deps: use correct nginx-server (DEV-263) ( #610 ) ( ccae958 ) angular: fix budget in prod mode ( #606 ) ( 5072948 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#812-2021-12-01","text":"","title":"8.1.2 (2021-12-01)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_32","text":"lists: adds changes required for lists to work due to the change in js-lib ( #599 ) ( ca83584 ) projects: don't use the cache when refreshing the projects list. Also renames some labels and methods to clarify that these things are for deactivating a project as opposed to deleting a project. ( #597 ) ( faebe3e )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#811-2021-11-19","text":"","title":"8.1.1 (2021-11-19)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_41","text":"results: display xml a better way (DEV-96) ( #593 ) ( d968f2f ) value: bug fix in text-value-as-string (DEV-242) ( #595 ) ( 0fb95ee )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#810-2021-11-18","text":"","title":"8.1.0 (2021-11-18)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_42","text":"fulltext-search: updates the projects list when a new project is created (DEV-212) ( #586 ) ( 43fcbfa ) ontology: resolve gui order issue (DEV-222) ( #590 ) ( 4ddbf7c ) ontology: send modified label (DEV-221) ( #589 ) ( 9d7ffea ) text-value: resource-instance-form and display-edit components now correctly display a paragraph text with line breaks (DEV-211) ( #584 ) ( be9d6f4 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_33","text":"deps: update angular to v12 ( #588 ) ( 37e65a8 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_28","text":"properties: ckEditor Internal Links (DEV-118) ( #591 ) ( cac988b ) update UI on region color change (DEV-215) ( #583 ) ( b497d0e )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#800-2021-11-10","text":"","title":"8.0.0 (2021-11-10)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_2","text":"resource: new resource route (DEV-196) (#581)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#maintenance_34","text":"small code improvements ( #579 ) ( d19e353 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_29","text":"resource: add additional routing for an ark url of a value (DEV-196) ( #575 ) ( c1b0b94 ) resource: new resource route (DEV-196) ( #581 ) ( 3fbd94c ) still-image: uses the color of the color property for the line color if a color property for the region exists ( #580 ) ( 7680353 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#701-2021-11-05","text":"","title":"7.0.1 (2021-11-05)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_43","text":"error: resolve error handler in case of server error (DEV-205) ( #576 ) ( ff9d097 ) ontology: class and property name has to be unique (DEV-183) ( #569 ) ( 059dd2a ) value: display ckEditor in case of rich-text property (DEV-182) ( #571 ) ( 6bfe254 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_35","text":"annotations will now only be drawn when the user is on the annotations tab ( #574 ) ( bddc2f1 ) deps: use release of ckeditor custom build (DEV-189) ( #570 ) ( fb55fd7 ) main: use version route (DEV-124) ( #565 ) ( 16f26ce ) move datadog rum methods to service (DEV-190) ( #572 ) ( 77191cb ) refactors upload-file service to use the string generated in the iiif-config file and changes the public class members in app-init service to private with getters. ( #573 ) ( c39ca5b )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#700-2021-10-28","text":"","title":"7.0.0 (2021-10-28)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_3","text":"error logging: rollbar implementation (DEV-20) (#543)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_44","text":"ontology: use correct label (DEV-168) ( #564 ) ( 70cc7d8 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_36","text":"gh: update issue templates ( #562 ) ( 6d510c7 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_30","text":"error logging: rollbar implementation (DEV-20) ( #543 ) ( d0a9e3f )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#650-2021-10-21","text":"","title":"6.5.0 (2021-10-21)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_31","text":"ontology: bring back the name input field (DEV-157) ( #559 ) ( 51e539d )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#641-2021-10-20","text":"","title":"6.4.1 (2021-10-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_45","text":"value: fix boolean value issue ( #557 ) ( 4d35cd2 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_37","text":"deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #556 ) ( 5f8213c )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#640-2021-10-20","text":"","title":"6.4.0 (2021-10-20)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_32","text":"ontology: delete property from resource class (DSP-1854 / DEV-28) ( #499 ) ( 436c270 ) value: refactor boolean value (DEV-98) ( #554 ) ( 7affa5e )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#630-2021-10-15","text":"","title":"6.3.0 (2021-10-15)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_46","text":"disable edit/delete action in deactivated projects (DEV-52) ( #550 ) ( d7bec78 ) properties: do not submit res instance form by adding new value (DEV-150) ( #553 ) ( 99a3022 ) value: fix broken time value component (DEV-147) ( #552 ) ( fb846f9 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_33","text":"datadog RUM implementation (DEV-50) ( #546 ) ( ec59ee5 ) resource: new date picker (DEV-112) ( #532 ) ( 04e4b32 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#620-2021-10-08","text":"","title":"6.2.0 (2021-10-08)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_47","text":"error: improve the current error handler in DSP-APP (DSP-1911) ( #540 ) ( 0eb621b ) gravsearch results now appear after page refresh ( #542 ) ( a88dd79 ) resource-instance-form: reloads cached resource to show changes made to the data model ( #547 ) ( 37bb2a7 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_34","text":"ontology: display id / name in property and class (DEV-37) ( #544 ) ( 0a2bcfb ) search: add missing search resource component (DEV-95) ( #548 ) ( 79abd10 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_38","text":"fulltext-search: persist fulltext search term in input field (DSP-1674) ( #539 ) ( 67a52a3 ) resource: improve still image annotation form (DEV-53) ( #549 ) ( 38bbe41 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#610-2021-09-20","text":"","title":"6.1.0 (2021-09-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_48","text":"annotations: empty annotations on upload of new region ( #536 ) ( 075e6b1 ) links: trust the external links (DSP-1904) ( #537 ) ( 303ac3d ) resource-instance-form: resource class name now updates correctly in the event that the name was changed and the page was not refreshed ( #531 ) ( 5783d27 ) resource: increase width of space between entries of incoming links (DSP-1908) ( #538 ) ( 79b4d29 ) still-image-viewer: fix zoom buttons (DSP-1798) ( #533 ) ( b07ec63 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_35","text":"resource: draw regions (DSP-1845) ( #524 ) ( f08706b ) textarea is now provided is the gui-element is a textarea ( #529 ) ( e80a4d2 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_39","text":"modules: clean up imports and npm packages ( #535 ) ( 4310ff7 ) openseadragon prod build fix (DSP-1779) ( #534 ) ( 0a34eaa )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#600-2021-09-08","text":"","title":"6.0.0 (2021-09-08)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_4","text":"config: update config file for better iiif support (DSP-1880) (#511)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_49","text":"audio: sanitize audio url (DSP-1819) ( #513 ) ( 35871cd ) deps: fix security vulnerability ( #514 ) ( d793fb8 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_36","text":"config: update config file for better iiif support (DSP-1880) ( #511 ) ( b799600 ) resource: display incoming links (DSP-1846) ( #507 ) ( 9c3abce ) resource: optimize resource instance form (DSP-1256) ( #518 ) ( 5151677 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_40","text":"action: migrate action module (DSP-1852) ( #509 ) ( 725c45e ) core: migrate core module from UI-lib (DSP-1853) ( #505 ) ( ea1cd55 ) deps: bump dsp-js to latest version (DSP-1883) ( #521 ) ( c956d4b ) deps: bump dsp-ui to latest ( #502 ) ( 5d79065 ) fix style in resource, search-panel and progress-indicator (DSP-1887) ( #520 ) ( 854aff2 ) gh-ci: split workflow tasks ( #515 ) ( 83d5874 ) login: add autocomplete to login form (DSP-1892) ( #527 ) ( dd6be15 ) project: handle mandatory keyword field (DSP-1829) ( #503 ) ( 35f6e7b ) remove CoreModule dependency (DSP-1884) ( #519 ) ( 8549104 ) remove ViewerModule dependency (DSP-1890) ( #525 ) ( a99546e ) removes ActionModule dependency ( #523 ) ( bd60f00 ) removes SearchModule dependency ( #522 ) ( 269be23 ) resource: migrate viewer from UI-lib (DSP-1850) ( #504 ) ( b742a98 ) search: migrate search module (DSP-1851) ( #510 ) ( fc7ea5c ) update imports step 1 (DSP-1882) ( #516 ) ( e7a2c4f ) update remaining dsp-ui imports (DSP-1891) ( #526 ) ( 43888a6 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#530-2021-08-12","text":"","title":"5.3.0 (2021-08-12)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_41","text":"header: clean up code and use notification service after login ( #498 ) ( fb6c368 ) ontology: update create ontology tooltip for unique name (DSP-1139) ( #500 ) ( 946d00f )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_37","text":"resource: create link / collection resource (DSP-1835) ( #501 ) ( 8060756 ) workspace: add intermediate view (DSP-1834) ( #494 ) ( d0e475a )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#521-2021-08-03","text":"","title":"5.2.1 (2021-08-03)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_42","text":"deps: bump dsp-ui to latest version (DSP-1838) ( #495 ) ( 4adc49a )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#520-2021-08-02","text":"","title":"5.2.0 (2021-08-02)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_38","text":"resource: add comparison view (DSP-1796) ( #490 ) ( 731ea04 ) resource: update resource's label (DSP-1801) ( #492 ) ( e2c9867 ) improve error handler and fix search results issue (DSP-1826 / DSP-1831) ( #493 ) ( fa2f4b0 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#510-2021-07-26","text":"","title":"5.1.0 (2021-07-26)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_50","text":"ontology: fix regex pattern in ontology form (DSP-1139) ( #483 ) ( 4d0703f )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#documentation_4","text":"user-guide: update user-guide about ontology (DSP-976) ( #480 ) ( e12f196 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance_43","text":"ontology: better regex for onto name (DSP-1139) ( #488 ) ( ec881ef ) resource: hide file value in properties (DSP-1261) ( #484 ) ( 4ade17f )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_39","text":"resource: add document viewer with download (DSP-1791) ( #485 ) ( ce51bce ) resource: audio player (DSP-1805) ( #487 ) ( bf372dc ) resource: delete and erase resource (DSP-1228) ( #489 ) ( 8b1fdba ) resource: upload audio (DSP-1799) ( #486 ) ( d865df5 ) resource: upload pdf document (DSP-1776) ( #481 ) ( d916b4b )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#500-2021-07-05","text":"","title":"5.0.0 (2021-07-05)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_5","text":"upload: add upload form for still images (DSP-1761) (#472) config: add geoname config (DSP-1672) (#473)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#documentation_5","text":"ontology: update docs and show hint in ontology-form (DSP-1139) ( #476 ) ( 927237d )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#enhancements_40","text":"config: add geoname config (DSP-1672) ( #473 ) ( d4222ba ) ontology: add property to res class that is in use (DSP-1631) ( #477 ) ( b18e6ec ) ontology: change gui element for text value properties ( #478 ) ( 6af1f7e ) ontology: display description for default and existing props (DSP-1154) ( #475 ) ( 8be7e55 ) upload: add upload form for still images (DSP-1761) ( #472 ) ( 2f314a2 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_44","text":"deps: bump jdnconvertiblecalendar to v0.0.7 (DSP-1770) ( #479 ) ( b2ec64a )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#4111-2021-06-23","text":"","title":"4.11.1 (2021-06-23)"},{"location":"DSP-APP/contribution/release-notes/#documentation_6","text":"search: add advanced search user guide (DSP-1662) ( #470 ) ( 30edc96 ) user-guide: fix navigation links ( #468 ) ( 49c68f8 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance_45","text":"fix dead links to the documentation ( #471 ) ( d7ae022 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#4110-2021-06-22","text":"","title":"4.11.0 (2021-06-22)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_41","text":"ontology: check if an ontology, a class or a property can be deleted (DSP-1750) ( #457 ) ( fb0c275 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_46","text":"empty landing page instead login (DSP-1756) ( #466 ) ( 32cd462 ) gh-ci: update docs deployment (DSP-1741) ( #463 ) ( 6415152 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#documentation_7","text":"refactor documentation and set correct links ( #467 ) ( cbeb274 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#4101-2021-06-15","text":"","title":"4.10.1 (2021-06-15)"},{"location":"DSP-APP/contribution/release-notes/#documentation_8","text":"fix dead links and replace screenshots in project ( #460 ) ( a13b8ba ) prepare documentation for docs.dasch.swiss (DSP-1721) ( #458 ) ( 09259f1 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance_47","text":"analytics: add fathom ( #462 ) ( f1e0244 ) cookie-policy: reactivate the cookie policy banner (DSP-1727) ( #461 ) ( ac99fbc )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#4100-2021-06-07","text":"","title":"4.10.0 (2021-06-07)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_42","text":"ontology: new cardinality workflow (DSP-1652) ( #455 ) ( f1d049c )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#491-2021-05-26","text":"","title":"4.9.1 (2021-05-26)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_48","text":"resource: improve list of properties in resource viewer ( #453 ) ( 49d9b7f )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#490-2021-05-26","text":"","title":"4.9.0 (2021-05-26)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_51","text":"disable progress bar if search results are empty (DSP-1575) ( #442 ) ( 8c67d60 ) resource: add if condition (DSP-1655) ( #448 ) ( 656da04 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#documentation_9","text":"update documentation about contribution (DSP-1657) ( #449 ) ( c25280d )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#enhancements_43","text":"resource: display region annotations in still images (DSP-1585) ( #445 ) ( 86e75b9 ) search: specify linked resource in advanced search (DSP-1661) ( #451 ) ( 3f0d6d9 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_49","text":"deps: update packages to resolve security issues ( #450 ) ( 8e927f7 ) project: resolve regex term (DSP-1654) ( #444 ) ( 739beba )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#480-2021-05-21","text":"","title":"4.8.0 (2021-05-21)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_50","text":"CD/CI: automatically detect common vulnerabilities and coding errors ( #438 ) ( af02332 ) compiler: enable strict template (DSP-1403) ( #432 ) ( 583a338 ) environment: add test-server config (DSP-1650) ( #443 ) ( a56a45b ) Replace favicon and term Knora by DSP (DSP-1181 / DSP-1342) ( #441 ) ( 3b038b6 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_44","text":"ontology: new method to change gui order (DSP-1567/DSP-1646) ( #440 ) ( dfd0ce0 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#470-2021-05-07","text":"","title":"4.7.0 (2021-05-07)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_51","text":"search results: disable grid view (DSP-1597) ( #435 ) ( c4726fe )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_45","text":"DMP: own resource viewer (DSP-1586) ( #434 ) ( 35bd7b3 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#460-2021-04-27","text":"","title":"4.6.0 (2021-04-27)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_46","text":"DMP: bring back the workspace ( #431 ) ( e8b1c8e )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#452-2021-04-22","text":"","title":"4.5.2 (2021-04-22)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_52","text":"list: list no longer displays after deletion if it was the only list among lists ( #429 ) ( b05484e ) project: bug fix in project member management (DSP-1563) ( #425 ) ( ac820dd )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_52","text":"ontology: disable ontology graph view (DSP-1560) ( #427 ) ( 0a567d2 ) ontology: disable rti image class (DSP-1559) ( #430 ) ( 48c3c76 ) ontology: rename boolean prop type (DSP-1561) ( #426 ) ( 4dd23d3 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#451-2021-04-20","text":"","title":"4.5.1 (2021-04-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_53","text":"ontology: bug fix in create ontology process (DSP-1558) ( #423 ) ( bbd825b )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#450-2021-04-20","text":"","title":"4.5.0 (2021-04-20)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_54","text":"users: update session the correct way (DSP-690) ( #419 ) ( 3ec049e )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_47","text":"project: better error handler in case a project does not exist (DSP-1401) ( #421 ) ( d7470a0 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#443-2021-04-14","text":"","title":"4.4.3 (2021-04-14)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_55","text":"ontology: Bug fix in ontology form ( #417 ) ( 96dc804 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#442-2021-04-12","text":"","title":"4.4.2 (2021-04-12)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_53","text":"migrate to angular11: changes (DSP-1471) ( #415 ) ( 3271ece )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#441-2021-04-08","text":"","title":"4.4.1 (2021-04-08)"},{"location":"DSP-APP/contribution/release-notes/#maintenance_54","text":"migrate to angular10: changes (DSP-1415) ( #412 ) ( cec564d )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#440-2021-03-23","text":"","title":"4.4.0 (2021-03-23)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_56","text":"deps: package dependency build errors (DSP-1400) ( #410 ) ( 17e0e1a )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_55","text":"list-editor: new list form refactor (DSP-1392) ( #403 ) ( 8824682 ) ontology: improve ontology editor design (DSP-1376) ( #401 ) ( 6de83b8 ) project landing page: update metadata typings (DSP-1393) ( #407 ) ( b4f101b ) project metadata page: enable error handler ( #411 ) ( a4004ed )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_48","text":"eslint: migrate tslint to eslint (DSP-1372) ( #394 ) ( 6ffc3b6 ) ontology: edit data model info (DSP-1208) ( #385 ) ( 86a5fb8 ) ontology: form to create and edit property (DSP-1210) ( #406 ) ( 91ebb68 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#431-2021-03-03","text":"","title":"4.3.1 (2021-03-03)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_57","text":"project: disable error handler in metadata request (DSP-1395) ( #404 ) ( 86ebfcf )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#430-2021-03-02","text":"","title":"4.3.0 (2021-03-02)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_58","text":"ontology: set the cache earlier in case of only one ontology (DSP-1374) ( #397 ) ( c23ae61 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#enhancements_49","text":"list-editor: insert a child node at a specific position (DSP-1301) ( #395 ) ( 5107200 ) ontology: separate list of ontology properties (DSP-1364) ( #391 ) ( 0f94df6 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_56","text":"deps: bump three from 0.118.3 to 0.125.0 ( #402 ) ( 5ab9c49 ) gh-ci: update release please configuration (DSP-1381) ( #399 ) ( 040df19 ) project landing page: use metadata endpoint to get data from backend (DSP-1199) ( #400 ) ( 5dde42f ) tests: script to find ignored tests ( #396 ) ( 9ca249d )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#421-2021-02-24","text":"","title":"4.2.1 (2021-02-24)"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_59","text":"ontology: bug fix in list property (DSP-1368) ( #390 ) ( 2fb448e )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#420-2021-02-22","text":"","title":"4.2.0 (2021-02-22)"},{"location":"DSP-APP/contribution/release-notes/#enhancements_50","text":"list-editor: add deletion functionality (DSP-1334) ( #378 ) ( 34c74a6 ) list-editor: delete list root node (DSP-1356) ( #386 ) ( 5d5eabf ) list-editor: reposition a child node amongst its siblings (DSP-1340) ( #388 ) ( 0a9be0e ) ontology: default language for property label ( #382 ) ( 97230d1 ) ontology: edit res class info (DSP-1209) ( #380 ) ( 2debd03 ) ontology: refactor list of properties in resource class (DSP-1360) ( #389 ) ( aa565b3 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#410-2021-02-12","text":"","title":"4.1.0 (2021-02-12)"},{"location":"DSP-APP/contribution/release-notes/#documentation_10","text":"init mkdocs and move documentation from DSP-DOCS into DSP-APP repo (DSP-380) ( #379 ) ( 07f5067 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#maintenance_57","text":"bumps DSP-JS to 1.3.0 and DSP-UI to 1.2.1 ( #374 ) ( 7b795ee ) deps: bump socket.io from 2.3.0 to 2.4.1 ( #367 ) ( 8133d87 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_51","text":"list editor: Adds support for editing lists (DSP-741) ( #365 ) ( 5b6ee4b ) ontology: update cardinality in resource class (DSP-1266) ( #377 ) ( 5a766c1 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#400-2021-01-28","text":"","title":"4.0.0 (2021-01-28)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_6","text":"set up the login page as a starting page (DSP-1292) (#370) app+main: comment out the search and everything related to resources (DSP-1291) (#371)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_60","text":"dialog: Diaolog box height issue fixed ( #358 ) ( 15d1182 ) routing: bring back the route handler in main component (DSP-1303) ( #373 ) ( 8492c1a )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#maintenance_58","text":"update pr template (DSP-1189) ( #353 ) ( f348e70 ) update the dsp-ui and dsp-js versions to the latest ( #364 ) ( 66931f0 )","title":"Maintenance"},{"location":"DSP-APP/contribution/release-notes/#enhancements_52","text":"display metadata on project landing page (DSP-1065) ( #348 ) ( 3012ef5 ) error: Server error handler (DSP-710) ( #355 ) ( d5b77bf ) new-resource-form: make visible the required prop fields (DSP-1115) ( #342 ) ( 5885b04 ) project landing page: add copy to clipboard functionality (DSP-1248) ( #368 ) ( 17bf71c ) select-resource-class: allow accented character (DSP-1241) ( #363 ) ( 8a2654b )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#refactor","text":"app+main: comment out the search and everything related to resources (DSP-1291) ( #371 ) ( 50b1309 ) set up the login page as a starting page (DSP-1292) ( #370 ) ( 46dfdbb )","title":"refactor"},{"location":"DSP-APP/contribution/release-notes/#300-2020-12-18","text":"","title":"3.0.0 (2020-12-18)"},{"location":"DSP-APP/contribution/release-notes/#breaking-changes_7","text":"Prepare next big release (#350)","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-APP/contribution/release-notes/#bug-fixes_61","text":"header: Replace search-panel with fulltext-search ( #313 ) ( d234fa7 ) node_modules: Update dependencies ( #318 ) ( f85e4a2 ) project: Bug fix in project view when not logged-in ( #339 ) ( ce5acf1 ) workspace: Fix broken link ( #306 ) ( 52b324d ) Open external link in new tab ( #297 ) ( 99f188e ) Replaced reset buttons with cancel button ( #284 ) ( 1481018 ) Update docker environment ( #294 ) ( db6d277 )","title":"Bug Fixes"},{"location":"DSP-APP/contribution/release-notes/#documentation_11","text":"Update README ( #292 ) ( fa72ee1 )","title":"Documentation"},{"location":"DSP-APP/contribution/release-notes/#enhancements_53","text":"Prepare next big release ( #350 ) ( 6a39180 ) header: display form link when the session is active ( #332 ) ( d609bd5 ) header+dialog: create button in the header + dialog box ( #320 ) ( 5e4890d ) PR: Add template for PRs ( #305 ) ( 1468ee1 )","title":"Enhancements"},{"location":"DSP-APP/contribution/release-notes/#maintenance_59","text":"ci: Update package-name in gh actions workflow ( #352 ) ( 3d9bb13 ) Update js- and ui-lib version ( #293 ) ( 5409d9b )","title":"Maintenance"},{"location":"DSP-APP/user-guide/","text":"User Guide This is the documentation for the generic DSP Web Application of the Data and Service Center for the Humanities DaSCH. You can reach the app on admin.dasch.swiss . Getting started DSP-APP is an intuitive, easy to use web-based application placed on top of DSP-API to directly use its powerful data management functionalities. With this modern web application, the researchers can create their data models, search, browse, and work with their qualitative data as easily as they could with a desktop data management tool. In addition, data models and data will automatically follow accepted standards, be interoperable, findable, and re-usable. Researchers and scholars with small to medium data sets (e.g. PhD research, pilot project, or proof of concept) have access to long-term accessibility to keep their research data alive, guaranteeing longevity of the data. Login To login, click on the LOGIN button of the header (right side), a login form will appear. Fill in the form with your credentials (user name or email and password). In case of a forgotten password, please contact the DaSCH team . Registration You can use the DSP-APP with restricted access as guest. Otherwise, you'll need a login. At the moment, you have to contact the DaSCH team to get your login credentials. Help For any questions or help wanted, you can go to the help page, accessible from the Help button at the top right of the page (see login screen shot ). Here, you can find links to the user guide, get more information about the DaSCH softwares, and get more support through different platform according to your requests.","title":"Introduction"},{"location":"DSP-APP/user-guide/#user-guide","text":"This is the documentation for the generic DSP Web Application of the Data and Service Center for the Humanities DaSCH. You can reach the app on admin.dasch.swiss .","title":"User Guide"},{"location":"DSP-APP/user-guide/#getting-started","text":"DSP-APP is an intuitive, easy to use web-based application placed on top of DSP-API to directly use its powerful data management functionalities. With this modern web application, the researchers can create their data models, search, browse, and work with their qualitative data as easily as they could with a desktop data management tool. In addition, data models and data will automatically follow accepted standards, be interoperable, findable, and re-usable. Researchers and scholars with small to medium data sets (e.g. PhD research, pilot project, or proof of concept) have access to long-term accessibility to keep their research data alive, guaranteeing longevity of the data.","title":"Getting started"},{"location":"DSP-APP/user-guide/#login","text":"To login, click on the LOGIN button of the header (right side), a login form will appear. Fill in the form with your credentials (user name or email and password). In case of a forgotten password, please contact the DaSCH team .","title":"Login"},{"location":"DSP-APP/user-guide/#registration","text":"You can use the DSP-APP with restricted access as guest. Otherwise, you'll need a login. At the moment, you have to contact the DaSCH team to get your login credentials.","title":"Registration"},{"location":"DSP-APP/user-guide/#help","text":"For any questions or help wanted, you can go to the help page, accessible from the Help button at the top right of the page (see login screen shot ). Here, you can find links to the user guide, get more information about the DaSCH softwares, and get more support through different platform according to your requests.","title":"Help"},{"location":"DSP-APP/user-guide/project/","text":"Project Administration Project Once you are logged in , the dashboard displays the list of your project(s). If you are a project administrator or a system administrator, you can edit the project information or archive your project from the project menu. Archived projects are stored in a list on your dashboard and they can be \"reactivated\" at any time. https://admin.dasch.swiss/dashboard - By clicking on the project name, you get access to the full project information. A system administrator can create a new research project. This currently requires essential information such as the project name, a shortcode and a shortname (both provided by DaSCH). A short project description is optional, but highly recommended. Form to create a new project. As project administrator or system administrator, you can define your project, add your team members, create permission groups and - most important - define your data model (ontology) and the lists of your project. https://admin.dasch.swiss/project/0803/info - Project management functionalities; e.g. Incunabula project. Project information page is displayed without restricted content, the other functionalities are reserved for project admin and system admin. Project members As a system administrator or a project administrator, you can add users as project members. A user menu with different actions is accessible for each member of the project (the three-dot icon to the right side of the user line). The admin can grant another user as project admin (or remove this permission), edit user's information, change user's password if forgotten, and remove a user from the project. https://admin.dasch.swiss/project/0803/collaboration - Project members page where project admin and system admin can add new user to the team. Data model The definition of the data model ( ontology ) is the most important step. The data model is indispensable for structuring your data. Our platform provides a tool for an easy creation of one or more project data models. First, you have to know which data and resources you want to work with. The data model can be flexible and customizable. The question which you have to answer before you create your data model is according to which criteria do you organize your data ? In this respect it may be useful to ask yourself: How are your data organized? What are the goals you want to achieve, which research questions do you want to answer? As soon as you have come to a conclusion concerning the structure of your data, you're all set to create your data model. Create your data model Go to Data model and click New data model Go to your project, select the tab Data model (step 1) and click the button New data model (step 2) as shown below: By clicking New data model , a dialog box opens: Create data model Now you have to set a unique name ( please consider the NOTE ) and you can add a comment. Push the button Create to create your data model. NOTE: There are some rules for the unique name: must be at least 3 characters long shouldn't start with a number shouldn't start with the letter v and a number spaces or special characters are not allowed may not contain these reserved terms: knora ontology salsah shared simple standoff the unique name can't be changed afterwards! The label is a combination of the project's shortname and the unique name. You can replace it with any other string. After the creation of your data model, your page should look like this: Create resource CLASSES You can then create a resource class by clicking the button + Create new class : By clicking + Create new class , a small window pops up with six basic types to choose from: Which type you choose depends on the data type which you need to describe. Let's assume you have pdf-documents of books and they have a number of pages. To describe this in an ontology, you create a class as Document by clicking on Document . A dialog box pops up which looks like this: For the label you could write Book , and you should add a preferably meaningful comment in at least one of the predefined languages English (en), German (de), French (fr) or Italian (it). Then click the Submit button: Now you have created your first class Book , as seen below: Add PROPERTIES to a resource class Now you can add properties to your class. Your pdf of a book has a number of pages. Hence, it may be useful to define the number of pages as one of the properties of your class Book . Click on + Add Property in the Book box: Theoretically, you have two options now. If you defined properties before, you may simply add them here (second option in the following image). If you just start adding properties, you have to choose Create new from type . By hovering over Create new from type , a new menu box appears: You can choose from a selection of the following basic types with various subtypes: Text ( Short , Paragraph , Rich Text ) List ( Dropdown ) Boolean ( Yes/No selection; checkbox) Date / Time ( Date , Timestamp , Time sequence ) Number ( Integer , Decimal , Page number ) Link / Relation ( Link to Class , Part of Class , External URL ) Location ( Place ; a geonames-identifier ) Shape ( color ) Since in our example you want to add a property for the number of pages of your book, you choose Number . Now you will see that you can either choose the type Decimal , Integer or Page number for your property. Page numbers have no decimal places, thus you will select Integer (or Page number which is a special case (s. next section )) as the type for your property. The following window pops up: In the field Property label add for example Number of pages , in the comment section you should add a meaningful explanation. It might also make sense to toggle Required field? since every PDF Document consists of a number of pages. If you toggle it, the number of pages MUST be given if you add data to the class Book - it would then be a required field, not an optional one and data could only be saved if you add the number of pages. If you want to define a property which can have more than one value, you should tick Multiple values? . For the number of pages of a book this does not make sense, but in the case you want to define a property describing which people are mentioned in your Book , the option multiple values is likely to be needed. Now you should see the new property in the box as seen below: Correct property selection in case of special classes Book class with pages as individual classes If you have single digitized pages of a book in your project, they can be defined as its own individual Still image class type. In this case the \u2014 let's call it Page \u2014 class needs two specific properties to work the correct way. One is the part of -property which can be found in the list of properties in the section \"Link / Relation\". This property points to the main class called Book (which should be defined first and is type of Object without representation ). The second property is for the page number definition and is also necessary. This default property can be found in the list of properties in the section called \"Number\". This is how a book and the page class could look like: Define Lists One of the possible property types to choose from is List . Lists are very useful if you want to use controlled vocabulary to describe something. Typical examples are keywords. In your book example it may be useful to define a property which describes to which category of literature your pdf of a book belongs. Before you can add a property of type List to your data model, you have to define this list. For the definiton of a list you have to change to the Lists tab: Click Create your first list . If there is already a list defined, click New list . A new window pops up where you have to enter a name for your list ( List label ) and a short description, then click Create . As soon as the list is created you can continue with the definition of your data model. You can define the individual list items later. How to do this will be explained below. We first focus on the definition of a list property in the data model. Currently there is only one option for displaying a property of type List , namely Dropdown . It is capable of displaying flat as well as hierarchical lists. A new window opens up and as in the case of other properties you have to add a label, a desciption and to choose whether multiple values are allowed and/or whether this property is a required field. But in addition you have to select the list which contains your controlled vocabulary. How to define items in a list In our example we have created a list named Category . Now it is time to define the list items. We will list some main literature genres as the first hierarchy in our list. Enter the name of the list node and click the + as shown below: By clicking on the small arrow on the left a second hierarchical level becomes accessible where you can add items in the same was as for the main hierarchy. It is possible to add list items at any time. You may rearrange the order of your list items and add a new list item at a specific position in the list. Remove PROPERTIES from a resource class To remove a property, hover over the property which you want to remove. By doing so you see a white x with a black background (remove button) appearing, it is highlighted in yellow in the image below: Be aware, that you can only remove a property if there are no data yet! If you click the remove button, the property is removed and a green box pops up for a short time: Delete a property In order to really delete a property you have to go to the Properties section as shown below. Click on Properties , and afterwards click on the waste basket sign of the property which you intend to delete. Be aware, you can only delete properties which are NOT used in a resource class! Delete a CLASS To delete a resource class, click on the three dots in the box of the class which you want to delete. The following box appears and you then have to click Delete resource class . In the alert window popping up, you click the red button Delete . Afterwards, the resource class is deleted. Delete a data model To delete a whole data model, you have to click the button Delete on the right-hand side in the section Data model configuration . In the alert window appearing, you click the red button Delete . The data model is now deleted. An example In the following example we focus on how we can reflect about our data before building our model and how a data model can relate classes to each other. Preparing a data model You have interviewed 20 people and recorded the interviews. During these interviews you talked about photographs. Among all the data collected during the project, the most important are: audio-files of the interview transcribed text of conversations (or transcribe the files within the web application) photographs data about the person you interviewed location where the photograph was taken The following Diagram 1 shows the initial situation: Diagram 1: the initial situation. The second step will be to consider the hierarchy of the data. How your hierarchy looks like depends on which criteria your data were organized and what your purposes are. It might even be possible that you don\u2019t need a hierarchy as shown in Diagram 1. In our case, we know that the transcripts are linked to the audio-interviews, persons are linked to interviews and audio-interviews, photographs are linked to audio-interviews and transcripts plus locations are linked to the photographs. How the practical arrangement finally looks like depends on your purposes and preferences. For example we could choose to arrange the data with regards to their audio source as seen in Diagram 2: Diagram 2: Focus on the audio-interview. However, we can also prefer another visualization which focuses on the transcript (Diagram 3): Diagram 3: Focus on the transcript. We could think of many different hierarchies, lastly it depends on what serves your purposes best. Our next step will be to implement the hierarchy in Diagram 3 in our data model. Creating the data model 1. Create resource classes First, we create the resource classes that constitute the basic containers of our data model as depicted in Diagram 1: 2. Relate resource classes According to our Diagram 3, we determined the transcript to be the center of the hierarchy. In the transcript, the photographs are mentioned, the interviewed person is linked to the transcript and the audio-interview as the raw resource is linked to the transcript too. Thus, we have to add photograph, audio-interview and person as properties to the transcript. In the box of Transcript click on + Add property : In the window that appears we hover over Create new from type , in the appearing box we hover over Link and in the next appearing box we click on Resource class . By clicking on Resource class , the following window pops up: We can now fill in Property label Audio , and in Select resource class we choose from the list Audio-Interview . We should add a comment in at least one language to describe the property. It might also make sense to toggle Required field? since a transcript has to be extracted from the audio-interview: Finally, we click the Add to class button as seen below: We should then see the new property, which is a class added to the Transcript properties: After the definition of the whole hierarchy as seen in Diagram 3, the data model looks like this: The resource class Transcript has the resource classes Audio-Interview , Photograph and Person as linked properties. Furthermore, the resource class Photograph has the class Location as linked property. In such a way we reflect the central position of Transcript in our data model.","title":"Project Administration"},{"location":"DSP-APP/user-guide/project/#project-administration","text":"","title":"Project Administration"},{"location":"DSP-APP/user-guide/project/#project","text":"Once you are logged in , the dashboard displays the list of your project(s). If you are a project administrator or a system administrator, you can edit the project information or archive your project from the project menu. Archived projects are stored in a list on your dashboard and they can be \"reactivated\" at any time. https://admin.dasch.swiss/dashboard - By clicking on the project name, you get access to the full project information. A system administrator can create a new research project. This currently requires essential information such as the project name, a shortcode and a shortname (both provided by DaSCH). A short project description is optional, but highly recommended. Form to create a new project. As project administrator or system administrator, you can define your project, add your team members, create permission groups and - most important - define your data model (ontology) and the lists of your project. https://admin.dasch.swiss/project/0803/info - Project management functionalities; e.g. Incunabula project. Project information page is displayed without restricted content, the other functionalities are reserved for project admin and system admin.","title":"Project"},{"location":"DSP-APP/user-guide/project/#project-members","text":"As a system administrator or a project administrator, you can add users as project members. A user menu with different actions is accessible for each member of the project (the three-dot icon to the right side of the user line). The admin can grant another user as project admin (or remove this permission), edit user's information, change user's password if forgotten, and remove a user from the project. https://admin.dasch.swiss/project/0803/collaboration - Project members page where project admin and system admin can add new user to the team.","title":"Project members"},{"location":"DSP-APP/user-guide/project/#data-model","text":"The definition of the data model ( ontology ) is the most important step. The data model is indispensable for structuring your data. Our platform provides a tool for an easy creation of one or more project data models. First, you have to know which data and resources you want to work with. The data model can be flexible and customizable. The question which you have to answer before you create your data model is according to which criteria do you organize your data ? In this respect it may be useful to ask yourself: How are your data organized? What are the goals you want to achieve, which research questions do you want to answer? As soon as you have come to a conclusion concerning the structure of your data, you're all set to create your data model.","title":"Data model"},{"location":"DSP-APP/user-guide/project/#create-your-data-model","text":"Go to Data model and click New data model Go to your project, select the tab Data model (step 1) and click the button New data model (step 2) as shown below: By clicking New data model , a dialog box opens: Create data model Now you have to set a unique name ( please consider the NOTE ) and you can add a comment. Push the button Create to create your data model. NOTE: There are some rules for the unique name: must be at least 3 characters long shouldn't start with a number shouldn't start with the letter v and a number spaces or special characters are not allowed may not contain these reserved terms: knora ontology salsah shared simple standoff the unique name can't be changed afterwards! The label is a combination of the project's shortname and the unique name. You can replace it with any other string. After the creation of your data model, your page should look like this:","title":"Create your data model"},{"location":"DSP-APP/user-guide/project/#create-resource-classes","text":"You can then create a resource class by clicking the button + Create new class : By clicking + Create new class , a small window pops up with six basic types to choose from: Which type you choose depends on the data type which you need to describe. Let's assume you have pdf-documents of books and they have a number of pages. To describe this in an ontology, you create a class as Document by clicking on Document . A dialog box pops up which looks like this: For the label you could write Book , and you should add a preferably meaningful comment in at least one of the predefined languages English (en), German (de), French (fr) or Italian (it). Then click the Submit button: Now you have created your first class Book , as seen below:","title":"Create resource CLASSES"},{"location":"DSP-APP/user-guide/project/#add-properties-to-a-resource-class","text":"Now you can add properties to your class. Your pdf of a book has a number of pages. Hence, it may be useful to define the number of pages as one of the properties of your class Book . Click on + Add Property in the Book box: Theoretically, you have two options now. If you defined properties before, you may simply add them here (second option in the following image). If you just start adding properties, you have to choose Create new from type . By hovering over Create new from type , a new menu box appears: You can choose from a selection of the following basic types with various subtypes: Text ( Short , Paragraph , Rich Text ) List ( Dropdown ) Boolean ( Yes/No selection; checkbox) Date / Time ( Date , Timestamp , Time sequence ) Number ( Integer , Decimal , Page number ) Link / Relation ( Link to Class , Part of Class , External URL ) Location ( Place ; a geonames-identifier ) Shape ( color ) Since in our example you want to add a property for the number of pages of your book, you choose Number . Now you will see that you can either choose the type Decimal , Integer or Page number for your property. Page numbers have no decimal places, thus you will select Integer (or Page number which is a special case (s. next section )) as the type for your property. The following window pops up: In the field Property label add for example Number of pages , in the comment section you should add a meaningful explanation. It might also make sense to toggle Required field? since every PDF Document consists of a number of pages. If you toggle it, the number of pages MUST be given if you add data to the class Book - it would then be a required field, not an optional one and data could only be saved if you add the number of pages. If you want to define a property which can have more than one value, you should tick Multiple values? . For the number of pages of a book this does not make sense, but in the case you want to define a property describing which people are mentioned in your Book , the option multiple values is likely to be needed. Now you should see the new property in the box as seen below:","title":"Add PROPERTIES to a resource class"},{"location":"DSP-APP/user-guide/project/#correct-property-selection-in-case-of-special-classes","text":"","title":"Correct property selection in case of special classes"},{"location":"DSP-APP/user-guide/project/#book-class-with-pages-as-individual-classes","text":"If you have single digitized pages of a book in your project, they can be defined as its own individual Still image class type. In this case the \u2014 let's call it Page \u2014 class needs two specific properties to work the correct way. One is the part of -property which can be found in the list of properties in the section \"Link / Relation\". This property points to the main class called Book (which should be defined first and is type of Object without representation ). The second property is for the page number definition and is also necessary. This default property can be found in the list of properties in the section called \"Number\". This is how a book and the page class could look like:","title":"Book class with pages as individual classes"},{"location":"DSP-APP/user-guide/project/#define-lists","text":"One of the possible property types to choose from is List . Lists are very useful if you want to use controlled vocabulary to describe something. Typical examples are keywords. In your book example it may be useful to define a property which describes to which category of literature your pdf of a book belongs. Before you can add a property of type List to your data model, you have to define this list. For the definiton of a list you have to change to the Lists tab: Click Create your first list . If there is already a list defined, click New list . A new window pops up where you have to enter a name for your list ( List label ) and a short description, then click Create . As soon as the list is created you can continue with the definition of your data model. You can define the individual list items later. How to do this will be explained below. We first focus on the definition of a list property in the data model. Currently there is only one option for displaying a property of type List , namely Dropdown . It is capable of displaying flat as well as hierarchical lists. A new window opens up and as in the case of other properties you have to add a label, a desciption and to choose whether multiple values are allowed and/or whether this property is a required field. But in addition you have to select the list which contains your controlled vocabulary.","title":"Define Lists"},{"location":"DSP-APP/user-guide/project/#how-to-define-items-in-a-list","text":"In our example we have created a list named Category . Now it is time to define the list items. We will list some main literature genres as the first hierarchy in our list. Enter the name of the list node and click the + as shown below: By clicking on the small arrow on the left a second hierarchical level becomes accessible where you can add items in the same was as for the main hierarchy. It is possible to add list items at any time. You may rearrange the order of your list items and add a new list item at a specific position in the list.","title":"How to define items in a list"},{"location":"DSP-APP/user-guide/project/#remove-properties-from-a-resource-class","text":"To remove a property, hover over the property which you want to remove. By doing so you see a white x with a black background (remove button) appearing, it is highlighted in yellow in the image below: Be aware, that you can only remove a property if there are no data yet! If you click the remove button, the property is removed and a green box pops up for a short time:","title":"Remove PROPERTIES from a resource class"},{"location":"DSP-APP/user-guide/project/#delete-a-property","text":"In order to really delete a property you have to go to the Properties section as shown below. Click on Properties , and afterwards click on the waste basket sign of the property which you intend to delete. Be aware, you can only delete properties which are NOT used in a resource class!","title":"Delete a property"},{"location":"DSP-APP/user-guide/project/#delete-a-class","text":"To delete a resource class, click on the three dots in the box of the class which you want to delete. The following box appears and you then have to click Delete resource class . In the alert window popping up, you click the red button Delete . Afterwards, the resource class is deleted.","title":"Delete a CLASS"},{"location":"DSP-APP/user-guide/project/#delete-a-data-model","text":"To delete a whole data model, you have to click the button Delete on the right-hand side in the section Data model configuration . In the alert window appearing, you click the red button Delete . The data model is now deleted.","title":"Delete a data model"},{"location":"DSP-APP/user-guide/project/#an-example","text":"In the following example we focus on how we can reflect about our data before building our model and how a data model can relate classes to each other.","title":"An example"},{"location":"DSP-APP/user-guide/project/#preparing-a-data-model","text":"You have interviewed 20 people and recorded the interviews. During these interviews you talked about photographs. Among all the data collected during the project, the most important are: audio-files of the interview transcribed text of conversations (or transcribe the files within the web application) photographs data about the person you interviewed location where the photograph was taken The following Diagram 1 shows the initial situation: Diagram 1: the initial situation. The second step will be to consider the hierarchy of the data. How your hierarchy looks like depends on which criteria your data were organized and what your purposes are. It might even be possible that you don\u2019t need a hierarchy as shown in Diagram 1. In our case, we know that the transcripts are linked to the audio-interviews, persons are linked to interviews and audio-interviews, photographs are linked to audio-interviews and transcripts plus locations are linked to the photographs. How the practical arrangement finally looks like depends on your purposes and preferences. For example we could choose to arrange the data with regards to their audio source as seen in Diagram 2: Diagram 2: Focus on the audio-interview. However, we can also prefer another visualization which focuses on the transcript (Diagram 3): Diagram 3: Focus on the transcript. We could think of many different hierarchies, lastly it depends on what serves your purposes best. Our next step will be to implement the hierarchy in Diagram 3 in our data model.","title":"Preparing a data model"},{"location":"DSP-APP/user-guide/project/#creating-the-data-model","text":"1. Create resource classes First, we create the resource classes that constitute the basic containers of our data model as depicted in Diagram 1: 2. Relate resource classes According to our Diagram 3, we determined the transcript to be the center of the hierarchy. In the transcript, the photographs are mentioned, the interviewed person is linked to the transcript and the audio-interview as the raw resource is linked to the transcript too. Thus, we have to add photograph, audio-interview and person as properties to the transcript. In the box of Transcript click on + Add property : In the window that appears we hover over Create new from type , in the appearing box we hover over Link and in the next appearing box we click on Resource class . By clicking on Resource class , the following window pops up: We can now fill in Property label Audio , and in Select resource class we choose from the list Audio-Interview . We should add a comment in at least one language to describe the property. It might also make sense to toggle Required field? since a transcript has to be extracted from the audio-interview: Finally, we click the Add to class button as seen below: We should then see the new property, which is a class added to the Transcript properties: After the definition of the whole hierarchy as seen in Diagram 3, the data model looks like this: The resource class Transcript has the resource classes Audio-Interview , Photograph and Person as linked properties. Furthermore, the resource class Photograph has the class Location as linked property. In such a way we reflect the central position of Transcript in our data model.","title":"Creating the data model"},{"location":"DSP-APP/user-guide/publication/","text":"Publication \u26a0 NOT YET IMPLEMENTED","title":"Publication"},{"location":"DSP-APP/user-guide/publication/#publication","text":"\u26a0 NOT YET IMPLEMENTED","title":"Publication"},{"location":"DSP-APP/user-guide/system/","text":"System Administration \u26a0 Only for System administrator System administrators can get an overview of all projects and all users stored in DSP. System administration part is accessible from the user menu in the header. All projects System admin gets the list of all activated projects as well as archived projects. It is possible to create a new research project, the required information must be filled in. For each project, the system admin has the possibility to edit the project information and archive the project. Overview of all activated projects, the list of archived projects is displayed below. All users System admin gets the list of all activated and suspended users registered in DSP. New users can be created from this page only (button \"Create new\"). Overview of all users where the system admin has access to several actions. For each user, the system admin has access to several actions: Add as system admin or Remove as system admin : add or remove the user role of system admin Edit user : edit the user information (e.g. first name, last name, default language) Change user's password : the system admin can update the user's password if the user has forgotten it, the system admin must enter his password first (\u26a0 a reset password functionality will be implemented in a later version on the login page) Manage project membership : the system admin can assign the selected user to one or several project, or remove the user from a specific project Suspend user : the user is deactivated and no longer has access to DSP-APP. The system admin can reactivate it at any time.","title":"System Administration"},{"location":"DSP-APP/user-guide/system/#system-administration","text":"\u26a0 Only for System administrator System administrators can get an overview of all projects and all users stored in DSP. System administration part is accessible from the user menu in the header.","title":"System Administration"},{"location":"DSP-APP/user-guide/system/#all-projects","text":"System admin gets the list of all activated projects as well as archived projects. It is possible to create a new research project, the required information must be filled in. For each project, the system admin has the possibility to edit the project information and archive the project. Overview of all activated projects, the list of archived projects is displayed below.","title":"All projects"},{"location":"DSP-APP/user-guide/system/#all-users","text":"System admin gets the list of all activated and suspended users registered in DSP. New users can be created from this page only (button \"Create new\"). Overview of all users where the system admin has access to several actions. For each user, the system admin has access to several actions: Add as system admin or Remove as system admin : add or remove the user role of system admin Edit user : edit the user information (e.g. first name, last name, default language) Change user's password : the system admin can update the user's password if the user has forgotten it, the system admin must enter his password first (\u26a0 a reset password functionality will be implemented in a later version on the login page) Manage project membership : the system admin can assign the selected user to one or several project, or remove the user from a specific project Suspend user : the user is deactivated and no longer has access to DSP-APP. The system admin can reactivate it at any time.","title":"All users"},{"location":"DSP-APP/user-guide/user/","text":"User Profile Your user profile and projects To change your personal information as well as your default language used by the interface, you can edit your profile by clicking Edit my profile . Currently, the avatar image comes from gravatar.com (go on their website to register if you want your customized user photo). https://admin.dasch.swiss/dashboard - Overview of your user profile and your projects. The list of your projects is accessible from here, click on one project to get more information about it. As a project admin, you can also edit or archive your projects, and as a system admin, you can additionally create new projects. Edit your user profile. The username, the email address, and the admin rules are not editable. Your account As a matter of security, it is strongly recommended to update your password at least once a year. On your account page, you can update your password. https://admin.dasch.swiss/account - Update your password and deactivate your user account. \u26a0 You can delete (deactivate) your own user account. However, only a system administrator will be able to reactivate it.","title":"User Profile"},{"location":"DSP-APP/user-guide/user/#user-profile","text":"","title":"User Profile"},{"location":"DSP-APP/user-guide/user/#your-user-profile-and-projects","text":"To change your personal information as well as your default language used by the interface, you can edit your profile by clicking Edit my profile . Currently, the avatar image comes from gravatar.com (go on their website to register if you want your customized user photo). https://admin.dasch.swiss/dashboard - Overview of your user profile and your projects. The list of your projects is accessible from here, click on one project to get more information about it. As a project admin, you can also edit or archive your projects, and as a system admin, you can additionally create new projects. Edit your user profile. The username, the email address, and the admin rules are not editable.","title":"Your user profile and projects"},{"location":"DSP-APP/user-guide/user/#your-account","text":"As a matter of security, it is strongly recommended to update your password at least once a year. On your account page, you can update your password. https://admin.dasch.swiss/account - Update your password and deactivate your user account. \u26a0 You can delete (deactivate) your own user account. However, only a system administrator will be able to reactivate it.","title":"Your account"},{"location":"DSP-APP/user-guide/data/search-results/","text":"Search results The results of the search are displayed in an organized list . You can select one result at a time to get more information. Search result 1: Simple list of results, similar to Google's list of results. \u26a0 It is not possible to sort or order by criteria when searching with the full-text search, use the advanced search or the expert search instead to get back sorted results.","title":"Search results"},{"location":"DSP-APP/user-guide/data/search-results/#search-results","text":"The results of the search are displayed in an organized list . You can select one result at a time to get more information. Search result 1: Simple list of results, similar to Google's list of results. \u26a0 It is not possible to sort or order by criteria when searching with the full-text search, use the advanced search or the expert search instead to get back sorted results.","title":"Search results"},{"location":"DSP-APP/user-guide/data/search/","text":"Search and browse DSP-APP offers the possibility for the user to search in 3 different ways: full-text search, advanced search, and expert search (Gravsearch query). The search bar is always available in the header of each page, whether logged in or out. Full-text search The full-text search performs queries including one or more terms or phrases and returns data that matches the search conditions. By default, the search is performed in all projects stored in DSP. However, it is possible to filter by project using the \"Filter by project\" menu on the left side of the search bar. https://admin.dasch.swiss - Search 1: Full-text search When clicking on the search bar, the search history panel is displayed. The last 10 searches are registered. It is also possible to clear the search history list ( Clear list button at the bottom of the panel or the x at the end of each line). Search history list is accessible for the full-text search from any webpage. Special syntax: question mark? can be used as a wildcard symbol for a single character. asterisk* can be used as a wildcard symbol for zero, one, or multiple characters. \"quotation marks\" searches for the whole pattern. Advanced search The advanced search allows the creation of complex queries using a form. The form creates a string representing a Gravsearch (SPARQL) query to be sent to DSP-API. A query consists of the following elements: selection of the data model selection of a resource class belonging to the selected data model (optional) specification of properties, comparison operators, and values (optional). Although the selection of a resource or a property or both are optional, either a resource class has to be selected or at least one property has to be specified, otherwise, the query is not considered valid and cannot be submitted. https://admin.dasch.swiss - Search 2: Advanced search offers many filter combinations and is a powerful search tool. Comparison Operators Depending on the value type of the chosen property, one or more of the following comparison operators can be selected: is equal to : value equality: same number, exact same string, an overlap of date periods, same target resource. is not equal to : value inequality: not same number, not exact same string, no overlap of date periods, not same target resource. is greater than : value comparison: number is greater than search value, date period begins after search value. is greater than or equal to value equality/value comparison: number is equal to or greater than search value, an overlap of date periods or date period begins after search value. is less than : value comparison: number is less than search value, date period ends before search value. is less than or equal to : value equality/value comparison: number is equal to or less than search value, an overlap of date periods or date period ends before search value. exists : value for the given property exists. is like : search value is contained in a text using the SPARQL REGEX function (supports regular expressions). matches : text property: search value matches the text ( Lucene Query Parser Syntax ). linking property: matches the specified linked resource. Search Examples is like (regular Expressions) The is like operator lets the user search for texts that are like the search value via the support of regular expressions In this example, all books are found whose title contains \"Narrenschiff\" followed by a space and some other characters like \"(lat.)\" or \"(dt.)\". For general information about regular expressions, see this interactive tutorial . matches (Lucene Parser Syntax) Used with a text property, the matches operator lets the user search for texts that match the search value, supporting Lucene Query Parser Syntax . In this example, all persons are found whose names contain \"Ja\" and \"ob\" with a character in between (represented by the wildcard \"?\"). This search finds \"Jacob\" as well as \"Jakob\". Note the difference between regular expressions and Lucene parser syntax! matches (specifying a Linked Resource) Used with a linking property, the matches operator lets the user search for a linked resource that matches the specified properties. In this example, the user writes a query looking for all letters that have an author that: was born after January 1st, 1650 whose family name is \"Bernoulli\" This is different from the \"is equal to\" operator that lets the user specify a certain person (selected from a list). Expert search The expert search can be more powerful than the advanced search, but requires knowing how to use the query language Gravsearch (based on SparQL and developed by the DaSCH team). With Gravsearch, expert users can build searches by combining text-related criteria with any other criteria. For example : you could search for a page in a manuscript that contains a certain element and also mentions a person, who lived in the same country as another person, who is the author of another author. https://admin.dasch.swiss - Search 3: Expert search is a text area in which you can create Gravsearch queries. Here is the default example you can find in the app. To learn Gravsearch, go to the DSP-API documentation \u2192 Gravsearch","title":"Search and browse"},{"location":"DSP-APP/user-guide/data/search/#search-and-browse","text":"DSP-APP offers the possibility for the user to search in 3 different ways: full-text search, advanced search, and expert search (Gravsearch query). The search bar is always available in the header of each page, whether logged in or out.","title":"Search and browse"},{"location":"DSP-APP/user-guide/data/search/#full-text-search","text":"The full-text search performs queries including one or more terms or phrases and returns data that matches the search conditions. By default, the search is performed in all projects stored in DSP. However, it is possible to filter by project using the \"Filter by project\" menu on the left side of the search bar. https://admin.dasch.swiss - Search 1: Full-text search When clicking on the search bar, the search history panel is displayed. The last 10 searches are registered. It is also possible to clear the search history list ( Clear list button at the bottom of the panel or the x at the end of each line). Search history list is accessible for the full-text search from any webpage. Special syntax: question mark? can be used as a wildcard symbol for a single character. asterisk* can be used as a wildcard symbol for zero, one, or multiple characters. \"quotation marks\" searches for the whole pattern.","title":"Full-text search"},{"location":"DSP-APP/user-guide/data/search/#advanced-search","text":"The advanced search allows the creation of complex queries using a form. The form creates a string representing a Gravsearch (SPARQL) query to be sent to DSP-API. A query consists of the following elements: selection of the data model selection of a resource class belonging to the selected data model (optional) specification of properties, comparison operators, and values (optional). Although the selection of a resource or a property or both are optional, either a resource class has to be selected or at least one property has to be specified, otherwise, the query is not considered valid and cannot be submitted. https://admin.dasch.swiss - Search 2: Advanced search offers many filter combinations and is a powerful search tool.","title":"Advanced search"},{"location":"DSP-APP/user-guide/data/search/#comparison-operators","text":"Depending on the value type of the chosen property, one or more of the following comparison operators can be selected: is equal to : value equality: same number, exact same string, an overlap of date periods, same target resource. is not equal to : value inequality: not same number, not exact same string, no overlap of date periods, not same target resource. is greater than : value comparison: number is greater than search value, date period begins after search value. is greater than or equal to value equality/value comparison: number is equal to or greater than search value, an overlap of date periods or date period begins after search value. is less than : value comparison: number is less than search value, date period ends before search value. is less than or equal to : value equality/value comparison: number is equal to or less than search value, an overlap of date periods or date period ends before search value. exists : value for the given property exists. is like : search value is contained in a text using the SPARQL REGEX function (supports regular expressions). matches : text property: search value matches the text ( Lucene Query Parser Syntax ). linking property: matches the specified linked resource.","title":"Comparison Operators"},{"location":"DSP-APP/user-guide/data/search/#search-examples","text":"","title":"Search Examples"},{"location":"DSP-APP/user-guide/data/search/#is-like-regular-expressions","text":"The is like operator lets the user search for texts that are like the search value via the support of regular expressions In this example, all books are found whose title contains \"Narrenschiff\" followed by a space and some other characters like \"(lat.)\" or \"(dt.)\". For general information about regular expressions, see this interactive tutorial .","title":"is like (regular Expressions)"},{"location":"DSP-APP/user-guide/data/search/#matches-lucene-parser-syntax","text":"Used with a text property, the matches operator lets the user search for texts that match the search value, supporting Lucene Query Parser Syntax . In this example, all persons are found whose names contain \"Ja\" and \"ob\" with a character in between (represented by the wildcard \"?\"). This search finds \"Jacob\" as well as \"Jakob\". Note the difference between regular expressions and Lucene parser syntax!","title":"matches (Lucene Parser Syntax)"},{"location":"DSP-APP/user-guide/data/search/#matches-specifying-a-linked-resource","text":"Used with a linking property, the matches operator lets the user search for a linked resource that matches the specified properties. In this example, the user writes a query looking for all letters that have an author that: was born after January 1st, 1650 whose family name is \"Bernoulli\" This is different from the \"is equal to\" operator that lets the user specify a certain person (selected from a list).","title":"matches (specifying a Linked Resource)"},{"location":"DSP-APP/user-guide/data/search/#expert-search","text":"The expert search can be more powerful than the advanced search, but requires knowing how to use the query language Gravsearch (based on SparQL and developed by the DaSCH team). With Gravsearch, expert users can build searches by combining text-related criteria with any other criteria. For example : you could search for a page in a manuscript that contains a certain element and also mentions a person, who lived in the same country as another person, who is the author of another author. https://admin.dasch.swiss - Search 3: Expert search is a text area in which you can create Gravsearch queries. Here is the default example you can find in the app. To learn Gravsearch, go to the DSP-API documentation \u2192 Gravsearch","title":"Expert search"},{"location":"DSP-APP/user-guide/data/start/","text":"Data management Once your data model is ready, you're able to add data. The DSP-APP offers several possibilities to add data, whether you are starting from scratch or importing data from another program. Start from scratch When a project starts from scratch, you will enter and generate new data directly in the DSP-APP itself. Generating new data can be done one by one with a form at the moment: Upload files, e.g., an audio file, photography, a video, or a document Augment the metadata Create new resource instances You can create a new resource instance using the \"create new resource\" form: There is a button to open the create new resource form in the main header. Step1: Select the project you want to work with (if you are part of several ones), select the ontology (if the project has several ones), and then select the resource class you want to create a new instance. Click on Next. Step 1: Create a new resource instance e.g. a new audio file. Step2: Fill in the form and upload the file if requested (depending on the type of resource). Please, note that the required fields are marked with an asterisk * after the property label. Click on Save to create the new resource instance. To go back to Step 1, click on Back . If you cannot click on Save , it means that a required field has not been filled in. Step2: Create a new resource instance e.g. a new audio file in MP3 format. N.B.: Please, note that the image, video, and audio files must be in one of the required file types supported by the database. The supported types are listed in the upload section of the form.","title":"Start from scratch"},{"location":"DSP-APP/user-guide/data/start/#data-management","text":"Once your data model is ready, you're able to add data. The DSP-APP offers several possibilities to add data, whether you are starting from scratch or importing data from another program.","title":"Data management"},{"location":"DSP-APP/user-guide/data/start/#start-from-scratch","text":"When a project starts from scratch, you will enter and generate new data directly in the DSP-APP itself. Generating new data can be done one by one with a form at the moment: Upload files, e.g., an audio file, photography, a video, or a document Augment the metadata","title":"Start from scratch"},{"location":"DSP-APP/user-guide/data/start/#create-new-resource-instances","text":"You can create a new resource instance using the \"create new resource\" form: There is a button to open the create new resource form in the main header. Step1: Select the project you want to work with (if you are part of several ones), select the ontology (if the project has several ones), and then select the resource class you want to create a new instance. Click on Next. Step 1: Create a new resource instance e.g. a new audio file. Step2: Fill in the form and upload the file if requested (depending on the type of resource). Please, note that the required fields are marked with an asterisk * after the property label. Click on Save to create the new resource instance. To go back to Step 1, click on Back . If you cannot click on Save , it means that a required field has not been filled in. Step2: Create a new resource instance e.g. a new audio file in MP3 format. N.B.: Please, note that the image, video, and audio files must be in one of the required file types supported by the database. The supported types are listed in the upload section of the form.","title":"Create new resource instances"},{"location":"DSP-APP/user-guide/data/work-on-data/","text":"Work on your data Once you have found the desired resources, you can (re)view them and annotate the resource itself, the media file, or single metadata values. If you select more than one resource, you can compare them in a side-by-side view or link them. Data permissions In order to know what you are allowed to see or do with the selected resource, please check the permissions that are granted for your user role. You can find more details about the permissions in the documentation of DSP-API . If you don't have the permissions you were supposed to get, please contact the DaSCH team . Check the resource permissions you are granted. Display data Display a resource DSP-APP offers different resource views for different media types (images, videos, audio, archives, text, and document files). You can access the resources from the list of search results. Depending on the media type, DSP-APP offers different tools to work on the resource. Additionally, you can work on the resource directly, e.g, mark regions of interest on images and documents. Each media viewer offers different tools and functionalities, either displayed in the bottom toolbar (e.g. zoom, open in fullscreen button, play button, etc. - captioned in orange thereafter) or in the menu - the three-dot button on the bottom-left side (e.g. copy the ARK URL to the clipboard, download/replace the file, open the file in a new tab - captioned in red thereafter). Single resource view. The resource type in this example is \"Page\" and an image viewer displays the photograph of the manuscript page. Everything about the resource is displayed below the media viewer (when there is one). All the information about the resource itself (e.g. type, label, permissions, creator, date of creation, etc.), the data (properties and values), and different functionalities such as editing, deleting, sharing the resource. You can find more information about the functionalities in the following sections. Audio file Supported file types: mp3 , wav Image file Supported file types: jpeg , jp2 , jpg , tiff , tif , png In a resource of type \"still image\", you're able to draw regions on the image and annotate this region. Usually, a still image resource is used for book pages, photographs, postcards, letters, etc. When you open a resource that contains an image, it is displayed in a viewer. Several functionalities are accessible from the image viewer, e.g. zoom in/out, copy the IIIF link, replace the image or draw a region on the image. To access the regions, go to the annotation panel. You can click on an existing region in the image viewer, the focus of the page will be redirected to the annotation information. Access the annotation panel from the resource toolbar. Document file Supported file types: pdf , doc , docx , xls , xlsx , ppt , pptx Text file Supported file types: csv , txt , xml , xsd , xsl Video file Supported file types: mp4 Archive file Supported file types: 7z , gz , gzip , tar , tgz , z , zip Display resource properties By default, only important properties are shown in the resource viewer. To display them all, click on the \"unfold\" button in the resource toolbar. Show or hide properties from the toolbar. To get more information about the property value, i.e. date of creation and author name, hover over the value and then over the info button. Get the creation date and the author name of the value. Display a value comment To display the existing value comment, hover over the property value and click on the comment button (3rd icon from the left). Hover over the property value to see if there is a comment and display it. Display and compare several resources You can compare 2 or more resources of any type at the same time side by side. From the search result list, select your resources of interest by checking the checkbox (right side of each result) and clicking on the compare button on the right-side tile. Example: Select 3 resources and compare them. To keep in mind: The more you compare, the smaller the resource viewer for each will be. You can deselect one or more resources to remove them from the compare viewer. Visualise your selected resources side-by-side. You can compare 2 images with an object without representation for instance. Add new data \u26a0 You must have the granted permission to proceed. Add a resource See section Create new resource instances . Add a property value You can create a new property value if your data model allows it . The value should have a cardinality of 0-1, 0-N or, 1-N. A \"plus\" button is displayed to the right of the label or after the first value field. You fill in the form field and save the changes by clicking on the floppy disk button. You can undo (back arrow button) or cancel the changes (x button). Add a new property value. Save or undo the changes you made. If your property is linked to another resource, you can search for an existing value by typing the first three letters of the resource label you are looking for. You can also create a new resource instance by clicking on the first option in the drop-down menu, Create new: xxx . Add an image region To create a new region on an image, you click on the button Draw a region in the toolbar, then select the region you want on the image. Select a region on the image with the drawing tool. Enter the information about the region, an informative label and a description as a comment. You can change the color. Fill in the form about the selected region. The new region information is displayed after the image viewer. You can edit or delete if you have the granted permissions. A region has also an AKR URL you can copy and share. A new region has been created. Edit your data \u26a0 You must have the granted permission to proceed. Edit a resource To edit the resource label, open the resource menu on the right-side of the toolbar and click on Edit label . Edit a property value You can edit a property value from the resource viewer. Hover over the value and click on the edit button. Edit button when mousing over the value. You edit your value by changing the text content, searching for another resource label, or creating a new resource instance. Don't forget to save your changes (floppy disk button) or undo them (back arrow button) to leave the edit mode. It is the same process to add, edit or delete a comment to the value. Delete your data \u26a0 You must have the granted permission to proceed. Delete or erase a resource To delete a resource, there are 2 possibilities: Delete resource: the resource is not searchable or findable in DSP-APP anymore but the data still exists in the database. Erase resource: the resource is permanently deleted from the database, it will be impossible to get it back. Delete or erase a resource. Delete a property value You can delete a property value. Hover over the value and click on the delete button. You have to confirm your choice. It is possible to comment on the deletion of the value in the confirmation pop-up window to explain why it is being deleted. Delete a property value. Annotate and link data The main feature of the flexible data storage that DSP-APP uses is the possibility to annotate and link resources and their metadata. An annotation can be a small note about a date like \"Not sure about the birthdate of this person. There's another date mentioned in the resource XYZ\". Inside the note, it will be possible to link to another resource. Links in DSP-APP are always bi-directional. If you link resource A with resource B, then resource B knows about this connection. If you find resource B, you have the connection to resource A as well. It is possible to link resources of the same project or from 2 different projects. DSP-APP offers two ways to link data: Internal linkage: it allows you to create a direct link between 2 resources. The label of the linking resource (source) will appear in the \u201eincoming links\u201c section of the targeted resource. You will choose this option when you want to embed the link in a text. Link object: it allows you to create an annotation (the description of the link object) that can point to one or more resources. You will prefer this option if you want the link to exist and describe it. Internal linkage To link 2 resources (A is an image and B is a document in the example), you go to your resource A that will be linked, open the Share menu and click on the button Copy internal link on clipboard . You have copied the internal link of your resource A that will be used to make the link with your resource B. Copy the internal link of the resource A. Go to your resource B. You click on the edit button of the property value where you want to add the link (by hovering over the value content). This value must be of type rich text . Edit the property value of type rich text to add the link. You write and select a word or a group of words you want to attach the link to, then click on the Link button in the toolbar of the text editor, paste the internal link of resource A here, and click on Save . Add the link in your text and save. The word (or the group of words) is now highlighted in blue-grey and is clickable. The link has been added to your text. Link Object To create a link object, the process starts from the search result list. You select 2 or more resources from the list and click on the button Create a link object from this selection. Select the resources to link. You fill out the form indicating the project in which you want to register the link object, as well as a label to identify it. Optionally, you can add a comment (annotation) to describe this collection of resources. Then, click on Create. Fill in the form about the new link object. The linked resources are listed in the has Link to property of the link object resource viewer. The label of your link object is searchable through a full-text search . It is possible to add other resources later on by clicking on the + button in the has Link to property section. Share your data Each resource of your dataset gets an ARK URL (Archival Resource Key), a persistent identifier that will allow you to permanently cite your resource in papers, conference presentations, books, etc. You will find it in the Share menu of the resource toolbar, click on Copy ARK to clipboard to copy and paste it wherever you want. Copy ARK URL.","title":"Work on your data"},{"location":"DSP-APP/user-guide/data/work-on-data/#work-on-your-data","text":"Once you have found the desired resources, you can (re)view them and annotate the resource itself, the media file, or single metadata values. If you select more than one resource, you can compare them in a side-by-side view or link them.","title":"Work on your data"},{"location":"DSP-APP/user-guide/data/work-on-data/#data-permissions","text":"In order to know what you are allowed to see or do with the selected resource, please check the permissions that are granted for your user role. You can find more details about the permissions in the documentation of DSP-API . If you don't have the permissions you were supposed to get, please contact the DaSCH team . Check the resource permissions you are granted.","title":"Data permissions"},{"location":"DSP-APP/user-guide/data/work-on-data/#display-data","text":"","title":"Display data"},{"location":"DSP-APP/user-guide/data/work-on-data/#display-a-resource","text":"DSP-APP offers different resource views for different media types (images, videos, audio, archives, text, and document files). You can access the resources from the list of search results. Depending on the media type, DSP-APP offers different tools to work on the resource. Additionally, you can work on the resource directly, e.g, mark regions of interest on images and documents. Each media viewer offers different tools and functionalities, either displayed in the bottom toolbar (e.g. zoom, open in fullscreen button, play button, etc. - captioned in orange thereafter) or in the menu - the three-dot button on the bottom-left side (e.g. copy the ARK URL to the clipboard, download/replace the file, open the file in a new tab - captioned in red thereafter). Single resource view. The resource type in this example is \"Page\" and an image viewer displays the photograph of the manuscript page. Everything about the resource is displayed below the media viewer (when there is one). All the information about the resource itself (e.g. type, label, permissions, creator, date of creation, etc.), the data (properties and values), and different functionalities such as editing, deleting, sharing the resource. You can find more information about the functionalities in the following sections.","title":"Display a resource"},{"location":"DSP-APP/user-guide/data/work-on-data/#audio-file","text":"Supported file types: mp3 , wav","title":"Audio file"},{"location":"DSP-APP/user-guide/data/work-on-data/#image-file","text":"Supported file types: jpeg , jp2 , jpg , tiff , tif , png In a resource of type \"still image\", you're able to draw regions on the image and annotate this region. Usually, a still image resource is used for book pages, photographs, postcards, letters, etc. When you open a resource that contains an image, it is displayed in a viewer. Several functionalities are accessible from the image viewer, e.g. zoom in/out, copy the IIIF link, replace the image or draw a region on the image. To access the regions, go to the annotation panel. You can click on an existing region in the image viewer, the focus of the page will be redirected to the annotation information. Access the annotation panel from the resource toolbar.","title":"Image file"},{"location":"DSP-APP/user-guide/data/work-on-data/#document-file","text":"Supported file types: pdf , doc , docx , xls , xlsx , ppt , pptx","title":"Document file"},{"location":"DSP-APP/user-guide/data/work-on-data/#text-file","text":"Supported file types: csv , txt , xml , xsd , xsl","title":"Text file"},{"location":"DSP-APP/user-guide/data/work-on-data/#video-file","text":"Supported file types: mp4","title":"Video file"},{"location":"DSP-APP/user-guide/data/work-on-data/#archive-file","text":"Supported file types: 7z , gz , gzip , tar , tgz , z , zip","title":"Archive file"},{"location":"DSP-APP/user-guide/data/work-on-data/#display-resource-properties","text":"By default, only important properties are shown in the resource viewer. To display them all, click on the \"unfold\" button in the resource toolbar. Show or hide properties from the toolbar. To get more information about the property value, i.e. date of creation and author name, hover over the value and then over the info button. Get the creation date and the author name of the value.","title":"Display resource properties"},{"location":"DSP-APP/user-guide/data/work-on-data/#display-a-value-comment","text":"To display the existing value comment, hover over the property value and click on the comment button (3rd icon from the left). Hover over the property value to see if there is a comment and display it.","title":"Display a value comment"},{"location":"DSP-APP/user-guide/data/work-on-data/#display-and-compare-several-resources","text":"You can compare 2 or more resources of any type at the same time side by side. From the search result list, select your resources of interest by checking the checkbox (right side of each result) and clicking on the compare button on the right-side tile. Example: Select 3 resources and compare them. To keep in mind: The more you compare, the smaller the resource viewer for each will be. You can deselect one or more resources to remove them from the compare viewer. Visualise your selected resources side-by-side. You can compare 2 images with an object without representation for instance.","title":"Display and compare several resources"},{"location":"DSP-APP/user-guide/data/work-on-data/#add-new-data","text":"\u26a0 You must have the granted permission to proceed.","title":"Add new data"},{"location":"DSP-APP/user-guide/data/work-on-data/#add-a-resource","text":"See section Create new resource instances .","title":"Add a resource"},{"location":"DSP-APP/user-guide/data/work-on-data/#add-a-property-value","text":"You can create a new property value if your data model allows it . The value should have a cardinality of 0-1, 0-N or, 1-N. A \"plus\" button is displayed to the right of the label or after the first value field. You fill in the form field and save the changes by clicking on the floppy disk button. You can undo (back arrow button) or cancel the changes (x button). Add a new property value. Save or undo the changes you made. If your property is linked to another resource, you can search for an existing value by typing the first three letters of the resource label you are looking for. You can also create a new resource instance by clicking on the first option in the drop-down menu, Create new: xxx .","title":"Add a property value"},{"location":"DSP-APP/user-guide/data/work-on-data/#add-an-image-region","text":"To create a new region on an image, you click on the button Draw a region in the toolbar, then select the region you want on the image. Select a region on the image with the drawing tool. Enter the information about the region, an informative label and a description as a comment. You can change the color. Fill in the form about the selected region. The new region information is displayed after the image viewer. You can edit or delete if you have the granted permissions. A region has also an AKR URL you can copy and share. A new region has been created.","title":"Add an image region"},{"location":"DSP-APP/user-guide/data/work-on-data/#edit-your-data","text":"\u26a0 You must have the granted permission to proceed.","title":"Edit your data"},{"location":"DSP-APP/user-guide/data/work-on-data/#edit-a-resource","text":"To edit the resource label, open the resource menu on the right-side of the toolbar and click on Edit label .","title":"Edit a resource"},{"location":"DSP-APP/user-guide/data/work-on-data/#edit-a-property-value","text":"You can edit a property value from the resource viewer. Hover over the value and click on the edit button. Edit button when mousing over the value. You edit your value by changing the text content, searching for another resource label, or creating a new resource instance. Don't forget to save your changes (floppy disk button) or undo them (back arrow button) to leave the edit mode. It is the same process to add, edit or delete a comment to the value.","title":"Edit a property value"},{"location":"DSP-APP/user-guide/data/work-on-data/#delete-your-data","text":"\u26a0 You must have the granted permission to proceed.","title":"Delete your data"},{"location":"DSP-APP/user-guide/data/work-on-data/#delete-or-erase-a-resource","text":"To delete a resource, there are 2 possibilities: Delete resource: the resource is not searchable or findable in DSP-APP anymore but the data still exists in the database. Erase resource: the resource is permanently deleted from the database, it will be impossible to get it back. Delete or erase a resource.","title":"Delete or erase a resource"},{"location":"DSP-APP/user-guide/data/work-on-data/#delete-a-property-value","text":"You can delete a property value. Hover over the value and click on the delete button. You have to confirm your choice. It is possible to comment on the deletion of the value in the confirmation pop-up window to explain why it is being deleted. Delete a property value.","title":"Delete a property value"},{"location":"DSP-APP/user-guide/data/work-on-data/#annotate-and-link-data","text":"The main feature of the flexible data storage that DSP-APP uses is the possibility to annotate and link resources and their metadata. An annotation can be a small note about a date like \"Not sure about the birthdate of this person. There's another date mentioned in the resource XYZ\". Inside the note, it will be possible to link to another resource. Links in DSP-APP are always bi-directional. If you link resource A with resource B, then resource B knows about this connection. If you find resource B, you have the connection to resource A as well. It is possible to link resources of the same project or from 2 different projects. DSP-APP offers two ways to link data: Internal linkage: it allows you to create a direct link between 2 resources. The label of the linking resource (source) will appear in the \u201eincoming links\u201c section of the targeted resource. You will choose this option when you want to embed the link in a text. Link object: it allows you to create an annotation (the description of the link object) that can point to one or more resources. You will prefer this option if you want the link to exist and describe it.","title":"Annotate and link data"},{"location":"DSP-APP/user-guide/data/work-on-data/#internal-linkage","text":"To link 2 resources (A is an image and B is a document in the example), you go to your resource A that will be linked, open the Share menu and click on the button Copy internal link on clipboard . You have copied the internal link of your resource A that will be used to make the link with your resource B. Copy the internal link of the resource A. Go to your resource B. You click on the edit button of the property value where you want to add the link (by hovering over the value content). This value must be of type rich text . Edit the property value of type rich text to add the link. You write and select a word or a group of words you want to attach the link to, then click on the Link button in the toolbar of the text editor, paste the internal link of resource A here, and click on Save . Add the link in your text and save. The word (or the group of words) is now highlighted in blue-grey and is clickable. The link has been added to your text.","title":"Internal linkage"},{"location":"DSP-APP/user-guide/data/work-on-data/#link-object","text":"To create a link object, the process starts from the search result list. You select 2 or more resources from the list and click on the button Create a link object from this selection. Select the resources to link. You fill out the form indicating the project in which you want to register the link object, as well as a label to identify it. Optionally, you can add a comment (annotation) to describe this collection of resources. Then, click on Create. Fill in the form about the new link object. The linked resources are listed in the has Link to property of the link object resource viewer. The label of your link object is searchable through a full-text search . It is possible to add other resources later on by clicking on the + button in the has Link to property section.","title":"Link Object"},{"location":"DSP-APP/user-guide/data/work-on-data/#share-your-data","text":"Each resource of your dataset gets an ARK URL (Archival Resource Key), a persistent identifier that will allow you to permanently cite your resource in papers, conference presentations, books, etc. You will find it in the Share menu of the resource toolbar, click on Copy ARK to clipboard to copy and paste it wherever you want. Copy ARK URL.","title":"Share your data"},{"location":"DSP-TOOLS/","text":"DSP-TOOLS documentation DSP-TOOLS is a Python package with a command line interface that helps you interact with a DSP server. A DSP server is a remote server or a local machine where the DSP-API is running on. To install the latest version, run: pip3 install dsp-tools To update to the latest version run: pip3 install --upgrade dsp-tools The two main tasks that DSP-TOOLS serves for are: Create a project with its data model(s), described in a JSON file, on a DSP server In order to archive your data on the DaSCH Service Platform, you need a data model that describes your data. The data model is defined in a JSON project definition file which has to be transmitted to the DSP server. If the DSP server is aware of the data model for your project, conforming data can be uploaded into the DSP repository. Upload data, described in an XML file, to a DSP server that has a project with a matching data model Sometimes, data is added in large quantities. Therefore, DSP-TOOLS allows you to perform bulk imports of your data. In order to do so, the data has to be described in an XML file. DSP-TOOLS is able to read the XML file and upload all data to the DSP server. All functionalities of DSP-TOOLS revolve around these two basic tasks. DSP-TOOLS provides the following functionalities: dsp-tools create creates the project with its data model(s) on a DSP server from a JSON file. dsp-tools get reads a project with its data model(s) from a DSP server and writes it into a JSON file. dsp-tools xmlupload uploads data from an XML file (bulk data import) and writes the mapping from internal IDs to IRIs into a local file. dsp-tools excel2json creates an entire JSON project file from a folder with Excel files in it. dsp-tools excel2lists creates the \"lists\" section of a JSON project file from one or several Excel files. The resulting section can be integrated into a JSON project file and then be uploaded to a DSP server with dsp-tools create . dsp-tools excel2resources creates the \"resources\" section of a JSON project file from an Excel file. The resulting section can be integrated into a JSON project file and then be uploaded to a DSP server with dsp-tools create . dsp-tools excel2properties creates the \"properties\" section of a JSON project file from an Excel file. The resulting section can be integrated into a JSON project file and then be uploaded to a DSP server with dsp-tools create . dsp-tools excel2xml transforms a data source to XML if it is already structured according to the DSP specifications. The module excel2xml provides helper methods that can be used in a Python script to convert data from a tabular format into XML. dsp-tools id2iri takes an XML file for bulk data import and replaces referenced internal IDs with IRIs. The mapping has to be provided with a JSON file. dsp-tools start-stack / stop-stack assist you in running a DSP stack on your local machine.","title":"Overview"},{"location":"DSP-TOOLS/#dsp-tools-documentation","text":"DSP-TOOLS is a Python package with a command line interface that helps you interact with a DSP server. A DSP server is a remote server or a local machine where the DSP-API is running on. To install the latest version, run: pip3 install dsp-tools To update to the latest version run: pip3 install --upgrade dsp-tools The two main tasks that DSP-TOOLS serves for are: Create a project with its data model(s), described in a JSON file, on a DSP server In order to archive your data on the DaSCH Service Platform, you need a data model that describes your data. The data model is defined in a JSON project definition file which has to be transmitted to the DSP server. If the DSP server is aware of the data model for your project, conforming data can be uploaded into the DSP repository. Upload data, described in an XML file, to a DSP server that has a project with a matching data model Sometimes, data is added in large quantities. Therefore, DSP-TOOLS allows you to perform bulk imports of your data. In order to do so, the data has to be described in an XML file. DSP-TOOLS is able to read the XML file and upload all data to the DSP server. All functionalities of DSP-TOOLS revolve around these two basic tasks. DSP-TOOLS provides the following functionalities: dsp-tools create creates the project with its data model(s) on a DSP server from a JSON file. dsp-tools get reads a project with its data model(s) from a DSP server and writes it into a JSON file. dsp-tools xmlupload uploads data from an XML file (bulk data import) and writes the mapping from internal IDs to IRIs into a local file. dsp-tools excel2json creates an entire JSON project file from a folder with Excel files in it. dsp-tools excel2lists creates the \"lists\" section of a JSON project file from one or several Excel files. The resulting section can be integrated into a JSON project file and then be uploaded to a DSP server with dsp-tools create . dsp-tools excel2resources creates the \"resources\" section of a JSON project file from an Excel file. The resulting section can be integrated into a JSON project file and then be uploaded to a DSP server with dsp-tools create . dsp-tools excel2properties creates the \"properties\" section of a JSON project file from an Excel file. The resulting section can be integrated into a JSON project file and then be uploaded to a DSP server with dsp-tools create . dsp-tools excel2xml transforms a data source to XML if it is already structured according to the DSP specifications. The module excel2xml provides helper methods that can be used in a Python script to convert data from a tabular format into XML. dsp-tools id2iri takes an XML file for bulk data import and replaces referenced internal IDs with IRIs. The mapping has to be provided with a JSON file. dsp-tools start-stack / stop-stack assist you in running a DSP stack on your local machine.","title":"DSP-TOOLS documentation"},{"location":"DSP-TOOLS/changelog/","text":"Changelog 2.1.0 (2023-02-21) Bug Fixes create: improve validation to prevent endless loop if properties are undefined (DEV-1720) ( #297 ) ( ee3e446 ) create: property from other ontology not found (DEV-1381) #299 ( d1345ec ) Documentation fix identical heading problem, assimilate mkdocs config to dsp-docs (DEV-1713) ( #294 ) ( c235ff3 ) Enhancements excel2json: add support for gui_order, make templates better understandable (DEV-1711) ( #293 ) ( 3b5304f ) Maintenance bump start-stack to 2023.02.02 (DEV-1732) #302 ( b97a696 ) enhanced xmlupload: add test onto (DEV-1760) #300 ( ca32842 ) excel2xml: allow PathLike for bitstream-prop (DEV-1729) #298 ( ab9386f ) remove temporary workaround in GET groups (DEV-1733) #301 ( 7ead9de ) 2.0.3 (2023-02-07) Documentation restructure docs, add link-checking (DEV-1623) ( #286 ) ( d65ff53 ) Maintenance access data files correctly (DEV-1618) ( #288 ) ( 7a64a27 ) bump start-stack to 2023.02.01 (DEV-1709) ( #292 ) ( 5fd58d2 ) bump versions of start-stack to 2023.01.02 (DEV-1652) ( #290 ) ( 2889a20 ) update links according to new structure of docs (DEV-1648) ( #289 ) ( 16d9c12 ) 2.0.2 (2023-01-17) Bug Fixes get command fails if no groups are on the server (DEV-1622) ( #283 ) ( d6bf458 ) Documentation fix broken links, make dsp-tools uppercase (DEV-1550) ( #284 ) ( aa66109 ) 2.0.1 (2023-01-17) Maintenance bump versions of start-stack, use dynamic project IRI in get command (DEV-1613) ( #282 ) ( 2ecf4f5 ) refactor project creation (DEV-1165) ( #280 ) ( 5e662a6 ) use start-stack command for e2e tests, replace Makefile by poetry-exec-plugin (DEV-1597) ( #279 ) ( 6b85d15 ) 2.0.0 (2023-01-09) \u26a0 BREAKING CHANGES switch to src layout, use poetry, add developer docs (DEV-1523) ( #276 ) Maintenance adapt schema URLs, adapt title of release-please PR (DEV-1596) ( #278 ) ( 67f6475 ) switch to src layout, use poetry, add developer docs (DEV-1523) ( #276 ) ( 6ae3b4f ) 1.22.2 (2022-12-21) Bug Fixes start-stack: copy docker folder to user's home directory (DEV-1581) ( #274 ) ( b0ebfc5 ) 1.22.1 (2022-12-20) Bug Fixes start-stack: use TTL files from DSP-API v24.0.8 (DEV-1580) ( #273 ) ( 3ad96ba ) Documentation improve documentation of DSP permission system (DEV-1561) ( #270 ) ( 33ab59d ) 1.22.0 (2022-12-19) Bug Fixes excel2xml: better standard permissions (permissions definitions at top of XML file) (DEV-1560) ( #268 ) ( b0d30be ) xmlupload: improve URL recognition (DEV-1557) ( #266 ) ( 60f8fe5 ) xmlupload: prevent crash + improve error message when cardinalities are wrong (DEV-1559) #267 ( 7bfd82f ) Documentation excel2json: use rosetta as example data (DEV-1478) ( #254 ) ( af192cb ) readme: explain handling of git submodules (DEV-1502) ( #256 ) ( 1dc8483 ) text values: describe which combinations of gui_element and encoding are desirable (DEV-1521) ( #259 ) ( 21967c6 ) Enhancements use docker commands for stack handling (DEV-1530) ( #261 ) ( c11edc5 ) Maintenance bump versions of GitHub actions (DEV-1532) #263 ( efc9f51 ) fix regex for PR title (DEV-1504) ( #257 ) ( d4feb68 ) start-api: adjust version numbers of DSP-API and DSP-APP according to 2022.11.01 (DEV-1579) #271 ( 10dcd2f ) xmlupload: add metrics flag (DEV-1512) ( #264 ) ( f4822dc ) xmlupload: handling of upload errors (DEV-1505) ( #250 ) ( 1507b21 ) 1.21.0 (2022-11-11) Bug Fixes bugs in json schema (DEV-1142) ( #252 ) ( 92af830 ) excel2xml: prevent writing empty text-prop, make text-prop validation less restrictive (DEV-1440) #243 ( ae777e4 ) Enhancements add command excel2json to create JSON project file from folder with Excel files (DEV-960) ( #248 ) ( e8e05e4 ) startup API and APP with dsp-tools (DEV-126) ( #246 ) ( de182dc ) Documentation improve docs (DEV-1478) ( #249 ) ( 7947dec ) 1.20.0 (2022-10-18) Maintenance xmlupload: improve error message when syntax for referencing ontos is wrong (DEV-1399) ( #237 ) ( df0bf33 ) Documentation user needs to be project member to become project admin (DEV-1383) ( #241 ) ( 1a13c02 ) xmlupload: improve examples, add documentation of geometry-prop JSON format ( #240 ) ( 7df1d86 ) Enhancements xmlupload: enable migration of resource creation date (DEV-1402) ( #238 ) ( 83dd2de ) 1.19.0 (2022-10-07) Bug Fixes fix command dsp-tools xmlupload --validate (DEV-1360) ( #230 ) ( 0b2bd40 ) Enhancements address feedback to excel2xml : remove param values in all make_*_prop() methods, and fix some bugs (DEV-1361) ( #232 ) ( a7e9d85 ) change input format of excel command: use 1 Excel file for all same-language lists, rename command to excel2lists (DEV-955) ( #228 ) ( 21cc6bc ) Documentation improve docs and example data for excel2xml: create repo 0123-import-scripts (DEV-1370) ( #233 ) ( 9c6827e ) Maintenance bump versions (DEV-1117) #235 ( fc9c03c ) fix release-please (DEV-1396) #234 ( 3bd92d8 ) reduce GitHub workflow frequency (DEV-1344) #227 ( a0722d8 ) tests: enforce JKD 17 (DEV-1366) ( #231 ) ( 1036acd ) tidy up excel2lists, excel2resources, excel2properties (DEV-1352) ( #229 ) ( d2c2e08 ) 1.18.0 (2022-09-09) Enhancements add module csv2xml to convert tabular data to DSP-XML (DEV-134) ( #219 ) ( 19393aa ) Maintenance tidy up makefile (DEV-1166) ( #223 ) ( dca0854 ) Documentation clarify docs of onto creation (DEV-1164) ( #225 ) ( f64d2cf ) 1.17.1 (2022-08-22) Bug Fixes bugs in xmlupload and resource.py (DEV-1140) #217 ( 5e402e4 ) PyPI deployment (DEV-1270) ( #220 ) ( dafaa7e ) 1.17.0 (2022-08-16) Bug Fixes catch network interruptions during onto creation (DEV-1073) ( #210 ) ( ab0e3b2 ) Maintenance stop serving docs to dasch-swiss.github.io (DEV-826) ( #211 ) ( f2d25f9 ) Documentation add links from usage subpage to other subpages (DEV-812) ( #208 ) ( 92ac678 ) fix outdated links (DEV-1194) #215 ( 6849737 ) sort entries alphabetically (DEV-1184) ( #212 ) ( 75c6ae5 ) Enhancements add isSequenceOf (DEV-746) ( #214 ) ( 991d424 ) 1.16.0 (2022-07-18) Enhancements xmlupload: implement , , and tags (DEV-855) ( #204 ) ( 5044a9e ) 1.15.1 (2022-06-23) Bug Fixes excel2resources, excel2properties: cover all cases (DEV-1040) ( #201 ) ( 4c6ed19 ) xmlupload crashes without writing id2iri mapping (DEV-813) ( #194 ) ( 7948e75 ) Maintenance unpin dependency versions (DEV-983) ( #200 ) ( 5c56601 ) xmlupload: refactor xmlupload, add unittest (DEV-1043) ( #203 ) ( fcf8384 ) 1.15.0 (2022-06-02) Bug Fixes onto validation: correctly identify circular dependencies (DEV-769) ( #192 ) ( ed35902 ) testdata: remove salsah-links from test-id2iri-data.xml (DEV-975) ( #199 ) ( 7548501 ) xmlupload: prevent crash with incremental option (DEV-811) ( #197 ) ( cccb5e8 ) Enhancements add romansh (DEV-867) ( #193 ) ( 86d3e6a ) Documentation xmlupload: better explanation of permissions (DEV-969) ( #196 ) ( d3efde8 ) 1.14.0 (2022-05-03) Enhancements xmlupload: support Baseclass MovingImageRepresentation ( #185 ) ( 7ebf588 ) Documentation fix typos in documentation (DEV-849) ( #189 ) ( f887edd ) Maintenance json-schema: change JSON schema version to draft-07 (DEV-848) ( #188 ) ( 8ca6f87 ) update lists.json (DEV-851) ( #190 ) ( e0254be ) update schema-files (DEV-449) ( #187 ) ( 9a5a50b ) 1.13.0 (2022-04-25) Bug Fixes get: handle slash at end of server, improve docs (DEV-734) ( 17c0a40 ) groups: dsp-tools should not allow group creation if group name already in use (DEV-798) ( #183 ) ( 8f168ca ) Enhancements add support for external ontologies (dev-512) ( #170 ) ( ff36bc1 ) get: get more infos from user (DEV-641) ( #181 ) ( 407f5c5 ) Maintenance bump dependencies (DEV-815) ( #184 ) ( 5d2d109 ) change to pipenv (DEV-764) ( #177 ) ( 6c44688 ) improve XML and JSON Schemas (DEV-449) ( #180 ) ( 2c17b9d ) 1.12.2 (2022-03-31) Bug Fixes add missing dependency (DEV-763) ( 1cda29e ) 1.12.1 (2022-03-31) Maintenance remove bazel (DEV-735) ( #172 ) ( e12e9dd ) 1.12.0 (2022-03-25) Bug Fixes onto creation: prevent sorting algorith from modifying original ontology ( #169 ) ( 9a9e5f0 ) Enhancements onto creation: allow that resources and properties are not sorted by inheritance (DEV-626) ( #167 ) ( 2ebece3 ) xmlupload: allow circular references (DEV-577) ( #165 ) ( 75a444f ) 1.11.0 (2022-02-28) Enhancements improve prefix handling in json ontos (DEV-572) ( #164 ) ( 8610885 ) 1.10.1 (2022-02-23) Documentation add explanation how an Excel file for list creation must be structured (DEV-533) ( #159 ) ( 660d57b ) explain the interval-prop more precisely ( #162 ) ( 00c18dc ) 1.10.0 (2022-02-21) Documentation add validate argparse info to xmlupload ( #156 ) ( 08ddebd ) improve docs (DEV-450) ( #152 ) ( be5b69f ) Maintenance excel to json list (DEV-431) ( #155 ) ( 8a8c9d0 ) xml-upload: print XML validation errors when xmlupload fails due to validation (DEV-387) ( #149 ) ( 03554c2 ) Enhancements improve json schema validation error output (DEV-456) ( #153 ) ( 9f92b66 ) make comments optional for new properties and resources (DEV-502) ( #158 ) ( 9c30746 ) ontology: add Representation (DEV-551) ( #160 ) ( cba7be0 ) 1.9.0 (2022-01-27) Documentation add isPartOf and seqnum properties to documentation (DEV-216) ( #145 ) ( 09d42a4 ) dsp-tools-excel: mention the GUI order and other small improvements (DEV-99) ( #148 ) ( 853068d ) Enhancements xmlupload: use custom IRIs created from salsah ARKs for XML upload (DEV-179) ( #147 ) ( 873324a ) 1.8.1 (2022-01-11) Bug Fixes problem with reference to list values (DEV-356) ( #143 ) ( 3fce99a ) Maintenance deps: bump nltk from 3.6.5 to 3.6.6 ( #142 ) ( 4f91098 ) 1.8.0 (2022-01-10) Bug Fixes ontology: add default values for missing comments (DEV-337) ( #141 ) ( 6f0094e ) print only unresolvable resptrs ( #139 ) ( cbe1876 ) restrict the creation of classes without cardinalities (DEV-305) ( #136 ) ( 5604a5b ) Enhancements excel-to-json: allow comments in class and property definitions ( #111 ) ( 807959f ) get: extend get command to get more information (DEV-139) ( #137 ) ( 9ce6722 ) Maintenance improve ontology schema and extend tests (DEV-313) ( #140 ) ( 656ccff ) 1.7.1 (2021-12-14) Bug Fixes groups: make groups optional (DEV-138) ( #135 ) ( 6aa1aa7 ) Maintenance deps: bump lxml from 4.6.4 to 4.6.5 ( #133 ) ( 605dc2f ) 1.7.0 (2021-12-07) Bug Fixes boolean-values: allow 0 and 1 as boolean values (DEV-251) ( #131 ) ( fd58ad4 ) create-ontology: within an ontology, references to the ontology itself are not possible (DEV-135) ( #130 ) ( 6a40fc6 ) permissions: use permissions in xml upload (DEV-178) ( #127 ) ( 4dad0ce ) Documentation update out-of-date example in docs (DEV-265) ( #125 ) ( 0dc724c ) Enhancements update DSP-Tools to support ArchiveRepresentation (DEV-259) ( #128 ) ( 85a40c2 ) 1.6.1 (2021-11-25) Bug Fixes inconsistencies in groups and projects (DEV-261) ( #121 ) ( f9a95ed ) schema: list root node needs a comments object (DEV-61) ( #122 ) ( 7bdc589 ) 1.6.0 (2021-11-22) Bug Fixes comments: fix comments in ontology creation (DEV-250) ( #119 ) ( 08effdf ) update dsp-tools to work with API version 16.0.0 ( #117 ) ( af70e9b ) Documentation add time value section ( #116 ) ( 8ef0329 ) typo: correcting typos in documentation ( #112 ) ( 08c1059 ) Enhancements id-to-iri: extend xmlupload to allow references to existing resources (DEV-60) ( #108 ) ( 40b01db ) 1.5.2 (2021-11-16) Maintenance documentation: add missing documentation for excel2resources (DEV-144) ( cde0db5 ) 1.5.1 (2021-10-13) Bug Fixes schema-documentation: update schemas and documentation (DEV-61) ( #105 ) ( 4d9c1e4 ) 1.5.0 (2021-09-24) Enhancements schema: add error codes for validation (DSP-1902) ( #101 ) ( 0bc6149 ) 1.4.2 (2021-09-21) Bug Fixes docs: fix example in documentation (DSP-1740) ( #99 ) ( 11cdd72 ) 1.4.1 (2021-09-20) Maintenance schemas: update schemas (DSP-1902) ( #92 ) ( 16ba335 ) 1.4.0 (2021-09-16) Documentation typo: correct typo in documentation ( #85 ) ( c689d7f ) Enhancements excel-to-properties: create properties from Excel (DSP-1577) ( #89 ) ( 9f48e9a ) excel-to-resources: create resources from excel (DSP-1576) ( #88 ) ( 7b0302f ) 1.3.3 (2021-09-07) Bug Fixes wrong values & property ( #86 ) ( 7cf6405 ) 1.3.2 (2021-08-17) Bug Fixes import: fix import error when starting script directly ( DSP-1869) ( 05b1eb1 ) 1.3.1 (2021-08-11) Bug Fixes manifest: fix documentation and missing files ( DSP-1580) ( #80 ) ( 3345f2a ) 1.3.0 (2021-08-10) Enhancements excel-lists: create multilanguage json lists from excel files ( DSP-1580) ( #75 ) ( 06d071a ) 1.2.1 (2021-07-27) Bug Fixes release: fix skipped release after pull request #74 ( DSP-1797) ( #76 ) ( c8e0a11 ) 1.2.0 (2021-07-26) Enhancements verbose xml upload: use v option to print verbose output in XML upload ( DSP-1797) ( #70 ) ( b1f56a1 ) 1.1.6 (2021-07-22) Documentation add changelog ( #71 ) ( ce1feab ) 1.1.5 (2021-07-14) Documentation dsp-tools-xmlupload: Add Warning section ( #69 ) ( 05baf3d ) dsp-tools-xmlupload: addition to incomplete paragraph ( DSP-1693) ( #67 ) ( 318547f ) 1.1.4 (2021-06-16) Documentation add copyright information to docs ( DSP-1190) ( #65 ) ( 0174c4a ) 1.1.3 (2021-06-08) Documentation update readme after documentation update ( DSP-1693) ( #63 ) ( 7b7dcca ) 1.1.2 (2021-06-07) Maintenance bump Bazel to version with M1 support ( #60 ) ( 69772f4 ) Documentation improve documentation ( DSP-1693) ( #62 ) ( 591b5ad ) 1.1.1 (2021-04-20) Bug Fixes fix import ontology from salsah-export ( DSP-1532) ( #59 ) ( 6e3e7ca ) Maintenance fix doc deployment ( DSP-1492) ( #57 ) ( a55849e ) 1.1.0 (2021-04-09) Bug Fixes add create_ontology command line configuration ( 3ab7e6b ) add folder independence ( 2460937 ) add missing dependencies ( 4d75128 ) add user ( 277121b ) bulk-import of multiple resource link values ( 6ef8908 ), closes #9 cleanup api logging ( DSP-1076) ( #46 ) ( d48e704 ) command line scripts ( 732a0fa ) Correctly set user password ( 9db6445 ) Correctly set user password ( 3583ea2 ) Do not send logout request if token is not set ( 9cfd484 ) removed exception if keywords missing ( 81f7d97 ) requirements ( b5941f1 ) typo ( 3def59d ) Documentation fix twine upload ( bcc87ca ) update publishing description ( 6deb0da ) Enhancements import lists from excel ( DSP-1341) ( #48 ) ( 3628992 ) Maintenance add existing files into new structure ( 84dc1d2 ) add publishing setup ( c18c6b9 ) add pypi badge ( 3fc148c ) add runing tests on travis ( 2eeaeb8 ) add runing tests on travis ( cf4f9e4 ) add runing tests on travis ( b8f3bbc ) add runing tests on travis ( dc4fa02 ) add runing tests on travis ( 16844d8 ) add runing tests on travis ( 593ac85 ) add testing ( ongoing) ( c175a16 ) allow release PRs in PR title check ( #54 ) ( 0414948 ) automate release process ( DSP-1492) ( #52 ) ( 6a96eee ) bump version ( 49bc9d8 ) bump version ( e7364c7 ) bump version to 1.1.0 ( DSP-1492) ( #55 ) ( 3814ed2 ) configure dependencies and command line ( 7f79530 )","title":"Changelog"},{"location":"DSP-TOOLS/changelog/#changelog","text":"","title":"Changelog"},{"location":"DSP-TOOLS/changelog/#210-2023-02-21","text":"","title":"2.1.0 (2023-02-21)"},{"location":"DSP-TOOLS/changelog/#bug-fixes","text":"create: improve validation to prevent endless loop if properties are undefined (DEV-1720) ( #297 ) ( ee3e446 ) create: property from other ontology not found (DEV-1381) #299 ( d1345ec )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation","text":"fix identical heading problem, assimilate mkdocs config to dsp-docs (DEV-1713) ( #294 ) ( c235ff3 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements","text":"excel2json: add support for gui_order, make templates better understandable (DEV-1711) ( #293 ) ( 3b5304f )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#maintenance","text":"bump start-stack to 2023.02.02 (DEV-1732) #302 ( b97a696 ) enhanced xmlupload: add test onto (DEV-1760) #300 ( ca32842 ) excel2xml: allow PathLike for bitstream-prop (DEV-1729) #298 ( ab9386f ) remove temporary workaround in GET groups (DEV-1733) #301 ( 7ead9de )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#203-2023-02-07","text":"","title":"2.0.3 (2023-02-07)"},{"location":"DSP-TOOLS/changelog/#documentation_1","text":"restructure docs, add link-checking (DEV-1623) ( #286 ) ( d65ff53 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#maintenance_1","text":"access data files correctly (DEV-1618) ( #288 ) ( 7a64a27 ) bump start-stack to 2023.02.01 (DEV-1709) ( #292 ) ( 5fd58d2 ) bump versions of start-stack to 2023.01.02 (DEV-1652) ( #290 ) ( 2889a20 ) update links according to new structure of docs (DEV-1648) ( #289 ) ( 16d9c12 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#202-2023-01-17","text":"","title":"2.0.2 (2023-01-17)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_1","text":"get command fails if no groups are on the server (DEV-1622) ( #283 ) ( d6bf458 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_2","text":"fix broken links, make dsp-tools uppercase (DEV-1550) ( #284 ) ( aa66109 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#201-2023-01-17","text":"","title":"2.0.1 (2023-01-17)"},{"location":"DSP-TOOLS/changelog/#maintenance_2","text":"bump versions of start-stack, use dynamic project IRI in get command (DEV-1613) ( #282 ) ( 2ecf4f5 ) refactor project creation (DEV-1165) ( #280 ) ( 5e662a6 ) use start-stack command for e2e tests, replace Makefile by poetry-exec-plugin (DEV-1597) ( #279 ) ( 6b85d15 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#200-2023-01-09","text":"","title":"2.0.0 (2023-01-09)"},{"location":"DSP-TOOLS/changelog/#breaking-changes","text":"switch to src layout, use poetry, add developer docs (DEV-1523) ( #276 )","title":"\u26a0 BREAKING CHANGES"},{"location":"DSP-TOOLS/changelog/#maintenance_3","text":"adapt schema URLs, adapt title of release-please PR (DEV-1596) ( #278 ) ( 67f6475 ) switch to src layout, use poetry, add developer docs (DEV-1523) ( #276 ) ( 6ae3b4f )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#1222-2022-12-21","text":"","title":"1.22.2 (2022-12-21)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_2","text":"start-stack: copy docker folder to user's home directory (DEV-1581) ( #274 ) ( b0ebfc5 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#1221-2022-12-20","text":"","title":"1.22.1 (2022-12-20)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_3","text":"start-stack: use TTL files from DSP-API v24.0.8 (DEV-1580) ( #273 ) ( 3ad96ba )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_3","text":"improve documentation of DSP permission system (DEV-1561) ( #270 ) ( 33ab59d )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#1220-2022-12-19","text":"","title":"1.22.0 (2022-12-19)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_4","text":"excel2xml: better standard permissions (permissions definitions at top of XML file) (DEV-1560) ( #268 ) ( b0d30be ) xmlupload: improve URL recognition (DEV-1557) ( #266 ) ( 60f8fe5 ) xmlupload: prevent crash + improve error message when cardinalities are wrong (DEV-1559) #267 ( 7bfd82f )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_4","text":"excel2json: use rosetta as example data (DEV-1478) ( #254 ) ( af192cb ) readme: explain handling of git submodules (DEV-1502) ( #256 ) ( 1dc8483 ) text values: describe which combinations of gui_element and encoding are desirable (DEV-1521) ( #259 ) ( 21967c6 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_1","text":"use docker commands for stack handling (DEV-1530) ( #261 ) ( c11edc5 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#maintenance_4","text":"bump versions of GitHub actions (DEV-1532) #263 ( efc9f51 ) fix regex for PR title (DEV-1504) ( #257 ) ( d4feb68 ) start-api: adjust version numbers of DSP-API and DSP-APP according to 2022.11.01 (DEV-1579) #271 ( 10dcd2f ) xmlupload: add metrics flag (DEV-1512) ( #264 ) ( f4822dc ) xmlupload: handling of upload errors (DEV-1505) ( #250 ) ( 1507b21 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#1210-2022-11-11","text":"","title":"1.21.0 (2022-11-11)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_5","text":"bugs in json schema (DEV-1142) ( #252 ) ( 92af830 ) excel2xml: prevent writing empty text-prop, make text-prop validation less restrictive (DEV-1440) #243 ( ae777e4 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#enhancements_2","text":"add command excel2json to create JSON project file from folder with Excel files (DEV-960) ( #248 ) ( e8e05e4 ) startup API and APP with dsp-tools (DEV-126) ( #246 ) ( de182dc )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#documentation_5","text":"improve docs (DEV-1478) ( #249 ) ( 7947dec )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#1200-2022-10-18","text":"","title":"1.20.0 (2022-10-18)"},{"location":"DSP-TOOLS/changelog/#maintenance_5","text":"xmlupload: improve error message when syntax for referencing ontos is wrong (DEV-1399) ( #237 ) ( df0bf33 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#documentation_6","text":"user needs to be project member to become project admin (DEV-1383) ( #241 ) ( 1a13c02 ) xmlupload: improve examples, add documentation of geometry-prop JSON format ( #240 ) ( 7df1d86 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_3","text":"xmlupload: enable migration of resource creation date (DEV-1402) ( #238 ) ( 83dd2de )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#1190-2022-10-07","text":"","title":"1.19.0 (2022-10-07)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_6","text":"fix command dsp-tools xmlupload --validate (DEV-1360) ( #230 ) ( 0b2bd40 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#enhancements_4","text":"address feedback to excel2xml : remove param values in all make_*_prop() methods, and fix some bugs (DEV-1361) ( #232 ) ( a7e9d85 ) change input format of excel command: use 1 Excel file for all same-language lists, rename command to excel2lists (DEV-955) ( #228 ) ( 21cc6bc )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#documentation_7","text":"improve docs and example data for excel2xml: create repo 0123-import-scripts (DEV-1370) ( #233 ) ( 9c6827e )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#maintenance_6","text":"bump versions (DEV-1117) #235 ( fc9c03c ) fix release-please (DEV-1396) #234 ( 3bd92d8 ) reduce GitHub workflow frequency (DEV-1344) #227 ( a0722d8 ) tests: enforce JKD 17 (DEV-1366) ( #231 ) ( 1036acd ) tidy up excel2lists, excel2resources, excel2properties (DEV-1352) ( #229 ) ( d2c2e08 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#1180-2022-09-09","text":"","title":"1.18.0 (2022-09-09)"},{"location":"DSP-TOOLS/changelog/#enhancements_5","text":"add module csv2xml to convert tabular data to DSP-XML (DEV-134) ( #219 ) ( 19393aa )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#maintenance_7","text":"tidy up makefile (DEV-1166) ( #223 ) ( dca0854 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#documentation_8","text":"clarify docs of onto creation (DEV-1164) ( #225 ) ( f64d2cf )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#1171-2022-08-22","text":"","title":"1.17.1 (2022-08-22)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_7","text":"bugs in xmlupload and resource.py (DEV-1140) #217 ( 5e402e4 ) PyPI deployment (DEV-1270) ( #220 ) ( dafaa7e )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#1170-2022-08-16","text":"","title":"1.17.0 (2022-08-16)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_8","text":"catch network interruptions during onto creation (DEV-1073) ( #210 ) ( ab0e3b2 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#maintenance_8","text":"stop serving docs to dasch-swiss.github.io (DEV-826) ( #211 ) ( f2d25f9 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#documentation_9","text":"add links from usage subpage to other subpages (DEV-812) ( #208 ) ( 92ac678 ) fix outdated links (DEV-1194) #215 ( 6849737 ) sort entries alphabetically (DEV-1184) ( #212 ) ( 75c6ae5 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_6","text":"add isSequenceOf (DEV-746) ( #214 ) ( 991d424 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#1160-2022-07-18","text":"","title":"1.16.0 (2022-07-18)"},{"location":"DSP-TOOLS/changelog/#enhancements_7","text":"xmlupload: implement , , and tags (DEV-855) ( #204 ) ( 5044a9e )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#1151-2022-06-23","text":"","title":"1.15.1 (2022-06-23)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_9","text":"excel2resources, excel2properties: cover all cases (DEV-1040) ( #201 ) ( 4c6ed19 ) xmlupload crashes without writing id2iri mapping (DEV-813) ( #194 ) ( 7948e75 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#maintenance_9","text":"unpin dependency versions (DEV-983) ( #200 ) ( 5c56601 ) xmlupload: refactor xmlupload, add unittest (DEV-1043) ( #203 ) ( fcf8384 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#1150-2022-06-02","text":"","title":"1.15.0 (2022-06-02)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_10","text":"onto validation: correctly identify circular dependencies (DEV-769) ( #192 ) ( ed35902 ) testdata: remove salsah-links from test-id2iri-data.xml (DEV-975) ( #199 ) ( 7548501 ) xmlupload: prevent crash with incremental option (DEV-811) ( #197 ) ( cccb5e8 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#enhancements_8","text":"add romansh (DEV-867) ( #193 ) ( 86d3e6a )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#documentation_10","text":"xmlupload: better explanation of permissions (DEV-969) ( #196 ) ( d3efde8 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#1140-2022-05-03","text":"","title":"1.14.0 (2022-05-03)"},{"location":"DSP-TOOLS/changelog/#enhancements_9","text":"xmlupload: support Baseclass MovingImageRepresentation ( #185 ) ( 7ebf588 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#documentation_11","text":"fix typos in documentation (DEV-849) ( #189 ) ( f887edd )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#maintenance_10","text":"json-schema: change JSON schema version to draft-07 (DEV-848) ( #188 ) ( 8ca6f87 ) update lists.json (DEV-851) ( #190 ) ( e0254be ) update schema-files (DEV-449) ( #187 ) ( 9a5a50b )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#1130-2022-04-25","text":"","title":"1.13.0 (2022-04-25)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_11","text":"get: handle slash at end of server, improve docs (DEV-734) ( 17c0a40 ) groups: dsp-tools should not allow group creation if group name already in use (DEV-798) ( #183 ) ( 8f168ca )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#enhancements_10","text":"add support for external ontologies (dev-512) ( #170 ) ( ff36bc1 ) get: get more infos from user (DEV-641) ( #181 ) ( 407f5c5 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#maintenance_11","text":"bump dependencies (DEV-815) ( #184 ) ( 5d2d109 ) change to pipenv (DEV-764) ( #177 ) ( 6c44688 ) improve XML and JSON Schemas (DEV-449) ( #180 ) ( 2c17b9d )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#1122-2022-03-31","text":"","title":"1.12.2 (2022-03-31)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_12","text":"add missing dependency (DEV-763) ( 1cda29e )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#1121-2022-03-31","text":"","title":"1.12.1 (2022-03-31)"},{"location":"DSP-TOOLS/changelog/#maintenance_12","text":"remove bazel (DEV-735) ( #172 ) ( e12e9dd )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#1120-2022-03-25","text":"","title":"1.12.0 (2022-03-25)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_13","text":"onto creation: prevent sorting algorith from modifying original ontology ( #169 ) ( 9a9e5f0 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#enhancements_11","text":"onto creation: allow that resources and properties are not sorted by inheritance (DEV-626) ( #167 ) ( 2ebece3 ) xmlupload: allow circular references (DEV-577) ( #165 ) ( 75a444f )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#1110-2022-02-28","text":"","title":"1.11.0 (2022-02-28)"},{"location":"DSP-TOOLS/changelog/#enhancements_12","text":"improve prefix handling in json ontos (DEV-572) ( #164 ) ( 8610885 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#1101-2022-02-23","text":"","title":"1.10.1 (2022-02-23)"},{"location":"DSP-TOOLS/changelog/#documentation_12","text":"add explanation how an Excel file for list creation must be structured (DEV-533) ( #159 ) ( 660d57b ) explain the interval-prop more precisely ( #162 ) ( 00c18dc )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#1100-2022-02-21","text":"","title":"1.10.0 (2022-02-21)"},{"location":"DSP-TOOLS/changelog/#documentation_13","text":"add validate argparse info to xmlupload ( #156 ) ( 08ddebd ) improve docs (DEV-450) ( #152 ) ( be5b69f )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#maintenance_13","text":"excel to json list (DEV-431) ( #155 ) ( 8a8c9d0 ) xml-upload: print XML validation errors when xmlupload fails due to validation (DEV-387) ( #149 ) ( 03554c2 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#enhancements_13","text":"improve json schema validation error output (DEV-456) ( #153 ) ( 9f92b66 ) make comments optional for new properties and resources (DEV-502) ( #158 ) ( 9c30746 ) ontology: add Representation (DEV-551) ( #160 ) ( cba7be0 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#190-2022-01-27","text":"","title":"1.9.0 (2022-01-27)"},{"location":"DSP-TOOLS/changelog/#documentation_14","text":"add isPartOf and seqnum properties to documentation (DEV-216) ( #145 ) ( 09d42a4 ) dsp-tools-excel: mention the GUI order and other small improvements (DEV-99) ( #148 ) ( 853068d )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_14","text":"xmlupload: use custom IRIs created from salsah ARKs for XML upload (DEV-179) ( #147 ) ( 873324a )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#181-2022-01-11","text":"","title":"1.8.1 (2022-01-11)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_14","text":"problem with reference to list values (DEV-356) ( #143 ) ( 3fce99a )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#maintenance_14","text":"deps: bump nltk from 3.6.5 to 3.6.6 ( #142 ) ( 4f91098 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#180-2022-01-10","text":"","title":"1.8.0 (2022-01-10)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_15","text":"ontology: add default values for missing comments (DEV-337) ( #141 ) ( 6f0094e ) print only unresolvable resptrs ( #139 ) ( cbe1876 ) restrict the creation of classes without cardinalities (DEV-305) ( #136 ) ( 5604a5b )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#enhancements_15","text":"excel-to-json: allow comments in class and property definitions ( #111 ) ( 807959f ) get: extend get command to get more information (DEV-139) ( #137 ) ( 9ce6722 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#maintenance_15","text":"improve ontology schema and extend tests (DEV-313) ( #140 ) ( 656ccff )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#171-2021-12-14","text":"","title":"1.7.1 (2021-12-14)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_16","text":"groups: make groups optional (DEV-138) ( #135 ) ( 6aa1aa7 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#maintenance_16","text":"deps: bump lxml from 4.6.4 to 4.6.5 ( #133 ) ( 605dc2f )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#170-2021-12-07","text":"","title":"1.7.0 (2021-12-07)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_17","text":"boolean-values: allow 0 and 1 as boolean values (DEV-251) ( #131 ) ( fd58ad4 ) create-ontology: within an ontology, references to the ontology itself are not possible (DEV-135) ( #130 ) ( 6a40fc6 ) permissions: use permissions in xml upload (DEV-178) ( #127 ) ( 4dad0ce )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_15","text":"update out-of-date example in docs (DEV-265) ( #125 ) ( 0dc724c )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_16","text":"update DSP-Tools to support ArchiveRepresentation (DEV-259) ( #128 ) ( 85a40c2 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#161-2021-11-25","text":"","title":"1.6.1 (2021-11-25)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_18","text":"inconsistencies in groups and projects (DEV-261) ( #121 ) ( f9a95ed ) schema: list root node needs a comments object (DEV-61) ( #122 ) ( 7bdc589 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#160-2021-11-22","text":"","title":"1.6.0 (2021-11-22)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_19","text":"comments: fix comments in ontology creation (DEV-250) ( #119 ) ( 08effdf ) update dsp-tools to work with API version 16.0.0 ( #117 ) ( af70e9b )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_16","text":"add time value section ( #116 ) ( 8ef0329 ) typo: correcting typos in documentation ( #112 ) ( 08c1059 )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_17","text":"id-to-iri: extend xmlupload to allow references to existing resources (DEV-60) ( #108 ) ( 40b01db )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#152-2021-11-16","text":"","title":"1.5.2 (2021-11-16)"},{"location":"DSP-TOOLS/changelog/#maintenance_17","text":"documentation: add missing documentation for excel2resources (DEV-144) ( cde0db5 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#151-2021-10-13","text":"","title":"1.5.1 (2021-10-13)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_20","text":"schema-documentation: update schemas and documentation (DEV-61) ( #105 ) ( 4d9c1e4 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#150-2021-09-24","text":"","title":"1.5.0 (2021-09-24)"},{"location":"DSP-TOOLS/changelog/#enhancements_18","text":"schema: add error codes for validation (DSP-1902) ( #101 ) ( 0bc6149 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#142-2021-09-21","text":"","title":"1.4.2 (2021-09-21)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_21","text":"docs: fix example in documentation (DSP-1740) ( #99 ) ( 11cdd72 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#141-2021-09-20","text":"","title":"1.4.1 (2021-09-20)"},{"location":"DSP-TOOLS/changelog/#maintenance_18","text":"schemas: update schemas (DSP-1902) ( #92 ) ( 16ba335 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#140-2021-09-16","text":"","title":"1.4.0 (2021-09-16)"},{"location":"DSP-TOOLS/changelog/#documentation_17","text":"typo: correct typo in documentation ( #85 ) ( c689d7f )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_19","text":"excel-to-properties: create properties from Excel (DSP-1577) ( #89 ) ( 9f48e9a ) excel-to-resources: create resources from excel (DSP-1576) ( #88 ) ( 7b0302f )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#133-2021-09-07","text":"","title":"1.3.3 (2021-09-07)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_22","text":"wrong values & property ( #86 ) ( 7cf6405 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#132-2021-08-17","text":"","title":"1.3.2 (2021-08-17)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_23","text":"import: fix import error when starting script directly ( DSP-1869) ( 05b1eb1 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#131-2021-08-11","text":"","title":"1.3.1 (2021-08-11)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_24","text":"manifest: fix documentation and missing files ( DSP-1580) ( #80 ) ( 3345f2a )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#130-2021-08-10","text":"","title":"1.3.0 (2021-08-10)"},{"location":"DSP-TOOLS/changelog/#enhancements_20","text":"excel-lists: create multilanguage json lists from excel files ( DSP-1580) ( #75 ) ( 06d071a )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#121-2021-07-27","text":"","title":"1.2.1 (2021-07-27)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_25","text":"release: fix skipped release after pull request #74 ( DSP-1797) ( #76 ) ( c8e0a11 )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#120-2021-07-26","text":"","title":"1.2.0 (2021-07-26)"},{"location":"DSP-TOOLS/changelog/#enhancements_21","text":"verbose xml upload: use v option to print verbose output in XML upload ( DSP-1797) ( #70 ) ( b1f56a1 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#116-2021-07-22","text":"","title":"1.1.6 (2021-07-22)"},{"location":"DSP-TOOLS/changelog/#documentation_18","text":"add changelog ( #71 ) ( ce1feab )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#115-2021-07-14","text":"","title":"1.1.5 (2021-07-14)"},{"location":"DSP-TOOLS/changelog/#documentation_19","text":"dsp-tools-xmlupload: Add Warning section ( #69 ) ( 05baf3d ) dsp-tools-xmlupload: addition to incomplete paragraph ( DSP-1693) ( #67 ) ( 318547f )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#114-2021-06-16","text":"","title":"1.1.4 (2021-06-16)"},{"location":"DSP-TOOLS/changelog/#documentation_20","text":"add copyright information to docs ( DSP-1190) ( #65 ) ( 0174c4a )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#113-2021-06-08","text":"","title":"1.1.3 (2021-06-08)"},{"location":"DSP-TOOLS/changelog/#documentation_21","text":"update readme after documentation update ( DSP-1693) ( #63 ) ( 7b7dcca )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#112-2021-06-07","text":"","title":"1.1.2 (2021-06-07)"},{"location":"DSP-TOOLS/changelog/#maintenance_19","text":"bump Bazel to version with M1 support ( #60 ) ( 69772f4 )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#documentation_22","text":"improve documentation ( DSP-1693) ( #62 ) ( 591b5ad )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#111-2021-04-20","text":"","title":"1.1.1 (2021-04-20)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_26","text":"fix import ontology from salsah-export ( DSP-1532) ( #59 ) ( 6e3e7ca )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#maintenance_20","text":"fix doc deployment ( DSP-1492) ( #57 ) ( a55849e )","title":"Maintenance"},{"location":"DSP-TOOLS/changelog/#110-2021-04-09","text":"","title":"1.1.0 (2021-04-09)"},{"location":"DSP-TOOLS/changelog/#bug-fixes_27","text":"add create_ontology command line configuration ( 3ab7e6b ) add folder independence ( 2460937 ) add missing dependencies ( 4d75128 ) add user ( 277121b ) bulk-import of multiple resource link values ( 6ef8908 ), closes #9 cleanup api logging ( DSP-1076) ( #46 ) ( d48e704 ) command line scripts ( 732a0fa ) Correctly set user password ( 9db6445 ) Correctly set user password ( 3583ea2 ) Do not send logout request if token is not set ( 9cfd484 ) removed exception if keywords missing ( 81f7d97 ) requirements ( b5941f1 ) typo ( 3def59d )","title":"Bug Fixes"},{"location":"DSP-TOOLS/changelog/#documentation_23","text":"fix twine upload ( bcc87ca ) update publishing description ( 6deb0da )","title":"Documentation"},{"location":"DSP-TOOLS/changelog/#enhancements_22","text":"import lists from excel ( DSP-1341) ( #48 ) ( 3628992 )","title":"Enhancements"},{"location":"DSP-TOOLS/changelog/#maintenance_21","text":"add existing files into new structure ( 84dc1d2 ) add publishing setup ( c18c6b9 ) add pypi badge ( 3fc148c ) add runing tests on travis ( 2eeaeb8 ) add runing tests on travis ( cf4f9e4 ) add runing tests on travis ( b8f3bbc ) add runing tests on travis ( dc4fa02 ) add runing tests on travis ( 16844d8 ) add runing tests on travis ( 593ac85 ) add testing ( ongoing) ( c175a16 ) allow release PRs in PR title check ( #54 ) ( 0414948 ) automate release process ( DSP-1492) ( #52 ) ( 6a96eee ) bump version ( 49bc9d8 ) bump version ( e7364c7 ) bump version to 1.1.0 ( DSP-1492) ( #55 ) ( 3814ed2 ) configure dependencies and command line ( 7f79530 )","title":"Maintenance"},{"location":"DSP-TOOLS/cli-commands/","text":"The CLI commands of DSP-TOOLS Before starting: Have in mind the subdomains of a DSP server DaSCH follows some conventions when setting up DSP servers. Most of the commands documented on this page assume that you know how to address the subdomains of a DSP server. There are three relevant URLs you should know about: Subdomain admin stands for the DSP-APP frontend that you look at in your browser Subdomain api stands for the DSP-API (where DSP-TOOLS sends its data to) Subdomain iiif stands for the SIPI server interface (where DSP-TOOLS sends the multimedia files to) This means that for uploading data to a DSP server on the domain dasch.swiss , you have to type the following: dsp-tools xmlupload -s https://api.dasch.swiss -u root@example.com -p test -S https://iiif.dasch.swiss xml_data_file.xml create This command reads a JSON project definition (containing one or more data models) and creates it on a DSP server. dsp-tools create [ options ] project_definition.json The following options are available: -s | --server (optional, default: 0.0.0.0:3333 ): URL of the DSP server -u | --user (optional, default: root@example.com ): username used for authentication with the DSP-API -p | --password (optional, default: test ): password used for authentication with the DSP-API -V | --validate-only (optional): If set, only the validation of the JSON file is performed. -l | --lists-only (optional): If set, only the lists are created. Please note that in this case the project must already exist. -v | --verbose (optional): If set, more information about the progress is printed to the console. -d | --dump (optional): If set, dump test files for DSP-API requests. The defaults are intended for local testing: dsp-tools create project_definition.json will create the project defined in project_definition.json on localhost for local viewing. In order to create the same project on the DSP server https://admin.dasch.swiss , it is necessary to specify the following options: dsp-tools create -s https://api.dasch.swiss -u root@example.com -p test project_definition.json The expected JSON format is documented here . get This command retrieves a project with its data model(s) from a DSP server and writes it into a JSON file. This JSON file can then be used to create the same project on another DSP server. dsp-tools get [ options ] output_file.json The following options are available: -s | --server (optional, default: 0.0.0.0:3333 ): URL of the DSP server -u | --user (optional, default: root@example.com ): username used for authentication with the DSP-API -p | --password (optional, default: test ): password used for authentication with the DSP-API -P | --project (mandatory): shortcode, shortname or IRI of the project -v | --verbose (optional): If set, some information about the progress is printed to the console. The following example shows how to get a project from the DSP server https://admin.dasch.swiss : dsp-tools get -s https://api.dasch.swiss -u root@example.com -p test -P my_project output_file.json The expected JSON format is documented here . xmlupload This command uploads data defined in an XML file to a DSP server. dsp-tools xmlupload [ options ] xml_data_file.xml The following options are available: -s | --server (optional, default: 0.0.0.0:3333 ): URL of the DSP server -u | --user (optional, default: root@example.com ): username used for authentication with the DSP-API -p | --password (optional, default: test ): password used for authentication with the DSP-API -i | --imgdir (optional, default: . ): folder where the paths in the <bitstream> tags are evaluated from -S | --sipi (optional, default: http://0.0.0.0:1024 ): URL of the SIPI IIIF server -I | --incremental (optional) : If set, IRIs instead of internal IDs are expected as reference to already existing resources on DSP -V | --validate (optional): If set, the XML file will only be validated, but not uploaded. -v | --verbose (optional): If set, more information about the process is printed to the console. -m | --metrics (optional): If set, write metrics into a \"metrics\" folder in the current working directory Output: A file named id2iri_mapping_[timestamp].json is written to the current working directory. This file should be kept if data is later added with the --incremental option The defaults are intended for local testing: dsp-tools xmlupload xml_data_file.xml will upload the data defined in xml_data_file.xml on localhost for local viewing. In order to upload the same data to the DSP server https://admin.dasch.swiss , it is necessary to specify the following options: dsp-tools xmlupload -s https://api.dasch.swiss -u root@example.com -p test -S https://iiif.dasch.swiss xml_data_file.xml The expected XML format is documented here . excel2json This command creates a JSON project file from a nested folder structure with Excel files. dsp-tools excel2json data_model_files project.json The expected Excel file format and the folder structure are documented here . excel2lists This command creates the \"lists\" section of a JSON project file from Excel files. dsp-tools excel2lists [ options ] folder output.json The following options are available: -v | --verbose (optional): If set, more information about the progress is printed to the console. The expected Excel file format and the folder structure are documented here . Hint The command excel2json might be more convenient to use. excel2resources This command creates the \"resources\" section of a JSON project file from an Excel file. dsp-tools excel2resources excel_file.xlsx output_file.json The expected Excel format is documented here . Hint The command excel2json might be more convenient to use. excel2properties This command creates the \"properties\" section of a JSON project file from an Excel file. dsp-tools excel2properties excel_file.xlsx output_file.json The expected Excel format is documented here . Hint The command excel2json might be more convenient to use. excel2xml This command converts an Excel/CSV file that is already structured according to the DSP specifications to XML. This is mostly used for DaSCH-internal data migration. dsp-tools excel2xml data-source.xlsx project_shortcode ontology_name Arguments: data-source.xlsx (mandatory): An Excel/CSV file that is structured as explained below project_shortcode (mandatory): The four-digit hexadecimal shortcode of the project ontology_name (mandatory): the name of the ontology that the data belongs to The expected Excel format is documented here . If your data source is not yet structured according to the DSP specifications, you need a custom Python script for the data transformation. For this, you might want to import the module excel2xml into your Python script, which is described here . id2iri This command reads an XML file, and replaces the internal IDs contained in its <resptr> tags by the respective IRIs from the JSON mapping file. dsp-tools id2iri xml_file.xml mapping_file.json --outfile xml_file_replaced.xml The following options are available: --outfile (optional, default: id2iri_replaced_[timestamp].xml ): path to the output file This command cannot be used isolated, because it is part of a bigger procedure that is documented here . start-stack This command runs DSP-API and DSP-APP on a local machine. dsp-tools start-stack dsp-tools will ask you for permission to clean Docker with a docker system prune . This will remove all unused containers, networks and images. If you don't know what that means, just type y (\"yes\") and then Enter . The following options are available: --max_file_size=int (optional, default: 250 ): max. multimedia file size allowed by SIPI, in MB (max: 100'000) --prune (optional): if set, execute docker system prune without asking the user --no-prune (optional): if set, don't execute docker system prune (and don't ask) Example: If you start the stack with dsp-tools start-stack --max_file_size=1000 , it will be possible to upload files that are up to 1 GB big. If a file bigger than max_file_size is uploaded, SIPI will reject it. More help for this command can be found here . stop-stack When your work is done, shut down DSP-API and DSP-APP with dsp-tools stop-stack This deletes all Docker volumes, and removes all data that was in the database.","title":"CLI commands"},{"location":"DSP-TOOLS/cli-commands/#the-cli-commands-of-dsp-tools","text":"","title":"The CLI commands of DSP-TOOLS"},{"location":"DSP-TOOLS/cli-commands/#before-starting-have-in-mind-the-subdomains-of-a-dsp-server","text":"DaSCH follows some conventions when setting up DSP servers. Most of the commands documented on this page assume that you know how to address the subdomains of a DSP server. There are three relevant URLs you should know about: Subdomain admin stands for the DSP-APP frontend that you look at in your browser Subdomain api stands for the DSP-API (where DSP-TOOLS sends its data to) Subdomain iiif stands for the SIPI server interface (where DSP-TOOLS sends the multimedia files to) This means that for uploading data to a DSP server on the domain dasch.swiss , you have to type the following: dsp-tools xmlupload -s https://api.dasch.swiss -u root@example.com -p test -S https://iiif.dasch.swiss xml_data_file.xml","title":"Before starting: Have in mind the subdomains of a DSP server"},{"location":"DSP-TOOLS/cli-commands/#create","text":"This command reads a JSON project definition (containing one or more data models) and creates it on a DSP server. dsp-tools create [ options ] project_definition.json The following options are available: -s | --server (optional, default: 0.0.0.0:3333 ): URL of the DSP server -u | --user (optional, default: root@example.com ): username used for authentication with the DSP-API -p | --password (optional, default: test ): password used for authentication with the DSP-API -V | --validate-only (optional): If set, only the validation of the JSON file is performed. -l | --lists-only (optional): If set, only the lists are created. Please note that in this case the project must already exist. -v | --verbose (optional): If set, more information about the progress is printed to the console. -d | --dump (optional): If set, dump test files for DSP-API requests. The defaults are intended for local testing: dsp-tools create project_definition.json will create the project defined in project_definition.json on localhost for local viewing. In order to create the same project on the DSP server https://admin.dasch.swiss , it is necessary to specify the following options: dsp-tools create -s https://api.dasch.swiss -u root@example.com -p test project_definition.json The expected JSON format is documented here .","title":"create"},{"location":"DSP-TOOLS/cli-commands/#get","text":"This command retrieves a project with its data model(s) from a DSP server and writes it into a JSON file. This JSON file can then be used to create the same project on another DSP server. dsp-tools get [ options ] output_file.json The following options are available: -s | --server (optional, default: 0.0.0.0:3333 ): URL of the DSP server -u | --user (optional, default: root@example.com ): username used for authentication with the DSP-API -p | --password (optional, default: test ): password used for authentication with the DSP-API -P | --project (mandatory): shortcode, shortname or IRI of the project -v | --verbose (optional): If set, some information about the progress is printed to the console. The following example shows how to get a project from the DSP server https://admin.dasch.swiss : dsp-tools get -s https://api.dasch.swiss -u root@example.com -p test -P my_project output_file.json The expected JSON format is documented here .","title":"get"},{"location":"DSP-TOOLS/cli-commands/#xmlupload","text":"This command uploads data defined in an XML file to a DSP server. dsp-tools xmlupload [ options ] xml_data_file.xml The following options are available: -s | --server (optional, default: 0.0.0.0:3333 ): URL of the DSP server -u | --user (optional, default: root@example.com ): username used for authentication with the DSP-API -p | --password (optional, default: test ): password used for authentication with the DSP-API -i | --imgdir (optional, default: . ): folder where the paths in the <bitstream> tags are evaluated from -S | --sipi (optional, default: http://0.0.0.0:1024 ): URL of the SIPI IIIF server -I | --incremental (optional) : If set, IRIs instead of internal IDs are expected as reference to already existing resources on DSP -V | --validate (optional): If set, the XML file will only be validated, but not uploaded. -v | --verbose (optional): If set, more information about the process is printed to the console. -m | --metrics (optional): If set, write metrics into a \"metrics\" folder in the current working directory Output: A file named id2iri_mapping_[timestamp].json is written to the current working directory. This file should be kept if data is later added with the --incremental option The defaults are intended for local testing: dsp-tools xmlupload xml_data_file.xml will upload the data defined in xml_data_file.xml on localhost for local viewing. In order to upload the same data to the DSP server https://admin.dasch.swiss , it is necessary to specify the following options: dsp-tools xmlupload -s https://api.dasch.swiss -u root@example.com -p test -S https://iiif.dasch.swiss xml_data_file.xml The expected XML format is documented here .","title":"xmlupload"},{"location":"DSP-TOOLS/cli-commands/#excel2json","text":"This command creates a JSON project file from a nested folder structure with Excel files. dsp-tools excel2json data_model_files project.json The expected Excel file format and the folder structure are documented here .","title":"excel2json"},{"location":"DSP-TOOLS/cli-commands/#excel2lists","text":"This command creates the \"lists\" section of a JSON project file from Excel files. dsp-tools excel2lists [ options ] folder output.json The following options are available: -v | --verbose (optional): If set, more information about the progress is printed to the console. The expected Excel file format and the folder structure are documented here . Hint The command excel2json might be more convenient to use.","title":"excel2lists"},{"location":"DSP-TOOLS/cli-commands/#excel2resources","text":"This command creates the \"resources\" section of a JSON project file from an Excel file. dsp-tools excel2resources excel_file.xlsx output_file.json The expected Excel format is documented here . Hint The command excel2json might be more convenient to use.","title":"excel2resources"},{"location":"DSP-TOOLS/cli-commands/#excel2properties","text":"This command creates the \"properties\" section of a JSON project file from an Excel file. dsp-tools excel2properties excel_file.xlsx output_file.json The expected Excel format is documented here . Hint The command excel2json might be more convenient to use.","title":"excel2properties"},{"location":"DSP-TOOLS/cli-commands/#excel2xml","text":"This command converts an Excel/CSV file that is already structured according to the DSP specifications to XML. This is mostly used for DaSCH-internal data migration. dsp-tools excel2xml data-source.xlsx project_shortcode ontology_name Arguments: data-source.xlsx (mandatory): An Excel/CSV file that is structured as explained below project_shortcode (mandatory): The four-digit hexadecimal shortcode of the project ontology_name (mandatory): the name of the ontology that the data belongs to The expected Excel format is documented here . If your data source is not yet structured according to the DSP specifications, you need a custom Python script for the data transformation. For this, you might want to import the module excel2xml into your Python script, which is described here .","title":"excel2xml"},{"location":"DSP-TOOLS/cli-commands/#id2iri","text":"This command reads an XML file, and replaces the internal IDs contained in its <resptr> tags by the respective IRIs from the JSON mapping file. dsp-tools id2iri xml_file.xml mapping_file.json --outfile xml_file_replaced.xml The following options are available: --outfile (optional, default: id2iri_replaced_[timestamp].xml ): path to the output file This command cannot be used isolated, because it is part of a bigger procedure that is documented here .","title":"id2iri"},{"location":"DSP-TOOLS/cli-commands/#start-stack","text":"This command runs DSP-API and DSP-APP on a local machine. dsp-tools start-stack dsp-tools will ask you for permission to clean Docker with a docker system prune . This will remove all unused containers, networks and images. If you don't know what that means, just type y (\"yes\") and then Enter . The following options are available: --max_file_size=int (optional, default: 250 ): max. multimedia file size allowed by SIPI, in MB (max: 100'000) --prune (optional): if set, execute docker system prune without asking the user --no-prune (optional): if set, don't execute docker system prune (and don't ask) Example: If you start the stack with dsp-tools start-stack --max_file_size=1000 , it will be possible to upload files that are up to 1 GB big. If a file bigger than max_file_size is uploaded, SIPI will reject it. More help for this command can be found here .","title":"start-stack"},{"location":"DSP-TOOLS/cli-commands/#stop-stack","text":"When your work is done, shut down DSP-API and DSP-APP with dsp-tools stop-stack This deletes all Docker volumes, and removes all data that was in the database.","title":"stop-stack"},{"location":"DSP-TOOLS/excel2xml-module/","text":"The excel2xml module Two use cases - two approaches There are two kinds of Excel files that can be transformed into an XML file: structure provenance tool example screenshot custom structure customer module excel2xml DSP structure DSP server CLI command excel2xml The first use case is the most frequent: The DaSCH receives a data export from a research project. Every project uses different software, so every project will deliver their data in a different structure. The screenshot is just a simplified example. For this use case, it is necessary to write a Python script that transforms the data from an undefined state X into a DSP-conforming XML file that can be uploaded with dsp-tools xmlupload . For this, you need to import the module excel2xml into your Python script. The second use case is less frequent: We migrate data DaSCH-internally from one server to another. In this case, the data already has the correct structure, and can automatically be transformed to XML. This can be done with the CLI command excel2xml . This page deals only with the first use case, the module excel2xml . Module excel2xml : Convert a data source to XML To demonstrate the usage of the excel2xml module, there is a GitHub repository named 0123-import-scripts . It contains: a sample JSON project file sample data that fits the data model of the JSON project file a sample Python script that demonstrates how to use the module excel2xml . Navigate to https://github.com/dasch-swiss/0123-import-scripts and follow the steps described there. The README will teach you some basics that will be necessary to work with excel2xml . Once you are familiar with the basics, return to this page to learn how the sample Python script works. This is the simplified pattern how the Python script works: 1 main_df = pd.read_csv(\"excel2xml_sample_data.csv\", dtype=\"str\", sep=\",\") 2 root = excel2xml.make_root(...) 3 root = excel2xml.append_permissions(root) 4 # if necessary: create list mappings, according to explanation below 5 for index, row in main_df.iterrows(): 6 resource = excel2xml.make_resource(...) 7 resource.append(excel2xml.make_text_prop(...)) 8 root.append(resource) 9 excel2xml.write_xml(root, \"data.xml\") 1 read in your data source with the pandas library (https://pandas.pydata.org/) 2 create the root element `<knora>` 3 append the permissions 4 if necessary: create list mappings (see below) 5 iterate through the rows of your data source: 6 create the `<resource>` tag 7 append properties to it 8 append the resource to the root tag `<knora>` 9 save the finished XML file These steps are now explained in-depth: 1. Read in your data source In the first paragraph of the sample script, insert your ontology name, project shortcode, and the path to your data source. If necessary, activate one of the lines that are commented out. 2. Create root element <knora> Then, the root element is created, which represents the <knora> tag of the XML document. 3. Append the permissions As first children of <knora> , some standard permissions are added. At the end, please carefully check the permissions of the finished XML file to ensure that they meet your requirements, and adapt them if necessary. The standard permission of a resource is res-default , and of a property prop-default . If you don't specify it otherwise, all resources and properties get these permissions. With excel2xml , it is not possible to create resources/properties that don't have permissions, because they would be invisible for all users except project admins and system admins. Read more about permissions here . 4. Create list mappings Let's assume that your data source has a column containing list values named after the \"label\" of the JSON project list, instead of the \"name\" which is needed for the dsp-tools xmlupload . You need a way to get the names from the labels. If your data source uses the labels correctly, this is an easy task: The method create_json_list_mapping() creates a dictionary that maps the labels to the names: The list \"category\" in 0123-import-scripts/import_project.json looks as follows: { \"name\" : \"category\" , \"labels\" : { \"de\" : \"Kategorie\" , \"en\" : \"Category\" }, \"comments\" : { \"en\" : \"A list containing categories\" , \"de\" : \"Eine Liste mit Kategorien\" }, \"nodes\" : [ { \"name\" : \"artwork\" , \"labels\" : { \"de\" : \"Kunstwerk\" , \"en\" : \"Artwork\" } }, { \"name\" : \"nature\" , \"labels\" : { \"de\" : \"Natur\" , \"en\" : \"Nature\" }, \"nodes\" : [ { \"name\" : \"humans\" , \"labels\" : { \"de\" : \"Menschen\" , \"en\" : \"Humans\" } }, { \"...\" : \"...\" } ] } ] } If you pass this list to create_json_list_mapping() , it creates the following dictionary: { \"Kunstwerk\" : \"artwork\" , \"kunstwerk\" : \"artwork\" , \"Menschen\" : \"humans\" , \"menschen\" : \"humans\" , \"Natur\" : \"nature\" , \"natur\" : \"nature\" , \"...\" : \"...\" } If, however, your data source has spelling variants, you need the more sophisticated approach of create_json_excel_list_mapping() : This method creates a dictionary that maps the list values in your data source to their correct JSON project node name. This happens based on string similarity. Please carefully check the result if there are no false matches! The column \"Category\" in 0123-import-scripts/data_raw.csv has spelling mistakes: The dictionary that results if you call create_json_excel_list_mapping() : { \"Huumans\" : \"humans\" , \"huumans\" : \"humans\" , \"Artw\u00f6rk\" : \"artwork\" , \"artw\u00f6rk\" : \"artwork\" } The sample Python scripts features an example how to call these two methods, and how the resulting dictionaries can be used. 5. Iterate through the rows of your data source With the help of Pandas, you can then iterate through the rows of your Excel/CSV, and create resources and properties. 6. Create the <resource> tag There are four kind of resources that can be created: super tag method Resource <resource> make_resource() Annotation <annotation> make_annotation() Region <region> make_region() LinkObj <link> make_link() <resource> is the most frequent of them. The other three are explained here . Resource ID Special care is needed when the ID of a resource is created. Every resource must have an ID that is unique in the file, and it must meet the constraints of xsd:ID. You can simply achieve this if you use the method make_xsd_id_compatible() . If later, another resource would like to set a resptr-link to the resource that you are coding now, you must store the ID in a dict, so that you can retrieve it later. The example script contains an example of such a dict. 7. Append the properties For every property, there is a helper function that explains itself when you hover over it. So you don't need to worry anymore how to construct a certain XML value for a certain property. Here's how the Docstrings assist you: method signature: names of the parameters and accepted types short explanation how the method behaves usage examples link to the DSP-TOOLS documentation of this property a short description for every parameter short description of the returned object. Note: etree._Element is a type annotation of an underlying library. You don't have to care about it, as long as you proceed as described (append the returned object to the parent resource). Fine-tuning with PropertyElement There are two possibilities how to create a property: The value can be passed as it is, or as PropertyElement . If it is passed as it is, the permissions are assumed to be prop-default , texts are assumed to be encoded as utf8 , and the value won't have a comment: make_text_prop(\":testproperty\", \"first text\") <text-prop name=\":testproperty\"> <text encoding=\"utf8\" permissions=\"prop-default\">first text</text> </text-prop> If you want to change these defaults, you have to use a PropertyElement instead: make_text_prop( \":testproperty\", PropertyElement( value=\"first text\", permissions=\"prop-restricted\", encoding=\"xml\", comment=\"some comment\" ) ) <text-prop name=\":testproperty\"> <text encoding=\"xml\" permissions=\"prop-restricted\" comment=\"some comment\">first text</text> </text-prop> Supported boolean formats For make_boolean_prop(cell) , the following formats are supported: true: True, \"true\", \"True\", \"1\", 1, \"yes\", \"Yes\" false: False, \"false\", \"False\", \"0\", 0, \"no\", \"No\" N/A-like values will raise an Error. So if your cell is empty, this method will not count it as false, but will raise an Error. If you want N/A-like values to be counted as false, you may use a construct like this: if excel2xml.check_notna(cell): # the cell contains usable content excel2xml.make_boolean_prop(\":hasBoolean\", cell) else: # the cell is empty: you can decide to count this as \"False\" excel2xml.make_boolean_prop(\":hasBoolean\", False) Supported text values DSP's only restriction on text-properties is that the string must be longer than 0. It is, for example, possible to upload the following property: <text-prop name= \":hasText\" > <text encoding= \"utf8\" > </text> <text encoding= \"utf8\" > - </text> </text-prop> excel2xml allows to create such a property, but text values that don't meet the requirements of excel2xml.check_notna() will trigger a warning, for example: excel2xml.make_text_prop(\":hasText\", \" \") # OK, but triggers a warning excel2xml.make_text_prop(\":hasText\", \"-\") # OK, but triggers a warning 8. Append the resource to root At the end of the for-loop, it is important not to forget to append the finished resource to the root. 9. Save the file At the very end, save the file under a name that you can choose yourself. Other helper methods Check if a cell contains a usable value The method check_notna(cell) checks a value if it is usable in the context of data archiving. A value is considered usable if it is a number (integer or float, but not numpy.nan) a boolean a string with at least one Unicode letter (matching the regex \\\\p{L} ) or number, or at least one _, !, or ? (The strings \"None\", \" \", \"N/A\", and \"-\" are considered invalid.) a PropertyElement whose \"value\" fulfills the above criteria Examples: check_notna(0) == True check_notna(False) == True check_notna(\"\u0153\") == True check_notna(\"0\") == True check_notna(\"_\") == True check_notna(\"!\") == True check_notna(\"?\") == True check_notna(None) == False check_notna(\"None\") == False check_notna(<NA>) == False check_notna(\"<NA>\") == False check_notna(\"-\") == False check_notna(\" \") == False But why not just checking a cell by its boolean value? Like: if cell: resource.append(make_*_prop(cell)) There are many problems that can occur with this simple approach! Often, a cell won't evaluate to the boolean that you might expect: cell content return value of bool(cell) You might have expected... 0 False True, because 0 is a valid integer for your integer property \" \" True False, because an empty string is not usable for a text property numpy.nan True False, because N/A is not a usable value pandas.NA TypeError (*) False, because N/A is not a usable value \"<NA>\" True False, because this is the string representation of N/A \"-\" True False, because this is a placeholder in an empty text field (*) TypeError: boolean value of NA is ambiguous In contrast, check_notna(cell) will return the expected value for all cases in the table! Calendar date parsing The method find_date_in_string(string) tries to find a calendar date in a string. If successful, it returns the DSP-formatted date string. Notes: The date can be embedded in text. Only the first date found is returned. By default, dates are interpreted as CE (Christian era) in the Gregorian calendar. The years 0000-2999 are supported, in 4-digit form. Dates written with slashes are always interpreted in a European manner: 5/11/2021 is the 5th of November. Currently supported date formats: Input Output 0476_09_04 GREGORIAN:CE:0476-09-04:CE:0476-09-04 0476-09-04 GREGORIAN:CE:0476-09-04:CE:0476-09-04 30.4.2021 GREGORIAN:CE:2021-04-30:CE:2021-04-30 5/11/2021 GREGORIAN:CE:2021-11-05:CE:2021-11-05 Jan 26, 1993 GREGORIAN:CE:1993-01-26:CE:1993-01-26 February26,2051 GREGORIAN:CE:2051-02-26:CE:2051-02-26 28.2.-1.12.1515 GREGORIAN:CE:1515-02-28:CE:1515-12-01 25.-26.2.0800 GREGORIAN:CE:0800-02-25:CE:0800-02-26 1.9.2022-3.1.2024 GREGORIAN:CE:2022-09-01:CE:2024-01-03 1848 GREGORIAN:CE:1848:CE:1848 1849/1850 GREGORIAN:CE:1849:CE:1850 1849/50 GREGORIAN:CE:1849:CE:1850 1845-50 GREGORIAN:CE:1845:CE:1850","title":"excel2xml module"},{"location":"DSP-TOOLS/excel2xml-module/#the-excel2xml-module","text":"","title":"The excel2xml module"},{"location":"DSP-TOOLS/excel2xml-module/#two-use-cases-two-approaches","text":"There are two kinds of Excel files that can be transformed into an XML file: structure provenance tool example screenshot custom structure customer module excel2xml DSP structure DSP server CLI command excel2xml The first use case is the most frequent: The DaSCH receives a data export from a research project. Every project uses different software, so every project will deliver their data in a different structure. The screenshot is just a simplified example. For this use case, it is necessary to write a Python script that transforms the data from an undefined state X into a DSP-conforming XML file that can be uploaded with dsp-tools xmlupload . For this, you need to import the module excel2xml into your Python script. The second use case is less frequent: We migrate data DaSCH-internally from one server to another. In this case, the data already has the correct structure, and can automatically be transformed to XML. This can be done with the CLI command excel2xml . This page deals only with the first use case, the module excel2xml .","title":"Two use cases - two approaches"},{"location":"DSP-TOOLS/excel2xml-module/#module-excel2xml-convert-a-data-source-to-xml","text":"To demonstrate the usage of the excel2xml module, there is a GitHub repository named 0123-import-scripts . It contains: a sample JSON project file sample data that fits the data model of the JSON project file a sample Python script that demonstrates how to use the module excel2xml . Navigate to https://github.com/dasch-swiss/0123-import-scripts and follow the steps described there. The README will teach you some basics that will be necessary to work with excel2xml . Once you are familiar with the basics, return to this page to learn how the sample Python script works. This is the simplified pattern how the Python script works: 1 main_df = pd.read_csv(\"excel2xml_sample_data.csv\", dtype=\"str\", sep=\",\") 2 root = excel2xml.make_root(...) 3 root = excel2xml.append_permissions(root) 4 # if necessary: create list mappings, according to explanation below 5 for index, row in main_df.iterrows(): 6 resource = excel2xml.make_resource(...) 7 resource.append(excel2xml.make_text_prop(...)) 8 root.append(resource) 9 excel2xml.write_xml(root, \"data.xml\") 1 read in your data source with the pandas library (https://pandas.pydata.org/) 2 create the root element `<knora>` 3 append the permissions 4 if necessary: create list mappings (see below) 5 iterate through the rows of your data source: 6 create the `<resource>` tag 7 append properties to it 8 append the resource to the root tag `<knora>` 9 save the finished XML file These steps are now explained in-depth:","title":"Module excel2xml: Convert a data source to XML"},{"location":"DSP-TOOLS/excel2xml-module/#1-read-in-your-data-source","text":"In the first paragraph of the sample script, insert your ontology name, project shortcode, and the path to your data source. If necessary, activate one of the lines that are commented out.","title":"1. Read in your data source"},{"location":"DSP-TOOLS/excel2xml-module/#2-create-root-element-knora","text":"Then, the root element is created, which represents the <knora> tag of the XML document.","title":"2. Create root element &lt;knora&gt;"},{"location":"DSP-TOOLS/excel2xml-module/#3-append-the-permissions","text":"As first children of <knora> , some standard permissions are added. At the end, please carefully check the permissions of the finished XML file to ensure that they meet your requirements, and adapt them if necessary. The standard permission of a resource is res-default , and of a property prop-default . If you don't specify it otherwise, all resources and properties get these permissions. With excel2xml , it is not possible to create resources/properties that don't have permissions, because they would be invisible for all users except project admins and system admins. Read more about permissions here .","title":"3. Append the permissions"},{"location":"DSP-TOOLS/excel2xml-module/#4-create-list-mappings","text":"Let's assume that your data source has a column containing list values named after the \"label\" of the JSON project list, instead of the \"name\" which is needed for the dsp-tools xmlupload . You need a way to get the names from the labels. If your data source uses the labels correctly, this is an easy task: The method create_json_list_mapping() creates a dictionary that maps the labels to the names: The list \"category\" in 0123-import-scripts/import_project.json looks as follows: { \"name\" : \"category\" , \"labels\" : { \"de\" : \"Kategorie\" , \"en\" : \"Category\" }, \"comments\" : { \"en\" : \"A list containing categories\" , \"de\" : \"Eine Liste mit Kategorien\" }, \"nodes\" : [ { \"name\" : \"artwork\" , \"labels\" : { \"de\" : \"Kunstwerk\" , \"en\" : \"Artwork\" } }, { \"name\" : \"nature\" , \"labels\" : { \"de\" : \"Natur\" , \"en\" : \"Nature\" }, \"nodes\" : [ { \"name\" : \"humans\" , \"labels\" : { \"de\" : \"Menschen\" , \"en\" : \"Humans\" } }, { \"...\" : \"...\" } ] } ] } If you pass this list to create_json_list_mapping() , it creates the following dictionary: { \"Kunstwerk\" : \"artwork\" , \"kunstwerk\" : \"artwork\" , \"Menschen\" : \"humans\" , \"menschen\" : \"humans\" , \"Natur\" : \"nature\" , \"natur\" : \"nature\" , \"...\" : \"...\" } If, however, your data source has spelling variants, you need the more sophisticated approach of create_json_excel_list_mapping() : This method creates a dictionary that maps the list values in your data source to their correct JSON project node name. This happens based on string similarity. Please carefully check the result if there are no false matches! The column \"Category\" in 0123-import-scripts/data_raw.csv has spelling mistakes: The dictionary that results if you call create_json_excel_list_mapping() : { \"Huumans\" : \"humans\" , \"huumans\" : \"humans\" , \"Artw\u00f6rk\" : \"artwork\" , \"artw\u00f6rk\" : \"artwork\" } The sample Python scripts features an example how to call these two methods, and how the resulting dictionaries can be used.","title":"4. Create list mappings"},{"location":"DSP-TOOLS/excel2xml-module/#5-iterate-through-the-rows-of-your-data-source","text":"With the help of Pandas, you can then iterate through the rows of your Excel/CSV, and create resources and properties.","title":"5. Iterate through the rows of your data source"},{"location":"DSP-TOOLS/excel2xml-module/#6-create-the-resource-tag","text":"There are four kind of resources that can be created: super tag method Resource <resource> make_resource() Annotation <annotation> make_annotation() Region <region> make_region() LinkObj <link> make_link() <resource> is the most frequent of them. The other three are explained here .","title":"6. Create the &lt;resource&gt; tag"},{"location":"DSP-TOOLS/excel2xml-module/#resource-id","text":"Special care is needed when the ID of a resource is created. Every resource must have an ID that is unique in the file, and it must meet the constraints of xsd:ID. You can simply achieve this if you use the method make_xsd_id_compatible() . If later, another resource would like to set a resptr-link to the resource that you are coding now, you must store the ID in a dict, so that you can retrieve it later. The example script contains an example of such a dict.","title":"Resource ID"},{"location":"DSP-TOOLS/excel2xml-module/#7-append-the-properties","text":"For every property, there is a helper function that explains itself when you hover over it. So you don't need to worry anymore how to construct a certain XML value for a certain property. Here's how the Docstrings assist you: method signature: names of the parameters and accepted types short explanation how the method behaves usage examples link to the DSP-TOOLS documentation of this property a short description for every parameter short description of the returned object. Note: etree._Element is a type annotation of an underlying library. You don't have to care about it, as long as you proceed as described (append the returned object to the parent resource).","title":"7. Append the properties"},{"location":"DSP-TOOLS/excel2xml-module/#fine-tuning-with-propertyelement","text":"There are two possibilities how to create a property: The value can be passed as it is, or as PropertyElement . If it is passed as it is, the permissions are assumed to be prop-default , texts are assumed to be encoded as utf8 , and the value won't have a comment: make_text_prop(\":testproperty\", \"first text\") <text-prop name=\":testproperty\"> <text encoding=\"utf8\" permissions=\"prop-default\">first text</text> </text-prop> If you want to change these defaults, you have to use a PropertyElement instead: make_text_prop( \":testproperty\", PropertyElement( value=\"first text\", permissions=\"prop-restricted\", encoding=\"xml\", comment=\"some comment\" ) ) <text-prop name=\":testproperty\"> <text encoding=\"xml\" permissions=\"prop-restricted\" comment=\"some comment\">first text</text> </text-prop>","title":"Fine-tuning with PropertyElement"},{"location":"DSP-TOOLS/excel2xml-module/#supported-boolean-formats","text":"For make_boolean_prop(cell) , the following formats are supported: true: True, \"true\", \"True\", \"1\", 1, \"yes\", \"Yes\" false: False, \"false\", \"False\", \"0\", 0, \"no\", \"No\" N/A-like values will raise an Error. So if your cell is empty, this method will not count it as false, but will raise an Error. If you want N/A-like values to be counted as false, you may use a construct like this: if excel2xml.check_notna(cell): # the cell contains usable content excel2xml.make_boolean_prop(\":hasBoolean\", cell) else: # the cell is empty: you can decide to count this as \"False\" excel2xml.make_boolean_prop(\":hasBoolean\", False)","title":"Supported boolean formats"},{"location":"DSP-TOOLS/excel2xml-module/#supported-text-values","text":"DSP's only restriction on text-properties is that the string must be longer than 0. It is, for example, possible to upload the following property: <text-prop name= \":hasText\" > <text encoding= \"utf8\" > </text> <text encoding= \"utf8\" > - </text> </text-prop> excel2xml allows to create such a property, but text values that don't meet the requirements of excel2xml.check_notna() will trigger a warning, for example: excel2xml.make_text_prop(\":hasText\", \" \") # OK, but triggers a warning excel2xml.make_text_prop(\":hasText\", \"-\") # OK, but triggers a warning","title":"Supported text values"},{"location":"DSP-TOOLS/excel2xml-module/#8-append-the-resource-to-root","text":"At the end of the for-loop, it is important not to forget to append the finished resource to the root.","title":"8. Append the resource to root"},{"location":"DSP-TOOLS/excel2xml-module/#9-save-the-file","text":"At the very end, save the file under a name that you can choose yourself.","title":"9. Save the file"},{"location":"DSP-TOOLS/excel2xml-module/#other-helper-methods","text":"","title":"Other helper methods"},{"location":"DSP-TOOLS/excel2xml-module/#check-if-a-cell-contains-a-usable-value","text":"The method check_notna(cell) checks a value if it is usable in the context of data archiving. A value is considered usable if it is a number (integer or float, but not numpy.nan) a boolean a string with at least one Unicode letter (matching the regex \\\\p{L} ) or number, or at least one _, !, or ? (The strings \"None\", \" \", \"N/A\", and \"-\" are considered invalid.) a PropertyElement whose \"value\" fulfills the above criteria Examples: check_notna(0) == True check_notna(False) == True check_notna(\"\u0153\") == True check_notna(\"0\") == True check_notna(\"_\") == True check_notna(\"!\") == True check_notna(\"?\") == True check_notna(None) == False check_notna(\"None\") == False check_notna(<NA>) == False check_notna(\"<NA>\") == False check_notna(\"-\") == False check_notna(\" \") == False But why not just checking a cell by its boolean value? Like: if cell: resource.append(make_*_prop(cell)) There are many problems that can occur with this simple approach! Often, a cell won't evaluate to the boolean that you might expect: cell content return value of bool(cell) You might have expected... 0 False True, because 0 is a valid integer for your integer property \" \" True False, because an empty string is not usable for a text property numpy.nan True False, because N/A is not a usable value pandas.NA TypeError (*) False, because N/A is not a usable value \"<NA>\" True False, because this is the string representation of N/A \"-\" True False, because this is a placeholder in an empty text field (*) TypeError: boolean value of NA is ambiguous In contrast, check_notna(cell) will return the expected value for all cases in the table!","title":"Check if a cell contains a usable value"},{"location":"DSP-TOOLS/excel2xml-module/#calendar-date-parsing","text":"The method find_date_in_string(string) tries to find a calendar date in a string. If successful, it returns the DSP-formatted date string. Notes: The date can be embedded in text. Only the first date found is returned. By default, dates are interpreted as CE (Christian era) in the Gregorian calendar. The years 0000-2999 are supported, in 4-digit form. Dates written with slashes are always interpreted in a European manner: 5/11/2021 is the 5th of November. Currently supported date formats: Input Output 0476_09_04 GREGORIAN:CE:0476-09-04:CE:0476-09-04 0476-09-04 GREGORIAN:CE:0476-09-04:CE:0476-09-04 30.4.2021 GREGORIAN:CE:2021-04-30:CE:2021-04-30 5/11/2021 GREGORIAN:CE:2021-11-05:CE:2021-11-05 Jan 26, 1993 GREGORIAN:CE:1993-01-26:CE:1993-01-26 February26,2051 GREGORIAN:CE:2051-02-26:CE:2051-02-26 28.2.-1.12.1515 GREGORIAN:CE:1515-02-28:CE:1515-12-01 25.-26.2.0800 GREGORIAN:CE:0800-02-25:CE:0800-02-26 1.9.2022-3.1.2024 GREGORIAN:CE:2022-09-01:CE:2024-01-03 1848 GREGORIAN:CE:1848:CE:1848 1849/1850 GREGORIAN:CE:1849:CE:1850 1849/50 GREGORIAN:CE:1849:CE:1850 1845-50 GREGORIAN:CE:1845:CE:1850","title":"Calendar date parsing"},{"location":"DSP-TOOLS/incremental-xmlupload/","text":"Incremental xmlupload When uploading data with the xmlupload command, resources can reference each other with an internal ID, e.g. in the <resptr> tag. Once the data is in DSP, the resources cannot be referenced by their internal ID anymore. Instead, the resource's IRI has to be used. After a successful xmlupload , the mapping of internal IDs to their respective IRIs is written to a file called id2iri_mapping_[timestamp].json . What is this mapping used for? It can happen that at a later point of time, additional data is uploaded. Depending on what kind of references the additional data contains, there are 3 cases how this can happen: no references to existing resources: normal xmlupload references to existing resources via IRIs: incremental xmlupload references to existing resources via internal IDs: first id2iri, then incremental xmlupload 1. No references to existing resources The first case is the simplest one. Nothing has to be considered. The additional data can be uploaded with dsp-tools xmlupload additional_data.xml 2. References to existing resources via IRIs The second case is relatively easy, too: The file additional_data.xml contains references like <resptr>http://rdfh.ch/4123/nyOODvYySV2nJ5RWRdmOdQ</resptr> . Such a file can be uploaded with dsp-tools xmlupload --incremental additional_data.xml 3. References to existing resources via internal IDs The third case, however, is a bit more complicated: The file additional_data.xml contains references like <resptr>book_1</resptr> , where book_1 was the internal ID of a resource that had previously been uploaded to DSP. Before such an XML file can be uploaded, its internal IDs need to be replaced by their respective IRIs. That's where the JSON mapping file comes in: It contains a mapping from book_1 to http://rdfh.ch/4123/nyOODvYySV2nJ5RWRdmOdQ . id2iri As a first step, a new file must be generated with the id2iri command , like this: dsp-tools id2iri additional_data.xml id2iri_mapping_ [ timestamp ] .json --outfile additional_data_replaced.xml Important Only internal IDs inside the <resptr> tag are replaced. Salsah-links inside text properties (e.g. <a class=\"salsah-link\" href=\"IRI:book_1:IRI\">link to an ID</a> ) are NOT replaced. incremental xmlupload As second step, the newly generated XML file can be uploaded to DSP: dsp-tools xmlupload --incremental additional_data_replaced.xml Important Internal IDs and IRIs cannot be mixed within the same file. An XML file uploaded with the incremental option must not contain any internal IDs.","title":"Incremental xmlupload"},{"location":"DSP-TOOLS/incremental-xmlupload/#incremental-xmlupload","text":"When uploading data with the xmlupload command, resources can reference each other with an internal ID, e.g. in the <resptr> tag. Once the data is in DSP, the resources cannot be referenced by their internal ID anymore. Instead, the resource's IRI has to be used. After a successful xmlupload , the mapping of internal IDs to their respective IRIs is written to a file called id2iri_mapping_[timestamp].json . What is this mapping used for? It can happen that at a later point of time, additional data is uploaded. Depending on what kind of references the additional data contains, there are 3 cases how this can happen: no references to existing resources: normal xmlupload references to existing resources via IRIs: incremental xmlupload references to existing resources via internal IDs: first id2iri, then incremental xmlupload","title":"Incremental xmlupload"},{"location":"DSP-TOOLS/incremental-xmlupload/#1-no-references-to-existing-resources","text":"The first case is the simplest one. Nothing has to be considered. The additional data can be uploaded with dsp-tools xmlupload additional_data.xml","title":"1. No references to existing resources"},{"location":"DSP-TOOLS/incremental-xmlupload/#2-references-to-existing-resources-via-iris","text":"The second case is relatively easy, too: The file additional_data.xml contains references like <resptr>http://rdfh.ch/4123/nyOODvYySV2nJ5RWRdmOdQ</resptr> . Such a file can be uploaded with dsp-tools xmlupload --incremental additional_data.xml","title":"2. References to existing resources via IRIs"},{"location":"DSP-TOOLS/incremental-xmlupload/#3-references-to-existing-resources-via-internal-ids","text":"The third case, however, is a bit more complicated: The file additional_data.xml contains references like <resptr>book_1</resptr> , where book_1 was the internal ID of a resource that had previously been uploaded to DSP. Before such an XML file can be uploaded, its internal IDs need to be replaced by their respective IRIs. That's where the JSON mapping file comes in: It contains a mapping from book_1 to http://rdfh.ch/4123/nyOODvYySV2nJ5RWRdmOdQ .","title":"3. References to existing resources via internal IDs"},{"location":"DSP-TOOLS/incremental-xmlupload/#id2iri","text":"As a first step, a new file must be generated with the id2iri command , like this: dsp-tools id2iri additional_data.xml id2iri_mapping_ [ timestamp ] .json --outfile additional_data_replaced.xml Important Only internal IDs inside the <resptr> tag are replaced. Salsah-links inside text properties (e.g. <a class=\"salsah-link\" href=\"IRI:book_1:IRI\">link to an ID</a> ) are NOT replaced.","title":"id2iri"},{"location":"DSP-TOOLS/incremental-xmlupload/#incremental-xmlupload_1","text":"As second step, the newly generated XML file can be uploaded to DSP: dsp-tools xmlupload --incremental additional_data_replaced.xml Important Internal IDs and IRIs cannot be mixed within the same file. An XML file uploaded with the incremental option must not contain any internal IDs.","title":"incremental xmlupload"},{"location":"DSP-TOOLS/start-stack/","text":"Run the DSP stack on your local machine DSP-API is the heart of the DaSCH service platform. It is a server application for archiving data from the Humanities. DSP-APP is a generic user interface for the user to look at and work with data stored in DSP-API. It's a server application, too. For testing purposes, it is sometimes necessary to run DSP-API and DSP-APP on a local machine. There are two ways to do this: simple: run dsp-tools start-stack advanced: execute commands from within the DSP-API/DSP-APP repositories Here's an overview of the two ways: simple advanced target group researchers, RDU employees developers of DSP-API or DSP-APP how it works run dsp-tools start-stack execute commands from within locally cloned DSP-API/DSP-APP repositories software dependencies Docker, Python, DSP-TOOLS XCode command line tools, Docker, sbt, Java, Angular, node, yarn mechanism in the background run pre-built Docker images build DSP-API and DSP-APP from a branch in the repository available versions latest released version any branch, or locally modified working tree caveats dependencies must be kept up to date Simple way: dsp-tools start-stack The start-stack command runs Docker images with the latest released versions of DSP-API and DSP-APP, i.e. the versions that are running on https://admin.dasch.swiss . The only prerequisite for this is that Docker is running, and that you have Python and DSP-TOOLS installed. Some notes: As long as you want to keep the data in the database, don't execute dsp-tools stop-stack . It is possible to leave DSP-API up for a long time. If you want to save power, you can pause Docker. When you resume it, DSP-API will still be running, in the state how you left it. You can also send your computer to sleep while the DSP stack is running. For this, you don't even need to pause Docker. When should I restart DSP-API? After creating a data model and adding some data into your local DSP stack, you can work on DSP as if it was the live platform. But there are certain actions that are irreversible or can only be executed once, e.g. uploading the same JSON project file. If you edit your data model in the JSON file, and you want to upload it a second time, DSP-API will refuse to create the same project again. So, you might want to restart the stack and start over again from a clean setup. It is possible, however, to modify the XML data file and upload it again and again. But after some uploads, DSP is cluttered with data, so you might want to restart the stack. Advanced way If you want to run a specific branch of DSP-API / DSP-APP, or to modify them yourself, you need to: install the dependencies: follow the instructions on https://github.com/dasch-swiss/dsp-api and https://github.com/dasch-swiss/dsp-app keep the dependencies up to date (keep in mind that dependencies might be replaced over time) clone the repositories from GitHub keep them up to date with git pull execute commands from within the repositories ( make for DSP-API, angular for DSP-APP) take care that the repositories don't get cluttered with old data over time","title":"Running DSP locally"},{"location":"DSP-TOOLS/start-stack/#run-the-dsp-stack-on-your-local-machine","text":"DSP-API is the heart of the DaSCH service platform. It is a server application for archiving data from the Humanities. DSP-APP is a generic user interface for the user to look at and work with data stored in DSP-API. It's a server application, too. For testing purposes, it is sometimes necessary to run DSP-API and DSP-APP on a local machine. There are two ways to do this: simple: run dsp-tools start-stack advanced: execute commands from within the DSP-API/DSP-APP repositories Here's an overview of the two ways: simple advanced target group researchers, RDU employees developers of DSP-API or DSP-APP how it works run dsp-tools start-stack execute commands from within locally cloned DSP-API/DSP-APP repositories software dependencies Docker, Python, DSP-TOOLS XCode command line tools, Docker, sbt, Java, Angular, node, yarn mechanism in the background run pre-built Docker images build DSP-API and DSP-APP from a branch in the repository available versions latest released version any branch, or locally modified working tree caveats dependencies must be kept up to date","title":"Run the DSP stack on your local machine"},{"location":"DSP-TOOLS/start-stack/#simple-way-dsp-tools-start-stack","text":"The start-stack command runs Docker images with the latest released versions of DSP-API and DSP-APP, i.e. the versions that are running on https://admin.dasch.swiss . The only prerequisite for this is that Docker is running, and that you have Python and DSP-TOOLS installed. Some notes: As long as you want to keep the data in the database, don't execute dsp-tools stop-stack . It is possible to leave DSP-API up for a long time. If you want to save power, you can pause Docker. When you resume it, DSP-API will still be running, in the state how you left it. You can also send your computer to sleep while the DSP stack is running. For this, you don't even need to pause Docker.","title":"Simple way: dsp-tools start-stack"},{"location":"DSP-TOOLS/start-stack/#when-should-i-restart-dsp-api","text":"After creating a data model and adding some data into your local DSP stack, you can work on DSP as if it was the live platform. But there are certain actions that are irreversible or can only be executed once, e.g. uploading the same JSON project file. If you edit your data model in the JSON file, and you want to upload it a second time, DSP-API will refuse to create the same project again. So, you might want to restart the stack and start over again from a clean setup. It is possible, however, to modify the XML data file and upload it again and again. But after some uploads, DSP is cluttered with data, so you might want to restart the stack.","title":"When should I restart DSP-API?"},{"location":"DSP-TOOLS/start-stack/#advanced-way","text":"If you want to run a specific branch of DSP-API / DSP-APP, or to modify them yourself, you need to: install the dependencies: follow the instructions on https://github.com/dasch-swiss/dsp-api and https://github.com/dasch-swiss/dsp-app keep the dependencies up to date (keep in mind that dependencies might be replaced over time) clone the repositories from GitHub keep them up to date with git pull execute commands from within the repositories ( make for DSP-API, angular for DSP-APP) take care that the repositories don't get cluttered with old data over time","title":"Advanced way"},{"location":"DSP-TOOLS/developers/","text":"Developers documentation These pages contain important background information for developers of the DSP-TOOLS code repository, as well as Architectural Decision Records. Please read the README first.","title":"Developers documentation"},{"location":"DSP-TOOLS/developers/#developers-documentation","text":"These pages contain important background information for developers of the DSP-TOOLS code repository, as well as Architectural Decision Records. Please read the README first.","title":"Developers documentation"},{"location":"DSP-TOOLS/developers/git-submodules/","text":"Git submodules This repository embeds https://github.com/dasch-swiss/0123-import-scripts as a Git submodule in src/dsp_tools/import_scripts . That means that src/dsp_tools/import_scripts has no contents, but only a reference to a certain commit in the main branch of 0123-import-scripts . When you clone DSP-TOOLS from GitHub as usual, src/dsp_tools/import_scripts will be empty. Rationale to use a git submodule The code of the 0123-import-scripts repository is closely related to the documentation of the excel2xml module. When something changes in excel2xml , the changes need not only be reflected in the docs, but also in 0123-import-scripts . This can easily be forgotten. The decision to embed it as a submodule is meant to bring 0123-import-scripts closer to the attention of the developers of DSP-TOOLS. For example, a repo-wide search for a string or the usage of a method will also yield results from 0123-import-scripts . The example project rosetta is a similar case. Changes in DSP-TOOLS sometimes need to be reflected in rosetta. But since rosetta is not embedded as submodule, the developers have to take care not to forget rosetta. The contents of src/dsp_tools/import_scripts need not be part of the distribution, because the users of DSP-TOOLS will access these files via GitHub, and not via the distributed code. For this reason, this folder is excluded in pyproject.toml . Passively using the contents of the submodule If you don't have a clone of DSP-TOOLS yet, clone it with git clone --recurse-submodules https://github.com/dasch-swiss/dsp-tools.git After cloning it that way, and after some time has passed, you might want to get the latest changes from GitHub: cd dsp-tools git pull --recurse-submodules These two commands take care of the submodule, so that its contents are cloned/pulled as well. In case you have an old clone of DSP-TOOLS, without the submodule, and you want to update it, you have to proceed differently: cd dsp-tools git pull git submodule update --init --recursive Some notes: - git clone --recurse-submodules <repo> is shorthand for git clone <repo>; cd <repo>; git submodule update --init --recursive - git pull --recurse-submodules is shorthand for git pull; git submodule update --init --recursive - --init is necessary if you don't have the submodule src/dsp_tools/import_scripts yet. In all successive calls, when the submodule is already on your machine, the flag --init can be omitted. - --recursive is optional, in case there would be more than one (nested) submodules in the repository. - Since Git 2.15, you can tell Git to use --recurse-submodules for all commands that support it (except clone ), with git config submodule.recurse true . - These explanations rely on the Git Submodules documentation Renaming a parent directory of the submodule Renaming a parent directory of the submodule should be done with git mv old-name new-name , so that git won't be confused that the path to the submodule changed. If this doesn't help, it might be necessary to manually modify the gitdir in src/dsptools/import_scripts/.git the path in .gitmodules , and the name of the submodule in the title of that file the worktree entry in .git/modules/src/dsptools/import_scripts/config and the affected folder names in the path containing that file Actively working with the contents of the submodule After retrieving the contents of a submodule as described in the paragraph above, it is in \"detached HEAD\" state. Before committing to it, the main branch needs to be checked out. The order how to proceed is the following: cd src/dsp_tools/import_scripts git checkout main # check out main branch of 0123-import-scripts # (modify contents of submodule) git add . git commit -m \"modify submodule\" git push origin main # push to origin of 0123-import-scripts cd ../../.. git add src/dsp_tools/import_scripts git commit -m \"modify submodule\" git push origin feature-branch # push to origin of dsp-tools When switching between branches, there are two options: By default ( submodule.recurse is false AND branches are switched with git checkout <branch> ), the contents of submodules will not be updated. If submodule.recurse has been set to true, OR if branches are switched with git checkout <branch> --recurse-submodules , the contents of submodules will be updated according to the commit recorded in the super-project. If local modifications in a submodule would be overwritten, the checkout will fail. To quickly switch between branches when you have uncommitted work in the submodule, the first option might be preferable. After merging a Pull Request and switching back to the main branch, the second option might be more suitable. Read more about the checkout options in the official documentation","title":"Git submodules"},{"location":"DSP-TOOLS/developers/git-submodules/#git-submodules","text":"This repository embeds https://github.com/dasch-swiss/0123-import-scripts as a Git submodule in src/dsp_tools/import_scripts . That means that src/dsp_tools/import_scripts has no contents, but only a reference to a certain commit in the main branch of 0123-import-scripts . When you clone DSP-TOOLS from GitHub as usual, src/dsp_tools/import_scripts will be empty.","title":"Git submodules"},{"location":"DSP-TOOLS/developers/git-submodules/#rationale-to-use-a-git-submodule","text":"The code of the 0123-import-scripts repository is closely related to the documentation of the excel2xml module. When something changes in excel2xml , the changes need not only be reflected in the docs, but also in 0123-import-scripts . This can easily be forgotten. The decision to embed it as a submodule is meant to bring 0123-import-scripts closer to the attention of the developers of DSP-TOOLS. For example, a repo-wide search for a string or the usage of a method will also yield results from 0123-import-scripts . The example project rosetta is a similar case. Changes in DSP-TOOLS sometimes need to be reflected in rosetta. But since rosetta is not embedded as submodule, the developers have to take care not to forget rosetta. The contents of src/dsp_tools/import_scripts need not be part of the distribution, because the users of DSP-TOOLS will access these files via GitHub, and not via the distributed code. For this reason, this folder is excluded in pyproject.toml .","title":"Rationale to use a git submodule"},{"location":"DSP-TOOLS/developers/git-submodules/#passively-using-the-contents-of-the-submodule","text":"If you don't have a clone of DSP-TOOLS yet, clone it with git clone --recurse-submodules https://github.com/dasch-swiss/dsp-tools.git After cloning it that way, and after some time has passed, you might want to get the latest changes from GitHub: cd dsp-tools git pull --recurse-submodules These two commands take care of the submodule, so that its contents are cloned/pulled as well. In case you have an old clone of DSP-TOOLS, without the submodule, and you want to update it, you have to proceed differently: cd dsp-tools git pull git submodule update --init --recursive Some notes: - git clone --recurse-submodules <repo> is shorthand for git clone <repo>; cd <repo>; git submodule update --init --recursive - git pull --recurse-submodules is shorthand for git pull; git submodule update --init --recursive - --init is necessary if you don't have the submodule src/dsp_tools/import_scripts yet. In all successive calls, when the submodule is already on your machine, the flag --init can be omitted. - --recursive is optional, in case there would be more than one (nested) submodules in the repository. - Since Git 2.15, you can tell Git to use --recurse-submodules for all commands that support it (except clone ), with git config submodule.recurse true . - These explanations rely on the Git Submodules documentation","title":"Passively using the contents of the submodule"},{"location":"DSP-TOOLS/developers/git-submodules/#renaming-a-parent-directory-of-the-submodule","text":"Renaming a parent directory of the submodule should be done with git mv old-name new-name , so that git won't be confused that the path to the submodule changed. If this doesn't help, it might be necessary to manually modify the gitdir in src/dsptools/import_scripts/.git the path in .gitmodules , and the name of the submodule in the title of that file the worktree entry in .git/modules/src/dsptools/import_scripts/config and the affected folder names in the path containing that file","title":"Renaming a parent directory of the submodule"},{"location":"DSP-TOOLS/developers/git-submodules/#actively-working-with-the-contents-of-the-submodule","text":"After retrieving the contents of a submodule as described in the paragraph above, it is in \"detached HEAD\" state. Before committing to it, the main branch needs to be checked out. The order how to proceed is the following: cd src/dsp_tools/import_scripts git checkout main # check out main branch of 0123-import-scripts # (modify contents of submodule) git add . git commit -m \"modify submodule\" git push origin main # push to origin of 0123-import-scripts cd ../../.. git add src/dsp_tools/import_scripts git commit -m \"modify submodule\" git push origin feature-branch # push to origin of dsp-tools When switching between branches, there are two options: By default ( submodule.recurse is false AND branches are switched with git checkout <branch> ), the contents of submodules will not be updated. If submodule.recurse has been set to true, OR if branches are switched with git checkout <branch> --recurse-submodules , the contents of submodules will be updated according to the commit recorded in the super-project. If local modifications in a submodule would be overwritten, the checkout will fail. To quickly switch between branches when you have uncommitted work in the submodule, the first option might be preferable. After merging a Pull Request and switching back to the main branch, the second option might be more suitable. Read more about the checkout options in the official documentation","title":"Actively working with the contents of the submodule"},{"location":"DSP-TOOLS/developers/github-actions/","text":"GitHub actions GitHub actions are workflows that are (remotely) run by GitHub if a certain event happens. Actions are defined in YML files in the .github/workflows folder. The YML files define by what event an action is triggered what the action should do The syntax of the YML files is documented on the GitHub actions documentation page . It can be defined in the settings of the repository what happens if an action fails, e.g. an email is sent to the maintainer, or a PR is blocked from being merged, etc. check-pr-title.yml This action checks if the title of the PR complies with a certain regex. publish-to-pypi.yml This action is triggered when a Release-Please-PR (see below) is merged. Basically, this action calls poetry build and poetry publish . release-please.yml When a PR is merged to main, this action creates a Release-Please-PR. This is a PR that increments the version number of DSP-TOOLS, and adds a synopsis of the PRs merged since the last release to the changelog. When this PR is merged, the publish-to-pypi.yml action is triggered. tests-on-push.yml In the settings of the DSP-TOOLS repository, these tests are configured to be mandatory to pass before a PR can be merged. Basically, this action checks that the docs can be built without errors or warnings there are no dead links in the docs the unit tests run without errors the end-to-end tests run without errors Checking dead links is a non-trivial task. There are several tools for it, but the only one which works for our purpose is markdown-link-validator . There are some caveats, though: Firstly, markdown-link-validator doesn't recognize internal links to files in the docs/assets folder. These must be added as ignore patterns, cf. the flag -i \\.assets\\/.+ in the code snippet below. Secondly, external links to private pages raise an error, even though they are correct. An example is the link to https://github.com/dasch-swiss/dsp-tools/settings above. To make markdown-link-validator work, the following flag is necessary: -i .+github\\.com\\/dasch\\-swiss\\/dsp-tools\\/settings So finally, this is the call to markdown-link-validator: markdown-link-validator ./docs -i \\. assets \\/ .+ -i .+github \\. com \\/ dasch \\- swiss \\/ dsp-tools \\/ settings As the documentation grows, and new titles are added, it might be necessary to adapt this call!","title":"GitHub actions"},{"location":"DSP-TOOLS/developers/github-actions/#github-actions","text":"GitHub actions are workflows that are (remotely) run by GitHub if a certain event happens. Actions are defined in YML files in the .github/workflows folder. The YML files define by what event an action is triggered what the action should do The syntax of the YML files is documented on the GitHub actions documentation page . It can be defined in the settings of the repository what happens if an action fails, e.g. an email is sent to the maintainer, or a PR is blocked from being merged, etc.","title":"GitHub actions"},{"location":"DSP-TOOLS/developers/github-actions/#check-pr-titleyml","text":"This action checks if the title of the PR complies with a certain regex.","title":"check-pr-title.yml"},{"location":"DSP-TOOLS/developers/github-actions/#publish-to-pypiyml","text":"This action is triggered when a Release-Please-PR (see below) is merged. Basically, this action calls poetry build and poetry publish .","title":"publish-to-pypi.yml"},{"location":"DSP-TOOLS/developers/github-actions/#release-pleaseyml","text":"When a PR is merged to main, this action creates a Release-Please-PR. This is a PR that increments the version number of DSP-TOOLS, and adds a synopsis of the PRs merged since the last release to the changelog. When this PR is merged, the publish-to-pypi.yml action is triggered.","title":"release-please.yml"},{"location":"DSP-TOOLS/developers/github-actions/#tests-on-pushyml","text":"In the settings of the DSP-TOOLS repository, these tests are configured to be mandatory to pass before a PR can be merged. Basically, this action checks that the docs can be built without errors or warnings there are no dead links in the docs the unit tests run without errors the end-to-end tests run without errors Checking dead links is a non-trivial task. There are several tools for it, but the only one which works for our purpose is markdown-link-validator . There are some caveats, though: Firstly, markdown-link-validator doesn't recognize internal links to files in the docs/assets folder. These must be added as ignore patterns, cf. the flag -i \\.assets\\/.+ in the code snippet below. Secondly, external links to private pages raise an error, even though they are correct. An example is the link to https://github.com/dasch-swiss/dsp-tools/settings above. To make markdown-link-validator work, the following flag is necessary: -i .+github\\.com\\/dasch\\-swiss\\/dsp-tools\\/settings So finally, this is the call to markdown-link-validator: markdown-link-validator ./docs -i \\. assets \\/ .+ -i .+github \\. com \\/ dasch \\- swiss \\/ dsp-tools \\/ settings As the documentation grows, and new titles are added, it might be necessary to adapt this call!","title":"tests-on-push.yml"},{"location":"DSP-TOOLS/developers/mkdocs/","text":"MkDocs and markdown-link-validator The documentation of DSP-TOOLS is built with MkDocs (see README ). Please consider the following caveats: Styling constraints in the documentation In our GitHub actions, we check PRs for dead links in the documentation. Our tool markdown-link-validator is only able to check internal links if they start with ./ . For example: [prefixes]\u2063(./dsp-tools-create.md#prefixes-object) instead of [prefixes](dsp-tools-create.md#prefixes-object) ![Colors_en]\u2063(./assets/images/img-list-english-colors.png) instead of ![Colors_en](assets/images/img-list-english-colors.png) It is okay, however, to make an internal link to a title of the current document: [prefixes]\u2063(#prefixes-object) Please follow this constraint, so that markdown-link-validator can check the internal links. Handling false positives of markdown-link-validator What can be done if your links are correct, but markdown-link-validator doesn't recognize them? One solution is to add an ignore pattern to the call to markdown-link-validator in .github/workflows/tests-on-push.yml . If your link is in a code block, and isn't intended to be used as link, you can also add an invisible Unicode character, like in the examples above. No duplicate headings, no special characters in headings When linking to a heading, the name heading is slugified. Unfortunately, there are different flavors of Markdown, and different slug algorithms. As long as the heading is unique in the document, and doesn't contain special characters, there is no problem. But consider a document like this: # Heading / Title First heading with this name # Heading / Title Second heading with this name # Further down in the document [link to second heading]\u2063(#heading-title_1) <!--mkdocs supports only this syntax--> [link to second heading]\u2063(#heading--title-1) <!--npm markdown-link-validator supports only this syntax--> To make things worse, different IDEs use different slug algorithms, too, which might lead to misleading hints from the IDE. The real danger lies within MkDocs: while it doesn't support the heading--title-1 syntax, it doesn't complain if you use it, not even when using the --strict flag. This can lead to broken links on https://docs.dasch.swiss/ , without anyone noticing. The best solution how to deal with this is to give a unique name to every heading within the same document not to use special characters A short overview of Markdown tools and slug algorithms: MkDocs uses Python Markdown to translate Markdown files into HTML (see here ). Python Markdown's default slugify used to strip out all Unicode chars (see here ). markdown-link-validator uses uslug to create the slugs (see here ). VS Code targets the CommonMark Markdown specification using the markdown-it library (see here ). Another useful reading is here .","title":"MkDocs and markdown-link-validator"},{"location":"DSP-TOOLS/developers/mkdocs/#mkdocs-and-markdown-link-validator","text":"The documentation of DSP-TOOLS is built with MkDocs (see README ). Please consider the following caveats:","title":"MkDocs and markdown-link-validator"},{"location":"DSP-TOOLS/developers/mkdocs/#styling-constraints-in-the-documentation","text":"In our GitHub actions, we check PRs for dead links in the documentation. Our tool markdown-link-validator is only able to check internal links if they start with ./ . For example: [prefixes]\u2063(./dsp-tools-create.md#prefixes-object) instead of [prefixes](dsp-tools-create.md#prefixes-object) ![Colors_en]\u2063(./assets/images/img-list-english-colors.png) instead of ![Colors_en](assets/images/img-list-english-colors.png) It is okay, however, to make an internal link to a title of the current document: [prefixes]\u2063(#prefixes-object) Please follow this constraint, so that markdown-link-validator can check the internal links.","title":"Styling constraints in the documentation"},{"location":"DSP-TOOLS/developers/mkdocs/#handling-false-positives-of-markdown-link-validator","text":"What can be done if your links are correct, but markdown-link-validator doesn't recognize them? One solution is to add an ignore pattern to the call to markdown-link-validator in .github/workflows/tests-on-push.yml . If your link is in a code block, and isn't intended to be used as link, you can also add an invisible Unicode character, like in the examples above.","title":"Handling false positives of markdown-link-validator"},{"location":"DSP-TOOLS/developers/mkdocs/#no-duplicate-headings-no-special-characters-in-headings","text":"When linking to a heading, the name heading is slugified. Unfortunately, there are different flavors of Markdown, and different slug algorithms. As long as the heading is unique in the document, and doesn't contain special characters, there is no problem. But consider a document like this: # Heading / Title First heading with this name # Heading / Title Second heading with this name # Further down in the document [link to second heading]\u2063(#heading-title_1) <!--mkdocs supports only this syntax--> [link to second heading]\u2063(#heading--title-1) <!--npm markdown-link-validator supports only this syntax--> To make things worse, different IDEs use different slug algorithms, too, which might lead to misleading hints from the IDE. The real danger lies within MkDocs: while it doesn't support the heading--title-1 syntax, it doesn't complain if you use it, not even when using the --strict flag. This can lead to broken links on https://docs.dasch.swiss/ , without anyone noticing. The best solution how to deal with this is to give a unique name to every heading within the same document not to use special characters A short overview of Markdown tools and slug algorithms: MkDocs uses Python Markdown to translate Markdown files into HTML (see here ). Python Markdown's default slugify used to strip out all Unicode chars (see here ). markdown-link-validator uses uslug to create the slugs (see here ). VS Code targets the CommonMark Markdown specification using the markdown-it library (see here ). Another useful reading is here .","title":"No duplicate headings, no special characters in headings"},{"location":"DSP-TOOLS/developers/packaging/","text":"Dependency management, packaging, and distribution General considerations There are a number of tasks necessary to develop and distribute a Python package, and a number of tools to assist with these processes. The Python Packaging User Guide lists the following, among others: Task poetry Hatch pipenv venv build setuptools flit twine Dependency management X X Virtual environment X X X X Build frontend X X X Build backend X X X X Publishing to pypi.org X X X X DSP-TOOLS uses poetry for all of these tasks. This allows us to use one single tool for all processes, and to keep the number of configuration files at a minimum. There are many configuration and metadata files that can be found on the top level of a Python repository. The ones used in the DSP-TOOLS repository are: File Purpose README.md Markdown-formatted infos for developers pyproject.toml Modern configuration/metadata file replacing the deprecated files listed below .gitignore List of files not under version control (won't be uploaded to GitHub) .gitmodules DSP-TOOLS contains a Git submodule (more infos below) CHANGELOG.md Markdown-formatted release notes (must not be edited by hand) LICENSE Text file with the license how to use the source code of DSP-TOOLS poetry.lock Pinned versions of all (sub-)dependencies, allows a deterministic installation mkdocs.yml Configuration of mkdocs , used to build the documentation webpages In earlier times, there were some more configuration files, but thanks to poetry, they are not necessary anymore: Deprecated file Purpose Replaced by MANIFEST.in files to include into distribution pyproject.toml: [tool.poetry.include] setup.py project metadata, dependencies pyproject.toml setup.cfg configuration for setuptools pyproject.toml requirements.txt all (sub-)dependencies pyproject.toml: [tool.poetry.dependencies] dev-requirements.txt additional dependencies for development pyproject.toml: [tool.poetry.group.dev.dependencies] Pipfile direct dependencies pyproject.toml: [tool.poetry.dependencies] Pipfile.lock pinned dependencies poetry.lock Makefile commands that can be executed with make [command] pyproject.toml: [tool.poetry-exec-plugin.commands] Dependency management The classic way to manage the dependencies was to write the required packages by hand into a requirements.txt and into a setup.py file. But this is cumbersome and error-prone, so there was a time when pipenv was the way to go: Pipenv introduced the important distinction between (a) dependencies necessary to run the application, (b) dependencies necessary for development, and (c) sub-dependencies, i.e. dependencies of your dependencies. Another useful concept of pipenv is the distinction between a human-friendly list of (mostly unpinned) direct dependencies and a machine-friendly definition of exact (pinned) versions of all dependencies. But since pipenv has no packaging functionality, it was necessary to sync the dependency definitions from Pipfile to requirements.txt and setup.py . setup.py , too, is problematic, especially calling setup.py sdist bdist_wheel . Python projects should define their dependencies and metadata in the modern pyproject.toml file. So it is necessary to dynamically manage the dependencies in pyproject.toml . And poetry seems to be the only tool capable of doing this. Packaging All project metadata, together with the dependencies and the configuration of the packaging tool poetry, is defined in pyproject.toml . The authoritative resource on how to create this file is https://packaging.python.org/en/latest/specifications/declaring-project-metadata . The table [build-system] of pyproject.toml tells frontend build tools what backend build tool to use. The backend doesn't need to be installed. It will be installed by the frontend in a temporary, isolated environment for use during the build process. DSP-TOOLS uses poetry as both frontend and backend. What happens when a distribution package of DSP-TOOLS is created? Poetry creates two files in the dist folder: a . tar.gz compressed archive (the sdist or source distribution) and a .whl file (a wheel). Both contain the contents of the src folder plus some metadata - they are equivalent. They are then uploaded to the Python Package Index (PyPI) . When a user installs DSP-TOOLS with pip install dsp-tools , pip takes the sdist or the wheel, unpacks it, and copies it into the site-packages folder of the user's Python installation. As a result, the user has the same packages in his site-packages folder as the src folder of the dsp-tools repository. In our case, this is the dsp_tools package. Since site-packages is on sys.path , the user can then import the package dsp_tools in his script. Advantages of the src layout Putting all packages into a src folder has an important consequence: It forces the developer to work with an editable installation of his package. Why? Without an editable installation, it is impossible to write correct import statements. from src.package import module will not work, because the user has package installed, not src . And relative imports like import module will not work either, because when the tests code (situated in a separate test folder) imports the actual code, the relative imports in the actual code fail. This is because relative imports depend on the location of the file that is run, not on the file that contains the import statement. The solution is to always have an editable installation of the package under development. Poetry does this automatically when you execute poetry install . This makes the package dsp_tools importable - just like on a user's machine. And exactly this is the big advantage: With the src layout and an editable installation, the setup on the developer's machine is more similar to the user's setup. The advantages of the src layout are: import parity The tests run against the package as it will be installed by the user - not against the situation in the developer's repository. It is obvious to both humans and tools if a folder is a package to be distributed, or not. The editable installation is only able to import modules that will also be importable in a regular installation. For the developer, the working directory is the root of the repository, so the root will implicitly be included in sys.path . Users will never have the same current working directory than the developer. So, removing the packages from the root by putting them into src prevents some practices that will not work on the user's machine. For more in-depth explanations, please visit the following pages: https://blog.ionelmc.ro/2014/05/25/python-packaging https://hynek.me/articles/testing-packaging https://packaging.python.org/en/latest/discussions/src-layout-vs-flat-layout Publishing and distribution Publishing is automated with GitHub Actions and should not be done manually. If you still need to do it, follow the steps below. Generate the distribution package: poetry build You can install the package locally from the dist: pip install dist/some_name.whl Upload package: poetry publish","title":"Dependencies, packaging & distribution"},{"location":"DSP-TOOLS/developers/packaging/#dependency-management-packaging-and-distribution","text":"","title":"Dependency management, packaging, and distribution"},{"location":"DSP-TOOLS/developers/packaging/#general-considerations","text":"There are a number of tasks necessary to develop and distribute a Python package, and a number of tools to assist with these processes. The Python Packaging User Guide lists the following, among others: Task poetry Hatch pipenv venv build setuptools flit twine Dependency management X X Virtual environment X X X X Build frontend X X X Build backend X X X X Publishing to pypi.org X X X X DSP-TOOLS uses poetry for all of these tasks. This allows us to use one single tool for all processes, and to keep the number of configuration files at a minimum. There are many configuration and metadata files that can be found on the top level of a Python repository. The ones used in the DSP-TOOLS repository are: File Purpose README.md Markdown-formatted infos for developers pyproject.toml Modern configuration/metadata file replacing the deprecated files listed below .gitignore List of files not under version control (won't be uploaded to GitHub) .gitmodules DSP-TOOLS contains a Git submodule (more infos below) CHANGELOG.md Markdown-formatted release notes (must not be edited by hand) LICENSE Text file with the license how to use the source code of DSP-TOOLS poetry.lock Pinned versions of all (sub-)dependencies, allows a deterministic installation mkdocs.yml Configuration of mkdocs , used to build the documentation webpages In earlier times, there were some more configuration files, but thanks to poetry, they are not necessary anymore: Deprecated file Purpose Replaced by MANIFEST.in files to include into distribution pyproject.toml: [tool.poetry.include] setup.py project metadata, dependencies pyproject.toml setup.cfg configuration for setuptools pyproject.toml requirements.txt all (sub-)dependencies pyproject.toml: [tool.poetry.dependencies] dev-requirements.txt additional dependencies for development pyproject.toml: [tool.poetry.group.dev.dependencies] Pipfile direct dependencies pyproject.toml: [tool.poetry.dependencies] Pipfile.lock pinned dependencies poetry.lock Makefile commands that can be executed with make [command] pyproject.toml: [tool.poetry-exec-plugin.commands]","title":"General considerations"},{"location":"DSP-TOOLS/developers/packaging/#dependency-management","text":"The classic way to manage the dependencies was to write the required packages by hand into a requirements.txt and into a setup.py file. But this is cumbersome and error-prone, so there was a time when pipenv was the way to go: Pipenv introduced the important distinction between (a) dependencies necessary to run the application, (b) dependencies necessary for development, and (c) sub-dependencies, i.e. dependencies of your dependencies. Another useful concept of pipenv is the distinction between a human-friendly list of (mostly unpinned) direct dependencies and a machine-friendly definition of exact (pinned) versions of all dependencies. But since pipenv has no packaging functionality, it was necessary to sync the dependency definitions from Pipfile to requirements.txt and setup.py . setup.py , too, is problematic, especially calling setup.py sdist bdist_wheel . Python projects should define their dependencies and metadata in the modern pyproject.toml file. So it is necessary to dynamically manage the dependencies in pyproject.toml . And poetry seems to be the only tool capable of doing this.","title":"Dependency management"},{"location":"DSP-TOOLS/developers/packaging/#packaging","text":"All project metadata, together with the dependencies and the configuration of the packaging tool poetry, is defined in pyproject.toml . The authoritative resource on how to create this file is https://packaging.python.org/en/latest/specifications/declaring-project-metadata . The table [build-system] of pyproject.toml tells frontend build tools what backend build tool to use. The backend doesn't need to be installed. It will be installed by the frontend in a temporary, isolated environment for use during the build process. DSP-TOOLS uses poetry as both frontend and backend. What happens when a distribution package of DSP-TOOLS is created? Poetry creates two files in the dist folder: a . tar.gz compressed archive (the sdist or source distribution) and a .whl file (a wheel). Both contain the contents of the src folder plus some metadata - they are equivalent. They are then uploaded to the Python Package Index (PyPI) . When a user installs DSP-TOOLS with pip install dsp-tools , pip takes the sdist or the wheel, unpacks it, and copies it into the site-packages folder of the user's Python installation. As a result, the user has the same packages in his site-packages folder as the src folder of the dsp-tools repository. In our case, this is the dsp_tools package. Since site-packages is on sys.path , the user can then import the package dsp_tools in his script.","title":"Packaging"},{"location":"DSP-TOOLS/developers/packaging/#advantages-of-the-src-layout","text":"Putting all packages into a src folder has an important consequence: It forces the developer to work with an editable installation of his package. Why? Without an editable installation, it is impossible to write correct import statements. from src.package import module will not work, because the user has package installed, not src . And relative imports like import module will not work either, because when the tests code (situated in a separate test folder) imports the actual code, the relative imports in the actual code fail. This is because relative imports depend on the location of the file that is run, not on the file that contains the import statement. The solution is to always have an editable installation of the package under development. Poetry does this automatically when you execute poetry install . This makes the package dsp_tools importable - just like on a user's machine. And exactly this is the big advantage: With the src layout and an editable installation, the setup on the developer's machine is more similar to the user's setup. The advantages of the src layout are: import parity The tests run against the package as it will be installed by the user - not against the situation in the developer's repository. It is obvious to both humans and tools if a folder is a package to be distributed, or not. The editable installation is only able to import modules that will also be importable in a regular installation. For the developer, the working directory is the root of the repository, so the root will implicitly be included in sys.path . Users will never have the same current working directory than the developer. So, removing the packages from the root by putting them into src prevents some practices that will not work on the user's machine. For more in-depth explanations, please visit the following pages: https://blog.ionelmc.ro/2014/05/25/python-packaging https://hynek.me/articles/testing-packaging https://packaging.python.org/en/latest/discussions/src-layout-vs-flat-layout","title":"Advantages of the src layout"},{"location":"DSP-TOOLS/developers/packaging/#publishing-and-distribution","text":"Publishing is automated with GitHub Actions and should not be done manually. If you still need to do it, follow the steps below. Generate the distribution package: poetry build You can install the package locally from the dist: pip install dist/some_name.whl Upload package: poetry publish","title":"Publishing and distribution"},{"location":"DSP-TOOLS/developers/start-stack-command/","text":"How to maintain the start-stack command The start-stack command starts Docker containers of DSP-API and DSP-APP, in the version that is running on https://admin.dasch.swiss . In addition to the containers, a number of files from the DSP-API GitHub repository is necessary. The version of the docker images and these files must be the same. The version is hardcoded at the following places in the code: src/dsp_tools/docker/docker-compose.yml : The 4 variables services/{app,db,sipi,api}/image must point to the DockerHub image of the last deployed version. src/dsp_tools/utils/stack_handling.py : The variable commit_of_used_api_version must be the commit hash of DSP-API of the version that is running on https://admin.dasch.swiss .","title":"Maintaining the start-stack command"},{"location":"DSP-TOOLS/developers/start-stack-command/#how-to-maintain-the-start-stack-command","text":"The start-stack command starts Docker containers of DSP-API and DSP-APP, in the version that is running on https://admin.dasch.swiss . In addition to the containers, a number of files from the DSP-API GitHub repository is necessary. The version of the docker images and these files must be the same. The version is hardcoded at the following places in the code: src/dsp_tools/docker/docker-compose.yml : The 4 variables services/{app,db,sipi,api}/image must point to the DockerHub image of the last deployed version. src/dsp_tools/utils/stack_handling.py : The variable commit_of_used_api_version must be the commit hash of DSP-API of the version that is running on https://admin.dasch.swiss .","title":"How to maintain the start-stack command"},{"location":"DSP-TOOLS/developers/user-data/","text":"User data in the user's home directory DSP-TOOLS saves user data in the user's home directory, in the folder .dsp-tools . Here is an overview of its structure: folder command using it description xmluploads xmlupload saves id2iri mappings and error reports docker start-stack files necessary to startup Docker containers Remark: Docker is normally not able to access files stored in the site-packages of a Python installation. Therefore, it's necessary to copy the \"docker\" folder to the user's home directory. How to ship data files to the user Accessing non-Python files (a.k.a. resources, a.k.a data files) in the code needs special attention. Firstly, the build tool must be told to include this folder/files in the distribution. In our case, this happens in [tool.poetry.include] in the pyproject.toml file. Secondly, when accessing the files on the customer's machine, the files inside site-packages should be read-only to avoid a series of common problems (e.g. when multiple users share a common Python installation, when the package is loaded from a zip file, or when multiple instances of a Python application run in parallel). Thirdly, the files can neither be accessed with a relative path from the referencing file, nor with a path relative to the root of the project. For example, if you have a structure like this: dsp-tools \u251c\u2500\u2500 pyproject.toml \u2514\u2500\u2500 src \u2514\u2500\u2500 dsp_tools \u251c\u2500\u2500 schemas \u2502 \u2514\u2500\u2500 data.xsd \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 dsp_tools.py it is not possible to do one of the following in dsp_tools/dsp_tools.py: with open ( 'schemas/data.xsd' ) as data_file : ... with open ( 'src/dsp_tools/schemas/data.xsd' ) as data_file : ... The reason why these two approaches fail is that the working directory on the user's machine is determined by the directory where DSP-TOOLS is called from - not the directory where the distribution files are situated in. To circumvent this problem, it was once common to manipulate a package\u2019s __file__ attribute in order to find the location of data files: import os data_path = os . path . join ( os . path . dirname ( __file__ ), 'schemas' , 'data.xsd' ) with open ( data_path ) as data_file : ... However, this manipulation isn\u2019t compatible with PEP 302-based import hooks, including importing from zip files and Python Eggs. The canonical way is to use importlib.resources : from importlib.resources import files # address \"schemas\" directory in module syntax: needs __init__.py data_text = files ( 'dsp_tools.schemas' ) . joinpath ( 'data.xsd' ) . read_text () # avoid module syntax when addressing \"schemas\" directory: no __init__.py necessary data_text = files ( 'dsp_tools' ) . joinpath ( 'schemas' ) . joinpath ( 'data.xsd' ) . read_text () Note that depending on how the directory is addressed, an __init__.py file is necessary or can be omitted. The information on this page is mainly based upon: - https://stackoverflow.com/a/20885799/14414188 - https://stackoverflow.com/a/58941536/14414188 - https://setuptools.pypa.io/en/latest/userguide/datafiles.html#accessing-data-files-at-runtime","title":"User data"},{"location":"DSP-TOOLS/developers/user-data/#user-data-in-the-users-home-directory","text":"DSP-TOOLS saves user data in the user's home directory, in the folder .dsp-tools . Here is an overview of its structure: folder command using it description xmluploads xmlupload saves id2iri mappings and error reports docker start-stack files necessary to startup Docker containers Remark: Docker is normally not able to access files stored in the site-packages of a Python installation. Therefore, it's necessary to copy the \"docker\" folder to the user's home directory.","title":"User data in the user's home directory"},{"location":"DSP-TOOLS/developers/user-data/#how-to-ship-data-files-to-the-user","text":"Accessing non-Python files (a.k.a. resources, a.k.a data files) in the code needs special attention. Firstly, the build tool must be told to include this folder/files in the distribution. In our case, this happens in [tool.poetry.include] in the pyproject.toml file. Secondly, when accessing the files on the customer's machine, the files inside site-packages should be read-only to avoid a series of common problems (e.g. when multiple users share a common Python installation, when the package is loaded from a zip file, or when multiple instances of a Python application run in parallel). Thirdly, the files can neither be accessed with a relative path from the referencing file, nor with a path relative to the root of the project. For example, if you have a structure like this: dsp-tools \u251c\u2500\u2500 pyproject.toml \u2514\u2500\u2500 src \u2514\u2500\u2500 dsp_tools \u251c\u2500\u2500 schemas \u2502 \u2514\u2500\u2500 data.xsd \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 dsp_tools.py it is not possible to do one of the following in dsp_tools/dsp_tools.py: with open ( 'schemas/data.xsd' ) as data_file : ... with open ( 'src/dsp_tools/schemas/data.xsd' ) as data_file : ... The reason why these two approaches fail is that the working directory on the user's machine is determined by the directory where DSP-TOOLS is called from - not the directory where the distribution files are situated in. To circumvent this problem, it was once common to manipulate a package\u2019s __file__ attribute in order to find the location of data files: import os data_path = os . path . join ( os . path . dirname ( __file__ ), 'schemas' , 'data.xsd' ) with open ( data_path ) as data_file : ... However, this manipulation isn\u2019t compatible with PEP 302-based import hooks, including importing from zip files and Python Eggs. The canonical way is to use importlib.resources : from importlib.resources import files # address \"schemas\" directory in module syntax: needs __init__.py data_text = files ( 'dsp_tools.schemas' ) . joinpath ( 'data.xsd' ) . read_text () # avoid module syntax when addressing \"schemas\" directory: no __init__.py necessary data_text = files ( 'dsp_tools' ) . joinpath ( 'schemas' ) . joinpath ( 'data.xsd' ) . read_text () Note that depending on how the directory is addressed, an __init__.py file is necessary or can be omitted. The information on this page is mainly based upon: - https://stackoverflow.com/a/20885799/14414188 - https://stackoverflow.com/a/58941536/14414188 - https://setuptools.pypa.io/en/latest/userguide/datafiles.html#accessing-data-files-at-runtime","title":"How to ship data files to the user"},{"location":"DSP-TOOLS/file-formats/excel2json/","text":"Excel file format to generate a JSON project The folder structure With the excel2json command, a JSON project file can be created from Excel files. To put it simple, a JSON project consists of 0-1 \"lists\" sections 1-n ontologies, each containing 1 \"properties\" section 1 \"resources\" section For each of these 3 sections, one or several Excel files are necessary. The Excel files and their format are described below. If you want to convert the Excel files to JSON, it is possible to invoke a command for each of these sections separately (as described below). But it is more convenient to use the command that creates the entire JSON project file. In order to do so, put all involved files into a folder with the following structure: data_model_files |-- lists | |-- de.xlsx | `-- en.xlsx `-- onto_name (onto_label) |-- properties.xlsx `-- resources.xlsx Conventions for the folder names: The \"lists\" folder must have exactly this name, if it exists. It can also be omitted. Replace \"onto_name\" by your ontology's name, and \"onto_label\" by your ontology's label. The only name that can be chosen freely is the name of the topmost folder (\"data_model_files\" in this example). Then, use the following command: dsp-tools excel2json data_model_files project.json This will create a file project.json with the lists, properties, and resources from the Excel files. Please note that the \"header\" of the resulting JSON file is empty and thus invalid. It is necessary to add the project shortcode, shortname, longname, descriptions, and keywords by hand. Likewise, there will be no prefixes, no groups and no users in the resulting JSON file. Continue reading the following paragraphs to learn more about the expected structure of the Excel files. resources section With the excel2resources command, the resources section used in a data model (JSON) can be created from an Excel file. Only XLSX files are allowed. The resources section can be inserted into the ontology file and then be uploaded onto a DSP server. An Excel file template can be found here or also in the data_model_files folder of 0123-import-scripts . It is recommended to work from the template. The expected worksheets of the Excel file are: classes : a table with all resource classes intended to be used in the resulting JSON class1 , class2 ,...: a table for each resource class named after its name The worksheet called classes must have the following structure: The expected columns are: name (mandatory): Unique identifier for the resource class label_en , label_de , label_fr , label_it , label_rm (one language mandatory): Label of the resource class that will be displayed in DSP-APP. Should be rather short. comment_en , comment_de , comment_fr , comment_it , comment_rm (optional): Description of the resource class. Can be longer than the label. super (mandatory): The type of this resource class, i.e. the base resource class(es) that this resource class is derived from. Must be one of the values listed in the documentation. If more than one: separated by commas. The optional columns may be omitted in the Excel. All other worksheets, one for each resource class, have the following structure: The expected columns are: Property (mandatory): The unique identifier of the property Cardinality (mandatory): Indicates how often the property may occur. The possible values are: \"1\" : exactly once (mandatory one value and only one) \"0-1\" : The value may be omitted, but can occur only once. \"1-n\" : At least one value must be present, but multiple values may be present. \"0-n\" : The value may be omitted, but may also occur multiple times. gui_order (optional): By default, DSP-APP displays the properties in the order how they are listed in the Excel sheet. If you prefer another order, you can make a numbering in this column. Example: You order the propnames alphabetically in the Excel, but they should be displayed in another order in DSP-APP. properties section With the excel2properties command, the properties section used in a data model (JSON) can be created from an Excel file. Only the first worksheet of the Excel file is considered and only XLSX files are allowed. The properties section can be inserted into the ontology file and then be uploaded onto a DSP server. An Excel file template can be found here or also in the data_model_files folder of 0123-import-scripts . It is recommended to work from the template. The Excel sheet must have the following structure: The expected columns are: name (mandatory): Unique identifier for the property label_en , label_de , label_fr , label_it , label_rm : (one language mandatory): Label of the property that will be displayed in DSP-APP. Should be rather short. comment_en , comment_de , comment_fr , comment_it , comment_rm (optional): Description of the property. Can be longer than the label. super (mandatory): The type of this property, i.e. the base property/ies that this property is derived from. Must be one of the values listed in the documentation. If more than one: separated by commas. object (mandatory): Target value of this property. Must be one of the values listed in the documentation. If the property is derived from hasValue , the type of the property must be further specified by the object it takes, e.g. TextValue , ListValue , or IntValue . If the property is derived from hasLinkTo , the object specifies the resource class that this property refers to. gui_element (mandatory): The graphic component, defines how this property should be displayed. Depends on the value of object : Read the documentation of the respective object to learn which gui_element can be used. gui_attributes (only mandatory for lists): Some gui_element s need further specifications. Read the documentation of the respective object to learn if your gui_element needs a gui_attributes . Form: \"attr: value, attr: value\". The optional columns may be omitted in the Excel. For backwards compatibility, files with column titles hlist , en , de , fr , it , or rm are valid, but deprecated. lists section With the excel2lists command, the lists section of a JSON project file can be created from one or several Excel files. The lists can then be inserted into a JSON project file and uploaded to a DSP server. The following example shows how to create the \"lists\" section from the two Excel files de.xlsx and en.xlsx which are located in a directory called listfolder : dsp-tools excel2lists listfolder lists.json The Excel sheets must have the following structure: Some notes: The data must be in the first worksheet of each Excel file. It is important that all Excel files have the same structure. So, the translation of a label in the second Excel file has to be in the exact same cell as the one in the first Excel file. Only Excel files with file extension .xlsx are considered. The file name must consist of the language label, e.g. de.xlsx / en.xlsx . The language has to be one of {de, en, fr, it, rm}. As node name, a simplified version of the English label is taken. If English is not available, one of the other languages is taken. If there are two nodes with the same name, an incrementing number is appended to the name. After the creation of the list, a validation against the JSON schema for lists is performed. An error message is printed out if the list is not valid. It is recommended to work from the following templates: en.xlsx : File with the English labels de.xlsx : File with the German labels or alternatively from the data_model_files folder of 0123-import-scripts The output of the above command, with the template files, is: { \"lists\" : [ { \"name\" : \"colors\" , \"labels\" : { \"de\" : \"Farben\" , \"en\" : \"colors\" }, \"comments\" : { \"de\" : \"Farben\" , \"en\" : \"colors\" }, \"nodes\" : [ { \"name\" : \"red\" , \"labels\" : { \"de\" : \"rot\" , \"en\" : \"red\" } }, \"...\" ] }, { \"name\" : \"category\" , \"labels\" : { \"de\" : \"Kategorie\" , \"en\" : \"category\" }, \"comments\" : { \"de\" : \"Kategorie\" , \"en\" : \"category\" }, \"nodes\" : [ { \"name\" : \"artwork\" , \"labels\" : { \"de\" : \"Kunstwerk\" , \"en\" : \"artwork\" } }, \"...\" ] }, { \"name\" : \"faculties-of-the-university-of-basel\" , \"labels\" : { \"de\" : \"Fakult\u00e4ten der Universit\u00e4t Basel\" , \"en\" : \"Faculties of the University of Basel\" }, \"comments\" : { \"de\" : \"Fakult\u00e4ten der Universit\u00e4t Basel\" , \"en\" : \"Faculties of the University of Basel\" }, \"nodes\" : [ { \"name\" : \"faculty-of-science\" , \"labels\" : { \"de\" : \"Philosophisch-Naturwissenschaftliche Fakult\u00e4t\" , \"en\" : \"Faculty of Science\" } }, \"...\" ] } ] }","title":"excel2json"},{"location":"DSP-TOOLS/file-formats/excel2json/#excel-file-format-to-generate-a-json-project","text":"","title":"Excel file format to generate a JSON project"},{"location":"DSP-TOOLS/file-formats/excel2json/#the-folder-structure","text":"With the excel2json command, a JSON project file can be created from Excel files. To put it simple, a JSON project consists of 0-1 \"lists\" sections 1-n ontologies, each containing 1 \"properties\" section 1 \"resources\" section For each of these 3 sections, one or several Excel files are necessary. The Excel files and their format are described below. If you want to convert the Excel files to JSON, it is possible to invoke a command for each of these sections separately (as described below). But it is more convenient to use the command that creates the entire JSON project file. In order to do so, put all involved files into a folder with the following structure: data_model_files |-- lists | |-- de.xlsx | `-- en.xlsx `-- onto_name (onto_label) |-- properties.xlsx `-- resources.xlsx Conventions for the folder names: The \"lists\" folder must have exactly this name, if it exists. It can also be omitted. Replace \"onto_name\" by your ontology's name, and \"onto_label\" by your ontology's label. The only name that can be chosen freely is the name of the topmost folder (\"data_model_files\" in this example). Then, use the following command: dsp-tools excel2json data_model_files project.json This will create a file project.json with the lists, properties, and resources from the Excel files. Please note that the \"header\" of the resulting JSON file is empty and thus invalid. It is necessary to add the project shortcode, shortname, longname, descriptions, and keywords by hand. Likewise, there will be no prefixes, no groups and no users in the resulting JSON file. Continue reading the following paragraphs to learn more about the expected structure of the Excel files.","title":"The folder structure"},{"location":"DSP-TOOLS/file-formats/excel2json/#resources-section","text":"With the excel2resources command, the resources section used in a data model (JSON) can be created from an Excel file. Only XLSX files are allowed. The resources section can be inserted into the ontology file and then be uploaded onto a DSP server. An Excel file template can be found here or also in the data_model_files folder of 0123-import-scripts . It is recommended to work from the template. The expected worksheets of the Excel file are: classes : a table with all resource classes intended to be used in the resulting JSON class1 , class2 ,...: a table for each resource class named after its name The worksheet called classes must have the following structure: The expected columns are: name (mandatory): Unique identifier for the resource class label_en , label_de , label_fr , label_it , label_rm (one language mandatory): Label of the resource class that will be displayed in DSP-APP. Should be rather short. comment_en , comment_de , comment_fr , comment_it , comment_rm (optional): Description of the resource class. Can be longer than the label. super (mandatory): The type of this resource class, i.e. the base resource class(es) that this resource class is derived from. Must be one of the values listed in the documentation. If more than one: separated by commas. The optional columns may be omitted in the Excel. All other worksheets, one for each resource class, have the following structure: The expected columns are: Property (mandatory): The unique identifier of the property Cardinality (mandatory): Indicates how often the property may occur. The possible values are: \"1\" : exactly once (mandatory one value and only one) \"0-1\" : The value may be omitted, but can occur only once. \"1-n\" : At least one value must be present, but multiple values may be present. \"0-n\" : The value may be omitted, but may also occur multiple times. gui_order (optional): By default, DSP-APP displays the properties in the order how they are listed in the Excel sheet. If you prefer another order, you can make a numbering in this column. Example: You order the propnames alphabetically in the Excel, but they should be displayed in another order in DSP-APP.","title":"resources section"},{"location":"DSP-TOOLS/file-formats/excel2json/#properties-section","text":"With the excel2properties command, the properties section used in a data model (JSON) can be created from an Excel file. Only the first worksheet of the Excel file is considered and only XLSX files are allowed. The properties section can be inserted into the ontology file and then be uploaded onto a DSP server. An Excel file template can be found here or also in the data_model_files folder of 0123-import-scripts . It is recommended to work from the template. The Excel sheet must have the following structure: The expected columns are: name (mandatory): Unique identifier for the property label_en , label_de , label_fr , label_it , label_rm : (one language mandatory): Label of the property that will be displayed in DSP-APP. Should be rather short. comment_en , comment_de , comment_fr , comment_it , comment_rm (optional): Description of the property. Can be longer than the label. super (mandatory): The type of this property, i.e. the base property/ies that this property is derived from. Must be one of the values listed in the documentation. If more than one: separated by commas. object (mandatory): Target value of this property. Must be one of the values listed in the documentation. If the property is derived from hasValue , the type of the property must be further specified by the object it takes, e.g. TextValue , ListValue , or IntValue . If the property is derived from hasLinkTo , the object specifies the resource class that this property refers to. gui_element (mandatory): The graphic component, defines how this property should be displayed. Depends on the value of object : Read the documentation of the respective object to learn which gui_element can be used. gui_attributes (only mandatory for lists): Some gui_element s need further specifications. Read the documentation of the respective object to learn if your gui_element needs a gui_attributes . Form: \"attr: value, attr: value\". The optional columns may be omitted in the Excel. For backwards compatibility, files with column titles hlist , en , de , fr , it , or rm are valid, but deprecated.","title":"properties section"},{"location":"DSP-TOOLS/file-formats/excel2json/#lists-section","text":"With the excel2lists command, the lists section of a JSON project file can be created from one or several Excel files. The lists can then be inserted into a JSON project file and uploaded to a DSP server. The following example shows how to create the \"lists\" section from the two Excel files de.xlsx and en.xlsx which are located in a directory called listfolder : dsp-tools excel2lists listfolder lists.json The Excel sheets must have the following structure: Some notes: The data must be in the first worksheet of each Excel file. It is important that all Excel files have the same structure. So, the translation of a label in the second Excel file has to be in the exact same cell as the one in the first Excel file. Only Excel files with file extension .xlsx are considered. The file name must consist of the language label, e.g. de.xlsx / en.xlsx . The language has to be one of {de, en, fr, it, rm}. As node name, a simplified version of the English label is taken. If English is not available, one of the other languages is taken. If there are two nodes with the same name, an incrementing number is appended to the name. After the creation of the list, a validation against the JSON schema for lists is performed. An error message is printed out if the list is not valid. It is recommended to work from the following templates: en.xlsx : File with the English labels de.xlsx : File with the German labels or alternatively from the data_model_files folder of 0123-import-scripts The output of the above command, with the template files, is: { \"lists\" : [ { \"name\" : \"colors\" , \"labels\" : { \"de\" : \"Farben\" , \"en\" : \"colors\" }, \"comments\" : { \"de\" : \"Farben\" , \"en\" : \"colors\" }, \"nodes\" : [ { \"name\" : \"red\" , \"labels\" : { \"de\" : \"rot\" , \"en\" : \"red\" } }, \"...\" ] }, { \"name\" : \"category\" , \"labels\" : { \"de\" : \"Kategorie\" , \"en\" : \"category\" }, \"comments\" : { \"de\" : \"Kategorie\" , \"en\" : \"category\" }, \"nodes\" : [ { \"name\" : \"artwork\" , \"labels\" : { \"de\" : \"Kunstwerk\" , \"en\" : \"artwork\" } }, \"...\" ] }, { \"name\" : \"faculties-of-the-university-of-basel\" , \"labels\" : { \"de\" : \"Fakult\u00e4ten der Universit\u00e4t Basel\" , \"en\" : \"Faculties of the University of Basel\" }, \"comments\" : { \"de\" : \"Fakult\u00e4ten der Universit\u00e4t Basel\" , \"en\" : \"Faculties of the University of Basel\" }, \"nodes\" : [ { \"name\" : \"faculty-of-science\" , \"labels\" : { \"de\" : \"Philosophisch-Naturwissenschaftliche Fakult\u00e4t\" , \"en\" : \"Faculty of Science\" } }, \"...\" ] } ] }","title":"lists section"},{"location":"DSP-TOOLS/file-formats/excel2xml/","text":"Excel file format to generate an XML data file Hint If you want to convert customer data to XML, you need the excel2xml module instead of the CLI command. With the excel2xml CLI command, an XML data file can be created from an Excel/CSV file. The Excel/CSV file must be structured as in this image: Some notes: The special tags <annotation> , <link> , and <region> are represented as resources of restype Annotation , LinkObj , and Region . The columns \"ark\", \"iri\", and \"creation_date\" are only used for DaSCH-internal data migration. If file is provided, but no file permissions , an attempt will be started to deduce them from the resource permissions ( res-default --> prop-default and res-restricted --> prop-restricted ). If this attempt is not successful, a BaseError will be raised.","title":"excel2xml"},{"location":"DSP-TOOLS/file-formats/excel2xml/#excel-file-format-to-generate-an-xml-data-file","text":"Hint If you want to convert customer data to XML, you need the excel2xml module instead of the CLI command. With the excel2xml CLI command, an XML data file can be created from an Excel/CSV file. The Excel/CSV file must be structured as in this image: Some notes: The special tags <annotation> , <link> , and <region> are represented as resources of restype Annotation , LinkObj , and Region . The columns \"ark\", \"iri\", and \"creation_date\" are only used for DaSCH-internal data migration. If file is provided, but no file permissions , an attempt will be started to deduce them from the resource permissions ( res-default --> prop-default and res-restricted --> prop-restricted ). If this attempt is not successful, a BaseError will be raised.","title":"Excel file format to generate an XML data file"},{"location":"DSP-TOOLS/file-formats/xml-data-file/","text":"The XML file format for importing data With the xmlupload command, data can be imported into a DSP repository (on a DSP server) from an XML file. The import file is a standard XML file as described on this page. After a successful upload of the data, an output file is written (called id2iri_mapping_[timestamp].json ) with the mapping from the internal IDs used inside the XML to their corresponding IRIs which uniquely identify them inside DSP. This file should be kept if data is later added with the --incremental option . The import file must start with the standard XML header: <?xml version='1.0' encoding='utf-8'?> The root element <knora> The <knora> element describes all resources that should be imported. It has the following attributes: xmlns : \"https://dasch.swiss/schema\" (required) xmlns:xsi : \"http://www.w3.org/2001/XMLSchema-instance\" (required) xsi:schemaLocation : \"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/data.xsd\" ( required) shortcode : project shortcode, e.g. \"0801\" (required) default-ontology : name of the ontology (required) The <knora> element may look as follows: <knora xmlns= \"https://dasch.swiss/schema\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/data.xsd\" shortcode= \"0806\" default-ontology= \"webern\" > ... </knora> The <knora> element can only contain the following sub-elements: <permissions> (optional) <resource> The DSP permissions The DSP server provides access control for every resource and every property. Groups The user doesn't hold the permissions directly, but belongs to an arbitrary number of groups which hold the permissions. There are built-in groups and project specific groups : Built-in groups : Every user is automatically in at least one of the following built-in groups: UnknownUser : The user is not known to DSP (not logged in). KnownUser : The user is logged in, but not a member of the project the data element belongs to. ProjectMember : The user belongs to the same project as the data element. ProjectAdmin : The user is project administrator in the project the data element belongs to. Creator : The user is the owner of the element (created the element). SystemAdmin : The user is a system administrator. Project specific groups : can be defined in the JSON project file Rights A group can have exactly one of these rights: (no right): If no permission is defined for a certain group of users, these users cannot view any resources/values. RV restricted view permission : Same as V , but if it is applied to an image, the image is shown with a reduced resolution or with a watermark overlay. V view permission : The user can view a resource or a value, but cannot modify it. M modify permission : The user can modify the element, but cannot mark it as deleted. The original resource or value will be preserved. D delete permission : The user is allowed to mark an element as deleted. The original resource or value will be preserved. CR change right permission : The user can change the permission of a resource or value. The user is also allowed to permanently delete (erase) a resource. Every right of this row includes all previous rights. Defining permissions with the <permissions> element The <permissions> element defines a permission ID that can subsequently be used in a permissions attribute of a <resource> or <xyz-prop> tag. It is optional to define permissions in the XML. If not defined, default permissions are applied, so that only project and system administrators can view and edit resources. All other users have no rights at all, not even view or restricted view permissions. The <permissions> element defines which rights are given to which groups: <permissions id= \"res-default\" > <allow group= \"UnknownUser\" > RV </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"dsp-test:MlsEditors\" > D </allow> </permissions> In addition to the DSP built-in groups, project specific groups are supported as well. A project specific group name has the form project-shortname:groupname . If you don't want a group to have access at all, leave it out. In the following example, resources or properties with permission special-permission can only be viewed by ProjectAdmin s: <permissions id= \"special-permission\" > <allow group= \"ProjectAdmin\" > CR </allow> </permissions> Using permissions with the permissions attribute Once defined, the permission IDs can be used as permissions attribute in the <resource> and <xyz-prop> tags. It is important to note that a resource doesn't inherit its permissions to its properties. Each property must have its own permissions. So, in the following example, the bitstreams don't inherit the permissions from their resource: <resource ...> <bitstream permissions=\"prop-default\">images/EURUS015a.jpg</bitstream> </resource> <resource ...> <bitstream permissions=\"prop-restricted\">images/EURUS015a.jpg</bitstream> </resource> <resource ...> <bitstream>images/EURUS015a.jpg</bitstream> </resource> To take as example KnownUser , i.e. a logged-in user who is not member of the project: With permissions=\"prop-default\" , he has V rights on the image: Normal view. With permissions=\"prop-restricted\" , he has RV rights on the image: Blurred image. With a blank <bitstream> tag, he has no rights on the image: No view possible. Only users from ProjectAdmin upwards are able to look at the image. Describing resources with the <resource> element A <resource> element contains all necessary information to create a resource. It has the following attributes: label (required): a human-readable, preferably meaningful short name of the resource restype (required): the resource type as defined within the ontology id (required): a unique, arbitrary string providing a unique ID to the resource in order to be referencable by other resources; the ID is only used during the import process and later replaced by the IRI used internally by DSP permissions (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights): a reference to a permission ID iri (optional): a custom IRI, used when migrating existing resources (DaSCH-internal only) ark (optional): a version 0 ARK, used when migrating existing resources. It is not possible to use iri and ark in the same resource. When ark is used, it overrides iri (DaSCH-internal only). creation_date (optional): the creation date of the resource, used when migrating existing resources . It must be formatted according to the constraints of xsd:dateTimeStamp , which means that the timezone is required, e.g.: 2005-10-23T13:45:12.502951+02:00 (DaSCH-internal only) A complete <resource> element may look as follows: <resource label= \"EURUS015a\" restype= \":Postcard\" id= \"238807\" permissions= \"res-def-perm\" > ... </resource> For every property that the ontology requires, the <resource> element contains one property element (e.g. <integer-prop name=\"property_name> ). The property element contains one or more values. Example of a property element of type integer with two values: <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 4711 </integer> <integer permissions= \"prop-default\" > 1 </integer> </integer-prop> The following property elements exist: <bitstream> : contains a path to a file (if the resource is a multimedia resource) <boolean-prop> : contains a boolean value <color-prop> : contains color values <date-prop> : contains date values <decimal-prop> : contains decimal values <geometry-prop> : contains JSON geometry definitions for a region <geoname-prop> : contains geonames.org location codes <list-prop> : contains list element labels <integer-prop> : contains integer values <interval-prop> : contains interval values <period-prop> : contains time period values (not yet implemented) <resptr-prop> : contains links to other resources <text-prop> : contains text values <time-prop> : contains time values <uri-prop> : contains URI values <bitstream> The <bitstream> element is used for bitstream data. It contains the path to a bitstream object like an image file, a ZIP container, an audio file etc. It must only be used if the resource is a StillImageRepresentation , an AudioRepresentation , a DocumentRepresentation etc. Notes: There is only one <bitstream> element allowed per representation. The <bitstream> element must be the first element. By default, the path is relative to the working directory where dsp-tools xmlupload is executed in. This behaviour can be modified with the flag --imgdir . If you keep the default, it is recommended to choose the project folder as working directory, my_project in the example below: my_project \u251c\u2500\u2500 files \u2502 \u251c\u2500\u2500 data_model.json \u2502 \u2514\u2500\u2500 data_file.xml (<bitstream>images/dog.jpg</bitstream>) \u2514\u2500\u2500 images \u251c\u2500\u2500 dog.jpg \u2514\u2500\u2500 cat.jpg my_project % dsp-tools xmlupload files/data_file.xml Supported file extensions: Representation Supported formats ArchiveRepresentation ZIP, TAR, GZ, Z, TAR.GZ, TGZ, GZIP, 7Z AudioRepresentation MP3, WAV DocumentRepresentation PDF, DOC, DOCX, XLS, XLSX, PPT, PPTX MovingImageRepresentation MP4 StillImageRepresentation JPG, JPEG, PNG, TIF, TIFF, JP2 TextRepresentation TXT, CSV, XML, XSL, XSD For more details, please consult the API docs . Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) Example of a public image inside a StillImageRepresentation : <resource restype= \":Image\" id= \"image_1\" label= \"image_1\" permissions= \"res-default\" > <bitstream permissions= \"prop-default\" > postcards/images/EURUS015a.jpg </bitstream> </resource> <boolean-prop> The <boolean-prop> element is used for boolean values. It must contain exactly one <boolean> element. Attributes: name : name of the property as defined in the ontology (required) <boolean> The <boolean> element must contain the string \"true\" or \"false\", or the numeral 1 (true) or 0 (false). Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a public and a hidden boolean property: <boolean-prop name=\":hasBoolean\"> <boolean permissions=\"prop-default\">true</boolean> </boolean-prop> <boolean-prop name=\":hasHiddenBoolean\"> <boolean>0</boolean> </boolean-prop> <color-prop> The <color-prop> element is used for color values. It must contain at least one <color> element. Attributes: name : name of the property as defined in the ontology (required) <color> The <color> element is used to indicate a color value. The color has to be given in web-notation, that is a # followed by 3 or 6 hex numerals. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden color value: <color-prop name= \":hasColor\" > <color permissions= \"prop-default\" > #00ff66 </color> <color> #ff00ff </color> </color-prop> <date-prop> The <date-prop> element is used for date values. It must contain at least one <date> element. Attributes: name : name of the property as defined in the ontology (required) <date> the <date> element contains a DSP-specific date value. It has the following format: calendar:epoch:yyyy-mm-dd:epoch:yyyy-mm-dd calendar : either \"JULIAN\" or \"GREGORIAN\" (optional, default: GREGORIAN) epoch : either \"BCE\" or \"CE\" (optional, default CE) yyyy : year with four digits (required) mm : month with two digits (optional, e.g. 01, 02, ..., 12) dd : day with two digits (optional, e.g. 01, 02, ..., 31) Notes: If the day is omitted, then the precision is month, if also the month is omitted, the precision is year. Internally, a date is always represented as a start and end date. If start and end date match, it's an exact date. If start and end date don't match, it's a range. If the end date is omitted, it's a range from the earliest possible beginning of the start date to the latest possible end of the start date. For example: \"1893\" will be expanded to a range from January 1st 1893 to December 31st 1893. \"1893-01\" will be expanded to a range from January 1st 1893 to January 31st 1893. \"1893-01-01\" will be expanded to the exact date January 1st 1893 to January 1st 1893 (technically also a range). Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden date value: <date-prop name= \":hasDate\" > <date permissions= \"prop-default\" > GREGORIAN:CE:2014-01-31 </date> <date> GREGORIAN:CE:1930-09-02:CE:1930-09-03 </date> </date-prop> <decimal-prop> The <decimal-prop> element is used for decimal values. It must contain at least one <decimal> element. Attributes: name : name of the property as defined in the ontology (required) <decimal> The <decimal> element contains a decimal number. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden decimal value: <decimal-prop name= \":hasDecimal\" > <decimal permissions= \"prop-default\" > 3.14159 </decimal> <decimal> 2.71828 </decimal> </decimal-prop> <geometry-prop> The <geometry-prop> element is used for a geometric definition of a 2-D region (e.g. a region on an image). It must contain at least one <geometry> element. A <geometry-prop> can only be used inside a <region> tag . Attributes: name : the only allowed name is hasGeometry , because this property is a DSP base property that can only be used in the <region> tag . <geometry> A geometry value is defined as a JSON object. It contains the following data: status : \"active\" or \"deleted\" type : \"circle\", \"rectangle\" or \"polygon\" (only the rectangle can be displayed in DSP-APP. The others can be looked at in another frontend, e.g. in TANGOH.) lineColor : web-color lineWidth : integer number (in pixels) points : array of coordinate objects of the form {\"x\": decimal, \"y\": decimal} radius : coordinate object of the form {\"x\": decimal, \"y\": decimal} In the SALSAH data, there is also a key named original_index in the JSON format of all three shapes, but it doesn't seem to have an influence on the shapes that TANGOH displays, so it can be omitted. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example: <geometry-prop name=\"hasGeometry\"> <geometry permissions=\"prop-default\"> { \"status\": \"active\", \"type\": \"rectangle\", \"lineColor\": \"#ff1100\", \"lineWidth\": 5, \"points\": [ {\"x\":0.1,\"y\":0.7}, {\"x\":0.3,\"y\":0.2} ] } </geometry> <geometry permissions=\"prop-default\"> { \"status\": \"active\", \"type\": \"circle\", \"lineColor\": \"#ff1100\", \"lineWidth\": 5, \"points\": [{\"x\":0.5,\"y\":0.3}], \"radius\": {\"x\":0.1,\"y\":0.1} // vector (0.1, 0.1) } </geometry> <geometry permissions=\"prop-default\"> { \"status\": \"active\", \"type\": \"polygon\", \"lineColor\": \"#ff1100\", \"lineWidth\": 5, \"points\": [{\"x\": 0.4, \"y\": 0.6}, {\"x\": 0.5, \"y\": 0.9}, {\"x\": 0.8, \"y\": 0.9}, {\"x\": 0.7, \"y\": 0.6}] } </geometry> </geometry-prop> The underlying grid is a 0-1 normalized top left-anchored grid. The following coordinate system shows the three shapes that were defined above: <geoname-prop> The <geoname-prop> element is used for values that contain a geonames.org ID. It must contain at least one <geoname> element. Attributes: name : name of the property as defined in the ontology (required) <geoname> Contains a valid geonames.org ID. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public link to Vienna and a hidden link to Basel: <geoname-prop name= \":hasLocation\" > <geoname permissions= \"prop-default\" > 2761369 </geoname> <geoname> 2661604 </geoname> </geoname-prop> <integer-prop> The <integer-prop> element is used for integer values. It must contain at least one <integer> element. Attributes: name : name of the property as defined in the ontology (required) <integer> The <integer> element contains an integer value. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden integer value: <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 4711 </integer> <integer> 1 </integer> </integer-prop> <interval-prop> The <interval-prop> element is used for intervals with a start and an end point on a timeline, e.g. relative to the beginning of an audio or video file. An <interval-prop> must contain at least one <interval> element. Attributes: name : name of the property as defined in the ontology (required) <interval> A time interval is represented by plain decimal numbers (=seconds), without a special notation for minutes and hours. The <interval> element contains two decimals separated by a colon ( : ). The places before the decimal point are seconds, and the places after the decimal points are fractions of a second. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden interval value: <interval-prop name= \":hasInterval\" > <interval permissions= \"prop-default\" > 60.5:120.5 </interval> <!-- 0:01:00.5 - 0:02:00.5 --> <interval> 61:3600 </interval> <!-- 0:01:01 - 1:00:00 --> </interval-prop> <list-prop> The <list-prop> element is used as entry point into a list (list node). List nodes are identified by their name attribute that was given when creating the list nodes (which must be unique within each list!). It must contain at least one <list> element. Attributes: name : name of the property as defined in the ontology (required) list : name of the list as defined in the ontology (required) <list> The <list> element references a node in a (pull-down or hierarchical) list. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden list value: <list-prop list= \"category\" name= \":hasCategory\" > <list permissions= \"prop-default\" > physics </list> <list> nature </list> </list-prop> <resptr-prop> The <resptr-prop> element is used to link other resources within DSP. It must contain at least one <resptr> element. Attributes: name : name of the property as defined in the ontology (required) <resptr> The <resptr> element contains either the internal ID of another resource inside the XML or the IRI of an already existing resource on DSP. Inside the same XML file, a mixture of the two is not possible. If referencing existing resources, xmlupload --incremental has to be used. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public link to <resource id=\"res_1\" ...> and a hidden link to and <resource id=\"res_2\" ...> : <resptr-prop name= \":hasReferenceTo\" > <resptr permissions= \"prop-default\" > res_1 </resptr> <resptr> res_2 </resptr> </resptr-prop> <text-prop> The <text-prop> element is used for text values. It must contain at least one <text> element. Attributes: name : name of the property as defined in the ontology (required) <text> The <text> element has the following attributes: encoding (required) utf8 : simple text without markup xml : complex text with markup. It must follow the XML format as defined by the DSP standard mapping . permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) For the possible combinations of encoding with the gui_element defined in the ontology , see the table: gui_element (JSON ontology) encoding (XML data) How DSP-APP renders the whitespaces SimpleText utf8 Pretty-print whitespaces and newlines from the XML are taken into the text field as they are. Textarea utf8 Pretty-print whitespaces and newlines from the XML are taken into the text field as they are. Richtext xml Pretty-print whitespaces and newlines from the XML are removed. If you want a newline in the text field, use <br /> instead. Example of a public and a hidden text: <text-prop name= \":hasDescription\" > <text encoding= \"xml\" permissions= \"prop-default\" > Probe bei \"Wimberger\". Lokal in Wien? </text> <text encoding= \"xml\" > <strong> Bold text </strong> and a <a class= \"salsah-link\" href= \"IRI:obj_0003:IRI\" > link to an ID </a> . <br/> And a <a class= \"salsah-link\" href= \"http://rdfh.ch/4123/nyOODvYySV2nJ5RWRdmOdQ\" > link to an IRI </a> . </text> </text-prop> The second text above contains a link to the resource obj_0003 , which is defined in the same XML file. It also contains a link to the resource http://rdfh.ch/4123/nyOODvYySV2nJ5RWRdmOdQ , which already exists on the DSP server. <time-prop> The <time-prop> element is used for time values in the Gregorian calendar. It must contain at least one <time> element. Attributes: name : name of the property as defined in the ontology (required) <time> The <time> element represents an exact datetime value in the form xsd:dateTimeStamp , which is defined as yyyy-mm-ddThh:mm:ss.sssssssssssszzzzzz . The following abbreviations describe this form: yyyy : a four-digit numeral that represents the year. The value cannot start with a minus (-) or a plus (+) sign. 0001 is the lexical representation of the year 1 of the Common Era (also known as 1 AD). The value cannot be 0000. The calendar is always the Gregorian calendar. mm : a two-digit numeral that represents the month dd : a two-digit numeral that represents the day hh : a two-digit numeral representing the hours. Must be between 0 and 23 mm : a two-digit numeral that represents the minutes ss : a two-digit numeral that represents the seconds ssssssssssss : If present, a 1-to-12-digit numeral that represents the fractional seconds (optional) zzzzzz : represents the time zone (required). Each part of the datetime value that is expressed as a numeric value is constrained to the maximum value within the interval that is determined by the next higher part of the datetime value. For example, the day value can never be 32 and cannot be 29 for month 02 and year 2002 (February 2002). The timezone is defined as follows: A plus (+) or minus (-) sign that is followed by hh:mm: + : Indicates that the specified time instant is in a time zone that is ahead of the UTC time by hh hours and mm minutes. - : Indicates that the specified time instant is in a time zone that is behind UTC time by hh hours and mm minutes. hh : a two-digit numeral (with leading zeros as required) that represents the hours. The value must be between -14 and +14, inclusive. mm : a two-digit numeral that represents the minutes. The value must be zero when hh is equal to 14. Z: The literal Z, which represents the time in UTC (Z represents Zulu time, which is equivalent to UTC). Specifying Z for the time zone is equivalent to specifying +00:00 or -00:00. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden time value: <time-prop name= \":hasTime\" > <time permissions= \"prop-default\" > 2019-10-23T13:45:12Z </time> <time> 2009-10-10T12:00:00-05:00 </time> </time-prop> <uri-prop> The <uri-prop> represents a Uniform Resource Identifier . It must contain at least one <uri> element. Attributes: name : name of the property as defined in the ontology (required) <uri> The <uri> element contains a syntactically valid URI. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden URI: <uri-prop name= \":hasURI\" > <uri permissions= \"prop-default\" > http://www.groove-t-gang.ch </uri> <uri> http://dasch.swiss </uri> </uri-prop> DSP base resources and base properties to be used directly in the XML file There is a number of base resources and base properties that must not be subclassed in a project ontology. They are directly available in the XML data file. Please have in mind that built-in names of the knora-base ontology must be used without prepended colon. See also the related part of the JSON project documentation <annotation> <annotation> is an annotation to another resource of any class. It must have the following predefined properties: hasComment (1-n) isAnnotationOf (1) Example: <annotation label= \"Annotation to another resource\" id= \"annotation_0\" permissions= \"res-default\" > <text-prop name= \"hasComment\" > <text encoding= \"utf8\" permissions= \"prop-default\" > This is an annotation to a resource. </text> </text-prop> <resptr-prop name= \"isAnnotationOf\" > <resptr permissions= \"prop-default\" > img_1 </resptr> </resptr-prop> </annotation> Technical note: An <annotation> is in fact a <resource restype=\"Annotation\"> . But it is mandatory to use the shortcut, so that the XML file can be validated more precisely. <region> A <region> resource defines a region of interest (ROI) in an image. It must have the following predefined properties: hasColor (1) isRegionOf (1) hasGeometry (1) hasComment (1-n) Example: <region label= \"Rectangle in image\" id= \"region_0\" permissions= \"res-default\" > <color-prop name= \"hasColor\" > <color permissions= \"prop-default\" > #5d1f1e </color> </color-prop> <resptr-prop name= \"isRegionOf\" > <resptr permissions= \"prop-default\" > img_1 </resptr> </resptr-prop> <geometry-prop name= \"hasGeometry\" > <geometry permissions= \"prop-default\" > { \"status\": \"active\", \"type\": \"rectangle\", \"lineColor\": \"#ff1100\", \"lineWidth\": 5, \"points\": [ {\"x\":0.1,\"y\":0.7}, {\"x\":0.3,\"y\":0.2} ] } </geometry> </geometry-prop> <text-prop name= \"hasComment\" > <text encoding= \"utf8\" permissions= \"prop-default\" > This is a rectangle-formed region of interest. </text> </text-prop> </region> More details about the <geometry-prop> are documented here . Technical note: A <region> is in fact a <resource restype=\"Region\"> . But it is mandatory to use the shortcut, so that the XML file can be validated more precisely. <link> <link> is a resource linking together several other resources of different classes. It must have the following predefined properties: hasComment (1-n) hasLinkTo (1-n) Example: <link label= \"Link between three resources\" id= \"link_obj_0\" permissions= \"res-default\" > <text-prop name= \"hasComment\" > <text permissions= \"prop-default\" encoding= \"utf8\" > A link object can link together an arbitrary number of resources from any resource class. </text> </text-prop> <resptr-prop name= \"hasLinkTo\" > <resptr permissions= \"prop-default\" > doc_001 </resptr> <resptr permissions= \"prop-default\" > img_obj_5 </resptr> <resptr permissions= \"prop-default\" > audio_obj_0 </resptr> </resptr-prop> </link> Technical note: A <link> is in fact a <resource restype=\"LinkObj\"> . But it is mandatory to use the shortcut, so that the XML file can be validated more precisely. Complete example DaSCH provides you with two example repositories that contain everything which is necessary to create a project and upload data. Both of them also contain an XML data file. You can find them here: https://github.com/dasch-swiss/0123-import-scripts https://github.com/dasch-swiss/082E-rosetta-scripts In addition, there is another complete example of an XML data file here: <?xml version='1.0' encoding='utf-8'?> <knora xmlns= \"https://dasch.swiss/schema\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/data.xsd\" shortcode= \"0001\" default-ontology= \"anything\" > <!-- permissions: see https://docs.dasch.swiss/latest/DSP-API/02-knora-ontologies/knora-base/#permissions --> <permissions id= \"res-default\" > <allow group= \"UnknownUser\" > V </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"Creator\" > CR </allow> <allow group= \"ProjectAdmin\" > CR </allow> <allow group= \"anything:Thing searcher\" > D </allow> </permissions> <permissions id= \"res-restricted\" > <allow group= \"UnknownUser\" > RV </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"Creator\" > CR </allow> <allow group= \"ProjectAdmin\" > CR </allow> <allow group= \"anything:Thing searcher\" > M </allow> </permissions> <permissions id= \"prop-default\" > <allow group= \"UnknownUser\" > V </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"Creator\" > CR </allow> <allow group= \"ProjectAdmin\" > CR </allow> <allow group= \"anything:Thing searcher\" > D </allow> </permissions> <permissions id= \"prop-restricted\" > <allow group= \"UnknownUser\" > RV </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"Creator\" > CR </allow> <allow group= \"ProjectAdmin\" > CR </allow> <allow group= \"anything:Thing searcher\" > M </allow> </permissions> <resource label= \"obj_inst1\" restype= \":BlueThing\" id= \"obj_0001\" permissions= \"res-default\" > <list-prop list= \"treelistroot\" name= \":hasListItem\" > <list permissions= \"prop-default\" > Tree list node 02 </list> </list-prop> <list-prop list= \"treelistroot\" name= \":hasOtherListItem\" > <list permissions= \"prop-default\" > Tree list node 03 </list> </list-prop> <text-prop name= \":hasRichtext\" > <text permissions= \"prop-default\" encoding= \"xml\" > The <strong> third </strong> object and a <a class= \"salsah-link\" href= \"IRI:obj_0003:IRI\" > link </a> to. </text> </text-prop> <text-prop name= \":hasRichtext\" > <text permissions= \"prop-default\" encoding= \"xml\" > The <strong> third </strong> object and a <a class= \"salsah-link\" href= \"IRI:obj_0003:IRI\" > link </a> to. </text> </text-prop> <text-prop name= \":hasText\" > <text permissions= \"prop-default\" encoding= \"utf8\" > Dies ist ein einfacher Text ohne Markup </text> <text permissions= \"prop-restricted\" encoding= \"utf8\" > Nochmals ein einfacher Text </text> </text-prop> <date-prop name= \":hasDate\" > <date permissions= \"prop-default\" > JULIAN:CE:1401-05-17:CE:1402-01 </date> </date-prop> <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 4711 </integer> </integer-prop> <decimal-prop name= \":hasDecimal\" > <decimal permissions= \"prop-default\" comment= \"Eulersche Zahl\" > 2.718281828459 </decimal> </decimal-prop> <boolean-prop name= \":hasBoolean\" > <boolean permissions= \"prop-default\" > true </boolean> </boolean-prop> <uri-prop name= \":hasUri\" > <uri permissions= \"prop-default\" > http://dasch.swiss/gaga </uri> </uri-prop> <interval-prop name= \":hasInterval\" > <interval permissions= \"prop-default\" > 12.5:14.2 </interval> </interval-prop> <color-prop name= \":hasColor\" > <color permissions= \"prop-default\" > #00ff00 </color> </color-prop> <geoname-prop name= \":hasGeoname\" > <geoname permissions= \"prop-default\" comment= \"A sacred place for railroad fans\" > 5416656 </geoname> </geoname-prop> <resptr-prop name= \":hasBlueThing\" > <resptr permissions= \"prop-default\" > obj_0002 </resptr> </resptr-prop> </resource> <resource label= \"obj_inst2\" restype= \":BlueThing\" id= \"obj_0002\" permissions= \"res-default\" > <list-prop list= \"treelistroot\" name= \":hasListItem\" > <list permissions= \"prop-default\" > Tree list node 10 </list> </list-prop> <list-prop list= \"treelistroot\" name= \":hasOtherListItem\" > <list permissions= \"prop-default\" > Tree list node 11 </list> </list-prop> <text-prop name= \":hasRichtext\" > <text permissions= \"prop-default\" encoding= \"xml\" > What is this <em> bold </em> thing? </text> </text-prop> <text-prop name= \":hasText\" > <text permissions= \"prop-default\" encoding= \"utf8\" > aa bbb cccc ddddd </text> </text-prop> <date-prop name= \":hasDate\" > <date permissions= \"prop-default\" > 1888 </date> </date-prop> <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 42 </integer> </integer-prop> <decimal-prop name= \":hasDecimal\" > <decimal permissions= \"prop-default\" comment= \"Die Zahl PI\" > 3.14159 </decimal> </decimal-prop> <boolean-prop name= \":hasBoolean\" > <boolean permissions= \"prop-default\" > false </boolean> </boolean-prop> <uri-prop name= \":hasUri\" > <uri permissions= \"prop-default\" > http://unibas.ch/gugus </uri> </uri-prop> <interval-prop name= \":hasInterval\" > <interval permissions= \"prop-default\" > 24:100.075 </interval> </interval-prop> <color-prop name= \":hasColor\" > <color permissions= \"prop-default\" > #33ff77 </color> </color-prop> <geoname-prop name= \":hasGeoname\" > <geoname permissions= \"prop-default\" comment= \"A sacred place for railroad fans\" > 5416656 </geoname> </geoname-prop> <resptr-prop name= \":hasBlueThing\" > <resptr permissions= \"prop-default\" > obj_0003 </resptr> </resptr-prop> </resource> <resource label= \"obj_inst3\" restype= \":BlueThing\" id= \"obj_0003\" permissions= \"res-default\" > <list-prop list= \"treelistroot\" name= \":hasListItem\" > <list permissions= \"prop-default\" > Tree list node 01 </list> </list-prop> <list-prop list= \"treelistroot\" name= \":hasOtherListItem\" > <list permissions= \"prop-default\" > Tree list node 02 </list> </list-prop> <text-prop name= \":hasRichtext\" > <text permissions= \"prop-default\" encoding= \"xml\" > This is <em> bold and <strong> strong </strong></em> text! </text> </text-prop> <text-prop name= \":hasText\" > <text permissions= \"prop-default\" encoding= \"utf8\" > aa bbb cccc ddddd </text> </text-prop> <date-prop name= \":hasDate\" > <date permissions= \"prop-default\" > 1888 </date> </date-prop> <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 42 </integer> </integer-prop> <decimal-prop name= \":hasDecimal\" > <decimal permissions= \"prop-default\" comment= \"Die Zahl PI\" > 3.14159 </decimal> </decimal-prop> <boolean-prop name= \":hasBoolean\" > <boolean permissions= \"prop-default\" > false </boolean> </boolean-prop> <uri-prop name= \":hasUri\" > <uri permissions= \"prop-default\" > http://unibas.ch/gugus </uri> </uri-prop> <interval-prop name= \":hasInterval\" > <interval permissions= \"prop-default\" > 24:100.075 </interval> </interval-prop> <color-prop name= \":hasColor\" > <color permissions= \"prop-default\" > #33ff77 </color> </color-prop> <geoname-prop name= \":hasGeoname\" > <geoname permissions= \"prop-default\" comment= \"A sacred place for railroad fans\" > 5416656 </geoname> </geoname-prop> </resource> <resource label= \"obj_inst4\" restype= \":ThingPicture\" id= \"obj_0004\" permissions= \"res-default\" > <bitstream> gaga.tif </bitstream> <text-prop name= \":hasPictureTitle\" > <text permissions= \"prop-default\" encoding= \"utf8\" > This is the famous Lena </text> </text-prop> </resource> </knora>","title":"XML data file"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#the-xml-file-format-for-importing-data","text":"With the xmlupload command, data can be imported into a DSP repository (on a DSP server) from an XML file. The import file is a standard XML file as described on this page. After a successful upload of the data, an output file is written (called id2iri_mapping_[timestamp].json ) with the mapping from the internal IDs used inside the XML to their corresponding IRIs which uniquely identify them inside DSP. This file should be kept if data is later added with the --incremental option . The import file must start with the standard XML header: <?xml version='1.0' encoding='utf-8'?>","title":"The XML file format for importing data"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#the-root-element-knora","text":"The <knora> element describes all resources that should be imported. It has the following attributes: xmlns : \"https://dasch.swiss/schema\" (required) xmlns:xsi : \"http://www.w3.org/2001/XMLSchema-instance\" (required) xsi:schemaLocation : \"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/data.xsd\" ( required) shortcode : project shortcode, e.g. \"0801\" (required) default-ontology : name of the ontology (required) The <knora> element may look as follows: <knora xmlns= \"https://dasch.swiss/schema\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/data.xsd\" shortcode= \"0806\" default-ontology= \"webern\" > ... </knora> The <knora> element can only contain the following sub-elements: <permissions> (optional) <resource>","title":"The root element &lt;knora&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#the-dsp-permissions","text":"The DSP server provides access control for every resource and every property.","title":"The DSP permissions"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#groups","text":"The user doesn't hold the permissions directly, but belongs to an arbitrary number of groups which hold the permissions. There are built-in groups and project specific groups : Built-in groups : Every user is automatically in at least one of the following built-in groups: UnknownUser : The user is not known to DSP (not logged in). KnownUser : The user is logged in, but not a member of the project the data element belongs to. ProjectMember : The user belongs to the same project as the data element. ProjectAdmin : The user is project administrator in the project the data element belongs to. Creator : The user is the owner of the element (created the element). SystemAdmin : The user is a system administrator. Project specific groups : can be defined in the JSON project file","title":"Groups"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#rights","text":"A group can have exactly one of these rights: (no right): If no permission is defined for a certain group of users, these users cannot view any resources/values. RV restricted view permission : Same as V , but if it is applied to an image, the image is shown with a reduced resolution or with a watermark overlay. V view permission : The user can view a resource or a value, but cannot modify it. M modify permission : The user can modify the element, but cannot mark it as deleted. The original resource or value will be preserved. D delete permission : The user is allowed to mark an element as deleted. The original resource or value will be preserved. CR change right permission : The user can change the permission of a resource or value. The user is also allowed to permanently delete (erase) a resource. Every right of this row includes all previous rights.","title":"Rights"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#defining-permissions-with-the-permissions-element","text":"The <permissions> element defines a permission ID that can subsequently be used in a permissions attribute of a <resource> or <xyz-prop> tag. It is optional to define permissions in the XML. If not defined, default permissions are applied, so that only project and system administrators can view and edit resources. All other users have no rights at all, not even view or restricted view permissions. The <permissions> element defines which rights are given to which groups: <permissions id= \"res-default\" > <allow group= \"UnknownUser\" > RV </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"dsp-test:MlsEditors\" > D </allow> </permissions> In addition to the DSP built-in groups, project specific groups are supported as well. A project specific group name has the form project-shortname:groupname . If you don't want a group to have access at all, leave it out. In the following example, resources or properties with permission special-permission can only be viewed by ProjectAdmin s: <permissions id= \"special-permission\" > <allow group= \"ProjectAdmin\" > CR </allow> </permissions>","title":"Defining permissions with the &lt;permissions&gt; element"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#using-permissions-with-the-permissions-attribute","text":"Once defined, the permission IDs can be used as permissions attribute in the <resource> and <xyz-prop> tags. It is important to note that a resource doesn't inherit its permissions to its properties. Each property must have its own permissions. So, in the following example, the bitstreams don't inherit the permissions from their resource: <resource ...> <bitstream permissions=\"prop-default\">images/EURUS015a.jpg</bitstream> </resource> <resource ...> <bitstream permissions=\"prop-restricted\">images/EURUS015a.jpg</bitstream> </resource> <resource ...> <bitstream>images/EURUS015a.jpg</bitstream> </resource> To take as example KnownUser , i.e. a logged-in user who is not member of the project: With permissions=\"prop-default\" , he has V rights on the image: Normal view. With permissions=\"prop-restricted\" , he has RV rights on the image: Blurred image. With a blank <bitstream> tag, he has no rights on the image: No view possible. Only users from ProjectAdmin upwards are able to look at the image.","title":"Using permissions with the permissions attribute"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#describing-resources-with-the-resource-element","text":"A <resource> element contains all necessary information to create a resource. It has the following attributes: label (required): a human-readable, preferably meaningful short name of the resource restype (required): the resource type as defined within the ontology id (required): a unique, arbitrary string providing a unique ID to the resource in order to be referencable by other resources; the ID is only used during the import process and later replaced by the IRI used internally by DSP permissions (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights): a reference to a permission ID iri (optional): a custom IRI, used when migrating existing resources (DaSCH-internal only) ark (optional): a version 0 ARK, used when migrating existing resources. It is not possible to use iri and ark in the same resource. When ark is used, it overrides iri (DaSCH-internal only). creation_date (optional): the creation date of the resource, used when migrating existing resources . It must be formatted according to the constraints of xsd:dateTimeStamp , which means that the timezone is required, e.g.: 2005-10-23T13:45:12.502951+02:00 (DaSCH-internal only) A complete <resource> element may look as follows: <resource label= \"EURUS015a\" restype= \":Postcard\" id= \"238807\" permissions= \"res-def-perm\" > ... </resource> For every property that the ontology requires, the <resource> element contains one property element (e.g. <integer-prop name=\"property_name> ). The property element contains one or more values. Example of a property element of type integer with two values: <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 4711 </integer> <integer permissions= \"prop-default\" > 1 </integer> </integer-prop> The following property elements exist: <bitstream> : contains a path to a file (if the resource is a multimedia resource) <boolean-prop> : contains a boolean value <color-prop> : contains color values <date-prop> : contains date values <decimal-prop> : contains decimal values <geometry-prop> : contains JSON geometry definitions for a region <geoname-prop> : contains geonames.org location codes <list-prop> : contains list element labels <integer-prop> : contains integer values <interval-prop> : contains interval values <period-prop> : contains time period values (not yet implemented) <resptr-prop> : contains links to other resources <text-prop> : contains text values <time-prop> : contains time values <uri-prop> : contains URI values","title":"Describing resources with the &lt;resource&gt; element"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#bitstream","text":"The <bitstream> element is used for bitstream data. It contains the path to a bitstream object like an image file, a ZIP container, an audio file etc. It must only be used if the resource is a StillImageRepresentation , an AudioRepresentation , a DocumentRepresentation etc. Notes: There is only one <bitstream> element allowed per representation. The <bitstream> element must be the first element. By default, the path is relative to the working directory where dsp-tools xmlupload is executed in. This behaviour can be modified with the flag --imgdir . If you keep the default, it is recommended to choose the project folder as working directory, my_project in the example below: my_project \u251c\u2500\u2500 files \u2502 \u251c\u2500\u2500 data_model.json \u2502 \u2514\u2500\u2500 data_file.xml (<bitstream>images/dog.jpg</bitstream>) \u2514\u2500\u2500 images \u251c\u2500\u2500 dog.jpg \u2514\u2500\u2500 cat.jpg my_project % dsp-tools xmlupload files/data_file.xml Supported file extensions: Representation Supported formats ArchiveRepresentation ZIP, TAR, GZ, Z, TAR.GZ, TGZ, GZIP, 7Z AudioRepresentation MP3, WAV DocumentRepresentation PDF, DOC, DOCX, XLS, XLSX, PPT, PPTX MovingImageRepresentation MP4 StillImageRepresentation JPG, JPEG, PNG, TIF, TIFF, JP2 TextRepresentation TXT, CSV, XML, XSL, XSD For more details, please consult the API docs . Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) Example of a public image inside a StillImageRepresentation : <resource restype= \":Image\" id= \"image_1\" label= \"image_1\" permissions= \"res-default\" > <bitstream permissions= \"prop-default\" > postcards/images/EURUS015a.jpg </bitstream> </resource>","title":"&lt;bitstream&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#boolean-prop","text":"The <boolean-prop> element is used for boolean values. It must contain exactly one <boolean> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;boolean-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#boolean","text":"The <boolean> element must contain the string \"true\" or \"false\", or the numeral 1 (true) or 0 (false). Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a public and a hidden boolean property: <boolean-prop name=\":hasBoolean\"> <boolean permissions=\"prop-default\">true</boolean> </boolean-prop> <boolean-prop name=\":hasHiddenBoolean\"> <boolean>0</boolean> </boolean-prop>","title":"&lt;boolean&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#color-prop","text":"The <color-prop> element is used for color values. It must contain at least one <color> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;color-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#color","text":"The <color> element is used to indicate a color value. The color has to be given in web-notation, that is a # followed by 3 or 6 hex numerals. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden color value: <color-prop name= \":hasColor\" > <color permissions= \"prop-default\" > #00ff66 </color> <color> #ff00ff </color> </color-prop>","title":"&lt;color&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#date-prop","text":"The <date-prop> element is used for date values. It must contain at least one <date> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;date-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#date","text":"the <date> element contains a DSP-specific date value. It has the following format: calendar:epoch:yyyy-mm-dd:epoch:yyyy-mm-dd calendar : either \"JULIAN\" or \"GREGORIAN\" (optional, default: GREGORIAN) epoch : either \"BCE\" or \"CE\" (optional, default CE) yyyy : year with four digits (required) mm : month with two digits (optional, e.g. 01, 02, ..., 12) dd : day with two digits (optional, e.g. 01, 02, ..., 31) Notes: If the day is omitted, then the precision is month, if also the month is omitted, the precision is year. Internally, a date is always represented as a start and end date. If start and end date match, it's an exact date. If start and end date don't match, it's a range. If the end date is omitted, it's a range from the earliest possible beginning of the start date to the latest possible end of the start date. For example: \"1893\" will be expanded to a range from January 1st 1893 to December 31st 1893. \"1893-01\" will be expanded to a range from January 1st 1893 to January 31st 1893. \"1893-01-01\" will be expanded to the exact date January 1st 1893 to January 1st 1893 (technically also a range). Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden date value: <date-prop name= \":hasDate\" > <date permissions= \"prop-default\" > GREGORIAN:CE:2014-01-31 </date> <date> GREGORIAN:CE:1930-09-02:CE:1930-09-03 </date> </date-prop>","title":"&lt;date&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#decimal-prop","text":"The <decimal-prop> element is used for decimal values. It must contain at least one <decimal> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;decimal-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#decimal","text":"The <decimal> element contains a decimal number. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden decimal value: <decimal-prop name= \":hasDecimal\" > <decimal permissions= \"prop-default\" > 3.14159 </decimal> <decimal> 2.71828 </decimal> </decimal-prop>","title":"&lt;decimal&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#geometry-prop","text":"The <geometry-prop> element is used for a geometric definition of a 2-D region (e.g. a region on an image). It must contain at least one <geometry> element. A <geometry-prop> can only be used inside a <region> tag . Attributes: name : the only allowed name is hasGeometry , because this property is a DSP base property that can only be used in the <region> tag .","title":"&lt;geometry-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#geometry","text":"A geometry value is defined as a JSON object. It contains the following data: status : \"active\" or \"deleted\" type : \"circle\", \"rectangle\" or \"polygon\" (only the rectangle can be displayed in DSP-APP. The others can be looked at in another frontend, e.g. in TANGOH.) lineColor : web-color lineWidth : integer number (in pixels) points : array of coordinate objects of the form {\"x\": decimal, \"y\": decimal} radius : coordinate object of the form {\"x\": decimal, \"y\": decimal} In the SALSAH data, there is also a key named original_index in the JSON format of all three shapes, but it doesn't seem to have an influence on the shapes that TANGOH displays, so it can be omitted. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example: <geometry-prop name=\"hasGeometry\"> <geometry permissions=\"prop-default\"> { \"status\": \"active\", \"type\": \"rectangle\", \"lineColor\": \"#ff1100\", \"lineWidth\": 5, \"points\": [ {\"x\":0.1,\"y\":0.7}, {\"x\":0.3,\"y\":0.2} ] } </geometry> <geometry permissions=\"prop-default\"> { \"status\": \"active\", \"type\": \"circle\", \"lineColor\": \"#ff1100\", \"lineWidth\": 5, \"points\": [{\"x\":0.5,\"y\":0.3}], \"radius\": {\"x\":0.1,\"y\":0.1} // vector (0.1, 0.1) } </geometry> <geometry permissions=\"prop-default\"> { \"status\": \"active\", \"type\": \"polygon\", \"lineColor\": \"#ff1100\", \"lineWidth\": 5, \"points\": [{\"x\": 0.4, \"y\": 0.6}, {\"x\": 0.5, \"y\": 0.9}, {\"x\": 0.8, \"y\": 0.9}, {\"x\": 0.7, \"y\": 0.6}] } </geometry> </geometry-prop> The underlying grid is a 0-1 normalized top left-anchored grid. The following coordinate system shows the three shapes that were defined above:","title":"&lt;geometry&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#geoname-prop","text":"The <geoname-prop> element is used for values that contain a geonames.org ID. It must contain at least one <geoname> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;geoname-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#geoname","text":"Contains a valid geonames.org ID. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public link to Vienna and a hidden link to Basel: <geoname-prop name= \":hasLocation\" > <geoname permissions= \"prop-default\" > 2761369 </geoname> <geoname> 2661604 </geoname> </geoname-prop>","title":"&lt;geoname&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#integer-prop","text":"The <integer-prop> element is used for integer values. It must contain at least one <integer> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;integer-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#integer","text":"The <integer> element contains an integer value. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden integer value: <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 4711 </integer> <integer> 1 </integer> </integer-prop>","title":"&lt;integer&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#interval-prop","text":"The <interval-prop> element is used for intervals with a start and an end point on a timeline, e.g. relative to the beginning of an audio or video file. An <interval-prop> must contain at least one <interval> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;interval-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#interval","text":"A time interval is represented by plain decimal numbers (=seconds), without a special notation for minutes and hours. The <interval> element contains two decimals separated by a colon ( : ). The places before the decimal point are seconds, and the places after the decimal points are fractions of a second. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden interval value: <interval-prop name= \":hasInterval\" > <interval permissions= \"prop-default\" > 60.5:120.5 </interval> <!-- 0:01:00.5 - 0:02:00.5 --> <interval> 61:3600 </interval> <!-- 0:01:01 - 1:00:00 --> </interval-prop>","title":"&lt;interval&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#list-prop","text":"The <list-prop> element is used as entry point into a list (list node). List nodes are identified by their name attribute that was given when creating the list nodes (which must be unique within each list!). It must contain at least one <list> element. Attributes: name : name of the property as defined in the ontology (required) list : name of the list as defined in the ontology (required)","title":"&lt;list-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#list","text":"The <list> element references a node in a (pull-down or hierarchical) list. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden list value: <list-prop list= \"category\" name= \":hasCategory\" > <list permissions= \"prop-default\" > physics </list> <list> nature </list> </list-prop>","title":"&lt;list&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#resptr-prop","text":"The <resptr-prop> element is used to link other resources within DSP. It must contain at least one <resptr> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;resptr-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#resptr","text":"The <resptr> element contains either the internal ID of another resource inside the XML or the IRI of an already existing resource on DSP. Inside the same XML file, a mixture of the two is not possible. If referencing existing resources, xmlupload --incremental has to be used. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public link to <resource id=\"res_1\" ...> and a hidden link to and <resource id=\"res_2\" ...> : <resptr-prop name= \":hasReferenceTo\" > <resptr permissions= \"prop-default\" > res_1 </resptr> <resptr> res_2 </resptr> </resptr-prop>","title":"&lt;resptr&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#text-prop","text":"The <text-prop> element is used for text values. It must contain at least one <text> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;text-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#text","text":"The <text> element has the following attributes: encoding (required) utf8 : simple text without markup xml : complex text with markup. It must follow the XML format as defined by the DSP standard mapping . permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) For the possible combinations of encoding with the gui_element defined in the ontology , see the table: gui_element (JSON ontology) encoding (XML data) How DSP-APP renders the whitespaces SimpleText utf8 Pretty-print whitespaces and newlines from the XML are taken into the text field as they are. Textarea utf8 Pretty-print whitespaces and newlines from the XML are taken into the text field as they are. Richtext xml Pretty-print whitespaces and newlines from the XML are removed. If you want a newline in the text field, use <br /> instead. Example of a public and a hidden text: <text-prop name= \":hasDescription\" > <text encoding= \"xml\" permissions= \"prop-default\" > Probe bei \"Wimberger\". Lokal in Wien? </text> <text encoding= \"xml\" > <strong> Bold text </strong> and a <a class= \"salsah-link\" href= \"IRI:obj_0003:IRI\" > link to an ID </a> . <br/> And a <a class= \"salsah-link\" href= \"http://rdfh.ch/4123/nyOODvYySV2nJ5RWRdmOdQ\" > link to an IRI </a> . </text> </text-prop> The second text above contains a link to the resource obj_0003 , which is defined in the same XML file. It also contains a link to the resource http://rdfh.ch/4123/nyOODvYySV2nJ5RWRdmOdQ , which already exists on the DSP server.","title":"&lt;text&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#time-prop","text":"The <time-prop> element is used for time values in the Gregorian calendar. It must contain at least one <time> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;time-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#time","text":"The <time> element represents an exact datetime value in the form xsd:dateTimeStamp , which is defined as yyyy-mm-ddThh:mm:ss.sssssssssssszzzzzz . The following abbreviations describe this form: yyyy : a four-digit numeral that represents the year. The value cannot start with a minus (-) or a plus (+) sign. 0001 is the lexical representation of the year 1 of the Common Era (also known as 1 AD). The value cannot be 0000. The calendar is always the Gregorian calendar. mm : a two-digit numeral that represents the month dd : a two-digit numeral that represents the day hh : a two-digit numeral representing the hours. Must be between 0 and 23 mm : a two-digit numeral that represents the minutes ss : a two-digit numeral that represents the seconds ssssssssssss : If present, a 1-to-12-digit numeral that represents the fractional seconds (optional) zzzzzz : represents the time zone (required). Each part of the datetime value that is expressed as a numeric value is constrained to the maximum value within the interval that is determined by the next higher part of the datetime value. For example, the day value can never be 32 and cannot be 29 for month 02 and year 2002 (February 2002). The timezone is defined as follows: A plus (+) or minus (-) sign that is followed by hh:mm: + : Indicates that the specified time instant is in a time zone that is ahead of the UTC time by hh hours and mm minutes. - : Indicates that the specified time instant is in a time zone that is behind UTC time by hh hours and mm minutes. hh : a two-digit numeral (with leading zeros as required) that represents the hours. The value must be between -14 and +14, inclusive. mm : a two-digit numeral that represents the minutes. The value must be zero when hh is equal to 14. Z: The literal Z, which represents the time in UTC (Z represents Zulu time, which is equivalent to UTC). Specifying Z for the time zone is equivalent to specifying +00:00 or -00:00. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden time value: <time-prop name= \":hasTime\" > <time permissions= \"prop-default\" > 2019-10-23T13:45:12Z </time> <time> 2009-10-10T12:00:00-05:00 </time> </time-prop>","title":"&lt;time&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#uri-prop","text":"The <uri-prop> represents a Uniform Resource Identifier . It must contain at least one <uri> element. Attributes: name : name of the property as defined in the ontology (required)","title":"&lt;uri-prop&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#uri","text":"The <uri> element contains a syntactically valid URI. Attributes: permissions : Permission ID (optional, but if omitted, users who are lower than a ProjectAdmin have no permissions at all, not even view rights) comment : a comment for this specific value (optional) Example of a property with a public and a hidden URI: <uri-prop name= \":hasURI\" > <uri permissions= \"prop-default\" > http://www.groove-t-gang.ch </uri> <uri> http://dasch.swiss </uri> </uri-prop>","title":"&lt;uri&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#dsp-base-resources-and-base-properties-to-be-used-directly-in-the-xml-file","text":"There is a number of base resources and base properties that must not be subclassed in a project ontology. They are directly available in the XML data file. Please have in mind that built-in names of the knora-base ontology must be used without prepended colon. See also the related part of the JSON project documentation","title":"DSP base resources and base properties to be used directly in the XML file"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#annotation","text":"<annotation> is an annotation to another resource of any class. It must have the following predefined properties: hasComment (1-n) isAnnotationOf (1) Example: <annotation label= \"Annotation to another resource\" id= \"annotation_0\" permissions= \"res-default\" > <text-prop name= \"hasComment\" > <text encoding= \"utf8\" permissions= \"prop-default\" > This is an annotation to a resource. </text> </text-prop> <resptr-prop name= \"isAnnotationOf\" > <resptr permissions= \"prop-default\" > img_1 </resptr> </resptr-prop> </annotation> Technical note: An <annotation> is in fact a <resource restype=\"Annotation\"> . But it is mandatory to use the shortcut, so that the XML file can be validated more precisely.","title":"&lt;annotation&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#region","text":"A <region> resource defines a region of interest (ROI) in an image. It must have the following predefined properties: hasColor (1) isRegionOf (1) hasGeometry (1) hasComment (1-n) Example: <region label= \"Rectangle in image\" id= \"region_0\" permissions= \"res-default\" > <color-prop name= \"hasColor\" > <color permissions= \"prop-default\" > #5d1f1e </color> </color-prop> <resptr-prop name= \"isRegionOf\" > <resptr permissions= \"prop-default\" > img_1 </resptr> </resptr-prop> <geometry-prop name= \"hasGeometry\" > <geometry permissions= \"prop-default\" > { \"status\": \"active\", \"type\": \"rectangle\", \"lineColor\": \"#ff1100\", \"lineWidth\": 5, \"points\": [ {\"x\":0.1,\"y\":0.7}, {\"x\":0.3,\"y\":0.2} ] } </geometry> </geometry-prop> <text-prop name= \"hasComment\" > <text encoding= \"utf8\" permissions= \"prop-default\" > This is a rectangle-formed region of interest. </text> </text-prop> </region> More details about the <geometry-prop> are documented here . Technical note: A <region> is in fact a <resource restype=\"Region\"> . But it is mandatory to use the shortcut, so that the XML file can be validated more precisely.","title":"&lt;region&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#link","text":"<link> is a resource linking together several other resources of different classes. It must have the following predefined properties: hasComment (1-n) hasLinkTo (1-n) Example: <link label= \"Link between three resources\" id= \"link_obj_0\" permissions= \"res-default\" > <text-prop name= \"hasComment\" > <text permissions= \"prop-default\" encoding= \"utf8\" > A link object can link together an arbitrary number of resources from any resource class. </text> </text-prop> <resptr-prop name= \"hasLinkTo\" > <resptr permissions= \"prop-default\" > doc_001 </resptr> <resptr permissions= \"prop-default\" > img_obj_5 </resptr> <resptr permissions= \"prop-default\" > audio_obj_0 </resptr> </resptr-prop> </link> Technical note: A <link> is in fact a <resource restype=\"LinkObj\"> . But it is mandatory to use the shortcut, so that the XML file can be validated more precisely.","title":"&lt;link&gt;"},{"location":"DSP-TOOLS/file-formats/xml-data-file/#complete-example","text":"DaSCH provides you with two example repositories that contain everything which is necessary to create a project and upload data. Both of them also contain an XML data file. You can find them here: https://github.com/dasch-swiss/0123-import-scripts https://github.com/dasch-swiss/082E-rosetta-scripts In addition, there is another complete example of an XML data file here: <?xml version='1.0' encoding='utf-8'?> <knora xmlns= \"https://dasch.swiss/schema\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"https://dasch.swiss/schema https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/data.xsd\" shortcode= \"0001\" default-ontology= \"anything\" > <!-- permissions: see https://docs.dasch.swiss/latest/DSP-API/02-knora-ontologies/knora-base/#permissions --> <permissions id= \"res-default\" > <allow group= \"UnknownUser\" > V </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"Creator\" > CR </allow> <allow group= \"ProjectAdmin\" > CR </allow> <allow group= \"anything:Thing searcher\" > D </allow> </permissions> <permissions id= \"res-restricted\" > <allow group= \"UnknownUser\" > RV </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"Creator\" > CR </allow> <allow group= \"ProjectAdmin\" > CR </allow> <allow group= \"anything:Thing searcher\" > M </allow> </permissions> <permissions id= \"prop-default\" > <allow group= \"UnknownUser\" > V </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"Creator\" > CR </allow> <allow group= \"ProjectAdmin\" > CR </allow> <allow group= \"anything:Thing searcher\" > D </allow> </permissions> <permissions id= \"prop-restricted\" > <allow group= \"UnknownUser\" > RV </allow> <allow group= \"KnownUser\" > V </allow> <allow group= \"Creator\" > CR </allow> <allow group= \"ProjectAdmin\" > CR </allow> <allow group= \"anything:Thing searcher\" > M </allow> </permissions> <resource label= \"obj_inst1\" restype= \":BlueThing\" id= \"obj_0001\" permissions= \"res-default\" > <list-prop list= \"treelistroot\" name= \":hasListItem\" > <list permissions= \"prop-default\" > Tree list node 02 </list> </list-prop> <list-prop list= \"treelistroot\" name= \":hasOtherListItem\" > <list permissions= \"prop-default\" > Tree list node 03 </list> </list-prop> <text-prop name= \":hasRichtext\" > <text permissions= \"prop-default\" encoding= \"xml\" > The <strong> third </strong> object and a <a class= \"salsah-link\" href= \"IRI:obj_0003:IRI\" > link </a> to. </text> </text-prop> <text-prop name= \":hasRichtext\" > <text permissions= \"prop-default\" encoding= \"xml\" > The <strong> third </strong> object and a <a class= \"salsah-link\" href= \"IRI:obj_0003:IRI\" > link </a> to. </text> </text-prop> <text-prop name= \":hasText\" > <text permissions= \"prop-default\" encoding= \"utf8\" > Dies ist ein einfacher Text ohne Markup </text> <text permissions= \"prop-restricted\" encoding= \"utf8\" > Nochmals ein einfacher Text </text> </text-prop> <date-prop name= \":hasDate\" > <date permissions= \"prop-default\" > JULIAN:CE:1401-05-17:CE:1402-01 </date> </date-prop> <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 4711 </integer> </integer-prop> <decimal-prop name= \":hasDecimal\" > <decimal permissions= \"prop-default\" comment= \"Eulersche Zahl\" > 2.718281828459 </decimal> </decimal-prop> <boolean-prop name= \":hasBoolean\" > <boolean permissions= \"prop-default\" > true </boolean> </boolean-prop> <uri-prop name= \":hasUri\" > <uri permissions= \"prop-default\" > http://dasch.swiss/gaga </uri> </uri-prop> <interval-prop name= \":hasInterval\" > <interval permissions= \"prop-default\" > 12.5:14.2 </interval> </interval-prop> <color-prop name= \":hasColor\" > <color permissions= \"prop-default\" > #00ff00 </color> </color-prop> <geoname-prop name= \":hasGeoname\" > <geoname permissions= \"prop-default\" comment= \"A sacred place for railroad fans\" > 5416656 </geoname> </geoname-prop> <resptr-prop name= \":hasBlueThing\" > <resptr permissions= \"prop-default\" > obj_0002 </resptr> </resptr-prop> </resource> <resource label= \"obj_inst2\" restype= \":BlueThing\" id= \"obj_0002\" permissions= \"res-default\" > <list-prop list= \"treelistroot\" name= \":hasListItem\" > <list permissions= \"prop-default\" > Tree list node 10 </list> </list-prop> <list-prop list= \"treelistroot\" name= \":hasOtherListItem\" > <list permissions= \"prop-default\" > Tree list node 11 </list> </list-prop> <text-prop name= \":hasRichtext\" > <text permissions= \"prop-default\" encoding= \"xml\" > What is this <em> bold </em> thing? </text> </text-prop> <text-prop name= \":hasText\" > <text permissions= \"prop-default\" encoding= \"utf8\" > aa bbb cccc ddddd </text> </text-prop> <date-prop name= \":hasDate\" > <date permissions= \"prop-default\" > 1888 </date> </date-prop> <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 42 </integer> </integer-prop> <decimal-prop name= \":hasDecimal\" > <decimal permissions= \"prop-default\" comment= \"Die Zahl PI\" > 3.14159 </decimal> </decimal-prop> <boolean-prop name= \":hasBoolean\" > <boolean permissions= \"prop-default\" > false </boolean> </boolean-prop> <uri-prop name= \":hasUri\" > <uri permissions= \"prop-default\" > http://unibas.ch/gugus </uri> </uri-prop> <interval-prop name= \":hasInterval\" > <interval permissions= \"prop-default\" > 24:100.075 </interval> </interval-prop> <color-prop name= \":hasColor\" > <color permissions= \"prop-default\" > #33ff77 </color> </color-prop> <geoname-prop name= \":hasGeoname\" > <geoname permissions= \"prop-default\" comment= \"A sacred place for railroad fans\" > 5416656 </geoname> </geoname-prop> <resptr-prop name= \":hasBlueThing\" > <resptr permissions= \"prop-default\" > obj_0003 </resptr> </resptr-prop> </resource> <resource label= \"obj_inst3\" restype= \":BlueThing\" id= \"obj_0003\" permissions= \"res-default\" > <list-prop list= \"treelistroot\" name= \":hasListItem\" > <list permissions= \"prop-default\" > Tree list node 01 </list> </list-prop> <list-prop list= \"treelistroot\" name= \":hasOtherListItem\" > <list permissions= \"prop-default\" > Tree list node 02 </list> </list-prop> <text-prop name= \":hasRichtext\" > <text permissions= \"prop-default\" encoding= \"xml\" > This is <em> bold and <strong> strong </strong></em> text! </text> </text-prop> <text-prop name= \":hasText\" > <text permissions= \"prop-default\" encoding= \"utf8\" > aa bbb cccc ddddd </text> </text-prop> <date-prop name= \":hasDate\" > <date permissions= \"prop-default\" > 1888 </date> </date-prop> <integer-prop name= \":hasInteger\" > <integer permissions= \"prop-default\" > 42 </integer> </integer-prop> <decimal-prop name= \":hasDecimal\" > <decimal permissions= \"prop-default\" comment= \"Die Zahl PI\" > 3.14159 </decimal> </decimal-prop> <boolean-prop name= \":hasBoolean\" > <boolean permissions= \"prop-default\" > false </boolean> </boolean-prop> <uri-prop name= \":hasUri\" > <uri permissions= \"prop-default\" > http://unibas.ch/gugus </uri> </uri-prop> <interval-prop name= \":hasInterval\" > <interval permissions= \"prop-default\" > 24:100.075 </interval> </interval-prop> <color-prop name= \":hasColor\" > <color permissions= \"prop-default\" > #33ff77 </color> </color-prop> <geoname-prop name= \":hasGeoname\" > <geoname permissions= \"prop-default\" comment= \"A sacred place for railroad fans\" > 5416656 </geoname> </geoname-prop> </resource> <resource label= \"obj_inst4\" restype= \":ThingPicture\" id= \"obj_0004\" permissions= \"res-default\" > <bitstream> gaga.tif </bitstream> <text-prop name= \":hasPictureTitle\" > <text permissions= \"prop-default\" encoding= \"utf8\" > This is the famous Lena </text> </text-prop> </resource> </knora>","title":"Complete example"},{"location":"DSP-TOOLS/file-formats/json-project/caveats/","text":"Caveats when working with a JSON project file Referencing Ontologies For several fields, such as super in both resources and properties or propname in cardinalities it is necessary to reference entities that are defined elsewhere. The following cases are possible: DSP-API internals: They are referenced as such and do not have a leading colon. E.g. Resource , DocumentRepresentation or hasValue An external ontology: The ontology must be defined in the prefixes section. The prefix can then be used for referencing the ontology. E.g. foaf:familyName or sdo:Organization The current ontology: Within an ontology definition, references can be made by prepending a colon without a prefix. E.g. :hasName Optionally, an explicit prefix can be used. In this case the ontology must be added to the prefixes section and the prefix must be identical to the ontology's name . A different ontology defined in the same file: Within one data model file, multiple ontologies can be defined. These will be created in the exact order they appear in the ontologies array. Once an ontology has been created, it can be referenced by the following ontologies by its name, e.g. first-onto:hasName . It is not necessary to add first-onto to the prefixes. DSP base resources and base properties to be used directly in the XML file There is a number of DSP base resources that must not be subclassed in a project ontology. They are directly available in the XML data file: Annotation is an annotation to another resource of any class. It can be used in the XML file with the <annotation> tag . It automatically has the following predefined properties: hasComment (1-n) isAnnotationOf (1) LinkObj is a resource linking together several other resources of different classes. It can be used in the XML file with the <link> tag . It automatically has the following predefined properties: hasComment (1-n) hasLinkTo (1-n) A Region resource defines a region of interest (ROI) in an image. It can be used in the XML file with the <region> tag . It automatically has the following predefined properties: hasColor (1) isRegionOf (1) hasGeometry (1) hasComment (1-n) There are some DSP base properties that are used directly in the above resource classes. Some of them can also be subclassed and used in a resource class. hasLinkTo : a link to another resource can be subclassed ( hasLinkTo Property ) can be used directly in the XML data file in the <link> tag hasColor : Defines a color value. can be subclassed ( ColorValue ) can be used directly in the XML data file in the <region> tag hasComment : Defines a standard comment. can be subclassed ( hasComment Property ) can be used directly in the XML data file in the <region> tag or <link> tag hasGeometry : Defines a geometry value (a JSON describing a polygon, circle or rectangle). must be used directly in the XML data file in the <region> tag isRegionOf : A special variant of hasLinkTo . It means that the given resource class is a region of interest in an image. must be used directly in the XML data file in the <region> tag isAnnotationOf : A special variant of hasLinkTo . It means that the given resource class is an annotation to another resource class. must be used directly in the XML data file in the <annotation> tag","title":"Caveats"},{"location":"DSP-TOOLS/file-formats/json-project/caveats/#caveats-when-working-with-a-json-project-file","text":"","title":"Caveats when working with a JSON project file"},{"location":"DSP-TOOLS/file-formats/json-project/caveats/#referencing-ontologies","text":"For several fields, such as super in both resources and properties or propname in cardinalities it is necessary to reference entities that are defined elsewhere. The following cases are possible: DSP-API internals: They are referenced as such and do not have a leading colon. E.g. Resource , DocumentRepresentation or hasValue An external ontology: The ontology must be defined in the prefixes section. The prefix can then be used for referencing the ontology. E.g. foaf:familyName or sdo:Organization The current ontology: Within an ontology definition, references can be made by prepending a colon without a prefix. E.g. :hasName Optionally, an explicit prefix can be used. In this case the ontology must be added to the prefixes section and the prefix must be identical to the ontology's name . A different ontology defined in the same file: Within one data model file, multiple ontologies can be defined. These will be created in the exact order they appear in the ontologies array. Once an ontology has been created, it can be referenced by the following ontologies by its name, e.g. first-onto:hasName . It is not necessary to add first-onto to the prefixes.","title":"Referencing Ontologies"},{"location":"DSP-TOOLS/file-formats/json-project/caveats/#dsp-base-resources-and-base-properties-to-be-used-directly-in-the-xml-file","text":"There is a number of DSP base resources that must not be subclassed in a project ontology. They are directly available in the XML data file: Annotation is an annotation to another resource of any class. It can be used in the XML file with the <annotation> tag . It automatically has the following predefined properties: hasComment (1-n) isAnnotationOf (1) LinkObj is a resource linking together several other resources of different classes. It can be used in the XML file with the <link> tag . It automatically has the following predefined properties: hasComment (1-n) hasLinkTo (1-n) A Region resource defines a region of interest (ROI) in an image. It can be used in the XML file with the <region> tag . It automatically has the following predefined properties: hasColor (1) isRegionOf (1) hasGeometry (1) hasComment (1-n) There are some DSP base properties that are used directly in the above resource classes. Some of them can also be subclassed and used in a resource class. hasLinkTo : a link to another resource can be subclassed ( hasLinkTo Property ) can be used directly in the XML data file in the <link> tag hasColor : Defines a color value. can be subclassed ( ColorValue ) can be used directly in the XML data file in the <region> tag hasComment : Defines a standard comment. can be subclassed ( hasComment Property ) can be used directly in the XML data file in the <region> tag or <link> tag hasGeometry : Defines a geometry value (a JSON describing a polygon, circle or rectangle). must be used directly in the XML data file in the <region> tag isRegionOf : A special variant of hasLinkTo . It means that the given resource class is a region of interest in an image. must be used directly in the XML data file in the <region> tag isAnnotationOf : A special variant of hasLinkTo . It means that the given resource class is an annotation to another resource class. must be used directly in the XML data file in the <annotation> tag","title":"DSP base resources and base properties to be used directly in the XML file"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/","text":"The \"ontologies\" array of a JSON project An ontology is a formal representation of a set of terms which represent real world objects. Dependencies, attributes and relations of and between the individual components of the set are recorded in a logical, formal language. In contrast to a taxonomy, which defines a mere hierarchical structure within a range of terms, an ontology is much more a network of information of logical dependencies of term elements. Or, in other words, an ontology defines a strict, formal \"data model\" for real world concepts such as \"Person\", \"Work\", \"Artist\" etc. An ontology thus has to offer at least two things: a set of concepts or terms (called resource classes ) that represent concepts of real world objects properties describing these resources. These properties are linked either to a final value or may define a relationship to another resource. Let's assume that we define a resource class called \"Person\" and two properties called \"hasBirthday\" and \"hasParent\". For a specific instance of a \"Person\", \"hasBirthday\" will have a final value such as \"1960-05-21\", whereas \"hasParent\" will link to another instance of a \"Person\". Within DSP, properties may be re-used for different resources. E.g. a property \"description\" may be used for a resource called \"image\" as well as \"movie\". Therefore, the list of properties is separated from the list of resources. The properties are assigned to the resources by defining \" cardinalities \". A cardinality indicates if a property is mandatory or can be omitted (e.g. if unknown), and if a property may be used several times on the same instance of a resource or not. The cardinality definitions are explained further below . The ontology object in detail Example of an ontology object: { \"name\": \"seworon\", \"label\": \"Secrets of the World Ontology\", \"properties\": [ ... ], \"resources\": [ ... ] } Ontology: Name (required) \"name\": \"<string>\" The ontology's (short) name should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). Ontology: Label (required) \"label\": \"<string>\" A string that provides the full name of the ontology. Ontology: Properties (required) \"properties\": [<property-definition>, <property-definition>, ...] A properties array contains all properties used to describe resources in the ontology. A property has to be of a certain data type. It is not possible to create a custom data type. The following fields are mandatory: name labels super object gui_element The following fields are optional: comments subject gui_attributes A detailed description of properties can be found below . Ontology: Resources (required) The resource classes are the primary entities of the data model. They are the actual objects inside a terminology space. A resource class can be seen as a template for the representation of a real object that is represented in the DSP. A resource class defines properties ( data fields ). For each of these properties a data type as well as the cardinality has to be provided. \"resources\": [<resource-definition>, <resource-definition>, ...] A resource object needs to have the following fields: name labels super cardinalities The following field is optional: comments A detailed description of resources can be found below . The property object in detail { \"name\" : \"id\" , \"subject\" : \":School\" , \"object\" : \"TextValue\" , \"super\" : [ \"hasValue\" ], \"labels\" : { \"en\" : \"School ID\" , \"de\" : \"ID der Schule\" , \"fr\" : \"ID de l'\u00e9cole\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"size\" : 32 , \"maxlength\" : 128 } } Property: Name (required) \"name\": \"<string>\" A name for the property, e.g. \"pageOf\", \"hasBirthdate\", \"createdBy\". It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). By convention, property names start with a lower case letter. Property: Labels (required) \"labels\": {\"<language>\": \"<string>\", ...} Collection of labels for the property as strings with language tag (currently \"en\", \"de\", \"fr\", \"it\", and \"rm\" are supported). Property: Comments (optional) \"comments\": { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } Comments with language tags. Currently, \"de\", \"en\", \"fr\", \"it\", and \"rm\" are supported. The comments element is optional. Property: Super (required) \"super\": [\"<super-property>\", \"<super-property>, ...] A property is always derived from at least one other property. There are three groups of properties that can serve as super-property: DSP base properties properties defined in external ontologies properties defined in the project ontology itself The syntax how to refer to these different groups of properties is described here . The following DSP base properties are available: hasValue : This is the most general case, to be used in all cases when your property is none of the special cases below. hasLinkTo : a link to another resource isPartOf : A special variant of hasLinkTo . It says that an instance of the given resource class is an integral part of another resource class. E.g. a \"page\" is part of a \"book\". seqnum : An integer that is used to define a sequence number in an ordered set of instances, e.g. the ordering of the pages in a book. A resource that has a property derived from seqnum must also have a property derived from isPartOf . hasColor : Defines a color value. hasComment : Defines a standard comment. isSequenceOf : A special variant of hasLinkTo . It says that an instance of the given resource class is a section of an audio/video resource. hasSequenceBounds : This base property is used together with isSequenceOf . It denotes a time interval of an audio/ video resource. Property: Subject (optional) \"subject\": \"<resource-class>\" The subject defines the resource class the property can be used on. It has to be provided as prefixed name of the resource class (see here on how prefixed names are used). Property: object, gui_element, gui_attributes These three are related as follows: object (required) is used to define the data type of the value that the property will store. gui_element (required) depends on the value of object . gui_attributes (optional) depends on the value of gui_element . Overview DSP base property ( super ) object gui_element hasValue BooleanValue CheckBox hasColor ColorValue Colorpicker hasValue DateValue Date hasValue DecimalValue Slider, SimpleText hasValue GeonameValue Geonames hasValue IntValue Spinbox, SimpleText hasValue ListValue Radio, List hasValue TextValue SimpleText, Textarea, Richtext hasComment TextValue SimpleText hasValue TimeValue TimeStamp hasValue UriValue SimpleText hasLinkTo (resourceclass) Searchbox hasRepresentation Representation Searchbox isPartOf (resourceclass) Searchbox seqnum IntValue Spinbox, SimpleText isSequenceOf (AudioRepresentation, MovingImageRepresentation, or subclass) Searchbox hasSequenceBounds IntervalValue Interval BooleanValue \"object\": \"BooleanValue\" Represents a Boolean (\"true\" or \"false\"). See the xmlupload documentation for more information. gui_elements / gui_attributes : Checkbox : The only GUI element for boolean values: a box to check or uncheck gui_attributes : No attributes Example: { \"name\" : \"hasBoolean\" , \"super\" : [ \"hasValue\" ], \"object\" : \"BooleanValue\" , \"labels\" : { \"en\" : \"Boolean value\" }, \"gui_element\" : \"Checkbox\" } ColorValue \"object\": \"ColorValue\" A string representation of a color in the hexadecimal form. See the xmlupload documentation for more information. gui_elements / gui_attributes : Colorpicker : The only GUI element for colors. It's used to choose a color. gui_attributes : ncolors=integer (optional): Number of colors the color picker should present. Example: { \"name\" : \"hasColor\" , \"super\" : [ \"hasColor\" ], \"object\" : \"ColorValue\" , \"labels\" : { \"en\" : \"Color\" }, \"gui_element\" : \"Colorpicker\" } DateValue object\": \"DateValue\" Represents a date. It's a string with the format calendar:start:end . See the xmlupload documentation for more information. gui_elements / gui_attributes : Date : The only GUI element for DateValue . A date picker GUI. gui_attributes : No attributes Example: { \"name\" : \"hasDate\" , \"super\" : [ \"hasValue\" ], \"object\" : \"DateValue\" , \"labels\" : { \"en\" : \"Date\" }, \"gui_element\" : \"Date\" } DecimalValue \"object\": \"DecimalValue\" A number with decimal point. See the xmlupload documentation for more information. gui_elements / gui_attributes : Slider : Provides a slider to select a decimal value. gui_attributes : max=decimal (mandatory): maximal value min=decimal (mandatory): minimal value SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): maximum number of characters accepted size=integer (optional): size of the input field Example: { \"name\" : \"hasDecimal\" , \"super\" : [ \"hasValue\" ], \"object\" : \"DecimalValue\" , \"labels\" : { \"en\" : \"Decimal number\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"maxlength\" : 255 , \"size\" : 80 } } GeonameValue \"object\": \"GeonameValue\" Represents a location ID of geonames.org . See the xmlupload documentation for more information. gui_elements / gui_attributes : Geonames : The only GUI element for GeonameValue . A dropdown to select a geonames.org location, either by ID if digits are typed in, or by name if letters are typed in. gui_attributes : No attributes Example: { \"name\" : \"hasGeoname\" , \"super\" : [ \"hasValue\" ], \"object\" : \"GeonameValue\" , \"labels\" : { \"en\" : \"Geoname\" }, \"gui_element\" : \"Geonames\" } IntValue \"object\": \"IntValue\" Represents an integer value. See the xmlupload documentation for more information. gui_elements / gui_attributes : Spinbox : A GUI element for IntegerValue . A text field with and an \"up\" and a \"down\" button for increment/decrement. gui_attributes : max=decimal (optional): Maximal value min=decimal (optional): Minimal value SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example: { \"name\" : \"hasInteger\" , \"super\" : [ \"hasValue\" ], \"object\" : \"IntValue\" , \"labels\" : { \"en\" : \"Integer\" }, \"gui_element\" : \"Spinbox\" , \"gui_attributes\" : { \"max\" : 10.0 , \"min\" : 0.0 } } ListValue \"object\": \"ListValue\" Represents a node of a (possibly hierarchical) list. See the xmlupload documentation for more information. gui_elements / gui_attributes : Radio : A GUI element for ListValue . A set of radio buttons. This works only with flat lists. gui_attributes : hlist=<list-name> (required): The name of a list defined in the \"lists\" section . List : A GUI element for ListValue . A dropdown to select a list node. This GUI element should be chosen for hierarchical lists or flat lists that could be expanded to hierarchical lists in the future. gui_attributes : hlist=<list-name> (required): The name of a list defined in the \"lists\" section . Example: { \"name\" : \"hasListItem\" , \"super\" : [ \"hasValue\" ], \"object\" : \"ListValue\" , \"labels\" : { \"en\" : \"List element\" }, \"gui_element\" : \"List\" , \"gui_attributes\" : { \"hlist\" : \"treelistroot\" } } TextValue \"object\": \"TextValue\" Represents a text that may contain standoff markup. See the xmlupload documentation for more information. gui_elements / gui_attributes : SimpleText : one-line text entry box (for text without markup) gui_attributes : maxlength=integer (optional): maximal length (number of characters accepted) size=integer (optional): size (width) of widget Textarea : multiline text entry box (for text without markup) gui_attributes : cols=integer (optional): number of columns of the textarea rows=integer (optional): number of rows of the textarea width=percent (optional): width of the textarea on the screen wrap=soft|hard (optional): wrapping of text Richtext : multiline rich-text editor (for text with markup) gui_attributes : No attributes Example: { \"name\" : \"hasPictureTitle\" , \"super\" : [ \"hasValue\" ], \"object\" : \"TextValue\" , \"labels\" : { \"en\" : \"Title\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"maxlength\" : 255 , \"size\" : 80 } } hasComment property \"object\": \"TextValue\" This property is actually very similar to a simple text field. Example: { \"name\" : \"hasComment\" , \"super\" : [ \"hasComment\" ], \"object\" : \"TextValue\" , \"labels\" : { \"de\" : \"Kommentar\" , \"en\" : \"Comment\" , \"fr\" : \"Commentaire\" }, \"gui_element\" : \"SimpleText\" } TimeValue \"object\": \"TimeValue\" A time value represents a precise moment in time in the Gregorian calendar. See the xmlupload documentation for more information. gui_elements / gui_attributes : TimeStamp : A GUI element for TimeValue which contains a date picker and a time picker. gui_attributes : No attributes Example: { \"name\" : \"hasTime\" , \"super\" : [ \"hasValue\" ], \"object\" : \"TimeValue\" , \"labels\" : { \"en\" : \"Time\" }, \"gui_element\" : \"TimeStamp\" } UriValue \"object\": \"UriValue\" Represents an URI. See the xmlupload documentation for more information. gui_elements / gui_attributes : SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example: { \"name\" : \"hasUri\" , \"super\" : [ \"hasValue\" ], \"object\" : \"UriValue\" , \"labels\" : { \"en\" : \"URI\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"maxlength\" : 255 , \"size\" : 80 } } Link-properties Link properties do not follow the pattern of the previous data types, because they do not connect to a final value but to an existing resource. Thus, the object denominates the resource class the link will point to. hasLinkTo Property \"object\": \"<resourceclass>\" The most basic kind of link property is the hasLinkTo property. Its \"super\" element has to be hasLinkTo or derived from hasLinkTo . There are different groups of resource classes that can be the object: project resources: a resource class defined in the present ontology itself external resources: a resource class defined in another ontology DSP base resources: Resource : the most generic one, can point to any resource class, be it a DSP base resource, a project resource, or an external resource. Resource is at the very top of the inheritance hierarchy. Region : a region in an image StillImageRepresentation , MovingImageRepresentation , TextRepresentation , AudioRepresentation , DDDRepresentation , DocumentRepresentation , or ArchiveRepresentation The syntax how to refer to these different groups of resources is described here . gui_elements/gui_attributes : Searchbox : The only GUI element for hasLinkTo . Allows searching resources by entering the target resource name. gui_attributes : numprops=integer (optional): Number of search results to be displayed Example: { \"name\" : \"hasOtherThing\" , \"super\" : [ \"hasLinkTo\" ], \"object\" : \":Thing\" , \"labels\" : \"Another thing\" , \"gui_element\" : \"Searchbox\" } hasRepresentation Property \"object\": \"Representation\" A property pointing to the DSP base resource class Representation , which is the parent class of the DSP base resource classes StillImageRepresentation , AudioRepresentation , MovingImageRepresentation , ... Has to be used in combination with \"super\": [\"hasRepresentation\"] . This generic property can point to any type of the aforementioned representations, or to a subclass of them. See the xmlupload documentation for more information. gui_elements / gui_attributes : Searchbox : Allows searching resources that have super class Representation by entering at least 3 characters into a searchbox. gui_attributes : numprops=integer (optional): While dynamically displaying the search result, the number of properties that should be displayed. Example: { \"name\" : \"hasRep\" , \"super\" : [ \"hasRepresentation\" ], \"object\" : \"Representation\" , \"labels\" : { \"en\" : \"Represented by\" }, \"gui_element\" : \"Searchbox\" } isPartOf Property \"object\": \"<resourceclass>\" A special case of linked resources are resources in a part-whole relation, i.e. resources that are composed of other resources. A isPartOf property has to be added to the resource that is part of another resource. In case of resources that are of type StillImageRepresentation , an additional property derived from seqnum with object IntValue is required. When defined, the user is able to leaf through the parts of a compound object, p.ex. to leaf through pages of a book. The DSP base properties isPartOf and seqnum can be used to derive a custom property from them, or they can be used directly as cardinalities in a resource. The example belows shows both possibilities. gui_elements/gui_attributes : Searchbox : The only GUI element for isPartOf . Allows searching resources by entering the target resource name. gui_attributes : numprops=integer (optional): Number of search results to be displayed Example: \"properties\": [ { \"name\": \"partOfBook\", \"super\": [\"isPartOf\"], \"object\": \":Book\", \"labels\": {\"en\": \"is part of\"}, \"gui_element\": \"Searchbox\" }, { \"name\": \"hasPageNumber\", \"super\": [\"seqnum\"], \"object\": \"IntValue\", \"labels\": {\"en\": \"has page number\"}, \"gui_element\": \"Spinbox\" } ], \"resources\": [ { \"name\": \"Page\", \"labels\": {\"en\": \"Page using properties derived from 'isPartOf' and 'seqnum'\"}, \"super\": \"StillImageRepresentation\", \"cardinalities\": [ { \"propname\": \":partOfBook\", \"cardinality\": \"1\" }, { \"propname\": \":hasPageNumber\", \"cardinality\": \"1\" } ] }, { \"name\": \"MinimalisticPage\", \"labels\": {\"en\": \"Page using 'isPartOf' and 'seqnum' directly\"}, \"super\": \"StillImageRepresentation\", \"cardinalities\": [ { \"propname\": \"isPartOf\", \"cardinality\": \"1\" }, { \"propname\": \"seqnum\", \"cardinality\": \"1\" } ] } ] seqnum Property \"object\": \"IntValue\" This property can be attached to a StillImageRepresentation , together with isPartOf . The seqnum is then the page number of the image inside the compound object. Apart from this, seqnum is like an integer property. See the xmlupload documentation for more information. gui_elements / gui_attributes : Spinbox : A GUI element for IntegerValue . A text field with and an \"up\" and a \"down\" button for increment/decrement. gui_attributes : max=decimal (optional): Maximal value min=decimal (optional): Minimal value SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example: See the isPartOf Property above. isSequenceOf Property \"object\": <AudioRepresentation/MovingImageRepresentation or a subclass of one of them> This property can be used, together with a hasSequenceBounds property, on a resource representing a sequence of an audio/video resource. The isSequenceOf would then point to the audio/video resource, and the hasSequenceBounds would be the time interval of the sequence. The DSP base properties isSequenceOf and hasSequenceBounds can be used to derive a custom property from them, or they can be used directly as cardinalities in a resource. The example below shows both possibilities. gui_elements/gui_attributes : Searchbox : The only GUI element for isSequenceOf . Allows searching resources by entering the target resource name. gui_attributes : numprops=integer (optional): Number of search results to be displayed Example: \"properties\": [ { \"name\": \"sequenceOfAudio\", \"super\": [\"isSequenceOf\"], \"subject\": \":AudioSequence\", \"object\": \":Audio\", \"labels\": {\"en\": \"is sequence of\"}, \"gui_element\": \"Searchbox\" }, { \"name\": \"hasBounds\", \"super\": [\"hasSequenceBounds\"], \"subject\": \":AudioSequence\", \"object\": \"IntervalValue\", \"labels\": {\"en\": \"Start and end point of a sequence of an audio/video\"}, \"gui_element\": \"Interval\" } ], \"resources\": [ { \"name\": \"AudioSequence\", \"labels\": {\"en\": \"Sequence of audio using properties derived from 'isSequenceOf' and 'hasSequenceBounds'\"}, \"super\": \"Resource\", \"cardinalities\": [ { \"propname\": \":sequenceOfAudio\", \"cardinality\": \"1\" }, { \"propname\": \":hasBounds\", \"cardinality\": \"1\" } ] }, { \"name\": \"MinimalisticAudioSequence\", \"labels\": {\"en\": \"Sequence of audio using 'isSequenceOf' and 'hasSequenceBounds' directly\"}, \"super\": \"Resource\", \"cardinalities\": [ { \"propname\": \"isSequenceOf\", \"cardinality\": \"1\" }, { \"propname\": \"hasSequenceBounds\", \"cardinality\": \"1\" } ] } ] hasSequenceBounds Property \"object\": \"IntervalValue\" This property represents a time interval of an audio or video. It can be used together with an isSequenceOf property on a resource that represents the sequence. The isSequenceOf would then point to the audio/video resource, and the hasSequenceBounds would be the time interval of the sequence, represented as two decimal numbers. See the isSequenceOf property or the xmlupload documentation for more information. gui_elements / gui_attributes : SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Interval : Two Sliders, one for each decimal gui_attributes : No attributes Example: { \"name\" : \"hasBounds\" , \"super\" : [ \"hasSequenceBounds\" ], \"subject\" : \":AudioSequence\" , \"object\" : \"IntervalValue\" , \"labels\" : { \"en\" : \"Interval defining the start and end point of a sequence of an audio or video file\" }, \"gui_element\" : \"Interval\" } The resource object in detail { \"name\" : \"school\" , \"labels\" : { \"de\" : \"Schule\" , \"en\" : \"School\" , \"fr\" : \"Ecole\" , \"it\" : \"Scuola\" }, \"super\" : \"Resource\" , \"comments\" : { \"de\" : \"Eine Bildungsinstitution f\u00fcr Grundbildung\" , \"en\" : \"An education institution for basic education\" , \"fr\" : \"Une institution de formation de base\" , \"it\" : \"Un'istituzione educativa per l'istruzione di base\" }, \"cardinalities\" : [ { \"propname\" : \":schulcode\" , \"gui_order\" : 1 , \"cardinality\" : \"1\" }, { \"propname\" : \":schulname\" , \"gui_order\" : 2 , \"cardinality\" : \"1\" }, { \"propname\" : \":bildungsgang\" , \"gui_order\" : 3 , \"cardinality\" : \"0-n\" } ] } Resource: Name (required) \"name\": \"<string>\" A name for the resource, e.g. \"Book\", \"Manuscript\", \"Person\". It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). By convention, resource names start with an upper case letter. Resource: Labels (required) \"labels\": {\"<language>\": \"<string>\", ...} Collection of labels for the resource as strings with language tag (currently \"en\", \"de\", \"fr\", \"it\", and \"rm\" are supported). Resource: Super (required) \"super\": [\"<super-resource>\", \"<super-resource>\", ...] A resource is always derived from at least one other resource. There are three groups of resources that can serve as super-resource: DSP base resources resources defined in external ontologies resources defined in the project ontology itself The syntax how to refer to these different groups of resources is described here . The following base resources can be used as super-resource: Resource : A generic resource representing an item from the real world. This is the most general case, to be used in all cases when your resource is none of the special cases below. ArchiveRepresentation : A resource representing an archive file (e.g. ZIP) AudioRepresentation : A resource representing an audio file DDDRepresentation : A resource representing a 3-D representation (not yet implemented) DocumentRepresentation : A resource representing an opaque document (e.g. a PDF) MovingImageRepresentation : A resource representing a video StillImageRepresentation : A resource representing an image TextRepresentation : A resource representing a text File Extensions : An overview of the supported file types per representation can be found in the xmlupload documentation . Resource: Cardinalities (required) \"cardinalities\": [...] An array that contains information about the relation between resources and properties. It tells what properties a resource can have as well as how many values a property can have. cardinalities : Array of references to the properties that the resource may hold. A cardinality is defined as follows: propname (mandatory): The name of the property. If it's used in the form :my_property , the current ontology is referenced. If the property was defined in another ontology, the prefix of that ontology must be provided. gui_order (optional): By default, DSP-APP displays the properties in the order how they are defined in the cardinalities array. If you prefer another order, you can provide a positive integer here. Example: You order the propnames alphabetically in the JSON file, but they should be displayed in another order in DSP-APP. cardinality (mandatory): Indicates how often a given property may occur. The possible values are: \"1\" : exactly once (mandatory one value and only one) \"0-1\" : The value may be omitted, but can occur only once. \"1-n\" : At least one value must be present, but multiple values may be present. \"0-n\" : The value may be omitted, but may also occur multiple times. Resource: Comments (optional) \"comments\": { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } Comments with language tags. Currently, \"de\", \"en\", \"fr\", \"it\", and \"rm\" are supported. The comments element is optional.","title":"Ontologies"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#the-ontologies-array-of-a-json-project","text":"An ontology is a formal representation of a set of terms which represent real world objects. Dependencies, attributes and relations of and between the individual components of the set are recorded in a logical, formal language. In contrast to a taxonomy, which defines a mere hierarchical structure within a range of terms, an ontology is much more a network of information of logical dependencies of term elements. Or, in other words, an ontology defines a strict, formal \"data model\" for real world concepts such as \"Person\", \"Work\", \"Artist\" etc. An ontology thus has to offer at least two things: a set of concepts or terms (called resource classes ) that represent concepts of real world objects properties describing these resources. These properties are linked either to a final value or may define a relationship to another resource. Let's assume that we define a resource class called \"Person\" and two properties called \"hasBirthday\" and \"hasParent\". For a specific instance of a \"Person\", \"hasBirthday\" will have a final value such as \"1960-05-21\", whereas \"hasParent\" will link to another instance of a \"Person\". Within DSP, properties may be re-used for different resources. E.g. a property \"description\" may be used for a resource called \"image\" as well as \"movie\". Therefore, the list of properties is separated from the list of resources. The properties are assigned to the resources by defining \" cardinalities \". A cardinality indicates if a property is mandatory or can be omitted (e.g. if unknown), and if a property may be used several times on the same instance of a resource or not. The cardinality definitions are explained further below .","title":"The \"ontologies\" array of a JSON project"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#the-ontology-object-in-detail","text":"Example of an ontology object: { \"name\": \"seworon\", \"label\": \"Secrets of the World Ontology\", \"properties\": [ ... ], \"resources\": [ ... ] }","title":"The ontology object in detail"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#ontology-name","text":"(required) \"name\": \"<string>\" The ontology's (short) name should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character).","title":"Ontology: Name"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#ontology-label","text":"(required) \"label\": \"<string>\" A string that provides the full name of the ontology.","title":"Ontology: Label"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#ontology-properties","text":"(required) \"properties\": [<property-definition>, <property-definition>, ...] A properties array contains all properties used to describe resources in the ontology. A property has to be of a certain data type. It is not possible to create a custom data type. The following fields are mandatory: name labels super object gui_element The following fields are optional: comments subject gui_attributes A detailed description of properties can be found below .","title":"Ontology: Properties"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#ontology-resources","text":"(required) The resource classes are the primary entities of the data model. They are the actual objects inside a terminology space. A resource class can be seen as a template for the representation of a real object that is represented in the DSP. A resource class defines properties ( data fields ). For each of these properties a data type as well as the cardinality has to be provided. \"resources\": [<resource-definition>, <resource-definition>, ...] A resource object needs to have the following fields: name labels super cardinalities The following field is optional: comments A detailed description of resources can be found below .","title":"Ontology: Resources"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#the-property-object-in-detail","text":"{ \"name\" : \"id\" , \"subject\" : \":School\" , \"object\" : \"TextValue\" , \"super\" : [ \"hasValue\" ], \"labels\" : { \"en\" : \"School ID\" , \"de\" : \"ID der Schule\" , \"fr\" : \"ID de l'\u00e9cole\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"size\" : 32 , \"maxlength\" : 128 } }","title":"The property object in detail"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#property-name","text":"(required) \"name\": \"<string>\" A name for the property, e.g. \"pageOf\", \"hasBirthdate\", \"createdBy\". It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). By convention, property names start with a lower case letter.","title":"Property: Name"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#property-labels","text":"(required) \"labels\": {\"<language>\": \"<string>\", ...} Collection of labels for the property as strings with language tag (currently \"en\", \"de\", \"fr\", \"it\", and \"rm\" are supported).","title":"Property: Labels"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#property-comments","text":"(optional) \"comments\": { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } Comments with language tags. Currently, \"de\", \"en\", \"fr\", \"it\", and \"rm\" are supported. The comments element is optional.","title":"Property: Comments"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#property-super","text":"(required) \"super\": [\"<super-property>\", \"<super-property>, ...] A property is always derived from at least one other property. There are three groups of properties that can serve as super-property: DSP base properties properties defined in external ontologies properties defined in the project ontology itself The syntax how to refer to these different groups of properties is described here . The following DSP base properties are available: hasValue : This is the most general case, to be used in all cases when your property is none of the special cases below. hasLinkTo : a link to another resource isPartOf : A special variant of hasLinkTo . It says that an instance of the given resource class is an integral part of another resource class. E.g. a \"page\" is part of a \"book\". seqnum : An integer that is used to define a sequence number in an ordered set of instances, e.g. the ordering of the pages in a book. A resource that has a property derived from seqnum must also have a property derived from isPartOf . hasColor : Defines a color value. hasComment : Defines a standard comment. isSequenceOf : A special variant of hasLinkTo . It says that an instance of the given resource class is a section of an audio/video resource. hasSequenceBounds : This base property is used together with isSequenceOf . It denotes a time interval of an audio/ video resource.","title":"Property: Super"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#property-subject","text":"(optional) \"subject\": \"<resource-class>\" The subject defines the resource class the property can be used on. It has to be provided as prefixed name of the resource class (see here on how prefixed names are used).","title":"Property: Subject"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#property-object-gui_element-gui_attributes","text":"These three are related as follows: object (required) is used to define the data type of the value that the property will store. gui_element (required) depends on the value of object . gui_attributes (optional) depends on the value of gui_element .","title":"Property: object, gui_element, gui_attributes"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#overview","text":"DSP base property ( super ) object gui_element hasValue BooleanValue CheckBox hasColor ColorValue Colorpicker hasValue DateValue Date hasValue DecimalValue Slider, SimpleText hasValue GeonameValue Geonames hasValue IntValue Spinbox, SimpleText hasValue ListValue Radio, List hasValue TextValue SimpleText, Textarea, Richtext hasComment TextValue SimpleText hasValue TimeValue TimeStamp hasValue UriValue SimpleText hasLinkTo (resourceclass) Searchbox hasRepresentation Representation Searchbox isPartOf (resourceclass) Searchbox seqnum IntValue Spinbox, SimpleText isSequenceOf (AudioRepresentation, MovingImageRepresentation, or subclass) Searchbox hasSequenceBounds IntervalValue Interval","title":"Overview"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#booleanvalue","text":"\"object\": \"BooleanValue\" Represents a Boolean (\"true\" or \"false\"). See the xmlupload documentation for more information. gui_elements / gui_attributes : Checkbox : The only GUI element for boolean values: a box to check or uncheck gui_attributes : No attributes Example: { \"name\" : \"hasBoolean\" , \"super\" : [ \"hasValue\" ], \"object\" : \"BooleanValue\" , \"labels\" : { \"en\" : \"Boolean value\" }, \"gui_element\" : \"Checkbox\" }","title":"BooleanValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#colorvalue","text":"\"object\": \"ColorValue\" A string representation of a color in the hexadecimal form. See the xmlupload documentation for more information. gui_elements / gui_attributes : Colorpicker : The only GUI element for colors. It's used to choose a color. gui_attributes : ncolors=integer (optional): Number of colors the color picker should present. Example: { \"name\" : \"hasColor\" , \"super\" : [ \"hasColor\" ], \"object\" : \"ColorValue\" , \"labels\" : { \"en\" : \"Color\" }, \"gui_element\" : \"Colorpicker\" }","title":"ColorValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#datevalue","text":"object\": \"DateValue\" Represents a date. It's a string with the format calendar:start:end . See the xmlupload documentation for more information. gui_elements / gui_attributes : Date : The only GUI element for DateValue . A date picker GUI. gui_attributes : No attributes Example: { \"name\" : \"hasDate\" , \"super\" : [ \"hasValue\" ], \"object\" : \"DateValue\" , \"labels\" : { \"en\" : \"Date\" }, \"gui_element\" : \"Date\" }","title":"DateValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#decimalvalue","text":"\"object\": \"DecimalValue\" A number with decimal point. See the xmlupload documentation for more information. gui_elements / gui_attributes : Slider : Provides a slider to select a decimal value. gui_attributes : max=decimal (mandatory): maximal value min=decimal (mandatory): minimal value SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): maximum number of characters accepted size=integer (optional): size of the input field Example: { \"name\" : \"hasDecimal\" , \"super\" : [ \"hasValue\" ], \"object\" : \"DecimalValue\" , \"labels\" : { \"en\" : \"Decimal number\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"maxlength\" : 255 , \"size\" : 80 } }","title":"DecimalValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#geonamevalue","text":"\"object\": \"GeonameValue\" Represents a location ID of geonames.org . See the xmlupload documentation for more information. gui_elements / gui_attributes : Geonames : The only GUI element for GeonameValue . A dropdown to select a geonames.org location, either by ID if digits are typed in, or by name if letters are typed in. gui_attributes : No attributes Example: { \"name\" : \"hasGeoname\" , \"super\" : [ \"hasValue\" ], \"object\" : \"GeonameValue\" , \"labels\" : { \"en\" : \"Geoname\" }, \"gui_element\" : \"Geonames\" }","title":"GeonameValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#intvalue","text":"\"object\": \"IntValue\" Represents an integer value. See the xmlupload documentation for more information. gui_elements / gui_attributes : Spinbox : A GUI element for IntegerValue . A text field with and an \"up\" and a \"down\" button for increment/decrement. gui_attributes : max=decimal (optional): Maximal value min=decimal (optional): Minimal value SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example: { \"name\" : \"hasInteger\" , \"super\" : [ \"hasValue\" ], \"object\" : \"IntValue\" , \"labels\" : { \"en\" : \"Integer\" }, \"gui_element\" : \"Spinbox\" , \"gui_attributes\" : { \"max\" : 10.0 , \"min\" : 0.0 } }","title":"IntValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#listvalue","text":"\"object\": \"ListValue\" Represents a node of a (possibly hierarchical) list. See the xmlupload documentation for more information. gui_elements / gui_attributes : Radio : A GUI element for ListValue . A set of radio buttons. This works only with flat lists. gui_attributes : hlist=<list-name> (required): The name of a list defined in the \"lists\" section . List : A GUI element for ListValue . A dropdown to select a list node. This GUI element should be chosen for hierarchical lists or flat lists that could be expanded to hierarchical lists in the future. gui_attributes : hlist=<list-name> (required): The name of a list defined in the \"lists\" section . Example: { \"name\" : \"hasListItem\" , \"super\" : [ \"hasValue\" ], \"object\" : \"ListValue\" , \"labels\" : { \"en\" : \"List element\" }, \"gui_element\" : \"List\" , \"gui_attributes\" : { \"hlist\" : \"treelistroot\" } }","title":"ListValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#textvalue","text":"\"object\": \"TextValue\" Represents a text that may contain standoff markup. See the xmlupload documentation for more information. gui_elements / gui_attributes : SimpleText : one-line text entry box (for text without markup) gui_attributes : maxlength=integer (optional): maximal length (number of characters accepted) size=integer (optional): size (width) of widget Textarea : multiline text entry box (for text without markup) gui_attributes : cols=integer (optional): number of columns of the textarea rows=integer (optional): number of rows of the textarea width=percent (optional): width of the textarea on the screen wrap=soft|hard (optional): wrapping of text Richtext : multiline rich-text editor (for text with markup) gui_attributes : No attributes Example: { \"name\" : \"hasPictureTitle\" , \"super\" : [ \"hasValue\" ], \"object\" : \"TextValue\" , \"labels\" : { \"en\" : \"Title\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"maxlength\" : 255 , \"size\" : 80 } }","title":"TextValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#hascomment-property","text":"\"object\": \"TextValue\" This property is actually very similar to a simple text field. Example: { \"name\" : \"hasComment\" , \"super\" : [ \"hasComment\" ], \"object\" : \"TextValue\" , \"labels\" : { \"de\" : \"Kommentar\" , \"en\" : \"Comment\" , \"fr\" : \"Commentaire\" }, \"gui_element\" : \"SimpleText\" }","title":"hasComment property"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#timevalue","text":"\"object\": \"TimeValue\" A time value represents a precise moment in time in the Gregorian calendar. See the xmlupload documentation for more information. gui_elements / gui_attributes : TimeStamp : A GUI element for TimeValue which contains a date picker and a time picker. gui_attributes : No attributes Example: { \"name\" : \"hasTime\" , \"super\" : [ \"hasValue\" ], \"object\" : \"TimeValue\" , \"labels\" : { \"en\" : \"Time\" }, \"gui_element\" : \"TimeStamp\" }","title":"TimeValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#urivalue","text":"\"object\": \"UriValue\" Represents an URI. See the xmlupload documentation for more information. gui_elements / gui_attributes : SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example: { \"name\" : \"hasUri\" , \"super\" : [ \"hasValue\" ], \"object\" : \"UriValue\" , \"labels\" : { \"en\" : \"URI\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"maxlength\" : 255 , \"size\" : 80 } }","title":"UriValue"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#link-properties","text":"Link properties do not follow the pattern of the previous data types, because they do not connect to a final value but to an existing resource. Thus, the object denominates the resource class the link will point to.","title":"Link-properties"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#haslinkto-property","text":"\"object\": \"<resourceclass>\" The most basic kind of link property is the hasLinkTo property. Its \"super\" element has to be hasLinkTo or derived from hasLinkTo . There are different groups of resource classes that can be the object: project resources: a resource class defined in the present ontology itself external resources: a resource class defined in another ontology DSP base resources: Resource : the most generic one, can point to any resource class, be it a DSP base resource, a project resource, or an external resource. Resource is at the very top of the inheritance hierarchy. Region : a region in an image StillImageRepresentation , MovingImageRepresentation , TextRepresentation , AudioRepresentation , DDDRepresentation , DocumentRepresentation , or ArchiveRepresentation The syntax how to refer to these different groups of resources is described here . gui_elements/gui_attributes : Searchbox : The only GUI element for hasLinkTo . Allows searching resources by entering the target resource name. gui_attributes : numprops=integer (optional): Number of search results to be displayed Example: { \"name\" : \"hasOtherThing\" , \"super\" : [ \"hasLinkTo\" ], \"object\" : \":Thing\" , \"labels\" : \"Another thing\" , \"gui_element\" : \"Searchbox\" }","title":"hasLinkTo Property"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#hasrepresentation-property","text":"\"object\": \"Representation\" A property pointing to the DSP base resource class Representation , which is the parent class of the DSP base resource classes StillImageRepresentation , AudioRepresentation , MovingImageRepresentation , ... Has to be used in combination with \"super\": [\"hasRepresentation\"] . This generic property can point to any type of the aforementioned representations, or to a subclass of them. See the xmlupload documentation for more information. gui_elements / gui_attributes : Searchbox : Allows searching resources that have super class Representation by entering at least 3 characters into a searchbox. gui_attributes : numprops=integer (optional): While dynamically displaying the search result, the number of properties that should be displayed. Example: { \"name\" : \"hasRep\" , \"super\" : [ \"hasRepresentation\" ], \"object\" : \"Representation\" , \"labels\" : { \"en\" : \"Represented by\" }, \"gui_element\" : \"Searchbox\" }","title":"hasRepresentation Property"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#ispartof-property","text":"\"object\": \"<resourceclass>\" A special case of linked resources are resources in a part-whole relation, i.e. resources that are composed of other resources. A isPartOf property has to be added to the resource that is part of another resource. In case of resources that are of type StillImageRepresentation , an additional property derived from seqnum with object IntValue is required. When defined, the user is able to leaf through the parts of a compound object, p.ex. to leaf through pages of a book. The DSP base properties isPartOf and seqnum can be used to derive a custom property from them, or they can be used directly as cardinalities in a resource. The example belows shows both possibilities. gui_elements/gui_attributes : Searchbox : The only GUI element for isPartOf . Allows searching resources by entering the target resource name. gui_attributes : numprops=integer (optional): Number of search results to be displayed Example: \"properties\": [ { \"name\": \"partOfBook\", \"super\": [\"isPartOf\"], \"object\": \":Book\", \"labels\": {\"en\": \"is part of\"}, \"gui_element\": \"Searchbox\" }, { \"name\": \"hasPageNumber\", \"super\": [\"seqnum\"], \"object\": \"IntValue\", \"labels\": {\"en\": \"has page number\"}, \"gui_element\": \"Spinbox\" } ], \"resources\": [ { \"name\": \"Page\", \"labels\": {\"en\": \"Page using properties derived from 'isPartOf' and 'seqnum'\"}, \"super\": \"StillImageRepresentation\", \"cardinalities\": [ { \"propname\": \":partOfBook\", \"cardinality\": \"1\" }, { \"propname\": \":hasPageNumber\", \"cardinality\": \"1\" } ] }, { \"name\": \"MinimalisticPage\", \"labels\": {\"en\": \"Page using 'isPartOf' and 'seqnum' directly\"}, \"super\": \"StillImageRepresentation\", \"cardinalities\": [ { \"propname\": \"isPartOf\", \"cardinality\": \"1\" }, { \"propname\": \"seqnum\", \"cardinality\": \"1\" } ] } ]","title":"isPartOf Property"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#seqnum-property","text":"\"object\": \"IntValue\" This property can be attached to a StillImageRepresentation , together with isPartOf . The seqnum is then the page number of the image inside the compound object. Apart from this, seqnum is like an integer property. See the xmlupload documentation for more information. gui_elements / gui_attributes : Spinbox : A GUI element for IntegerValue . A text field with and an \"up\" and a \"down\" button for increment/decrement. gui_attributes : max=decimal (optional): Maximal value min=decimal (optional): Minimal value SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Example: See the isPartOf Property above.","title":"seqnum Property"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#issequenceof-property","text":"\"object\": <AudioRepresentation/MovingImageRepresentation or a subclass of one of them> This property can be used, together with a hasSequenceBounds property, on a resource representing a sequence of an audio/video resource. The isSequenceOf would then point to the audio/video resource, and the hasSequenceBounds would be the time interval of the sequence. The DSP base properties isSequenceOf and hasSequenceBounds can be used to derive a custom property from them, or they can be used directly as cardinalities in a resource. The example below shows both possibilities. gui_elements/gui_attributes : Searchbox : The only GUI element for isSequenceOf . Allows searching resources by entering the target resource name. gui_attributes : numprops=integer (optional): Number of search results to be displayed Example: \"properties\": [ { \"name\": \"sequenceOfAudio\", \"super\": [\"isSequenceOf\"], \"subject\": \":AudioSequence\", \"object\": \":Audio\", \"labels\": {\"en\": \"is sequence of\"}, \"gui_element\": \"Searchbox\" }, { \"name\": \"hasBounds\", \"super\": [\"hasSequenceBounds\"], \"subject\": \":AudioSequence\", \"object\": \"IntervalValue\", \"labels\": {\"en\": \"Start and end point of a sequence of an audio/video\"}, \"gui_element\": \"Interval\" } ], \"resources\": [ { \"name\": \"AudioSequence\", \"labels\": {\"en\": \"Sequence of audio using properties derived from 'isSequenceOf' and 'hasSequenceBounds'\"}, \"super\": \"Resource\", \"cardinalities\": [ { \"propname\": \":sequenceOfAudio\", \"cardinality\": \"1\" }, { \"propname\": \":hasBounds\", \"cardinality\": \"1\" } ] }, { \"name\": \"MinimalisticAudioSequence\", \"labels\": {\"en\": \"Sequence of audio using 'isSequenceOf' and 'hasSequenceBounds' directly\"}, \"super\": \"Resource\", \"cardinalities\": [ { \"propname\": \"isSequenceOf\", \"cardinality\": \"1\" }, { \"propname\": \"hasSequenceBounds\", \"cardinality\": \"1\" } ] } ]","title":"isSequenceOf Property"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#hassequencebounds-property","text":"\"object\": \"IntervalValue\" This property represents a time interval of an audio or video. It can be used together with an isSequenceOf property on a resource that represents the sequence. The isSequenceOf would then point to the audio/video resource, and the hasSequenceBounds would be the time interval of the sequence, represented as two decimal numbers. See the isSequenceOf property or the xmlupload documentation for more information. gui_elements / gui_attributes : SimpleText : A simple text entry box (one line only). gui_attributes : maxlength=integer (optional): The maximum number of characters accepted size=integer (optional): The size of the input field Interval : Two Sliders, one for each decimal gui_attributes : No attributes Example: { \"name\" : \"hasBounds\" , \"super\" : [ \"hasSequenceBounds\" ], \"subject\" : \":AudioSequence\" , \"object\" : \"IntervalValue\" , \"labels\" : { \"en\" : \"Interval defining the start and end point of a sequence of an audio or video file\" }, \"gui_element\" : \"Interval\" }","title":"hasSequenceBounds Property"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#the-resource-object-in-detail","text":"{ \"name\" : \"school\" , \"labels\" : { \"de\" : \"Schule\" , \"en\" : \"School\" , \"fr\" : \"Ecole\" , \"it\" : \"Scuola\" }, \"super\" : \"Resource\" , \"comments\" : { \"de\" : \"Eine Bildungsinstitution f\u00fcr Grundbildung\" , \"en\" : \"An education institution for basic education\" , \"fr\" : \"Une institution de formation de base\" , \"it\" : \"Un'istituzione educativa per l'istruzione di base\" }, \"cardinalities\" : [ { \"propname\" : \":schulcode\" , \"gui_order\" : 1 , \"cardinality\" : \"1\" }, { \"propname\" : \":schulname\" , \"gui_order\" : 2 , \"cardinality\" : \"1\" }, { \"propname\" : \":bildungsgang\" , \"gui_order\" : 3 , \"cardinality\" : \"0-n\" } ] }","title":"The resource object in detail"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#resource-name","text":"(required) \"name\": \"<string>\" A name for the resource, e.g. \"Book\", \"Manuscript\", \"Person\". It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). By convention, resource names start with an upper case letter.","title":"Resource: Name"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#resource-labels","text":"(required) \"labels\": {\"<language>\": \"<string>\", ...} Collection of labels for the resource as strings with language tag (currently \"en\", \"de\", \"fr\", \"it\", and \"rm\" are supported).","title":"Resource: Labels"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#resource-super","text":"(required) \"super\": [\"<super-resource>\", \"<super-resource>\", ...] A resource is always derived from at least one other resource. There are three groups of resources that can serve as super-resource: DSP base resources resources defined in external ontologies resources defined in the project ontology itself The syntax how to refer to these different groups of resources is described here . The following base resources can be used as super-resource: Resource : A generic resource representing an item from the real world. This is the most general case, to be used in all cases when your resource is none of the special cases below. ArchiveRepresentation : A resource representing an archive file (e.g. ZIP) AudioRepresentation : A resource representing an audio file DDDRepresentation : A resource representing a 3-D representation (not yet implemented) DocumentRepresentation : A resource representing an opaque document (e.g. a PDF) MovingImageRepresentation : A resource representing a video StillImageRepresentation : A resource representing an image TextRepresentation : A resource representing a text File Extensions : An overview of the supported file types per representation can be found in the xmlupload documentation .","title":"Resource: Super"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#resource-cardinalities","text":"(required) \"cardinalities\": [...] An array that contains information about the relation between resources and properties. It tells what properties a resource can have as well as how many values a property can have. cardinalities : Array of references to the properties that the resource may hold. A cardinality is defined as follows: propname (mandatory): The name of the property. If it's used in the form :my_property , the current ontology is referenced. If the property was defined in another ontology, the prefix of that ontology must be provided. gui_order (optional): By default, DSP-APP displays the properties in the order how they are defined in the cardinalities array. If you prefer another order, you can provide a positive integer here. Example: You order the propnames alphabetically in the JSON file, but they should be displayed in another order in DSP-APP. cardinality (mandatory): Indicates how often a given property may occur. The possible values are: \"1\" : exactly once (mandatory one value and only one) \"0-1\" : The value may be omitted, but can occur only once. \"1-n\" : At least one value must be present, but multiple values may be present. \"0-n\" : The value may be omitted, but may also occur multiple times.","title":"Resource: Cardinalities"},{"location":"DSP-TOOLS/file-formats/json-project/ontologies/#resource-comments","text":"(optional) \"comments\": { \"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } Comments with language tags. Currently, \"de\", \"en\", \"fr\", \"it\", and \"rm\" are supported. The comments element is optional.","title":"Resource: Comments"},{"location":"DSP-TOOLS/file-formats/json-project/overview/","text":"JSON project definition format This document describes the structure of a JSON project definition file that can be uploaded to a DSP server with the create command. A project on a DSP server is like a container for data. It defines some basic metadata, the data model(s) and optionally the user(s) who will be able to access the data. After the creation of a project, data can be uploaded that conforms with the data model(s). This documentation is divided into the following parts: Overview of the project description file (this page) The \"ontologies\" section explained in detail Some caveats to have in mind A short overview A complete project definition looks like this: { \"prefixes\": { \"foaf\": \"http://xmlns.com/foaf/0.1/\", \"dcterms\": \"http://purl.org/dc/terms/\" }, \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/project.json\", \"project\": { \"shortcode\": \"0123\", \"shortname\": \"BiZ\", \"longname\": \"Bildung in Zahlen\", \"descriptions\": { \"en\": \"This is a simple example project\", \"de\": \"Dies ist ein einfaches Beispielprojekt\" }, \"keywords\": [ \"example\", \"simple\" ], \"groups\": [ ... ], \"users\": [ ... ], \"lists\": [ ... ], \"ontologies\": [ ... ] } } prefixes object (optional) \"prefixes\": { \"prefix\": \"<iri>\", ...} The prefixes object contains the prefixes of external ontologies that are used in the current file. All prefixes are composed of the prefix and a URI. The prefix is used as namespace so one does not have to write the fully qualified name of the referenced object each time it is used. Instead of writing a property called \"familyName\" as http://xmlns.com/foaf/0.1/familyName one can simply write foaf:familyName . { \"prefixes\" : { \"foaf\" : \"http://xmlns.com/foaf/0.1/\" , \"dcterms\" : \"http://purl.org/dc/terms/\" } } It is not necessary to define prefixes for the ontologies that are defined in the same file. Ontologies in the same file can be referenced by their name. See this section for more information about referencing ontologies. \"$schema\" object (required) The $schema object refers to the JSON schema for DSP data model definitions and is mandatory. \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/project.json\" \"project\" object (required) \"project\": {\"key\": \"<value>\", ...} The project object contains the basic metadata about the project. The following fields are required: shortcode shortname longname keywords ontologies The following fields are optional (if one or more of these fields are not used, they should be omitted): descriptions lists groups users \"project\" object in detail In the following section, all fields of the project object are explained in detail. Shortcode (required) \"shortcode\": \"<4-hex-characters>\" The shortcode has to be unique and is represented by a 4 digit hexadecimal string. The shortcode has to be provided by the DaSCH. Shortname (required) \"shortname\": \"<string>\" The shortname has to be unique. It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character). Longname (required) \"longname\": \"<string>\" The longname is a string that provides the full name of the project. Descriptions (required) \"descriptions\": {\"<lang>\": \"<string>\", ...} The description is represented as a collection of strings with language tags (currently, \"en\", \"de\", \"fr\", \"it\", and \"rm\" are supported). Keywords (required) \"keywords\": [\"<string>\", \"<string>\", ...] Keywords are represented as an array of strings and are used to describe and/or tag the project. Groups (optional) \"groups\": [<group-definition>, <group-definition>,...] The groups object contains project specific group definitions. As opposed to the built-in groups , the membership of the users to the project specific groups can be freely chosen by the ProjectAdmin . A project may define several groups such as \"student-assistant\", \"editors\", etc. in order to provide their members specific permissions. The groups that were created here are then available in the XML file in the <permissions> element . A project specific group definition has the following elements: name (mandatory): name of the group descriptions (mandatory): description of the group with language tags in the form \"descriptions\": {\"<lang>\": \"<string>\", ...} (currently, \"en\", \"de\", \"fr\", \"it\", and \"rm\" are supported) selfjoin (optional): true if users are allowed to join the group themselves, false (default) if a ProjectAdmin has to add them status (optional): true (default) if the group is active, false if the group is inactive Example: { \"groups\" : [ { \"name\" : \"biz-editors\" , \"descriptions\" : { \"en\" : \"Editors for the BiZ project\" }, \"selfjoin\" : false , \"status\" : true } ] } Users (optional) \"users\": [<user-definition>, <user-definition>,...] This object contains user definitions. A user has the following elements: username : username used for login email : email that identifies the user, has to be unique within DSP givenName : first name of the user familyName : surname of the user password : password of the user lang : the default language of the user: \"en\", \"de\", \"fr\", \"it\", \"rm\" (optional, default: \"en\") groups (optional): List of groups the user belongs to. The group names must be provided in one of the following forms: other_project_shortname:groupname :groupname (for groups defined in the current JSON project file) SystemAdmin (the most powerful group, built-in into DSP) projects (optional): List of projects the user belongs to. The project name has to be followed by a : and either member or admin . This indicates if the new user has admin rights in the given project or is an ordinary user. myproject:admin would add the user as admin to the project myproject . The project defined in the same JSON project file can be omitted, so only :admin or :member is enough. Note that in order to give a user :admin rights, he also needs to be a :member of the project. If projects is omitted, the user won't be part in any project. status (optional): true (default) if the user is active, false if the user is deleted/inactive Example: { \"users\" : [ { \"username\" : \"bizedit\" , \"email\" : \"bizedit@test.org\" , \"givenName\" : \"biz-given\" , \"familyName\" : \"biz-family\" , \"password\" : \"biz1234\" , \"lang\" : \"en\" , \"groups\" : [ \":biz-editors\" , \"SystemAdmin\" ], \"projects\" : [ \":admin\" , \"otherProject:member\" ], \"status\" : true } ] } The users element is optional. If not used, it should be omitted. Lists (optional) \"lists\": [<list-definition>,<list-definition>,...] Lists can be used to provide controlled vocabularies. They can be flat or hierarchical. One advantage of the use of hierarchical lists is that it allows a user to sub-categorize objects. This helps in the formulation of specific search requests. If there is a list node \"Vocal music\" and sub-nodes \"Song\" and \"Opera\", a search for \"Vocal Music\" would return objects classified as \"Song\" and \"Opera\". But a search for \"Song\" would only return objects classified as \"Song\". The \"lists\" section is an array of list definitions. A list definition has one root node whose name is used to identify the list. The children of the root node are the list nodes. If the list is hierarchical, the list nodes can have children, and these children can again have children, etc. When a project defines a list, resources can use the list values by defining a list property, e.g. a property with object \"ListValue\" . A node of a list may have the following elements: name (mandatory): Name of the node. Has to be unique within the entire \"lists\" section. labels (mandatory): Label with language tags in the form {\"<lang>\": \"<label>\", \"<lang>\": \"<label>\", ... } . At least one language needs to be specified. Currently, \"de\", \"en\", \"fr\", \"it\", and \"rm\" are supported. comments (mandatory for root node, optional for all other nodes): Comment with language tags in the form {\"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } . Currently, \"de\", \"en\", \"fr\", \"it\", and \"rm\" are supported. nodes (optional): Array of sub-nodes. Example of a \"lists\" section that contains the two lists \"color\" and \"category\": { \"lists\" : [ { \"name\" : \"color\" , \"labels\" : { \"de\" : \"Farbe\" , \"en\" : \"Color\" }, \"comments\" : { \"de\" : \"Eine Liste mit einigen Farben\" , \"en\" : \"A list with some colors\" }, \"nodes\" : [ { \"name\" : \"red\" , \"labels\" : { \"de\" : \"rot\" , \"en\" : \"red\" } }, { \"name\" : \"yellow\" , \"labels\" : { \"de\" : \"gelb\" , \"en\" : \"yellow\" } }, { \"name\" : \"blue\" , \"labels\" : { \"de\" : \"blau\" , \"en\" : \"blue\" } }, { \"name\" : \"green\" , \"labels\" : { \"de\" : \"gr\u00fcn\" , \"en\" : \"green\" } } ] }, { \"name\" : \"category\" , \"labels\" : { \"de\" : \"Kategorie\" , \"en\" : \"category\" }, \"comments\" : { \"de\" : \"Eine Liste mit Kategorien\" , \"en\" : \"A list with categories\" }, \"nodes\" : [ { \"name\" : \"artwork\" , \"labels\" : { \"de\" : \"Kunstwerk\" , \"en\" : \"artwork\" } }, { \"name\" : \"vehicles\" , \"labels\" : { \"de\" : \"Fahrzeuge\" , \"en\" : \"vehicles\" } }, { \"name\" : \"nature\" , \"labels\" : { \"de\" : \"Natur\" , \"en\" : \"nature\" }, \"nodes\" : [ { \"name\" : \"humanes\" , \"labels\" : { \"de\" : \"Menschen\" , \"en\" : \"Humanes\" } }, { \"name\" : \"animals\" , \"labels\" : { \"de\" : \"Tiere\" , \"en\" : \"Animals\" }, \"nodes\" : [ { \"name\" : \"mammals\" , \"labels\" : { \"de\" : \"S\u00e4ugetiere\" , \"en\" : \"Mammals\" } }, { \"name\" : \"insects\" , \"labels\" : { \"de\" : \"Insekten\" , \"en\" : \"Insects\" } }, { \"name\" : \"birds\" , \"labels\" : { \"de\" : \"V\u00f6gel\" , \"en\" : \"Birds\" } }, { \"name\" : \"amphibians\" , \"labels\" : { \"de\" : \"Ambhibien\" , \"en\" : \"Amphibians\" } }, { \"name\" : \"reptiles\" , \"labels\" : { \"de\" : \"Reptilien\" , \"en\" : \"Reptiles\" } } ] }, { \"name\" : \"plants\" , \"labels\" : { \"de\" : \"Pflanzen\" , \"en\" : \"Plants\" } }, { \"name\" : \"weather\" , \"labels\" : { \"de\" : \"Wetter\" , \"en\" : \"Weather\" } }, { \"name\" : \"physics\" , \"labels\" : { \"de\" : \"Physik\" , \"en\" : \"Physics\" } } ] } ] } ] } Lists from Excel Instead of being described in JSON, a list can be imported from one or several Excel files. In this case, the nodes element of the root node consists of {\"folder\": \"<path-to-folder-containing-the-excel-files>\"} . In the above example, the list \"color\" could be imported as follows: { \"lists\" : [ { \"name\" : \"color\" , \"labels\" : { \"de\" : \"Farbe\" , \"en\" : \"Color\" }, \"comments\" : { \"de\" : \"Eine Liste mit einigen Farben\" , \"en\" : \"A list with some colors\" }, \"nodes\" : { \"folder\" : \"path-to-folder\" } }, { \"name\" : \"category\" , \"labels\" : { \"de\" : \"Kategorie\" , \"en\" : \"category\" }, \"comments\" : { \"de\" : \"Eine Liste mit Kategorien\" , \"en\" : \"A list with categories\" }, \"nodes\" : [ \"...\" ] } ] } To do so, it would be necessary to place the following two files into the folder \"path-to-folder\": The expected format of the Excel files is documented here . The only difference to the explanations there is that column A of the Excel worksheet is not interpreted as list name (root node), but as node name of the first children level below the root node. Ontologies (required) \"ontologies\": [<ontology-definition>, <ontology-definition>, ...] Inside the ontologies array, a project may have multiple ontology definitions. An ontology definition consists of the following fields: name label properties resources The ontologies array is documented here Fully fleshed out example of a JSON project file DaSCH provides you with two example repositories that contain everything which is necessary to create a project and upload data. Both of them also contain a JSON project definition file. You can find them here: https://github.com/dasch-swiss/0123-import-scripts https://github.com/dasch-swiss/082E-rosetta-scripts In addition, there is another complete example of a JSON project file here: { \"prefixes\" : { \"foaf\" : \"http://xmlns.com/foaf/0.1/\" , \"dcterms\" : \"http://purl.org/dc/terms/\" }, \"$schema\" : \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/project.json\" , \"project\" : { \"shortcode\" : \"0170\" , \"shortname\" : \"teimp\" , \"longname\" : \"Test Import\" , \"descriptions\" : { \"en\" : \"This is a project for testing the creation of ontologies and data\" , \"de\" : \"Dies ist ein Projekt, um die Erstellung von Ontologien und Datenimport zu testen\" }, \"keywords\" : [ \"test\" , \"import\" ], \"lists\" : [ { \"name\" : \"orgtype\" , \"labels\" : { \"en\" : \"Organization Type\" , \"de\" : \"Organisationsart\" }, \"comments\" : { \"en\" : \"List of different organization types\" , \"de\" : \"Liste unterschiedlicher Organisationstypen\" }, \"nodes\" : [ { \"name\" : \"business\" , \"labels\" : { \"en\" : \"Commerce\" , \"de\" : \"Handel\" }, \"nodes\" : [ { \"name\" : \"transport\" , \"labels\" : { \"en\" : \"Transportation\" , \"de\" : \"Transport\" } }, { \"name\" : \"finances\" , \"labels\" : { \"en\" : \"Finances\" , \"de\" : \"Finanzen\" } } ] }, { \"name\" : \"society\" , \"labels\" : { \"en\" : \"Society\" , \"de\" : \"Gesellschaft\" } } ] } ], \"ontologies\" : [ { \"name\" : \"teimp\" , \"label\" : \"Test import ontology\" , \"properties\" : [ { \"name\" : \"firstname\" , \"super\" : [ \"hasValue\" , \"foaf:givenName\" ], \"object\" : \"TextValue\" , \"labels\" : { \"en\" : \"Firstname\" , \"de\" : \"Vorname\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"size\" : 24 , \"maxlength\" : 32 } }, { \"name\" : \"lastname\" , \"super\" : [ \"hasValue\" , \"foaf:familyName\" ], \"object\" : \"TextValue\" , \"labels\" : { \"en\" : \"Lastname\" , \"de\" : \"Nachname\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"size\" : 24 , \"maxlength\" : 64 } }, { \"name\" : \"member\" , \"super\" : [ \"hasLinkTo\" ], \"object\" : \":organization\" , \"labels\" : { \"en\" : \"member of\" , \"de\" : \"Mitglied von\" }, \"gui_element\" : \"Searchbox\" }, { \"name\" : \"name\" , \"super\" : [ \"hasValue\" ], \"object\" : \"TextValue\" , \"labels\" : { \"en\" : \"Name\" , \"de\" : \"Name\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"size\" : 64 , \"maxlength\" : 64 } }, { \"name\" : \"orgtype\" , \"super\" : [ \"hasValue\" ], \"object\" : \"ListValue\" , \"labels\" : { \"en\" : \"Organization type\" , \"de\" : \"Organisationstyp\" }, \"comments\" : { \"en\" : \"Type of organization\" , \"de\" : \"Art der Organisation\" }, \"gui_element\" : \"List\" , \"gui_attributes\" : { \"hlist\" : \"orgtype\" } } ], \"resources\" : [ { \"name\" : \"person\" , \"super\" : \"Resource\" , \"labels\" : { \"en\" : \"Person\" , \"de\" : \"Person\" }, \"comments\" : { \"en\" : \"Represents a human being\" , \"de\" : \"Repr\u00e4sentiert eine Person/Menschen\" }, \"cardinalities\" : [ { \"propname\" : \":firstname\" , \"gui_order\" : 1 , \"cardinality\" : \"1\" }, { \"propname\" : \":lastname\" , \"gui_order\" : 2 , \"cardinality\" : \"1\" }, { \"propname\" : \":member\" , \"gui_order\" : 3 , \"cardinality\" : \"0-n\" } ] }, { \"name\" : \"organization\" , \"super\" : \"Resource\" , \"labels\" : { \"en\" : \"Organization\" , \"de\" : \"Organisation\" }, \"comments\" : { \"en\" : \"Denotes an organizational unit\" , \"de\" : \"Eine Institution oder Tr\u00e4gerschaft\" }, \"cardinalities\" : [ { \"propname\" : \":name\" , \"gui_order\" : 1 , \"cardinality\" : \"1-n\" }, { \"propname\" : \":orgtype\" , \"gui_order\" : 2 , \"cardinality\" : \"1-n\" } ] } ] } ] } }","title":"Overview"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#json-project-definition-format","text":"This document describes the structure of a JSON project definition file that can be uploaded to a DSP server with the create command. A project on a DSP server is like a container for data. It defines some basic metadata, the data model(s) and optionally the user(s) who will be able to access the data. After the creation of a project, data can be uploaded that conforms with the data model(s). This documentation is divided into the following parts: Overview of the project description file (this page) The \"ontologies\" section explained in detail Some caveats to have in mind","title":"JSON project definition format"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#a-short-overview","text":"A complete project definition looks like this: { \"prefixes\": { \"foaf\": \"http://xmlns.com/foaf/0.1/\", \"dcterms\": \"http://purl.org/dc/terms/\" }, \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/project.json\", \"project\": { \"shortcode\": \"0123\", \"shortname\": \"BiZ\", \"longname\": \"Bildung in Zahlen\", \"descriptions\": { \"en\": \"This is a simple example project\", \"de\": \"Dies ist ein einfaches Beispielprojekt\" }, \"keywords\": [ \"example\", \"simple\" ], \"groups\": [ ... ], \"users\": [ ... ], \"lists\": [ ... ], \"ontologies\": [ ... ] } }","title":"A short overview"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#prefixes-object","text":"(optional) \"prefixes\": { \"prefix\": \"<iri>\", ...} The prefixes object contains the prefixes of external ontologies that are used in the current file. All prefixes are composed of the prefix and a URI. The prefix is used as namespace so one does not have to write the fully qualified name of the referenced object each time it is used. Instead of writing a property called \"familyName\" as http://xmlns.com/foaf/0.1/familyName one can simply write foaf:familyName . { \"prefixes\" : { \"foaf\" : \"http://xmlns.com/foaf/0.1/\" , \"dcterms\" : \"http://purl.org/dc/terms/\" } } It is not necessary to define prefixes for the ontologies that are defined in the same file. Ontologies in the same file can be referenced by their name. See this section for more information about referencing ontologies.","title":"prefixes object"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#schema-object","text":"(required) The $schema object refers to the JSON schema for DSP data model definitions and is mandatory. \"$schema\": \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/project.json\"","title":"\"$schema\" object"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#project-object","text":"(required) \"project\": {\"key\": \"<value>\", ...} The project object contains the basic metadata about the project. The following fields are required: shortcode shortname longname keywords ontologies The following fields are optional (if one or more of these fields are not used, they should be omitted): descriptions lists groups users","title":"\"project\" object"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#project-object-in-detail","text":"In the following section, all fields of the project object are explained in detail.","title":"\"project\" object in detail"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#shortcode","text":"(required) \"shortcode\": \"<4-hex-characters>\" The shortcode has to be unique and is represented by a 4 digit hexadecimal string. The shortcode has to be provided by the DaSCH.","title":"Shortcode"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#shortname","text":"(required) \"shortname\": \"<string>\" The shortname has to be unique. It should be in the form of a xsd:NCNAME . This means a string without blanks or special characters but - and _ are allowed (although not as first character).","title":"Shortname"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#longname","text":"(required) \"longname\": \"<string>\" The longname is a string that provides the full name of the project.","title":"Longname"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#descriptions","text":"(required) \"descriptions\": {\"<lang>\": \"<string>\", ...} The description is represented as a collection of strings with language tags (currently, \"en\", \"de\", \"fr\", \"it\", and \"rm\" are supported).","title":"Descriptions"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#keywords","text":"(required) \"keywords\": [\"<string>\", \"<string>\", ...] Keywords are represented as an array of strings and are used to describe and/or tag the project.","title":"Keywords"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#groups","text":"(optional) \"groups\": [<group-definition>, <group-definition>,...] The groups object contains project specific group definitions. As opposed to the built-in groups , the membership of the users to the project specific groups can be freely chosen by the ProjectAdmin . A project may define several groups such as \"student-assistant\", \"editors\", etc. in order to provide their members specific permissions. The groups that were created here are then available in the XML file in the <permissions> element . A project specific group definition has the following elements: name (mandatory): name of the group descriptions (mandatory): description of the group with language tags in the form \"descriptions\": {\"<lang>\": \"<string>\", ...} (currently, \"en\", \"de\", \"fr\", \"it\", and \"rm\" are supported) selfjoin (optional): true if users are allowed to join the group themselves, false (default) if a ProjectAdmin has to add them status (optional): true (default) if the group is active, false if the group is inactive Example: { \"groups\" : [ { \"name\" : \"biz-editors\" , \"descriptions\" : { \"en\" : \"Editors for the BiZ project\" }, \"selfjoin\" : false , \"status\" : true } ] }","title":"Groups"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#users","text":"(optional) \"users\": [<user-definition>, <user-definition>,...] This object contains user definitions. A user has the following elements: username : username used for login email : email that identifies the user, has to be unique within DSP givenName : first name of the user familyName : surname of the user password : password of the user lang : the default language of the user: \"en\", \"de\", \"fr\", \"it\", \"rm\" (optional, default: \"en\") groups (optional): List of groups the user belongs to. The group names must be provided in one of the following forms: other_project_shortname:groupname :groupname (for groups defined in the current JSON project file) SystemAdmin (the most powerful group, built-in into DSP) projects (optional): List of projects the user belongs to. The project name has to be followed by a : and either member or admin . This indicates if the new user has admin rights in the given project or is an ordinary user. myproject:admin would add the user as admin to the project myproject . The project defined in the same JSON project file can be omitted, so only :admin or :member is enough. Note that in order to give a user :admin rights, he also needs to be a :member of the project. If projects is omitted, the user won't be part in any project. status (optional): true (default) if the user is active, false if the user is deleted/inactive Example: { \"users\" : [ { \"username\" : \"bizedit\" , \"email\" : \"bizedit@test.org\" , \"givenName\" : \"biz-given\" , \"familyName\" : \"biz-family\" , \"password\" : \"biz1234\" , \"lang\" : \"en\" , \"groups\" : [ \":biz-editors\" , \"SystemAdmin\" ], \"projects\" : [ \":admin\" , \"otherProject:member\" ], \"status\" : true } ] } The users element is optional. If not used, it should be omitted.","title":"Users"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#lists","text":"(optional) \"lists\": [<list-definition>,<list-definition>,...] Lists can be used to provide controlled vocabularies. They can be flat or hierarchical. One advantage of the use of hierarchical lists is that it allows a user to sub-categorize objects. This helps in the formulation of specific search requests. If there is a list node \"Vocal music\" and sub-nodes \"Song\" and \"Opera\", a search for \"Vocal Music\" would return objects classified as \"Song\" and \"Opera\". But a search for \"Song\" would only return objects classified as \"Song\". The \"lists\" section is an array of list definitions. A list definition has one root node whose name is used to identify the list. The children of the root node are the list nodes. If the list is hierarchical, the list nodes can have children, and these children can again have children, etc. When a project defines a list, resources can use the list values by defining a list property, e.g. a property with object \"ListValue\" . A node of a list may have the following elements: name (mandatory): Name of the node. Has to be unique within the entire \"lists\" section. labels (mandatory): Label with language tags in the form {\"<lang>\": \"<label>\", \"<lang>\": \"<label>\", ... } . At least one language needs to be specified. Currently, \"de\", \"en\", \"fr\", \"it\", and \"rm\" are supported. comments (mandatory for root node, optional for all other nodes): Comment with language tags in the form {\"<lang>\": \"<comment>\", \"<lang>\": \"<comment>\", ... } . Currently, \"de\", \"en\", \"fr\", \"it\", and \"rm\" are supported. nodes (optional): Array of sub-nodes. Example of a \"lists\" section that contains the two lists \"color\" and \"category\": { \"lists\" : [ { \"name\" : \"color\" , \"labels\" : { \"de\" : \"Farbe\" , \"en\" : \"Color\" }, \"comments\" : { \"de\" : \"Eine Liste mit einigen Farben\" , \"en\" : \"A list with some colors\" }, \"nodes\" : [ { \"name\" : \"red\" , \"labels\" : { \"de\" : \"rot\" , \"en\" : \"red\" } }, { \"name\" : \"yellow\" , \"labels\" : { \"de\" : \"gelb\" , \"en\" : \"yellow\" } }, { \"name\" : \"blue\" , \"labels\" : { \"de\" : \"blau\" , \"en\" : \"blue\" } }, { \"name\" : \"green\" , \"labels\" : { \"de\" : \"gr\u00fcn\" , \"en\" : \"green\" } } ] }, { \"name\" : \"category\" , \"labels\" : { \"de\" : \"Kategorie\" , \"en\" : \"category\" }, \"comments\" : { \"de\" : \"Eine Liste mit Kategorien\" , \"en\" : \"A list with categories\" }, \"nodes\" : [ { \"name\" : \"artwork\" , \"labels\" : { \"de\" : \"Kunstwerk\" , \"en\" : \"artwork\" } }, { \"name\" : \"vehicles\" , \"labels\" : { \"de\" : \"Fahrzeuge\" , \"en\" : \"vehicles\" } }, { \"name\" : \"nature\" , \"labels\" : { \"de\" : \"Natur\" , \"en\" : \"nature\" }, \"nodes\" : [ { \"name\" : \"humanes\" , \"labels\" : { \"de\" : \"Menschen\" , \"en\" : \"Humanes\" } }, { \"name\" : \"animals\" , \"labels\" : { \"de\" : \"Tiere\" , \"en\" : \"Animals\" }, \"nodes\" : [ { \"name\" : \"mammals\" , \"labels\" : { \"de\" : \"S\u00e4ugetiere\" , \"en\" : \"Mammals\" } }, { \"name\" : \"insects\" , \"labels\" : { \"de\" : \"Insekten\" , \"en\" : \"Insects\" } }, { \"name\" : \"birds\" , \"labels\" : { \"de\" : \"V\u00f6gel\" , \"en\" : \"Birds\" } }, { \"name\" : \"amphibians\" , \"labels\" : { \"de\" : \"Ambhibien\" , \"en\" : \"Amphibians\" } }, { \"name\" : \"reptiles\" , \"labels\" : { \"de\" : \"Reptilien\" , \"en\" : \"Reptiles\" } } ] }, { \"name\" : \"plants\" , \"labels\" : { \"de\" : \"Pflanzen\" , \"en\" : \"Plants\" } }, { \"name\" : \"weather\" , \"labels\" : { \"de\" : \"Wetter\" , \"en\" : \"Weather\" } }, { \"name\" : \"physics\" , \"labels\" : { \"de\" : \"Physik\" , \"en\" : \"Physics\" } } ] } ] } ] }","title":"Lists"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#lists-from-excel","text":"Instead of being described in JSON, a list can be imported from one or several Excel files. In this case, the nodes element of the root node consists of {\"folder\": \"<path-to-folder-containing-the-excel-files>\"} . In the above example, the list \"color\" could be imported as follows: { \"lists\" : [ { \"name\" : \"color\" , \"labels\" : { \"de\" : \"Farbe\" , \"en\" : \"Color\" }, \"comments\" : { \"de\" : \"Eine Liste mit einigen Farben\" , \"en\" : \"A list with some colors\" }, \"nodes\" : { \"folder\" : \"path-to-folder\" } }, { \"name\" : \"category\" , \"labels\" : { \"de\" : \"Kategorie\" , \"en\" : \"category\" }, \"comments\" : { \"de\" : \"Eine Liste mit Kategorien\" , \"en\" : \"A list with categories\" }, \"nodes\" : [ \"...\" ] } ] } To do so, it would be necessary to place the following two files into the folder \"path-to-folder\": The expected format of the Excel files is documented here . The only difference to the explanations there is that column A of the Excel worksheet is not interpreted as list name (root node), but as node name of the first children level below the root node.","title":"Lists from Excel"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#ontologies","text":"(required) \"ontologies\": [<ontology-definition>, <ontology-definition>, ...] Inside the ontologies array, a project may have multiple ontology definitions. An ontology definition consists of the following fields: name label properties resources The ontologies array is documented here","title":"Ontologies"},{"location":"DSP-TOOLS/file-formats/json-project/overview/#fully-fleshed-out-example-of-a-json-project-file","text":"DaSCH provides you with two example repositories that contain everything which is necessary to create a project and upload data. Both of them also contain a JSON project definition file. You can find them here: https://github.com/dasch-swiss/0123-import-scripts https://github.com/dasch-swiss/082E-rosetta-scripts In addition, there is another complete example of a JSON project file here: { \"prefixes\" : { \"foaf\" : \"http://xmlns.com/foaf/0.1/\" , \"dcterms\" : \"http://purl.org/dc/terms/\" }, \"$schema\" : \"https://raw.githubusercontent.com/dasch-swiss/dsp-tools/main/src/dsp_tools/schemas/project.json\" , \"project\" : { \"shortcode\" : \"0170\" , \"shortname\" : \"teimp\" , \"longname\" : \"Test Import\" , \"descriptions\" : { \"en\" : \"This is a project for testing the creation of ontologies and data\" , \"de\" : \"Dies ist ein Projekt, um die Erstellung von Ontologien und Datenimport zu testen\" }, \"keywords\" : [ \"test\" , \"import\" ], \"lists\" : [ { \"name\" : \"orgtype\" , \"labels\" : { \"en\" : \"Organization Type\" , \"de\" : \"Organisationsart\" }, \"comments\" : { \"en\" : \"List of different organization types\" , \"de\" : \"Liste unterschiedlicher Organisationstypen\" }, \"nodes\" : [ { \"name\" : \"business\" , \"labels\" : { \"en\" : \"Commerce\" , \"de\" : \"Handel\" }, \"nodes\" : [ { \"name\" : \"transport\" , \"labels\" : { \"en\" : \"Transportation\" , \"de\" : \"Transport\" } }, { \"name\" : \"finances\" , \"labels\" : { \"en\" : \"Finances\" , \"de\" : \"Finanzen\" } } ] }, { \"name\" : \"society\" , \"labels\" : { \"en\" : \"Society\" , \"de\" : \"Gesellschaft\" } } ] } ], \"ontologies\" : [ { \"name\" : \"teimp\" , \"label\" : \"Test import ontology\" , \"properties\" : [ { \"name\" : \"firstname\" , \"super\" : [ \"hasValue\" , \"foaf:givenName\" ], \"object\" : \"TextValue\" , \"labels\" : { \"en\" : \"Firstname\" , \"de\" : \"Vorname\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"size\" : 24 , \"maxlength\" : 32 } }, { \"name\" : \"lastname\" , \"super\" : [ \"hasValue\" , \"foaf:familyName\" ], \"object\" : \"TextValue\" , \"labels\" : { \"en\" : \"Lastname\" , \"de\" : \"Nachname\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"size\" : 24 , \"maxlength\" : 64 } }, { \"name\" : \"member\" , \"super\" : [ \"hasLinkTo\" ], \"object\" : \":organization\" , \"labels\" : { \"en\" : \"member of\" , \"de\" : \"Mitglied von\" }, \"gui_element\" : \"Searchbox\" }, { \"name\" : \"name\" , \"super\" : [ \"hasValue\" ], \"object\" : \"TextValue\" , \"labels\" : { \"en\" : \"Name\" , \"de\" : \"Name\" }, \"gui_element\" : \"SimpleText\" , \"gui_attributes\" : { \"size\" : 64 , \"maxlength\" : 64 } }, { \"name\" : \"orgtype\" , \"super\" : [ \"hasValue\" ], \"object\" : \"ListValue\" , \"labels\" : { \"en\" : \"Organization type\" , \"de\" : \"Organisationstyp\" }, \"comments\" : { \"en\" : \"Type of organization\" , \"de\" : \"Art der Organisation\" }, \"gui_element\" : \"List\" , \"gui_attributes\" : { \"hlist\" : \"orgtype\" } } ], \"resources\" : [ { \"name\" : \"person\" , \"super\" : \"Resource\" , \"labels\" : { \"en\" : \"Person\" , \"de\" : \"Person\" }, \"comments\" : { \"en\" : \"Represents a human being\" , \"de\" : \"Repr\u00e4sentiert eine Person/Menschen\" }, \"cardinalities\" : [ { \"propname\" : \":firstname\" , \"gui_order\" : 1 , \"cardinality\" : \"1\" }, { \"propname\" : \":lastname\" , \"gui_order\" : 2 , \"cardinality\" : \"1\" }, { \"propname\" : \":member\" , \"gui_order\" : 3 , \"cardinality\" : \"0-n\" } ] }, { \"name\" : \"organization\" , \"super\" : \"Resource\" , \"labels\" : { \"en\" : \"Organization\" , \"de\" : \"Organisation\" }, \"comments\" : { \"en\" : \"Denotes an organizational unit\" , \"de\" : \"Eine Institution oder Tr\u00e4gerschaft\" }, \"cardinalities\" : [ { \"propname\" : \":name\" , \"gui_order\" : 1 , \"cardinality\" : \"1-n\" }, { \"propname\" : \":orgtype\" , \"gui_order\" : 2 , \"cardinality\" : \"1-n\" } ] } ] } ] } }","title":"Fully fleshed out example of a JSON project file"},{"location":"community/about-us/","text":"About us Since 2017, the Data and Service Center for the Humanities (DaSCH) has been a member of the Swiss Academy of Humanities and Social Sciences. The main task of the institution is to operate a platform for humanities research data that ensures access to this data. In addition, the networking of data with other databases is to be promoted (linked open data), thus creating added value for research and the interested public. Get more information on our website: https://dasch.swiss Follow us on GitHub Twitter Facebook","title":"About us"},{"location":"community/about-us/#about-us","text":"Since 2017, the Data and Service Center for the Humanities (DaSCH) has been a member of the Swiss Academy of Humanities and Social Sciences. The main task of the institution is to operate a platform for humanities research data that ensures access to this data. In addition, the networking of data with other databases is to be promoted (linked open data), thus creating added value for research and the interested public. Get more information on our website: https://dasch.swiss Follow us on GitHub Twitter Facebook","title":"About us"},{"location":"community/product-updates/","text":"Product Updates You'll find the general list of features, updates and bug fixes of the DaSCH Service Platform (DSP) on our confluence DSP Changelog page . Each DSP repository has also its own release notes: DSP-API release notes DSP-JS-LIB release notes DSP-APP release notes DSP-TOOLS release notes SIPI release notes","title":"Product Updates"},{"location":"community/product-updates/#product-updates","text":"You'll find the general list of features, updates and bug fixes of the DaSCH Service Platform (DSP) on our confluence DSP Changelog page . Each DSP repository has also its own release notes: DSP-API release notes DSP-JS-LIB release notes DSP-APP release notes DSP-TOOLS release notes SIPI release notes","title":"Product Updates"},{"location":"developers/getting-started/","text":"Developer Overview Getting started with the DaSCH Service Platform (DSP) Local Development Environment At the DaSCH, the principal development environment is Apple macOS . Each developer machine should have the following prerequisites installed: Docker Desktop: https://www.docker.com/products/docker-desktop Homebrew: https://brew.sh , which can be used to install: git expect sbt python (Python 3) node Java AdoptOpenJDK 11 To install, follow these steps: brew tap AdoptOpenJDK/openjdk brew cask install AdoptOpenJDK/openjdk/adoptopenjdk11 To pin the version of Java, you can add this environment variable to your startup script (bashrc, etc.): export JAVA_HOME = ` /usr/libexec/java_home -v 11 ` You can also use jEnv to use different versions of Java for different things. Bazel build tools To install, follow these steps: npm install -g @bazel/bazelisk npm install -g @bazel/buildozer This will install bazelisk which is a wrapper to the bazel binary. It will, when the bazel command ir run, automatically install the supported Bazel version, defined in the .bazelversion file in the root of the knora-api repository. Clone DSP-API from GitHub To clone DSP-API from Github open a terminal window and change to the directory where you intend to install DSP-API. Then type git clone https://github.com/dasch-swiss/dsp-api.git This will install the directory dsp-api with subdirectories in the chosen directory. Bazel Commands Build webapi : # build webapi bazel build //webapi/... # run all webapi tests bazel test //webapi/... Build the docker image From inside the cloned dsp-api repository folder, create a test repository: make init-db-test Then start the DSP stack: make stack-up This should start the complete Knora stack consisting of Fuseki, DSP-API, Redis, and Sipi. If everything worked properly, the Dashboard in Docker Desktop should show those containers running. To stop everything again, type make stack-down Please see the Makefile for other useful make targets. Build Structure The Bazel build is defined in a number of files: WORKSPACE - here are external dependencies defined BUILD - there are a number of BUILD files throughout the directory structure where each represents a separate package responsible for everything underneath. *.bzl - custom extensions loaded and used in BUILD files For a more detailed discussion, please see the Concepts and Terminology section in the Bazel documentation. Some Notes Override some .bazelrc settings in your own copy created at ~/.bazelrc : build --action_env = PATH = \"/usr/local/bin:/opt/local/bin:/usr/bin:/bin\" build --strategy = Scalac = worker build --worker_sandboxing query --package_path %workspace%:/usr/local/bin/bazel/base_workspace startup --host_jvm_args = -Djavax.net.ssl.trustStore = /Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home/lib/security/cacerts \\ --host_jvm_args = -Djavax.net.ssl.trustStorePassword = changeit Add Bazel Plugin and Project to IntelliJ The latest version of the Bazel plugin supports only IntelliJ upto version 2020.01.04 . After you make sure to run this version of IntelliJ, install the plugin from inside IntelliJ. Click on File -> Import Bazel Project and select twice next . Uncomment the Scala language and click Finish . Run single spec: bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec Run single spec and only tests containing gaga in the description bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec --test_arg = -z --test_arg = \"gaga\" Start Scala REPL bazel run //webapi:main_library_repl Build stamping By default, Bazel tries not to include anything about the system state in build outputs. However, released binaries and libraries often want to include something like the version they were built at or the branch or tag they came from. To reconcile this, Bazel has an option called the workspace status command . This command is run outside of any sandboxes on the local machine, so it can access anything about your source control, OS, or anything else you might want to include. It then dumps its output into bazel-out/volatile-status.txt , which you can use (and certain language rulesets provide support for accessing from code). Our workspace status command is defined in //tools/buildstamp/get_workspace_status . To use it on every bazel command, we need to supply it to each Bazel invocation, which is done by the following line found in .bazelrc : build --workspace_status_command = tools/buildstamp/get_workspace_status --stamp = yes Any line added to .bazelrc is invoked on each corresponding command. The //tools/buildstamp/get_workspace_status emits additional values to bazel-out/volatile-status.txt whereas BUILD_TIMESTAMP is emitted by Bazel itself: BUILD_SCM_REVISION 2d6df6c8fe2d56e3712eb26763f9727916a60164 BUILD_SCM_STATUS Modified BUILD_SCM_TAG v13.0.0-rc.21-17-g2d6df6c-dirty BUILD_TIMESTAMP 1604401028 The value of BUILD_SCM_TAG is used in //webapi/src/main/scala/org/knora/webapi/http/version/versioninfo , which emits a JAR containing VersionInfo.scala . This file is generated based on VersionInfoTemplate.scala found in the same Bazel package. In short, the versioninfo target producing the JAR library depends on the version_info_with_build_tag target which emits the VersionInfo.scala file which has the {BUILD_TAG} variable replaced by the current value of BUILD_SCM_TAG . In an intermediary step, the version_info_without_build_tag target, replaces variables coming from //third_party:versions.bzl . Visualize your Build Add the following line to your ~/.bazelrc: query --package_path %workspace%: [ PATH TO BAZEL ] /base_workspace # set the path to the bazel binary Run bazel query inside your project directory, asking it to search for all dependencies of //:main (or however the label is to your target of interest): bazel query 'deps(//:main)' --output graph > graph.in This creates a file called graph.in , which is a text representation of the build graph. You can use dot (install with brew install graphviz ) to create a png: dot -Tpng < graph.in > graph.png","title":"Getting Started"},{"location":"developers/getting-started/#developer-overview","text":"","title":"Developer Overview"},{"location":"developers/getting-started/#getting-started-with-the-dasch-service-platform-dsp","text":"","title":"Getting started with the DaSCH Service Platform (DSP)"},{"location":"developers/getting-started/#local-development-environment","text":"At the DaSCH, the principal development environment is Apple macOS . Each developer machine should have the following prerequisites installed: Docker Desktop: https://www.docker.com/products/docker-desktop Homebrew: https://brew.sh , which can be used to install: git expect sbt python (Python 3) node","title":"Local Development Environment"},{"location":"developers/getting-started/#java-adoptopenjdk-11","text":"To install, follow these steps: brew tap AdoptOpenJDK/openjdk brew cask install AdoptOpenJDK/openjdk/adoptopenjdk11 To pin the version of Java, you can add this environment variable to your startup script (bashrc, etc.): export JAVA_HOME = ` /usr/libexec/java_home -v 11 ` You can also use jEnv to use different versions of Java for different things.","title":"Java AdoptOpenJDK 11"},{"location":"developers/getting-started/#bazel-build-tools","text":"To install, follow these steps: npm install -g @bazel/bazelisk npm install -g @bazel/buildozer This will install bazelisk which is a wrapper to the bazel binary. It will, when the bazel command ir run, automatically install the supported Bazel version, defined in the .bazelversion file in the root of the knora-api repository.","title":"Bazel build tools"},{"location":"developers/getting-started/#clone-dsp-api-from-github","text":"To clone DSP-API from Github open a terminal window and change to the directory where you intend to install DSP-API. Then type git clone https://github.com/dasch-swiss/dsp-api.git This will install the directory dsp-api with subdirectories in the chosen directory.","title":"Clone DSP-API from GitHub"},{"location":"developers/getting-started/#bazel-commands","text":"Build webapi : # build webapi bazel build //webapi/... # run all webapi tests bazel test //webapi/...","title":"Bazel Commands"},{"location":"developers/getting-started/#build-the-docker-image","text":"From inside the cloned dsp-api repository folder, create a test repository: make init-db-test Then start the DSP stack: make stack-up This should start the complete Knora stack consisting of Fuseki, DSP-API, Redis, and Sipi. If everything worked properly, the Dashboard in Docker Desktop should show those containers running. To stop everything again, type make stack-down Please see the Makefile for other useful make targets.","title":"Build the docker image"},{"location":"developers/getting-started/#build-structure","text":"The Bazel build is defined in a number of files: WORKSPACE - here are external dependencies defined BUILD - there are a number of BUILD files throughout the directory structure where each represents a separate package responsible for everything underneath. *.bzl - custom extensions loaded and used in BUILD files For a more detailed discussion, please see the Concepts and Terminology section in the Bazel documentation.","title":"Build Structure"},{"location":"developers/getting-started/#some-notes","text":"Override some .bazelrc settings in your own copy created at ~/.bazelrc : build --action_env = PATH = \"/usr/local/bin:/opt/local/bin:/usr/bin:/bin\" build --strategy = Scalac = worker build --worker_sandboxing query --package_path %workspace%:/usr/local/bin/bazel/base_workspace startup --host_jvm_args = -Djavax.net.ssl.trustStore = /Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home/lib/security/cacerts \\ --host_jvm_args = -Djavax.net.ssl.trustStorePassword = changeit Add Bazel Plugin and Project to IntelliJ The latest version of the Bazel plugin supports only IntelliJ upto version 2020.01.04 . After you make sure to run this version of IntelliJ, install the plugin from inside IntelliJ. Click on File -> Import Bazel Project and select twice next . Uncomment the Scala language and click Finish . Run single spec: bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec Run single spec and only tests containing gaga in the description bazel test //webapi/src/test/scala/org/knora/webapi/e2e/v1:SearchV1R2RSpec --test_arg = -z --test_arg = \"gaga\" Start Scala REPL bazel run //webapi:main_library_repl","title":"Some Notes"},{"location":"developers/getting-started/#build-stamping","text":"By default, Bazel tries not to include anything about the system state in build outputs. However, released binaries and libraries often want to include something like the version they were built at or the branch or tag they came from. To reconcile this, Bazel has an option called the workspace status command . This command is run outside of any sandboxes on the local machine, so it can access anything about your source control, OS, or anything else you might want to include. It then dumps its output into bazel-out/volatile-status.txt , which you can use (and certain language rulesets provide support for accessing from code). Our workspace status command is defined in //tools/buildstamp/get_workspace_status . To use it on every bazel command, we need to supply it to each Bazel invocation, which is done by the following line found in .bazelrc : build --workspace_status_command = tools/buildstamp/get_workspace_status --stamp = yes Any line added to .bazelrc is invoked on each corresponding command. The //tools/buildstamp/get_workspace_status emits additional values to bazel-out/volatile-status.txt whereas BUILD_TIMESTAMP is emitted by Bazel itself: BUILD_SCM_REVISION 2d6df6c8fe2d56e3712eb26763f9727916a60164 BUILD_SCM_STATUS Modified BUILD_SCM_TAG v13.0.0-rc.21-17-g2d6df6c-dirty BUILD_TIMESTAMP 1604401028 The value of BUILD_SCM_TAG is used in //webapi/src/main/scala/org/knora/webapi/http/version/versioninfo , which emits a JAR containing VersionInfo.scala . This file is generated based on VersionInfoTemplate.scala found in the same Bazel package. In short, the versioninfo target producing the JAR library depends on the version_info_with_build_tag target which emits the VersionInfo.scala file which has the {BUILD_TAG} variable replaced by the current value of BUILD_SCM_TAG . In an intermediary step, the version_info_without_build_tag target, replaces variables coming from //third_party:versions.bzl .","title":"Build stamping"},{"location":"developers/getting-started/#visualize-your-build","text":"Add the following line to your ~/.bazelrc: query --package_path %workspace%: [ PATH TO BAZEL ] /base_workspace # set the path to the bazel binary Run bazel query inside your project directory, asking it to search for all dependencies of //:main (or however the label is to your target of interest): bazel query 'deps(//:main)' --output graph > graph.in This creates a file called graph.in , which is a text representation of the build graph. You can use dot (install with brew install graphviz ) to create a png: dot -Tpng < graph.in > graph.png","title":"Visualize your Build"},{"location":"developers/introduction/","text":"Introduction to DSP-API The main software framework in the back-end of the DaSCH Service Platform is called DSP-API (previously Knora). DSP-API is a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP-API aims to solve key problems in the long-term preservation and reuse of humanities data: Traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. Downloading the data to check whether the data are interesting or not is time-consuming and makes it impractical to reuse data from many different sources. DSP-API solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP-API, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different data formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old data files, or even all the operating systems that these programs ran on. Instead of preserving all these data formats, DSP-API supports the conversion of all sorts of data to a small number of formats that are suitable for long-term preservation, and that maintain the data\u2019s meaning and structure: Non-binary data is stored as R esource D escription F ramework ( RDF ), in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. For a concise information about RDF basics see here . Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by the media server SIPI , with metadata stored in the triplestore. For a concise information about SIPI see here . Moreover, DSP-API has built-in support for special data structures that occur on a regular basis in humanities data: persistent links, calender-independent dates and flexible searchable text markup. Persistent links are a very important feature. If a resource is changed, a new resource will be created in DSP-API. The older version remains available and citable, there will be no dead links. This means that if in a publication an older version is referenced, the cited version still can be displayed, but there will be a notice that a newer version exists with the corresponding link attached to it. A date could be given in any kind of calendar - e.g. the Julian, Gregorian, Jewish or Islamic - just to name the most frequent ones. DSP-API stores dates using the Julian day count that was established by astronomers. Use of the Julian day count easily allows for conversion from one calendar into another and to calculate distances between two dates. It is possible to search for a date in one calendar and to convert it into another one. Commonly used text markup systems have troubles to cope with overlapping markup. DSP-API solves this problem by using Standoff/RDF markup where the markup is stored as RDF data, separately from the text. This enables overlapping markup. DSP-API\u2019s RDF-based standoff is designed to support the needs of complex digital critical editions. DSP-API can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time. The following table contains a non-exhaustive list of data formats and the information on how these formats are stored and managed by DSP-API (and SIPI): Original format Format in DSP-API Text (XML, LaTEX, Word, etc.) DSP resources (RDF) containing Standoff/RDF Tabular data, including relational databases DSP resources Data in tree or graph structures DSP resources Images (jpg, png, tiff, etc.) JPEG 2000 files stored by SIPI Audio and video files format not decided yet, stored by SIPI pdf stored by SIPI, but data reuse is improved by extracting the text for storage as Standoff/RDF DSP-API makes data available for reuse via its generic, standards-based A pplication P rogramming I nterfaces (APIs). A V irtual R esearch E nvironment (VRE) can then use these APIs to search, link together, and add to data from different research projects in a unified way. The full DSP-API documentation can be found here . Layout of DaSCH Service Platform The DaSCH Service Platform is a platform that includes five layers (see Figure 1). The bottom layer consists of an RDF triplestore, the IIIF-based media server SIPI , the knora-base ontology and any project specific ontologies that extend the base ontology. The second layer is occupied by the DSP-API which is a RESTful API, i.e. an application program interface that uses HTTP requests to GET, PUT, POST and DELETE data. The DSP API has an implemented access control. It returns information in JSON-LD format. In order to make the data accessible in an easy way, three more layers are built on top of the DSP API. The DSP-JS library comprises the third layer, it contains a reusable Node.js module for HTTP requests written in TypeScript. Layer four is occupied by DSP UI modules . These modules help to create a graphical user interface. They are developed with Angular and TypeScript and designed in such a way that they can be integrated to an Angular project. The top layer is made up of the generic DSP-APP and the more specific project Apps. From the top layer Gravsearch queries are sent to the DSP API, where permissions are checked and the queries translated into SPARQL queries, which are sent further down to the triplestore. The results are returned to the DSP-APP if the user has the sufficient permissions. In such a way, copyrighted material can be protected. Figure 1: DaSCH Service Platform architecture. The generic web app DSP-APP itself consists of three different parts (see Figure 2). First, there is the project administration part where you can manage your project - build your data model, set permissions, add users, etc. Then, there is a cross-project research platform where you search (full text, advanced or expert search), add or modify your data - this is your working environment. The third component is the Manifest+ viewer wich is designed for project presentation. Alternatively, it is possible to build more elaborate project-specific Apps based on the provided DSP-API modules in the different layers. However, it's up to you to keep such project-specific Apps compatible with the latest DSP API version. Figure 2: Details of DSP-APP. Currently, the following programming languages, software and formats are used for the various components: Component Software and formats RDF triplestore Apache Jena Fuseki Ontologies knora-base ontology and derived project ontologies SIPI C++, Lua, API-format: JSON DSP API Scala, API-formats: JSON-LD, RDF/XML or Turtle DSP-JS TypeScript, communication with DSP-API DSP-UI modules Angular modules, TypeScript, uses DSP-JS DSP-APP Angular, TypeScript, uses DSP-UI modules and DSP-JS The knora-base ontology DSP-API has a base ontology , i.e. a data model, with pre-defined basic data types. In addition to this base ontology, each project can create its own data model which is capable to describe the types of items it wishes to store. Project specific ontologies must be extensions of the knora-base ontology. The knora-base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In our documents it will be identified by the prefix knora-base or simply kb . TODO: add link to knora-base doc. Standoff/RDF Text Markup Standoff markup is text markup that is stored separately from the content it describes. DSP-API\u2019s Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. By storing markup as RDF, DSP-API can search for markup structures in the same way as for any RDF data structure. This enables searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as DSP resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. One could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain period of time. In DSP-API\u2019s Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, but has its own semantic properties. It is possible to define own tag classes in the ontology by creating subclasses of the already defined kb:StandoffTag , and to attach own properties to them. ### http://www.knora.org/ontology/knora-base#StandoffLinkTag kb:StandoffLinkTag rdf:type owl:Class ; rdfs:subClassOf kb:StandoffTag , [ rdf:type owl:Restriction ; owl:onProperty kb:standoffTagHasLink ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"Represents a reference to a Knora resource in a TextValue\"@en . DSP-API supports automatic conversion between XML and Standoff/RDF. This can be achieved by Standoff/RDF storing the order of tags and their hierarchical relationships. Then, an XML-to-Standoff Mapping for the standoff tag classes and properties has to be defined. The mapping is written in XML. Afterwards, an XML document can be imported into DSP-API, which will store it in Standoff/RDF format. The following example shows a possible mapping for a knoraDate: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name> text </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffRootTag </classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name> mydate </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/0001/anything#StandoffEventTag </classIri> <attributes> <attribute> <attributeName> description </attributeName> <namespace> noNamespace </namespace> <propertyIri> http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription </propertyIri> </attribute> </attributes> <datatype> <type> http://www.knora.org/ontology/knora-base#StandoffDateTag </type> <attributeName> knoraDate </attributeName> </datatype> </standoffClass> </mappingElement> </mapping> Once the mapping has been created, an XML like the following could be sent to DSP-API and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description= \"new year\" knoraDate= \"GREGORIAN:2016-12-31\" > New Year's Eve </mydate> . It was a lot of fun. </text> The text and markup can then be searched using the search language Gravsearch (TODO: add link). When the document is retrieved, DSP-API converts it back to the original XML. Using Gravsearch for searches DSP-API provides a search language called Gravsearch that is based on the SPARQL language. Gravsearch supports DSP\u2019s humanites-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows for combining text-related criteria with any other criteria in searches. TODO: add link to Gravsearch doc.","title":"Introduction"},{"location":"developers/introduction/#introduction-to-dsp-api","text":"The main software framework in the back-end of the DaSCH Service Platform is called DSP-API (previously Knora). DSP-API is a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP-API aims to solve key problems in the long-term preservation and reuse of humanities data: Traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. Downloading the data to check whether the data are interesting or not is time-consuming and makes it impractical to reuse data from many different sources. DSP-API solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP-API, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different data formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old data files, or even all the operating systems that these programs ran on. Instead of preserving all these data formats, DSP-API supports the conversion of all sorts of data to a small number of formats that are suitable for long-term preservation, and that maintain the data\u2019s meaning and structure: Non-binary data is stored as R esource D escription F ramework ( RDF ), in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. For a concise information about RDF basics see here . Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by the media server SIPI , with metadata stored in the triplestore. For a concise information about SIPI see here . Moreover, DSP-API has built-in support for special data structures that occur on a regular basis in humanities data: persistent links, calender-independent dates and flexible searchable text markup. Persistent links are a very important feature. If a resource is changed, a new resource will be created in DSP-API. The older version remains available and citable, there will be no dead links. This means that if in a publication an older version is referenced, the cited version still can be displayed, but there will be a notice that a newer version exists with the corresponding link attached to it. A date could be given in any kind of calendar - e.g. the Julian, Gregorian, Jewish or Islamic - just to name the most frequent ones. DSP-API stores dates using the Julian day count that was established by astronomers. Use of the Julian day count easily allows for conversion from one calendar into another and to calculate distances between two dates. It is possible to search for a date in one calendar and to convert it into another one. Commonly used text markup systems have troubles to cope with overlapping markup. DSP-API solves this problem by using Standoff/RDF markup where the markup is stored as RDF data, separately from the text. This enables overlapping markup. DSP-API\u2019s RDF-based standoff is designed to support the needs of complex digital critical editions. DSP-API can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time. The following table contains a non-exhaustive list of data formats and the information on how these formats are stored and managed by DSP-API (and SIPI): Original format Format in DSP-API Text (XML, LaTEX, Word, etc.) DSP resources (RDF) containing Standoff/RDF Tabular data, including relational databases DSP resources Data in tree or graph structures DSP resources Images (jpg, png, tiff, etc.) JPEG 2000 files stored by SIPI Audio and video files format not decided yet, stored by SIPI pdf stored by SIPI, but data reuse is improved by extracting the text for storage as Standoff/RDF DSP-API makes data available for reuse via its generic, standards-based A pplication P rogramming I nterfaces (APIs). A V irtual R esearch E nvironment (VRE) can then use these APIs to search, link together, and add to data from different research projects in a unified way. The full DSP-API documentation can be found here .","title":"Introduction to DSP-API"},{"location":"developers/introduction/#layout-of-dasch-service-platform","text":"The DaSCH Service Platform is a platform that includes five layers (see Figure 1). The bottom layer consists of an RDF triplestore, the IIIF-based media server SIPI , the knora-base ontology and any project specific ontologies that extend the base ontology. The second layer is occupied by the DSP-API which is a RESTful API, i.e. an application program interface that uses HTTP requests to GET, PUT, POST and DELETE data. The DSP API has an implemented access control. It returns information in JSON-LD format. In order to make the data accessible in an easy way, three more layers are built on top of the DSP API. The DSP-JS library comprises the third layer, it contains a reusable Node.js module for HTTP requests written in TypeScript. Layer four is occupied by DSP UI modules . These modules help to create a graphical user interface. They are developed with Angular and TypeScript and designed in such a way that they can be integrated to an Angular project. The top layer is made up of the generic DSP-APP and the more specific project Apps. From the top layer Gravsearch queries are sent to the DSP API, where permissions are checked and the queries translated into SPARQL queries, which are sent further down to the triplestore. The results are returned to the DSP-APP if the user has the sufficient permissions. In such a way, copyrighted material can be protected. Figure 1: DaSCH Service Platform architecture. The generic web app DSP-APP itself consists of three different parts (see Figure 2). First, there is the project administration part where you can manage your project - build your data model, set permissions, add users, etc. Then, there is a cross-project research platform where you search (full text, advanced or expert search), add or modify your data - this is your working environment. The third component is the Manifest+ viewer wich is designed for project presentation. Alternatively, it is possible to build more elaborate project-specific Apps based on the provided DSP-API modules in the different layers. However, it's up to you to keep such project-specific Apps compatible with the latest DSP API version. Figure 2: Details of DSP-APP. Currently, the following programming languages, software and formats are used for the various components: Component Software and formats RDF triplestore Apache Jena Fuseki Ontologies knora-base ontology and derived project ontologies SIPI C++, Lua, API-format: JSON DSP API Scala, API-formats: JSON-LD, RDF/XML or Turtle DSP-JS TypeScript, communication with DSP-API DSP-UI modules Angular modules, TypeScript, uses DSP-JS DSP-APP Angular, TypeScript, uses DSP-UI modules and DSP-JS","title":"Layout of DaSCH Service Platform"},{"location":"developers/introduction/#the-knora-base-ontology","text":"DSP-API has a base ontology , i.e. a data model, with pre-defined basic data types. In addition to this base ontology, each project can create its own data model which is capable to describe the types of items it wishes to store. Project specific ontologies must be extensions of the knora-base ontology. The knora-base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In our documents it will be identified by the prefix knora-base or simply kb . TODO: add link to knora-base doc.","title":"The knora-base ontology"},{"location":"developers/introduction/#standoffrdf-text-markup","text":"Standoff markup is text markup that is stored separately from the content it describes. DSP-API\u2019s Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. By storing markup as RDF, DSP-API can search for markup structures in the same way as for any RDF data structure. This enables searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as DSP resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. One could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain period of time. In DSP-API\u2019s Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, but has its own semantic properties. It is possible to define own tag classes in the ontology by creating subclasses of the already defined kb:StandoffTag , and to attach own properties to them. ### http://www.knora.org/ontology/knora-base#StandoffLinkTag kb:StandoffLinkTag rdf:type owl:Class ; rdfs:subClassOf kb:StandoffTag , [ rdf:type owl:Restriction ; owl:onProperty kb:standoffTagHasLink ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"Represents a reference to a Knora resource in a TextValue\"@en . DSP-API supports automatic conversion between XML and Standoff/RDF. This can be achieved by Standoff/RDF storing the order of tags and their hierarchical relationships. Then, an XML-to-Standoff Mapping for the standoff tag classes and properties has to be defined. The mapping is written in XML. Afterwards, an XML document can be imported into DSP-API, which will store it in Standoff/RDF format. The following example shows a possible mapping for a knoraDate: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name> text </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/standoff#StandoffRootTag </classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name> mydate </name> <class> noClass </class> <namespace> noNamespace </namespace> <separatesWords> false </separatesWords> </tag> <standoffClass> <classIri> http://www.knora.org/ontology/0001/anything#StandoffEventTag </classIri> <attributes> <attribute> <attributeName> description </attributeName> <namespace> noNamespace </namespace> <propertyIri> http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription </propertyIri> </attribute> </attributes> <datatype> <type> http://www.knora.org/ontology/knora-base#StandoffDateTag </type> <attributeName> knoraDate </attributeName> </datatype> </standoffClass> </mappingElement> </mapping> Once the mapping has been created, an XML like the following could be sent to DSP-API and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description= \"new year\" knoraDate= \"GREGORIAN:2016-12-31\" > New Year's Eve </mydate> . It was a lot of fun. </text> The text and markup can then be searched using the search language Gravsearch (TODO: add link). When the document is retrieved, DSP-API converts it back to the original XML.","title":"Standoff/RDF Text Markup"},{"location":"developers/introduction/#using-gravsearch-for-searches","text":"DSP-API provides a search language called Gravsearch that is based on the SPARQL language. Gravsearch supports DSP\u2019s humanites-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows for combining text-related criteria with any other criteria in searches. TODO: add link to Gravsearch doc.","title":"Using Gravsearch for searches"},{"location":"developers/rdf/","text":"Resource Description Framework (RDF) basics The Resource Description Framework (RDF) is the basic representation language and foundation of the Semantic Web. It addresses the fundamental issue of managing distributed data. All things in the world are referred to as resources . Resources can be anything: documents, people, physical objects as well as abstract concepts. The Resource Description Framework (RDF) is the framework for expressing information about such resources. It is useful if information on the Web is not only displayed, but needs to be processed by applications. The following introduction to RDF draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 27\u201350 which we warmly recommend for reading. Further information can be found in the RDF 1.1 Primer . A note about the examples in this document It was aimed for to explain all following language features by using only one exemplary project. The setting of the chosen project is the following: It is about archaeological objects stemming from different findspots - known and unknown - and kept in different institutions around the world today. These objects show depictions of mythological scenes that illustrate episodes known from ancient literature, e.g. the Iliad or the Odyssey of Homer, or reflect thoughts of various ancient philosophers about the nature of our world and all creatures living therein. For some of these objects other data and documents exist on the Web, e.g. entries in museum databases, and we may possess low or high resolution images of them. Furthermore, the findspots - if known - can be identified unambigously by reference to geographical databases, e.g. GeoNames. If data are available in tabular form, the rows represent the items we intend to describe and each column represents some property of these items. The cells in the table then denote particular values for these properties. Table 1 shows a small excerpt of such a table from our exemplary project. ID Category City Institution InventoryNr. 1 Ceramics Boston Museum of Fine Arts 28.46 2 Glyptics London British Museum 2717 3 Relief New York Metropolitan Museum 24.97.11 In RDF, each of these cells has to be represented with three values which are called triples : a global reference for the row, a global reference for the column, and the value in the cell itself. The identifier for the row is the subject of the triple, the identifier for the column the predicate of the triple, and the value in the cell the object of the triple. There are three types of RDF data that can occur in triples: I nternational R esource I dentifiers ( IRI s) / U niversal R esource I dentifiers ( URI s), literals and blank nodes . A triple now describes the relationship between two resources which are the subject and the object of the triple. The predicate represents the nature of the relationship between subject and object. The relationship is directional - the predicate always points from the subject to the object - and is called a property . Table 2 shows all the triples of the data in Table 1. |Subject|Predicate|Object| |-----|:----:|---| |ID 1|belongsToCategory|Ceramics| |ID 1|todayIn|Boston| |ID 1|isKeptIn|Museum of Fine Arts| |ID 1|hasInventory|28.46| |ID 2|belongsToCategory|Glyptics| |ID 2|todayIn|London| |ID 2|isKeptIn|British Museum| |ID 2|hasInventory|2717| |ID 3|belongsToCategory|Relief| |ID 3|todayIn|New York| |ID 3|isKeptIn|Metropolitan Museum| |ID 3|hasInventory|24.97.11| Often, the same resource, e.g. a person, is referenced in multiple triples. When more than one triple refers to the same thing, it is more useful to view the triples in a directed graph where each triple is depicted by nodes and arcs: the subjects and objects of the triples are the nodes while the predicates denote the arcs with the predicate as label on the arc: Furthermore, if the subject or object is a URI/IRI or a blank node, it is depicted within an ellipse, if it is a literal value, however, within a rectangle. The graph display of the triples in Table 2 then looks as follows: Let's assume we possess the information in Table 3 from another source which we intend to merge with our data presented in Table 1. |Work|Author|Depiction| |-----|:----:|---| |Iliad|Homer|24.97.11| |Odyssey|Homer|24.97.11| This provides us with the following triples in Table 4: |Subject|Predicate|Object| |-----|:----:|---| |Iliad|hasAuthor|Homer| |Odyssey|hasAuthor|Homer| |Iliad|hasDepictionOn|24.97.11| |Odyssey|hasDepictionOn|24.97.11| The graph display of the triples in Table 2 concerning ID 3 and of the triples in Table 4 looks as follows: Since we now look at one specific example, namely \"ID 3\", all the values are literals and hence depicted in yellow rectangles. Namespaces, Uniform Resource Identifiers (URIs) and International Resource Identifiers (IRIs) If we intend to merge information from different sources, an essential question is whether a node in one graph is the same node as a node in another graph. RDF solves this issue through use of U niform R esource I dentifiers (URIs) or I nternational R esource I dentifiers (IRIs). Our well known web addresses, the URLs, are just a special case of URIs and IRIs. An International Resource Identifier is the internationalised form of a URI. IRIs extend the allowed characters in URIs from a subset of the ASCII character set to almost all characters of the Universal Code Character Set (Unicode / ISO 10646). The syntax of the URI/IRI allows to deference it, i.e. to use all the information in the URI/IRI such as server name, protocol, port number, file name etc. to locate a file or a location on the Web. The possibility of dereferencing enables participation in a global Web infrastructure. URIs and IRIs are painful to write out in detail when expressing models. Hence, it is common to use an abbreviation scheme. Then a URI/IRI has two parts: a namespace and an identifier with a colon in between. The representation for the identifier United Kingdom in the namespace geonames is geonames:UnitedKingdom . URIs/IRIs may not contain embedded spaces. Hence, the so-called InterCap convention is followed: names that consist of multiple words are transformed to identifiers without spaces by capitalizing each word: \"part of\" becomes partOf , \"Measure for Measure\" MeasureForMeasure , and so on. The selection of namespaces is unrestricted. However, it is common practice to refer to related identifiers in a single namespace. Following the above example all geographical information would be placed into the suggestive namespace geonames . These names correspond to fully qualified URIs - geonames stands for material in the geographical database GeoNames . Using URIs/IRIs as standard for global identifiers enables for a worldwide reference and thus, two peolpe anywhere in the world to refer to the same thing unequivocally. This property allows for specifying certain terms by a standard organization such as W3C. W3C standards provide definitions for terms such as e.g. type , Class , subClassOf which are intended to apply globally across the Semantic Web. W3C has defined a number of standard namespaces for use with Web technologies. The most important are: * xsd: Indicates identifiers for XML schema definition. The global IRI for the xsd namespace is http://www.w3.org/2001/XMLSchema# . * xslns: Indicates identifiers for XML namespaces. The global IRI for the xslns namespace is https://www.w3.org/XML/1998/namespace . * rdf: Indicates identifiers used in RDF. The global IRI for the rdf namespace is http://www.w3.org/1999/02/22-rdf-syntax-ns# . * rdfs: Indicates identifiers used for the RDF Schema language (RDFS). The global IRI for the rdfs namespace is http://www.w3.org/2000/01/rdf-schema# . * owl: Indicates identifiers used for the Web Ontology Language (OWL). The global IRI for the owl namespace is http://www.w3.org/2002/07/owl# . Any URI in one of these namespaces - e.g. rdfs:subClassOf which is short for http://www.w3.org/2000/01/rdf-schema#subClassOf - refers to a particular term defined in the RDFS standard by the W3C. The term can also be dereferenced: at the server www.w3.org there is a page at the location 2000/01/rdf-schema with an entry about rdfs:subClassOf which gives additional information about this resource. Literals Literals are values that are not URIs/IRIs. They may be simple strings such as \"Homer\", dates such as \"April 30th, 700 BCE\", numbers such as \"2.71828\". They are often associated with one of the following datatypes (list non-exhaustive): * boolean with value true or false * string with value character string * decimal with an arbitrary-precision decimal number as value * integer with an arbitrary-precision integer number as value * date with value in format yyyy-mm-dd Literals may only appear as object of a triple. Identifiers in the RDF namespace The RDF data model specifies the notion of triples and the merging of sets of triples. With the introduction of namespaces RDF provides agreements on how to refer to a particular entity. The RDF standard defines a small number of standard identifiers in the namespace rdf . rdf:type is a property that provides an elementary system in RDF to define types. rdf:type can be the predicate of a triple, the subject of the triple can be any identifier and the object of the triple is understood to be a type. rdf:type can be used to e.g. state, that Homers works belong to a group of literary works we call Poetry: Subject Predicate Object Iliad rdf:type Poetry Odyssey rdf:type Poetry rdf:Property is an identifier to indicate when another identifier is to be used as a predicate rather than as subject or object. Some triples from our examples in Table 2 and Table 4 can be expressed with rdf:Property in the following way: Subject Predicate Object wrote rdf:type rdf:Property isKeptIn rdf:type rdf:Property hasDepictionOn rdf:type rdf:Property Reification The strict subject - predicate - object form of RDF triples is limiting if one wants to qualify a statement further, if a statement about another statement seems desireable. We may wish to express that our object with ID 3 in Table 1 was bought by the Metropolitan Museum in 1924. Such a process of a statement about a statement is called reification . Reification can be achieved by different approaches. The easiest approach is to add just further triples expressing the desired relationship. myonto:ID3 myonto:todayIn \"New York\" . myonto:ID3 myonto:keptIn \"Metropolitan Museum\" . myonto:ID3 myonto:hasAccessionDate 1924 . The namespace myonto is used in the above example to express that the statements concern resources and properties which are defined in our own namespace. In contrast, otheronto will be used in following examples to express that an external not further defined namespace is referred to. The simple approach shown above works well if more information about some event or statement needs to be specified. However, it doesn't work well in cases when information about the statement itself shall be expressed: We may wish to express that the information that on our object with ID 3 in Table 1 scenes from the Iliad are depicted (information contained in Table 3) stems from the catalogue entry of this object in the online collection of the Metropolitan Museum. Such metadata about statements are often related with provenance indications, likelihood expressions, context information or time spans. In such cases it is necessary to explicitly make a statement about a statement. This process, called explicit reification is supported by the RDF standard with three resources called rdf:subject , rdf:predicate and rdf:object . With the following set of triples we can express that in the online collection of the Metropolitan Museum is written that ID 3 contains a depiction of scenes from the Iliad: myonto:n1 rdf:subject myonto:Iliad ; rdf:predicate myonto:hasDepictionOn ; rdf:object myonto:ID 3 . web:MetropolitanMuseum myonto:says myonto:n1 . Expressing RDF in textual form: Turtle When data are published in RDF on the Web the issue of representing RDF in text arises. There are multiple ways of achieving this. We are using a compact serialization of RDF which is called Turtle . It uses pre-defined shortcuts or namespaces. Since a binding between the local used namespaces and the global URIs/IRIs have to be achieved, Turtle begins with a preamble in which these bindings are defined: @prefix myonto: http://www.myontology @prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# With these abbreviations the triples can be expressed in subject/predicate/object order followed by a period. myonto:HomerWorks rdf:type myonto:Poetry . This statement expresses that Homer's literary works belong to the category of poetry. If several triples share a common subject it need not be repeated each time. Instead of terminating the first triple with a period, a semicolon (;) is used to indicate that another triple with the same subject follows. myonto:Homer rdf:type myonto:Author ; myonto:wrote \"Iliad\" . This statement expresses that in my ontology named myonto Homer is part of my class Author and that he wrote the Iliad. If there are several triples that share both subject and predicate, a comma (,) is used to separate the objects. E.g. to express, that Homer wrote both the Iliad and the Odyssey, I can use the following statement: myonto:Homer myonto:wrote myonto:Iliad, myonto:Odyssey . To improve terseness and readability Turtle provides some abbreviations. The most widley used abbreviation is the word a to mean rdf:type . Thus, the following two triples are equivalent, both telling that the class Ceramics in my ontology is part of a larger class called Category: myonto:Ceramics rdf:type myonto:Category . myonto:Ceramics a myonto:Category . Blank nodes Sometimes we are aware of that something exists, that we know some things about it, but its identity is unknown. We want to express what we know about this resource without bothering to use a global identifier. Such a resource without a global identifier can be represented by a blank node. Blank nodes are comparable to the unknown variables x or y in an equation - they represent something without saying what their value is. Blank nodes can be the subject and/or the object of a triple. Within the framework of our example of archaeological objects showing depictions of Homeric poetry which are held by different institutions, the exact provenience of some objects may be unknown since they stem from illicit excavations and were bought on the antiquities market many years ago. Nevertheless, we know that each object possesses a provenience. A blank node is indicated by square brackets ([]). All triples of which it is a subject are placed within these brackets. The information that if an object was bought on the antiquities market no detail information about its find context is available can be put inside a blank node: [ rdf:type myonto:Market ; myonto:noInfo myonto:FindContext ] Such a blank node can then be referred to in other triples by including the entire bracketed sequence in place of the blank node. The following example expresses that all my objects which belong to the class UnprovenancedObj in my ontology myonto were bought on the antiquities market and for them I have no detail information about their find contexts available: myonto:UnprovenancedObj myonto:isPartOf [ rdf:type myonto:Market ; myonto:noInfo myonto:FindContext ] Ordered information in RDF Ordering of RDF triples has to be specified explicitly: elements can be ordered in a list format. In Turtle an ordered list can be expressed by putting a sequence of objects within brackets (()). If we want to express that the king of Mykene, Agamemnon, was the father of four children, Iphigeneia being the oldest and Orestes being the youngest, we can express that in the following way: Agamemnon myonto:isFatherOf (Iphigeneia, Elektra, Chrysothemis, Orestes) . RDF Schema (RDFS) RDF simply creates a graph structure to represent data. The RDF S chema (RDFS) is a semantic extension of RDF wich provides some guidelines about how to use this graph structure, i.e. it imposes special syntactic conditions or restrictions upon RDF graphs. The schema is informaton about the data. It should help to provide meaning to the data. Thus, it is a layer on top of the RDF layer to describe consistency constraints in the data. The key to these levels is inferencing . The statements of meaning are given in the form of an inference pattern: \"Given some initial information, the following new information can be derived.\" That's the way the RDF Schema language (RDFS) and also the Web Ontology Language (OWL) work. All schema information in RDFS is expressed by RDF triples. The meaning of asserted triples is defined with new inferred triples. The structures that describe the meaning of the data are also in triples. The following introduction to RDF Schema draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 113\u2013152 which we warmly recommend for reading. Further information can be found in the Recommendations of RDF Schema 1.1 . Asserted triples and inferred triples Asserted triples are triple data that were explicitly added in the original RDF store. Inferred triples are additional triples that are inferred by one of the inference rules. There is no logical distinction between inferred and asserted triples. Hence, one should be careful concerning inference rules and how to implement them. The RDFS and OWL standards define for certain patterns of triples which inferences are valid. The simplest approach is to store all triples in a single store and to ignore whether they are asserted or inferred. This approach is called cached inferencing since all inferences are stored with the data. It is simple, but the number of triples in the triple store increases and some inferred triples may later turn out to be incorrect und unwarranted. The other extreme is to never actually store any inferred triples in any persistent store. Then, inferencing is done in response to queries only. This approach can be called just in time inferencing , since the inferences are made just in time. The query responses are produced such that they respect all the appropriate inferences, but no inferred triple is retained. Both approaches have an important impact if data sources change, i.e. if a triple is deleted or a new triple added. If cached inferencing was chosen, originally inferred triples which are no longer valid must be identified and removed or new ones added. An important variant of just in time inferencing is where explicit inferencing is undesired. What kind of inferencing is needed depends on the required level of expressivity for a certain task. There are different inferencing levels. RDFS operates on a small number of inference rules that deal mostly with relating classes to subclasses and properties to classes. OWL includes constraints on properties and notions of equality and includes rules for describing classes based on allowed values for properties. All these standards use inferencing, but they differ in the inferencing that they support. Classes Resources can be grouped in classes which are themselves resources. The members of such a class are known as instances of the class. Classes are often identified by URIs/IRIs. All RDF datatypes are classes. The instances of a class that is a datatype are the members of the value space of the datatype. Thus, \"3.14\" is an instance of the class decimal, \"4\" is an instance of the class integer, \"2000-01-01\" is an instance of the class date, etc. The basic construct for specifying a group of related resources in RDFS is called an rdfs:Class . The way to express that something is a class is with a triple in which the predicate is rdf:type and the object is rdfs:Class as in the following examples: myonto:Ceramics rdf:type rdfs:Class . myonto:BlackFigured rdf:type rdfs:Class . These triples express that our resources Ceramics and BlackFigured are classes. One of the basic terms is rdfs:subClassOf . The meaning of \" B is a subClassOf C \" is \"every member of class B is also a member of class C\", expressed in the form of an inference. From a further information \" x is a member of B \" one can derive the new information \" x is a member of C \". Speaking more generally, if a class A is a subclass of another class B, then anything of type A is also of type B. This is called the type propagation rule . This feature of inference systems is particulary useful in a Semantic Web context in which new combinations of relationships likely occur as data from multiple sources are merged. In the framework of our example the class BlackFigured is a subclass of the class Ceramics . For any member of the class BlackFigured we can then derive that it is also a member of the class Ceramics due to the following statement : myonto:BlackFigured rdfs:subClassOf myonto:Ceramics . A class may be a member of its own class extension and an instance of itself, this applies e.g. for rdfs:Class . Properties An RDF property describes the relationship between a subject resource and an object resource. Properties with inferences One of the most fundemantal terms in RDFS is rdfs:subPropertyOf . It is a transitive property and allows a modeler to describe a hierarchy of related properties. If we want to express that some of the people who work for a museum are permanently employed while others possess only loose contracts we could express this fact with the following triples: myonto:isEmployedBy rdfs:subPropertyOf myonto:worksFor . myonto:contractsTo rdfs:subPropertyOf myonto:worksFor . Regardless whether a person is employed by the museum or is a contractor, the person works for the museum. Other basic properties are rdfs:range and rdfs:domain . They have meanings inspired by the mathematical use of the words range and domain : the domain of a function is the set of values for which it is defined, its range is the set of values it can take. Both give informaton about how a property P is to be used: domain refers to the subject of any triple that uses P as its predicate, range refers to the object of any such triple. rdfs:domain P rdfs:domain D . means that property P has domain D . From this we can infer that the subject of that triple is a member of the class D . rdfs:domain can be used to specify with which class the defined property can be used with. It is possible to specify multiple rdfs:domain properties when defining a property. We pick just two classes from our example - Ceramics and BlackFigured - which show a subclass relation: myonto:BlackFigured rdfs:subClassOf myonto:Ceramics . We now have a property called incised whose domain is BlackFigured . myonto:incised rdfs:domain myonto:BlackFigured . This means that all my objects with incised decoration belong to the class BlackFigured . rdfs:range P rdfs:range R . means that the property P has range R . From this we can infer that the object (the value of P ) of that triple is a member of class R . If the predicate of a triple has more than one rdfs:range property, the resources denoted by the objects of triples are instances of all the classes stated by the rdfs:range properties. If we want to specify that queens who gave birth to a son could theoretically become queen mothers, we could do that with the following combination of rdfs:domain and rdfs:range : myonto:hasSon rdfs:domain myonto:Queen . myonto:hasSon rdfs:range myonto:QueenMother . It is important to know that if P is used in an inconsistent way with this declaration, RDFS does not signal an error, but rather infers the necessary type information to bring P into accordance with its domain and range declarations! In RDFS, there is no notion of an incorrect or inconsistent inference, i.e. it will never proclaim an input as invalid but simply infer appropriate type information. Domains and ranges are not used to validate information, but to determine new information based on old information. In practice, there are often better and more appropriate options to use instead of rdfs:domain and rdfs:range alone. Properties without inferences RDFS provides some properties from which no inferences can be drawn, i.e. no inference semantics is defined for them. They are useful and important for documentation purposes. These are rdfs:label , rdfs:comment , rdfs:seeAlso and rdfs:isDefinedBy . Resources on the Semantic Web are specified by IRIs/URIs which are not meaningful to people. Thus, RDFS provides the property rdfs:label whose intended use is to provide a human-readable version for any resource's name. Multilingual labels are possible if the language tagging facility of RDF literals is used. myonto:BlackFigured rdfs:label \"black-figured vessels\"@en, \"schwarzfigurige Gef\u00e4sse\"@de . Frequently it is useful to add comments about a model, i.e. to document it properly. In RDFS, rdfs:comment is an instance of rdf:Property that can be used to provide a human-readable description of a resource. Multilingual documentation is possible if the language tagging facility of RDF literals is used. To make a comment a triple using the property rdfs:comment as a predicate has to be asserted. myonto:BlackFigured rdfs:comment \"The class BlackFigured contains ceramic vessels where the decoration is painted with black paint.\" . In the case where a resource is an URL, supplementary information about this resource may be useful. This additional information is often included in documents. rdfs:seeAlso provides a way to specify the web location of such supplementary information. The web location has to be given in the form of an IRI/URI! The precise behaviour of a processor is not specified, but most tools that encounter rdfs:seeAlso link them to those links in a browser or application interface. In our example we could link findspots of archaeological objects to a web resource with geodata, e.g. GeoNames, in the following way: myonto:latitude rdfs:seeAlso geonames:lat . rdfs:isDefinedby provides a link to the primary resource of information about a resource. Thus, the definitional description of a resource can be found, e.g. rdfs:isDefinedBy is defined in RDF to be a rdfs:subPropertyOf of rdfs:seeAlso . Combinations and patterns Intersection RDFS inference rules are few and rather simple. More specific patterns can be obtained by combining basic RDFS features. One such case is set intersection. If we intend to draw the inference that if a resource x is an instance of class C , then it should also be an instance of classes A and B , expressing the formal relationship C \u2286 A \u2229 B . Such an inference can be obtained by making C a subclass of A and B : :C rdfs:subClassOf :A . :C rdfs:subClassOf :B . Due to the inference rule defined for rdfs:subClassOf we can infer from the triple x rdf:type :C . the desired triples x rdf:type :A . x rdf:type :B . Thus, from a membership in C membership in A and B can be inferred. But from membership in A and B membership in C cannot be inferred! Inferences can only be drawn in one direction. In an analogous way to the treatment of classes, set intersection can be defined for properties using the construct rdfs:subPropertyOf . Union The union of two sets ( A \u222a B \u2286 C ) can be obtained by making C a superclass of A and B . :A rdfs:subClassOf :C . :B rdfs:subClassOf :C . Then, for any instance x that is either a member of class A or of B it will be inferred that it is also a member of class C . In an analogous way to the treatment of classes, set union can be defined for properties using rdfs:subPropertyOf . Collections A collection is represented as a list of items. rdf:List is an instance of rdfs:Class that can be used to build descriptions of lists and other list-like structures. Summary The following Figure 4 illustrates the concepts of resource, class, and sub-class based on our example project. Figure 5 shows the same in a more general way: resources are denoted by a large black dot and arrows are drawn from a resource to the class it defines. A sub-class is shown by a rectangle (the sub-class) completely enclosed by another (the super-class), i.e. class ConstraintProperty is a subclass of class Property. The notion rdf:type specifies that something is a member of a group, i.e. an instance of a class. By using rdfs:Class instead of rdf:type a description of the meaning of a membership in a group is gained. Meaning is expressed through the mechanisms of inference in RDFS that can be drawn when a resource is used in a certain way. The following Figure 6 expresses the same information about the class hierarchy, but does so using a graphic representation of the RDF data model. If a class is a subset of another, there is an arc labelled \"s\" from the node representing the first class to the node representing the second one (\"s\" stands for rdfs:subClassOf ). If a resource was an instance of a class, then there is an arc labelled \"t\" from the resource to the node representing the class (\"t\" stands for rdf:type ). Not all arcs are drawn, e.g. rdfs:ConstraintProperty is a subclass of rdfs:Resource because it is a subclass of rdf:Property which is a subclass of rdfs:Resource . Examples: - The class rdfs:Literal is an instance of rdfs:Class and an instance of rdfs:Resource . - The class rdf:Property is the class of RDF properties and an instance of rdfs:Class . Web Ontology Language (OWL) OWL is intended to be used when information contained in documents needs to be processed by applications, it explicitly represents the meaning of terms in vocabularies and the relationship between those terms. The representation of terms and their interrelationships are called an ontology . A concrete syntax is needed in order to store ontologies and to exchange them among tools and applications. The primary exchange syntax for OWL is the XML syntax for RDF (RDF/XML), but other syntaxes such as e.g. Turtle are also frequently used. The data described by an OWL ontology is interpreted as a set of \"individuals\" and a set of \"property assertions\" which relate these individuals to each other. An ontology consists of a set of axioms which place constraints on sets of individuals called \"classes\" and the types of relationships permitted between them. OWL ontologies can import other ontologies, adding information from the imported ontology to the current ontology. The main building blocks of the OWL language are an RDF graph and at least one concrete syntax - there may be more than one - that can be used to serialize and exchange ontologies. OWL has been designed to meet the needs for a Web Ontology Language. It is part of the W3C recommendations related to the Semantic Web: - XML provides a surface syntax for structured documents, but imposes no semantic constraints. - XML Schema is a language for restricting the structure of XML documents and extends XML with datatypes. - RDF is a datamodel for objects and relations between them. Furthermore, it provides a simple semantics for this datamodel and these datamodels can be represented in an XML syntax. - RDF Schema is a vocabulary for describing properties and classes of RDF resources, with a semantics for generalization-hierarchies of such properties and classes. - OWL then adds more vocabulary to RDF for describing properties and classes: e.g. relations between classes, cardinality, equality, characteristics of properties and enumerated classes. The following introduction to OWL draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 153\u2013305 which we warmly recommend for reading. Further information can be found in the Recommendations of the OWL 2 Web Ontology Language Document Overview (Second Edition) and the Wikipedia entry of OWL . owl:Class In OWL, a Class defines a group of individuals that belong together because they share some properties. An owl:Class differs from an rdfs:Class - an owl:Class is a special case of an rdfs:Class . Classes can be organised in a hierarchy using rdfs:subClassOf . Thus, owl:Class is defined as a subclass of rdfs:Class : owl:Class rdfs:subClassOf rdfs:Class . This means that every member of an owl:Class is also a member of rdfs:Class . There is a built-in most general class named owl:Thing which is the class of all individuals. It is a superclass of all OWL classes. There is also a built-in class named owl:Nothing which is the class that has no instances. It is a subclass of all OWL classes. owl:inverseOf Extra language features that are not directly provided by OWL, but that one may desire, such as e.g. superClassOf , are often supported by OWL as a combination of other features. The construct owl:inverseOf inverses a property, i.e. the direction of the property is reversed. This property can be used to define e.g. the superClassOf of a resource by combining it with rdfs:subClassOf in the following way: myonto:superClassOf owl:inverseOf rdfs:subClassOf . owl:SymmetricProperty For a symmetric property holds that if a pair (x,y) is an instance of the property P, then also the pair (y,x) is an instance of this property P. Such a property is provided by owl:SymmetricProperty and expressed in OWL as a Class. An example for such a property is to be married - if Agamemnon is married to Klytaimnestra, Klytaimnestra is also married to Agamemnon. Thus we can define a property married in our ontology with the following triples: myonto:married rdf:type owl:SymmetricProperty . Agamemnon myonto:married Klytaimnestra . Be aware - to make sure that owl:inverseOf works in both directions, one has to assert that owl:inverseOf rdf:type owl:SymmetricProperty . owl:TransitiveProperty Another important property is transitivity. Transitivity is a relation between three elements such that if it holds between the first and second and it also holds between the second and third, it must necessarily hold between the first and the third. In OWL, transitivity is provided by the construct owl:TransitiveProperty which is a class of properties. To model the property isLocatedIn in our ontology as a member of the transitive class we can state myonto:isLocatedIn rdf:type owl:TransitiveProperty . Together with the triples Rome myonto:isLocatedIn Italy . Italy myonto:isLocatedIn Europe . we can infer that Rome is located in Europe. owl:equivalentClass A frequent situation is that if information about the same entity from different sources is merged then the two providers of this information will not have used the same URI/IRI for refering to the same entity. When combining these data it may be useful to state that two URIs/IRIs actually refer to the same entity. When two classes are known to always have the same members, they are said to be equivalent . Such a situation can be expressed with one simple statement using owl:equivalentClass : owl:equivalentClass rdf:type owl:SymmetricProperty . myonto:GreekGods owl:equivalentClass otheronto:Deities . The second triple expresses that the class GreekGods in our ontology is equivalent to the class Deities in some other ontology we refer to. Note that when two classes are equivalent, it only means that they have the same members. But other properties of these classes aren't shared! owl:equivalentProperty If one intends to state that two properties are equivalent, owl:equivalentProperty can be used: myonto:isInvisible owl:equivalentClass otheronto:notSeen . This statement expresses that the property which is called isInvisible in our ontology, is named notSeen in some other ontology. owl:sameAs If it turns out that two individuals are actually one and the same, owl:sameAs can be used to state this fact: myonto:Puteoli owl:sameAs otheronto:Puzzeoli . This statement expresses that the site which is called Puteoli in our ontology, is the same as a site named Puzzeoli in some other ontology. owl:FunctionalProperty A functional property owl:FunctionalProperty is a property which can only have one single value. An everyday example for such a property is e.g. hasBirthplace since each person has only one birth place. Functional properties can be useful to infer sameness, e.g. if names with foreign characters are transliterated differently in two sources - a Greek \"B\" may be transliterated either as \"B\" or as \"V\", we can state: myonto:GreekB owl:FunctionalProperty otheronto:GreekV . owl:InverseFunctionalProperty However, it is more common to use the related notion of owl:InverseFunctionalProperty . One can think of this construct to be the inverse of owl:FunctionalProperty as its name suggests. Especially identifying numbers are inverse functional properties. myonto:hasInventoryNumber rdf:type owl:InverseFunctionalProperty . myonto:ID3 myonto:hasInventoryNumber \"24.97.11\" . otheronto:ID2435 myonto:hasInventoryNumber \"24.97.11\" . From the above example follows that ID 3 in my data set is the same object as ID 2435 in another data set. It is sometimes useful for a single property to be an owl:FunctionalProperty and an owl:InverseFunctionalProperty . This means that it is a one-to-one property: for each individual there is exactly one value for the property and the other way round. This feature is intended in the case of unique identifiers as in the following example: myonto:hasID rdfs:domain myonto:Monument . myonto:hasID rdfs:range xsd:Integer . myonto:hasID rfd:type owl:FunctionalProperty . myonto:hasID rfd:type owl:InverseFunctionalProperty . This means that each member of class Monument possesses a unique identifier that is an integer number. Any two monuments that share an ID must be the same (due to inverse functionality) and in addition, each monument can have at most one ID (due to functionality). owl:ObjectProperty and owl:DatatypeProperty The constructs owl:sameAs , owl:FunctionalProperty and owl:InverseFunctionalProperty especially help to describe how information from multiple sources can be merged. OWL can also provide useful information for editing tools if a value of some property may be either a link to another object or a widget for a particular data type. For this purpose OWL distinguishes between owl:DatatypeProperty and owl:ObjectProperty . owl:DatatypeProperty can have a data value as object, owl:ObjectProperty can have a resource as object. myonto:inSameMuseum rdf:type owl:ObjectProperty. myonto:shipVoyage rdf:type owl:DatatypeProperty. The first example may be used to express that one archaeological object is kept in the same museum as another archaeological object while the second example may select those individuals who participated in a ship voyage such as e.g. the Argonauts. Restrictions The construct owl:Restriction allows to describe individuals of classes in terms of existing properties and classes that have already been modeled. The class of all things in OWL called owl:Thing is unrestricted. A restriction provides some description that limits the kinds of things that can be said about a member of the class. A restriction class in OWL is defined by the keyword owl:onProperty . A description of how the new class is constrained can be provided e.g. by owl:allValuesFrom , owl:someValuesFrom and owl:hasValue . The membership in a restriction class must satisfy the specified conditions as well as the owl:onProperty specification. Property constraints owl:someValuesFrom selects all individuals from a class for which at least one value of the property P comes from class C . In our example we can formulate such a restriction as: [a owl:Restriction; owl:onProperty myonto:isLocatedIn; owl:someValuesFrom myonto:Museum] All archaeological objects kept in a museum today thus have been defined as all archaeological objects for which at least one value of the property isLocatedIn comes from the class Museum . The [ ] notation refers to a blank node which is described by the properties listed here. This restriction class has no specific name associated with it - it is defined by the properties of the restriction and is hence called an unnamed class . owl:allValuesFrom selects all individuals from a class for which all values of the property P come from class C . In our example we can formulate such a restriction as: [a owl:Restriction; owl:onProperty myonto:hasProvenience; owl:allValuesFrom myonto:Findspot] This restriction selects all our archaeological objects for which the findspot is known. A noteworthy difference between owl:someValuesFrom and owl:allValuesFrom is that the former implies that there must be such a member, while the latter technically means if there are any members, then they all must have this property which doesn't imply that there are any members. owl:hasValue is used to produce a restriction of the form \"all individuals that have the value A for the property P \". We can formulate such a restriction as: [ a owl:Restriction ; owl:onProperty myonto:P ; owl:hasValue myonto:A ] . Let's assume we defined a property myonto:hasImage which helps to select archaeological objects for which we possess images. We can now state a restriction for those with high resolution images: myonto:HighResolutionObject owl:equivalentClass [ a owl:Restriction ; owl:onProperty myonto:hasImage; owl:hasValue myonto:hasHighresImage ] . That we have such a high resolution image of a certain object we can formulate with the following triple: myonto:ID3 myonto:hasImage myonto:hasHighresImage . Then it is possible to deduce myonto:ID3 a myonto:HighResolutionObject . owl:hasValue is just a special case of the owl:someValuesFrom restriction. Nevertheless, it is very useful because it effectively turns specific instance descriptions into class descriptions. OWL provides a facility for defining new classes as unions ( owl:unionOf ) and intersections ( owl:intersectionOf ) of previously defined classes. The union of two or more classes includes the members of all those classes while the intersection includes only those that belong to every one of the classes. OWL allows to enumerate the members of a class using the construct owl:oneOf . If I have a class myonto:ObjectsSomeSmallMuseum with the members \"vase1\", \"vase2\" and \"relief1\", then: myonto:ObjectsSomeSmallMuseum rdf:type owl:Class; owl:oneOf (myonto:vase1 myonto:vase2 myonto:relief1). My class myonto:ObjectsSomeSmallMuseum is related via the property owl:oneOf to a list of the members of the class. However, owl:oneOf should be used only in situations in which the definition of the class is not likely to change at all or at least not frequently. One such case would e.g. be the number of planets in the solar system. In contrast, the above example may be appropriate for our own immediate needs, but not for a more general approach: although we include only three objects of this small museum in our data, the museum itself for sure owns many more. Sometimes it may be useful to state that one thing is different from another thing. OWL provides owl:differentFrom for this. An example is the following: myonto:Zenon owl:differentFrom otheronto:Zenon. Two different ancient Greek philosophers with the name Zenon are known. The above triple states that the Zenon in our ontology (e.g. Zenon of Elea) is not the same Zenon as in another ontology (e.g. Zenon of Kition). Cardinalities OWL also includes restrictions that refer to cardinalities , i.e. the number of values for a specific property. Cardinality restrictions can be used to define sets of particular interest. Cardinality refers to the number of distinct values a property has. The fact that we only know about two works attributed to Homer - the Iliad and the Odyssey - we may state by using owl:cardinality : [a owl:Restriction; owl:onProperty myonto:HomerWorks; owl:cardinality 2] Cardinality restrictions can also be used to specify upper and lower boundaries, the respective constructs are named owl:maxCardinality and owl:minCardinality . The restriction to cardinalities of 0 and 1 have special modeling utility: minCardinality 0 indicates a set of individuals for which some value for a specified property is optional minCardinality 1 indicates a set of individuals for which some value for a specified property is required maxCardinality 0 specifies that no value for the specified property is allowed maxCardinality 1 specifies that a value is unique (but need not exist) Reasoning with individuals and classes From an RDF perspective inferences about individuals and inferences about classes are very similar: in both cases new triples are added to the model based on the asserted triples. However, from a modeling perspective, these two kinds of reasoning are very different. The former draws specific conclusions about individuals while the latter draws general conclusions about classes of individuals. In the case of reasoning about individuals the information specified in one source is transformed according to a model for use in another context with the help of constructs such as rdfs:subClassOf , rdfs:subPropertyOf and various owl:Restriction . Class reasoning determines how data are related in general with constructs such as rdfs:subClassOf , rdfs:subPropertyOf , rdfs:domain or rdfs:range . Once these more general relationships have been inferred, the processing of the data can be done much easier. Composing files OWL provides a built-in class owl:Ontology . The URI/IRI of an ontology usually corresponds to the URL of the file on the Web where the ontology is stored. The corresponding URI/IRI can be eclosed in angle brackets as follows: <http://www.knora.org/ontology/knora-base> rdf:type owl:Ontology. This can be useful when modularity of semantic models is specified. The most frequent way to specify modularity is with the property owl:imports . This property connects two instances of the class owl:Ontology . Summary of constructs rdfs:subClassOf - the members of a subclass are also a member of a superclass rdfs:subPropertyOf - relations described by a subproperty also hold for the superproperty rdfs:domain - the subject of a triple is classified into the domain of the predicate rdfs:range - the object of a triple is classified into the range of the predicate rdfs:label - human-readable name of a resource, no semantics inferable rdfs:comment - human-readable information of the model, no semantics inferable owl:equivalentClass - the members of each class are also members of the other class owl:equivalentProperty - relations that hold for each property also hold for the other property owl:sameAs - all statements about one instance hold for the other instance owl:inverseOf - exchanges subject and object owl:TransitiveProperty - the chains of a relationship collapse into a single relationship owl:SymmetricProperty - the property is its own inverse owl:FunctionalProperty - only one value as object allowed owl:InverseFunctionalProperty - only one value as subject allowed owl:ObjectProperty - the property can have a resource as object owl:DatatypeProperty - the property can have a data value as object owl:Restriction - a building block in OWL that describes classes by restricting the values that are allowed for certain properties owl:hasValue - a type of restriction that refers to a single value for a property owl:someValuesFrom - a type of restriction that refers to a set from which some value for a property must come owl:allValuesFrom - a type of restriction that refers to a set from which all values for a property must come owl:onProperty - a link from a restriction to the property it restricts. owl:unionOf - unites classes and creates a new class owl:intersectionOf - determines the intersection of classes and creates a new class owl:complementOf - determines the compliment of a class and creates a new class owl:oneOf - specifies that a class consists just of the listed members owl:differentFrom - specifies that one individual is not identical to another one owl:disjointWith - specifies that two classes cannot share a member owl:cardinality - specifies information about the number of distict values for some property owl:minCardinality - specifies information about the minimum number of distinct values for a property owl:maxCardinality - specifies information about the maximum number of distinct values for a property owl:imports - allows one ontology to refer explicitly to another ontology.","title":"RDF"},{"location":"developers/rdf/#resource-description-framework-rdf-basics","text":"The Resource Description Framework (RDF) is the basic representation language and foundation of the Semantic Web. It addresses the fundamental issue of managing distributed data. All things in the world are referred to as resources . Resources can be anything: documents, people, physical objects as well as abstract concepts. The Resource Description Framework (RDF) is the framework for expressing information about such resources. It is useful if information on the Web is not only displayed, but needs to be processed by applications. The following introduction to RDF draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 27\u201350 which we warmly recommend for reading. Further information can be found in the RDF 1.1 Primer .","title":"Resource Description Framework (RDF) basics"},{"location":"developers/rdf/#a-note-about-the-examples-in-this-document","text":"It was aimed for to explain all following language features by using only one exemplary project. The setting of the chosen project is the following: It is about archaeological objects stemming from different findspots - known and unknown - and kept in different institutions around the world today. These objects show depictions of mythological scenes that illustrate episodes known from ancient literature, e.g. the Iliad or the Odyssey of Homer, or reflect thoughts of various ancient philosophers about the nature of our world and all creatures living therein. For some of these objects other data and documents exist on the Web, e.g. entries in museum databases, and we may possess low or high resolution images of them. Furthermore, the findspots - if known - can be identified unambigously by reference to geographical databases, e.g. GeoNames. If data are available in tabular form, the rows represent the items we intend to describe and each column represents some property of these items. The cells in the table then denote particular values for these properties. Table 1 shows a small excerpt of such a table from our exemplary project. ID Category City Institution InventoryNr. 1 Ceramics Boston Museum of Fine Arts 28.46 2 Glyptics London British Museum 2717 3 Relief New York Metropolitan Museum 24.97.11 In RDF, each of these cells has to be represented with three values which are called triples : a global reference for the row, a global reference for the column, and the value in the cell itself. The identifier for the row is the subject of the triple, the identifier for the column the predicate of the triple, and the value in the cell the object of the triple. There are three types of RDF data that can occur in triples: I nternational R esource I dentifiers ( IRI s) / U niversal R esource I dentifiers ( URI s), literals and blank nodes . A triple now describes the relationship between two resources which are the subject and the object of the triple. The predicate represents the nature of the relationship between subject and object. The relationship is directional - the predicate always points from the subject to the object - and is called a property . Table 2 shows all the triples of the data in Table 1. |Subject|Predicate|Object| |-----|:----:|---| |ID 1|belongsToCategory|Ceramics| |ID 1|todayIn|Boston| |ID 1|isKeptIn|Museum of Fine Arts| |ID 1|hasInventory|28.46| |ID 2|belongsToCategory|Glyptics| |ID 2|todayIn|London| |ID 2|isKeptIn|British Museum| |ID 2|hasInventory|2717| |ID 3|belongsToCategory|Relief| |ID 3|todayIn|New York| |ID 3|isKeptIn|Metropolitan Museum| |ID 3|hasInventory|24.97.11| Often, the same resource, e.g. a person, is referenced in multiple triples. When more than one triple refers to the same thing, it is more useful to view the triples in a directed graph where each triple is depicted by nodes and arcs: the subjects and objects of the triples are the nodes while the predicates denote the arcs with the predicate as label on the arc: Furthermore, if the subject or object is a URI/IRI or a blank node, it is depicted within an ellipse, if it is a literal value, however, within a rectangle. The graph display of the triples in Table 2 then looks as follows: Let's assume we possess the information in Table 3 from another source which we intend to merge with our data presented in Table 1. |Work|Author|Depiction| |-----|:----:|---| |Iliad|Homer|24.97.11| |Odyssey|Homer|24.97.11| This provides us with the following triples in Table 4: |Subject|Predicate|Object| |-----|:----:|---| |Iliad|hasAuthor|Homer| |Odyssey|hasAuthor|Homer| |Iliad|hasDepictionOn|24.97.11| |Odyssey|hasDepictionOn|24.97.11| The graph display of the triples in Table 2 concerning ID 3 and of the triples in Table 4 looks as follows: Since we now look at one specific example, namely \"ID 3\", all the values are literals and hence depicted in yellow rectangles.","title":"A note about the examples in this document"},{"location":"developers/rdf/#namespaces-uniform-resource-identifiers-uris-and-international-resource-identifiers-iris","text":"If we intend to merge information from different sources, an essential question is whether a node in one graph is the same node as a node in another graph. RDF solves this issue through use of U niform R esource I dentifiers (URIs) or I nternational R esource I dentifiers (IRIs). Our well known web addresses, the URLs, are just a special case of URIs and IRIs. An International Resource Identifier is the internationalised form of a URI. IRIs extend the allowed characters in URIs from a subset of the ASCII character set to almost all characters of the Universal Code Character Set (Unicode / ISO 10646). The syntax of the URI/IRI allows to deference it, i.e. to use all the information in the URI/IRI such as server name, protocol, port number, file name etc. to locate a file or a location on the Web. The possibility of dereferencing enables participation in a global Web infrastructure. URIs and IRIs are painful to write out in detail when expressing models. Hence, it is common to use an abbreviation scheme. Then a URI/IRI has two parts: a namespace and an identifier with a colon in between. The representation for the identifier United Kingdom in the namespace geonames is geonames:UnitedKingdom . URIs/IRIs may not contain embedded spaces. Hence, the so-called InterCap convention is followed: names that consist of multiple words are transformed to identifiers without spaces by capitalizing each word: \"part of\" becomes partOf , \"Measure for Measure\" MeasureForMeasure , and so on. The selection of namespaces is unrestricted. However, it is common practice to refer to related identifiers in a single namespace. Following the above example all geographical information would be placed into the suggestive namespace geonames . These names correspond to fully qualified URIs - geonames stands for material in the geographical database GeoNames . Using URIs/IRIs as standard for global identifiers enables for a worldwide reference and thus, two peolpe anywhere in the world to refer to the same thing unequivocally. This property allows for specifying certain terms by a standard organization such as W3C. W3C standards provide definitions for terms such as e.g. type , Class , subClassOf which are intended to apply globally across the Semantic Web. W3C has defined a number of standard namespaces for use with Web technologies. The most important are: * xsd: Indicates identifiers for XML schema definition. The global IRI for the xsd namespace is http://www.w3.org/2001/XMLSchema# . * xslns: Indicates identifiers for XML namespaces. The global IRI for the xslns namespace is https://www.w3.org/XML/1998/namespace . * rdf: Indicates identifiers used in RDF. The global IRI for the rdf namespace is http://www.w3.org/1999/02/22-rdf-syntax-ns# . * rdfs: Indicates identifiers used for the RDF Schema language (RDFS). The global IRI for the rdfs namespace is http://www.w3.org/2000/01/rdf-schema# . * owl: Indicates identifiers used for the Web Ontology Language (OWL). The global IRI for the owl namespace is http://www.w3.org/2002/07/owl# . Any URI in one of these namespaces - e.g. rdfs:subClassOf which is short for http://www.w3.org/2000/01/rdf-schema#subClassOf - refers to a particular term defined in the RDFS standard by the W3C. The term can also be dereferenced: at the server www.w3.org there is a page at the location 2000/01/rdf-schema with an entry about rdfs:subClassOf which gives additional information about this resource.","title":"Namespaces, Uniform Resource Identifiers (URIs) and International Resource Identifiers (IRIs)"},{"location":"developers/rdf/#literals","text":"Literals are values that are not URIs/IRIs. They may be simple strings such as \"Homer\", dates such as \"April 30th, 700 BCE\", numbers such as \"2.71828\". They are often associated with one of the following datatypes (list non-exhaustive): * boolean with value true or false * string with value character string * decimal with an arbitrary-precision decimal number as value * integer with an arbitrary-precision integer number as value * date with value in format yyyy-mm-dd Literals may only appear as object of a triple.","title":"Literals"},{"location":"developers/rdf/#identifiers-in-the-rdf-namespace","text":"The RDF data model specifies the notion of triples and the merging of sets of triples. With the introduction of namespaces RDF provides agreements on how to refer to a particular entity. The RDF standard defines a small number of standard identifiers in the namespace rdf . rdf:type is a property that provides an elementary system in RDF to define types. rdf:type can be the predicate of a triple, the subject of the triple can be any identifier and the object of the triple is understood to be a type. rdf:type can be used to e.g. state, that Homers works belong to a group of literary works we call Poetry: Subject Predicate Object Iliad rdf:type Poetry Odyssey rdf:type Poetry rdf:Property is an identifier to indicate when another identifier is to be used as a predicate rather than as subject or object. Some triples from our examples in Table 2 and Table 4 can be expressed with rdf:Property in the following way: Subject Predicate Object wrote rdf:type rdf:Property isKeptIn rdf:type rdf:Property hasDepictionOn rdf:type rdf:Property","title":"Identifiers in the RDF namespace"},{"location":"developers/rdf/#reification","text":"The strict subject - predicate - object form of RDF triples is limiting if one wants to qualify a statement further, if a statement about another statement seems desireable. We may wish to express that our object with ID 3 in Table 1 was bought by the Metropolitan Museum in 1924. Such a process of a statement about a statement is called reification . Reification can be achieved by different approaches. The easiest approach is to add just further triples expressing the desired relationship. myonto:ID3 myonto:todayIn \"New York\" . myonto:ID3 myonto:keptIn \"Metropolitan Museum\" . myonto:ID3 myonto:hasAccessionDate 1924 . The namespace myonto is used in the above example to express that the statements concern resources and properties which are defined in our own namespace. In contrast, otheronto will be used in following examples to express that an external not further defined namespace is referred to. The simple approach shown above works well if more information about some event or statement needs to be specified. However, it doesn't work well in cases when information about the statement itself shall be expressed: We may wish to express that the information that on our object with ID 3 in Table 1 scenes from the Iliad are depicted (information contained in Table 3) stems from the catalogue entry of this object in the online collection of the Metropolitan Museum. Such metadata about statements are often related with provenance indications, likelihood expressions, context information or time spans. In such cases it is necessary to explicitly make a statement about a statement. This process, called explicit reification is supported by the RDF standard with three resources called rdf:subject , rdf:predicate and rdf:object . With the following set of triples we can express that in the online collection of the Metropolitan Museum is written that ID 3 contains a depiction of scenes from the Iliad: myonto:n1 rdf:subject myonto:Iliad ; rdf:predicate myonto:hasDepictionOn ; rdf:object myonto:ID 3 . web:MetropolitanMuseum myonto:says myonto:n1 .","title":"Reification"},{"location":"developers/rdf/#expressing-rdf-in-textual-form-turtle","text":"When data are published in RDF on the Web the issue of representing RDF in text arises. There are multiple ways of achieving this. We are using a compact serialization of RDF which is called Turtle . It uses pre-defined shortcuts or namespaces. Since a binding between the local used namespaces and the global URIs/IRIs have to be achieved, Turtle begins with a preamble in which these bindings are defined: @prefix myonto: http://www.myontology @prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# With these abbreviations the triples can be expressed in subject/predicate/object order followed by a period. myonto:HomerWorks rdf:type myonto:Poetry . This statement expresses that Homer's literary works belong to the category of poetry. If several triples share a common subject it need not be repeated each time. Instead of terminating the first triple with a period, a semicolon (;) is used to indicate that another triple with the same subject follows. myonto:Homer rdf:type myonto:Author ; myonto:wrote \"Iliad\" . This statement expresses that in my ontology named myonto Homer is part of my class Author and that he wrote the Iliad. If there are several triples that share both subject and predicate, a comma (,) is used to separate the objects. E.g. to express, that Homer wrote both the Iliad and the Odyssey, I can use the following statement: myonto:Homer myonto:wrote myonto:Iliad, myonto:Odyssey . To improve terseness and readability Turtle provides some abbreviations. The most widley used abbreviation is the word a to mean rdf:type . Thus, the following two triples are equivalent, both telling that the class Ceramics in my ontology is part of a larger class called Category: myonto:Ceramics rdf:type myonto:Category . myonto:Ceramics a myonto:Category .","title":"Expressing RDF in textual form: Turtle"},{"location":"developers/rdf/#blank-nodes","text":"Sometimes we are aware of that something exists, that we know some things about it, but its identity is unknown. We want to express what we know about this resource without bothering to use a global identifier. Such a resource without a global identifier can be represented by a blank node. Blank nodes are comparable to the unknown variables x or y in an equation - they represent something without saying what their value is. Blank nodes can be the subject and/or the object of a triple. Within the framework of our example of archaeological objects showing depictions of Homeric poetry which are held by different institutions, the exact provenience of some objects may be unknown since they stem from illicit excavations and were bought on the antiquities market many years ago. Nevertheless, we know that each object possesses a provenience. A blank node is indicated by square brackets ([]). All triples of which it is a subject are placed within these brackets. The information that if an object was bought on the antiquities market no detail information about its find context is available can be put inside a blank node: [ rdf:type myonto:Market ; myonto:noInfo myonto:FindContext ] Such a blank node can then be referred to in other triples by including the entire bracketed sequence in place of the blank node. The following example expresses that all my objects which belong to the class UnprovenancedObj in my ontology myonto were bought on the antiquities market and for them I have no detail information about their find contexts available: myonto:UnprovenancedObj myonto:isPartOf [ rdf:type myonto:Market ; myonto:noInfo myonto:FindContext ]","title":"Blank nodes"},{"location":"developers/rdf/#ordered-information-in-rdf","text":"Ordering of RDF triples has to be specified explicitly: elements can be ordered in a list format. In Turtle an ordered list can be expressed by putting a sequence of objects within brackets (()). If we want to express that the king of Mykene, Agamemnon, was the father of four children, Iphigeneia being the oldest and Orestes being the youngest, we can express that in the following way: Agamemnon myonto:isFatherOf (Iphigeneia, Elektra, Chrysothemis, Orestes) .","title":"Ordered information in RDF"},{"location":"developers/rdf/#rdf-schema-rdfs","text":"RDF simply creates a graph structure to represent data. The RDF S chema (RDFS) is a semantic extension of RDF wich provides some guidelines about how to use this graph structure, i.e. it imposes special syntactic conditions or restrictions upon RDF graphs. The schema is informaton about the data. It should help to provide meaning to the data. Thus, it is a layer on top of the RDF layer to describe consistency constraints in the data. The key to these levels is inferencing . The statements of meaning are given in the form of an inference pattern: \"Given some initial information, the following new information can be derived.\" That's the way the RDF Schema language (RDFS) and also the Web Ontology Language (OWL) work. All schema information in RDFS is expressed by RDF triples. The meaning of asserted triples is defined with new inferred triples. The structures that describe the meaning of the data are also in triples. The following introduction to RDF Schema draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 113\u2013152 which we warmly recommend for reading. Further information can be found in the Recommendations of RDF Schema 1.1 .","title":"RDF Schema (RDFS)"},{"location":"developers/rdf/#asserted-triples-and-inferred-triples","text":"Asserted triples are triple data that were explicitly added in the original RDF store. Inferred triples are additional triples that are inferred by one of the inference rules. There is no logical distinction between inferred and asserted triples. Hence, one should be careful concerning inference rules and how to implement them. The RDFS and OWL standards define for certain patterns of triples which inferences are valid. The simplest approach is to store all triples in a single store and to ignore whether they are asserted or inferred. This approach is called cached inferencing since all inferences are stored with the data. It is simple, but the number of triples in the triple store increases and some inferred triples may later turn out to be incorrect und unwarranted. The other extreme is to never actually store any inferred triples in any persistent store. Then, inferencing is done in response to queries only. This approach can be called just in time inferencing , since the inferences are made just in time. The query responses are produced such that they respect all the appropriate inferences, but no inferred triple is retained. Both approaches have an important impact if data sources change, i.e. if a triple is deleted or a new triple added. If cached inferencing was chosen, originally inferred triples which are no longer valid must be identified and removed or new ones added. An important variant of just in time inferencing is where explicit inferencing is undesired. What kind of inferencing is needed depends on the required level of expressivity for a certain task. There are different inferencing levels. RDFS operates on a small number of inference rules that deal mostly with relating classes to subclasses and properties to classes. OWL includes constraints on properties and notions of equality and includes rules for describing classes based on allowed values for properties. All these standards use inferencing, but they differ in the inferencing that they support.","title":"Asserted triples and inferred triples"},{"location":"developers/rdf/#classes","text":"Resources can be grouped in classes which are themselves resources. The members of such a class are known as instances of the class. Classes are often identified by URIs/IRIs. All RDF datatypes are classes. The instances of a class that is a datatype are the members of the value space of the datatype. Thus, \"3.14\" is an instance of the class decimal, \"4\" is an instance of the class integer, \"2000-01-01\" is an instance of the class date, etc. The basic construct for specifying a group of related resources in RDFS is called an rdfs:Class . The way to express that something is a class is with a triple in which the predicate is rdf:type and the object is rdfs:Class as in the following examples: myonto:Ceramics rdf:type rdfs:Class . myonto:BlackFigured rdf:type rdfs:Class . These triples express that our resources Ceramics and BlackFigured are classes. One of the basic terms is rdfs:subClassOf . The meaning of \" B is a subClassOf C \" is \"every member of class B is also a member of class C\", expressed in the form of an inference. From a further information \" x is a member of B \" one can derive the new information \" x is a member of C \". Speaking more generally, if a class A is a subclass of another class B, then anything of type A is also of type B. This is called the type propagation rule . This feature of inference systems is particulary useful in a Semantic Web context in which new combinations of relationships likely occur as data from multiple sources are merged. In the framework of our example the class BlackFigured is a subclass of the class Ceramics . For any member of the class BlackFigured we can then derive that it is also a member of the class Ceramics due to the following statement : myonto:BlackFigured rdfs:subClassOf myonto:Ceramics . A class may be a member of its own class extension and an instance of itself, this applies e.g. for rdfs:Class .","title":"Classes"},{"location":"developers/rdf/#properties","text":"An RDF property describes the relationship between a subject resource and an object resource.","title":"Properties"},{"location":"developers/rdf/#properties-with-inferences","text":"One of the most fundemantal terms in RDFS is rdfs:subPropertyOf . It is a transitive property and allows a modeler to describe a hierarchy of related properties. If we want to express that some of the people who work for a museum are permanently employed while others possess only loose contracts we could express this fact with the following triples: myonto:isEmployedBy rdfs:subPropertyOf myonto:worksFor . myonto:contractsTo rdfs:subPropertyOf myonto:worksFor . Regardless whether a person is employed by the museum or is a contractor, the person works for the museum. Other basic properties are rdfs:range and rdfs:domain . They have meanings inspired by the mathematical use of the words range and domain : the domain of a function is the set of values for which it is defined, its range is the set of values it can take. Both give informaton about how a property P is to be used: domain refers to the subject of any triple that uses P as its predicate, range refers to the object of any such triple.","title":"Properties with inferences"},{"location":"developers/rdf/#rdfsdomain","text":"P rdfs:domain D . means that property P has domain D . From this we can infer that the subject of that triple is a member of the class D . rdfs:domain can be used to specify with which class the defined property can be used with. It is possible to specify multiple rdfs:domain properties when defining a property. We pick just two classes from our example - Ceramics and BlackFigured - which show a subclass relation: myonto:BlackFigured rdfs:subClassOf myonto:Ceramics . We now have a property called incised whose domain is BlackFigured . myonto:incised rdfs:domain myonto:BlackFigured . This means that all my objects with incised decoration belong to the class BlackFigured .","title":"rdfs:domain"},{"location":"developers/rdf/#rdfsrange","text":"P rdfs:range R . means that the property P has range R . From this we can infer that the object (the value of P ) of that triple is a member of class R . If the predicate of a triple has more than one rdfs:range property, the resources denoted by the objects of triples are instances of all the classes stated by the rdfs:range properties. If we want to specify that queens who gave birth to a son could theoretically become queen mothers, we could do that with the following combination of rdfs:domain and rdfs:range : myonto:hasSon rdfs:domain myonto:Queen . myonto:hasSon rdfs:range myonto:QueenMother . It is important to know that if P is used in an inconsistent way with this declaration, RDFS does not signal an error, but rather infers the necessary type information to bring P into accordance with its domain and range declarations! In RDFS, there is no notion of an incorrect or inconsistent inference, i.e. it will never proclaim an input as invalid but simply infer appropriate type information. Domains and ranges are not used to validate information, but to determine new information based on old information. In practice, there are often better and more appropriate options to use instead of rdfs:domain and rdfs:range alone.","title":"rdfs:range"},{"location":"developers/rdf/#properties-without-inferences","text":"RDFS provides some properties from which no inferences can be drawn, i.e. no inference semantics is defined for them. They are useful and important for documentation purposes. These are rdfs:label , rdfs:comment , rdfs:seeAlso and rdfs:isDefinedBy . Resources on the Semantic Web are specified by IRIs/URIs which are not meaningful to people. Thus, RDFS provides the property rdfs:label whose intended use is to provide a human-readable version for any resource's name. Multilingual labels are possible if the language tagging facility of RDF literals is used. myonto:BlackFigured rdfs:label \"black-figured vessels\"@en, \"schwarzfigurige Gef\u00e4sse\"@de . Frequently it is useful to add comments about a model, i.e. to document it properly. In RDFS, rdfs:comment is an instance of rdf:Property that can be used to provide a human-readable description of a resource. Multilingual documentation is possible if the language tagging facility of RDF literals is used. To make a comment a triple using the property rdfs:comment as a predicate has to be asserted. myonto:BlackFigured rdfs:comment \"The class BlackFigured contains ceramic vessels where the decoration is painted with black paint.\" . In the case where a resource is an URL, supplementary information about this resource may be useful. This additional information is often included in documents. rdfs:seeAlso provides a way to specify the web location of such supplementary information. The web location has to be given in the form of an IRI/URI! The precise behaviour of a processor is not specified, but most tools that encounter rdfs:seeAlso link them to those links in a browser or application interface. In our example we could link findspots of archaeological objects to a web resource with geodata, e.g. GeoNames, in the following way: myonto:latitude rdfs:seeAlso geonames:lat . rdfs:isDefinedby provides a link to the primary resource of information about a resource. Thus, the definitional description of a resource can be found, e.g. rdfs:isDefinedBy is defined in RDF to be a rdfs:subPropertyOf of rdfs:seeAlso .","title":"Properties without inferences"},{"location":"developers/rdf/#combinations-and-patterns","text":"","title":"Combinations and patterns"},{"location":"developers/rdf/#intersection","text":"RDFS inference rules are few and rather simple. More specific patterns can be obtained by combining basic RDFS features. One such case is set intersection. If we intend to draw the inference that if a resource x is an instance of class C , then it should also be an instance of classes A and B , expressing the formal relationship C \u2286 A \u2229 B . Such an inference can be obtained by making C a subclass of A and B : :C rdfs:subClassOf :A . :C rdfs:subClassOf :B . Due to the inference rule defined for rdfs:subClassOf we can infer from the triple x rdf:type :C . the desired triples x rdf:type :A . x rdf:type :B . Thus, from a membership in C membership in A and B can be inferred. But from membership in A and B membership in C cannot be inferred! Inferences can only be drawn in one direction. In an analogous way to the treatment of classes, set intersection can be defined for properties using the construct rdfs:subPropertyOf .","title":"Intersection"},{"location":"developers/rdf/#union","text":"The union of two sets ( A \u222a B \u2286 C ) can be obtained by making C a superclass of A and B . :A rdfs:subClassOf :C . :B rdfs:subClassOf :C . Then, for any instance x that is either a member of class A or of B it will be inferred that it is also a member of class C . In an analogous way to the treatment of classes, set union can be defined for properties using rdfs:subPropertyOf .","title":"Union"},{"location":"developers/rdf/#collections","text":"A collection is represented as a list of items. rdf:List is an instance of rdfs:Class that can be used to build descriptions of lists and other list-like structures.","title":"Collections"},{"location":"developers/rdf/#summary","text":"The following Figure 4 illustrates the concepts of resource, class, and sub-class based on our example project. Figure 5 shows the same in a more general way: resources are denoted by a large black dot and arrows are drawn from a resource to the class it defines. A sub-class is shown by a rectangle (the sub-class) completely enclosed by another (the super-class), i.e. class ConstraintProperty is a subclass of class Property. The notion rdf:type specifies that something is a member of a group, i.e. an instance of a class. By using rdfs:Class instead of rdf:type a description of the meaning of a membership in a group is gained. Meaning is expressed through the mechanisms of inference in RDFS that can be drawn when a resource is used in a certain way. The following Figure 6 expresses the same information about the class hierarchy, but does so using a graphic representation of the RDF data model. If a class is a subset of another, there is an arc labelled \"s\" from the node representing the first class to the node representing the second one (\"s\" stands for rdfs:subClassOf ). If a resource was an instance of a class, then there is an arc labelled \"t\" from the resource to the node representing the class (\"t\" stands for rdf:type ). Not all arcs are drawn, e.g. rdfs:ConstraintProperty is a subclass of rdfs:Resource because it is a subclass of rdf:Property which is a subclass of rdfs:Resource . Examples: - The class rdfs:Literal is an instance of rdfs:Class and an instance of rdfs:Resource . - The class rdf:Property is the class of RDF properties and an instance of rdfs:Class .","title":"Summary"},{"location":"developers/rdf/#web-ontology-language-owl","text":"OWL is intended to be used when information contained in documents needs to be processed by applications, it explicitly represents the meaning of terms in vocabularies and the relationship between those terms. The representation of terms and their interrelationships are called an ontology . A concrete syntax is needed in order to store ontologies and to exchange them among tools and applications. The primary exchange syntax for OWL is the XML syntax for RDF (RDF/XML), but other syntaxes such as e.g. Turtle are also frequently used. The data described by an OWL ontology is interpreted as a set of \"individuals\" and a set of \"property assertions\" which relate these individuals to each other. An ontology consists of a set of axioms which place constraints on sets of individuals called \"classes\" and the types of relationships permitted between them. OWL ontologies can import other ontologies, adding information from the imported ontology to the current ontology. The main building blocks of the OWL language are an RDF graph and at least one concrete syntax - there may be more than one - that can be used to serialize and exchange ontologies. OWL has been designed to meet the needs for a Web Ontology Language. It is part of the W3C recommendations related to the Semantic Web: - XML provides a surface syntax for structured documents, but imposes no semantic constraints. - XML Schema is a language for restricting the structure of XML documents and extends XML with datatypes. - RDF is a datamodel for objects and relations between them. Furthermore, it provides a simple semantics for this datamodel and these datamodels can be represented in an XML syntax. - RDF Schema is a vocabulary for describing properties and classes of RDF resources, with a semantics for generalization-hierarchies of such properties and classes. - OWL then adds more vocabulary to RDF for describing properties and classes: e.g. relations between classes, cardinality, equality, characteristics of properties and enumerated classes. The following introduction to OWL draws heavily on the book of Dean Allemang & James Hendler, Semantic Web for the Working Ontologist. Effective Modeling in RDFS and OWL, Second Edition, 2011, 153\u2013305 which we warmly recommend for reading. Further information can be found in the Recommendations of the OWL 2 Web Ontology Language Document Overview (Second Edition) and the Wikipedia entry of OWL .","title":"Web Ontology Language (OWL)"},{"location":"developers/rdf/#owlclass","text":"In OWL, a Class defines a group of individuals that belong together because they share some properties. An owl:Class differs from an rdfs:Class - an owl:Class is a special case of an rdfs:Class . Classes can be organised in a hierarchy using rdfs:subClassOf . Thus, owl:Class is defined as a subclass of rdfs:Class : owl:Class rdfs:subClassOf rdfs:Class . This means that every member of an owl:Class is also a member of rdfs:Class . There is a built-in most general class named owl:Thing which is the class of all individuals. It is a superclass of all OWL classes. There is also a built-in class named owl:Nothing which is the class that has no instances. It is a subclass of all OWL classes.","title":"owl:Class"},{"location":"developers/rdf/#owlinverseof","text":"Extra language features that are not directly provided by OWL, but that one may desire, such as e.g. superClassOf , are often supported by OWL as a combination of other features. The construct owl:inverseOf inverses a property, i.e. the direction of the property is reversed. This property can be used to define e.g. the superClassOf of a resource by combining it with rdfs:subClassOf in the following way: myonto:superClassOf owl:inverseOf rdfs:subClassOf .","title":"owl:inverseOf"},{"location":"developers/rdf/#owlsymmetricproperty","text":"For a symmetric property holds that if a pair (x,y) is an instance of the property P, then also the pair (y,x) is an instance of this property P. Such a property is provided by owl:SymmetricProperty and expressed in OWL as a Class. An example for such a property is to be married - if Agamemnon is married to Klytaimnestra, Klytaimnestra is also married to Agamemnon. Thus we can define a property married in our ontology with the following triples: myonto:married rdf:type owl:SymmetricProperty . Agamemnon myonto:married Klytaimnestra . Be aware - to make sure that owl:inverseOf works in both directions, one has to assert that owl:inverseOf rdf:type owl:SymmetricProperty .","title":"owl:SymmetricProperty"},{"location":"developers/rdf/#owltransitiveproperty","text":"Another important property is transitivity. Transitivity is a relation between three elements such that if it holds between the first and second and it also holds between the second and third, it must necessarily hold between the first and the third. In OWL, transitivity is provided by the construct owl:TransitiveProperty which is a class of properties. To model the property isLocatedIn in our ontology as a member of the transitive class we can state myonto:isLocatedIn rdf:type owl:TransitiveProperty . Together with the triples Rome myonto:isLocatedIn Italy . Italy myonto:isLocatedIn Europe . we can infer that Rome is located in Europe.","title":"owl:TransitiveProperty"},{"location":"developers/rdf/#owlequivalentclass","text":"A frequent situation is that if information about the same entity from different sources is merged then the two providers of this information will not have used the same URI/IRI for refering to the same entity. When combining these data it may be useful to state that two URIs/IRIs actually refer to the same entity. When two classes are known to always have the same members, they are said to be equivalent . Such a situation can be expressed with one simple statement using owl:equivalentClass : owl:equivalentClass rdf:type owl:SymmetricProperty . myonto:GreekGods owl:equivalentClass otheronto:Deities . The second triple expresses that the class GreekGods in our ontology is equivalent to the class Deities in some other ontology we refer to. Note that when two classes are equivalent, it only means that they have the same members. But other properties of these classes aren't shared!","title":"owl:equivalentClass"},{"location":"developers/rdf/#owlequivalentproperty","text":"If one intends to state that two properties are equivalent, owl:equivalentProperty can be used: myonto:isInvisible owl:equivalentClass otheronto:notSeen . This statement expresses that the property which is called isInvisible in our ontology, is named notSeen in some other ontology.","title":"owl:equivalentProperty"},{"location":"developers/rdf/#owlsameas","text":"If it turns out that two individuals are actually one and the same, owl:sameAs can be used to state this fact: myonto:Puteoli owl:sameAs otheronto:Puzzeoli . This statement expresses that the site which is called Puteoli in our ontology, is the same as a site named Puzzeoli in some other ontology.","title":"owl:sameAs"},{"location":"developers/rdf/#owlfunctionalproperty","text":"A functional property owl:FunctionalProperty is a property which can only have one single value. An everyday example for such a property is e.g. hasBirthplace since each person has only one birth place. Functional properties can be useful to infer sameness, e.g. if names with foreign characters are transliterated differently in two sources - a Greek \"B\" may be transliterated either as \"B\" or as \"V\", we can state: myonto:GreekB owl:FunctionalProperty otheronto:GreekV .","title":"owl:FunctionalProperty"},{"location":"developers/rdf/#owlinversefunctionalproperty","text":"However, it is more common to use the related notion of owl:InverseFunctionalProperty . One can think of this construct to be the inverse of owl:FunctionalProperty as its name suggests. Especially identifying numbers are inverse functional properties. myonto:hasInventoryNumber rdf:type owl:InverseFunctionalProperty . myonto:ID3 myonto:hasInventoryNumber \"24.97.11\" . otheronto:ID2435 myonto:hasInventoryNumber \"24.97.11\" . From the above example follows that ID 3 in my data set is the same object as ID 2435 in another data set. It is sometimes useful for a single property to be an owl:FunctionalProperty and an owl:InverseFunctionalProperty . This means that it is a one-to-one property: for each individual there is exactly one value for the property and the other way round. This feature is intended in the case of unique identifiers as in the following example: myonto:hasID rdfs:domain myonto:Monument . myonto:hasID rdfs:range xsd:Integer . myonto:hasID rfd:type owl:FunctionalProperty . myonto:hasID rfd:type owl:InverseFunctionalProperty . This means that each member of class Monument possesses a unique identifier that is an integer number. Any two monuments that share an ID must be the same (due to inverse functionality) and in addition, each monument can have at most one ID (due to functionality).","title":"owl:InverseFunctionalProperty"},{"location":"developers/rdf/#owlobjectproperty-and-owldatatypeproperty","text":"The constructs owl:sameAs , owl:FunctionalProperty and owl:InverseFunctionalProperty especially help to describe how information from multiple sources can be merged. OWL can also provide useful information for editing tools if a value of some property may be either a link to another object or a widget for a particular data type. For this purpose OWL distinguishes between owl:DatatypeProperty and owl:ObjectProperty . owl:DatatypeProperty can have a data value as object, owl:ObjectProperty can have a resource as object. myonto:inSameMuseum rdf:type owl:ObjectProperty. myonto:shipVoyage rdf:type owl:DatatypeProperty. The first example may be used to express that one archaeological object is kept in the same museum as another archaeological object while the second example may select those individuals who participated in a ship voyage such as e.g. the Argonauts.","title":"owl:ObjectProperty and owl:DatatypeProperty"},{"location":"developers/rdf/#restrictions","text":"The construct owl:Restriction allows to describe individuals of classes in terms of existing properties and classes that have already been modeled. The class of all things in OWL called owl:Thing is unrestricted. A restriction provides some description that limits the kinds of things that can be said about a member of the class. A restriction class in OWL is defined by the keyword owl:onProperty . A description of how the new class is constrained can be provided e.g. by owl:allValuesFrom , owl:someValuesFrom and owl:hasValue . The membership in a restriction class must satisfy the specified conditions as well as the owl:onProperty specification.","title":"Restrictions"},{"location":"developers/rdf/#property-constraints","text":"owl:someValuesFrom selects all individuals from a class for which at least one value of the property P comes from class C . In our example we can formulate such a restriction as: [a owl:Restriction; owl:onProperty myonto:isLocatedIn; owl:someValuesFrom myonto:Museum] All archaeological objects kept in a museum today thus have been defined as all archaeological objects for which at least one value of the property isLocatedIn comes from the class Museum . The [ ] notation refers to a blank node which is described by the properties listed here. This restriction class has no specific name associated with it - it is defined by the properties of the restriction and is hence called an unnamed class . owl:allValuesFrom selects all individuals from a class for which all values of the property P come from class C . In our example we can formulate such a restriction as: [a owl:Restriction; owl:onProperty myonto:hasProvenience; owl:allValuesFrom myonto:Findspot] This restriction selects all our archaeological objects for which the findspot is known. A noteworthy difference between owl:someValuesFrom and owl:allValuesFrom is that the former implies that there must be such a member, while the latter technically means if there are any members, then they all must have this property which doesn't imply that there are any members. owl:hasValue is used to produce a restriction of the form \"all individuals that have the value A for the property P \". We can formulate such a restriction as: [ a owl:Restriction ; owl:onProperty myonto:P ; owl:hasValue myonto:A ] . Let's assume we defined a property myonto:hasImage which helps to select archaeological objects for which we possess images. We can now state a restriction for those with high resolution images: myonto:HighResolutionObject owl:equivalentClass [ a owl:Restriction ; owl:onProperty myonto:hasImage; owl:hasValue myonto:hasHighresImage ] . That we have such a high resolution image of a certain object we can formulate with the following triple: myonto:ID3 myonto:hasImage myonto:hasHighresImage . Then it is possible to deduce myonto:ID3 a myonto:HighResolutionObject . owl:hasValue is just a special case of the owl:someValuesFrom restriction. Nevertheless, it is very useful because it effectively turns specific instance descriptions into class descriptions. OWL provides a facility for defining new classes as unions ( owl:unionOf ) and intersections ( owl:intersectionOf ) of previously defined classes. The union of two or more classes includes the members of all those classes while the intersection includes only those that belong to every one of the classes. OWL allows to enumerate the members of a class using the construct owl:oneOf . If I have a class myonto:ObjectsSomeSmallMuseum with the members \"vase1\", \"vase2\" and \"relief1\", then: myonto:ObjectsSomeSmallMuseum rdf:type owl:Class; owl:oneOf (myonto:vase1 myonto:vase2 myonto:relief1). My class myonto:ObjectsSomeSmallMuseum is related via the property owl:oneOf to a list of the members of the class. However, owl:oneOf should be used only in situations in which the definition of the class is not likely to change at all or at least not frequently. One such case would e.g. be the number of planets in the solar system. In contrast, the above example may be appropriate for our own immediate needs, but not for a more general approach: although we include only three objects of this small museum in our data, the museum itself for sure owns many more. Sometimes it may be useful to state that one thing is different from another thing. OWL provides owl:differentFrom for this. An example is the following: myonto:Zenon owl:differentFrom otheronto:Zenon. Two different ancient Greek philosophers with the name Zenon are known. The above triple states that the Zenon in our ontology (e.g. Zenon of Elea) is not the same Zenon as in another ontology (e.g. Zenon of Kition).","title":"Property constraints"},{"location":"developers/rdf/#cardinalities","text":"OWL also includes restrictions that refer to cardinalities , i.e. the number of values for a specific property. Cardinality restrictions can be used to define sets of particular interest. Cardinality refers to the number of distinct values a property has. The fact that we only know about two works attributed to Homer - the Iliad and the Odyssey - we may state by using owl:cardinality : [a owl:Restriction; owl:onProperty myonto:HomerWorks; owl:cardinality 2] Cardinality restrictions can also be used to specify upper and lower boundaries, the respective constructs are named owl:maxCardinality and owl:minCardinality . The restriction to cardinalities of 0 and 1 have special modeling utility: minCardinality 0 indicates a set of individuals for which some value for a specified property is optional minCardinality 1 indicates a set of individuals for which some value for a specified property is required maxCardinality 0 specifies that no value for the specified property is allowed maxCardinality 1 specifies that a value is unique (but need not exist)","title":"Cardinalities"},{"location":"developers/rdf/#reasoning-with-individuals-and-classes","text":"From an RDF perspective inferences about individuals and inferences about classes are very similar: in both cases new triples are added to the model based on the asserted triples. However, from a modeling perspective, these two kinds of reasoning are very different. The former draws specific conclusions about individuals while the latter draws general conclusions about classes of individuals. In the case of reasoning about individuals the information specified in one source is transformed according to a model for use in another context with the help of constructs such as rdfs:subClassOf , rdfs:subPropertyOf and various owl:Restriction . Class reasoning determines how data are related in general with constructs such as rdfs:subClassOf , rdfs:subPropertyOf , rdfs:domain or rdfs:range . Once these more general relationships have been inferred, the processing of the data can be done much easier.","title":"Reasoning with individuals and classes"},{"location":"developers/rdf/#composing-files","text":"OWL provides a built-in class owl:Ontology . The URI/IRI of an ontology usually corresponds to the URL of the file on the Web where the ontology is stored. The corresponding URI/IRI can be eclosed in angle brackets as follows: <http://www.knora.org/ontology/knora-base> rdf:type owl:Ontology. This can be useful when modularity of semantic models is specified. The most frequent way to specify modularity is with the property owl:imports . This property connects two instances of the class owl:Ontology .","title":"Composing files"},{"location":"developers/rdf/#summary-of-constructs","text":"rdfs:subClassOf - the members of a subclass are also a member of a superclass rdfs:subPropertyOf - relations described by a subproperty also hold for the superproperty rdfs:domain - the subject of a triple is classified into the domain of the predicate rdfs:range - the object of a triple is classified into the range of the predicate rdfs:label - human-readable name of a resource, no semantics inferable rdfs:comment - human-readable information of the model, no semantics inferable owl:equivalentClass - the members of each class are also members of the other class owl:equivalentProperty - relations that hold for each property also hold for the other property owl:sameAs - all statements about one instance hold for the other instance owl:inverseOf - exchanges subject and object owl:TransitiveProperty - the chains of a relationship collapse into a single relationship owl:SymmetricProperty - the property is its own inverse owl:FunctionalProperty - only one value as object allowed owl:InverseFunctionalProperty - only one value as subject allowed owl:ObjectProperty - the property can have a resource as object owl:DatatypeProperty - the property can have a data value as object owl:Restriction - a building block in OWL that describes classes by restricting the values that are allowed for certain properties owl:hasValue - a type of restriction that refers to a single value for a property owl:someValuesFrom - a type of restriction that refers to a set from which some value for a property must come owl:allValuesFrom - a type of restriction that refers to a set from which all values for a property must come owl:onProperty - a link from a restriction to the property it restricts. owl:unionOf - unites classes and creates a new class owl:intersectionOf - determines the intersection of classes and creates a new class owl:complementOf - determines the compliment of a class and creates a new class owl:oneOf - specifies that a class consists just of the listed members owl:differentFrom - specifies that one individual is not identical to another one owl:disjointWith - specifies that two classes cannot share a member owl:cardinality - specifies information about the number of distict values for some property owl:minCardinality - specifies information about the minimum number of distinct values for a property owl:maxCardinality - specifies information about the maximum number of distinct values for a property owl:imports - allows one ontology to refer explicitly to another ontology.","title":"Summary of constructs"},{"location":"developers/dsp/contribution/","text":"How to contribute to the development of the DSP The DSP software is developed under git version control using GitHub . It includes the following main repositories: In all these repositories, we follow the GitHub flow recommendations: Create a branch from main . Add commits . Open a pull request . Discuss and review your code . Merge into main branch. Create Branch Guidelines You will work on an own branch to resolve one issue or user story defined on Jira . Each of those issues has a DEV-number which has to be used in the branch name: wip/<DEV-nr>-<subject> The prefix wip stands for \"work in progress\" followed by a \"/\" (slash). The second part starts with the DEV-number followed by a short subject which contains a succinct description of the issue/user story. DEV-number and subject have to be written in kebab-case with \"-\" (hyphens). Git Commit Guidelines We follow strict rules how a commit message has to look like. This leads to more readable messages that are easy to follow when looking through the project history and release notes. Since release notes are automatically generated from commits, it is important to follow the Conventional Commit messages . Commit Message Format <type>(<scope>): <subject> Type Must be one of the following: fix : represents bug fixes, and correlates to a SemVer patch . refactor : represents production code refactoring, and correlates to a patch . feat : represents a new feature, and correlates to a SemVer minor . feat! , fix! , refactor! , etc.: represents a breaking change (indicated by the ! ) and will result in a SemVer major .\\ \u26a0 It is important that the exclamation mark is placed before the colon. For example feat!: <subject> or feat(api-v2)!: <subject> docs : documentation changes (no production code change). chore : maintenance tasks (no production code change). style : styles update (no production code change). test : all about tests: adding, refactoring tests (no production code change). The first four items on this list are taken into account for the release notes and have an effect on the version number. Scope (optional) The scope could be anything specifying place of the commit change. Subject The subject contains succinct description of the change: use the imperative, present tense: \"change\" not \"changed\" nor \"changes\" don't capitalize first letter no dot (.) at the end Pull Request Guidelines Set title and add description A pull request usually resolves one issue or user story defined on Jira . Since we started to use the release-please-action it's very important to set the PR title in the correct way, especially because all commits added within the pull request are squashed. Otherwise, PRs with bad titles won't be added to the automatically generated CHANGELOG and release notes. Thus, every PR title has to follow the commit message convention mentioned above , with small modifications. PR Title Format <type>(<scope>): <subject> (<DEV-no.>) It's crucial to start the PR title with the <type> ( allowed types ), followed by optional <scope> (in brackets and without space between type and scope). <subject> should be Jira task title or its short version. At the end of the PR title add inside the brackets <DEV-no.> , which represents the number of the task(s) related to the PR. Here is an example: docs(contribution): example pull request title (DEV-001) The PR description should contain important information for its reviewers. Don't copy/paste the Jira task description here. Instead, start the description by adding the following: Resolves <DEV-no.> GitHub's Autolink Setting will automatically generate a link to the Jira issue. Add a label (optional) This step is optional, since it has no impact on the release process anymore. However, adding at least one of the corresponding labels to your PR will help quickly realize its purpose: breaking : breaking changes. enhancement : new feature. bug : a bug fix. styling update style (no production code change). documentation : changes to the documentation. testing : all about tests: adding, refactoring tests (no production code change). refactor : refactoring production code. chore : maintenance tasks (no production code change). dependencies : update a dependency package version. Make a draft Please convert the pull request to draft as long it isn't ready for reviewing. As soon as the PR is ready for review , click on the corresponding button \"Ready for review\". Branch protection rules The main branch of each repo (it's usually the main branch) is protected by the following rules: Require pull request reviews before merging At least from one reviewer Require status checks to pass before merging Require branches to be up-to-date before merging Status checks e.g. tests defined in each repository's CI When the PR is merged, the branch will be deleted automatically. Code Review Guidelines Reviewers should pay attention to proper PR title setting . General GitHub actions workflows (CI) We use GitHub actions to automate some processes. Run tests With each push to GitHub, the tests of the repository are executed. Successful tests are needed to merge code into the repository's main branch (s. Branch protection rules ). Prepare release We use release-please-action to prepare the next release. This action script automates the CHANGELOG generation, the creation of GitHub releases, and version bumps. In doing so, it creates a release PR which updates itself with each push into main branch following the commit messages. It's important to use the defined rules from above in all commits and in PR titles . Create release When we are ready to tag a release, simply merge the release PR. This will create a release on GitHub, builds the npm package or the docker image and publishes on the corresponding platform.","title":"Contribution"},{"location":"developers/dsp/contribution/#how-to-contribute-to-the-development-of-the-dsp","text":"The DSP software is developed under git version control using GitHub . It includes the following main repositories: In all these repositories, we follow the GitHub flow recommendations: Create a branch from main . Add commits . Open a pull request . Discuss and review your code . Merge into main branch.","title":"How to contribute to the development of the DSP"},{"location":"developers/dsp/contribution/#create-branch-guidelines","text":"You will work on an own branch to resolve one issue or user story defined on Jira . Each of those issues has a DEV-number which has to be used in the branch name: wip/<DEV-nr>-<subject> The prefix wip stands for \"work in progress\" followed by a \"/\" (slash). The second part starts with the DEV-number followed by a short subject which contains a succinct description of the issue/user story. DEV-number and subject have to be written in kebab-case with \"-\" (hyphens).","title":"Create Branch Guidelines"},{"location":"developers/dsp/contribution/#git-commit-guidelines","text":"We follow strict rules how a commit message has to look like. This leads to more readable messages that are easy to follow when looking through the project history and release notes. Since release notes are automatically generated from commits, it is important to follow the Conventional Commit messages .","title":"Git Commit Guidelines"},{"location":"developers/dsp/contribution/#commit-message-format","text":"<type>(<scope>): <subject>","title":"Commit Message Format"},{"location":"developers/dsp/contribution/#type","text":"Must be one of the following: fix : represents bug fixes, and correlates to a SemVer patch . refactor : represents production code refactoring, and correlates to a patch . feat : represents a new feature, and correlates to a SemVer minor . feat! , fix! , refactor! , etc.: represents a breaking change (indicated by the ! ) and will result in a SemVer major .\\ \u26a0 It is important that the exclamation mark is placed before the colon. For example feat!: <subject> or feat(api-v2)!: <subject> docs : documentation changes (no production code change). chore : maintenance tasks (no production code change). style : styles update (no production code change). test : all about tests: adding, refactoring tests (no production code change). The first four items on this list are taken into account for the release notes and have an effect on the version number.","title":"Type"},{"location":"developers/dsp/contribution/#scope-optional","text":"The scope could be anything specifying place of the commit change.","title":"Scope (optional)"},{"location":"developers/dsp/contribution/#subject","text":"The subject contains succinct description of the change: use the imperative, present tense: \"change\" not \"changed\" nor \"changes\" don't capitalize first letter no dot (.) at the end","title":"Subject"},{"location":"developers/dsp/contribution/#pull-request-guidelines","text":"","title":"Pull Request Guidelines"},{"location":"developers/dsp/contribution/#set-title-and-add-description","text":"A pull request usually resolves one issue or user story defined on Jira . Since we started to use the release-please-action it's very important to set the PR title in the correct way, especially because all commits added within the pull request are squashed. Otherwise, PRs with bad titles won't be added to the automatically generated CHANGELOG and release notes. Thus, every PR title has to follow the commit message convention mentioned above , with small modifications.","title":"Set title and add description"},{"location":"developers/dsp/contribution/#pr-title-format","text":"<type>(<scope>): <subject> (<DEV-no.>) It's crucial to start the PR title with the <type> ( allowed types ), followed by optional <scope> (in brackets and without space between type and scope). <subject> should be Jira task title or its short version. At the end of the PR title add inside the brackets <DEV-no.> , which represents the number of the task(s) related to the PR. Here is an example: docs(contribution): example pull request title (DEV-001) The PR description should contain important information for its reviewers. Don't copy/paste the Jira task description here. Instead, start the description by adding the following: Resolves <DEV-no.> GitHub's Autolink Setting will automatically generate a link to the Jira issue.","title":"PR Title Format"},{"location":"developers/dsp/contribution/#add-a-label-optional","text":"This step is optional, since it has no impact on the release process anymore. However, adding at least one of the corresponding labels to your PR will help quickly realize its purpose: breaking : breaking changes. enhancement : new feature. bug : a bug fix. styling update style (no production code change). documentation : changes to the documentation. testing : all about tests: adding, refactoring tests (no production code change). refactor : refactoring production code. chore : maintenance tasks (no production code change). dependencies : update a dependency package version.","title":"Add a label (optional)"},{"location":"developers/dsp/contribution/#make-a-draft","text":"Please convert the pull request to draft as long it isn't ready for reviewing. As soon as the PR is ready for review , click on the corresponding button \"Ready for review\".","title":"Make a draft"},{"location":"developers/dsp/contribution/#branch-protection-rules","text":"The main branch of each repo (it's usually the main branch) is protected by the following rules: Require pull request reviews before merging At least from one reviewer Require status checks to pass before merging Require branches to be up-to-date before merging Status checks e.g. tests defined in each repository's CI When the PR is merged, the branch will be deleted automatically.","title":"Branch protection rules"},{"location":"developers/dsp/contribution/#code-review-guidelines","text":"Reviewers should pay attention to proper PR title setting .","title":"Code Review Guidelines"},{"location":"developers/dsp/contribution/#general-github-actions-workflows-ci","text":"We use GitHub actions to automate some processes.","title":"General GitHub actions workflows (CI)"},{"location":"developers/dsp/contribution/#run-tests","text":"With each push to GitHub, the tests of the repository are executed. Successful tests are needed to merge code into the repository's main branch (s. Branch protection rules ).","title":"Run tests"},{"location":"developers/dsp/contribution/#prepare-release","text":"We use release-please-action to prepare the next release. This action script automates the CHANGELOG generation, the creation of GitHub releases, and version bumps. In doing so, it creates a release PR which updates itself with each push into main branch following the commit messages. It's important to use the defined rules from above in all commits and in PR titles .","title":"Prepare release"},{"location":"developers/dsp/contribution/#create-release","text":"When we are ready to tag a release, simply merge the release PR. This will create a release on GitHub, builds the npm package or the docker image and publishes on the corresponding platform.","title":"Create release"},{"location":"developers/libraries/","text":"Libraries DSP-JS DSP-JS is a library to facilitate the communication with DSP-API in web clients developed with TypeScript/JavaScript. It depends on RxJS and is web framework agnostic (it can be used with Angular, React, Vue.js etc.). \u2192 Go to the DSP-JS documentation","title":"Libraries"},{"location":"developers/libraries/#libraries","text":"","title":"Libraries"},{"location":"developers/libraries/#dsp-js","text":"DSP-JS is a library to facilitate the communication with DSP-API in web clients developed with TypeScript/JavaScript. It depends on RxJS and is web framework agnostic (it can be used with Angular, React, Vue.js etc.). \u2192 Go to the DSP-JS documentation","title":"DSP-JS"},{"location":"developers/sipi/","text":"SIPI basics The media server SIPI The S imple I mage P resentation I nterface (Sipi) takes care of storing, converting and serving image, audio and video files as well as other documents such as pdf files. It is designed to be used by all institutions that need to preserve high-quality images and to make them available online. SIPI implements the I nternational I mage I nteroperability F ramework ( IIIF ), which aims at supporting interoperability between different image repositories. SIPI efficiently converts lossless between image formats while preserving the metadata contained in the image files. If images are stored in JPEG 2000 format, SIPI can convert them on the fly to formats that are commonly used on the Internet. SIPI is written in C++ and runs on Linux and Mac OS X. It offers a flexible framework for specifying authentication and authorization logic which is obtained by scripts written in the scripting language Lua . SIPI supports restricted access to images, either by reducing the image dimensions or by adding watermarks to the images. Interaction of DSP-API and SIPI If a file is requested from SIPI by e.g. an image link served by DSP-API, a preflight function is called. This function needs three parameters: a prefix, the identifier (the name of the requested file) and a cookie. All file links created by DSP-API use the project number as prefix. An example link from our incunabula project may look as follows: 0.0.0.0:1024/0803/incunabula_0000003328.jp2/full/2613,3505/0/default.jpg . Based on the provided information, SIPI asks DSP-API about the permissions on the file in question of the current user. Therefore, the cookie is needed: it contains the current user's DSP-API session ID. Hence, DSP-API can match SIPI's request with a given user profile and tell SIPI the permissions this user has on the requested file. If the user has sufficient permissions, the file is served in full quality. If the user has only preview rights, SIPI serves a reduced quality of the file or integrates a watermark. If the user has no permissions, SIPI refuses to serve the file. However, all of this behaviour is defined in the preflight function in SIPI and not controlled by DSP-API. DSP-API only provides the permission code. Thus, DSP-API and SIPI stick to a clear division of responsibility regarding files: DSP-API knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from SIPI, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by SIPI. When a user creates a resource with a digital representation attached to it in DSP-API either via the G raphical U ser I nterface (GUI) or directly via the A pplication P rogramming I nterface (API), the file is directly sent to SIPI to calculate a thumbnail hosted by SIPI which then gets displayed to the user in the browser. SIPI copies the original file into a temporary directory and keeps it there for later processing in another request. In its answer in JSON format, SIPI returns the path to the thumbnail, the name of the temporarily stored original file managed by SIPI, the mime type of the original file and the original name of the file submitted by the client. At the moment when the user wants to attach the file to a resource, the request is sent to DSP-API's API providing all the required parameters to create the resource along with additional information about the file to be attached. The file itself is not submitted to the DSP-API's API, but its filename returned by SIPI.","title":"Sipi"},{"location":"developers/sipi/#sipi-basics","text":"","title":"SIPI basics"},{"location":"developers/sipi/#the-media-server-sipi","text":"The S imple I mage P resentation I nterface (Sipi) takes care of storing, converting and serving image, audio and video files as well as other documents such as pdf files. It is designed to be used by all institutions that need to preserve high-quality images and to make them available online. SIPI implements the I nternational I mage I nteroperability F ramework ( IIIF ), which aims at supporting interoperability between different image repositories. SIPI efficiently converts lossless between image formats while preserving the metadata contained in the image files. If images are stored in JPEG 2000 format, SIPI can convert them on the fly to formats that are commonly used on the Internet. SIPI is written in C++ and runs on Linux and Mac OS X. It offers a flexible framework for specifying authentication and authorization logic which is obtained by scripts written in the scripting language Lua . SIPI supports restricted access to images, either by reducing the image dimensions or by adding watermarks to the images.","title":"The media server SIPI"},{"location":"developers/sipi/#interaction-of-dsp-api-and-sipi","text":"If a file is requested from SIPI by e.g. an image link served by DSP-API, a preflight function is called. This function needs three parameters: a prefix, the identifier (the name of the requested file) and a cookie. All file links created by DSP-API use the project number as prefix. An example link from our incunabula project may look as follows: 0.0.0.0:1024/0803/incunabula_0000003328.jp2/full/2613,3505/0/default.jpg . Based on the provided information, SIPI asks DSP-API about the permissions on the file in question of the current user. Therefore, the cookie is needed: it contains the current user's DSP-API session ID. Hence, DSP-API can match SIPI's request with a given user profile and tell SIPI the permissions this user has on the requested file. If the user has sufficient permissions, the file is served in full quality. If the user has only preview rights, SIPI serves a reduced quality of the file or integrates a watermark. If the user has no permissions, SIPI refuses to serve the file. However, all of this behaviour is defined in the preflight function in SIPI and not controlled by DSP-API. DSP-API only provides the permission code. Thus, DSP-API and SIPI stick to a clear division of responsibility regarding files: DSP-API knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from SIPI, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by SIPI. When a user creates a resource with a digital representation attached to it in DSP-API either via the G raphical U ser I nterface (GUI) or directly via the A pplication P rogramming I nterface (API), the file is directly sent to SIPI to calculate a thumbnail hosted by SIPI which then gets displayed to the user in the browser. SIPI copies the original file into a temporary directory and keeps it there for later processing in another request. In its answer in JSON format, SIPI returns the path to the thumbnail, the name of the temporarily stored original file managed by SIPI, the mime type of the original file and the original name of the file submitted by the client. At the moment when the user wants to attach the file to a resource, the request is sent to DSP-API's API providing all the required parameters to create the resource along with additional information about the file to be attached. The file itself is not submitted to the DSP-API's API, but its filename returned by SIPI.","title":"Interaction of DSP-API and SIPI"}]}